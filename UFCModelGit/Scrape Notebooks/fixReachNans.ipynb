{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fight</th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>event</th>\n",
       "      <th>referee</th>\n",
       "      <th>method_of_victory</th>\n",
       "      <th>date</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>...</th>\n",
       "      <th>redCorner_subs_attempted</th>\n",
       "      <th>blueCorner_subs_attempted</th>\n",
       "      <th>round</th>\n",
       "      <th>time</th>\n",
       "      <th>redCorner_height</th>\n",
       "      <th>blueCorner_height</th>\n",
       "      <th>redCorner_reach</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Magomed Ankalaev vs Johnny Walker</td>\n",
       "      <td>Magomed Ankalaev</td>\n",
       "      <td>Johnny Walker</td>\n",
       "      <td>Magomed Ankalaev</td>\n",
       "      <td>UFC Fight Night: Ankalaev vs. Walker 2</td>\n",
       "      <td>Marc Goddard</td>\n",
       "      <td>KO/TKO</td>\n",
       "      <td>01.13.2024</td>\n",
       "      <td>UFC Apex</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2:42</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>6' 6\"</td>\n",
       "      <td>75\"</td>\n",
       "      <td>82\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jim Miller vs Gabriel Benitez</td>\n",
       "      <td>Jim Miller</td>\n",
       "      <td>Gabriel Benitez</td>\n",
       "      <td>Jim Miller</td>\n",
       "      <td>UFC Fight Night: Ankalaev vs. Walker 2</td>\n",
       "      <td>Dan Miragliotta</td>\n",
       "      <td>Submission</td>\n",
       "      <td>01.13.2024</td>\n",
       "      <td>UFC Apex</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3:25</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>71\"</td>\n",
       "      <td>71\"</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mario Bautista vs Ricky Simon</td>\n",
       "      <td>Ricky Simon</td>\n",
       "      <td>Mario Bautista</td>\n",
       "      <td>Mario Bautista</td>\n",
       "      <td>UFC Fight Night: Ankalaev vs. Walker 2</td>\n",
       "      <td>Mark Smith</td>\n",
       "      <td>Decision - Unanimous</td>\n",
       "      <td>01.13.2024</td>\n",
       "      <td>UFC Apex</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brunno Ferreira vs Phil Hawes</td>\n",
       "      <td>Phil Hawes</td>\n",
       "      <td>Brunno Ferreira</td>\n",
       "      <td>Brunno Ferreira</td>\n",
       "      <td>UFC Fight Night: Ankalaev vs. Walker 2</td>\n",
       "      <td>Chris Tognoni</td>\n",
       "      <td>KO/TKO</td>\n",
       "      <td>01.13.2024</td>\n",
       "      <td>UFC Apex</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4:55</td>\n",
       "      <td>6' 0\"</td>\n",
       "      <td>5' 10\"</td>\n",
       "      <td>77\"</td>\n",
       "      <td>72\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Waldo Cortes Acosta vs Andrei Arlovski</td>\n",
       "      <td>Andrei Arlovski</td>\n",
       "      <td>Waldo Cortes Acosta</td>\n",
       "      <td>Waldo Cortes Acosta</td>\n",
       "      <td>UFC Fight Night: Ankalaev vs. Walker 2</td>\n",
       "      <td>Marc Goddard</td>\n",
       "      <td>Decision - Unanimous</td>\n",
       "      <td>01.13.2024</td>\n",
       "      <td>UFC Apex</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>6' 4\"</td>\n",
       "      <td>77\"</td>\n",
       "      <td>78\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    fight         redCorner  \\\n",
       "0       Magomed Ankalaev vs Johnny Walker  Magomed Ankalaev   \n",
       "1           Jim Miller vs Gabriel Benitez        Jim Miller   \n",
       "2           Mario Bautista vs Ricky Simon       Ricky Simon   \n",
       "3           Brunno Ferreira vs Phil Hawes        Phil Hawes   \n",
       "4  Waldo Cortes Acosta vs Andrei Arlovski   Andrei Arlovski   \n",
       "\n",
       "            blueCorner               winner  \\\n",
       "0        Johnny Walker     Magomed Ankalaev   \n",
       "1      Gabriel Benitez           Jim Miller   \n",
       "2       Mario Bautista       Mario Bautista   \n",
       "3      Brunno Ferreira      Brunno Ferreira   \n",
       "4  Waldo Cortes Acosta  Waldo Cortes Acosta   \n",
       "\n",
       "                                    event          referee  \\\n",
       "0  UFC Fight Night: Ankalaev vs. Walker 2     Marc Goddard   \n",
       "1  UFC Fight Night: Ankalaev vs. Walker 2  Dan Miragliotta   \n",
       "2  UFC Fight Night: Ankalaev vs. Walker 2       Mark Smith   \n",
       "3  UFC Fight Night: Ankalaev vs. Walker 2    Chris Tognoni   \n",
       "4  UFC Fight Night: Ankalaev vs. Walker 2     Marc Goddard   \n",
       "\n",
       "      method_of_victory        date     venue title_fight  ...  \\\n",
       "0                KO/TKO  01.13.2024  UFC Apex          no  ...   \n",
       "1            Submission  01.13.2024  UFC Apex          no  ...   \n",
       "2  Decision - Unanimous  01.13.2024  UFC Apex          no  ...   \n",
       "3                KO/TKO  01.13.2024  UFC Apex          no  ...   \n",
       "4  Decision - Unanimous  01.13.2024  UFC Apex          no  ...   \n",
       "\n",
       "  redCorner_subs_attempted  blueCorner_subs_attempted  round  time  \\\n",
       "0                      0.0                        0.0      2  2:42   \n",
       "1                      1.0                        0.0      3  3:25   \n",
       "2                      0.0                        0.0      3  5:00   \n",
       "3                      0.0                        0.0      1  4:55   \n",
       "4                      0.0                        0.0      3  5:00   \n",
       "\n",
       "   redCorner_height  blueCorner_height  redCorner_reach  blueCorner_reach  \\\n",
       "0             6' 3\"              6' 6\"              75\"               82\"   \n",
       "1             5' 8\"              5' 8\"              71\"               71\"   \n",
       "2             5' 6\"              5' 9\"              69\"               69\"   \n",
       "3             6' 0\"             5' 10\"              77\"               72\"   \n",
       "4             6' 3\"              6' 4\"              77\"               78\"   \n",
       "\n",
       "   redCorner_stance blueCorner_stance  \n",
       "0          Orthodox          Orthodox  \n",
       "1          Southpaw          Southpaw  \n",
       "2          Orthodox            Switch  \n",
       "3          Orthodox          Orthodox  \n",
       "4          Orthodox          Orthodox  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create df\n",
    "df = pd.read_csv('databaseUpdated-01.18.2024.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proxies: 39\n"
     ]
    }
   ],
   "source": [
    "#generate proxyList\n",
    "proxylist =[]\n",
    "with open('working_proxies.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        proxylist.append(row[0])\n",
    "print(f'Proxies: {len(proxylist)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProxyUserAgent():\n",
    "    for i in proxylist:\n",
    "        #test to see if website is accessible\n",
    "        userAgents = ['Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/116.0','Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/115.0','Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36','Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36','Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36','Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0','Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/116.0','Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36 Edg/115.0.1901.188','insomnia/8.4.5','Mozilla/5.0 (Linux; Android 13; Pixel 6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (Linux; Android 13; Pixel 6a) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (Linux; Android 13; Pixel 6 Pro) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (Linux; Android 13; Pixel 7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (Linux; Android 13; Pixel 7 Pro) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (Linux; Android 12; moto g pure) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (Linux; Android 12; moto g stylus 5G) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36v','Mozilla/5.0 (Linux; Android 13; SM-G998U) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (iPhone; CPU iPhone OS 12_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) FxiOS/13.2b11866 Mobile/16A366 Safari/605.1.15','Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/11.0 Mobile/15A372 Safari/604.1']\n",
    "        userAgent = userAgents[random.randint(0,len(userAgents)-1)]\n",
    "        try:\n",
    "            payload = ''\n",
    "            headers = {\n",
    "                \"cookie\": \"_tapology_mma_session=zo%252F9cU1na2qfRAvGf4E%252FBdxyMqNEgZbmqUYGnDxTYw%252BkgkuquO4qPimSMq%252FNc4fAxpLoIGwkl%252Fvw%252FhO04rqrL1PuS7516fTWktFyWhkz6YUy7MvWUVyjNQ7R26QYA8TeQruG5w%252B6RAj71bMME5MxoLjpSOs%252FyinaA6qsprmBZ2LnagrpzZ7bxaPvk7o%252FohTgZgxpo0FGWGaDdHERD%252B3Bt3C3ucykGOC7WB65EM8xB6C8gMNzGsvEu8FbvGnbMaoqzGzx%252FjRprzFrLN4mE5vdrJ1fsjoDV9cn5NEE2zI%253D--IkSvjCRiM5qMGaKi--o55iUwoIEhI6T8jM4UW6tA%253D%253D\",\n",
    "                \"User-Agent\": f'{userAgent}'\n",
    "            }\n",
    "\n",
    "            url = \"https://www.tapology.com\"\n",
    "        \n",
    "            #site request\n",
    "            #soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "            response = requests.request(\"GET\", url, data=payload, headers=headers, proxies={'http': f\"http://{i}\"})\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            boutInfo = soup.find('div', class_=re.compile('right'))\n",
    "            labels = boutInfo.find_all('li')\n",
    "            proxyheader = [i,userAgent]\n",
    "            return proxyheader\n",
    "        except:\n",
    "            pass\n",
    "        #check to see if uesr agent was the issue\n",
    "        try:\n",
    "            userAgents.remove(userAgent)\n",
    "            userAgent = userAgents[random.randint(0,len(userAgents)-1)]\n",
    "            payload = ''\n",
    "            headers = {'User-Agent':f'{userAgent}',\n",
    "            \"cookie\": \"_tapology_mma_session=TCLB17ieOPnBLmCBTuxpX8s3uBODZMN3jL3jBbFhwPoywfbzG7gyvp%252BAzbOk4gOZ%252FOCykOUwcpEoJBwoj2rJyiMxdHWSaiLFkBYjfuUDpZ2VY6ECFn6rpTPmUBY1Zr2anIqiklY6fz9yQlBkPAhcx%252BWSzVgsc%252B%252F8UCqkb6WnM6xr8GUikb8U2UkMVYZ3Nj1dIA0vbXpDhKykqgW%252BCnlyglp8rtdlQ37m0SaYWjLDthG7Tik3idUvGlSXFAU55zAnxz6UNncMNhTbo5ltINfso54j60i7hOq0utNOz9w%253D--ChZexYwNpevIJ%252BV8--HhKStLELFfNWYOTZIAKM6Q%253D%253D\"}\n",
    "            url = \"https://www.tapology.com/fightcenter/bouts/2974-ufc-64-clay-the-carpenter-guida-vs-justin-pretty-boy-james\"\n",
    "        \n",
    "            #site request\n",
    "            #soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "            response = requests.request(\"GET\", url, data=payload, headers=headers, proxies={'http': f\"http://{i}\"})\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            boutInfo = soup.find('div', class_=re.compile('right'))\n",
    "            labels = boutInfo.find_all('li')\n",
    "            proxyheader = [i,userAgent]\n",
    "            return proxyheader\n",
    "        #if user agent is not new issue, wait for next IP\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            print(\"Waiting for new IP...\")\n",
    "            ipurl = \"https://ipecho.net/plain\"\n",
    "            ipHeader = {\"User-Agent\": \"insomnia/8.4.5\"}\n",
    "            ipr = requests.request(\"GET\", url=ipurl, headers=ipHeader)\n",
    "            soup = BeautifulSoup(ipr.content, 'html.parser')\n",
    "            currentIp = soup.text.strip()\n",
    "            newIP = soup.text.strip()\n",
    "            while(currentIp == newIP):\n",
    "                ipurl = \"https://ipecho.net/plain\"\n",
    "                ipHeader = {\"User-Agent\": \"insomnia/8.4.5\"}\n",
    "                ipr = requests.request(\"GET\", url=ipurl, headers=ipHeader)\n",
    "                soup = BeautifulSoup(ipr.content, 'html.parser')\n",
    "                newIP = soup.text.strip()\n",
    "                time.sleep(15)\n",
    "            userAgents.remove(userAgent)\n",
    "            userAgent = userAgents[random.randint(0,len(userAgents)-1)]\n",
    "            payload = ''\n",
    "            headers = {'User-Agent':f'{userAgent}',\n",
    "            \"cookie\": \"_tapology_mma_session=TCLB17ieOPnBLmCBTuxpX8s3uBODZMN3jL3jBbFhwPoywfbzG7gyvp%252BAzbOk4gOZ%252FOCykOUwcpEoJBwoj2rJyiMxdHWSaiLFkBYjfuUDpZ2VY6ECFn6rpTPmUBY1Zr2anIqiklY6fz9yQlBkPAhcx%252BWSzVgsc%252B%252F8UCqkb6WnM6xr8GUikb8U2UkMVYZ3Nj1dIA0vbXpDhKykqgW%252BCnlyglp8rtdlQ37m0SaYWjLDthG7Tik3idUvGlSXFAU55zAnxz6UNncMNhTbo5ltINfso54j60i7hOq0utNOz9w%253D--ChZexYwNpevIJ%252BV8--HhKStLELFfNWYOTZIAKM6Q%253D%253D\"}\n",
    "            url = \"https://www.tapology.com/fightcenter/bouts/2974-ufc-64-clay-the-carpenter-guida-vs-justin-pretty-boy-james\"\n",
    "        \n",
    "            #site request\n",
    "            #soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "            response = requests.request(\"GET\", url, data=payload, headers=headers, proxies={'http': f\"http://{i}\"})\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            boutInfo = soup.find('div', class_=re.compile('right'))\n",
    "            labels = boutInfo.find_all('li')\n",
    "            proxyheader = [i,userAgent]\n",
    "            return proxyheader\n",
    "        except:\n",
    "            print(\"Maintenence required...\")\n",
    "            input(\"Press enter to continue\")\n",
    "            userAgents.remove(userAgent)\n",
    "            userAgent = userAgents[random.randint(0,len(userAgents)-1)]\n",
    "            payload = ''\n",
    "            headers = {'User-Agent':f'{userAgent}',\n",
    "            \"cookie\": \"_tapology_mma_session=TCLB17ieOPnBLmCBTuxpX8s3uBODZMN3jL3jBbFhwPoywfbzG7gyvp%252BAzbOk4gOZ%252FOCykOUwcpEoJBwoj2rJyiMxdHWSaiLFkBYjfuUDpZ2VY6ECFn6rpTPmUBY1Zr2anIqiklY6fz9yQlBkPAhcx%252BWSzVgsc%252B%252F8UCqkb6WnM6xr8GUikb8U2UkMVYZ3Nj1dIA0vbXpDhKykqgW%252BCnlyglp8rtdlQ37m0SaYWjLDthG7Tik3idUvGlSXFAU55zAnxz6UNncMNhTbo5ltINfso54j60i7hOq0utNOz9w%253D--ChZexYwNpevIJ%252BV8--HhKStLELFfNWYOTZIAKM6Q%253D%253D\"}\n",
    "            url = \"https://www.tapology.com/fightcenter/bouts/2974-ufc-64-clay-the-carpenter-guida-vs-justin-pretty-boy-james\"\n",
    "        \n",
    "            #site request\n",
    "            #soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "            response = requests.request(\"GET\", url, data=payload, headers=headers, proxies={'http': f\"http://{i}\"})\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            boutInfo = soup.find('div', class_=re.compile('right'))\n",
    "            labels = boutInfo.find_all('li')\n",
    "            proxyheader = [i,userAgent]\n",
    "            return proxyheader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('---', np.nan, inplace=True)\n",
    "df.replace('--', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1582\n",
      "           redCorner      blueCorner redCorner_height blueCorner_height  \\\n",
      "2581  Maurice Greene  Michel Batista            6' 7\"             6' 3\"   \n",
      "\n",
      "     redCorner_reach blueCorner_reach redCorner_stance blueCorner_stance  \\\n",
      "2581             80\"              NaN         Orthodox          Orthodox   \n",
      "\n",
      "      redCorner_age  blueCorner_age        date  \n",
      "2581           34.0            32.0  11.30.2018  \n"
     ]
    }
   ],
   "source": [
    "#find nans to fix\n",
    "columns_of_interest = ['redCorner_reach', 'blueCorner_reach', 'redCorner_stance', 'blueCorner_stance', 'redCorner_age', 'blueCorner_age',]\n",
    "\n",
    "first_row_with_nan = df[df[columns_of_interest].isnull().any(axis=1)].head(1)\n",
    "\n",
    "values_to_print = first_row_with_nan[['redCorner', 'blueCorner', 'redCorner_height', 'blueCorner_height', 'redCorner_reach', 'blueCorner_reach', 'redCorner_stance', 'blueCorner_stance', 'redCorner_age', 'blueCorner_age', 'date']]\n",
    "\n",
    "total_nans = df[columns_of_interest].isnull().sum().sum()\n",
    "\n",
    "print(total_nans)\n",
    "print(values_to_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6161\n",
    "for index, row in df.loc[:2415].iterrows():\n",
    "    reach = None\n",
    "    if row['blueCorner_reach'] is np.nan or row['blueCorner_reach'] is np.nan:\n",
    "        fighter = row['blueCorner']\n",
    "        fighterList = fighter.split(' ')\n",
    "        if len(fighterList) == 1:\n",
    "            url = f'https://www.tapology.com/search?term={fighterList[0]}&commit=Submit&model%5Bfighters%5D=fightersSearch'\n",
    "\n",
    "            #getProxyHeader\n",
    "            proxyheader = getProxyUserAgent()\n",
    "            proxy = proxyheader[0]\n",
    "            userAgent = proxyheader[1]\n",
    "\n",
    "            #define headers\n",
    "            headers = {\n",
    "            \"cookie\": \"_tapology_mma_session=nUbYZsmfBxCMml3EfKnycLX59tOCxmooAxj8ifN56kFksGAYkSXxKRVIy7bT2%252FXP9kIGTPOV3O%252BN1%252B4GWiNAjhG9S8sCeUtN3W2bwuxKzi8XGqMMYBSU1NWLZnSqZSIME2kzEx4xwAIBlWjakwZAGvZYuo4mIAV1OmuP%252B6n%252FU5ps1xWx1z%252BHrPIex61hMrNZpQfSwZNsbHcOLcrEjFLxfWUeIq7knZyMBQPGrlD%252BcSOCROXMSCXkEe7DbSgmZQLI5PVfbsBzN29g6irLU4XHrtsn%252FeZ%252BWFBGkAz1fEo%253D--thae17JwlRQtS%252BZB--4vVdpKGWVPPNtOCCVdkaWg%253D%253D\",\n",
    "            \"User-Agent\": f'{userAgent}'\n",
    "            }\n",
    "\n",
    "            #site request\n",
    "            site = requests.get(url, headers=headers, proxies={'http': f\"http://{proxy}, 'https:'https/{proxy}\"})\n",
    "            soup = BeautifulSoup(site.content, 'html.parser')\n",
    "\n",
    "            #get href\n",
    "            linkPart = soup.find('td', class_=re.compile('altA'))\n",
    "            a = linkPart.find('a')\n",
    "            href = a['href']\n",
    "\n",
    "            url = f'https://tapology.com{href}'\n",
    "            #site request\n",
    "            site = requests.get(url, headers=headers, proxies={'http': f\"http://{proxy}, 'https:'https/{proxy}\"})\n",
    "            soup = BeautifulSoup(site.content, 'html.parser')\n",
    "            \n",
    "            div = soup.find('div', class_=re.compile('details details_two_columns'))\n",
    "            lis = div.find_all('li')\n",
    "            for li in lis:\n",
    "                if 'Reach:' in li.text.strip():\n",
    "                    spans = li.find_all('span')\n",
    "                    if len(spans)>1:\n",
    "                        reachTemp = spans[1].text.strip()\n",
    "                        reachList = reachTemp.split(' ')\n",
    "                        reach = str(reachTemp[0])\n",
    "                        df.at[index, 'blueCorner_reach'] = reach\n",
    "        if len(fighterList) == 2:\n",
    "            url = f'https://www.tapology.com/search?term={fighterList[0]}+{fighterList[1]}&commit=Submit&model%5Bfighters%5D=fightersSearch'\n",
    "            \n",
    "            #getProxyHeader\n",
    "            proxyheader = getProxyUserAgent()\n",
    "            proxy = proxyheader[0]\n",
    "            userAgent = proxyheader[1]\n",
    "\n",
    "            #define headers\n",
    "            headers = {\n",
    "            \"cookie\": \"_tapology_mma_session=nUbYZsmfBxCMml3EfKnycLX59tOCxmooAxj8ifN56kFksGAYkSXxKRVIy7bT2%252FXP9kIGTPOV3O%252BN1%252B4GWiNAjhG9S8sCeUtN3W2bwuxKzi8XGqMMYBSU1NWLZnSqZSIME2kzEx4xwAIBlWjakwZAGvZYuo4mIAV1OmuP%252B6n%252FU5ps1xWx1z%252BHrPIex61hMrNZpQfSwZNsbHcOLcrEjFLxfWUeIq7knZyMBQPGrlD%252BcSOCROXMSCXkEe7DbSgmZQLI5PVfbsBzN29g6irLU4XHrtsn%252FeZ%252BWFBGkAz1fEo%253D--thae17JwlRQtS%252BZB--4vVdpKGWVPPNtOCCVdkaWg%253D%253D\",\n",
    "            \"User-Agent\": f'{userAgent}'\n",
    "            }\n",
    "\n",
    "            #site request\n",
    "            site = requests.get(url, headers=headers, proxies={'http': f\"http://{proxy}, 'https:'https/{proxy}\"})\n",
    "            soup = BeautifulSoup(site.content, 'html.parser')\n",
    "\n",
    "            #get href\n",
    "            linkPart = soup.find('td', class_=re.compile('altA'))\n",
    "            a = linkPart.find('a')\n",
    "            href = a['href']\n",
    "\n",
    "            url = f'https://tapology.com{href}'\n",
    "            #site request\n",
    "            site = requests.get(url, headers=headers, proxies={'http': f\"http://{proxy}, 'https:'https/{proxy}\"})\n",
    "            soup = BeautifulSoup(site.content, 'html.parser')\n",
    "            \n",
    "            div = soup.find('div', class_=re.compile('details details_two_columns'))\n",
    "            lis = div.find_all('li')\n",
    "            for li in lis:\n",
    "                if 'Reach:' in li.text.strip():\n",
    "                    spans = li.find_all('span')\n",
    "                    if len(spans)>1:\n",
    "                        reachTemp = spans[1].text.strip()\n",
    "                        reachList = reachTemp.split(' ')\n",
    "                        reach = str(reachTemp[0])\n",
    "                        df.at[index, 'blueCorner_reach'] = reach\n",
    "        if len(fighterList) == 3:\n",
    "            url =f'https://www.tapology.com/search?term={fighterList[0]}+{fighterList[1]}+{fighterList[2]}&commit=Submit&model%5Bfighters%5D=fightersSearch'\n",
    "            #getProxyHeader\n",
    "            proxyheader = getProxyUserAgent()\n",
    "            proxy = proxyheader[0]\n",
    "            userAgent = proxyheader[1]\n",
    "\n",
    "            #define headers\n",
    "            headers = {\n",
    "            \"cookie\": \"_tapology_mma_session=nUbYZsmfBxCMml3EfKnycLX59tOCxmooAxj8ifN56kFksGAYkSXxKRVIy7bT2%252FXP9kIGTPOV3O%252BN1%252B4GWiNAjhG9S8sCeUtN3W2bwuxKzi8XGqMMYBSU1NWLZnSqZSIME2kzEx4xwAIBlWjakwZAGvZYuo4mIAV1OmuP%252B6n%252FU5ps1xWx1z%252BHrPIex61hMrNZpQfSwZNsbHcOLcrEjFLxfWUeIq7knZyMBQPGrlD%252BcSOCROXMSCXkEe7DbSgmZQLI5PVfbsBzN29g6irLU4XHrtsn%252FeZ%252BWFBGkAz1fEo%253D--thae17JwlRQtS%252BZB--4vVdpKGWVPPNtOCCVdkaWg%253D%253D\",\n",
    "            \"User-Agent\": f'{userAgent}'\n",
    "            }\n",
    "\n",
    "            #site request\n",
    "            site = requests.get(url, headers=headers, proxies={'http': f\"http://{proxy}, 'https:'https/{proxy}\"})\n",
    "            soup = BeautifulSoup(site.content, 'html.parser')\n",
    "\n",
    "            #get href\n",
    "            linkPart = soup.find('td', class_=re.compile('altA'))\n",
    "            a = linkPart.find('a')\n",
    "            href = a['href']\n",
    "\n",
    "            url = f'https://tapology.com{href}'\n",
    "            #site request\n",
    "            site = requests.get(url, headers=headers, proxies={'http': f\"http://{proxy}, 'https:'https/{proxy}\"})\n",
    "            soup = BeautifulSoup(site.content, 'html.parser')\n",
    "            \n",
    "            div = soup.find('div', class_=re.compile('details details_two_columns'))\n",
    "            lis = div.find_all('li')\n",
    "            for li in lis:\n",
    "                if 'Reach:' in li.text.strip():\n",
    "                    spans = li.find_all('span')\n",
    "                    if len(spans)>1:\n",
    "                        reachTemp = spans[1].text.strip()\n",
    "                        reachList = reachTemp.split(' ')\n",
    "                        reach = str(reachTemp[0])\n",
    "                        df.at[index, 'blueCorner_reach'] = reach\n",
    "        if len(fighterList) == 4:\n",
    "            url = f'https://www.tapology.com/search?term={fighterList[0]}+{fighterList[1]}+{fighterList[2]}+{fighterList[3]}&commit=Submit&model%5Bfighters%5D=fightersSearch'\n",
    "            #getProxyHeader\n",
    "            proxyheader = getProxyUserAgent()\n",
    "            proxy = proxyheader[0]\n",
    "            userAgent = proxyheader[1]\n",
    "\n",
    "            #define headers\n",
    "            headers = {\n",
    "            \"cookie\": \"_tapology_mma_session=nUbYZsmfBxCMml3EfKnycLX59tOCxmooAxj8ifN56kFksGAYkSXxKRVIy7bT2%252FXP9kIGTPOV3O%252BN1%252B4GWiNAjhG9S8sCeUtN3W2bwuxKzi8XGqMMYBSU1NWLZnSqZSIME2kzEx4xwAIBlWjakwZAGvZYuo4mIAV1OmuP%252B6n%252FU5ps1xWx1z%252BHrPIex61hMrNZpQfSwZNsbHcOLcrEjFLxfWUeIq7knZyMBQPGrlD%252BcSOCROXMSCXkEe7DbSgmZQLI5PVfbsBzN29g6irLU4XHrtsn%252FeZ%252BWFBGkAz1fEo%253D--thae17JwlRQtS%252BZB--4vVdpKGWVPPNtOCCVdkaWg%253D%253D\",\n",
    "            \"User-Agent\": f'{userAgent}'\n",
    "            }\n",
    "\n",
    "            #site request\n",
    "            site = requests.get(url, headers=headers, proxies={'http': f\"http://{proxy}, 'https:'https/{proxy}\"})\n",
    "            soup = BeautifulSoup(site.content, 'html.parser')\n",
    "\n",
    "            #get href\n",
    "            linkPart = soup.find('td', class_=re.compile('altA'))\n",
    "            a = linkPart.find('a')\n",
    "            href = a['href']\n",
    "\n",
    "            url = f'https://tapology.com{href}'\n",
    "            #site request\n",
    "            site = requests.get(url, headers=headers, proxies={'http': f\"http://{proxy}, 'https:'https/{proxy}\"})\n",
    "            soup = BeautifulSoup(site.content, 'html.parser')\n",
    "            \n",
    "            div = soup.find('div', class_=re.compile('details details_two_columns'))\n",
    "            lis = div.find_all('li')\n",
    "            for li in lis:\n",
    "                if 'Reach:' in li.text.strip():\n",
    "                    spans = li.find_all('span')\n",
    "                    if len(spans)>1:\n",
    "                        reachTemp = spans[1].text.strip()\n",
    "                        reachList = reachTemp.split(' ')\n",
    "                        reach = str(reachTemp[0])\n",
    "                        df.at[index, 'blueCorner_reach'] = reach\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
