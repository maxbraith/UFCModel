{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "from csv import writer\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "import concurrent.futures\n",
    "import datetime\n",
    "import datetime\n",
    "from datetime import date\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get name of most recent database\n",
    "mostRecentDatabase = input(\"Enter date of most recent update YYYY-MM-DD: \")\n",
    "\n",
    "#get number of events to update the database with\n",
    "numberOfEventsForUpdate = input(\"Enter number of events for update: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "3700\n",
      "3700\n",
      "3745\n",
      "45.131.4.207:80\n",
      "141.101.123.29:80\n",
      "172.67.101.185:80\n",
      "188.114.96.160:80\n",
      "104.16.195.74:80\n",
      "45.131.4.127:80\n",
      "69.84.182.8:80\n",
      "172.64.131.2:80\n",
      "23.227.39.24:80\n",
      "45.12.30.26:80\n",
      "45.131.4.64:80\n",
      "185.162.231.238:80\n",
      "31.43.179.110:80\n",
      "31.43.179.23:80\n",
      "104.21.76.221:80\n",
      "172.67.206.108\n",
      "108.162.196.106:80\n",
      "45.131.5.33:80\n",
      "172.67.25.30:80\n",
      "20.26.249.29:8080\n",
      "45.131.4.197:80\n",
      "108.162.196.42:80\n",
      "159.112.235.86:80\n",
      "172.67.53.232:80\n",
      "104.16.105.106:80\n",
      "141.101.120.45:80\n",
      "172.67.161.231:80\n",
      "172.67.151.200:80\n",
      "159.112.235.44:80\n",
      "188.114.96.246:80\n",
      "66.235.200.236:80\n",
      "141.101.120.120:80\n",
      "185.170.166.32:80\n",
      "141.101.120.127:80\n",
      "172.67.165.43:80\n",
      "141.101.121.148:80\n",
      "141.101.121.203:80\n",
      "185.238.228.33:80\n",
      "45.131.4.176:80\n",
      "141.101.121.130:80\n",
      "45.131.7.158:8045.131.4.232:80\n",
      "141.101.120.177:80\n",
      "\n",
      "185.162.230.240:80\n",
      "5.182.34.134:80\n",
      "172.67.161.210:80\n",
      "172.64.149.75:80\n",
      "185.162.230.131:80\n",
      "172.64.166.71:80\n",
      "172.67.177.153:80\n",
      "172.67.255.220:80\n",
      "185.162.230.205:80\n",
      "45.131.6.107:80\n",
      "172.67.182.80:80\n",
      "45.131.5.205:80\n",
      "23.227.38.230:80\n",
      "172.64.149.53:80\n",
      "172.67.70.92:80\n",
      "141.101.121.167:80\n",
      "172.67.10.96:80\n",
      "141.101.121.44:80\n",
      "159.112.235.76:80\n",
      "141.101.122.9:80\n",
      "172.67.167.220:80\n",
      "185.162.231.215:80\n",
      "185.162.230.185:80\n",
      "185.162.229.2:80\n",
      "66.235.200.29:80\n",
      "45.131.6.124:80\n",
      "23.227.38.198:80\n",
      "141.101.121.3:80\n",
      "45.12.31.253:80\n",
      "185.162.228.114:80\n",
      "185.162.231.217:80\n",
      "63.141.128.95:80\n",
      "45.12.31.174:80\n",
      "172.67.140.224:80\n",
      "20.206.106.192:8123\n",
      "104.19.31.79:80\n",
      "141.101.123.112:80\n",
      "172.67.70.126:80\n",
      "172.64.207.185:80\n",
      "173.245.49.181:80\n",
      "104.22.37.236:80\n",
      "23.227.38.170:80\n",
      "185.162.228.52:80\n",
      "63.141.128.176:80\n",
      "104.21.6.88:80\n",
      "45.12.31.67:80\n",
      "185.162.230.35:80\n",
      "63.141.128.167:80\n",
      "23.227.39.222:80\n",
      "172.67.159.96:80\n",
      "31.43.179.231:80\n",
      "172.67.185.160:80\n",
      "45.131.6.211:80\n",
      "185.162.228.44:80\n",
      "141.101.123.117:80\n",
      "141.101.113.0:80\n",
      "66.235.200.251:80\n",
      "31.43.179.246:80\n",
      "31.43.179.165:80\n",
      "5.182.34.142:80\n",
      "45.12.30.36:80\n",
      "172.67.76.123:80\n",
      "141.101.122.120:80\n",
      "141.101.120.164:80\n",
      "141.101.121.144:80\n",
      "45.131.7.144:80\n",
      "45.12.31.196:80\n",
      "172.67.189.12:80\n",
      "188.253.6.26\n",
      "63.141.128.151:80\n",
      "109.61.42.223:80\n",
      "185.162.231.39:80\n",
      "23.227.39.45:80\n",
      "172.67.171.34:80\n",
      "141.101.120.229:80\n",
      "66.235.200.217:80\n",
      "66.235.200.38:80\n",
      "185.162.229.249:80\n",
      "172.67.222.119:80\n",
      "172.67.131.199:80\n",
      "172.67.157.17:80\n",
      "172.67.171.212:80\n",
      "23.227.38.239:80\n",
      "104.25.0.13:80\n",
      "213.33.126.130:80213.33.2.28:80\n",
      "\n",
      "62.255.223.195:8080\n",
      "185.162.229.118:80\n",
      "141.101.121.155:80\n",
      "203.192.199.158:8080\n",
      "45.131.208.21:80\n",
      "211.251.236.253:80\n",
      "188.114.96.138:80\n",
      "141.101.122.211:80\n",
      "45.131.4.15:80\n",
      "172.67.192.47:80\n",
      "141.101.122.189:80\n",
      "127.154.219.129:80\n",
      "141.101.120.56:80\n",
      "141.101.121.150:80\n",
      "185.162.229.121:80\n",
      "164.38.155.11:80\n",
      "23.227.38.189:80\n",
      "50.232.104.86:80\n",
      "66.235.200.6:80\n",
      "141.101.121.14:80\n",
      "61.129.2.212:8080\n",
      "159.112.235.7:80\n",
      "45.131.4.120:80\n",
      "50.171.207.92:80\n",
      "172.67.72.1:80\n",
      "45.131.6.193:80\n",
      "45.12.30.129:80\n",
      "91.107.183.65:80\n",
      "104.25.0.240:80\n",
      "104.17.153.216:80\n",
      "104.25.190.180:80\n",
      "172.67.229.30:80\n",
      "141.101.121.204:80\n",
      "185.162.229.31:80\n",
      "141.101.121.223:80\n",
      "172.64.149.71:80\n",
      "66.235.200.140:80\n",
      "172.64.144.78:80\n",
      "45.131.5.106:80\n",
      "185.238.228.57:80\n",
      "141.193.213.120:80\n",
      "185.162.231.250:80\n",
      "141.101.121.41:80\n",
      "141.193.213.41:80\n",
      "45.131.208.22:80\n",
      "185.162.228.252:80\n",
      "172.67.0.42:80\n",
      "141.101.115.244:80\n",
      "172.67.153.77:80\n",
      "172.67.25.94:80\n",
      "45.131.4.61:80\n",
      "172.64.205.250:80\n",
      "172.67.167.49:80\n",
      "141.101.120.18:80\n",
      "108.162.192.158:80\n",
      "172.67.176.13:80\n",
      "127.0.119.167:80\n",
      "172.67.91.190:80\n",
      "104.25.1.123:80\n",
      "141.101.121.136:80\n",
      "45.131.5.85:80\n",
      "173.245.49.69:80\n",
      "172.64.104.38:80\n",
      "45.131.5.129:80\n",
      "41.204.53.27:80\n",
      "185.162.229.112:80\n",
      "164.38.155.52:80\n",
      "43.153.207.93:3128\n",
      "50.231.110.26:80\n",
      "172.67.97.169:80\n",
      "104.25.2.6:80\n",
      "172.67.167.1:80\n",
      "108.162.196.155:80\n",
      "87.98.148.98:80\n",
      "172.64.96.64:80\n",
      "104.16.146.108:80\n",
      "104.20.90.194:80\n",
      "45.131.4.143:80\n",
      "172.67.0.5:80\n",
      "31.43.179.199:80\n",
      "141.101.122.79:80\n",
      "104.16.226.6:80\n",
      "45.131.6.250:80\n",
      "45.131.208.56:80\n",
      "172.67.182.59:80\n",
      "23.227.39.253:80\n",
      "91.222.238.112:80\n",
      "172.67.152.152:80\n",
      "172.67.219.113:80\n",
      "49.7.11.187:80\n",
      "170.233.193.129:999\n",
      "141.101.115.250:80\n",
      "141.101.120.91:80\n",
      "185.162.231.27:80\n",
      "45.131.208.69:80\n",
      "31.43.179.214:80\n",
      "104.17.132.79:80\n",
      "104.18.136.28:80\n",
      "23.227.38.62:80\n",
      "172.67.180.244:80\n",
      "108.162.198.142:80\n",
      "45.131.7.17:80\n",
      "172.64.149.64:80\n",
      "172.67.219.212:80\n",
      "172.67.180.196:80\n",
      "45.131.7.245:80\n",
      "45.131.7.254\n",
      "34.97.46.98:8561\n",
      "185.162.228.111:80\n",
      "211.128.96.206:80\n",
      "185.162.230.187:80\n",
      "172.67.170.7:80\n",
      "172.67.254.62:80\n",
      "104.20.24.214:80\n",
      "172.67.167.22:80\n",
      "141.193.213.25:80\n",
      "164.38.155.65:80\n",
      "108.162.192.156:80\n",
      "188.114.96.4:80\n",
      "141.101.120.59:80\n",
      "108.162.192.194:80\n",
      "172.67.253.207:80\n",
      "185.170.166.17:80\n",
      "172.67.255.222:80\n",
      "172.64.84.72:80\n",
      "172.67.254.241:80\n",
      "23.227.39.243:80\n",
      "172.64.33.156:80\n",
      "5.182.34.51:80\n",
      "104.17.241.25:80\n",
      "45.131.6.207:80\n",
      "172.67.181.142:80\n",
      "172.67.36.174:80\n",
      "141.101.120.209:80\n",
      "185.238.228.110:80\n",
      "172.67.210.2:80\n",
      "172.67.176.4:80\n",
      "185.162.231.210:80\n",
      "172.67.176.88:80\n",
      "141.101.122.179:80\n",
      "141.101.123.13:80\n",
      "185.238.228.138:80\n",
      "172.67.181.218:80\n",
      "172.67.70.84:80\n",
      "172.67.182.23:80\n",
      "141.193.213.6:80\n",
      "185.162.229.131:80\n",
      "172.67.180.60:80\n",
      "141.193.213.42:80\n",
      "185.162.230.108:80\n",
      "172.67.181.2:80\n",
      "172.64.194.2:80\n",
      "172.67.182.136:80\n",
      "45.131.4.95:80\n",
      "141.101.120.171:80\n",
      "108.162.198.18:80\n",
      "45.131.6.105:80\n",
      "172.67.70.65:80\n",
      "172.67.105.234:80\n",
      "45.131.5.40:80\n",
      "185.162.230.142:80\n",
      "159.112.235.108:80\n",
      "23.227.39.120:80\n",
      "185.238.228.196:80\n",
      "8.213.156.191:4145\n",
      "45.12.30.254:80\n",
      "172.64.40.184:80\n",
      "172.67.53.215:80\n",
      "63.141.128.208:80\n",
      "69.84.182.53:80\n",
      "141.101.120.113:80\n",
      "185.162.229.146:80\n",
      "172.67.176.250:80\n",
      "45.131.6.74:80\n",
      "119.92.75.48:8181\n",
      "172.67.3.0:80\n",
      "45.12.30.184:80\n",
      "141.101.121.181:80\n",
      "50.149.15.33:80\n",
      "108.162.196.118:80\n",
      "185.191.236.162:3128\n",
      "141.101.121.48:80\n",
      "47.252.29.28:11222\n",
      "172.67.75.174:80\n",
      "173.245.49.53:80\n",
      "45.131.7.109:80\n",
      "8.215.3.250:8443\n",
      "185.76.10.68:8080\n",
      "141.101.120.178:80\n",
      "185.162.228.185:80\n",
      "185.238.228.17:80\n",
      "104.18.5.38:80\n",
      "172.67.181.28:80\n",
      "141.101.115.254:80\n",
      "185.238.228.96:80\n",
      "172.67.182.114:80\n",
      "66.235.200.149:80\n",
      "172.64.168.28:80\n",
      "50.171.207.94:80\n",
      "172.64.160.74:80\n",
      "23.227.38.173:80\n",
      "69.84.182.18:80\n",
      "141.101.120.223:80\n",
      "172.64.196.5:80\n",
      "172.67.152.107:80\n",
      "172.67.167.213:80\n",
      "50.168.72.117:80\n",
      "185.162.229.205:80\n",
      "141.101.121.185:80\n",
      "172.67.241.49:80\n",
      "141.193.213.192:80\n",
      "104.25.1.175:80\n",
      "185.238.228.237:80\n",
      "141.101.122.117:80\n",
      "172.64.129.6:80\n",
      "45.131.7.82:80\n",
      "172.67.181.89:80\n",
      "172.67.222.11:80\n",
      "143.42.191.48:80\n",
      "5.182.34.147:80\n",
      "63.141.128.230:80\n",
      "23.227.39.17:80\n",
      "5.182.34.129:80\n",
      "185.170.166.10:80\n",
      "172.67.151.67:80\n",
      "172.67.167.12:80\n",
      "173.245.49.201:80\n",
      "104.25.184.189:80\n",
      "104.19.109.209:80\n",
      "213.143.113.82:80\n",
      "172.67.182.38:80\n",
      "173.245.49.172:80\n",
      "185.162.228.233:80\n",
      "172.67.96.23:80\n",
      "45.12.30.76:80\n",
      "66.235.200.52:80\n",
      "8.220.141.8:80\n",
      "108.162.198.121:80\n",
      "141.101.123.181:80\n",
      "172.64.205.157:80\n",
      "141.101.121.225:80\n",
      "172.67.177.43:80\n",
      "172.64.192.132:80\n",
      "185.238.228.158:80\n",
      "185.162.231.45:80\n",
      "141.101.123.20:80\n",
      "172.67.70.82:80\n",
      "185.193.30.29:80\n",
      "172.64.106.239:80\n",
      "104.25.0.73:80\n",
      "188.114.96.161\n",
      "185.162.231.140:80\n",
      "162.159.242.249:80\n",
      "45.131.6.89:80\n",
      "172.67.3.148:80\n",
      "172.64.145.0:80\n",
      "173.245.49.49:80141.101.121.229:80\n",
      "\n",
      "23.227.39.217:80\n",
      "185.162.231.117:80\n",
      "141.101.120.148:80\n",
      "23.227.38.126:80\n",
      "172.64.152.2:80\n",
      "104.16.61.8:80\n",
      "172.64.136.199:80\n",
      "172.66.41.4:80\n",
      "185.162.231.188:80\n",
      "172.67.182.0:80\n",
      "172.67.181.6:80\n",
      "45.131.5.125:80\n",
      "172.67.194.35:80\n",
      "103.49.114.195\n",
      "172.67.70.69:80\n",
      "141.101.120.170:80\n",
      "23.227.39.173:80\n",
      "141.101.120.46:80\n",
      "172.67.141.148:80\n",
      "172.67.71.173:80\n",
      "45.131.208.96:80\n",
      "127.94.115.10:80\n",
      "104.18.220.95:80\n",
      "45.12.30.86:80\n",
      "63.141.128.108:80\n",
      "45.131.6.34:80\n",
      "141.193.213.223:80\n",
      "185.238.228.132:80\n",
      "185.162.228.175:80\n",
      "23.227.39.155:80\n",
      "141.193.213.221:80\n",
      "172.64.149.13:80\n",
      "172.67.178.152:80\n",
      "47.91.120.190:9080\n",
      "50.169.37.50:80\n",
      "141.101.121.226:80\n",
      "185.162.228.167:80\n",
      "45.131.6.139:80\n",
      "172.67.185.175:80\n",
      "172.67.6.140:80\n",
      "141.101.123.62:80\n",
      "108.162.192.76:80\n",
      "172.67.181.189:80172.67.185.204:80\n",
      "\n",
      "172.64.89.152:80\n",
      "89.116.250.0:80\n",
      "172.67.229.15:80\n",
      "159.112.235.189:80\n",
      "127.122.150.98:80\n",
      "50.144.76.221:80\n",
      "172.67.0.1:80\n",
      "172.67.70.63:80\n",
      "172.67.144.93:80\n",
      "141.193.213.101:80\n",
      "164.38.155.75:80\n",
      "172.64.148.199:80\n",
      "194.147.33.5\n",
      "172.66.40.84:80\n",
      "172.67.141.117:80\n",
      "141.101.121.101:80\n",
      "129.222.202.169:80\n",
      "45.131.6.160:80\n",
      "159.112.235.144:80\n",
      "45.12.30.197:80\n",
      "172.67.167.53:80\n",
      "172.67.254.127:80\n",
      "188.114.97.5:80\n",
      "<Response [200]>, 192.42.116.208\n",
      "172.67.182.97:80\n",
      "45.12.31.112:80172.67.192.46:80\n",
      "\n",
      "141.101.121.19:80\n",
      "127.13.68.23:80\n",
      "172.67.70.144:80\n",
      "141.101.121.195:80\n",
      "172.67.75.180:80\n",
      "5.182.34.41:80\n",
      "141.101.121.211:80\n",
      "141.101.121.227:80\n",
      "141.101.120.53:80\n",
      "172.64.169.208:80\n",
      "188.114.96.102:80\n",
      "45.131.7.188:80\n",
      "141.101.120.192:80\n",
      "66.235.200.192:80\n",
      "172.67.222.223:80\n",
      "172.64.53.216:80\n",
      "172.67.70.25:80\n",
      "172.67.73.111:80\n",
      "141.101.120.13:80\n",
      "23.227.38.171:80\n",
      "141.101.123.89:80\n",
      "8.210.17.35:9098\n",
      "141.193.213.181:80\n",
      "172.67.185.150:80\n",
      "23.227.39.186:80\n",
      "185.162.228.95:80\n",
      "23.227.38.131:80\n",
      "172.67.250.212:80\n",
      "185.162.229.172:80\n",
      "172.67.167.25\n",
      "172.67.235.253:80\n",
      "141.101.120.30:80\n",
      "104.25.0.190:80\n",
      "47.91.29.151:9098\n",
      "104.16.107.206:80\n",
      "45.131.5.98:80\n",
      "159.112.235.41:80\n",
      "141.101.122.105:80\n",
      "172.67.161.128:80\n",
      "172.67.181.93:80\n",
      "127.245.245.164:80\n",
      "159.112.235.24:80\n",
      "141.101.120.195:80\n",
      "104.25.0.105:80\n",
      "104.21.64.208:80\n",
      "185.162.230.247:80\n",
      "172.67.141.43:80\n",
      "141.101.121.0:80\n",
      "127.52.73.139:80\n",
      "38.54.71.67:80\n",
      "172.67.177.60:80\n",
      "185.162.229.228:80\n",
      "172.67.75.189:80\n",
      "172.67.68.68:80\n",
      "107.175.179.52:80\n",
      "141.101.120.135:80\n",
      "172.67.178.110:80\n",
      "104.21.102.95:80\n",
      "172.67.70.132:80\n",
      "159.112.235.244:80\n",
      "172.67.201.181:80\n",
      "45.131.5.149:80\n",
      "45.131.5.215:80\n",
      "66.235.200.41:80\n",
      "104.26.6.171:80\n",
      "172.67.191.35:80\n",
      "141.101.122.161:80\n",
      "23.227.39.110:80\n",
      "185.162.228.229:80\n",
      "141.101.120.155:80\n",
      "172.67.70.51:80\n",
      "172.67.255.2:80\n",
      "141.101.121.213:80\n",
      "141.101.120.81:80\n",
      "173.245.49.82:80\n",
      "141.193.213.23:80\n",
      "141.101.120.212:80\n",
      "20.204.212.45:3129\n",
      "172.67.161.228:80\n",
      "45.131.7.27:80\n",
      "159.112.235.57:80\n",
      "104.21.236.208:80\n",
      "51.89.255.67:80\n",
      "63.141.128.94:80\n",
      "141.101.120.114:80\n",
      "172.67.167.8:80\n",
      "172.64.134.206:80\n",
      "45.131.7.76:80\n",
      "127.251.171.253:80\n",
      "66.29.154.105:3128\n",
      "172.67.201.152:80\n",
      "172.67.161.223:80\n",
      "141.101.121.99:80\n",
      "172.67.34.164:80\n",
      "141.193.213.220:80\n",
      "50.231.104.58\n",
      "45.12.31.104:80\n",
      "141.101.120.190:80\n",
      "69.84.182.10:80\n",
      "141.101.121.140:80\n",
      "172.67.177.211:80\n",
      "172.64.171.46:80\n",
      "172.64.96.122:80\n",
      "141.101.120.187:80\n",
      "141.101.122.22:80\n",
      "172.64.85.128:80\n",
      "45.131.6.82:80\n",
      "141.101.121.244:80\n",
      "172.67.209.12:80\n",
      "188.114.97.4:80\n",
      "45.131.4.47:80\n",
      "172.67.229.210:80\n",
      "172.67.182.159:80\n",
      "172.67.182.54:80\n",
      "172.67.172.162:80\n",
      "45.12.30.168:80\n",
      "5.182.34.150:80\n",
      "185.162.228.243:80\n",
      "185.162.228.235:80\n",
      "159.112.235.45:80\n",
      "141.101.120.110:80\n",
      "172.67.68.204:80\n",
      "172.67.180.18:80\n",
      "45.131.7.136:80\n",
      "164.38.155.8:80\n",
      "172.67.167.98:80\n",
      "172.67.3.119:80\n",
      "124.156.100.83:8118\n",
      "172.67.171.217:80\n",
      "172.67.181.30:80\n",
      "50.207.199.86:80\n",
      "172.64.155.5:80\n",
      "172.67.181.62:80\n",
      "45.131.4.234:80\n",
      "45.131.5.228:80\n",
      "31.43.179.51\n",
      "8.219.77.141:80\n",
      "141.101.120.121:80\n",
      "141.101.121.77:80\n",
      "66.235.200.64:80\n",
      "172.67.191.227:80\n",
      "185.170.166.69:80\n",
      "185.162.228.220:80\n",
      "190.61.84.166:9812\n",
      "104.16.221.57:80\n",
      "45.131.5.191:80\n",
      "141.101.120.4:80\n",
      "172.67.176.148:80\n",
      "63.141.128.39:80\n",
      "45.131.5.196:80\n",
      "31.43.179.159:80\n",
      "47.56.110.204\n",
      "24.205.201.186:80\n",
      "185.162.231.190:80\n",
      "23.254.231.55:80\n",
      "154.9.227.204:8080\n",
      "141.101.121.69:80\n",
      "45.131.4.200:80\n",
      "172.67.3.154:80\n",
      "172.67.142.245:80\n",
      "159.112.235.19:80\n",
      "141.101.113.2\n",
      "45.131.5.5:80\n",
      "173.245.49.27:80\n",
      "69.84.182.42:80\n",
      "185.162.229.138:80\n",
      "31.43.179.136:80\n",
      "50.171.122.24:80\n",
      "185.162.229.143:80\n",
      "45.131.6.115:80\n",
      "23.247.136.245:80\n",
      "141.101.121.179:80\n",
      "23.227.38.7:80\n",
      "47.237.113.119:1000\n",
      "23.227.38.97:80\n",
      "104.21.85.109:80\n",
      "172.67.167.92:80\n",
      "45.131.5.132:80\n",
      "172.64.147.34:80\n",
      "185.162.231.214:80\n",
      "141.101.123.21:80\n",
      "172.67.214.8:80\n",
      "45.12.31.224:80\n",
      "141.101.122.229:80\n",
      "104.25.108.120:80\n",
      "185.162.231.64:80\n",
      "23.227.39.105:80\n",
      "172.67.192.32\n",
      "141.101.120.68:80\n",
      "172.67.68.115:80\n",
      "172.64.101.20:80\n",
      "185.170.166.50:80\n",
      "172.67.182.126:80\n",
      "141.193.213.115:80\n",
      "172.67.43.134:80\n",
      "141.101.120.220:80\n",
      "108.162.194.4:80\n",
      "185.238.228.187:80\n",
      "31.43.179.87:80\n",
      "50.122.86.118:80\n",
      "104.16.105.198:80\n",
      "63.141.128.16:80\n",
      "172.67.35.15:80\n",
      "172.64.194.88:80\n",
      "172.67.172.151:80\n",
      "198.49.68.80:80\n",
      "45.12.31.55:80\n",
      "103.169.142.0:80\n",
      "185.162.230.233:80\n",
      "172.67.176.182:80\n",
      "45.131.6.215:80\n",
      "50.221.74.130:80\n",
      "189.240.60.171:9090\n",
      "172.67.220.106:80\n",
      "124.163.236.54:7302\n",
      "172.67.70.240:80\n",
      "185.162.228.197:80\n",
      "164.38.155.16:80\n",
      "141.193.213.50:80\n",
      "31.43.179.254:80\n",
      "185.162.231.130:80\n",
      "190.93.244.226:80\n",
      "172.64.149.0:80\n",
      "66.235.200.10:80\n",
      "172.64.149.72:80\n",
      "172.67.182.125:80\n",
      "173.245.49.212:80\n",
      "172.67.167.171:80\n",
      "66.235.200.18:80\n",
      "185.238.228.53:80\n",
      "63.141.128.89:80\n",
      "172.67.191.235:80\n",
      "172.67.3.111:80\n",
      "172.64.150.143:80\n",
      "172.67.171.236:80\n",
      "172.67.161.205:80\n",
      "104.20.198.49:80\n",
      "66.235.200.218:80\n",
      "155.94.241.130\n",
      "172.67.70.232:80\n",
      "103.153.154.6:80\n",
      "172.67.232.228:80\n",
      "141.101.121.186:80\n",
      "23.227.39.122:80\n",
      "185.162.229.160:80\n",
      "108.162.194.77:80\n",
      "45.131.6.199:80\n",
      "185.162.230.201:80\n",
      "172.64.149.36:80\n",
      "185.162.228.115:80\n",
      "45.131.4.113:80\n",
      "172.64.69.165:80\n",
      "45.131.208.48:80\n",
      "141.101.120.147:80\n",
      "50.239.72.19:80\n",
      "185.162.228.108:80\n",
      "141.101.115.2:80\n",
      "66.191.31.158:80\n",
      "172.67.70.61:80\n",
      "172.67.180.35:80\n",
      "185.146.173.20:80\n",
      "45.131.6.236:80\n",
      "185.238.228.63:80\n",
      "172.67.180.210:80\n",
      "141.193.213.65:80\n",
      "172.66.43.12:80\n",
      "45.131.5.124:80\n",
      "185.238.228.137:80\n",
      "45.131.7.80:80\n",
      "185.162.231.156\n",
      "89.213.0.29:80\n",
      "97.74.87.226:80\n",
      "172.67.146.243:80\n",
      "172.67.177.63:80\n",
      "141.193.213.195:80\n",
      "188.114.96.53:80\n",
      "172.64.149.50:80\n",
      "45.131.7.160:80\n",
      "172.67.220.126:80\n",
      "104.26.1.171:80\n",
      "172.67.171.215:80\n",
      "172.67.200.220:80\n",
      "141.101.120.88:80\n",
      "141.101.123.238:80\n",
      "172.67.26.118:80\n",
      "172.67.206.101:80\n",
      "172.67.188.27:80\n",
      "45.131.208.59:80\n",
      "108.162.193.112:80\n",
      "185.238.228.189:80\n",
      "45.12.30.231:80\n",
      "172.67.101.180:80\n",
      "45.131.4.108:80\n",
      "172.67.18.108:80\n",
      "23.227.38.110:80\n",
      "23.227.38.23:80\n",
      "159.112.235.227:80\n",
      "162.159.251.182:80\n",
      "172.67.181.117:80\n",
      "23.227.39.190:80\n",
      "172.67.29.81:80\n",
      "172.64.197.89:80\n",
      "45.12.31.243:80\n",
      "45.131.6.27:80\n",
      "172.67.180.250:80\n",
      "172.67.231.3:80\n",
      "185.162.228.23:80\n",
      "104.20.75.76:80\n",
      "188.114.96.248:80\n",
      "63.141.128.172:80\n",
      "141.101.120.244:80\n",
      "172.67.120.227:80\n",
      "147.75.34.103:9401\n",
      "66.235.200.150:80\n",
      "188.114.96.31:80\n",
      "164.38.155.67:80\n",
      "45.131.208.32:80\n",
      "141.101.115.137:80\n",
      "104.16.108.42:80\n",
      "45.12.30.243:80\n",
      "23.227.39.128:80\n",
      "47.251.43.115:33333\n",
      "45.131.6.186:80\n",
      "172.66.47.196:80\n",
      "172.67.70.47:80\n",
      "172.67.79.163:80\n",
      "172.67.211.9:80\n",
      "141.193.213.114:80\n",
      "159.112.235.80:80\n",
      "45.131.4.38:80\n",
      "104.24.220.52:80\n",
      "172.67.202.12:80\n",
      "172.67.215.133:80\n",
      "141.101.120.188:80\n",
      "172.67.97.95:80\n",
      "45.131.6.227:80\n",
      "58.246.58.150\n",
      "108.162.198.21:80\n",
      "172.67.181.165:80\n",
      "108.162.198.168:80\n",
      "172.64.110.15:80\n",
      "172.64.129.95:80\n",
      "47.90.149.238:8443\n",
      "45.131.7.57:80\n",
      "8.211.51.115:8081\n",
      "23.227.38.107:80\n",
      "141.101.123.64:80\n",
      "8.221.138.111:3128\n",
      "8.213.128.6:8103\n",
      "172.67.133.23:80\n",
      "159.112.235.239:80\n",
      "172.67.181.222:80\n",
      "141.101.123.100:80\n",
      "172.67.3.93:80\n",
      "141.101.120.132:80\n",
      "185.162.231.128:80\n",
      "172.67.53.142:80\n",
      "34.93.79.152:80\n",
      "104.25.0.181:80\n",
      "141.101.120.222:80\n",
      "108.162.198.165:80\n",
      "172.67.191.62:80\n",
      "50.172.75.127:80\n",
      "141.193.213.238:80\n",
      "172.64.80.55:80\n",
      "45.131.5.173:80\n",
      "172.67.180.205:80\n",
      "172.67.156.241:80\n",
      "45.131.5.9:80\n",
      "45.131.7.13:80\n",
      "45.131.5.32:80\n",
      "172.67.145.176:80\n",
      "172.64.97.111:80\n",
      "194.219.134.234:80\n",
      "188.114.99.233:80\n",
      "104.17.37.235:80\n",
      "47.91.115.179:98\n",
      "172.67.70.107:80\n",
      "141.101.121.248:80\n",
      "172.67.167.140:80\n",
      "104.16.81.76:80\n",
      "103.164.235.49:3125\n",
      "189.240.60.169:9090\n",
      "154.65.39.7\n",
      "185.162.230.30:80\n",
      "172.67.172.160:80\n",
      "185.238.228.183:80\n",
      "185.170.166.60:80\n",
      "104.16.108.234:80\n",
      "5.10.245.165:80\n",
      "50.169.222.241:80\n",
      "159.112.235.69:80\n",
      "45.131.7.19:80\n",
      "185.162.231.135:80\n",
      "185.162.229.22:80\n",
      "4.175.200.138:8080\n",
      "141.101.122.230:80\n",
      "172.67.43.16:80\n",
      "172.67.185.188:80\n",
      "185.162.231.107:80\n",
      "47.90.167.27:1000\n",
      "47.76.144.139:4006\n",
      "172.67.242.165:80\n",
      "66.235.200.136:80\n",
      "173.245.49.200:80\n",
      "141.193.213.22:80\n",
      "45.131.4.75:80\n",
      "45.12.31.90:80\n",
      "104.25.0.23:80\n",
      "147.75.34.103:9400\n",
      "141.101.113.98:80\n",
      "31.43.179.71:80\n",
      "172.67.126.212:80\n",
      "45.12.31.205:80\n",
      "172.67.164.40:80\n",
      "172.67.192.30:80\n",
      "172.67.192.53:80\n",
      "172.67.172.172:80141.101.121.233:80\n",
      "\n",
      "141.101.121.78:80\n",
      "185.162.228.194:80\n",
      "172.64.145.92:80\n",
      "154.16.146.41:80\n",
      "20.210.113.32:8123\n",
      "185.174.138.19:80\n",
      "172.67.181.21:805.182.34.118:80\n",
      "\n",
      "20.204.214.23:3129\n",
      "23.227.38.4:80\n",
      "172.67.52.13:80\n",
      "141.101.121.53:80\n",
      "141.101.122.207:80\n",
      "50.174.7.158:80\n",
      "38.54.6.39:3128\n",
      "4.159.61.189:8080\n",
      "69.84.182.58:80\n",
      "188.114.99.188:80\n",
      "172.64.129.2:80\n",
      "172.67.181.82:80\n",
      "31.43.179.114:80\n",
      "185.162.229.41:80\n",
      "172.64.90.184:80\n",
      "185.162.231.169:80\n",
      "45.131.208.23:80\n",
      "147.75.34.103:10005\n",
      "172.64.136.8:80\n",
      "172.64.69.24:80\n",
      "141.101.122.176:80\n",
      "45.131.6.223:80\n",
      "104.16.144.212:80\n",
      "185.162.228.154:80\n",
      "127.162.186.138:80\n",
      "141.101.122.194:80\n",
      "104.16.63.118:80\n",
      "141.101.122.78:80\n",
      "172.67.188.69:80\n",
      "45.131.6.197:80\n",
      "23.227.39.172:80\n",
      "172.64.207.234:80\n",
      "141.101.121.107:80\n",
      "172.67.167.67:80\n",
      "141.101.122.41:80\n",
      "172.67.53.232\n",
      "185.162.230.43:80\n",
      "45.12.31.138:80\n",
      "172.67.202.109:80\n",
      "45.131.5.255:80\n",
      "159.112.235.99:80\n",
      "141.101.122.147:80\n",
      "159.112.235.201:80\n",
      "23.227.38.153:80\n",
      "141.101.121.57:80\n",
      "50.172.75.120:80\n",
      "45.131.6.130:80\n",
      "91.107.252.136:80\n",
      "102.134.98.222:8081\n",
      "141.101.120.22:80\n",
      "159.112.235.175:80\n",
      "172.67.154.222:80\n",
      "173.245.49.86:80\n",
      "172.64.99.86:80\n",
      "141.101.120.201:80\n",
      "172.64.149.25:80\n",
      "172.64.168.10:80\n",
      "172.67.133.150:80\n",
      "66.235.200.26:80\n",
      "141.101.120.5:80\n",
      "34.97.149.89:8561\n",
      "141.101.122.191:80\n",
      "154.64.226.138:80\n",
      "172.67.167.59:80\n",
      "172.67.3.142:80\n",
      "172.67.167.66:80\n",
      "172.67.133.29:80\n",
      "23.227.38.221:80\n",
      "23.227.39.184:80\n",
      "45.131.4.86:80\n",
      "82.119.96.254:80\n",
      "185.162.231.171:80\n",
      "141.101.120.116:80\n",
      "172.67.254.250:80\n",
      "45.131.6.24:80\n",
      "104.20.198.41:80\n",
      "159.112.235.113:80\n",
      "172.64.149.31:80\n",
      "50.149.15.36:80\n",
      "141.101.120.95:80\n",
      "47.241.43.44:7777\n",
      "172.67.192.1:80\n",
      "141.101.123.166:80\n",
      "172.67.180.27:80\n",
      "104.21.218.103:80\n",
      "45.131.7.202:80\n",
      "45.131.6.208:80\n",
      "31.43.179.113:80\n",
      "172.67.181.79:80\n",
      "141.101.121.70:80\n",
      "173.245.49.211:80\n",
      "63.141.128.7:80\n",
      "23.227.38.98:80\n",
      "172.67.181.186:80\n",
      "23.227.39.4:80\n",
      "172.64.160.213:80\n",
      "172.67.136.242:80\n",
      "104.25.1.76:80\n",
      "62.169.26.156:8081\n",
      "45.131.6.181:80\n",
      "185.238.228.13:80\n",
      "172.67.179.181:80\n",
      "141.101.120.92:80\n",
      "223.135.156.183:8080\n",
      "185.162.229.57:80\n",
      "108.162.192.88:80\n",
      "47.238.60.156:8008\n",
      "172.67.201.200:80\n",
      "63.141.128.182:80\n",
      "141.193.213.122:80\n",
      "45.131.5.99:80\n",
      "45.175.252.18:999\n",
      "8.213.197.208:9098\n",
      "63.141.128.15:80\n",
      "141.101.122.165:80\n",
      "185.238.228.99:80\n",
      "141.101.121.174:80\n",
      "141.101.123.12:80\n",
      "172.67.181.12:80\n",
      "141.101.120.122:80\n",
      "188.114.99.77\n",
      "45.12.31.160:80\n",
      "23.227.39.58:80\n",
      "185.162.228.144:80\n",
      "172.67.7.218:80\n",
      "172.64.169.201:80\n",
      "172.67.75.2:80\n",
      "45.12.31.172:80\n",
      "50.239.72.18:80\n",
      "23.227.39.47:80\n",
      "31.43.179.183:80\n",
      "172.67.70.70:80\n",
      "45.131.5.37:80172.67.43.209:80\n",
      "\n",
      "172.67.202.243:80\n",
      "172.67.154.224:80\n",
      "172.67.27.32:80\n",
      "45.12.30.169:80\n",
      "172.67.201.154:80\n",
      "23.227.38.238:80\n",
      "45.131.7.218:80\n",
      "8.212.168.170:9080\n",
      "141.101.120.6:80\n",
      "31.43.179.68:80\n",
      "159.112.235.242:80\n",
      "141.101.121.230:80\n",
      "141.101.120.137:80\n",
      "185.162.230.179:80\n",
      "124.243.133.226:80\n",
      "5.182.34.92:80\n",
      "66.235.200.65:80\n",
      "160.153.0.9:80\n",
      "141.101.121.10:80\n",
      "172.67.6.219:80\n",
      "108.162.192.249:80\n",
      "172.67.126.201:80\n",
      "159.112.235.55:80\n",
      "172.67.3.104:80\n",
      "141.101.122.55:80\n",
      "141.101.121.215:80\n",
      "23.227.39.240:80\n",
      "172.67.181.184:80\n",
      "23.227.39.95:80\n",
      "45.131.5.213:80\n",
      "172.67.26.8:80\n",
      "5.182.34.114:80\n",
      "80.249.112.162:80\n",
      "63.143.57.119:80\n",
      "172.67.220.13:80\n",
      "185.162.228.54:80\n",
      "45.12.31.71:80\n",
      "185.162.228.51:80\n",
      "172.64.196.26:80172.67.70.9:80\n",
      "\n",
      "141.101.114.87:80\n",
      "63.141.128.35:80\n",
      "172.67.199.34:80\n",
      "80.14.162.49:80\n",
      "104.23.125.117:80\n",
      "45.12.31.122:80\n",
      "185.238.228.67:80\n",
      "23.227.39.0:80\n",
      "45.12.31.137:80\n",
      "159.112.235.112:80\n",
      "23.227.38.197:80\n",
      "185.162.230.93:80\n",
      "141.101.122.134:80\n",
      "127.206.82.112:80\n",
      "141.193.213.196:80\n",
      "141.101.122.199:80\n",
      "188.114.96.37:80\n",
      "104.19.120.84:80\n",
      "172.67.181.11:80\n",
      "172.67.182.96:80\n",
      "63.141.128.175:80\n",
      "141.101.121.33:80\n",
      "23.227.38.161:80\n",
      "141.101.120.158:80\n",
      "173.245.49.21:80\n",
      "45.131.7.50:80\n",
      "102.165.58.218\n",
      "188.114.96.46:80\n",
      "172.67.99.47:80\n",
      "172.67.185.153:80\n",
      "185.162.231.58:80\n",
      "185.162.230.125:80\n",
      "188.114.96.2:80\n",
      "185.162.231.5:80\n",
      "164.38.155.62:80\n",
      "23.227.39.67:80\n",
      "172.67.70.115:80\n",
      "185.238.228.8:80\n",
      "45.131.6.235:80\n",
      "172.67.141.43\n",
      "172.64.128.163:80\n",
      "104.16.224.33:80\n",
      "159.112.235.174:80\n",
      "172.67.22.228:80\n",
      "45.131.7.61:80\n",
      "50.202.75.26:80\n",
      "104.26.2.171:80\n",
      "63.141.128.231:80\n",
      "172.67.167.120:80\n",
      "63.141.128.55:80\n",
      "23.227.38.142:80\n",
      "104.27.122.6:80\n",
      "185.162.230.37:80\n",
      "63.141.128.194:80\n",
      "66.235.200.12:80\n",
      "185.162.230.149:80\n",
      "185.162.230.89:80\n",
      "45.131.7.46:80\n",
      "190.93.244.178:80\n",
      "164.38.155.47:80\n",
      "172.67.4.215:80\n",
      "172.67.157.198:80\n",
      "63.141.128.180:80\n",
      "141.193.213.94:80\n",
      "141.101.120.84:80\n",
      "185.162.228.15:80\n",
      "172.67.216.114:80\n",
      "164.38.155.94:80172.64.106.16:80\n",
      "\n",
      "108.162.192.92:80\n",
      "141.101.122.187:80\n",
      "50.219.249.54:80\n",
      "45.131.5.48:80\n",
      "45.131.4.66:80\n",
      "172.67.198.106:80\n",
      "66.235.200.98:80\n",
      "45.12.31.223:80\n",
      "172.67.176.11:80\n",
      "45.131.5.91:80\n",
      "84.39.112.144:3128\n",
      "162.159.242.245:80\n",
      "162.159.242.174:80\n",
      "172.67.167.58:80\n",
      "5.182.34.23:80\n",
      "172.64.144.27:80\n",
      "188.114.96.137:80\n",
      "172.67.70.200:80\n",
      "172.67.214.66:80\n",
      "173.245.59.112:80\n",
      "31.43.179.48:80\n",
      "69.84.182.27:80\n",
      "172.67.93.72:80\n",
      "45.131.4.248:80\n",
      "63.141.128.153:80\n",
      "31.43.179.38:80\n",
      "185.238.228.191:80\n",
      "172.64.108.35:80\n",
      "23.227.38.76:80\n",
      "50.207.199.81:80\n",
      "23.227.38.237:80\n",
      "45.131.4.250:80\n",
      "50.174.7.152:80\n",
      "45.12.31.91:80\n",
      "141.101.122.3:80\n",
      "104.18.57.71:80\n",
      "178.63.180.104:3128\n",
      "141.101.123.207:80\n",
      "50.171.122.30:80\n",
      "23.227.39.138:80\n",
      "173.245.49.154:80\n",
      "172.64.175.36:80\n",
      "141.101.121.17:80\n",
      "185.162.229.100:80\n",
      "190.93.246.137:80\n",
      "172.67.70.158:80\n",
      "185.162.228.112:80\n",
      "141.101.113.121:80\n",
      "104.17.166.210:80\n",
      "45.131.5.158:80\n",
      "23.227.38.132:80\n",
      "172.64.102.37:80\n",
      "172.67.28.157:80\n",
      "104.16.108.204:80\n",
      "185.162.229.102:80\n",
      "23.227.38.115:80\n",
      "164.38.155.44:80\n",
      "50.144.208.231:80\n",
      "172.67.182.152:80\n",
      "104.18.120.109:80\n",
      "45.131.4.144:80\n",
      "172.67.57.183:80\n",
      "63.141.128.3:80\n",
      "23.227.39.106:80\n",
      "185.170.166.30:80\n",
      "23.173.216.99:1081\n",
      "188.114.98.224:80\n",
      "45.12.31.228:80\n",
      "172.67.191.247:80\n",
      "172.67.43.79:80\n",
      "109.194.22.61\n",
      "103.36.10.200:8080\n",
      "141.101.121.201:80\n",
      "63.141.128.93:80\n",
      "47.178.24.220:80\n",
      "172.64.134.242:80\n",
      "66.235.200.27:80\n",
      "185.170.166.34:80\n",
      "104.16.105.142:80\n",
      "45.12.30.21:80\n",
      "108.162.193.85:80\n",
      "172.67.185.183\n",
      "108.162.194.95:80\n",
      "45.12.30.193:80\n",
      "66.235.200.220:80\n",
      "172.67.167.94:80\n",
      "45.131.7.22:80\n",
      "172.67.89.222:80\n",
      "172.64.161.2:80\n",
      "141.101.113.46:80\n",
      "104.20.89.77:80\n",
      "172.67.70.211:80\n",
      "173.245.49.8:80\n",
      "172.66.0.96:80\n",
      "185.238.228.193:8045.12.30.148:80\n",
      "\n",
      "45.131.6.204:80\n",
      "141.101.122.250:80\n",
      "172.67.170.25:80\n",
      "172.67.71.152:80\n",
      "172.67.181.202:80\n",
      "<Response [200]>, 43.134.229.98\n",
      "45.131.6.155:80\n",
      "185.162.228.6:80\n",
      "173.245.49.62:80\n",
      "141.101.115.36:80\n",
      "172.67.187.6:80\n",
      "94.43.164.242:8080\n",
      "172.66.40.144:80\n",
      "172.67.163.38:80\n",
      "39.109.113.97:4090\n",
      "141.101.120.87:80\n",
      "63.141.128.211:80\n",
      "158.255.77.169:80\n",
      "172.67.167.112:80\n",
      "50.217.226.44:80\n",
      "141.193.213.117:80\n",
      "172.67.10.41:80\n",
      "23.227.38.14:80\n",
      "45.12.30.102:80\n",
      "65.108.207.6:80\n",
      "172.67.161.219:80\n",
      "172.67.211.111:80\n",
      "45.12.30.134:80\n",
      "172.67.3.145:80\n",
      "159.112.235.179:80\n",
      "172.64.206.45:80\n",
      "188.114.96.21:80\n",
      "172.67.181.224:80\n",
      "162.159.242.208:80\n",
      "172.67.182.102:80\n",
      "188.114.96.188:80\n",
      "45.131.208.93:80\n",
      "141.193.213.165:80\n",
      "172.66.41.232:80\n",
      "66.235.200.55:80\n",
      "45.12.30.96:80\n",
      "130.61.171.71:80\n",
      "172.67.150.173:80\n",
      "23.227.39.169:80\n",
      "172.64.207.85:80\n",
      "5.182.34.176:80\n",
      "185.238.228.16:80\n",
      "104.25.1.99:80\n",
      "141.101.121.222:80\n",
      "66.235.200.110:80\n",
      "31.43.179.236:80\n",
      "185.238.228.221:80\n",
      "172.67.177.171:80\n",
      "172.64.128.31:80104.18.105.64:80\n",
      "\n",
      "104.20.75.81:80\n",
      "172.67.133.169:80\n",
      "173.245.49.19:80\n",
      "172.67.70.114:80\n",
      "8.221.141.88:3128\n",
      "172.67.73.16:80\n",
      "173.245.49.120:80\n",
      "141.101.120.186:80\n",
      "172.67.214.185:80\n",
      "141.101.120.183:80\n",
      "45.131.4.175:80\n",
      "141.101.122.100:80\n",
      "172.64.175.247:80\n",
      "104.24.69.32:80\n",
      "185.162.228.177:80\n",
      "172.67.192.51:80\n",
      "172.67.208.217:80\n",
      "45.131.6.175:80\n",
      "45.12.31.236:80\n",
      "45.131.7.6:80\n",
      "185.170.166.150:80\n",
      "159.112.235.97:80\n",
      "172.67.171.230:80\n",
      "172.67.167.194:80\n",
      "104.22.14.48:80\n",
      "66.235.200.189:80\n",
      "141.101.121.87:80\n",
      "172.66.46.89:80\n",
      "159.112.235.38:80\n",
      "164.38.155.10:80\n",
      "190.93.244.126:80\n",
      "172.67.106.205:80\n",
      "141.101.121.192:80\n",
      "185.238.228.175:80\n",
      "164.38.155.20:80\n",
      "141.101.121.184:80\n",
      "141.101.122.129:80\n",
      "141.101.120.136:80\n",
      "141.101.120.185:80\n",
      "172.67.182.35:80\n",
      "45.131.5.163:80\n",
      "172.67.182.14:80\n",
      "141.101.121.81:80\n",
      "36.93.217.223:8080\n",
      "154.65.39.7:80\n",
      "160.153.0.11:80\n",
      "185.238.228.34:80\n",
      "172.67.127.188:80\n",
      "45.131.7.178:80\n",
      "172.64.153.236:80\n",
      "50.207.199.83:80\n",
      "141.101.120.86:80\n",
      "141.101.120.126:80\n",
      "172.64.152.98:80\n",
      "111.1.61.49:3128\n",
      "185.162.228.83:80\n",
      "172.67.2.157:80\n",
      "172.67.179.200:80\n",
      "66.235.200.223:80\n",
      "172.64.193.212:80\n",
      "172.67.221.10:80\n",
      "149.129.255.179:8081\n",
      "185.238.228.202:80172.67.181.187:80\n",
      "\n",
      "172.67.172.168:80\n",
      "172.64.53.237:80\n",
      "172.67.181.114:80\n",
      "141.101.120.202:80\n",
      "5.182.34.80:80\n",
      "172.64.198.30:80\n",
      "141.101.121.137:80\n",
      "104.24.15.158:80\n",
      "185.162.230.44:80\n",
      "141.101.121.243:80\n",
      "45.131.208.29:80\n",
      "172.64.149.33:80\n",
      "104.27.11.28:80\n",
      "172.64.103.38:80\n",
      "23.227.39.167:80\n",
      "172.67.167.11:80\n",
      "172.67.70.165:80\n",
      "141.101.120.29:80\n",
      "45.131.6.168:80\n",
      "172.67.177.169:80\n",
      "172.67.203.99:80\n",
      "139.59.1.14:3128\n",
      "172.67.191.233:80\n",
      "23.227.39.16:80\n",
      "185.162.229.153:80\n",
      "141.101.120.11:80\n",
      "23.227.38.12:80\n",
      "164.38.155.21:80\n",
      "185.170.166.12:80\n",
      "154.85.58.149:80\n",
      "172.66.203.111:80\n",
      "108.162.193.78:80\n",
      "104.17.84.150:80\n",
      "45.12.30.52:80\n",
      "173.245.49.176:80\n",
      "8.215.12.103:8008\n",
      "172.64.149.73:80\n",
      "5.182.34.245:80\n",
      "164.38.155.19:80\n",
      "172.67.43.113:80\n",
      "141.193.213.108:80\n",
      "63.141.128.88:80\n",
      "141.101.121.12:80\n",
      "104.25.0.27:80\n",
      "141.101.121.180:80\n",
      "45.131.5.78:80\n",
      "45.131.6.225:80\n",
      "188.114.96.154:80\n",
      "141.101.122.239:80\n",
      "45.131.6.17:80\n",
      "172.64.110.180:80\n",
      "162.159.242.204:80\n",
      "141.101.120.153:80\n",
      "62.99.138.162:80\n",
      "202.6.233.133:80\n",
      "141.101.122.154:80\n",
      "45.12.31.177:80\n",
      "141.101.120.213:80\n",
      "172.67.216.216:80\n",
      "185.162.228.224:80\n",
      "50.174.7.157:80\n",
      "45.131.5.188:80\n",
      "172.67.208.202:80\n",
      "141.101.120.245:80\n",
      "66.235.200.15:80\n",
      "45.131.7.165:80\n",
      "45.131.4.36:80\n",
      "66.235.200.187:80\n",
      "50.168.72.115:80\n",
      "172.64.150.102:80\n",
      "185.162.231.168:80\n",
      "45.131.7.122:80\n",
      "172.67.255.64:80\n",
      "141.193.213.212:80\n",
      "185.162.230.217:80\n",
      "63.141.128.79:80\n",
      "141.101.122.160:80\n",
      "173.245.49.40:80\n",
      "31.43.179.117:80\n",
      "172.67.31.149:80\n",
      "159.112.235.162:80\n",
      "104.25.58.39:80\n",
      "63.141.128.254:80\n",
      "5.182.34.77:80\n",
      "78.80.228.150:80\n",
      "172.67.182.21:80\n",
      "23.227.39.203:80\n",
      "127.229.240.140:80\n",
      "23.227.39.246:80\n",
      "172.64.200.39:80\n",
      "50.149.15.47:80\n",
      "172.64.203.2:80\n",
      "104.16.108.149:80\n",
      "141.101.120.138:80\n",
      "141.101.122.210:80\n",
      "108.162.193.160:80\n",
      "23.227.38.199:80\n",
      "31.43.179.239:80\n",
      "172.67.191.253:80\n",
      "45.131.7.171:80\n",
      "141.101.120.61:80\n",
      "172.67.106.10:80\n",
      "185.162.229.170:80\n",
      "172.67.240.126:80\n",
      "69.84.182.16:80\n",
      "172.67.182.13:80\n",
      "172.67.182.34:80\n",
      "172.67.202.57:80\n",
      "50.217.226.40:80\n",
      "185.162.231.160:80\n",
      "47.250.159.65:8443\n",
      "23.227.38.169:80\n",
      "172.67.182.127:80\n",
      "162.159.242.100:80\n",
      "159.112.235.220:80\n",
      "172.67.59.156:80\n",
      "<Response [200]>, 91.92.109.43\n",
      "104.16.105.207:80\n",
      "8.213.222.247:8008\n",
      "50.217.226.43:80\n",
      "189.202.188.149:80\n",
      "50.172.150.134:80\n",
      "188.114.96.61:80\n",
      "172.67.218.212:80\n",
      "141.101.121.63:80\n",
      "172.64.41.6:80\n",
      "188.114.97.181:80\n",
      "45.131.5.231:80\n",
      "172.67.180.50:80\n",
      "141.101.121.43:80\n",
      "104.21.80.70:80\n",
      "141.101.120.52:80\n",
      "188.114.96.50:80\n",
      "63.141.128.65:80\n",
      "173.245.58.135:80\n",
      "51.222.161.115:80\n",
      "185.162.229.82:80\n",
      "172.67.75.204:80\n",
      "172.67.205.4:80\n",
      "108.162.193.54:80\n",
      "141.101.121.158:80\n",
      "173.245.49.9:80\n",
      "38.54.6.39:80\n",
      "172.67.8.155:80\n",
      "45.12.31.69:80\n",
      "31.43.179.97:80\n",
      "31.43.179.182:80\n",
      "66.235.200.129:80\n",
      "172.67.0.13:80\n",
      "172.64.103.5:80\n",
      "159.112.235.147:80\n",
      "172.67.170.132:80\n",
      "45.131.4.155:80\n",
      "104.27.83.183:80\n",
      "172.66.41.41:80\n",
      "172.67.170.0:80\n",
      "172.64.104.35:80\n",
      "172.64.149.165:80\n",
      "172.67.33.118:80\n",
      "31.43.179.195:80\n",
      "45.131.5.59:80\n",
      "108.162.196.53:80\n",
      "172.64.152.203:80\n",
      "172.67.75.56:80\n",
      "63.141.128.66:80\n",
      "45.131.5.97:80\n",
      "141.101.120.58:80\n",
      "172.67.119.249:80\n",
      "172.67.88.159:80\n",
      "172.64.144.116:80\n",
      "185.162.228.38:80\n",
      "66.235.200.246:80\n",
      "46.47.197.210\n",
      "141.101.121.93:80\n",
      "127.97.173.33:80\n",
      "127.96.7.37:80\n",
      "38.54.116.9:9080\n",
      "45.12.31.184:80\n",
      "85.210.84.11:8080\n",
      "69.84.182.26:80\n",
      "141.101.121.25:80\n",
      "108.162.198.22:80\n",
      "45.131.7.69:80\n",
      "<Response [200]>, 103.67.237.208\n",
      "63.141.128.198:80\n",
      "172.67.254.145:80\n",
      "172.67.177.202:80\n",
      "172.67.185.210:80\n",
      "172.67.167.15:80\n",
      "172.64.163.125:80\n",
      "127.0.0.7:80\n",
      "66.235.200.154:80\n",
      "141.101.120.47:80\n",
      "172.64.164.2:80\n",
      "104.17.248.164:80\n",
      "170.114.45.8:80\n",
      "104.26.7.171:80\n",
      "5.182.34.133:80\n",
      "23.227.39.145:80\n",
      "185.162.229.87:80\n",
      "50.172.75.124:80\n",
      "50.239.72.16:80\n",
      "185.162.228.102:80\n",
      "141.101.121.234:80\n",
      "45.81.115.86:3128\n",
      "172.64.103.212:80\n",
      "45.131.7.157:80\n",
      "45.12.30.238:80\n",
      "45.131.5.224:80\n",
      "50.172.75.123:80\n",
      "23.227.39.35:80\n",
      "172.67.199.148:80\n",
      "159.112.235.149:80\n",
      "45.12.31.173:80\n",
      "172.67.3.99:80\n",
      "172.67.221.188:80\n",
      "172.67.167.21:80\n",
      "114.129.2.82:8081\n",
      "172.67.181.192:80\n",
      "31.43.179.134:80\n",
      "172.67.22.205:80\n",
      "141.101.120.169:80\n",
      "172.67.182.137:80\n",
      "45.131.6.205:80\n",
      "172.67.165.152:80\n",
      "172.67.142.11:80\n",
      "104.20.233.70:80\n",
      "141.101.121.60:80\n",
      "104.19.112.172:80\n",
      "135.181.17.160:3128\n",
      "172.64.131.156:80\n",
      "172.64.151.10:80\n",
      "45.131.6.141:80\n",
      "188.114.96.15:80\n",
      "45.131.6.129:80\n",
      "63.141.128.53:80\n",
      "172.67.70.207:80\n",
      "172.67.75.152:80\n",
      "141.101.120.140:80\n",
      "172.67.177.78:80\n",
      "185.162.229.152:80\n",
      "154.16.146.42:80\n",
      "45.4.148.70:8080\n",
      "159.112.235.235:80\n",
      "188.114.97.10:80\n",
      "45.131.5.123:80\n",
      "159.112.235.181:80\n",
      "172.67.165.60:80\n",
      "141.101.120.252:80\n",
      "104.17.9.114:80\n",
      "45.12.31.117:80\n",
      "45.12.30.19:80\n",
      "172.64.149.48:80\n",
      "172.64.144.2:80\n",
      "84.255.197.228\n",
      "172.67.70.196:80\n",
      "172.67.128.150:80\n",
      "45.131.7.103:80\n",
      "141.101.122.153:80\n",
      "172.64.168.124:80\n",
      "172.64.173.27:80\n",
      "172.67.181.149:80\n",
      "63.141.128.17:80\n",
      "185.162.231.179:80\n",
      "63.141.128.203:80\n",
      "45.131.4.94:80\n",
      "172.64.141.213:80\n",
      "141.101.123.133:80\n",
      "159.112.235.117:80\n",
      "72.10.160.173\n",
      "141.101.120.238:80\n",
      "20.204.212.76:3129\n",
      "141.101.121.161:80\n",
      "185.162.229.48:80\n",
      "159.112.235.46:80\n",
      "172.67.152.71:80\n",
      "45.12.30.165:80\n",
      "103.190.179.27:80\n",
      "69.84.182.20:80\n",
      "103.200.20.56:3128\n",
      "104.25.0.174:80\n",
      "23.227.39.90:80\n",
      "172.64.193.115:80\n",
      "172.67.165.70:80\n",
      "141.101.121.108:80\n",
      "172.67.167.7:80\n",
      "104.16.109.213:80\n",
      "172.67.181.155:80\n",
      "104.25.13.108:80\n",
      "66.235.200.44:80\n",
      "185.162.229.126:80\n",
      "172.64.165.125:80\n",
      "141.101.120.125:80\n",
      "172.67.70.46:80\n",
      "162.159.241.165:80\n",
      "141.193.213.218:80\n",
      "141.101.120.60:80\n",
      "104.25.0.2:80\n",
      "63.141.128.159:80\n",
      "23.227.39.132:80\n",
      "47.91.121.127:80\n",
      "172.191.74.198:8080\n",
      "45.12.30.75:80\n",
      "141.101.120.123:80\n",
      "108.162.193.158:80\n",
      "31.43.179.230:80\n",
      "23.227.38.87:80\n",
      "172.67.193.14:80\n",
      "23.227.38.39:80\n",
      "172.67.181.63:80\n",
      "50.174.7.155:80\n",
      "172.67.255.224:80\n",
      "188.114.96.224:80\n",
      "51.222.161.115:8080\n",
      "159.112.235.232:80\n",
      "45.12.30.78:80\n",
      "50.239.72.17:80\n",
      "141.193.213.187:80\n",
      "46.161.194.88:8085\n",
      "172.67.158.58:80\n",
      "164.38.155.6:80\n",
      "172.67.43.202:80\n",
      "45.131.5.234:80\n",
      "173.245.49.133:80\n",
      "159.112.235.101:80\n",
      "116.202.19.18:80\n",
      "31.43.179.135:80\n",
      "147.75.34.103:80\n",
      "5.182.34.121:80\n",
      "185.162.230.206:80\n",
      "159.112.235.133:80\n",
      "172.64.207.96:80\n",
      "23.227.38.231:80\n",
      "172.67.178.14:80\n",
      "172.64.171.84:80\n",
      "159.112.235.252:80\n",
      "47.250.11.111:9080\n",
      "172.67.75.37:80\n",
      "141.101.122.168:80\n",
      "172.67.181.61:80\n",
      "23.227.38.49:80\n",
      "8.209.96.245:89\n",
      "185.162.231.46:80172.67.179.233:80\n",
      "\n",
      "172.67.252.132:80\n",
      "162.159.242.8:80\n",
      "172.67.188.15:80\n",
      "172.67.72.64:80\n",
      "104.24.32.10:80\n",
      "104.16.230.163:80\n",
      "23.227.38.245:80\n",
      "173.245.49.221:80\n",
      "141.101.121.46:80\n",
      "141.101.115.5:80\n",
      "45.131.208.12:80\n",
      "172.67.181.195:80\n",
      "188.114.96.81:80\n",
      "45.12.30.77:80\n",
      "104.19.217.219:80\n",
      "45.85.119.133:80\n",
      "172.67.229.153:80\n",
      "160.153.0.2:80141.101.120.115:80\n",
      "104.18.237.128:80\n",
      "\n",
      "45.131.5.135:80\n",
      "141.101.122.110:80\n",
      "141.101.120.228:80\n",
      "172.67.192.17:80\n",
      "141.101.121.135:80\n",
      "31.43.179.217:80\n",
      "141.193.213.13:80\n",
      "108.162.192.36:80\n",
      "141.193.213.17:80\n",
      "63.141.128.243:80\n",
      "172.67.175.165:80\n",
      "45.131.6.113:80\n",
      "141.101.122.131:80\n",
      "45.131.5.221:80\n",
      "5.182.34.17:80\n",
      "172.67.70.95:80172.67.218.243:80\n",
      "\n",
      "172.64.103.11:80\n",
      "45.131.4.90:80\n",
      "104.16.0.77:80\n",
      "45.12.30.126:80\n",
      "104.25.0.225:80\n",
      "172.67.167.55:80\n",
      "50.207.199.80:80\n",
      "45.131.7.186:80\n",
      "141.101.122.138:80\n",
      "45.131.7.36:80\n",
      "141.101.121.16:80\n",
      "31.43.179.148:80\n",
      "23.88.51.178:8888\n",
      "172.67.254.255:80188.114.96.60:80\n",
      "\n",
      "127.173.50.110:80\n",
      "172.64.146.137:80\n",
      "173.245.49.70:80\n",
      "45.131.7.219:80\n",
      "66.235.200.34:80\n",
      "45.131.208.50:80\n",
      "185.162.229.176:80\n",
      "172.67.68.214:80\n",
      "141.193.213.222:80\n",
      "31.43.179.61:80\n",
      "172.67.168.40:80\n",
      "172.67.182.146:80\n",
      "172.67.181.144:80\n",
      "45.131.5.172:80\n",
      "141.193.213.93:80\n",
      "50.223.246.226:80\n",
      "45.131.7.40:80\n",
      "31.43.179.218:80\n",
      "45.131.7.49:80\n",
      "5.182.34.113:80\n",
      "104.16.105.15:80\n",
      "185.170.166.24:80\n",
      "185.162.228.219:80\n",
      "45.131.7.227:80\n",
      "141.101.122.178:80\n",
      "141.101.120.215:80\n",
      "31.43.179.222:80\n",
      "185.162.230.99:80\n",
      "66.235.200.0:80\n",
      "50.29.238.9:8888\n",
      "45.12.31.85:80\n",
      "172.67.136.237:80\n",
      "172.64.106.103:80\n",
      "45.12.30.178:80\n",
      "63.141.128.171:80\n",
      "120.205.70.102:8060\n",
      "45.131.4.239:80\n",
      "212.183.88.153:80\n",
      "164.38.155.58:80\n",
      "172.67.134.16:80\n",
      "141.101.120.176:80\n",
      "141.193.213.226:80\n",
      "141.101.120.65:80\n",
      "141.101.121.218:80\n",
      "103.101.99.45:8080\n",
      "141.101.120.117:80\n",
      "147.75.34.103:10004\n",
      "141.101.122.118:80\n",
      "172.67.176.7:80\n",
      "172.67.254.148:80\n",
      "141.101.120.64:80\n",
      "108.162.194.121:80\n",
      "172.67.236.139:80172.67.192.19:80\n",
      "69.84.182.37:80\n",
      "141.101.121.97:80\n",
      "\n",
      "<Response [200]>, 189.240.60.168\n",
      "79.110.200.148\n",
      "185.238.228.163:80\n",
      "31.43.179.205:80\n",
      "141.101.114.26:80\n",
      "185.162.228.128:80\n",
      "172.67.182.41:80\n",
      "141.101.90.98:80\n",
      "185.162.228.104:80\n",
      "45.131.7.31:80\n",
      "172.67.147.31:80\n",
      "141.101.120.198:80172.67.192.44:80\n",
      "104.25.1.206:80\n",
      "\n",
      "45.131.6.5:80\n",
      "45.12.30.167:80\n",
      "31.43.179.15\n",
      "141.101.120.159:80\n",
      "23.227.38.175:80\n",
      "195.66.93.188:3128\n",
      "185.162.231.220:80\n",
      "172.67.165.11:80\n",
      "45.131.6.135:80\n",
      "104.16.145.212:80\n",
      "172.67.155.139:80\n",
      "172.67.176.2:80\n",
      "172.64.102.11:80\n",
      "172.67.182.109:80\n",
      "104.17.50.45:80\n",
      "104.25.0.66:80\n",
      "198.41.194.146:80\n",
      "50.171.187.53:80\n",
      "31.43.179.137:80\n",
      "172.64.85.123:80\n",
      "162.159.244.45:80\n",
      "50.174.7.159:80\n",
      "172.67.167.72:8045.12.30.62:80\n",
      "188.114.98.234:80\n",
      "\n",
      "141.101.120.237:80\n",
      "45.131.4.178:80\n",
      "172.67.164.104:80\n",
      "172.64.149.85:80\n",
      "5.182.34.218:80\n",
      "160.153.0.42:80\n",
      "104.16.107.142:80\n",
      "141.101.121.73:80\n",
      "172.67.0.9:80\n",
      "41.204.53.19:80\n",
      "141.101.121.62:80\n",
      "45.131.4.245:80\n",
      "172.67.180.254:80\n",
      "172.67.75.17:80\n",
      "141.101.121.7:80\n",
      "141.101.122.149:80\n",
      "172.64.200.31:80\n",
      "13.80.134.180:80\n",
      "38.54.116.9:4006\n",
      "4.158.61.222:8080\n",
      "104.25.1.60:80\n",
      "141.101.120.197:80\n",
      "159.112.235.197:80\n",
      "162.159.251.122:80\n",
      "173.245.49.238:80\n",
      "185.162.228.169:80\n",
      "45.131.7.249:80\n",
      "172.67.167.71:80\n",
      "172.67.167.44:80\n",
      "50.174.7.156:80\n",
      "45.131.6.75:80\n",
      "172.64.149.7:80\n",
      "172.64.197.31:80\n",
      "8.211.51.115:8443\n",
      "188.114.97.188:80\n",
      "31.43.179.226:80\n",
      "185.162.228.77:80\n",
      "69.84.182.22:80\n",
      "172.64.161.17:80\n",
      "172.67.70.181:80\n",
      "141.101.115.243:80\n",
      "141.101.121.45:80\n",
      "50.144.76.222:80\n",
      "183.100.14.134:8000\n",
      "188.114.97.3:80\n",
      "185.162.228.218:80\n",
      "172.67.181.16:80\n",
      "172.64.149.17:80\n",
      "173.245.49.106:80\n",
      "104.18.161.122:80\n",
      "69.84.182.33:80\n",
      "<Response [200]>, 43.134.68.153\n",
      "35.209.198.222:80\n",
      "172.67.69.131:80\n",
      "63.141.128.75:80\n",
      "141.101.121.221:80\n",
      "172.67.219.60:80\n",
      "185.238.228.144:80\n",
      "164.38.155.64:80\n",
      "66.235.200.143:80\n",
      "185.162.229.11:80\n",
      "46.254.92.2:80\n",
      "104.16.143.127:80\n",
      "173.245.49.188:80141.101.120.101:80\n",
      "185.162.228.207:80\n",
      "\n",
      "172.67.90.190:80\n",
      "141.101.121.224:80\n",
      "104.16.189.203:80\n",
      "141.193.213.205:80\n",
      "172.67.71.127:80\n",
      "172.67.181.136:80\n",
      "188.114.96.87:80\n",
      "172.67.177.132:80\n",
      "185.162.231.33:80\n",
      "188.114.97.6:80\n",
      "185.162.230.18:80\n",
      "185.162.229.149:80\n",
      "23.227.39.44:80\n",
      "116.203.28.43:80\n",
      "23.227.38.200:80\n",
      "141.101.120.107:80\n",
      "141.101.121.147:80\n",
      "185.162.229.159:80\n",
      "104.19.194.29:80\n",
      "141.101.120.67:80\n",
      "66.235.200.93:80\n",
      "45.12.31.121:80\n",
      "108.162.195.155:80\n",
      "172.67.196.0:80\n",
      "141.101.122.13:80\n",
      "45.131.5.222:80\n",
      "122.10.225.55:8000\n",
      "45.131.6.137:80\n",
      "185.221.160.176:80\n",
      "172.67.180.37:80\n",
      "172.67.182.47:80\n",
      "45.12.31.5:80\n",
      "66.235.200.119:80\n",
      "173.245.49.97:80\n",
      "141.101.121.18:80\n",
      "23.227.38.86:80\n",
      "5.182.34.235:80\n",
      "45.131.208.57:80\n",
      "172.67.32.169:80\n",
      "104.18.27.94:80\n",
      "104.25.1.5:80\n",
      "188.114.96.77:80\n",
      "172.67.180.253:80\n",
      "141.101.113.246:80\n",
      "45.131.5.171:80\n",
      "185.238.228.115:80\n",
      "172.64.151.202:80\n",
      "141.101.120.17:80\n",
      "45.131.5.146:80\n",
      "85.215.64.49:80\n",
      "45.131.7.38:80\n",
      "141.101.120.128:80\n",
      "172.67.170.9:80\n",
      "104.21.31.189:80\n",
      "172.67.181.138:80\n",
      "45.131.7.200:80\n",
      "31.43.179.46:80\n",
      "172.67.130.251:80\n",
      "185.76.10.71:8082\n",
      "173.245.58.31:80\n",
      "190.103.177.131:80\n",
      "104.22.21.245:80\n",
      "172.67.68.152:80\n",
      "104.19.138.4:80\n",
      "172.67.167.113:80\n",
      "104.25.0.185:80\n",
      "185.162.231.187:80\n",
      "23.227.38.211:80\n",
      "45.12.30.248:80172.67.43.194:80\n",
      "\n",
      "185.162.228.131:80\n",
      "172.67.182.164:80\n",
      "172.67.25.199:80\n",
      "172.67.223.81:80\n",
      "159.112.235.251:80\n",
      "45.12.30.93:80\n",
      "23.227.39.85:80\n",
      "172.67.172.159:80\n",
      "45.131.7.181:80\n",
      "141.101.120.174:80\n",
      "45.12.30.41:80\n",
      "5.182.34.143:80\n",
      "172.67.181.182:80\n",
      "45.131.4.124:80\n",
      "108.162.196.115:80\n",
      "141.101.120.233:80\n",
      "185.162.230.148:80\n",
      "172.64.166.249:80\n",
      "185.162.231.115:80\n",
      "45.12.31.155:80\n",
      "172.67.180.234:80\n",
      "50.207.199.85:80\n",
      "41.196.0.163:8082\n",
      "172.64.86.217:80\n",
      "172.67.70.124:80\n",
      "104.21.80.83:80\n",
      "185.162.231.162:80\n",
      "63.141.128.112:80\n",
      "172.67.185.162:80\n",
      "185.162.230.97:80\n",
      "188.166.56.246:80\n",
      "185.162.229.130:80\n",
      "185.238.228.254:80\n",
      "104.16.105.182:80\n",
      "172.67.196.162:80\n",
      "45.131.5.249:80\n",
      "185.238.228.157:80\n",
      "172.67.74.70:80\n",
      "141.101.122.137:80\n",
      "185.162.231.123:80\n",
      "141.101.120.224:80\n",
      "5.161.219.13:4228\n",
      "172.67.180.42:80\n",
      "45.12.30.64:80\n",
      "141.101.122.102:80\n",
      "172.67.75.52:80\n",
      "129.226.193.16:3128\n",
      "104.26.5.185:80185.162.230.119:80\n",
      "\n",
      "50.172.75.114:80\n",
      "185.238.228.126:80\n",
      "38.54.6.39:312\n",
      "172.67.171.227:80\n",
      "185.162.230.178:80\n",
      "104.19.22.177:80\n",
      "108.162.193.171:80\n",
      "172.67.167.39:80\n",
      "173.245.49.75:80\n",
      "187.1.16.36:92\n",
      "103.127.92.92:80\n",
      "172.67.123.70:80\n",
      "45.131.5.165:80\n",
      "164.38.155.41:80\n",
      "172.67.168.35:80\n",
      "104.16.147.108:80\n",
      "172.64.142.68:80\n",
      "185.162.231.226:80\n",
      "172.67.180.61:80\n",
      "172.67.177.1:80\n",
      "34.97.11.208:8561\n",
      "141.101.113.0\n",
      "23.227.38.133:80\n",
      "185.162.229.25:80\n",
      "141.101.123.138:80\n",
      "172.67.70.23:80\n",
      "172.67.138.138:80\n",
      "108.162.193.6:80\n",
      "172.67.181.197:8045.12.30.173:80\n",
      "\n",
      "185.162.229.43:80\n",
      "173.245.49.197:80\n",
      "66.235.200.118:80\n",
      "45.131.4.101:80\n",
      "45.131.6.15:80\n",
      "172.64.141.111:80\n",
      "172.67.255.216:80\n",
      "172.67.192.20:80\n",
      "172.67.185.176:80\n",
      "172.67.156.239:80\n",
      "31.43.179.200:80\n",
      "63.141.128.105:80\n",
      "141.101.122.49:80\n",
      "172.64.150.233:80\n",
      "185.238.228.177:80\n",
      "172.67.180.28:80\n",
      "158.255.215.50:9090\n",
      "141.101.120.204:80\n",
      "172.67.209.163:80\n",
      "45.12.31.159:80\n",
      "103.247.23.65:2022\n",
      "23.227.39.194:80\n",
      "45.131.6.39:80\n",
      "141.101.122.111:80\n",
      "58.246.58.150:9002\n",
      "87.248.129.26:80\n",
      "141.101.120.160:80\n",
      "172.66.43.172:80\n",
      "31.43.179.105:80\n",
      "141.101.120.217:80\n",
      "104.23.126.8:80\n",
      "94.154.152.7:8079\n",
      "108.162.195.56:80\n",
      "50.149.13.195:80\n",
      "185.162.229.184:80\n",
      "185.162.228.248:80\n",
      "108.162.198.64:80\n",
      "188.114.97.1:80\n",
      "45.131.7.229:80\n",
      "185.170.166.26:80\n",
      "172.67.88.34:80\n",
      "141.193.213.194:80\n",
      "172.67.70.185:80\n",
      "141.101.120.34:80\n",
      "144.126.216.57:80\n",
      "188.114.99.37:80\n",
      "172.67.182.22:80\n",
      "141.101.115.253:80\n",
      "141.101.120.82:80\n",
      "172.67.59.19:80\n",
      "172.67.86.165:80\n",
      "50.171.207.89:80\n",
      "45.131.5.54:80\n",
      "172.67.164.239:80\n",
      "45.131.4.60:80\n",
      "172.67.30.148:80\n",
      "63.141.128.246:80\n",
      "8.209.96.245:3128\n",
      "63.141.128.109:80\n",
      "185.162.230.126:80\n",
      "127.71.24.254:80\n",
      "172.67.131.76:80\n",
      "31.43.179.185:80\n",
      "104.20.179.187:80\n",
      "23.227.38.174:80\n",
      "104.20.123.164:80\n",
      "185.162.231.82:80\n",
      "195.23.57.78:80\n",
      "45.12.31.215:80\n",
      "172.67.87.48:80\n",
      "172.64.137.111:80\n",
      "45.131.7.225:80\n",
      "172.66.42.3:80\n",
      "104.25.244.70:80\n",
      "185.238.228.173:80\n",
      "172.67.170.24:80\n",
      "63.141.128.4:80\n",
      "172.67.182.128:80\n",
      "45.131.7.104:80\n",
      "141.101.122.33\n",
      "63.141.128.228:80\n",
      "5.182.34.70:80\n",
      "141.101.121.118:80\n",
      "104.18.254.76:80\n",
      "50.172.75.125:80\n",
      "185.170.166.87:80\n",
      "141.101.122.150:80\n",
      "23.227.39.170:80\n",
      "123.126.158.50:80\n",
      "45.131.5.24:80\n",
      "45.131.6.214:80\n",
      "104.20.75.69:80\n",
      "172.67.66.171:80\n",
      "31.43.179.193:80\n",
      "23.227.39.40:80\n",
      "47.237.107.41:3128\n",
      "45.131.7.213:80\n",
      "190.186.18.161:999\n",
      "188.114.97.15:80\n",
      "104.18.35.72:80\n",
      "172.67.181.164:80\n",
      "173.245.49.138:80\n",
      "45.131.7.35:80\n",
      "45.131.4.226:80\n",
      "45.12.30.214:80\n",
      "43.255.113.232:8085\n",
      "141.101.120.124:80\n",
      "173.245.49.95:80\n",
      "5.10.245.141:80\n",
      "63.141.128.220:80\n",
      "104.21.194.182:80\n",
      "178.218.43.60:4411\n",
      "50.231.104.58:80\n",
      "143.42.66.91:80\n",
      "127.215.59.206:80\n",
      "45.131.5.63:80\n",
      "172.67.70.159:80\n",
      "160.153.0.14:80\n",
      "104.20.75.26:80\n",
      "172.67.22.22:80\n",
      "172.67.181.9:80\n",
      "104.20.22.93:80\n",
      "108.162.195.27:80\n",
      "172.67.192.11:80\n",
      "185.162.230.216:80\n",
      "141.101.122.68:80\n",
      "104.26.12.110:80\n",
      "45.131.6.81:80\n",
      "187.94.100.254:8080\n",
      "177.221.44.89:49999\n",
      "41.207.187.178:80\n",
      "185.170.166.74:80\n",
      "173.245.49.171:80\n",
      "20.24.43.214:8123\n",
      "108.162.194.129:80\n",
      "104.19.233.117:80\n",
      "172.67.4.16:80\n",
      "185.193.30.210:80\n",
      "45.131.6.84:80\n",
      "172.66.40.120:80\n",
      "172.67.36.21:80\n",
      "159.112.235.143:80\n",
      "172.67.171.210:80\n",
      "141.101.121.114:80\n",
      "141.101.123.190:80\n",
      "108.162.196.144:80\n",
      "172.67.177.186:80\n",
      "172.67.161.199:80\n",
      "185.238.228.207:80\n",
      "159.112.235.67:80\n",
      "45.131.5.177:80\n",
      "64.23.223.154:80\n",
      "65.1.244.232:3128\n",
      "162.159.242.30:80\n",
      "141.101.122.202:80\n",
      "141.101.121.36:80\n",
      "172.67.70.198:80\n",
      "50.168.72.116:80\n",
      "172.67.25.204:80\n",
      "172.67.180.34:80\n",
      "141.101.120.7:80\n",
      "172.67.167.187:80\n",
      "141.101.122.67:80\n",
      "141.101.122.98:80\n",
      "69.84.182.11:80\n",
      "185.170.166.46:80\n",
      "125.99.106.250:3128\n",
      "172.67.176.74:80\n",
      "104.16.106.234:80\n",
      "172.67.33.204:80\n",
      "103.56.157.223:8080\n",
      "45.131.5.182:80\n",
      "185.162.231.94:80\n",
      "185.238.228.251:80\n",
      "185.162.230.7:80\n",
      "141.193.213.53:80\n",
      "159.112.235.176:80\n",
      "50.175.123.230:80\n",
      "185.162.228.190:80\n",
      "172.67.146.112:80\n",
      "23.227.38.94:80\n",
      "172.67.132.219:80\n",
      "104.18.81.76:80\n",
      "172.67.43.91:80\n",
      "159.112.235.155:80\n",
      "172.67.22.225:80\n",
      "45.12.30.14:80\n",
      "172.67.100.121:80\n",
      "141.101.121.21:80\n",
      "172.67.191.251:80\n",
      "172.67.43.192:80\n",
      "172.67.205.0:80\n",
      "188.114.96.20:80\n",
      "108.162.196.83:80\n",
      "141.193.213.158:80\n",
      "172.67.204.246:80\n",
      "23.227.38.190:80\n",
      "172.67.212.132:80\n",
      "172.67.32.101:80\n",
      "172.67.161.254:80\n",
      "5.182.34.46:80\n",
      "65.108.9.181:80\n",
      "23.227.39.18:80\n",
      "141.101.122.106:80\n",
      "63.141.128.58:80\n",
      "159.112.235.49:80\n",
      "172.67.176.77:80\n",
      "172.67.176.247:80\n",
      "45.131.4.160:80\n",
      "45.131.4.58:80\n",
      "141.101.122.208:80\n",
      "141.101.122.141:80\n",
      "66.235.200.185:80\n",
      "172.67.73.239:80\n",
      "141.193.213.229:80\n",
      "141.101.120.3:80\n",
      "172.67.149.229:80\n",
      "45.131.6.101:80\n",
      "172.67.170.19:80\n",
      "45.131.7.248:80\n",
      "159.246.55.217:80\n",
      "159.112.235.171:80\n",
      "104.25.0.141:80\n",
      "104.27.15.161:80\n",
      "45.131.5.159:80\n",
      "45.131.6.143:80\n",
      "172.64.87.109:80\n",
      "190.93.246.202:80\n",
      "45.131.7.209:80\n",
      "141.101.120.9:80\n",
      "45.131.7.253:80\n",
      "4.158.55.159:8080\n",
      "45.131.5.157:80\n",
      "23.227.39.204:80\n",
      "185.162.229.255:80\n",
      "127.186.210.76:80\n",
      "172.67.70.45:80\n",
      "51.89.134.69:80\n",
      "141.101.120.25:80\n",
      "104.23.107.172:80\n",
      "85.8.68.2:80\n",
      "141.101.120.205:80\n",
      "141.193.213.249:80\n",
      "66.235.200.8:80\n",
      "45.131.5.128:80\n",
      "103.69.20.28:58080\n",
      "45.12.31.141:80\n",
      "50.172.75.121:80\n",
      "185.238.228.194:80\n",
      "172.64.149.76:80\n",
      "104.27.26.29:80\n",
      "138.0.231.202\n",
      "23.227.39.2:80\n",
      "185.162.231.3:80\n",
      "185.162.229.128:80\n",
      "45.131.6.97:80\n",
      "172.67.3.105:80\n",
      "172.64.203.43:80\n",
      "172.67.167.34:80\n",
      "172.67.248.81:80\n",
      "172.67.229.32:80\n",
      "45.131.6.93:80\n",
      "141.101.123.39:80\n",
      "172.67.66.6:80\n",
      "36.92.193.189:80\n",
      "172.67.70.195:80\n",
      "47.237.92.86:88\n",
      "34.175.101.255:80\n",
      "141.101.121.54:80\n",
      "45.85.119.154:80\n",
      "188.114.96.216:80\n",
      "141.101.123.210:80\n",
      "108.162.198.178:80\n",
      "45.12.31.73:80\n",
      "66.235.200.188:80\n",
      "159.112.235.95:80\n",
      "127.49.253.186:80\n",
      "50.171.187.51:80\n",
      "185.238.228.148:80\n",
      "45.131.208.73:80\n",
      "45.131.7.121:80\n",
      "69.84.182.1:80\n",
      "104.19.79.238:80\n",
      "172.67.182.43\n",
      "172.67.40.241:80\n",
      "141.101.114.88:80\n",
      "185.162.228.170:80\n",
      "172.67.107.49:80\n",
      "23.227.39.93:80\n",
      "172.67.141.47:80\n",
      "141.101.120.231:80\n",
      "141.101.122.133:80\n",
      "172.67.181.103:80\n",
      "172.67.180.59:80\n",
      "172.64.148.103:80\n",
      "141.101.122.156:80\n",
      "63.141.128.201:80\n",
      "31.43.179.204:80\n",
      "50.172.75.126:80\n",
      "141.193.213.5:80\n",
      "45.131.4.154:80\n",
      "141.193.213.148:80\n",
      "185.162.229.147:80\n",
      "45.131.6.13:80\n",
      "112.118.59.97\n",
      "141.101.123.97:80\n",
      "172.67.177.128:80\n",
      "172.67.212.31:80\n",
      "138.68.60.8:8080\n",
      "141.101.122.81:80\n",
      "172.67.167.14:80\n",
      "172.66.44.159:80\n",
      "172.67.181.175:80\n",
      "141.101.123.74:80\n",
      "172.67.179.179:80\n",
      "172.67.159.135:80\n",
      "185.162.231.143:80\n",
      "183.88.241.167:8080\n",
      "141.101.114.34:80\n",
      "45.12.31.233:80\n",
      "141.101.120.75:80\n",
      "50.219.249.62:80\n",
      "141.101.121.2:80\n",
      "50.144.208.237:80\n",
      "63.141.128.29:80\n",
      "141.101.121.75:80\n",
      "104.19.225.70:80\n",
      "36.66.242.117:8080\n",
      "<Response [200]>, 109.71.240.93\n",
      "74.48.78.52:80\n",
      "141.101.122.17:80\n",
      "45.131.4.35:80\n",
      "203.104.34.144:3128\n",
      "185.162.229.4:80\n",
      "45.85.119.44:80\n",
      "104.25.194.175:80\n",
      "198.41.204.39:80\n",
      "172.64.165.2:80\n",
      "188.114.96.13:80\n",
      "185.76.10.68:8082\n",
      "141.101.121.191:80\n",
      "45.131.4.237:80\n",
      "104.24.179.171:80\n",
      "185.238.228.128:80\n",
      "66.235.200.228:80\n",
      "185.238.228.91:80\n",
      "23.227.39.96:80\n",
      "141.101.122.186:80\n",
      "8.215.12.103:80\n",
      "45.12.30.181:80\n",
      "108.162.194.71:80\n",
      "45.12.31.128:80\n",
      "108.162.192.135:80\n",
      "172.67.240.33:80\n",
      "49.51.244.112:8888\n",
      "8.213.137.155:8090\n",
      "172.67.70.154:80\n",
      "154.16.146.44:80\n",
      "172.67.176.56:80\n",
      "185.162.230.72:80\n",
      "172.67.50.55:80\n",
      "185.238.228.246:80\n",
      "141.101.120.235:80\n",
      "173.245.49.67:80\n",
      "23.227.39.225:80\n",
      "141.101.120.219:80\n",
      "104.19.124.112:80\n",
      "141.101.123.103:80\n",
      "104.22.50.220:80\n",
      "172.67.0.66:80\n",
      "89.145.162.81:3128\n",
      "172.67.55.49:80\n",
      "172.67.25.90:80\n",
      "172.64.101.253:80\n",
      "173.245.49.173:80\n",
      "172.67.202.134:80\n",
      "50.217.226.42:80\n",
      "45.131.5.190:80\n",
      "63.141.128.226:80\n",
      "172.67.188.10:80\n",
      "141.101.120.1:80\n",
      "188.114.99.153:80\n",
      "23.227.39.88:80\n",
      "172.67.10.152:80\n",
      "141.101.121.197:80\n",
      "172.67.70.246:80\n",
      "172.67.51.128:80\n",
      "172.67.182.85:80\n",
      "66.235.200.133:80\n",
      "45.131.6.50:80\n",
      "23.227.38.162:80\n",
      "141.101.122.220:80\n",
      "172.67.161.0:80\n",
      "162.159.242.190:80\n",
      "141.101.123.34:80\n",
      "172.67.181.205:80\n",
      "213.202.222.75:8080\n",
      "172.67.193.241:80\n",
      "172.67.81.196:80\n",
      "31.43.179.69:80\n",
      "172.67.177.229:80\n",
      "141.193.213.4:80\n",
      "172.64.153.186:80\n",
      "141.101.120.66:80\n",
      "172.67.72.223:80\n",
      "172.67.216.77:80\n",
      "181.214.1.84:80\n",
      "172.67.42.93:80\n",
      "185.162.231.224:80\n",
      "141.193.213.234:80\n",
      "104.19.83.128:80\n",
      "172.67.223.110:80\n",
      "172.67.9.218:80\n",
      "185.162.228.24:80\n",
      "172.67.207.127:80\n",
      "141.193.213.2:80\n",
      "172.64.111.56:80\n",
      "141.101.122.158:80\n",
      "45.131.4.246:80\n",
      "172.67.182.26:80\n",
      "209.97.150.167:3128\n",
      "45.131.4.46:80\n",
      "141.101.121.132:80\n",
      "159.112.235.154:80\n",
      "172.67.156.163:80\n",
      "139.59.1.14:8080\n",
      "164.38.155.97:80\n",
      "27.123.1.46:3128\n",
      "45.131.4.236:80\n",
      "50.144.76.223:80\n",
      "172.67.70.71:80\n",
      "45.12.31.217:80\n",
      "172.67.60.187:80\n",
      "172.67.167.222:80\n",
      "172.64.80.36:80\n",
      "172.64.140.242:80\n",
      "162.240.154.26:3128\n",
      "5.182.34.28:80\n",
      "45.12.30.170:80\n",
      "20.26.97.150:8080\n",
      "172.67.182.76:80\n",
      "188.114.96.51:80\n",
      "45.131.4.168:80\n",
      "50.168.72.118:80\n",
      "23.227.39.232:80\n",
      "188.114.96.109:80\n",
      "172.67.221.193:80\n",
      "5.182.34.170:80\n",
      "34.97.229.206:8561\n",
      "65.109.204.150:80\n",
      "104.16.106.65:80\n",
      "163.172.33.137:4017\n",
      "23.227.39.39:80\n",
      "104.25.42.178:80\n",
      "172.67.171.206:80\n",
      "141.101.122.216:80\n",
      "5.182.34.123:80\n",
      "172.64.166.11:80\n",
      "185.162.228.118:80\n",
      "213.157.6.50:80\n",
      "172.67.82.139:80\n",
      "102.130.125.86:80\n",
      "172.64.154.81:80\n",
      "172.67.3.90:80\n",
      "133.18.234.13:80\n",
      "141.193.213.146:80\n",
      "108.162.193.190:80\n",
      "23.227.38.100:80\n",
      "172.67.136.253:80\n",
      "141.101.122.127:80\n",
      "172.67.176.83:80\n",
      "45.131.5.66:80\n",
      "23.227.38.223:80\n",
      "50.174.7.162:80\n",
      "45.131.4.26:80\n",
      "5.255.113.61:80\n",
      "190.93.247.196:80\n",
      "172.67.215.253:80\n",
      "141.193.213.248:80\n",
      "27.54.150.122:8080\n",
      "45.131.7.192:80\n",
      "23.227.39.206:80\n",
      "185.238.228.39:80\n",
      "45.12.30.18:80\n",
      "172.67.43.245:80\n",
      "23.227.39.238:80\n",
      "172.64.140.232:80\n",
      "172.67.192.4:80\n",
      "31.43.179.10:80\n",
      "63.141.128.18:80\n",
      "66.235.200.172:80\n",
      "190.93.245.41:80\n",
      "45.131.5.248:80\n",
      "104.20.225.218:80\n",
      "172.64.98.80:80\n",
      "66.235.200.247:80\n",
      "141.101.122.252:80\n",
      "172.64.149.43:80\n",
      "172.67.187.136:80\n",
      "50.223.38.6:80\n",
      "172.67.162.18:80\n",
      "185.162.231.194:80\n",
      "172.64.149.40:80\n",
      "45.131.5.152:80\n",
      "63.141.128.107:80\n",
      "20.205.61.143:8123\n",
      "172.67.176.199:80\n",
      "172.67.181.108:80\n",
      "185.162.228.28:80\n",
      "63.141.128.166:80\n",
      "172.67.206.126:80\n",
      "45.131.5.232:80\n",
      "172.67.161.229:80\n",
      "45.131.5.4:80\n",
      "45.131.5.130:80\n",
      "5.182.34.148:80\n",
      "173.245.49.216:80\n",
      "141.193.213.252:80\n",
      "159.112.235.140:80\n",
      "141.101.123.223:80\n",
      "172.67.167.27:80\n",
      "172.67.177.223:80\n",
      "141.101.123.28:80\n",
      "172.67.68.250:80\n",
      "172.66.41.194:80\n",
      "172.67.207.121:80\n",
      "188.114.98.160:80\n",
      "108.162.192.123:80\n",
      "173.245.49.234:80\n",
      "172.67.180.90:80\n",
      "141.101.122.107:80\n",
      "127.178.147.23:80\n",
      "141.101.121.85:80\n",
      "172.67.192.6:80\n",
      "23.227.38.51:80\n",
      "147.78.243.134:8080\n",
      "141.101.113.17:80\n",
      "159.112.235.43:80\n",
      "172.67.130.208:80\n",
      "141.101.120.207:80\n",
      "45.131.208.52:80\n",
      "141.101.120.20:80\n",
      "185.162.228.14:80\n",
      "45.12.31.150:80\n",
      "45.131.4.56:80\n",
      "45.131.7.232:80\n",
      "185.162.230.53:80\n",
      "141.193.213.102:80\n",
      "172.67.70.2:80\n",
      "188.114.96.18:80\n",
      "104.18.103.125:80\n",
      "172.64.145.85:80\n",
      "185.162.228.94:80\n",
      "188.114.98.229:80\n",
      "141.193.213.98:80\n",
      "108.162.193.70:80\n",
      "45.131.5.140:80\n",
      "185.162.229.18:80\n",
      "172.67.70.226:80\n",
      "185.162.231.108:80\n",
      "162.159.240.72:80\n",
      "172.67.162.173:80\n",
      "8.219.97.248:80\n",
      "185.162.230.58:80\n",
      "185.162.230.222:80\n",
      "190.93.246.26:80\n",
      "141.101.114.50:80\n",
      "172.64.175.103:80\n",
      "194.158.203.14:80\n",
      "45.131.4.249:80\n",
      "172.64.155.235:80\n",
      "23.227.38.227:80\n",
      "141.101.120.210:80\n",
      "141.193.213.0:80\n",
      "66.235.200.19:80\n",
      "45.131.6.123:80\n",
      "172.67.75.9:80\n",
      "104.22.20.245:80\n",
      "172.67.223.175:80\n",
      "149.202.91.219:80\n",
      "185.162.228.171:80\n",
      "45.131.7.114:80\n",
      "45.131.5.151:80\n",
      "66.235.200.81:80\n",
      "185.162.228.26:80\n",
      "45.131.7.164:80\n",
      "141.193.213.30:80\n",
      "50.237.207.186:80\n",
      "172.67.182.58:80\n",
      "172.64.96.23:80\n",
      "141.101.120.203:80\n",
      "172.67.47.177:80\n",
      "68.185.57.66:80\n",
      "141.101.121.92:80\n",
      "159.112.235.29:80\n",
      "141.101.120.200:80\n",
      "72.10.164.178\n",
      "63.141.128.232:80\n",
      "172.64.152.139:80\n",
      "172.67.172.19:80\n",
      "172.64.143.2:80\n",
      "141.101.123.46:80\n",
      "172.64.149.20:80\n",
      "23.227.39.193:80\n",
      "8.220.205.172:8081\n",
      "172.67.75.202:80\n",
      "104.16.213.202:80\n",
      "45.131.5.12:80\n",
      "172.67.126.135:80\n",
      "141.101.121.23:80\n",
      "45.131.208.47:80\n",
      "45.131.208.64:80\n",
      "185.162.231.163:80\n",
      "50.207.199.84:80\n",
      "63.141.128.133:80\n",
      "172.67.3.108:80\n",
      "50.168.72.122:80\n",
      "45.131.4.142:80\n",
      "172.67.3.98:80\n",
      "141.101.121.253:80\n",
      "104.18.5.16:80\n",
      "173.245.49.61:80\n",
      "172.64.170.2:80\n",
      "63.141.128.149:80\n",
      "66.235.200.77:80\n",
      "185.162.229.127:80\n",
      "185.162.231.233:80\n",
      "160.153.0.23:80\n",
      "45.12.31.140:80\n",
      "8.211.200.183:8081\n",
      "185.162.229.219:8045.131.4.45:80\n",
      "\n",
      "45.131.4.67:80\n",
      "<Response [200]>, 46.17.63.166\n",
      "5.182.34.167:80\n",
      "193.253.220.32:80\n",
      "141.101.120.247:80\n",
      "185.162.231.127:80\n",
      "141.101.121.109:80\n",
      "172.64.197.198:80\n",
      "115.127.19.163:9090\n",
      "172.67.179.214:80\n",
      "203.150.128.250\n",
      "83.1.176.118:80\n",
      "141.101.122.190:80\n",
      "185.162.228.82:80\n",
      "172.67.70.79:80\n",
      "185.162.229.229:80\n",
      "104.16.106.154:80\n",
      "172.67.177.252:80\n",
      "172.67.117.231:80\n",
      "172.67.219.84:80\n",
      "164.38.155.74:80\n",
      "141.101.122.185:80\n",
      "172.67.181.134:80\n",
      "63.141.128.76:80\n",
      "141.101.122.31:80\n",
      "185.162.229.26:80\n",
      "188.114.99.171:80\n",
      "185.162.229.46:80\n",
      "172.67.174.120:80\n",
      "51.89.14.70:80\n",
      "66.235.200.195:80\n",
      "104.16.72.45:80\n",
      "188.114.98.233:80\n",
      "45.131.6.52:80\n",
      "45.131.5.168:80\n",
      "172.64.149.56:80\n",
      "45.131.6.103:80\n",
      "185.76.10.71:8081\n",
      "141.101.121.5:80\n",
      "31.43.179.152:80\n",
      "23.227.39.15:80\n",
      "159.112.235.208:80\n",
      "54.212.22.168:80\n",
      "141.101.120.172:80\n",
      "141.101.120.103:80\n",
      "104.16.207.86:80\n",
      "172.67.43.146:80\n",
      "172.67.70.75:80\n",
      "185.170.166.61:80\n",
      "104.16.143.212:80\n",
      "172.67.176.149:80\n",
      "45.131.4.172:80\n",
      "141.101.121.66:80\n",
      "63.141.128.144:80\n",
      "45.12.31.76:80\n",
      "141.101.121.15:80\n",
      "45.12.31.240:80\n",
      "141.101.120.26:80\n",
      "185.162.230.221:80\n",
      "45.131.5.56:80\n",
      "172.67.229.18:80\n",
      "188.114.97.141:80\n",
      "173.245.49.91:80\n",
      "172.67.153.51:80\n",
      "172.64.206.54:80\n",
      "23.227.39.244:80\n",
      "185.238.228.218:80\n",
      "172.67.177.61:80\n",
      "188.114.96.99:80\n",
      "172.67.70.66:80\n",
      "104.16.111.78:80\n",
      "45.131.6.132:80\n",
      "104.25.1.19:80\n",
      "189.240.60.168:9090\n",
      "172.67.70.32:80\n",
      "172.67.34.10:80\n",
      "31.43.179.99:80\n",
      "172.67.191.240:80\n",
      "172.67.181.129:80\n",
      "45.12.30.149:80\n",
      "172.64.89.97:80\n",
      "172.67.170.170:80\n",
      "141.101.122.72:80\n",
      "172.64.200.15:80\n",
      "185.162.231.38:80\n",
      "141.193.213.14:80\n",
      "185.162.230.165:80\n",
      "34.81.72.31:80\n",
      "45.131.5.206:80\n",
      "141.101.121.120:80\n",
      "170.114.46.8:80\n",
      "103.40.121.31:8087\n",
      "185.162.230.154:80\n",
      "172.67.182.155:80\n",
      "66.235.200.145:80\n",
      "172.67.203.123:80\n",
      "141.193.213.18:80\n",
      "172.67.171.208:80\n",
      "141.101.121.37:80\n",
      "23.227.38.204:80\n",
      "45.131.5.208:80\n",
      "45.131.5.192:80\n",
      "172.64.141.101:80\n",
      "23.227.39.182:80\n",
      "45.12.30.65:80\n",
      "41.204.53.17:80\n",
      "141.101.120.151:80\n",
      "66.235.200.177:80\n",
      "141.101.123.224:80\n",
      "45.12.30.189\n",
      "104.16.219.108:80\n",
      "104.25.0.132:80\n",
      "172.67.167.107:80\n",
      "66.235.200.194:80\n",
      "147.75.34.103:10000\n",
      "47.91.120.190:1025\n",
      "50.218.208.10:80\n",
      "172.67.223.255:80\n",
      "141.101.123.118:80\n",
      "172.64.193.14:80\n",
      "141.101.122.8:80\n",
      "141.101.123.82:80\n",
      "172.64.90.66:80\n",
      "104.16.146.212:80\n",
      "63.141.128.33:80\n",
      "63.141.128.164:80\n",
      "45.12.31.23:80\n",
      "172.67.181.207:80\n",
      "173.245.49.30:80\n",
      "141.101.115.251:80\n",
      "164.38.155.25:80\n",
      "45.131.6.25:80\n",
      "108.162.193.73:80\n",
      "172.67.246.126:80\n",
      "172.67.206.105:80\n",
      "185.162.231.92:80\n",
      "160.153.0.158:80\n",
      "62.169.26.156:8082\n",
      "45.12.31.3:80\n",
      "162.159.242.104:80\n",
      "104.25.0.173:80\n",
      "185.162.231.189:80\n",
      "172.64.154.180:80\n",
      "185.162.229.95:80\n",
      "104.25.0.0:80\n",
      "104.23.141.196:80\n",
      "172.67.172.7:80\n",
      "5.182.34.238:80\n",
      "172.67.62.100:80\n",
      "172.64.149.18:80\n",
      "172.67.128.39:80\n",
      "50.171.163.242:80\n",
      "31.211.82.232:3128\n",
      "172.64.151.110:80\n",
      "172.67.23.199:80\n",
      "172.67.254.173:80\n",
      "174.138.54.65:80\n",
      "45.131.6.245:80\n",
      "31.43.179.253:80\n",
      "104.19.85.214:80\n",
      "172.64.204.240:80\n",
      "141.101.123.147:80\n",
      "172.67.181.188:80\n",
      "172.67.181.5:80\n",
      "162.223.90.130:80\n",
      "31.47.58.37:80\n",
      "172.67.180.6:80\n",
      "141.101.120.236:80\n",
      "185.162.231.81:80\n",
      "172.67.43.219:80\n",
      "172.67.167.75:80\n",
      "23.227.38.128:80\n",
      "66.29.154.103:3128\n",
      "172.67.195.65:80\n",
      "147.75.34.103:10003\n",
      "172.67.156.214:80\n",
      "172.67.192.42:80\n",
      "172.67.3.84:80\n",
      "45.12.30.57:80\n",
      "187.32.246.82:3128\n",
      "185.162.229.244:80\n",
      "172.66.42.119:80\n",
      "172.64.128.134:80\n",
      "141.101.120.142:80\n",
      "188.114.96.58:80\n",
      "157.254.53.50:80\n",
      "31.43.179.98:80\n",
      "172.67.162.212:80\n",
      "172.67.75.148:80\n",
      "141.101.121.32:80\n",
      "45.131.208.1:80\n",
      "45.131.5.164:80\n",
      "141.101.123.171:80\n",
      "54.37.74.220:80\n",
      "47.238.130.212:8081\n",
      "23.227.38.187:80\n",
      "141.101.121.194:80\n",
      "172.64.155.138:80\n",
      "66.235.200.200:80\n",
      "23.227.38.157:80\n",
      "103.160.204.104:80\n",
      "63.141.128.9:80\n",
      "185.162.228.223:80\n",
      "185.238.228.150:80\n",
      "172.64.35.17:80\n",
      "23.227.38.83:80\n",
      "72.10.160.170:21047\n",
      "0.0.0.0:80\n",
      "185.162.230.189:80\n",
      "172.67.183.130:80\n",
      "43.255.113.232:80\n",
      "104.20.125.124:80\n",
      "23.227.38.251:80\n",
      "141.101.120.90:80\n",
      "172.67.161.237:80\n",
      "141.101.120.10:80\n",
      "104.16.25.216:80\n",
      "173.245.49.139:80\n",
      "45.12.30.139:80\n",
      "172.67.213.75:80\n",
      "45.131.4.105\n",
      "185.162.229.195:80\n",
      "45.131.7.236:80\n",
      "141.101.121.72:80\n",
      "172.64.50.65:80\n",
      "63.141.128.250:80\n",
      "50.149.13.194:80\n",
      "23.227.38.89:80\n",
      "66.235.200.107:80\n",
      "172.64.154.50:80\n",
      "31.43.179.36:80\n",
      "172.67.182.132:80\n",
      "172.64.131.16:80\n",
      "164.38.155.31:80\n",
      "185.162.228.227:80\n",
      "141.101.123.244:80\n",
      "45.131.6.172\n",
      "172.67.229.16:80\n",
      "141.101.122.115:80\n",
      "108.162.198.141:80\n",
      "172.67.3.62:80\n",
      "141.101.123.153:80\n",
      "185.162.229.58:80\n",
      "173.245.49.232:80\n",
      "203.19.38.114:1080\n",
      "172.64.86.249:80\n",
      "8.215.3.250:8081\n",
      "104.20.75.36:80\n",
      "200.77.186.88:80\n",
      "188.114.96.30:80\n",
      "31.43.179.118:80\n",
      "66.235.200.254:80\n",
      "172.67.156.153:80\n",
      "141.101.120.152:80\n",
      "23.227.38.141:80\n",
      "172.67.177.200:80\n",
      "185.162.230.130:80\n",
      "45.131.4.122:80\n",
      "104.17.147.22:80\n",
      "172.67.43.203:80\n",
      "104.27.37.131:80\n",
      "50.221.230.186:80\n",
      "159.112.235.73:80\n",
      "104.25.0.65:80\n",
      "141.193.213.177:80\n",
      "141.101.120.96:80\n",
      "141.101.121.39:80\n",
      "141.101.120.112:80\n",
      "23.227.39.59:80\n",
      "172.67.181.119:80\n",
      "172.67.71.68:80\n",
      "141.101.120.2:80\n",
      "45.131.6.213:80\n",
      "45.131.4.252:80\n",
      "63.141.128.127:80\n",
      "185.238.228.114:80\n",
      "172.67.43.131:80\n",
      "63.141.128.104:80\n",
      "141.101.120.130:80\n",
      "104.27.27.97:80\n",
      "172.67.98.18:80\n",
      "45.131.7.132:80\n",
      "23.227.39.231:80\n",
      "172.67.176.121:80\n",
      "50.217.226.46:80\n",
      "45.131.5.67:80\n",
      "172.64.195.2:80\n",
      "189.240.60.164:9090\n",
      "172.67.56.51:80\n",
      "141.193.213.19:80\n",
      "104.25.234.81:80\n",
      "172.67.192.28:80\n",
      "141.101.121.238:80\n",
      "172.67.70.141:80\n",
      "172.67.167.118:80\n",
      "23.227.39.201:80\n",
      "141.101.121.123:80\n",
      "104.17.62.87:80\n",
      "141.101.121.142:80\n",
      "188.114.96.56:80\n",
      "172.67.138.108:80\n",
      "50.217.226.41\n",
      "45.12.30.104:80\n",
      "31.43.179.164:80\n",
      "185.162.229.59:80\n",
      "104.17.66.69:80\n",
      "162.214.165.203:80\n",
      "45.8.21.156\n",
      "104.17.239.10:80\n",
      "172.67.75.186:80\n",
      "108.162.195.77:80\n",
      "141.101.122.99:80\n",
      "141.101.122.112:80\n",
      "172.67.0.6:80\n",
      "185.162.229.72:80\n",
      "190.58.248.86:80\n",
      "172.67.176.173:80\n",
      "172.64.161.48:80\n",
      "141.101.120.37:80\n",
      "185.76.10.68:8081\n",
      "172.67.161.204:80\n",
      "45.131.208.106:80\n",
      "172.67.3.87:80\n",
      "185.162.228.48:80\n",
      "141.101.121.205:80\n",
      "141.101.121.235:80\n",
      "50.171.187.50:80\n",
      "159.112.235.153:80\n",
      "172.67.181.107:80\n",
      "45.131.7.180:80\n",
      "45.131.6.42:80\n",
      "172.67.26.7:80\n",
      "141.101.120.42:80\n",
      "103.203.234.28:8090\n",
      "141.101.121.28:80\n",
      "172.67.43.124:80\n",
      "50.172.75.122:80\n",
      "172.67.253.69:80\n",
      "45.131.7.79:80\n",
      "160.153.0.1:80\n",
      "23.227.38.52:80\n",
      "172.67.145.144:80\n",
      "141.101.122.182:80\n",
      "185.238.228.147:80\n",
      "141.101.121.127:80\n",
      "141.101.121.1:80\n",
      "172.67.191.232:80\n",
      "172.64.95.115:80\n",
      "159.112.235.215:80\n",
      "172.67.192.7:80\n",
      "185.162.229.98:80\n",
      "172.64.160.123:80\n",
      "27.147.139.241:58080\n",
      "172.64.149.58:80\n",
      "172.67.219.146:80\n",
      "185.238.228.130:80\n",
      "172.64.89.0:80\n",
      "172.67.182.118:80\n",
      "50.175.123.239:80\n",
      "172.67.90.216:80\n",
      "172.67.192.16:80\n",
      "141.101.113.49:80\n",
      "23.227.60.19:80\n",
      "141.193.213.183:80\n",
      "47.90.205.231:33333\n",
      "141.193.213.193:80\n",
      "141.101.120.80:80\n",
      "104.24.136.68:80\n",
      "104.25.0.147:80\n",
      "45.12.30.138:80\n",
      "141.101.122.82:80\n",
      "63.143.57.116:80\n",
      "172.67.182.8:80\n",
      "172.67.185.152:80\n",
      "141.101.122.123:80\n",
      "141.101.115.247:80\n",
      "203.99.240.179:80\n",
      "159.65.245.255:80\n",
      "63.141.128.113:80\n",
      "172.67.170.20:80\n",
      "141.101.122.130:80\n",
      "108.162.192.0:80\n",
      "185.162.229.14:80\n",
      "45.131.6.76:80\n",
      "66.235.200.54:80\n",
      "172.67.182.141:80\n",
      "172.67.138.63:80\n",
      "172.64.151.24:80\n",
      "45.12.31.123:80\n",
      "141.101.120.196:80\n",
      "207.230.8.10:999\n",
      "43.153.208.148:3128\n",
      "172.67.177.139:80\n",
      "62.72.166.135:80\n",
      "185.162.229.218:80\n",
      "185.238.228.136:80\n",
      "172.67.187.199:80\n",
      "172.67.182.92:80\n",
      "104.22.1.113:80\n",
      "172.67.37.33:80\n",
      "185.162.231.106:80\n",
      "104.16.104.12:80\n",
      "141.101.123.233:8045.131.5.118:80\n",
      "141.193.213.32:80\n",
      "\n",
      "172.67.43.160:80\n",
      "45.131.6.180:80\n",
      "8.213.128.90:8989\n",
      "141.101.122.16:80\n",
      "45.131.5.211:80\n",
      "190.93.244.9:80\n",
      "172.64.198.163:80\n",
      "81.200.149.178:80\n",
      "172.64.149.65:80\n",
      "45.131.5.86:80\n",
      "172.64.149.74:80\n",
      "172.64.202.141:80\n",
      "172.67.71.85:80\n",
      "45.131.4.14:8023.227.38.118:80\n",
      "\n",
      "172.67.14.237:80\n",
      "45.131.208.88:80\n",
      "141.101.122.209:80\n",
      "45.12.30.43:80\n",
      "172.67.43.240:80\n",
      "172.67.177.199:80\n",
      "104.20.205.191:80\n",
      "173.245.49.15:80\n",
      "<Response [200]>, 185.94.35.159\n",
      "41.204.53.30:80\n",
      "141.101.122.196:80\n",
      "141.101.123.174:80\n",
      "45.12.30.189:80\n",
      "172.67.111.143:80\n",
      "104.16.105.146:80\n",
      "172.67.176.169:80\n",
      "172.67.191.44:80\n",
      "185.162.228.40:80\n",
      "45.12.31.24:80\n",
      "104.25.0.122:80\n",
      "185.170.166.31:80\n",
      "5.182.34.182:80\n",
      "45.131.5.93:80\n",
      "50.217.226.45:80\n",
      "41.230.216.70:80\n",
      "185.162.230.69:80\n",
      "45.131.6.20:80\n",
      "23.227.39.174:80\n",
      "104.18.44.93:80\n",
      "108.162.193.175:80\n",
      "45.131.6.144:80\n",
      "45.131.4.17:80\n",
      "185.162.231.49:80\n",
      "172.67.70.122:80\n",
      "185.162.231.254:80\n",
      "141.101.123.180:80\n",
      "172.64.103.77:80\n",
      "50.169.222.244:80\n",
      "141.101.121.20:80\n",
      "45.131.6.80:80\n",
      "45.131.5.58:80\n",
      "172.67.171.205:80\n",
      "172.67.71.198:80\n",
      "172.67.71.247:80\n",
      "188.114.98.27:80\n",
      "111.1.61.47:3128\n",
      "172.67.70.134:80\n",
      "50.174.7.153:80\n",
      "172.67.219.44:80\n",
      "104.20.75.31:80\n",
      "170.114.45.1:80\n",
      "188.114.96.57:80\n",
      "159.112.235.39:80\n",
      "45.12.31.234:80\n",
      "172.67.40.139:80\n",
      "185.162.230.87:80\n",
      "159.112.235.78:80\n",
      "172.64.166.128:80\n",
      "172.67.133.81:80\n",
      "104.20.227.246:80\n",
      "141.193.213.40:80\n",
      "172.67.245.159:80\n",
      "104.20.75.198:80\n",
      "172.64.142.76:80\n",
      "172.67.12.34:80\n",
      "104.16.105.225:80\n",
      "172.67.167.117:80\n",
      "50.207.199.87:80\n",
      "47.74.152.29:8888\n",
      "188.114.96.97:80\n",
      "45.131.7.101:80\n",
      "50.220.168.134:80\n",
      "50.174.109.166:80\n",
      "45.12.30.138\n",
      "172.67.111.100:80\n",
      "141.193.213.141:80\n",
      "69.84.182.28:80\n",
      "45.12.31.148:80\n",
      "78.28.152.111:80\n",
      "159.112.235.187:80\n",
      "172.67.12.89:80\n",
      "172.67.170.13:80\n",
      "185.238.228.179:80\n",
      "141.101.120.250:80\n",
      "80.78.64.70:8080\n",
      "23.227.39.141:80\n",
      "172.67.142.195:80\n",
      "172.67.163.136:80\n",
      "<Response [200]>, 151.236.14.178\n",
      "141.101.123.155:80\n",
      "172.67.176.15:80\n",
      "172.67.129.45:80\n",
      "172.67.3.76:80\n",
      "172.67.175.139:80\n",
      "172.64.34.156:80\n",
      "172.67.167.63:80\n",
      "172.67.185.155:80\n",
      "45.12.31.245:80\n",
      "8.221.138.111:80\n",
      "185.162.228.246:80\n",
      "23.227.38.243:80\n",
      "172.67.185.174:80\n",
      "220.248.70.237:9002\n",
      "172.67.55.151:80\n",
      "45.12.31.202:80\n",
      "45.131.5.82:8063.141.128.158:80\n",
      "\n",
      "104.25.87.42:80\n",
      "195.114.209.50:80\n",
      "172.67.167.36:80\n",
      "172.64.87.177:80\n",
      "141.193.213.247:80\n",
      "23.227.39.121:80\n",
      "141.101.123.105:80\n",
      "172.67.82.234:80\n",
      "45.131.4.110:80\n",
      "66.235.200.87:80\n",
      "185.162.228.86:80\n",
      "159.112.235.64:80\n",
      "23.227.39.250:80\n",
      "190.93.244.171:80\n",
      "45.131.208.24:80\n",
      "23.227.60.200:80\n",
      "172.64.92.45:80\n",
      "172.67.181.239:80\n",
      "159.112.235.16:80\n",
      "141.101.122.85:80\n",
      "141.101.122.152:80\n",
      "172.67.31.55:80\n",
      "66.235.200.138:80\n",
      "104.19.235.10:80\n",
      "104.21.194.19:80\n",
      "185.162.228.173:80\n",
      "5.182.34.88:80\n",
      "172.67.177.188:80\n",
      "185.162.229.24:80\n",
      "172.67.43.233:80\n",
      "172.67.161.218:80\n",
      "185.162.231.85:80\n",
      "45.131.5.88:80\n",
      "172.64.139.80:80\n",
      "172.67.182.105:80\n",
      "45.131.7.190:80\n",
      "141.101.120.98:80\n",
      "41.204.53.17\n",
      "104.18.251.208:80\n",
      "23.227.38.44:80\n",
      "45.131.5.77:80\n",
      "159.112.235.1:80\n",
      "141.101.121.71:80\n",
      "69.84.182.51:80\n",
      "141.101.122.53:80\n",
      "66.235.200.225:80\n",
      "141.101.122.64:80\n",
      "141.101.123.203:80\n",
      "172.67.167.153:80\n",
      "185.162.228.230:80\n",
      "141.101.123.58:80\n",
      "117.74.65.207:443\n",
      "172.67.170.109:80\n",
      "188.114.96.9:80\n",
      "141.101.120.100:80\n",
      "149.154.157.17:4003\n",
      "172.67.10.96\n",
      "141.101.123.143:80\n",
      "141.101.121.67:80\n",
      "47.250.51.110:31281\n",
      "108.162.198.161:80\n",
      "172.67.181.145:80\n",
      "172.67.192.10:80\n",
      "34.111.135.19:80\n",
      "141.101.123.129:80\n",
      "172.67.128.116:80\n",
      "50.168.72.112:80\n",
      "172.64.149.37:80\n",
      "172.67.97.27:80\n",
      "172.67.182.162:80\n",
      "172.67.70.152:80\n",
      "185.238.228.240:80\n",
      "172.67.11.143:80\n",
      "23.227.39.136:80\n",
      "61.239.229.209:8193\n",
      "172.67.123.230:80\n",
      "143.107.199.248:8080\n",
      "172.67.184.254:80\n",
      "172.67.70.247:80\n",
      "185.162.230.101\n",
      "45.131.4.76:80\n",
      "23.227.39.91:80\n",
      "114.129.2.82\n",
      "141.101.120.230:80\n",
      "172.64.131.181:80\n",
      "172.67.152.101:80\n",
      "172.67.182.2:80\n",
      "94.247.129.244:3128\n",
      "141.101.120.179:80\n",
      "108.162.198.72:80\n",
      "141.101.120.165:80\n",
      "188.114.96.76:80\n",
      "210.61.207.92:80\n",
      "31.43.179.52:80\n",
      "104.20.98.117:80\n",
      "160.153.0.26:80\n",
      "31.43.179.194:80\n",
      "172.67.177.23:80\n",
      "185.162.230.123:80\n",
      "185.162.231.178:80\n",
      "63.141.128.217:80\n",
      "45.12.30.108:80\n",
      "141.101.121.26:80\n",
      "172.64.205.110:80\n",
      "141.101.120.193:80\n",
      "104.25.0.20:80\n",
      "172.64.160.44:80\n",
      "5.182.34.178:80\n",
      "172.67.176.224:80\n",
      "141.101.121.236:80\n",
      "104.25.1.250:80\n",
      "172.67.190.16:80\n",
      "50.144.76.218:80\n",
      "172.67.141.210:80\n",
      "185.162.229.70:80\n",
      "31.43.179.160:80\n",
      "172.67.70.190:80\n",
      "5.182.34.193:80\n",
      "172.67.171.224:80\n",
      "104.21.85.200:80\n",
      "103.120.6.46:80\n",
      "172.67.165.47:80\n",
      "172.67.43.184:80\n",
      "45.131.7.214:80\n",
      "141.101.121.52:80\n",
      "172.66.41.75:80\n",
      "172.67.167.2:80\n",
      "185.162.231.87:80\n",
      "123.30.154.171:7777\n",
      "159.112.235.5:80\n",
      "172.67.167.104:80\n",
      "104.19.171.188:80\n",
      "104.16.241.204:80\n",
      "45.85.119.238:80\n",
      "85.210.121.11:8080\n",
      "141.193.213.103:80\n",
      "104.19.5.247:80\n",
      "185.162.231.0:80\n",
      "198.44.255.3:80\n",
      "172.67.75.200:80\n",
      "23.227.38.45:80\n",
      "172.67.181.204:80\n",
      "45.131.5.117:80\n",
      "141.101.120.248:80\n",
      "172.67.175.171:80\n",
      "159.112.235.170:80\n",
      "159.112.235.209:80\n",
      "172.67.206.108:80\n",
      "69.84.182.44:80\n",
      "103.46.10.18:7777\n",
      "141.101.121.200:80\n",
      "141.101.123.234:80\n",
      "172.64.194.94:80\n",
      "141.101.123.59:80\n",
      "80.120.49.242:80\n",
      "45.131.6.62:80\n",
      "172.67.127.8:80\n",
      "141.101.120.182:80\n",
      "104.21.124.121:8085.210.203.188:8080\n",
      "\n",
      "45.12.30.203:80\n",
      "172.67.219.1:80\n",
      "172.67.177.11:80\n",
      "104.20.220.109:80\n",
      "108.162.195.101:80\n",
      "141.101.120.214:80\n",
      "104.20.75.132:80\n",
      "172.67.177.237:80\n",
      "8.220.204.215:80\n",
      "172.64.111.176:80\n",
      "172.67.0.222:80\n",
      "141.101.121.117:80\n",
      "141.101.121.199:80\n",
      "172.66.45.210:80\n",
      "185.162.228.211:80\n",
      "104.25.1.236:80\n",
      "173.245.49.209:80\n",
      "141.101.121.34:80\n",
      "185.238.228.151:80\n",
      "172.67.0.2:80\n",
      "63.141.128.200:80\n",
      "185.162.230.139:80\n",
      "141.101.120.41:80\n",
      "172.67.185.182:80\n",
      "45.12.30.205:80\n",
      "141.101.121.168:80\n",
      "104.25.2.5:80\n",
      "141.101.120.19:80\n",
      "38.54.116.9:8008\n",
      "141.193.213.99:80\n",
      "188.114.96.153:80\n",
      "172.67.188.9:80\n",
      "141.101.121.154:80\n",
      "63.141.128.123:80\n",
      "185.162.229.50:80\n",
      "172.67.181.210:80\n",
      "172.67.140.71:80\n",
      "141.101.120.85:80\n",
      "164.38.155.84:80\n",
      "185.162.231.104:80\n",
      "172.67.164.135:80\n",
      "172.67.191.237:80\n",
      "188.114.96.62:80\n",
      "43.134.121.40:3128\n",
      "45.131.7.184:80\n",
      "172.67.167.41:80\n",
      "185.162.230.143:80\n",
      "172.64.204.2:80\n",
      "23.227.38.226:80\n",
      "50.168.72.119:80\n",
      "173.245.49.141:80\n",
      "141.101.120.106:80\n",
      "185.162.228.72:80\n",
      "104.21.223.181:80\n",
      "23.227.38.122:80\n",
      "185.162.231.151:80\n",
      "172.67.177.207:80\n",
      "104.21.68.195:80\n",
      "185.162.228.3:80\n",
      "45.12.31.50:80\n",
      "172.67.171.213:80\n",
      "203.89.8.107:80\n",
      "190.93.244.37:80\n",
      "172.67.85.32:80\n",
      "172.67.70.162:80\n",
      "172.64.48.219:80\n",
      "173.245.49.228:80\n",
      "104.21.66.184:80\n",
      "45.12.30.42:80\n",
      "115.74.246.138:8080\n",
      "108.162.196.76:80\n",
      "172.67.164.202:80\n",
      "141.193.213.37:80\n",
      "185.162.228.174:80\n",
      "172.67.185.198:80\n",
      "141.101.121.88:80\n",
      "185.162.230.248:80\n",
      "45.131.6.233:80\n",
      "45.131.4.119:80\n",
      "172.67.182.36:80\n",
      "45.12.31.92:80\n",
      "185.162.230.62:80\n",
      "45.131.5.167:80\n",
      "185.162.229.23:80\n",
      "185.162.230.113:80\n",
      "141.101.120.134:80\n",
      "45.131.4.131:80\n",
      "141.101.120.111:80\n",
      "141.193.213.113:80\n",
      "141.193.213.90:80\n",
      "127.51.49.45:80\n",
      "185.162.228.119:80\n",
      "45.131.210.64:80\n",
      "172.64.195.55:80\n",
      "23.227.39.133:80\n",
      "63.141.128.5:80\n",
      "141.101.120.189:80\n",
      "45.131.6.117:80\n",
      "45.12.30.195:80\n",
      "20.205.61.143:80\n",
      "172.67.187.240:80\n",
      "63.141.128.143:80\n",
      "50.149.13.197:80\n",
      "172.67.174.180:80\n",
      "141.101.113.95:80\n",
      "104.25.0.119:80\n",
      "141.101.120.175:80\n",
      "104.16.109.207:80\n",
      "45.12.30.103:80\n",
      "45.131.6.145:80\n",
      "172.67.217.243:80\n",
      "172.64.197.2:80\n",
      "172.67.181.203:80\n",
      "159.112.235.165:80\n",
      "127.119.167.236:80\n",
      "31.43.179.163:80\n",
      "141.101.121.50:80\n",
      "45.131.5.95:80\n",
      "45.12.30.141:80\n",
      "172.67.187.242:80\n",
      "172.67.3.115:80\n",
      "172.64.198.124:80\n",
      "45.131.208.61:80\n",
      "159.112.235.87:80\n",
      "141.101.120.154:80\n",
      "45.131.6.6:80\n",
      "172.67.16.210:80\n",
      "141.101.120.199:80\n",
      "172.67.38.96:80\n",
      "8.213.134.213:9098\n",
      "45.131.6.79:80\n",
      "141.101.122.135:80\n",
      "141.101.121.214:80\n",
      "172.67.79.154:80\n",
      "185.162.229.34:80\n",
      "80.228.235.6:80\n",
      "141.101.121.156:80\n",
      "141.101.123.77:80\n",
      "173.245.49.247:80\n",
      "159.112.235.166:80\n",
      "45.131.6.162:80\n",
      "172.67.166.239:80\n",
      "188.114.97.0:80\n",
      "185.162.229.215:80\n",
      "104.25.115.125:80\n",
      "141.101.121.8:80\n",
      "172.67.70.167:80\n",
      "172.67.69.9:80\n",
      "63.141.128.116:80\n",
      "108.162.194.156:80\n",
      "185.238.228.234:80\n",
      "141.101.113.20:80\n",
      "185.162.229.248:80\n",
      "45.131.208.46:80\n",
      "172.67.181.121:80\n",
      "172.67.176.216:80\n",
      "47.56.110.204:8989\n",
      "185.162.230.65\n",
      "45.131.7.207:80\n",
      "159.112.235.150:80\n",
      "172.64.91.21:80\n",
      "23.227.39.191:80\n",
      "141.101.120.139:80\n",
      "141.101.115.249:80\n",
      "172.64.198.18:80\n",
      "141.101.120.15:80\n",
      "172.67.139.99:80\n",
      "172.67.192.8:80\n",
      "172.67.134.82:80\n",
      "172.64.107.251:80\n",
      "185.162.228.113:80\n",
      "45.131.7.141:80\n",
      "141.101.120.74:80\n",
      "50.217.226.41:80\n",
      "104.20.75.48:80\n",
      "172.67.216.128:80\n",
      "172.67.181.171:80\n",
      "45.131.6.56:80\n",
      "141.101.120.141:80\n",
      "66.235.200.16:80\n",
      "190.93.244.108:80\n",
      "172.67.182.158:80\n",
      "8.213.156.191:1036\n",
      "185.162.229.103:80\n",
      "141.101.121.30:80\n",
      "104.18.45.96:80\n",
      "172.67.167.159:80\n",
      "8.220.205.172:9098\n",
      "164.38.155.87:80\n",
      "104.25.173.13:80\n",
      "172.67.181.14:80\n",
      "45.131.208.6:80\n",
      "185.170.166.68:80\n",
      "141.101.123.145:80\n",
      "50.217.226.47:80\n",
      "172.67.3.66:80\n",
      "172.67.167.73:80\n",
      "185.162.228.163:80\n",
      "141.101.120.36:80\n",
      "23.227.39.178:80\n",
      "188.114.96.52:80\n",
      "45.131.5.242:80\n",
      "45.12.30.113:80\n",
      "31.43.179.129:80\n",
      "172.67.49.148:80\n",
      "188.114.98.188:80\n",
      "190.93.246.254:80\n",
      "172.64.111.28:80\n",
      "141.101.121.59:80\n",
      "172.64.86.41:80\n",
      "172.67.254.44:80\n",
      "185.18.250.107:80\n",
      "63.141.128.126:80\n",
      "141.101.121.165:80\n",
      "23.227.38.148:80\n",
      "31.43.179.197:80\n",
      "45.131.4.13:80\n",
      "172.67.182.150:80\n",
      "172.67.182.113:80\n",
      "172.64.171.178:80\n",
      "104.26.3.46:80\n",
      "141.101.121.183:80\n",
      "45.131.5.44:80\n",
      "45.131.5.243:80\n",
      "141.101.115.245:80\n",
      "172.67.153.171:80\n",
      "172.67.215.205:80\n",
      "141.101.120.105:80\n",
      "23.227.39.94:80\n",
      "104.21.22.79:80\n",
      "104.26.2.46:80\n",
      "172.64.196.2:80\n",
      "172.67.176.104:80\n",
      "172.64.133.99:80\n",
      "111.53.178.249:7302\n",
      "141.101.121.134:80\n",
      "173.245.49.109:80\n",
      "45.131.6.21:80\n",
      "154.16.146.46:80\n",
      "23.227.39.38:80\n",
      "172.67.180.2:80\n",
      "162.159.242.230:80\n",
      "141.101.120.253:80\n",
      "45.131.5.84:80\n",
      "141.101.120.77:80\n",
      "172.67.70.229:80\n",
      "141.101.121.61:80\n",
      "172.67.165.42:80\n",
      "185.162.229.174:80\n",
      "141.101.115.252:80\n",
      "173.245.49.214:80\n",
      "172.64.91.42:80\n",
      "172.67.22.151:80\n",
      "172.67.3.131:80\n",
      "50.144.212.204:80\n",
      "141.101.123.116:80\n",
      "172.67.177.41:80\n",
      "141.101.121.188:80\n",
      "45.131.5.74:80\n",
      "172.67.106.72:80\n",
      "51.91.109.83:80\n",
      "172.67.3.73:80\n",
      "185.162.229.20:80\n",
      "172.64.108.3:80\n",
      "141.101.120.14:80\n",
      "<Response [200]>, 160.86.242.23\n",
      "45.12.30.29:80\n",
      "172.67.240.120:80\n",
      "141.101.113.23:80\n",
      "172.67.161.148:80\n",
      "141.193.213.232:80\n",
      "185.170.166.42:80\n",
      "172.64.84.81:80\n",
      "4.158.175.186:8080\n",
      "5.182.34.40:80\n",
      "8.212.168.170:8443\n",
      "185.162.231.99:80\n",
      "45.12.31.36:80\n",
      "172.67.182.139:80\n",
      "47.250.155.254:9098\n",
      "172.67.76.22:80\n",
      "45.85.119.144:80\n",
      "141.101.121.13:80\n",
      "66.235.200.73:80\n",
      "66.235.200.132:80\n",
      "23.227.38.220:80\n",
      "154.92.9.5:80\n",
      "141.101.120.0:80\n",
      "45.131.208.103:80\n",
      "193.233.84.94:1080\n",
      "66.235.200.227:80\n",
      "185.162.230.74:80\n",
      "66.235.200.2:80\n",
      "185.162.230.55:80\n",
      "190.107.232.138:999\n",
      "62.210.215.36:80\n",
      "50.168.72.113:80\n",
      "63.141.128.238:80\n",
      "172.67.172.152:80\n",
      "141.101.120.40:80\n",
      "66.235.200.166:80\n",
      "141.101.120.78:80\n",
      "188.114.97.18:80\n",
      "172.67.70.125:80\n",
      "172.67.167.251:80\n",
      "45.131.5.53:80\n",
      "45.12.30.218:80\n",
      "172.67.229.36:80\n",
      "85.210.84.189:8080\n",
      "188.114.96.75:80\n",
      "185.238.228.52:80\n",
      "45.131.5.216:80\n",
      "45.12.31.161:80\n",
      "173.245.49.12:80\n",
      "45.131.208.75:80\n",
      "141.101.120.184:80\n",
      "172.67.194.202:80\n",
      "172.64.202.196:80\n",
      "172.67.132.253:80\n",
      "8.220.204.92:8081\n",
      "45.131.6.170:80\n",
      "172.67.151.120:80\n",
      "172.67.43.210:80\n",
      "50.171.207.93:80\n",
      "185.238.228.5:80\n",
      "104.25.1.181:80\n",
      "185.162.231.196:80\n",
      "172.64.202.2:80\n",
      "141.101.120.21:80\n",
      "50.223.246.237:80\n",
      "194.163.149.123:1111\n",
      "45.131.5.17:80\n",
      "172.67.181.91:80\n",
      "172.67.10.90:80\n",
      "185.162.228.39:80\n",
      "51.255.20.138:80\n",
      "23.227.38.1:80\n",
      "172.67.128.62:80\n",
      "172.64.149.29:80\n",
      "45.131.5.143:80\n",
      "172.64.140.3:80\n",
      "172.67.254.245:80\n",
      "185.162.229.79:80\n",
      "172.67.59.22:80\n",
      "159.112.235.160:80\n",
      "172.67.191.242:80\n",
      "108.162.198.170:80\n",
      "141.101.122.121:80\n",
      "159.112.235.31:80\n",
      "164.38.155.35:80\n",
      "185.170.166.83:80\n",
      "31.43.179.125:80\n",
      "188.253.6.26:80\n",
      "38.51.232.18:8080\n",
      "45.12.30.107:80\n",
      "45.131.5.197:80\n",
      "172.67.70.217:80\n",
      "141.101.120.254:80\n",
      "172.67.139.161:80\n",
      "104.25.0.216:80\n",
      "45.131.208.113:80\n",
      "31.43.179.162:80\n",
      "104.25.135.170:80\n",
      "185.162.228.87:80\n",
      "50.207.199.82:80\n",
      "<Response [200]>, 43.134.33.254\n",
      "154.73.28.253:8080\n",
      "192.73.244.36:80\n",
      "32.223.6.94:80\n",
      "50.172.39.98:80\n",
      "50.174.7.154:80\n",
      "118.172.184.25:8180\n",
      "147.45.48.225:1080\n",
      "50.168.72.114:80\n",
      "<Response [200]>, 178.48.68.61\n",
      "8.211.194.85:9080\n",
      "47.250.11.111:9098\n"
     ]
    }
   ],
   "source": [
    "#scrape from freeproxy.world\n",
    "url = \"https://www.freeproxy.world/\"\n",
    "proxylist =[]\n",
    "#filter through all pages\n",
    "for i in range(1,75):\n",
    "    print(i)\n",
    "    try:\n",
    "        #filter to http proxy\n",
    "        querystring = {\"type\":\"http\",\"anonymity\":\"\",\"country\":\"\",\"speed\":\"\",\"port\":\"\",\"page\":f\"{i}\"}\n",
    "\n",
    "        payload = \"\"\n",
    "        headers = {\"User-Agent\": \"insomnia/8.4.5\"}\n",
    "\n",
    "        #site request\n",
    "        site = requests.request(\"GET\", url, data=payload, headers=headers, params=querystring)\n",
    "        soup = BeautifulSoup(site.content, 'html.parser')\n",
    "        trs = soup.find_all('tr')\n",
    "        for tr in trs:\n",
    "            try:\n",
    "                ip = tr.find('td',class_=re.compile('show-ip-div')).text.strip()\n",
    "                port = tr.find('a').text.strip()\n",
    "                proxylist.append(f'{ip}:{port}')\n",
    "            except:\n",
    "                pass\n",
    "    except:\n",
    "        pass\n",
    "print(len(proxylist))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#scrape free proxies from proxyscrape.com\n",
    "headers = {\"User-Agent\": \"insomnia/8.4.5\"}\n",
    "#site request\n",
    "url = 'https://proxyscrape.com/free-proxy-list'\n",
    "site = requests.get(url,headers=headers)\n",
    "soup = BeautifulSoup(site.content, 'html.parser')\n",
    "#scrape http proxy download link\n",
    "divs = soup.find_all('div', class_=re.compile('itemcard downloadcard'))\n",
    "for div in divs:\n",
    "    h2 = div.find('h2')\n",
    "    try:\n",
    "        if(h2.text.strip()=='HTTP Proxies'):\n",
    "            a = div.find('a')\n",
    "            download = a['download_url']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "#get content of download link\n",
    "try:\n",
    "    site = requests.get(download,headers=headers)\n",
    "    soup = BeautifulSoup(site.content, 'html.parser')\n",
    "    #add proxies to testlist\n",
    "    tempproxylist = soup.text.strip().split('\\r')\n",
    "    for proxy in tempproxylist:\n",
    "        proxylist.append(proxy)\n",
    "\n",
    "    print(len(proxylist))\n",
    "except:\n",
    "    pass    \n",
    "#scrape proxies from free-proxy-list.net\n",
    "url = 'https://free-proxy-list.net/'\n",
    "#site + soup\n",
    "site = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(site.content, 'html.parser')\n",
    "#scrape table\n",
    "try:\n",
    "    table = soup.find('div', class_=re.compile('table-responsive'))\n",
    "    trlabels = table.find_all('tr')\n",
    "except:\n",
    "    pass\n",
    "#scrape proxies and add to test list\n",
    "try:\n",
    "    for i in trlabels:\n",
    "            tdlabels = i.find_all('td')\n",
    "            if(tdlabels[6].text.strip()=='yes'):\n",
    "                proxylist.append(tdlabels[0].text.strip())\n",
    "except:\n",
    "    pass\n",
    "print(len(proxylist))\n",
    "#scrape proxies from hidemy.io\n",
    "url = 'https://hidemy.io/en/proxy-list/'\n",
    "#site request + soup\n",
    "site = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(site.content, 'html.parser')\n",
    "table = soup.find('div',class_=re.compile('table_block'))\n",
    "#scrape table\n",
    "trlabels = table.find_all('tr')\n",
    "#scrape proxies and add to test list\n",
    "for i in trlabels:\n",
    "    tdlabels = i.find_all('td')\n",
    "    try:\n",
    "\n",
    "        if(tdlabels[4].text.strip()=='HTTP'):\n",
    "            proxylist.append(tdlabels[0].text.strip())\n",
    "    except:\n",
    "        pass\n",
    "print(len(proxylist))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#test proxies\n",
    "workingProxies = []\n",
    "def extract(proxy):\n",
    "    works = False\n",
    "    try:\n",
    "        r = requests.get('https://www.whatismybrowser.com/detect/what-is-my-ip-address', proxies={'http':proxy, 'https':proxy}, timeout=2)\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        div = soup.find('div', class_='detected_result')\n",
    "        ip = div.find('div').text.strip()\n",
    "        print(f'{r}, {ip}')\n",
    "        works = True\n",
    "        workingProxies.append(proxy)\n",
    "        with open('working_proxies.csv', 'w', encoding='UTF8', newline='') as workingProx:\n",
    "            writer = csv.writer(workingProx)\n",
    "            for k in workingProxies:\n",
    "                writer.writerow([k])\n",
    "\n",
    "    except:\n",
    "        print(proxy)\n",
    "    return works\n",
    "\n",
    "#excecute test faster\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    executor.map(extract, list(set(proxylist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proxies: 13\n"
     ]
    }
   ],
   "source": [
    "proxylist =[]\n",
    "with open('working_proxies.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        proxylist.append(row[0])\n",
    "print(f'Proxies: {len(proxylist)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensure site is accessible\n",
    "def getProxyUserAgent():\n",
    "    for i in proxylist:\n",
    "        #test to see if website is accessible\n",
    "        userAgents = ['Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/116.0','Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/115.0','Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36','Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36','Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36','Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0','Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/116.0','Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36 Edg/115.0.1901.188','insomnia/8.4.5','Mozilla/5.0 (Linux; Android 13; Pixel 6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (Linux; Android 13; Pixel 6a) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (Linux; Android 13; Pixel 6 Pro) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (Linux; Android 13; Pixel 7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (Linux; Android 13; Pixel 7 Pro) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (Linux; Android 12; moto g pure) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (Linux; Android 12; moto g stylus 5G) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36v','Mozilla/5.0 (Linux; Android 13; SM-G998U) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (iPhone; CPU iPhone OS 12_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) FxiOS/13.2b11866 Mobile/16A366 Safari/605.1.15','Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/11.0 Mobile/15A372 Safari/604.1']\n",
    "        userAgent = userAgents[random.randint(0,len(userAgents)-1)]\n",
    "        try:\n",
    "            payload = ''\n",
    "            headers = {\n",
    "                \"cookie\": \"_tapology_mma_session=zo%252F9cU1na2qfRAvGf4E%252FBdxyMqNEgZbmqUYGnDxTYw%252BkgkuquO4qPimSMq%252FNc4fAxpLoIGwkl%252Fvw%252FhO04rqrL1PuS7516fTWktFyWhkz6YUy7MvWUVyjNQ7R26QYA8TeQruG5w%252B6RAj71bMME5MxoLjpSOs%252FyinaA6qsprmBZ2LnagrpzZ7bxaPvk7o%252FohTgZgxpo0FGWGaDdHERD%252B3Bt3C3ucykGOC7WB65EM8xB6C8gMNzGsvEu8FbvGnbMaoqzGzx%252FjRprzFrLN4mE5vdrJ1fsjoDV9cn5NEE2zI%253D--IkSvjCRiM5qMGaKi--o55iUwoIEhI6T8jM4UW6tA%253D%253D\",\n",
    "                \"User-Agent\": f'{userAgent}'\n",
    "            }\n",
    "\n",
    "            url = \"https://www.tapology.com\"\n",
    "        \n",
    "            #site request\n",
    "            response = requests.request(\"GET\", url, data=payload, headers=headers, proxies={'http': f\"http://{i}\"})\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            boutInfo = soup.find('div', class_=re.compile('right'))\n",
    "            labels = boutInfo.find_all('li')\n",
    "            proxyheader = [i,userAgent]\n",
    "            return proxyheader\n",
    "        except:\n",
    "            pass\n",
    "        #check to see if user agent was the issue\n",
    "        try:\n",
    "            userAgents.remove(userAgent)\n",
    "            userAgent = userAgents[random.randint(0,len(userAgents)-1)]\n",
    "            payload = ''\n",
    "            headers = {'User-Agent':f'{userAgent}',\n",
    "            \"cookie\": \"_tapology_mma_session=TCLB17ieOPnBLmCBTuxpX8s3uBODZMN3jL3jBbFhwPoywfbzG7gyvp%252BAzbOk4gOZ%252FOCykOUwcpEoJBwoj2rJyiMxdHWSaiLFkBYjfuUDpZ2VY6ECFn6rpTPmUBY1Zr2anIqiklY6fz9yQlBkPAhcx%252BWSzVgsc%252B%252F8UCqkb6WnM6xr8GUikb8U2UkMVYZ3Nj1dIA0vbXpDhKykqgW%252BCnlyglp8rtdlQ37m0SaYWjLDthG7Tik3idUvGlSXFAU55zAnxz6UNncMNhTbo5ltINfso54j60i7hOq0utNOz9w%253D--ChZexYwNpevIJ%252BV8--HhKStLELFfNWYOTZIAKM6Q%253D%253D\"}\n",
    "            url = \"https://www.tapology.com/fightcenter/bouts/2974-ufc-64-clay-the-carpenter-guida-vs-justin-pretty-boy-james\"\n",
    "        \n",
    "            #site request\n",
    "            response = requests.request(\"GET\", url, data=payload, headers=headers, proxies={'http': f\"http://{i}\"})\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            boutInfo = soup.find('div', class_=re.compile('right'))\n",
    "            labels = boutInfo.find_all('li')\n",
    "            proxyheader = [i,userAgent]\n",
    "            return proxyheader\n",
    "        #if user agent is not new issue, wait for next IP\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            print(\"Waiting for new IP...\")\n",
    "            ipurl = \"https://ipecho.net/plain\"\n",
    "            ipHeader = {\"User-Agent\": \"insomnia/8.4.5\"}\n",
    "            ipr = requests.request(\"GET\", url=ipurl, headers=ipHeader)\n",
    "            soup = BeautifulSoup(ipr.content, 'html.parser')\n",
    "            currentIp = soup.text.strip()\n",
    "            newIP = soup.text.strip()\n",
    "            while(currentIp == newIP):\n",
    "                ipurl = \"https://ipecho.net/plain\"\n",
    "                ipHeader = {\"User-Agent\": \"insomnia/8.4.5\"}\n",
    "                ipr = requests.request(\"GET\", url=ipurl, headers=ipHeader)\n",
    "                soup = BeautifulSoup(ipr.content, 'html.parser')\n",
    "                newIP = soup.text.strip()\n",
    "                time.sleep(15)\n",
    "            userAgents.remove(userAgent)\n",
    "            userAgent = userAgents[random.randint(0,len(userAgents)-1)]\n",
    "            payload = ''\n",
    "            headers = {'User-Agent':f'{userAgent}',\n",
    "            \"cookie\": \"_tapology_mma_session=TCLB17ieOPnBLmCBTuxpX8s3uBODZMN3jL3jBbFhwPoywfbzG7gyvp%252BAzbOk4gOZ%252FOCykOUwcpEoJBwoj2rJyiMxdHWSaiLFkBYjfuUDpZ2VY6ECFn6rpTPmUBY1Zr2anIqiklY6fz9yQlBkPAhcx%252BWSzVgsc%252B%252F8UCqkb6WnM6xr8GUikb8U2UkMVYZ3Nj1dIA0vbXpDhKykqgW%252BCnlyglp8rtdlQ37m0SaYWjLDthG7Tik3idUvGlSXFAU55zAnxz6UNncMNhTbo5ltINfso54j60i7hOq0utNOz9w%253D--ChZexYwNpevIJ%252BV8--HhKStLELFfNWYOTZIAKM6Q%253D%253D\"}\n",
    "            url = \"https://www.tapology.com/fightcenter/bouts/2974-ufc-64-clay-the-carpenter-guida-vs-justin-pretty-boy-james\"\n",
    "        \n",
    "            #site request\n",
    "            response = requests.request(\"GET\", url, data=payload, headers=headers, proxies={'http': f\"http://{i}\"})\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            boutInfo = soup.find('div', class_=re.compile('right'))\n",
    "            labels = boutInfo.find_all('li')\n",
    "            proxyheader = [i,userAgent]\n",
    "            return proxyheader\n",
    "        except:\n",
    "            print(\"Maintenence required...\")\n",
    "            input(\"Press enter to continue\")\n",
    "            userAgents.remove(userAgent)\n",
    "            userAgent = userAgents[random.randint(0,len(userAgents)-1)]\n",
    "            payload = ''\n",
    "            headers = {'User-Agent':f'{userAgent}',\n",
    "            \"cookie\": \"_tapology_mma_session=TCLB17ieOPnBLmCBTuxpX8s3uBODZMN3jL3jBbFhwPoywfbzG7gyvp%252BAzbOk4gOZ%252FOCykOUwcpEoJBwoj2rJyiMxdHWSaiLFkBYjfuUDpZ2VY6ECFn6rpTPmUBY1Zr2anIqiklY6fz9yQlBkPAhcx%252BWSzVgsc%252B%252F8UCqkb6WnM6xr8GUikb8U2UkMVYZ3Nj1dIA0vbXpDhKykqgW%252BCnlyglp8rtdlQ37m0SaYWjLDthG7Tik3idUvGlSXFAU55zAnxz6UNncMNhTbo5ltINfso54j60i7hOq0utNOz9w%253D--ChZexYwNpevIJ%252BV8--HhKStLELFfNWYOTZIAKM6Q%253D%253D\"}\n",
    "            url = \"https://www.tapology.com/fightcenter/bouts/2974-ufc-64-clay-the-carpenter-guida-vs-justin-pretty-boy-james\"\n",
    "        \n",
    "            #site request\n",
    "            response = requests.request(\"GET\", url, data=payload, headers=headers, proxies={'http': f\"http://{i}\"})\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            boutInfo = soup.find('div', class_=re.compile('right'))\n",
    "            labels = boutInfo.find_all('li')\n",
    "            proxyheader = [i,userAgent]\n",
    "            return proxyheader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#site request\n",
    "proxyheader = getProxyUserAgent()\n",
    "proxy = proxyheader[0]\n",
    "userAgent = proxyheader[1]\n",
    "querystring = {\"group\":\"ufc\",\"page\":1,\"region\":\"\",\"schedule\":\"results\",\"sport\":\"all\"}\n",
    "url = 'https://www.tapology.com/fightcenter'\n",
    "\n",
    "payload = \"\"\n",
    "headers = {\n",
    "    \"cookie\": \"_tapology_mma_session=%252BnGrxOO8u60FBkwjnPf5U9cMUlW%252B%252F76dZtFNqnrNzBiOvQybvXmEnNM%252Fu1%252BEvOx0w4zOYLO6aIlNCfl8UnsrtSYiMl2eRJHAyiBcnd2iP0A0MCwFxGErsRcK9jbT%252BixWWetj2aX%252FvsQSBYea%252Fe73CRDIdSn95lPxaMgzhrkIGIY2KzurUSeLm0hoWxHQyq01nb7UJfYbF53mL1vhZO1yAYpprixBeuhXy70HLYlQemANkpVvl7tT0Z5DTe68LgVyn8qXKLn1hOvclfkBIfaVwBd1HyV5eIRqOMicbIQ%253D--%252BzoeexZ3ARMoGYGy--kqTFUNtOGR74GqxibycT1g%253D%253D\",\n",
    "    \"User-Agent\": f\"{userAgent}\"\n",
    "}\n",
    "\n",
    "response = requests.request(\"GET\", url, data=payload, headers=headers, params=querystring, proxies={'http': f\"http://{proxy}, 'https:'https/{proxy}\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.tapology.com/fightcenter/events/116146-ufc-307\n",
      "['/fightcenter/bouts/906608-ufc-307-alex-poatan-pereira-vs-khalil-the-war-horse-rountree-jr', '/fightcenter/bouts/906607-ufc-307-rocky-raquel-pennington-vs-julianna-the-venezuelan-vixen-pena', '/fightcenter/bouts/902272-ufc-307-jose-aldo-junior-vs-mario-bautista', '/fightcenter/bouts/906605-ufc-307-roman-the-caucasian-dolidze-vs-kevin-trailblazer-holland', '/fightcenter/bouts/902376-ufc-307-kayla-harrison-vs-ketlen-fenomeno-vieira', '/fightcenter/bouts/906606-ufc-307-stephen-wonderboy-thompson-vs-joaquin-new-mansa-buckley', '/fightcenter/bouts/899333-ufc-307-marina-rodriguez-vs-iasmin-lucindo', '/fightcenter/bouts/915858-ufc-307-alexander-the-great-ape-hernandez-vs-austin-thud-hubbard', '/fightcenter/bouts/900300-ufc-307-ihor-duelist-potieria-vs-cesar-cesinha-almeida', '/fightcenter/bouts/912470-ufc-307-ovince-osp-st-preux-vs-ryan-superman-spann', '/fightcenter/bouts/902329-ufc-307-the-cookie-monster-carla-esparza-vs-the-tiny-tornado-tecia-pennington-ii', '/fightcenter/bouts/912981-ufc-307-tim-the-dirty-bird-means-vs-court-the-crusher-mcgee']\n"
     ]
    }
   ],
   "source": [
    "#get part for url of event, range defines number of events to scrape\n",
    "parts0 = []\n",
    "for i in range(0, int(numberOfEventsForUpdate)):\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    az = soup.find_all('a', class_=re.compile('border-b border-tap_3 border-dotted hover:border-solid'))\n",
    "    parts0.append(az[i]['href'])\n",
    "\n",
    "parts = []\n",
    "for part in parts0:\n",
    "    #site request\n",
    "    proxyheader = getProxyUserAgent()\n",
    "    proxy = proxyheader[0]\n",
    "    userAgent = proxyheader[1]\n",
    "    headers = {\n",
    "        \"cookie\": \"_tapology_mma_session=SalX0GSlJmX83Xr61Esyd2IpHEnEaKZ8EYxG%252FzqzxFw61SFd5cUeTP0bI6faVXCwYrNZI%252FCI%252F8k3ulCobIDgFsfjQS0mH2Cmyrjw8uRPRid1zHpuRUdB38T9zitk9HAt06s%252BJfGPJHcaekBUI5HjpDKqJqiMNg7codsNhLvZcnHeW1FlGhcz%252BGEtmlLZDuRBcl2UPylh%252B4x97JplnC7%252FxEOXfQg51XgXLvIBL4dbuO90Cwblj7LJe3XnNpqLWcefA4r6d9gVHHKBiRN10S1K9ntnmMjzz%252FLTgDxPUBI%253D--cIDn0iKYjggibUZ3--CAvjxd4oiPcvmYyMijxPGA%253D%253D\",\n",
    "        \"User-Agent\": f'{userAgent}'\n",
    "    }\n",
    "\n",
    "    url = f'https://www.tapology.com{part}'\n",
    "    print(url)\n",
    "    site = requests.get(url, headers=headers, proxies={'http': f\"http://{proxy}, 'https:'https/{proxy}\"})\n",
    "    #get url parts from all fights on the card\n",
    "    soup = BeautifulSoup(site.content, 'html.parser')\n",
    "    spans = soup.find_all('span', class_=re.compile('text-xs11 md:text-xs10 uppercase font-bold'))\n",
    "    for span in spans:\n",
    "        href = span.find('a')\n",
    "        part = href['href']\n",
    "        if part not in parts:\n",
    "            parts.append(part)\n",
    "print(parts) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.tapology.com/fightcenter/bouts/906608-ufc-307-alex-poatan-pereira-vs-khalil-the-war-horse-rountree-jr\n",
      "Scraping Alex Pereira vs. Khalil Rountree Jr....\n",
      "https://www.tapology.com/fightcenter/bouts/906607-ufc-307-rocky-raquel-pennington-vs-julianna-the-venezuelan-vixen-pena\n",
      "Scraping Raquel Pennington vs. Julianna Pea...\n",
      "https://www.tapology.com/fightcenter/bouts/902272-ufc-307-jose-aldo-junior-vs-mario-bautista\n",
      "Scraping Jos Aldo vs. Mario Bautista...\n",
      "https://www.tapology.com/fightcenter/bouts/906605-ufc-307-roman-the-caucasian-dolidze-vs-kevin-trailblazer-holland\n",
      "Scraping Roman Dolidze vs. Kevin Holland...\n",
      "https://www.tapology.com/fightcenter/bouts/902376-ufc-307-kayla-harrison-vs-ketlen-fenomeno-vieira\n",
      "Scraping Kayla Harrison vs. Ketlen Vieira...\n",
      "https://www.tapology.com/fightcenter/bouts/906606-ufc-307-stephen-wonderboy-thompson-vs-joaquin-new-mansa-buckley\n",
      "Scraping Stephen Thompson vs. Joaquin Buckley...\n",
      "https://www.tapology.com/fightcenter/bouts/899333-ufc-307-marina-rodriguez-vs-iasmin-lucindo\n",
      "Scraping Marina Rodriguez vs. Iasmin Lucindo...\n",
      "https://www.tapology.com/fightcenter/bouts/915858-ufc-307-alexander-the-great-ape-hernandez-vs-austin-thud-hubbard\n",
      "Scraping Alexander Hernandez vs. Austin Hubbard...\n",
      "https://www.tapology.com/fightcenter/bouts/900300-ufc-307-ihor-duelist-potieria-vs-cesar-cesinha-almeida\n",
      "Scraping Ihor Potieria vs. Csar Almeida...\n",
      "https://www.tapology.com/fightcenter/bouts/912470-ufc-307-ovince-osp-st-preux-vs-ryan-superman-spann\n",
      "Scraping Ovince St. Preux vs. Ryan Spann...\n",
      "https://www.tapology.com/fightcenter/bouts/902329-ufc-307-the-cookie-monster-carla-esparza-vs-the-tiny-tornado-tecia-pennington-ii\n",
      "Scraping Carla Esparza vs. Tecia Pennington II...\n",
      "https://www.tapology.com/fightcenter/bouts/912981-ufc-307-tim-the-dirty-bird-means-vs-court-the-crusher-mcgee\n",
      "Scraping Tim Means vs. Court McGee...\n"
     ]
    }
   ],
   "source": [
    "fightStats = []\n",
    "\n",
    "for i in parts:\n",
    "    proxyheader = getProxyUserAgent()\n",
    "    proxy = proxyheader[0]\n",
    "    userAgent = proxyheader[1]\n",
    "    payload = \"\"\n",
    "    headers = {\n",
    "        \"cookie\": \"_tapology_mma_session=6FGp%252FJUSTWYMfoxo8TfW%252BIXzLpUq7U9PMAJo5rHJA0IW5nmUvBfyvSfM1xK04kt35b9X7qEKQCxCoWu2ufxYHMbwDH88yla0%252FpzMP71n6pbfW%252FroMtWAh2n5sk9oxYFnmpfxohRaQMysmv%252B9f5fj0Omemblq8KM9NEDFiR5UPFyFXXYiM0Ee%252FWLYZ5JqObzpWnulDsrgvVtdtWFthH9vY6xz9HAvSb4KOm1HA6TvXXxYOO2Vuk6MeJwKYdwj3yqz8dV%252FHRgPknI5PsGEx3z3mxBNOJaFkRBT6iB%252B5Zo%253D--pNnhVuV4ORLaBVOE--yUSbtIv6C91epo3hOY0i5w%253D%253D\",\n",
    "        \"User-Agent\": f'{userAgent}'\n",
    "    }\n",
    "\n",
    "    \n",
    "    url = f\"https://www.tapology.com{i}\"\n",
    "    try:\n",
    "            \n",
    "        #site request\n",
    "        response = requests.request(\"GET\", url, data=payload, headers=headers, proxies={'http': f\"http://{proxy}, 'https:'https/{proxy}\"})\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        #scrape event details\n",
    "        lilabels = soup.find_all('li', class_=re.compile('even:bg-tap_f2 leading-normal py-1.5 md:py-2 px-1 md:text-xs'))\n",
    "    except:\n",
    "        proxyheader = getProxyUserAgent()\n",
    "        proxy = proxyheader[0]\n",
    "        userAgent = proxyheader[1]\n",
    "        payload = \"\"\n",
    "        headers = {\n",
    "            \"cookie\": \"_tapology_mma_session=6FGp%252FJUSTWYMfoxo8TfW%252BIXzLpUq7U9PMAJo5rHJA0IW5nmUvBfyvSfM1xK04kt35b9X7qEKQCxCoWu2ufxYHMbwDH88yla0%252FpzMP71n6pbfW%252FroMtWAh2n5sk9oxYFnmpfxohRaQMysmv%252B9f5fj0Omemblq8KM9NEDFiR5UPFyFXXYiM0Ee%252FWLYZ5JqObzpWnulDsrgvVtdtWFthH9vY6xz9HAvSb4KOm1HA6TvXXxYOO2Vuk6MeJwKYdwj3yqz8dV%252FHRgPknI5PsGEx3z3mxBNOJaFkRBT6iB%252B5Zo%253D--pNnhVuV4ORLaBVOE--yUSbtIv6C91epo3hOY0i5w%253D%253D\",\n",
    "            \"User-Agent\": f'{userAgent}'\n",
    "        }\n",
    "        response = requests.request(\"GET\", url, data=payload, headers=headers, proxies={'http': f\"http://{proxy}, 'https:'https/{proxy}\"})\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        #scrape event details\n",
    "        lilabels = soup.find_all('li', class_=re.compile('even:bg-tap_f2 leading-normal py-1.5 md:py-2 px-1 md:text-xs'))\n",
    "\n",
    "        \n",
    "    print(url)\n",
    "    #initialize attributes\n",
    "    event = None\n",
    "    date = None\n",
    "    venue = None\n",
    "    title_fight = 'no'\n",
    "    billing = None\n",
    "    winner = None\n",
    "    loser = None\n",
    "    winner_wins = None\n",
    "    loser_wins = None\n",
    "    winner_losses = None\n",
    "    loser_losses = None\n",
    "    winner_draws = None\n",
    "    loser_draws = None\n",
    "    winner_age = None\n",
    "    loser_age = None\n",
    "    belt_status = None\n",
    "    winner_nationality = None\n",
    "    loser_nationality = None\n",
    "    winner_fan = None\n",
    "    loser_fan = None\n",
    "    fight_name = None\n",
    "\n",
    "\n",
    "    for num in range(0, len(lilabels)+1):\n",
    "        #scrape + clean event name\n",
    "        try:\n",
    "            if(lilabels[num].find('span', class_=re.compile('font-bold text-neutral-900')).text.strip() == 'Event:'):\n",
    "                event = lilabels[num].find('a', class_=re.compile('link-primary-red')).text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        #scrape + clean date\n",
    "        try:\n",
    "            if(lilabels[num].find('span', class_=re.compile('font-bold text-neutral-900')).text.strip() == 'Date:'):\n",
    "                nCleanDate = lilabels[num].find('span', class_=re.compile('text-neutral-700')).text.strip()\n",
    "                dateList = nCleanDate.split(' ')\n",
    "                date = dateList[1]\n",
    "        except:\n",
    "            pass\n",
    "        #scrape + clean venue\n",
    "        try:\n",
    "            if(lilabels[num].find('span', class_=re.compile('font-bold text-neutral-900')).text.strip() == 'Venue:'):\n",
    "                venue = lilabels[num].find('span', class_=re.compile('text-neutral-700')).text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        #scrape whether it is a title fight\n",
    "        try:\n",
    "            if(lilabels[num].find('span', class_=re.compile('font-bold text-neutral-90')).text.strip() == 'Title on Line:'):\n",
    "                title_fight = 'yes'\n",
    "        except:\n",
    "            pass\n",
    "        #scrape + clean billing\n",
    "        try:\n",
    "            if(lilabels[num].find('span', class_=re.compile('font-bold text-neutral-900')).text.strip() == 'Bout Billing:'):\n",
    "                billing = lilabels[num].find('span', class_=re.compile('text-neutral-700')).text.strip()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    #scrape +clean winner\n",
    "    try:\n",
    "        winnerCheck = soup.find('span', class_=re.compile('text-lg leading-tight text-tap_3 font-bold')).text.strip()\n",
    "        if('defeats' in winnerCheck):\n",
    "            fighters = soup.find_all('a', class_=re.compile('link-primary-red hidden md:inline'))\n",
    "            winner = fighters[0].text.strip()\n",
    "            loser = fighters[1].text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #scrape + parse table\n",
    "    table = soup.find('table', class_=re.compile('md:mt-5 w-full text-center'))\n",
    "    tdLabels = table.find_all('td')\n",
    "\n",
    "    #scrape + clean winner record\n",
    "    try:\n",
    "        winnerRecordTempList = tdLabels[0].text.strip().split('\\n')\n",
    "        winnerRecord = winnerRecordTempList[0]\n",
    "        winnerRecordList = winnerRecord.split('-')\n",
    "        winner_wins = winnerRecordList[0]\n",
    "        winner_losses = winnerRecordList[1]\n",
    "        winner_draws = winnerRecordList[2]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #scrape + clean loser record\n",
    "    try:\n",
    "        loserRecordTempList = tdLabels[5].text.strip().split('\\n')\n",
    "        loserRecord = loserRecordTempList[0]\n",
    "        loserRecordList = loserRecord.split('-')\n",
    "        loser_wins = loserRecordList[0]\n",
    "        loser_losses = loserRecordList[1]\n",
    "        loser_draws = loserRecordList[2]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #scrape and parse table\n",
    "    trLabels = table.find_all('tr')\n",
    "    for tr in trLabels:\n",
    "        #scrape + clean winner and loser age\n",
    "        try:\n",
    "            if('Age at Fight' in tr.text.strip()):\n",
    "                td = tr.find_all('td')\n",
    "                winner_ageTemp = td[0].text.strip().split(' ')\n",
    "                winner_age = winner_ageTemp[0]\n",
    "                loser_ageTemp = td[5].text.strip().split(' ')\n",
    "                loser_age = loser_ageTemp[0]\n",
    "        except:\n",
    "            pass\n",
    "        #scrape + clean nationality\n",
    "        try:\n",
    "            if('Nation' in tr.text.strip()):\n",
    "                td = tr.find_all('td')\n",
    "                winner_nationTemp = td[0].text.strip().split('\\n')\n",
    "                winner_nationality = winner_nationTemp[0]\n",
    "                loser_nationTemp = td[4].text.strip().split('\\n')\n",
    "                loser_nationality = loser_nationTemp[0]\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "\n",
    "    #scrape + clean fight name\n",
    "    try:\n",
    "        fight_name = soup.find('h2', class_=re.compile('text-2xl md:text-2xl text-center font-bold text-tap_3')).text.strip()\n",
    "    except:\n",
    "        fight_name = soup.find('h2', class_=re.compile('text-xl md:text-2xl text-center font-bold text-tap_3')).text.strip()\n",
    "\n",
    "    print(f'Scraping {fight_name}...')\n",
    "    fightStats.append([fight_name,winner, loser, event,date,venue,title_fight,billing,winner_wins ,loser_wins ,winner_losses ,loser_losses ,winner_draws,loser_draws,winner_age ,loser_age ,belt_status ,winner_nationality ,loser_nationality ,winner_fan ,loser_fan])\n",
    "\n",
    "     \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = ['fight','winner', 'loser', 'event','date','venue','title_fight','billing','winner_wins' ,'loser_wins' ,'winner_losses' ,'loser_losses' ,'winner_draws','loser_draws','winner_age' ,'loser_age' ,'belt_status' ,'winner_nationality' ,'loser_nationality' ,'winner_fan ','loser_fan']\n",
    "\n",
    "\n",
    "with open('updateTapology.csv', 'w', encoding='UTF8', newline='') as updateTapology:\n",
    "    writer = csv.writer(updateTapology)\n",
    "    writer.writerow(head)\n",
    "    writer.writerows(fightStats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#define url and header\n",
    "url = 'http://ufcstats.com/statistics/events/completed?page=all'\n",
    "headers = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246\"}\n",
    "\n",
    "#site request\n",
    "site = requests.get(url, headers=headers)\n",
    "print(site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://ufcstats.com/event-details/eee8efec7b951d84']\n"
     ]
    }
   ],
   "source": [
    "#soup and get hrefs\n",
    "soup = BeautifulSoup(site.content, 'html.parser')\n",
    "hrefs = soup.find_all('a', class_=re.compile('b-link b-link_style_black'))\n",
    "\n",
    "#get link for most recent event\n",
    "link = hrefs[0]['href']\n",
    "\n",
    "#get part for url of event, range defines number of events to scrape\n",
    "links = []\n",
    "for i in range(0, int(numberOfEventsForUpdate)):\n",
    "    link = hrefs[i]['href']\n",
    "    links.append(link)\n",
    "\n",
    "print(links)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_links = []\n",
    "for link in links:\n",
    "    #site request\n",
    "    site = requests.get(link, headers=headers)\n",
    "    soup = BeautifulSoup(site.content, 'html.parser')\n",
    "\n",
    "    #scrape stat links\n",
    "    stat_linksTemp = soup.find_all('a', class_=['b-flag b-flag_style_green', 'b-flag b-flag_style_bordered'])\n",
    "    for statLink in stat_linksTemp:\n",
    "        stat_links.append(statLink)\n",
    "\n",
    "#clean stat links\n",
    "statLinks = []\n",
    "for link in stat_links:\n",
    "    href = link['href']\n",
    "    if href:\n",
    "        statLinks.append(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fights found: 12\n"
     ]
    }
   ],
   "source": [
    "#remove dups\n",
    "statLinks = list(dict.fromkeys(statLinks)) \n",
    "print(f'Fights found: {len(statLinks)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sraping Alex Pereira vs Khalil Rountree Jr....0%\n",
      "http://ufcstats.com/fight-details/8c5e06c71f392f33\n",
      "Sraping Raquel Pennington vs Julianna Pena...8%\n",
      "http://ufcstats.com/fight-details/1d68bb733de24b06\n",
      "Sraping Jose Aldo vs Mario Bautista...17%\n",
      "http://ufcstats.com/fight-details/3d7d82fff71e395a\n",
      "Sraping Roman Dolidze vs Kevin Holland...25%\n",
      "http://ufcstats.com/fight-details/5931cd9cf5da5f75\n",
      "Sraping Ketlen Vieira vs Kayla Harrison...33%\n",
      "http://ufcstats.com/fight-details/9ea124a13d071186\n",
      "Sraping Stephen Thompson vs Joaquin Buckley...42%\n",
      "http://ufcstats.com/fight-details/69bca5091b2a31f6\n",
      "Sraping Marina Rodriguez vs Iasmin Lucindo...50%\n",
      "http://ufcstats.com/fight-details/eb73b63bbd7b88a7\n",
      "Sraping Austin Hubbard vs Alexander Hernandez...58%\n",
      "http://ufcstats.com/fight-details/e8aad69aace1d31f\n",
      "Sraping Cesar Almeida vs Ihor Potieria...67%\n",
      "http://ufcstats.com/fight-details/ed5b6681ab4e83e5\n",
      "Sraping Ryan Spann vs Ovince Saint Preux...75%\n",
      "http://ufcstats.com/fight-details/58dec0a39cdefa3f\n",
      "Sraping Carla Esparza vs Tecia Pennington...83%\n",
      "http://ufcstats.com/fight-details/58e5fc1914c4e641\n",
      "Sraping Court McGee vs Tim Means...92%\n",
      "http://ufcstats.com/fight-details/84b3577229880760\n"
     ]
    }
   ],
   "source": [
    "#scrape stats\n",
    "fightStats = []\n",
    "count = 0\n",
    "for i in statLinks:\n",
    "\n",
    "    #initialize attributes\n",
    "    redCorner = None\n",
    "    blueCorner = None\n",
    "    winner = None\n",
    "    event = None\n",
    "    referee = None\n",
    "    method_of_victory = None\n",
    "    red_Knockdowns = None\n",
    "    blue_Knockdowns = None\n",
    "    red_sig_str = None\n",
    "    blue_sig_str = None\n",
    "    red_sig_str_percentage = None\n",
    "    blue_sig_str_percentage = None\n",
    "    red_total_strikes = None\n",
    "    blue_total_strikes = None\n",
    "    red_takedowns = None\n",
    "    blue_takedowns = None\n",
    "    red_takedown_percentage = None\n",
    "    blue_takedown_percentage = None\n",
    "    red_subs_attempted = None\n",
    "    blue_subs_attempted = None\n",
    "    round = None\n",
    "    time = None\n",
    "    redCorner_height = None\n",
    "    blueCorner_height = None\n",
    "    redCorner_reach = None\n",
    "    blueCorner_reach = None\n",
    "    redCorner_stance = None\n",
    "    blueCorner_stance = None\n",
    "\n",
    "    #site request\n",
    "    try:\n",
    "        site = requests.get(i, headers=headers)\n",
    "        soup = BeautifulSoup(site.content, 'html.parser')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #scrape corners\n",
    "    try:\n",
    "        red_corner = soup.find_all('i', class_=re.compile('b-fight-details__charts-name b-fight-details__charts-name_pos_left js-chart-name'))\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        blue_corner = soup.find_all('i', class_=re.compile('b-fight-details__charts-name b-fight-details__charts-name_pos_right js-chart-name'))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #clean corners\n",
    "    try:\n",
    "        redCorner = red_corner[0].text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        blueCorner = blue_corner[0].text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #scrape + clean winner\n",
    "    try:\n",
    "        divs = soup.find_all('div', class_=re.compile('b-fight-details__person'))\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        if(divs[1].find('i', class_='b-fight-details__person-status b-fight-details__person-status_style_green') != None):\n",
    "            winner = divs[1].find('a', class_=re.compile('b-link b-fight-details__person-link')).text.strip()\n",
    "        if(divs[3].find('i', class_='b-fight-details__person-status b-fight-details__person-status_style_green') != None):\n",
    "            winner = divs[3].find('a', class_=re.compile('b-link b-fight-details__person-link')).text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #scrape +clean event\n",
    "    try:\n",
    "        event = soup.find('a', class_=re.compile('b-link')).text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #scrape + clean method of vitory\n",
    "    try:\n",
    "        method_of_victory = soup.find('i', style='font-style: normal').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #scrape + clean referee\n",
    "    try:\n",
    "        referee = soup.find('span').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #scrape + clean round and time\n",
    "    iz = soup.find_all('i', class_=re.compile('b-fight-details__text-item'))\n",
    "    for j in range(len(iz)):\n",
    "        details = iz[j].find('i', class_=re.compile('b-fight-details__label'))\n",
    "        try:\n",
    "            test = details.text.strip()\n",
    "            if \"Round:\" in test:\n",
    "                round = iz[j].text.strip().replace(' ', '').replace('R', '').replace('o', '').replace('u', '').replace('n', '').replace('d', '').replace(':', '').replace(\"\\n\", '')\n",
    "            if \"Time:\" in test:\n",
    "                unFormattedTime = iz[j].text.strip().replace(' ', '').replace('T', '').replace('i', '').replace('m', '').replace('e', '').replace(':', '').replace(\"\\n\", '')\n",
    "                time = unFormattedTime[0] + \":\" + unFormattedTime[1:]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    #scrape red blue stats\n",
    "    try:\n",
    "        ps = soup.find_all('p', class_='b-fight-details__table-text')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        #scrape + clean knockdowns\n",
    "        red_Knockdowns = ps[2].text.strip()\n",
    "        blue_Knockdowns = ps[3].text.strip()\n",
    "\n",
    "        #scrape + clean sig strikes\n",
    "        red_sig_str = ps[4].text.strip()\n",
    "        blue_sig_str = ps[5].text.strip()\n",
    "\n",
    "        #scrape + clean sig strike percentage\n",
    "        red_sig_str_percentage = ps[6].text.strip()\n",
    "        blue_sig_str_percentage = ps[7].text.strip()\n",
    "\n",
    "        #scrape + clean total strikes\n",
    "        red_total_strikes = ps[8].text.strip()\n",
    "        blue_total_strikes = ps[9].text.strip()\n",
    "\n",
    "        #scrape + clean takedowns\n",
    "        red_takedowns = ps[10].text.strip()\n",
    "        blue_takedowns = ps[11].text.strip()\n",
    "\n",
    "        #scrape + clean takedown percentage\n",
    "        red_takedown_percentage = ps[12].text.strip()\n",
    "        blue_takedown_percentage = ps[13].text.strip()\n",
    "\n",
    "        #scrape + clean\n",
    "        red_subs_attempted = ps[14].text.strip()\n",
    "        blue_subs_attempted = ps[15].text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        #scrape redCorner/blueCorner links \n",
    "        indstatLinks = soup.find_all('a', class_=re.compile('b-link b-link_style_black'))\n",
    "        redCornerLink = indstatLinks[0]\n",
    "        blueCornerLink = indstatLinks[1]\n",
    "        \n",
    "        #clean for href\n",
    "        redCornerLink = redCornerLink['href']\n",
    "        blueCornerLink = blueCornerLink['href']\n",
    "\n",
    "        response = requests.get(redCornerLink, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        #clean soup for rest of stats\n",
    "        i_tags = soup.find_all('i')\n",
    "        for itags in i_tags:\n",
    "            itags.decompose()\n",
    "        tempRest = soup.find_all('li', class_=re.compile('b-list__box-list-item b-list__box-list-item_type_block'))\n",
    "        redCorner_height = tempRest[0].text.strip()\n",
    "        redCorner_reach = tempRest[2].text.strip()\n",
    "        redCorner_stance = tempRest[3].text.strip()\n",
    "\n",
    "        #height, reach, stance blue\n",
    "        response = requests.get(blueCornerLink, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        #clean soup for rest of stats\n",
    "        i_tags = soup.find_all('i')\n",
    "        for itags in i_tags:\n",
    "            itags.decompose()\n",
    "        tempRest = soup.find_all('li', class_=re.compile('b-list__box-list-item b-list__box-list-item_type_block'))\n",
    "        blueCorner_height = tempRest[0].text.strip()\n",
    "        blueCorner_reach = tempRest[2].text.strip()\n",
    "        blueCorner_stance = tempRest[3].text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    fightStats.append([redCorner, blueCorner, winner, event, referee, method_of_victory, red_Knockdowns, blue_Knockdowns, red_sig_str, blue_sig_str, red_sig_str_percentage, blue_sig_str_percentage, red_total_strikes, blue_total_strikes, red_takedowns, blue_takedowns, red_takedown_percentage, blue_takedown_percentage, red_subs_attempted, blue_subs_attempted, round, time, redCorner_height, blueCorner_height, redCorner_reach, blueCorner_reach, redCorner_stance, blueCorner_stance])\n",
    "\n",
    "\n",
    "    print(f'Sraping {redCorner} vs {blueCorner}...{f\"{count/len(statLinks):.0%}\"}')\n",
    "    print(i)\n",
    "    count+=1  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create csv file\n",
    "head = ['redCorner', 'blueCorner', 'winner', 'event', 'referee', 'method_of_victory', 'red_Knockdowns', 'blue_Knockdowns', 'red_sig_str', 'blue_sig_str', 'red_sig_str_percentage', 'blue_sig_str_percentage', 'red_total_strikes', 'blue_total_strikes', 'red_takedowns', 'blue_takedowns', 'red_takedown_percentage', 'blue_takedown_percentage', 'red_subs_attempted', 'blue_subs_attempted', 'round', 'time', 'redCorner_height', 'blueCorner_height', 'redCorner_reach', 'blueCorner_reach', 'redCorner_stance', 'blueCorner_stance']\n",
    "\n",
    "with open('updateUfc_history_fight_statistics.csv', 'w', encoding='UTF8', newline='') as updateHistory:\n",
    "    writer = csv.writer(updateHistory)\n",
    "    writer.writerow(head)\n",
    "    writer.writerows(fightStats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fight</th>\n",
       "      <th>winner</th>\n",
       "      <th>loser</th>\n",
       "      <th>event</th>\n",
       "      <th>date</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>billing</th>\n",
       "      <th>winner_wins</th>\n",
       "      <th>loser_wins</th>\n",
       "      <th>...</th>\n",
       "      <th>loser_losses</th>\n",
       "      <th>winner_draws</th>\n",
       "      <th>loser_draws</th>\n",
       "      <th>winner_age</th>\n",
       "      <th>loser_age</th>\n",
       "      <th>belt_status</th>\n",
       "      <th>winner_nationality</th>\n",
       "      <th>loser_nationality</th>\n",
       "      <th>winner_fan</th>\n",
       "      <th>loser_fan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex Pereira vs. Khalil Rountree Jr.</td>\n",
       "      <td>Alex Pereira</td>\n",
       "      <td>Khalil Rountree Jr.</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>yes</td>\n",
       "      <td>Main Event</td>\n",
       "      <td>Pereira</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raquel Pennington vs. Julianna Pea</td>\n",
       "      <td>Julianna Pea</td>\n",
       "      <td>Raquel Pennington</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>yes</td>\n",
       "      <td>Co-Main Event</td>\n",
       "      <td>Pea</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jos Aldo vs. Mario Bautista</td>\n",
       "      <td>Mario Bautista</td>\n",
       "      <td>Jos Aldo</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>Main Card</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roman Dolidze vs. Kevin Holland</td>\n",
       "      <td>Roman Dolidze</td>\n",
       "      <td>Kevin Holland</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>Main Card</td>\n",
       "      <td>Dolidze</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kayla Harrison vs. Ketlen Vieira</td>\n",
       "      <td>Kayla Harrison</td>\n",
       "      <td>Ketlen Vieira</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>Main Card</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  fight          winner                loser  \\\n",
       "0  Alex Pereira vs. Khalil Rountree Jr.    Alex Pereira  Khalil Rountree Jr.   \n",
       "1   Raquel Pennington vs. Julianna Pea   Julianna Pea    Raquel Pennington   \n",
       "2          Jos Aldo vs. Mario Bautista  Mario Bautista            Jos Aldo   \n",
       "3       Roman Dolidze vs. Kevin Holland   Roman Dolidze        Kevin Holland   \n",
       "4      Kayla Harrison vs. Ketlen Vieira  Kayla Harrison        Ketlen Vieira   \n",
       "\n",
       "                           event        date         venue title_fight  \\\n",
       "0  UFC 307: Pereira vs. Rountree  10.05.2024  Delta Center         yes   \n",
       "1  UFC 307: Pereira vs. Rountree  10.05.2024  Delta Center         yes   \n",
       "2  UFC 307: Pereira vs. Rountree  10.05.2024  Delta Center          no   \n",
       "3  UFC 307: Pereira vs. Rountree  10.05.2024  Delta Center          no   \n",
       "4  UFC 307: Pereira vs. Rountree  10.05.2024  Delta Center          no   \n",
       "\n",
       "         billing winner_wins  loser_wins  ...  loser_losses  winner_draws  \\\n",
       "0     Main Event     Pereira          11  ...             2           NaN   \n",
       "1  Co-Main Event        Pea          10  ...             5           NaN   \n",
       "2      Main Card    Bautista          14  ...             2           NaN   \n",
       "3      Main Card     Dolidze          13  ...             3           NaN   \n",
       "4      Main Card    Harrison          17  ...             1           NaN   \n",
       "\n",
       "   loser_draws  winner_age  loser_age  belt_status  winner_nationality  \\\n",
       "0            0          37         34          NaN              Brazil   \n",
       "1            0          35         36          NaN       United States   \n",
       "2            0          31         38          NaN       United States   \n",
       "3            0          36         31          NaN             Georgia   \n",
       "4            0          34         33          NaN       United States   \n",
       "\n",
       "  loser_nationality winner_fan   loser_fan  \n",
       "0     United States         NaN        NaN  \n",
       "1     United States         NaN        NaN  \n",
       "2            Brazil         NaN        NaN  \n",
       "3     United States         NaN        NaN  \n",
       "4            Brazil         NaN        NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframes\n",
    "df = pd.read_csv('updateTapology.csv')\n",
    "df2 = pd.read_csv('updateUfc_history_fight_statistics.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#match event names\n",
    "for (index, row), (index2, row2) in zip(df.iterrows(), df2.iterrows()):\n",
    "        if(row['event'] != row2['event']):\n",
    "            df.at[index, 'event'] = row2['event']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fight</th>\n",
       "      <th>winner</th>\n",
       "      <th>loser</th>\n",
       "      <th>event</th>\n",
       "      <th>date</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>billing</th>\n",
       "      <th>winner_wins</th>\n",
       "      <th>loser_wins</th>\n",
       "      <th>...</th>\n",
       "      <th>loser_losses</th>\n",
       "      <th>winner_draws</th>\n",
       "      <th>loser_draws</th>\n",
       "      <th>winner_age</th>\n",
       "      <th>loser_age</th>\n",
       "      <th>belt_status</th>\n",
       "      <th>winner_nationality</th>\n",
       "      <th>loser_nationality</th>\n",
       "      <th>winner_fan</th>\n",
       "      <th>loser_fan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex Pereira vs. Khalil Rountree Jr.</td>\n",
       "      <td>Alex Pereira</td>\n",
       "      <td>Khalil Rountree Jr.</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>yes</td>\n",
       "      <td>Main Event</td>\n",
       "      <td>Pereira</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raquel Pennington vs. Julianna Pea</td>\n",
       "      <td>Julianna Pea</td>\n",
       "      <td>Raquel Pennington</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>yes</td>\n",
       "      <td>Co-Main Event</td>\n",
       "      <td>Pea</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jos Aldo vs. Mario Bautista</td>\n",
       "      <td>Mario Bautista</td>\n",
       "      <td>Jos Aldo</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>Main Card</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roman Dolidze vs. Kevin Holland</td>\n",
       "      <td>Roman Dolidze</td>\n",
       "      <td>Kevin Holland</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>Main Card</td>\n",
       "      <td>Dolidze</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kayla Harrison vs. Ketlen Vieira</td>\n",
       "      <td>Kayla Harrison</td>\n",
       "      <td>Ketlen Vieira</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>Main Card</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  fight          winner                loser  \\\n",
       "0  Alex Pereira vs. Khalil Rountree Jr.    Alex Pereira  Khalil Rountree Jr.   \n",
       "1   Raquel Pennington vs. Julianna Pea   Julianna Pea    Raquel Pennington   \n",
       "2          Jos Aldo vs. Mario Bautista  Mario Bautista            Jos Aldo   \n",
       "3       Roman Dolidze vs. Kevin Holland   Roman Dolidze        Kevin Holland   \n",
       "4      Kayla Harrison vs. Ketlen Vieira  Kayla Harrison        Ketlen Vieira   \n",
       "\n",
       "                               event        date         venue title_fight  \\\n",
       "0  UFC 307: Pereira vs. Rountree Jr.  10.05.2024  Delta Center         yes   \n",
       "1  UFC 307: Pereira vs. Rountree Jr.  10.05.2024  Delta Center         yes   \n",
       "2  UFC 307: Pereira vs. Rountree Jr.  10.05.2024  Delta Center          no   \n",
       "3  UFC 307: Pereira vs. Rountree Jr.  10.05.2024  Delta Center          no   \n",
       "4  UFC 307: Pereira vs. Rountree Jr.  10.05.2024  Delta Center          no   \n",
       "\n",
       "         billing winner_wins  loser_wins  ...  loser_losses  winner_draws  \\\n",
       "0     Main Event     Pereira          11  ...             2           NaN   \n",
       "1  Co-Main Event        Pea          10  ...             5           NaN   \n",
       "2      Main Card    Bautista          14  ...             2           NaN   \n",
       "3      Main Card     Dolidze          13  ...             3           NaN   \n",
       "4      Main Card    Harrison          17  ...             1           NaN   \n",
       "\n",
       "   loser_draws  winner_age  loser_age  belt_status  winner_nationality  \\\n",
       "0            0          37         34          NaN              Brazil   \n",
       "1            0          35         36          NaN       United States   \n",
       "2            0          31         38          NaN       United States   \n",
       "3            0          36         31          NaN             Georgia   \n",
       "4            0          34         33          NaN       United States   \n",
       "\n",
       "  loser_nationality winner_fan   loser_fan  \n",
       "0     United States         NaN        NaN  \n",
       "1     United States         NaN        NaN  \n",
       "2            Brazil         NaN        NaN  \n",
       "3     United States         NaN        NaN  \n",
       "4            Brazil         NaN        NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find special characters in df\n",
    "winners = (df['winner'].values)\n",
    "losers = (df['loser'].values)\n",
    "fights = (df['fight'].values)\n",
    "chars2rep = []\n",
    "for winner in winners:\n",
    "    if(isinstance(winner, str)):\n",
    "        for char in winner:\n",
    "            if char.lower() not in ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "            if char.upper() not in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', \"Q\", 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "for loser in losers:\n",
    "    if(isinstance(loser, str)):\n",
    "        for char in loser:\n",
    "            if char.lower() not in ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "            if char.upper() not in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', \"Q\", 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "for fight in fights:\n",
    "    if(isinstance(fight, str)):\n",
    "        for char in fight:\n",
    "            if char.lower() not in ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "            if char.upper() not in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', \"Q\", 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "chars2rep = list(set(chars2rep))\n",
    "for char in chars2rep:\n",
    "    print(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean winners, losers, fights\n",
    "for i in range(5):\n",
    "    for index, row in df.iterrows():\n",
    "        winner = row['winner']\n",
    "        loser = row['loser']\n",
    "        fight = row['fight']\n",
    "        if(isinstance(winner, str)):\n",
    "            if('' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('', 'c')\n",
    "            if('' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('', 'e')\n",
    "            if('' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('', 'A')\n",
    "            if('' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('', 'L')\n",
    "            if('' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('', 'c')\n",
    "            if('' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('', 'a')\n",
    "            if('' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('', 'a')\n",
    "            if('' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('', 'a')\n",
    "            if('' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('', 'u')\n",
    "            if('' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('', 'e')\n",
    "            if('' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('', 'a')\n",
    "            if('.' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('.', '')\n",
    "            if('' in winner): \n",
    "                df.loc[index, 'winner'] = winner.replace('', 'e')\n",
    "            if('' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('', 'o')\n",
    "            if(\"'\" in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace(\"'\", '')\n",
    "            if('' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('', 'o')\n",
    "            if('' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('', 'i')\n",
    "            if('' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('', 'r')\n",
    "            if('-' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('-', ' ')\n",
    "            if('' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('', 'a')\n",
    "            if('' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('', 'L')\n",
    "            if('' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('', 't')\n",
    "            if('' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('', 'l')\n",
    "            if('' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('', 'o')\n",
    "            if('' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('', 's')\n",
    "            if('' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('', 'o')\n",
    "            if('' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('', 'c')\n",
    "            if('' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('', 'n')\n",
    "            if('' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('', 'n')\n",
    "            if('' in winner):\n",
    "                df.loc[index, 'winner'] = winner.replace('', 'z')\n",
    "        if(isinstance(loser, str)):\n",
    "            if('' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('', 'c')\n",
    "            if('' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('', 'e')\n",
    "            if('' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('', 'A')\n",
    "            if('' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('', 'L')\n",
    "            if('' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('', 'c')\n",
    "            if('' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('', 'a')\n",
    "            if('' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('', 'a')\n",
    "            if('' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('', 'a')\n",
    "            if('' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('', 'u')\n",
    "            if('' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('', 'e')\n",
    "            if('' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('', 'a')\n",
    "            if('.' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('.', '')\n",
    "            if('' in loser): \n",
    "                df.loc[index, 'loser'] = loser.replace('', 'e')\n",
    "            if('' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('', 'o')\n",
    "            if(\"'\" in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace(\"'\", '')\n",
    "            if('' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('', 'o')\n",
    "            if('' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('', 'i')\n",
    "            if('' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('', 'r')\n",
    "            if('-' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('-', ' ')\n",
    "            if('' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('', 'a')\n",
    "            if('' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('', 'L')\n",
    "            if('' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('', 't')\n",
    "            if('' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('', 'l')\n",
    "            if('' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('', 'o')\n",
    "            if('' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('', 's')\n",
    "            if('' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('', 'o')\n",
    "            if('' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('', 'c')\n",
    "            if('' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('', 'n')\n",
    "            if('' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('', 'n')\n",
    "            if('' in loser):\n",
    "                df.loc[index, 'loser'] = loser.replace('', 'z')\n",
    "        if(isinstance(fight, str)):\n",
    "            if('' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('', 'c')\n",
    "            if('' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('', 'e')\n",
    "            if('' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('', 'A')\n",
    "            if('' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('', 'L')\n",
    "            if('' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('', 'c')\n",
    "            if('' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('', 'a')\n",
    "            if('' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('', 'a')\n",
    "            if('' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('', 'a')\n",
    "            if('' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('', 'u')\n",
    "            if('' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('', 'e')\n",
    "            if('' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('', 'a')\n",
    "            if('.' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('.', '')\n",
    "            if('' in fight): \n",
    "                df.loc[index, 'fight'] = fight.replace('', 'e')\n",
    "            if('' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('', 'o')\n",
    "            if(\"'\" in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace(\"'\", '')\n",
    "            if('' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('', 'o')\n",
    "            if('' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('', 'i')\n",
    "            if('' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('', 'r')\n",
    "            if('-' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('-', ' ')\n",
    "            if('' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('', 'a')\n",
    "            if('' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('', 'L')\n",
    "            if('' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('', 't')\n",
    "            if('' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('', 'l')\n",
    "            if('' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('', 'o')\n",
    "            if('' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('', 's')\n",
    "            if('' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('', 'o')\n",
    "            if('' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('', 'c')\n",
    "            if('' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('', 'n')\n",
    "            if('' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('', 'n')\n",
    "            if('' in fight):\n",
    "                df.loc[index, 'fight'] = fight.replace('', 'z')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    }
   ],
   "source": [
    "#find special characters in df2\n",
    "redcorners = (df2['redCorner'].values)\n",
    "bluecorners = (df2['blueCorner'].values)\n",
    "\n",
    "chars2rep = []\n",
    "for redCorner in redcorners:\n",
    "    if(isinstance(redCorner, str)):\n",
    "        for char in redCorner:\n",
    "            if char.lower() not in ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "            if char.upper() not in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', \"Q\", 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "for blueCorner in bluecorners:\n",
    "    if(isinstance(blueCorner, str)):\n",
    "        for char in blueCorner:\n",
    "            if char.lower() not in ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "            if char.upper() not in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', \"Q\", 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "\n",
    "\n",
    "chars2rep = list(set(chars2rep))\n",
    "for char in chars2rep:\n",
    "    print(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean redCorner, blueCorner, winner\n",
    "for index, row in df2.iterrows():\n",
    "    redCorner = row['redCorner']\n",
    "    blueCorner = row['blueCorner']\n",
    "    winner = row['winner']\n",
    "    if(isinstance(redCorner, str)):\n",
    "        if(\"'\" in redCorner):\n",
    "            df2.loc[index, 'redCorner'] = redCorner.replace(\"'\", '')\n",
    "        if('.' in redCorner):\n",
    "            df2.loc[index, 'redCorner'] = redCorner.replace('.', '')\n",
    "        if('-' in redCorner):\n",
    "            df2.loc[index, 'redCorner'] = redCorner.replace('-', ' ')\n",
    "    if(isinstance(blueCorner, str)):\n",
    "        if(\"'\" in blueCorner):\n",
    "            df2.loc[index, 'blueCorner'] = blueCorner.replace(\"'\", '')\n",
    "        if('.' in blueCorner):\n",
    "            df2.loc[index, 'blueCorner'] = blueCorner.replace('.', '')\n",
    "        if('-' in blueCorner):\n",
    "            df2.loc[index, 'blueCorner'] = blueCorner.replace('-', ' ')\n",
    "    if(isinstance(winner, str)):\n",
    "        if(\"'\" in winner):\n",
    "            df2.loc[index, 'winner'] = winner.replace(\"'\", '')\n",
    "        if('.' in winner):\n",
    "            df2.loc[index, 'winner'] = winner.replace('.', '')\n",
    "        if('-' in winner):\n",
    "            df2.loc[index, 'winner'] = winner.replace('-', ' ')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fight</th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>event</th>\n",
       "      <th>referee</th>\n",
       "      <th>method_of_victory</th>\n",
       "      <th>date</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>...</th>\n",
       "      <th>redCorner_subs_attempted</th>\n",
       "      <th>blueCorner_subs_attempted</th>\n",
       "      <th>round</th>\n",
       "      <th>time</th>\n",
       "      <th>redCorner_height</th>\n",
       "      <th>blueCorner_height</th>\n",
       "      <th>redCorner_reach</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows  45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [fight, redCorner, blueCorner, winner, event, referee, method_of_victory, date, venue, title_fight, billing, redCorner_wins, blueCorner_wins, redCorner_losses, blueCorner_losses, redCorner_draws, blueCorner_draws, redCorner_age, blueCorner_age, redCorner_nation, blueCorner_nation, redCorner_fan, blueCorner_fan, redCorner_knockdowns, blueCorner_knockdowns, redCorner_sig_str, blueCorner_sig_str, redCorner_sig_str_percentage, blueCorner_sig_str_percentage, redCorner_total_str, blueCorner_total_str, redCorner_takedowns, blueCorner_takedowns, redCorner_takedown_percentage, blueCorner_takedown_percentage, redCorner_subs_attempted, blueCorner_subs_attempted, round, time, redCorner_height, blueCorner_height, redCorner_reach, blueCorner_reach, redCorner_stance, blueCorner_stance]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 45 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define headers\n",
    "column_headers = [\n",
    "    'fight', 'redCorner', 'blueCorner', 'winner', 'event', 'referee', 'method_of_victory',\n",
    "    'date', 'venue', 'title_fight', 'billing', 'redCorner_wins', 'blueCorner_wins',\n",
    "    'redCorner_losses', 'blueCorner_losses', 'redCorner_draws', 'blueCorner_draws',\n",
    "    'redCorner_age', 'blueCorner_age', 'redCorner_nation', 'blueCorner_nation',\n",
    "    'redCorner_fan', 'blueCorner_fan', 'redCorner_knockdowns', 'blueCorner_knockdowns',\n",
    "    'redCorner_sig_str', 'blueCorner_sig_str', 'redCorner_sig_str_percentage',\n",
    "    'blueCorner_sig_str_percentage', 'redCorner_total_str', 'blueCorner_total_str',\n",
    "    'redCorner_takedowns', 'blueCorner_takedowns', 'redCorner_takedown_percentage',\n",
    "    'blueCorner_takedown_percentage', 'redCorner_subs_attempted', 'blueCorner_subs_attempted', 'round', 'time',\n",
    "    'redCorner_height', 'blueCorner_height', 'redCorner_reach', 'blueCorner_reach', 'redCorner_stance', 'blueCorner_stance'\n",
    "]\n",
    "\n",
    "#create dataframe using headers\n",
    "dfNew = pd.DataFrame(columns=column_headers)\n",
    "\n",
    "dfNew.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix some inconsistencies\n",
    "df2['redCorner'] = df2['redCorner'].replace('Loopy Godinez', 'Lupita Godinez', regex=True)\n",
    "df2['blueCorner'] = df2['blueCorner'].replace('Loopy Godinez', 'Lupita Godinez', regex=True)\n",
    "df2['winner'] = df2['winner'].replace('Loopy Godinez', 'Lupita Godinez', regex=True)\n",
    "\n",
    "df2['redCorner'] = df2['redCorner'].replace('Viktoriia Dudakova', 'Victoria Dudakova', regex=True)\n",
    "df2['blueCorner'] = df2['blueCorner'].replace('Viktoriia Dudakova', 'Victoria Dudakova', regex=True)\n",
    "df2['winner'] = df2['winner'].replace('Viktoriia Dudakova', 'Victoria Dudakova', regex=True)\n",
    "\n",
    "#fight overturned - only shown in one df\n",
    "index = (df['fight'] == 'Miles Johns vs Dan Argueta') & (df['date'] == '09.23.2023')\n",
    "df.loc[index, 'winner'] = ''\n",
    "df.loc[index, 'loser'] = ''\n",
    "\n",
    "df2['redCorner'] = df2['redCorner'].replace('Blood Diamond', 'Mike Mathetha', regex=True)\n",
    "df2['blueCorner'] = df2['blueCorner'].replace('Blood Diamond', 'Mike Mathetha', regex=True)\n",
    "df2['winner'] = df2['winner'].replace('Blood Diamond', 'Mike Mathetha', regex=True)\n",
    "\n",
    "df2['redCorner'] = df2['redCorner'].replace('Assu Almabayev', 'Asu Almabaev', regex=True)\n",
    "df2['blueCorner'] = df2['blueCorner'].replace('Assu Almabayev', 'Asu Almabaev', regex=True)\n",
    "df2['winner'] = df2['winner'].replace('Assu Almabayev', 'Asu Almabaev', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Carl Deaton III', 'Carl Deaton', regex=True)\n",
    "df['winner'] = df['winner'].replace('Carl Deaton III', 'Carl Deaton', regex=True)\n",
    "df['loser'] = df['loser'].replace('Carl Deaton III', 'Carl Deaton', regex=True)\n",
    "\n",
    "df2['redCorner'] = df2['redCorner'].replace('Alexander Munoz', 'Alex Munoz', regex=True)\n",
    "df2['blueCorner'] = df2['blueCorner'].replace('Alexander Munoz', 'Alex Munoz', regex=True)\n",
    "df2['winner'] = df2['winner'].replace('Alexander Munoz', 'Alex Munoz', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Ovince St Preux', 'Ovince Saint Preux', regex=True)\n",
    "df['winner'] = df['winner'].replace('Ovince St Preux', 'Ovince Saint Preux', regex=True)\n",
    "df['loser'] = df['loser'].replace('Ovince St Preux', 'Ovince Saint Preux', regex=True)\n",
    "\n",
    "df2['redCorner'] = df2['redCorner'].replace('Kazula Vargas', 'Rodrigo Vargas', regex=True)\n",
    "df2['blueCorner'] = df2['blueCorner'].replace('Kazula Vargas', 'Rodrigo Vargas', regex=True)\n",
    "df2['winner'] = df2['winner'].replace('Kazula Vargas', 'Rodrigo Vargas', regex=True)\n",
    "\n",
    "df2['redCorner'] = df2['redCorner'].replace('Da Woon Jung', 'Da Un Jung', regex=True)\n",
    "df2['blueCorner'] = df2['blueCorner'].replace('Da Woon Jung', 'Da Un Jung', regex=True)\n",
    "df2['winner'] = df2['winner'].replace('Da Woon Jung', 'Da Un Jung', regex=True)\n",
    "\n",
    "df2['redCorner'] = df2['redCorner'].replace('Lara Procopio', 'Lara Fritzen', regex=True)\n",
    "df2['blueCorner'] = df2['blueCorner'].replace('Lara Procopio', 'Lara Fritzen', regex=True)\n",
    "df2['winner'] = df2['winner'].replace('Lara Procopio', 'Lara Fritzen', regex=True)\n",
    "\n",
    "df2['redCorner'] = df2['redCorner'].replace('Jacare Souza', 'Ronaldo Souza', regex=True)\n",
    "df2['blueCorner'] = df2['blueCorner'].replace('Jacare Souza', 'Ronaldo Souza', regex=True)\n",
    "df2['winner'] = df2['winner'].replace('Jacare Souza', 'Ronaldo Souza', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Jose Alberto Quinonez', 'Jose Quinonez', regex=True)\n",
    "df['winner'] = df['winner'].replace('Jose Alberto Quinonez', 'Jose Quinonez', regex=True)\n",
    "df['loser'] = df['loser'].replace('Jose Alberto Quinonez', 'Jose Quinonez', regex=True)\n",
    "\n",
    "df2['redCorner'] = df2['redCorner'].replace('Mara Romero Borella', 'Mara Borella', regex=True)\n",
    "df2['blueCorner'] = df2['blueCorner'].replace('Mara Romero Borella', 'Mara Borella', regex=True)\n",
    "df2['winner'] = df2['winner'].replace('Mara Romero Borella', 'Mara Borella', regex=True)\n",
    "\n",
    "df2['redCorner'] = df2['redCorner'].replace('Grigory Popov', 'Grigorii Popov', regex=True)\n",
    "df2['blueCorner'] = df2['blueCorner'].replace('Grigory Popov', 'Grigorii Popov', regex=True)\n",
    "df2['winner'] = df2['winner'].replace('Grigory Popov', 'Grigorii Popov', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Yanan Wu', 'Wu Yanan', regex=True)\n",
    "df['winner'] = df['winner'].replace('Yanan Wu', 'Wu Yanan', regex=True)\n",
    "df['loser'] = df['loser'].replace('Yanan Wu', 'Wu Yanan', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Alexey Kunchenko', 'Aleskei Kunchenko', regex=True)\n",
    "df['winner'] = df['winner'].replace('Alexey Kunchenko', 'Aleskei Kunchenko', regex=True)\n",
    "df['loser'] = df['loser'].replace('Alexey Kunchenko', 'Aleskei Kunchenko', regex=True)\n",
    "\n",
    "df2['redCorner'] = df2['redCorner'].replace('Cristiane Justino', 'Cris Cyborg', regex=True)\n",
    "df2['blueCorner'] = df2['blueCorner'].replace('Cristiane Justino', 'Cris Cyborg', regex=True)\n",
    "df2['winner'] = df2['winner'].replace('Cristiane Justino', 'Cris Cyborg', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Des Green', 'Desmond Green', regex=True)\n",
    "df['winner'] = df['winner'].replace('Des Green', 'Desmond Green', regex=True)\n",
    "df['loser'] = df['loser'].replace('Des Green', 'Desmond Green', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Dmitry Smolyakov', 'Dmitrii Smoliakov', regex=True)\n",
    "df['winner'] = df['winner'].replace('Dmitry Smolyakov', 'Dmitrii Smoliakov', regex=True)\n",
    "df['loser'] = df['loser'].replace('Dmitry Smolyakov', 'Dmitrii Smoliakov', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Ulka Sasaki', 'Yuta Sasaki', regex=True)\n",
    "df['winner'] = df['winner'].replace('Ulka Sasaki', 'Yuta Sasaki', regex=True)\n",
    "df['loser'] = df['loser'].replace('Ulka Sasaki', 'Yuta Sasaki', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Roberto Sanchez', 'Robert Sanchez', regex=True)\n",
    "df['winner'] = df['winner'].replace('Roberto Sanchez', 'Robert Sanchez', regex=True)\n",
    "df['loser'] = df['loser'].replace('Roberto Sanchez', 'Robert Sanchez', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Dmitriy Sosnovskiy', 'Dmitry Sosnovskiy', regex=True)\n",
    "df['winner'] = df['winner'].replace('Dmitriy Sosnovskiy', 'Dmitry Sosnovskiy', regex=True)\n",
    "df['loser'] = df['loser'].replace('Dmitriy Sosnovskiy', 'Dmitry Sosnovskiy', regex=True)\n",
    "\n",
    "df2['redCorner'] = df2['redCorner'].replace('Timothy Johnson', 'Tim Johnson', regex=True)\n",
    "df2['blueCorner'] = df2['blueCorner'].replace('Timothy Johnson', 'Tim Johnson', regex=True)\n",
    "df2['winner'] = df2['winner'].replace('Timothy Johnson', 'Tim Johnson', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Maia Kahaunaele', 'Maia Stevenson', regex=True)\n",
    "df['winner'] = df['winner'].replace('Maia Kahaunaele', 'Maia Stevenson', regex=True)\n",
    "df['loser'] = df['loser'].replace('Maia Kahaunaele', 'Maia Stevenson', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Bharat Khandare', 'Bharat Kandare', regex=True)\n",
    "df['winner'] = df['winner'].replace('Bharat Khandare', 'Bharat Kandare', regex=True)\n",
    "df['loser'] = df['loser'].replace('Bharat Khandare', 'Bharat Kandare', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Nico Musoke', 'Nicholas Musoke', regex=True)\n",
    "df['winner'] = df['winner'].replace('Nico Musoke', 'Nicholas Musoke', regex=True)\n",
    "df['loser'] = df['loser'].replace('Nico Musoke', 'Nicholas Musoke', regex=True)\n",
    "\n",
    "#fight overturned\n",
    "index = (df['fight'] == 'Alex Morono vs Niko Price') & (df['date'] == '02.04.2017')\n",
    "df.loc[index, 'winner'] = ''\n",
    "df.loc[index, 'loser'] = ''\n",
    "\n",
    "df2['redCorner'] = df2['redCorner'].replace('Joseph Gigliotti', 'Joe Gigliotti', regex=True)\n",
    "df2['blueCorner'] = df2['blueCorner'].replace('Joseph Gigliotti', 'Joe Gigliotti', regex=True)\n",
    "df2['winner'] = df2['winner'].replace('Joseph Gigliotti', 'Joe Gigliotti', regex=True)\n",
    "\n",
    "df2['redCorner'] = df2['redCorner'].replace('Tiago dos Santos e Silva', 'Tiago Trator', regex=True)\n",
    "df2['blueCorner'] = df2['blueCorner'].replace('Tiago dos Santos e Silva', 'Tiago Trator', regex=True)\n",
    "df2['winner'] = df2['winner'].replace('Tiago dos Santos e Silva', 'Tiago Trator', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Manny Gamburyan', 'Manvel Gamburyan', regex=True)\n",
    "df['winner'] = df['winner'].replace('Manny Gamburyan', 'Manvel Gamburyan', regex=True)\n",
    "df['loser'] = df['loser'].replace('Manny Gamburyan', 'Manvel Gamburyan', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Mike Graves', 'Michael Graves', regex=True)\n",
    "df['winner'] = df['winner'].replace('Mike Graves', 'Michael Graves', regex=True)\n",
    "df['loser'] = df['loser'].replace('Mike Graves', 'Michael Graves', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Marcio Alexandre Jr', 'Marcio Alexandre Junior', regex=True)\n",
    "df['winner'] = df['winner'].replace('Marcio Alexandre Jr', 'Marcio Alexandre Junior', regex=True)\n",
    "df['loser'] = df['loser'].replace('Marcio Alexandre Jr', 'Marcio Alexandre Junior', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Steven Kennedy', 'Steve Kennedy', regex=True)\n",
    "df['winner'] = df['winner'].replace('Steven Kennedy', 'Steve Kennedy', regex=True)\n",
    "df['loser'] = df['loser'].replace('Steven Kennedy', 'Steve Kennedy', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Ronald Stallings', 'Ron Stallings', regex=True)\n",
    "df['winner'] = df['winner'].replace('Ronald Stallings', 'Ron Stallings', regex=True)\n",
    "df['loser'] = df['loser'].replace('Ronald Stallings', 'Ron Stallings', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Tony Christodoulou', 'Anthony Christodoulou', regex=True)\n",
    "df['winner'] = df['winner'].replace('Tony Christodoulou', 'Anthony Christodoulou', regex=True)\n",
    "df['loser'] = df['loser'].replace('Tony Christodoulou', 'Anthony Christodoulou', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Costas Philippou', 'Constantinos Philippou', regex=True)\n",
    "df['winner'] = df['winner'].replace('Costas Philippou', 'Constantinos Philippou', regex=True)\n",
    "df['loser'] = df['loser'].replace('Costas Philippou', 'Constantinos Philippou', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Alp Ozkilic', 'Alptekin Ozkilic', regex=True)\n",
    "df['winner'] = df['winner'].replace('Alp Ozkilic', 'Alptekin Ozkilic', regex=True)\n",
    "df['loser'] = df['loser'].replace('Alp Ozkilic', 'Alptekin Ozkilic', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Robbie Peralta', 'Robert Peralta', regex=True)\n",
    "df['winner'] = df['winner'].replace('Robbie Peralta', 'Robert Peralta', regex=True)\n",
    "df['loser'] = df['loser'].replace('Robbie Peralta', 'Robert Peralta', regex=True)\n",
    "\n",
    "df2['redCorner'] = df2['redCorner'].replace('Elizeu Zaleski dos Santos', 'Elizeu Zaleski', regex=True)\n",
    "df2['blueCorner'] = df2['blueCorner'].replace('Elizeu Zaleski dos Santos', 'Elizeu Zaleski', regex=True)\n",
    "df2['winner'] = df2['winner'].replace('Elizeu Zaleski dos Santos', 'Elizeu Zaleski', regex=True)\n",
    "\n",
    "#fight overturned\n",
    "index = (df['fight'] == 'Norifumi Yamamoto vs Roman Salazar') & (df['date'] == '02.28.2015')\n",
    "df.loc[index, 'winner'] = ''\n",
    "df.loc[index, 'loser'] = ''\n",
    "\n",
    "df['fight'] = df['fight'].replace('Alexander Torres', 'Alex Torres', regex=True)\n",
    "df['winner'] = df['winner'].replace('Alexander Torres', 'Alex Torres', regex=True)\n",
    "df['loser'] = df['loser'].replace('Alexander Torres', 'Alex Torres', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Pat Walsh', 'Patrick Walsh', regex=True)\n",
    "df['winner'] = df['winner'].replace('Pat Walsh', 'Patrick Walsh', regex=True)\n",
    "df['loser'] = df['loser'].replace('Pat Walsh', 'Patrick Walsh', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Zhumabek Tursyn', 'Jumabieke Tuerxun', regex=True)\n",
    "df['winner'] = df['winner'].replace('Zhumabek Tursyn', 'Jumabieke Tuerxun', regex=True)\n",
    "df['loser'] = df['loser'].replace('Zhumabek Tursyn', 'Jumabieke Tuerxun', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Dan Spohn', 'Daniel Spohn', regex=True)\n",
    "df['winner'] = df['winner'].replace('Dan Spohn', 'Daniel Spohn', regex=True)\n",
    "df['loser'] = df['loser'].replace('Dan Spohn', 'Daniel Spohn', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Guilherme Bomba', 'Guilherme Vasconcelos', regex=True)\n",
    "df['winner'] = df['winner'].replace('Guilherme Bomba', 'Guilherme Vasconcelos', regex=True)\n",
    "df['loser'] = df['loser'].replace('Guilherme Bomba', 'Guilherme Vasconcelos', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Bubba McDaniel', 'Robert McDaniel', regex=True)\n",
    "df['winner'] = df['winner'].replace('Bubba McDaniel', 'Robert McDaniel', regex=True)\n",
    "df['loser'] = df['loser'].replace('Bubba McDaniel', 'Robert McDaniel', regex=True)\n",
    "\n",
    "#fight overturned\n",
    "index = (df['fight'] == 'Louis Gaudinot vs Phil Harris') & (df['date'] == '03.08.2014')\n",
    "df.loc[index, 'winner'] = ''\n",
    "df.loc[index, 'loser'] = ''\n",
    "\n",
    "df['fight'] = df['fight'].replace('Benny Alloway', 'Ben Alloway', regex=True)\n",
    "df['winner'] = df['winner'].replace('Benny Alloway', 'Ben Alloway', regex=True)\n",
    "df['loser'] = df['loser'].replace('Benny Alloway', 'Ben Alloway', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Phil De Fries', 'Philip De Fries', regex=True)\n",
    "df['winner'] = df['winner'].replace('Phil De Fries', 'Philip De Fries', regex=True)\n",
    "df['loser'] = df['loser'].replace('Phil De Fries', 'Philip De Fries', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Matt Riddle', 'Matthew Riddle', regex=True)\n",
    "df['winner'] = df['winner'].replace('Matt Riddle', 'Matthew Riddle', regex=True)\n",
    "df['loser'] = df['loser'].replace('Matt Riddle', 'Matthew Riddle', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Manny Rodriguez', 'Manuel Rodriguez', regex=True)\n",
    "df['winner'] = df['winner'].replace('Manny Rodriguez', 'Manuel Rodriguez', regex=True)\n",
    "df['loser'] = df['loser'].replace('Manny Rodriguez', 'Manuel Rodriguez', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('John Olav Einemo', 'Jon Olav Einemo', regex=True)\n",
    "df['winner'] = df['winner'].replace('John Olav Einemo', 'Jon Olav Einemo', regex=True)\n",
    "df['loser'] = df['loser'].replace('John Olav Einemo', 'Jon Olav Einemo', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Kimbo Slice', 'Kevin Ferguson', regex=True)\n",
    "df['winner'] = df['winner'].replace('Kimbo Slice', 'Kevin Ferguson', regex=True)\n",
    "df['loser'] = df['loser'].replace('Kimbo Slice', 'Kevin Ferguson', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Roli Delgado', 'Rolando Delgado', regex=True)\n",
    "df['winner'] = df['winner'].replace('Roli Delgado', 'Rolando Delgado', regex=True)\n",
    "df['loser'] = df['loser'].replace('Roli Delgado', 'Rolando Delgado', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Dave Kaplan', 'David Kaplan', regex=True)\n",
    "df['winner'] = df['winner'].replace('Dave Kaplan', 'David Kaplan', regex=True)\n",
    "df['loser'] = df['loser'].replace('Dave Kaplan', 'David Kaplan', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Mike Patt', 'Michael Patt', regex=True)\n",
    "df['winner'] = df['winner'].replace('Mike Patt', 'Michael Patt', regex=True)\n",
    "df['loser'] = df['loser'].replace('Mike Patt', 'Michael Patt', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Thomas Speer', 'Tommy Speer', regex=True)\n",
    "df['winner'] = df['winner'].replace('Thomas Speer', 'Tommy Speer', regex=True)\n",
    "df['loser'] = df['loser'].replace('Thomas Speer', 'Tommy Speer', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Douglas Evans', 'Doug Evans', regex=True)\n",
    "df['winner'] = df['winner'].replace('Douglas Evans', 'Doug Evans', regex=True)\n",
    "df['loser'] = df['loser'].replace('Douglas Evans', 'Doug Evans', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Daniel Barrera', 'Dan Barrera', regex=True)\n",
    "df['winner'] = df['winner'].replace('Daniel Barrera', 'Dan Barrera', regex=True)\n",
    "df['loser'] = df['loser'].replace('Daniel Barrera', 'Dan Barrera', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Allen Berubie', 'Allen Berube', regex=True)\n",
    "df['winner'] = df['winner'].replace('Allen Berubie', 'Allen Berube', regex=True)\n",
    "df['loser'] = df['loser'].replace('Allen Berubie', 'Allen Berube', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Yoshitomi Mishima', 'Dokonjonosuke Mishima', regex=True)\n",
    "df['winner'] = df['winner'].replace('Yoshitomi Mashima', 'Dokonjonosuke Mashima', regex=True)\n",
    "df['loser'] = df['loser'].replace('Yoshitomi Mashima', 'Dokonjonosuke Mashima', regex=True)\n",
    "\n",
    "df2['redCorner'] = df2['redCorner'].replace('Steve Lynch', 'Steven Lynch', regex=True)\n",
    "df2['blueCorner'] = df2['blueCorner'].replace('Steve Lynch', 'Steven Lynch', regex=True)\n",
    "df2['winner'] = df2['winner'].replace('Steve Lynch', 'Steven Lynch', regex=True)\n",
    "\n",
    "df2['redCorner'] = df2['redCorner'].replace('Stevie Lynch', 'Steven Lynch', regex=True)\n",
    "df2['blueCorner'] = df2['blueCorner'].replace('Stevie Lynch', 'Steven Lynch', regex=True)\n",
    "df2['winner'] = df2['winner'].replace('Stevie Lynch', 'Steven Lynch', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Josh Schockman', 'Josh Shockman', regex=True)\n",
    "df['winner'] = df['winner'].replace('Josh Schockman', 'Josh Shockman', regex=True)\n",
    "df['loser'] = df['loser'].replace('Josh Schockman', 'Josh Shockman', regex=True)\n",
    "\n",
    "df2['redCorner'] = df2['redCorner'].replace('Sammy Morgan', 'Sam Morgan', regex=True)\n",
    "df2['blueCorner'] = df2['blueCorner'].replace('Sammy Morgan', 'Sam Morgan', regex=True)\n",
    "df2['winner'] = df2['winner'].replace('Sammy Morgan', 'Sam Morgan', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Kris Rotharmel', 'Kristian Rothaermel', regex=True)\n",
    "df['winner'] = df['winner'].replace('Kris Rotharmel', 'Kristian Rothaermel', regex=True)\n",
    "df['loser'] = df['loser'].replace('Kris Rotharmel', 'Kristian Rothaermel', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Joao Marcos Pierini', 'Joao Pierini', regex=True)\n",
    "df['winner'] = df['winner'].replace('Joao Marcos Pierini', 'Joao Pierini', regex=True)\n",
    "df['loser'] = df['loser'].replace('Joao Marcos Pierini', 'Joao Pierini', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Tsuyoshi Kosaka', 'Tsuyoshi Kohsaka', regex=True)\n",
    "df['winner'] = df['winner'].replace('Tsuyoshi Kosaka', 'Tsuyoshi Kohsaka', regex=True)\n",
    "df['loser'] = df['loser'].replace('Tsuyoshi Kosaka', 'Tsuyoshi Kohsaka', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Andrey Semenov', 'Andrei Semenov', regex=True)\n",
    "df['winner'] = df['winner'].replace('Andrey Semenov', 'Andrei Semenov', regex=True)\n",
    "df['loser'] = df['loser'].replace('Andrey Semenov', 'Andrei Semenov', regex=True)\n",
    "\n",
    "df2['redCorner'] = df2['redCorner'].replace('Cesar Marsucci', 'Cesar Marscucci', regex=True)\n",
    "df2['blueCorner'] = df2['blueCorner'].replace('Cesar Marsucci', 'Cesar Marscucci', regex=True)\n",
    "df2['winner'] = df2['winner'].replace('Cesar Marsucci', 'Cesar Marscucci', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Cristophe Leninger', 'Christophe Leninger', regex=True)\n",
    "df['winner'] = df['winner'].replace('Cristophe Leninger', 'Christophe Leninger', regex=True)\n",
    "df['loser'] = df['loser'].replace('Cristophe Leninger', 'Christophe Leninger', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Kazuo Takahashi', 'Yoshiki Takahashi', regex=True)\n",
    "df['winner'] = df['winner'].replace('Kazuo Takahashi', 'Yoshiki Takahashi', regex=True)\n",
    "df['loser'] = df['loser'].replace('Kazuo Takahashi', 'Yoshiki Takahashi', regex=True)\n",
    "\n",
    "df2['redCorner'] = df2['redCorner'].replace('Felix Lee Mitchell', 'Felix Mitchell', regex=True)\n",
    "df2['blueCorner'] = df2['blueCorner'].replace('Felix Lee Mitchell', 'Felix Mitchell', regex=True)\n",
    "df2['winner'] = df2['winner'].replace('Felix Lee Mitchell', 'Felix Mitchell', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('John Campatella', 'John Campetella', regex=True)\n",
    "df['winner'] = df['winner'].replace('John Campatella', 'John Campetella', regex=True)\n",
    "df['loser'] = df['loser'].replace('John Campatella', 'John Campetella', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Eldo Dias Xavier', 'Eldo Xavier Diaz', regex=True)\n",
    "df['winner'] = df['winner'].replace('Eldo Dias Xavier', 'Eldo Xavier Diaz', regex=True)\n",
    "df['loser'] = df['loser'].replace('Eldo Dias Xavier', 'Eldo Xavier Diaz', regex=True)\n",
    "\n",
    "df['fight'] = df['fight'].replace('Alberto Cerra Leon', 'Alberta Cerra Leon', regex=True)\n",
    "df['winner'] = df['winner'].replace('Alberto Cerra Leon', 'Alberta Cerra Leon', regex=True)\n",
    "df['loser'] = df['loser'].replace('Alberto Cerra Leon', 'Alberta Cerra Leon', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>event</th>\n",
       "      <th>referee</th>\n",
       "      <th>method_of_victory</th>\n",
       "      <th>red_Knockdowns</th>\n",
       "      <th>blue_Knockdowns</th>\n",
       "      <th>red_sig_str</th>\n",
       "      <th>blue_sig_str</th>\n",
       "      <th>...</th>\n",
       "      <th>red_subs_attempted</th>\n",
       "      <th>blue_subs_attempted</th>\n",
       "      <th>round</th>\n",
       "      <th>time</th>\n",
       "      <th>redCorner_height</th>\n",
       "      <th>blueCorner_height</th>\n",
       "      <th>redCorner_reach</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex Pereira</td>\n",
       "      <td>Khalil Rountree Jr</td>\n",
       "      <td>Alex Pereira</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Marc Goddard</td>\n",
       "      <td>KO/TKO</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>127 of 209</td>\n",
       "      <td>61 of 191</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4:32</td>\n",
       "      <td>6' 4\"</td>\n",
       "      <td>6' 1\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raquel Pennington</td>\n",
       "      <td>Julianna Pena</td>\n",
       "      <td>Julianna Pena</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Jason Herzog</td>\n",
       "      <td>Decision - Split</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92 of 317</td>\n",
       "      <td>92 of 260</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>67\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jose Aldo</td>\n",
       "      <td>Mario Bautista</td>\n",
       "      <td>Mario Bautista</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Mike Beltran</td>\n",
       "      <td>Decision - Split</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51 of 117</td>\n",
       "      <td>49 of 142</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>70\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roman Dolidze</td>\n",
       "      <td>Kevin Holland</td>\n",
       "      <td>Roman Dolidze</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Jason Herzog</td>\n",
       "      <td>KO/TKO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19 of 33</td>\n",
       "      <td>18 of 28</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5:00</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ketlen Vieira</td>\n",
       "      <td>Kayla Harrison</td>\n",
       "      <td>Kayla Harrison</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Marc Goddard</td>\n",
       "      <td>Decision - Unanimous</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24 of 61</td>\n",
       "      <td>55 of 94</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>68\"</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           redCorner          blueCorner          winner  \\\n",
       "0       Alex Pereira  Khalil Rountree Jr    Alex Pereira   \n",
       "1  Raquel Pennington       Julianna Pena   Julianna Pena   \n",
       "2          Jose Aldo      Mario Bautista  Mario Bautista   \n",
       "3      Roman Dolidze       Kevin Holland   Roman Dolidze   \n",
       "4      Ketlen Vieira      Kayla Harrison  Kayla Harrison   \n",
       "\n",
       "                               event       referee     method_of_victory  \\\n",
       "0  UFC 307: Pereira vs. Rountree Jr.  Marc Goddard                KO/TKO   \n",
       "1  UFC 307: Pereira vs. Rountree Jr.  Jason Herzog      Decision - Split   \n",
       "2  UFC 307: Pereira vs. Rountree Jr.  Mike Beltran      Decision - Split   \n",
       "3  UFC 307: Pereira vs. Rountree Jr.  Jason Herzog                KO/TKO   \n",
       "4  UFC 307: Pereira vs. Rountree Jr.  Marc Goddard  Decision - Unanimous   \n",
       "\n",
       "   red_Knockdowns  blue_Knockdowns red_sig_str blue_sig_str  ...  \\\n",
       "0               1                0  127 of 209    61 of 191  ...   \n",
       "1               1                0   92 of 317    92 of 260  ...   \n",
       "2               0                0   51 of 117    49 of 142  ...   \n",
       "3               0                0    19 of 33     18 of 28  ...   \n",
       "4               0                0    24 of 61     55 of 94  ...   \n",
       "\n",
       "  red_subs_attempted blue_subs_attempted round  time redCorner_height  \\\n",
       "0                  0                   0     4  4:32            6' 4\"   \n",
       "1                  0                   1     5  5:00            5' 7\"   \n",
       "2                  0                   0     3  5:00            5' 7\"   \n",
       "3                  0                   0     1  5:00            6' 2\"   \n",
       "4                  0                   0     3  5:00            5' 8\"   \n",
       "\n",
       "  blueCorner_height redCorner_reach blueCorner_reach  redCorner_stance  \\\n",
       "0             6' 1\"             79\"              76\"          Orthodox   \n",
       "1             5' 6\"             67\"              69\"          Orthodox   \n",
       "2             5' 9\"             70\"              69\"          Orthodox   \n",
       "3             6' 3\"             76\"              81\"          Orthodox   \n",
       "4             5' 8\"             68\"              66\"          Orthodox   \n",
       "\n",
       "   blueCorner_stance  \n",
       "0           Southpaw  \n",
       "1           Orthodox  \n",
       "2             Switch  \n",
       "3           Orthodox  \n",
       "4           Southpaw  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine dfs updater\n",
    "for (index, row), (index2, row2) in zip(df.iterrows(), df2.iterrows()):\n",
    "    if(row['event'] == row2['event']):\n",
    "        fight = row['fight'].split(' vs ')\n",
    "        fighter1 = ''.join(sorted(str(fight[0]).replace(\" \", \"\").lower()))\n",
    "        fighter2 = ''.join(sorted(str(fight[1]).replace(\" \", \"\").lower()))\n",
    "        redCorner = ''.join(sorted(str(row2['redCorner']).replace(\" \", \"\").lower()))\n",
    "        blueCorner = ''.join(sorted(str(row2['blueCorner']).replace(\" \", \"\").lower()))\n",
    "        winner1 = ''.join(sorted(str(row['winner']).replace(\" \", \"\").lower()))\n",
    "        winner2 = ''.join(sorted(str(row2['winner']).replace(\" \", \"\").lower()))\n",
    "        if(fighter1 in redCorner or fighter1 in blueCorner or redCorner in fighter1 or blueCorner in fighter1):\n",
    "            if(fighter2 in redCorner or fighter2 in blueCorner or redCorner in fighter2 or blueCorner in fighter2):\n",
    "                if(winner1 in winner2 or winner2 in winner1):\n",
    "                    fight = row['fight']\n",
    "                    redCorner = row2['redCorner']\n",
    "                    blueCorner = row2['blueCorner']\n",
    "                    winner = row2['winner']\n",
    "                    event = row2['event']\n",
    "                    referee = row2['referee']\n",
    "                    method_of_vic = row2['method_of_victory']\n",
    "                    date = row['date']\n",
    "                    venue = row['venue']\n",
    "                    title_fight = row['title_fight']\n",
    "                    billing = row['billing']\n",
    "                    if(winner1 in redCorner or redCorner in winner1):\n",
    "                        redCorner_wins = row['winner_wins']\n",
    "                        redCorner_losses = row['winner_losses']\n",
    "                        redCorner_draws = row['winner_draws']\n",
    "                        redCorner_age = row['winner_age']\n",
    "                        redCorner_nation = row['winner_nationality']\n",
    "                        redCorner_fan = row['winner_fan ']\n",
    "                        blueCorner_wins = row['loser_wins']\n",
    "                        blueCorner_losses = row['loser_losses']\n",
    "                        blueCorner_draws = row['loser_draws']\n",
    "                        blueCorner_age = row['loser_age']\n",
    "                        blueCorner_nation = row['loser_nationality']\n",
    "                        blueCorner_fan = row['loser_fan']\n",
    "                    elif(winner1 in blueCorner or blueCorner in winner1):\n",
    "                        blueCorner_wins = row['winner_wins']\n",
    "                        blueCorner_losses = row['winner_losses']\n",
    "                        blueCorner_draws = row['winner_draws']\n",
    "                        blueCorner_age = row['winner_age']\n",
    "                        blueCorner_nation = row['winner_nationality']\n",
    "                        blueCorner_fan = row['winner_fan ']\n",
    "                        redCorner_wins = row['loser_wins']\n",
    "                        redCorner_losses = row['loser_losses']\n",
    "                        redCorner_draws = row['loser_draws']\n",
    "                        redCorner_age = row['loser_age']\n",
    "                        redCorner_nation = row['loser_nationality']\n",
    "                        redCorner_fan = row['loser_fan']\n",
    "                    else:\n",
    "                        if(fight[0] in redCorner or redCorner in fight[0]):\n",
    "                            redCorner_wins = row['winner_wins']\n",
    "                            redCorner_losses = row['winner_losses']\n",
    "                            redCorner_draws = row['winner_draws']\n",
    "                            redCorner_age = row['winner_age']\n",
    "                            redCorner_nation = row['winner_nationality']\n",
    "                            redCorner_fan = row['winner_fan ']\n",
    "                            blueCorner_wins = row['loser_wins']\n",
    "                            blueCorner_losses = row['loser_losses']\n",
    "                            blueCorner_draws = row['loser_draws']\n",
    "                            blueCorner_age = row['loser_age']\n",
    "                            blueCorner_nation = row['loser_nationality']\n",
    "                            blueCorner_fan = row['loser_fan']\n",
    "                        if(fight[0] in blueCorner or blueCorner in fight[0]):\n",
    "                            blueCorner_wins = row['winner_wins']\n",
    "                            blueCorner_losses = row['winner_losses']\n",
    "                            blueCorner_draws = row['winner_draws']\n",
    "                            blueCorner_age = row['winner_age']\n",
    "                            blueCorner_nation = row['winner_nationality']\n",
    "                            blueCorner_fan = row['winner_fan ']\n",
    "                            redCorner_wins = row['loser_wins']\n",
    "                            redCorner_losses = row['loser_losses']\n",
    "                            redCorner_draws = row['loser_draws']\n",
    "                            redCorner_age = row['loser_age']\n",
    "                            redCorner_nation = row['loser_nationality']\n",
    "                            redCorner_fan = row['loser_fan']\n",
    "                    redCorner_knockdowns = row2['red_Knockdowns']\n",
    "                    blueCorner_knockdowns = row2['blue_Knockdowns']\n",
    "                    redCorner_sig_str = row2['red_sig_str']\n",
    "                    blueCorner_sig_str = row2['blue_sig_str']\n",
    "                    redCorner_sig_str_percentage = row2['red_sig_str_percentage']\n",
    "                    blueCorner_sig_str_percentage = row2['blue_sig_str_percentage']\n",
    "                    redCorner_total_str = row2['red_total_strikes']\n",
    "                    blueCorner_total_str = row2['blue_total_strikes']\n",
    "                    redCorner_takedowns = row2['red_takedowns']\n",
    "                    blueCorner_takedowns = row2['blue_takedowns']\n",
    "                    redCorner_takedown_percentage = row2['red_takedown_percentage']\n",
    "                    blueCorner_takedown_percentage = row2['blue_takedown_percentage']\n",
    "                    redCorner_subs_attempted = row2['red_subs_attempted']\n",
    "                    blueCorner_subs_attempted = row2['blue_subs_attempted']\n",
    "                    roundA = row2['round']      \n",
    "                    time = row2['time']\n",
    "                    redCorner_height = row2['redCorner_height']\n",
    "                    blueCorner_height = row2['blueCorner_height']\n",
    "                    redCorner_reach = row2['redCorner_reach']\n",
    "                    blueCorner_reach = row2['blueCorner_reach']\n",
    "                    redCorner_stance = row2['redCorner_stance']\n",
    "                    blueCorner_stance = row2['blueCorner_stance']\n",
    "            else:\n",
    "                fight = row['fight'].split(' vs ')\n",
    "                fighter1 = str(fight[0]).replace(\" \", \"\").lower()\n",
    "                fighter2 = str(fight[1]).replace(\" \", \"\").lower()\n",
    "                redCorner = str(row2['redCorner']).replace(\" \", \"\").lower()\n",
    "                blueCorner = str(row2['blueCorner']).replace(\" \", \"\").lower()\n",
    "                winner1 = str(row['winner']).replace(\" \", \"\").lower()\n",
    "                winner2 = str(row2['winner']).replace(\" \", \"\").lower()\n",
    "                if(fighter1 in redCorner or fighter1 in blueCorner or redCorner in fighter1 or blueCorner in fighter1):\n",
    "                    if(fighter2 in redCorner or fighter2 in blueCorner or redCorner in fighter2 or blueCorner in fighter2):\n",
    "                        if(winner1 in winner2 or winner2 in winner1):\n",
    "                            fight = row['fight']\n",
    "                            redCorner = row2['redCorner']\n",
    "                            blueCorner = row2['blueCorner']\n",
    "                            winner = row2['winner']\n",
    "                            event = row2['event']\n",
    "                            referee = row2['referee']\n",
    "                            method_of_vic = row2['method_of_victory']\n",
    "                            date = row['date']\n",
    "                            venue = row['venue']\n",
    "                            title_fight = row['title_fight']\n",
    "                            billing = row['billing']\n",
    "                            if(winner1 in redCorner or redCorner in winner1):\n",
    "                                redCorner_wins = row['winner_wins']\n",
    "                                redCorner_losses = row['winner_losses']\n",
    "                                redCorner_draws = row['winner_draws']\n",
    "                                redCorner_age = row['winner_age']\n",
    "                                redCorner_nation = row['winner_nationality']\n",
    "                                redCorner_fan = row['winner_fan ']\n",
    "                                blueCorner_wins = row['loser_wins']\n",
    "                                blueCorner_losses = row['loser_losses']\n",
    "                                blueCorner_draws = row['loser_draws']\n",
    "                                blueCorner_age = row['loser_age']\n",
    "                                blueCorner_nation = row['loser_nationality']\n",
    "                                blueCorner_fan = row['loser_fan']\n",
    "                            elif(winner1 in blueCorner or blueCorner in winner1):\n",
    "                                blueCorner_wins = row['winner_wins']\n",
    "                                blueCorner_losses = row['winner_losses']\n",
    "                                blueCorner_draws = row['winner_draws']\n",
    "                                blueCorner_age = row['winner_age']\n",
    "                                blueCorner_nation = row['winner_nationality']\n",
    "                                blueCorner_fan = row['winner_fan ']\n",
    "                                redCorner_wins = row['loser_wins']\n",
    "                                redCorner_losses = row['loser_losses']\n",
    "                                redCorner_draws = row['loser_draws']\n",
    "                                redCorner_age = row['loser_age']\n",
    "                                redCorner_nation = row['loser_nationality']\n",
    "                                redCorner_fan = row['loser_fan']\n",
    "                            else:\n",
    "                                if(fight[0] in redCorner or redCorner in fight[0]):\n",
    "                                    redCorner_wins = row['winner_wins']\n",
    "                                    redCorner_losses = row['winner_losses']\n",
    "                                    redCorner_draws = row['winner_draws']\n",
    "                                    redCorner_age = row['winner_age']\n",
    "                                    redCorner_nation = row['winner_nationality']\n",
    "                                    redCorner_fan = row['winner_fan ']\n",
    "                                    blueCorner_wins = row['loser_wins']\n",
    "                                    blueCorner_losses = row['loser_losses']\n",
    "                                    blueCorner_draws = row['loser_draws']\n",
    "                                    blueCorner_age = row['loser_age']\n",
    "                                    blueCorner_nation = row['loser_nationality']\n",
    "                                    blueCorner_fan = row['loser_fan']\n",
    "                                if(fight[0] in blueCorner or blueCorner in fight[0]):\n",
    "                                    blueCorner_wins = row['winner_wins']\n",
    "                                    blueCorner_losses = row['winner_losses']\n",
    "                                    blueCorner_draws = row['winner_draws']\n",
    "                                    blueCorner_age = row['winner_age']\n",
    "                                    blueCorner_nation = row['winner_nationality']\n",
    "                                    blueCorner_fan = row['winner_fan ']\n",
    "                                    redCorner_wins = row['loser_wins']\n",
    "                                    redCorner_losses = row['loser_losses']\n",
    "                                    redCorner_draws = row['loser_draws']\n",
    "                                    redCorner_age = row['loser_age']\n",
    "                                    redCorner_nation = row['loser_nationality']\n",
    "                                    redCorner_fan = row['loser_fan']\n",
    "                            redCorner_knockdowns = row2['red_Knockdowns']\n",
    "                            blueCorner_knockdowns = row2['blue_Knockdowns']\n",
    "                            redCorner_sig_str = row2['red_sig_str']\n",
    "                            blueCorner_sig_str = row2['blue_sig_str']\n",
    "                            redCorner_sig_str_percentage = row2['red_sig_str_percentage']\n",
    "                            blueCorner_sig_str_percentage = row2['blue_sig_str_percentage']\n",
    "                            redCorner_total_str = row2['red_total_strikes']\n",
    "                            blueCorner_total_str = row2['blue_total_strikes']\n",
    "                            redCorner_takedowns = row2['red_takedowns']\n",
    "                            blueCorner_takedowns = row2['blue_takedowns']\n",
    "                            redCorner_takedown_percentage = row2['red_takedown_percentage']\n",
    "                            blueCorner_takedown_percentage = row2['blue_takedown_percentage']\n",
    "                            redCorner_subs_attempted = row2['red_subs_attempted']\n",
    "                            blueCorner_subs_attempted = row2['blue_subs_attempted']\n",
    "                            roundA = row2['round']      \n",
    "                            time = row2['time']\n",
    "                            redCorner_height = row2['redCorner_height']\n",
    "                            blueCorner_height = row2['blueCorner_height']\n",
    "                            redCorner_reach = row2['redCorner_reach']\n",
    "                            blueCorner_reach = row2['blueCorner_reach']\n",
    "                            redCorner_stance = row2['redCorner_stance']\n",
    "                            blueCorner_stance = row2['blueCorner_stance'] \n",
    "                    else:\n",
    "                        fight = row['fight'].split(' vs ')\n",
    "                        fighter1 = str(fight[0]).replace(\" \", \"\").lower()\n",
    "                        fighter2 = str(fight[1]).replace(\" \", \"\").lower()\n",
    "                        redCorner = str(row2['redCorner']).replace(\" \", \"\").lower()\n",
    "                        blueCorner = str(row2['blueCorner']).replace(\" \", \"\").lower()\n",
    "                        winner1 = str(row['winner']).replace(\" \", \"\").lower()\n",
    "                        winner2 = str(row2['winner']).replace(\" \", \"\").lower()\n",
    "                        fighter1 = redCorner\n",
    "                        fighter2 = blueCorner\n",
    "                        if(fighter1 in redCorner or fighter1 in blueCorner or redCorner in fighter1 or blueCorner in fighter1):\n",
    "                            if(fighter2 in redCorner or fighter2 in blueCorner or redCorner in fighter2 or blueCorner in fighter2):\n",
    "                                if(winner1 in winner2 or winner2 in winner1):\n",
    "                                    fight = row['fight']\n",
    "                                    redCorner = row2['redCorner']\n",
    "                                    blueCorner = row2['blueCorner']\n",
    "                                    winner = row2['winner']\n",
    "                                    event = row2['event']\n",
    "                                    referee = row2['referee']\n",
    "                                    method_of_vic = row2['method_of_victory']\n",
    "                                    date = row['date']\n",
    "                                    venue = row['venue']\n",
    "                                    title_fight = row['title_fight']\n",
    "                                    billing = row['billing']\n",
    "                                    if(winner1 in redCorner or redCorner in winner1):\n",
    "                                        redCorner_wins = row['winner_wins']\n",
    "                                        redCorner_losses = row['winner_losses']\n",
    "                                        redCorner_draws = row['winner_draws']\n",
    "                                        redCorner_age = row['winner_age']\n",
    "                                        redCorner_nation = row['winner_nationality']\n",
    "                                        redCorner_fan = row['winner_fan ']\n",
    "                                        blueCorner_wins = row['loser_wins']\n",
    "                                        blueCorner_losses = row['loser_losses']\n",
    "                                        blueCorner_draws = row['loser_draws']\n",
    "                                        blueCorner_age = row['loser_age']\n",
    "                                        blueCorner_nation = row['loser_nationality']\n",
    "                                        blueCorner_fan = row['loser_fan']\n",
    "                                    elif(winner1 in blueCorner or blueCorner in winner1):\n",
    "                                        blueCorner_wins = row['winner_wins']\n",
    "                                        blueCorner_losses = row['winner_losses']\n",
    "                                        blueCorner_draws = row['winner_draws']\n",
    "                                        blueCorner_age = row['winner_age']\n",
    "                                        blueCorner_nation = row['winner_nationality']\n",
    "                                        blueCorner_fan = row['winner_fan ']\n",
    "                                        redCorner_wins = row['loser_wins']\n",
    "                                        redCorner_losses = row['loser_losses']\n",
    "                                        redCorner_draws = row['loser_draws']\n",
    "                                        redCorner_age = row['loser_age']\n",
    "                                        redCorner_nation = row['loser_nationality']\n",
    "                                        redCorner_fan = row['loser_fan']\n",
    "                                    else:\n",
    "                                        if(fight[0] in redCorner or redCorner in fight[0]):\n",
    "                                            redCorner_wins = row['winner_wins']\n",
    "                                            redCorner_losses = row['winner_losses']\n",
    "                                            redCorner_draws = row['winner_draws']\n",
    "                                            redCorner_age = row['winner_age']\n",
    "                                            redCorner_nation = row['winner_nationality']\n",
    "                                            redCorner_fan = row['winner_fan ']\n",
    "                                            blueCorner_wins = row['loser_wins']\n",
    "                                            blueCorner_losses = row['loser_losses']\n",
    "                                            blueCorner_draws = row['loser_draws']\n",
    "                                            blueCorner_age = row['loser_age']\n",
    "                                            blueCorner_nation = row['loser_nationality']\n",
    "                                            blueCorner_fan = row['loser_fan']\n",
    "                                        if(fight[0] in blueCorner or blueCorner in fight[0]):\n",
    "                                            blueCorner_wins = row['winner_wins']\n",
    "                                            blueCorner_losses = row['winner_losses']\n",
    "                                            blueCorner_draws = row['winner_draws']\n",
    "                                            blueCorner_age = row['winner_age']\n",
    "                                            blueCorner_nation = row['winner_nationality']\n",
    "                                            blueCorner_fan = row['winner_fan ']\n",
    "                                            redCorner_wins = row['loser_wins']\n",
    "                                            redCorner_losses = row['loser_losses']\n",
    "                                            redCorner_draws = row['loser_draws']\n",
    "                                            redCorner_age = row['loser_age']\n",
    "                                            redCorner_nation = row['loser_nationality']\n",
    "                                            redCorner_fan = row['loser_fan']\n",
    "                                    redCorner_knockdowns = row2['red_Knockdowns']\n",
    "                                    blueCorner_knockdowns = row2['blue_Knockdowns']\n",
    "                                    redCorner_sig_str = row2['red_sig_str']\n",
    "                                    blueCorner_sig_str = row2['blue_sig_str']\n",
    "                                    redCorner_sig_str_percentage = row2['red_sig_str_percentage']\n",
    "                                    blueCorner_sig_str_percentage = row2['blue_sig_str_percentage']\n",
    "                                    redCorner_total_str = row2['red_total_strikes']\n",
    "                                    blueCorner_total_str = row2['blue_total_strikes']\n",
    "                                    redCorner_takedowns = row2['red_takedowns']\n",
    "                                    blueCorner_takedowns = row2['blue_takedowns']\n",
    "                                    redCorner_takedown_percentage = row2['red_takedown_percentage']\n",
    "                                    blueCorner_takedown_percentage = row2['blue_takedown_percentage']\n",
    "                                    redCorner_subs_attempted = row2['red_subs_attempted']\n",
    "                                    blueCorner_subs_attempted = row2['blue_subs_attempted']\n",
    "                                    roundA = row2['round']      \n",
    "                                    time = row2['time'] \n",
    "                                    redCorner_height = row2['redCorner_height']\n",
    "                                    blueCorner_height = row2['blueCorner_height']\n",
    "                                    redCorner_reach = row2['redCorner_reach']\n",
    "                                    blueCorner_reach = row2['blueCorner_reach']\n",
    "                                    redCorner_stance = row2['redCorner_stance']\n",
    "                                    blueCorner_stance = row2['blueCorner_stance']\n",
    "                else:\n",
    "                    fight = row['fight'].split(' vs ')\n",
    "                    fighter1 = str(fight[0]).replace(\" \", \"\").lower()\n",
    "                    fighter2 = str(fight[1]).replace(\" \", \"\").lower()\n",
    "                    redCorner = str(row2['redCorner']).replace(\" \", \"\").lower()\n",
    "                    blueCorner = str(row2['blueCorner']).replace(\" \", \"\").lower()\n",
    "                    winner1 = str(row['winner']).replace(\" \", \"\").lower()\n",
    "                    winner2 = str(row2['winner']).replace(\" \", \"\").lower()\n",
    "                    fighter1 = redCorner\n",
    "                    fighter2 = blueCorner\n",
    "                    if(fighter1 in redCorner or fighter1 in blueCorner or redCorner in fighter1 or blueCorner in fighter1):\n",
    "                        if(fighter2 in redCorner or fighter2 in blueCorner or redCorner in fighter2 or blueCorner in fighter2):\n",
    "                            if(winner1 in winner2 or winner2 in winner1):\n",
    "                                fight = row['fight']\n",
    "                                redCorner = row2['redCorner']\n",
    "                                blueCorner = row2['blueCorner']\n",
    "                                winner = row2['winner']\n",
    "                                event = row2['event']\n",
    "                                referee = row2['referee']\n",
    "                                method_of_vic = row2['method_of_victory']\n",
    "                                date = row['date']\n",
    "                                venue = row['venue']\n",
    "                                title_fight = row['title_fight']\n",
    "                                billing = row['billing']\n",
    "                                if(winner1 in redCorner or redCorner in winner1):\n",
    "                                    redCorner_wins = row['winner_wins']\n",
    "                                    redCorner_losses = row['winner_losses']\n",
    "                                    redCorner_draws = row['winner_draws']\n",
    "                                    redCorner_age = row['winner_age']\n",
    "                                    redCorner_nation = row['winner_nationality']\n",
    "                                    redCorner_fan = row['winner_fan ']\n",
    "                                    blueCorner_wins = row['loser_wins']\n",
    "                                    blueCorner_losses = row['loser_losses']\n",
    "                                    blueCorner_draws = row['loser_draws']\n",
    "                                    blueCorner_age = row['loser_age']\n",
    "                                    blueCorner_nation = row['loser_nationality']\n",
    "                                    blueCorner_fan = row['loser_fan']\n",
    "                                elif(winner1 in blueCorner or blueCorner in winner1):\n",
    "                                    blueCorner_wins = row['winner_wins']\n",
    "                                    blueCorner_losses = row['winner_losses']\n",
    "                                    blueCorner_draws = row['winner_draws']\n",
    "                                    blueCorner_age = row['winner_age']\n",
    "                                    blueCorner_nation = row['winner_nationality']\n",
    "                                    blueCorner_fan = row['winner_fan ']\n",
    "                                    redCorner_wins = row['loser_wins']\n",
    "                                    redCorner_losses = row['loser_losses']\n",
    "                                    redCorner_draws = row['loser_draws']\n",
    "                                    redCorner_age = row['loser_age']\n",
    "                                    redCorner_nation = row['loser_nationality']\n",
    "                                    redCorner_fan = row['loser_fan']\n",
    "                                else:\n",
    "                                    if(fight[0] in redCorner or redCorner in fight[0]):\n",
    "                                        redCorner_wins = row['winner_wins']\n",
    "                                        redCorner_losses = row['winner_losses']\n",
    "                                        redCorner_draws = row['winner_draws']\n",
    "                                        redCorner_age = row['winner_age']\n",
    "                                        redCorner_nation = row['winner_nationality']\n",
    "                                        redCorner_fan = row['winner_fan ']\n",
    "                                        blueCorner_wins = row['loser_wins']\n",
    "                                        blueCorner_losses = row['loser_losses']\n",
    "                                        blueCorner_draws = row['loser_draws']\n",
    "                                        blueCorner_age = row['loser_age']\n",
    "                                        blueCorner_nation = row['loser_nationality']\n",
    "                                        blueCorner_fan = row['loser_fan']\n",
    "                                    if(fight[0] in blueCorner or blueCorner in fight[0]):\n",
    "                                        blueCorner_wins = row['winner_wins']\n",
    "                                        blueCorner_losses = row['winner_losses']\n",
    "                                        blueCorner_draws = row['winner_draws']\n",
    "                                        blueCorner_age = row['winner_age']\n",
    "                                        blueCorner_nation = row['winner_nationality']\n",
    "                                        blueCorner_fan = row['winner_fan ']\n",
    "                                        redCorner_wins = row['loser_wins']\n",
    "                                        redCorner_losses = row['loser_losses']\n",
    "                                        redCorner_draws = row['loser_draws']\n",
    "                                        redCorner_age = row['loser_age']\n",
    "                                        redCorner_nation = row['loser_nationality']\n",
    "                                        redCorner_fan = row['loser_fan']\n",
    "                                redCorner_knockdowns = row2['red_Knockdowns']\n",
    "                                blueCorner_knockdowns = row2['blue_Knockdowns']\n",
    "                                redCorner_sig_str = row2['red_sig_str']\n",
    "                                blueCorner_sig_str = row2['blue_sig_str']\n",
    "                                redCorner_sig_str_percentage = row2['red_sig_str_percentage']\n",
    "                                blueCorner_sig_str_percentage = row2['blue_sig_str_percentage']\n",
    "                                redCorner_total_str = row2['red_total_strikes']\n",
    "                                blueCorner_total_str = row2['blue_total_strikes']\n",
    "                                redCorner_takedowns = row2['red_takedowns']\n",
    "                                blueCorner_takedowns = row2['blue_takedowns']\n",
    "                                redCorner_takedown_percentage = row2['red_takedown_percentage']\n",
    "                                blueCorner_takedown_percentage = row2['blue_takedown_percentage']\n",
    "                                redCorner_subs_attempted = row2['red_subs_attempted']\n",
    "                                blueCorner_subs_attempted = row2['blue_subs_attempted']\n",
    "                                roundA = row2['round']      \n",
    "                                time = row2['time'] \n",
    "                                redCorner_height = row2['redCorner_height']\n",
    "                                blueCorner_height = row2['blueCorner_height']\n",
    "                                redCorner_reach = row2['redCorner_reach']\n",
    "                                blueCorner_reach = row2['blueCorner_reach']\n",
    "                                redCorner_stance = row2['redCorner_stance']\n",
    "                                blueCorner_stance = row2['blueCorner_stance']\n",
    "        else:\n",
    "            fight = row['fight'].split(' vs ')\n",
    "            fighter1 = str(fight[0]).replace(\" \", \"\").lower()\n",
    "            fighter2 = str(fight[1]).replace(\" \", \"\").lower()\n",
    "            redCorner = str(row2['redCorner']).replace(\" \", \"\").lower()\n",
    "            blueCorner = str(row2['blueCorner']).replace(\" \", \"\").lower()\n",
    "            winner1 = str(row['winner']).replace(\" \", \"\").lower()\n",
    "            winner2 = str(row2['winner']).replace(\" \", \"\").lower()\n",
    "            if(fighter1 in redCorner or fighter1 in blueCorner or redCorner in fighter1 or blueCorner in fighter1):\n",
    "                if(fighter2 in redCorner or fighter2 in blueCorner or redCorner in fighter2 or blueCorner in fighter2):\n",
    "                    if(winner1 in winner2 or winner2 in winner1):\n",
    "                        fight = row['fight']\n",
    "                        redCorner = row2['redCorner']\n",
    "                        blueCorner = row2['blueCorner']\n",
    "                        winner = row2['winner']\n",
    "                        event = row2['event']\n",
    "                        referee = row2['referee']\n",
    "                        method_of_vic = row2['method_of_victory']\n",
    "                        date = row['date']\n",
    "                        venue = row['venue']\n",
    "                        title_fight = row['title_fight']\n",
    "                        billing = row['billing']\n",
    "                        if(winner1 in redCorner or redCorner in winner1):\n",
    "                            redCorner_wins = row['winner_wins']\n",
    "                            redCorner_losses = row['winner_losses']\n",
    "                            redCorner_draws = row['winner_draws']\n",
    "                            redCorner_age = row['winner_age']\n",
    "                            redCorner_nation = row['winner_nationality']\n",
    "                            redCorner_fan = row['winner_fan ']\n",
    "                            blueCorner_wins = row['loser_wins']\n",
    "                            blueCorner_losses = row['loser_losses']\n",
    "                            blueCorner_draws = row['loser_draws']\n",
    "                            blueCorner_age = row['loser_age']\n",
    "                            blueCorner_nation = row['loser_nationality']\n",
    "                            blueCorner_fan = row['loser_fan']\n",
    "                        elif(winner1 in blueCorner or blueCorner in winner1):\n",
    "                            blueCorner_wins = row['winner_wins']\n",
    "                            blueCorner_losses = row['winner_losses']\n",
    "                            blueCorner_draws = row['winner_draws']\n",
    "                            blueCorner_age = row['winner_age']\n",
    "                            blueCorner_nation = row['winner_nationality']\n",
    "                            blueCorner_fan = row['winner_fan ']\n",
    "                            redCorner_wins = row['loser_wins']\n",
    "                            redCorner_losses = row['loser_losses']\n",
    "                            redCorner_draws = row['loser_draws']\n",
    "                            redCorner_age = row['loser_age']\n",
    "                            redCorner_nation = row['loser_nationality']\n",
    "                            redCorner_fan = row['loser_fan']\n",
    "                        else:\n",
    "                            if(fight[0] in redCorner or redCorner in fight[0]):\n",
    "                                redCorner_wins = row['winner_wins']\n",
    "                                redCorner_losses = row['winner_losses']\n",
    "                                redCorner_draws = row['winner_draws']\n",
    "                                redCorner_age = row['winner_age']\n",
    "                                redCorner_nation = row['winner_nationality']\n",
    "                                redCorner_fan = row['winner_fan ']\n",
    "                                blueCorner_wins = row['loser_wins']\n",
    "                                blueCorner_losses = row['loser_losses']\n",
    "                                blueCorner_draws = row['loser_draws']\n",
    "                                blueCorner_age = row['loser_age']\n",
    "                                blueCorner_nation = row['loser_nationality']\n",
    "                                blueCorner_fan = row['loser_fan']\n",
    "                            if(fight[0] in blueCorner or blueCorner in fight[0]):\n",
    "                                blueCorner_wins = row['winner_wins']\n",
    "                                blueCorner_losses = row['winner_losses']\n",
    "                                blueCorner_draws = row['winner_draws']\n",
    "                                blueCorner_age = row['winner_age']\n",
    "                                blueCorner_nation = row['winner_nationality']\n",
    "                                blueCorner_fan = row['winner_fan ']\n",
    "                                redCorner_wins = row['loser_wins']\n",
    "                                redCorner_losses = row['loser_losses']\n",
    "                                redCorner_draws = row['loser_draws']\n",
    "                                redCorner_age = row['loser_age']\n",
    "                                redCorner_nation = row['loser_nationality']\n",
    "                                redCorner_fan = row['loser_fan']\n",
    "                        redCorner_knockdowns = row2['red_Knockdowns']\n",
    "                        blueCorner_knockdowns = row2['blue_Knockdowns']\n",
    "                        redCorner_sig_str = row2['red_sig_str']\n",
    "                        blueCorner_sig_str = row2['blue_sig_str']\n",
    "                        redCorner_sig_str_percentage = row2['red_sig_str_percentage']\n",
    "                        blueCorner_sig_str_percentage = row2['blue_sig_str_percentage']\n",
    "                        redCorner_total_str = row2['red_total_strikes']\n",
    "                        blueCorner_total_str = row2['blue_total_strikes']\n",
    "                        redCorner_takedowns = row2['red_takedowns']\n",
    "                        blueCorner_takedowns = row2['blue_takedowns']\n",
    "                        redCorner_takedown_percentage = row2['red_takedown_percentage']\n",
    "                        blueCorner_takedown_percentage = row2['blue_takedown_percentage']\n",
    "                        redCorner_subs_attempted = row2['red_subs_attempted']\n",
    "                        blueCorner_subs_attempted = row2['blue_subs_attempted']\n",
    "                        roundA = row2['round']      \n",
    "                        time = row2['time'] \n",
    "                        redCorner_height = row2['redCorner_height']\n",
    "                        blueCorner_height = row2['blueCorner_height']\n",
    "                        redCorner_reach = row2['redCorner_reach']\n",
    "                        blueCorner_reach = row2['blueCorner_reach']\n",
    "                        redCorner_stance = row2['redCorner_stance']\n",
    "                        blueCorner_stance = row2['blueCorner_stance'] \n",
    "                else:\n",
    "                    fight = row['fight'].split(' vs ')\n",
    "                    fighter1 = str(fight[0]).replace(\" \", \"\").lower()\n",
    "                    fighter2 = str(fight[1]).replace(\" \", \"\").lower()\n",
    "                    redCorner = str(row2['redCorner']).replace(\" \", \"\").lower()\n",
    "                    blueCorner = str(row2['blueCorner']).replace(\" \", \"\").lower()\n",
    "                    winner1 = str(row['winner']).replace(\" \", \"\").lower()\n",
    "                    winner2 = str(row2['winner']).replace(\" \", \"\").lower()\n",
    "                    fighter1 = redCorner\n",
    "                    fighter2 = blueCorner\n",
    "                    if(fighter1 in redCorner or fighter1 in blueCorner or redCorner in fighter1 or blueCorner in fighter1):\n",
    "                        if(fighter2 in redCorner or fighter2 in blueCorner or redCorner in fighter2 or blueCorner in fighter2):\n",
    "                            if(winner1 in winner2 or winner2 in winner1):\n",
    "                                fight = row['fight']\n",
    "                                redCorner = row2['redCorner']\n",
    "                                blueCorner = row2['blueCorner']\n",
    "                                winner = row2['winner']\n",
    "                                event = row2['event']\n",
    "                                referee = row2['referee']\n",
    "                                method_of_vic = row2['method_of_victory']\n",
    "                                date = row['date']\n",
    "                                venue = row['venue']\n",
    "                                title_fight = row['title_fight']\n",
    "                                billing = row['billing']\n",
    "                                if(winner1 in redCorner or redCorner in winner1):\n",
    "                                    redCorner_wins = row['winner_wins']\n",
    "                                    redCorner_losses = row['winner_losses']\n",
    "                                    redCorner_draws = row['winner_draws']\n",
    "                                    redCorner_age = row['winner_age']\n",
    "                                    redCorner_nation = row['winner_nationality']\n",
    "                                    redCorner_fan = row['winner_fan ']\n",
    "                                    blueCorner_wins = row['loser_wins']\n",
    "                                    blueCorner_losses = row['loser_losses']\n",
    "                                    blueCorner_draws = row['loser_draws']\n",
    "                                    blueCorner_age = row['loser_age']\n",
    "                                    blueCorner_nation = row['loser_nationality']\n",
    "                                    blueCorner_fan = row['loser_fan']\n",
    "                                elif(winner1 in blueCorner or blueCorner in winner1):\n",
    "                                    blueCorner_wins = row['winner_wins']\n",
    "                                    blueCorner_losses = row['winner_losses']\n",
    "                                    blueCorner_draws = row['winner_draws']\n",
    "                                    blueCorner_age = row['winner_age']\n",
    "                                    blueCorner_nation = row['winner_nationality']\n",
    "                                    blueCorner_fan = row['winner_fan ']\n",
    "                                    redCorner_wins = row['loser_wins']\n",
    "                                    redCorner_losses = row['loser_losses']\n",
    "                                    redCorner_draws = row['loser_draws']\n",
    "                                    redCorner_age = row['loser_age']\n",
    "                                    redCorner_nation = row['loser_nationality']\n",
    "                                    redCorner_fan = row['loser_fan']\n",
    "                                else:\n",
    "                                    if(fight[0] in redCorner or redCorner in fight[0]):\n",
    "                                        redCorner_wins = row['winner_wins']\n",
    "                                        redCorner_losses = row['winner_losses']\n",
    "                                        redCorner_draws = row['winner_draws']\n",
    "                                        redCorner_age = row['winner_age']\n",
    "                                        redCorner_nation = row['winner_nationality']\n",
    "                                        redCorner_fan = row['winner_fan ']\n",
    "                                        blueCorner_wins = row['loser_wins']\n",
    "                                        blueCorner_losses = row['loser_losses']\n",
    "                                        blueCorner_draws = row['loser_draws']\n",
    "                                        blueCorner_age = row['loser_age']\n",
    "                                        blueCorner_nation = row['loser_nationality']\n",
    "                                        blueCorner_fan = row['loser_fan']\n",
    "                                    if(fight[0] in blueCorner or blueCorner in fight[0]):\n",
    "                                        blueCorner_wins = row['winner_wins']\n",
    "                                        blueCorner_losses = row['winner_losses']\n",
    "                                        blueCorner_draws = row['winner_draws']\n",
    "                                        blueCorner_age = row['winner_age']\n",
    "                                        blueCorner_nation = row['winner_nationality']\n",
    "                                        blueCorner_fan = row['winner_fan ']\n",
    "                                        redCorner_wins = row['loser_wins']\n",
    "                                        redCorner_losses = row['loser_losses']\n",
    "                                        redCorner_draws = row['loser_draws']\n",
    "                                        redCorner_age = row['loser_age']\n",
    "                                        redCorner_nation = row['loser_nationality']\n",
    "                                        redCorner_fan = row['loser_fan']\n",
    "                                redCorner_knockdowns = row2['red_Knockdowns']\n",
    "                                blueCorner_knockdowns = row2['blue_Knockdowns']\n",
    "                                redCorner_sig_str = row2['red_sig_str']\n",
    "                                blueCorner_sig_str = row2['blue_sig_str']\n",
    "                                redCorner_sig_str_percentage = row2['red_sig_str_percentage']\n",
    "                                blueCorner_sig_str_percentage = row2['blue_sig_str_percentage']\n",
    "                                redCorner_total_str = row2['red_total_strikes']\n",
    "                                blueCorner_total_str = row2['blue_total_strikes']\n",
    "                                redCorner_takedowns = row2['red_takedowns']\n",
    "                                blueCorner_takedowns = row2['blue_takedowns']\n",
    "                                redCorner_takedown_percentage = row2['red_takedown_percentage']\n",
    "                                blueCorner_takedown_percentage = row2['blue_takedown_percentage']\n",
    "                                redCorner_subs_attempted = row2['red_subs_attempted']\n",
    "                                blueCorner_subs_attempted = row2['blue_subs_attempted']\n",
    "                                roundA = row2['round']      \n",
    "                                time = row2['time'] \n",
    "                                redCorner_height = row2['redCorner_height']\n",
    "                                blueCorner_height = row2['blueCorner_height']\n",
    "                                redCorner_reach = row2['redCorner_reach']\n",
    "                                blueCorner_reach = row2['blueCorner_reach']\n",
    "                                redCorner_stance = row2['redCorner_stance']\n",
    "                                blueCorner_stance = row2['blueCorner_stance']\n",
    "            else:\n",
    "                fight = row['fight'].split(' vs ')\n",
    "                fighter1 = str(fight[0]).replace(\" \", \"\").lower()\n",
    "                fighter2 = str(fight[1]).replace(\" \", \"\").lower()\n",
    "                redCorner = str(row2['redCorner']).replace(\" \", \"\").lower()\n",
    "                blueCorner = str(row2['blueCorner']).replace(\" \", \"\").lower()\n",
    "                winner1 = str(row['winner']).replace(\" \", \"\").lower()\n",
    "                winner2 = str(row2['winner']).replace(\" \", \"\").lower()\n",
    "                fighter1 = redCorner\n",
    "                fighter2 = blueCorner\n",
    "                if(fighter1 in redCorner or fighter1 in blueCorner or redCorner in fighter1 or blueCorner in fighter1):\n",
    "                    if(fighter2 in redCorner or fighter2 in blueCorner or redCorner in fighter2 or blueCorner in fighter2):\n",
    "                        if(winner1 in winner2 or winner2 in winner1):\n",
    "                            fight = row['fight']\n",
    "                            redCorner = row2['redCorner']\n",
    "                            blueCorner = row2['blueCorner']\n",
    "                            winner = row2['winner']\n",
    "                            event = row2['event']\n",
    "                            referee = row2['referee']\n",
    "                            method_of_vic = row2['method_of_victory']\n",
    "                            date = row['date']\n",
    "                            venue = row['venue']\n",
    "                            title_fight = row['title_fight']\n",
    "                            billing = row['billing']\n",
    "                            if(winner1 in redCorner or redCorner in winner1):\n",
    "                                redCorner_wins = row['winner_wins']\n",
    "                                redCorner_losses = row['winner_losses']\n",
    "                                redCorner_draws = row['winner_draws']\n",
    "                                redCorner_age = row['winner_age']\n",
    "                                redCorner_nation = row['winner_nationality']\n",
    "                                redCorner_fan = row['winner_fan ']\n",
    "                                blueCorner_wins = row['loser_wins']\n",
    "                                blueCorner_losses = row['loser_losses']\n",
    "                                blueCorner_draws = row['loser_draws']\n",
    "                                blueCorner_age = row['loser_age']\n",
    "                                blueCorner_nation = row['loser_nationality']\n",
    "                                blueCorner_fan = row['loser_fan']\n",
    "                            elif(winner1 in blueCorner or blueCorner in winner1):\n",
    "                                blueCorner_wins = row['winner_wins']\n",
    "                                blueCorner_losses = row['winner_losses']\n",
    "                                blueCorner_draws = row['winner_draws']\n",
    "                                blueCorner_age = row['winner_age']\n",
    "                                blueCorner_nation = row['winner_nationality']\n",
    "                                blueCorner_fan = row['winner_fan ']\n",
    "                                redCorner_wins = row['loser_wins']\n",
    "                                redCorner_losses = row['loser_losses']\n",
    "                                redCorner_draws = row['loser_draws']\n",
    "                                redCorner_age = row['loser_age']\n",
    "                                redCorner_nation = row['loser_nationality']\n",
    "                                redCorner_fan = row['loser_fan']\n",
    "                            else:\n",
    "                                if(fight[0] in redCorner or redCorner in fight[0]):\n",
    "                                    redCorner_wins = row['winner_wins']\n",
    "                                    redCorner_losses = row['winner_losses']\n",
    "                                    redCorner_draws = row['winner_draws']\n",
    "                                    redCorner_age = row['winner_age']\n",
    "                                    redCorner_nation = row['winner_nationality']\n",
    "                                    redCorner_fan = row['winner_fan ']\n",
    "                                    blueCorner_wins = row['loser_wins']\n",
    "                                    blueCorner_losses = row['loser_losses']\n",
    "                                    blueCorner_draws = row['loser_draws']\n",
    "                                    blueCorner_age = row['loser_age']\n",
    "                                    blueCorner_nation = row['loser_nationality']\n",
    "                                    blueCorner_fan = row['loser_fan']\n",
    "                                if(fight[0] in blueCorner or blueCorner in fight[0]):\n",
    "                                    blueCorner_wins = row['winner_wins']\n",
    "                                    blueCorner_losses = row['winner_losses']\n",
    "                                    blueCorner_draws = row['winner_draws']\n",
    "                                    blueCorner_age = row['winner_age']\n",
    "                                    blueCorner_nation = row['winner_nationality']\n",
    "                                    blueCorner_fan = row['winner_fan ']\n",
    "                                    redCorner_wins = row['loser_wins']\n",
    "                                    redCorner_losses = row['loser_losses']\n",
    "                                    redCorner_draws = row['loser_draws']\n",
    "                                    redCorner_age = row['loser_age']\n",
    "                                    redCorner_nation = row['loser_nationality']\n",
    "                                    redCorner_fan = row['loser_fan']\n",
    "                            redCorner_knockdowns = row2['red_Knockdowns']\n",
    "                            blueCorner_knockdowns = row2['blue_Knockdowns']\n",
    "                            redCorner_sig_str = row2['red_sig_str']\n",
    "                            blueCorner_sig_str = row2['blue_sig_str']\n",
    "                            redCorner_sig_str_percentage = row2['red_sig_str_percentage']\n",
    "                            blueCorner_sig_str_percentage = row2['blue_sig_str_percentage']\n",
    "                            redCorner_total_str = row2['red_total_strikes']\n",
    "                            blueCorner_total_str = row2['blue_total_strikes']\n",
    "                            redCorner_takedowns = row2['red_takedowns']\n",
    "                            blueCorner_takedowns = row2['blue_takedowns']\n",
    "                            redCorner_takedown_percentage = row2['red_takedown_percentage']\n",
    "                            blueCorner_takedown_percentage = row2['blue_takedown_percentage']\n",
    "                            redCorner_subs_attempted = row2['red_subs_attempted']\n",
    "                            blueCorner_subs_attempted = row2['blue_subs_attempted']\n",
    "                            roundA = row2['round']      \n",
    "                            time = row2['time'] \n",
    "                            redCorner_height = row2['redCorner_height']\n",
    "                            blueCorner_height = row2['blueCorner_height']\n",
    "                            redCorner_reach = row2['redCorner_reach']\n",
    "                            blueCorner_reach = row2['blueCorner_reach']\n",
    "                            redCorner_stance = row2['redCorner_stance']\n",
    "                            blueCorner_stance = row2['blueCorner_stance']                          \n",
    "    column_vals = {\n",
    "        'fight': fight,\n",
    "        'redCorner': redCorner,\n",
    "        'blueCorner': blueCorner,\n",
    "        'winner': winner,\n",
    "        'event': event,\n",
    "        'referee': referee,\n",
    "        'method_of_victory': method_of_vic,\n",
    "        'date': date,\n",
    "        'venue': venue,\n",
    "        'title_fight': title_fight,\n",
    "        'billing': billing,\n",
    "        'redCorner_wins': redCorner_wins,\n",
    "        'blueCorner_wins': blueCorner_wins,\n",
    "        'redCorner_losses': redCorner_losses,\n",
    "        'blueCorner_losses': blueCorner_losses,\n",
    "        'redCorner_draws': redCorner_draws,\n",
    "        'blueCorner_draws': blueCorner_draws,\n",
    "        'redCorner_age': redCorner_age,\n",
    "        'blueCorner_age': blueCorner_age,\n",
    "        'redCorner_nation': redCorner_nation,\n",
    "        'blueCorner_nation': blueCorner_nation,\n",
    "        'redCorner_fan': redCorner_fan,\n",
    "        'blueCorner_fan': blueCorner_fan,\n",
    "        'redCorner_knockdowns': redCorner_knockdowns,\n",
    "        'blueCorner_knockdowns': blueCorner_knockdowns,\n",
    "        'redCorner_sig_str': redCorner_sig_str,\n",
    "        'blueCorner_sig_str': blueCorner_sig_str,\n",
    "        'redCorner_sig_str_percentage': redCorner_sig_str_percentage,\n",
    "        'blueCorner_sig_str_percentage': blueCorner_sig_str_percentage,\n",
    "        'redCorner_total_str': redCorner_total_str,\n",
    "        'blueCorner_total_str': blueCorner_total_str,\n",
    "        'redCorner_takedowns': redCorner_takedowns,\n",
    "        'blueCorner_takedowns': blueCorner_takedowns,\n",
    "        'redCorner_takedown_percentage': redCorner_takedown_percentage,\n",
    "        'blueCorner_takedown_percentage': blueCorner_takedown_percentage,\n",
    "        'redCorner_subs_attempted': redCorner_subs_attempted,\n",
    "        'blueCorner_subs_attempted': blueCorner_subs_attempted,\n",
    "        'round': roundA,\n",
    "        'time': time,\n",
    "        'redCorner_height': redCorner_height,\n",
    "        'blueCorner_height': blueCorner_height,\n",
    "        'redCorner_reach': redCorner_reach,\n",
    "        'blueCorner_reach': blueCorner_reach,\n",
    "        'redCorner_stance': redCorner_stance,\n",
    "        'blueCorner_stance': blueCorner_stance\n",
    "    }\n",
    "    dfNew.loc[len(dfNew)] = column_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fight</th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>event</th>\n",
       "      <th>referee</th>\n",
       "      <th>method_of_victory</th>\n",
       "      <th>date</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>...</th>\n",
       "      <th>redCorner_subs_attempted</th>\n",
       "      <th>blueCorner_subs_attempted</th>\n",
       "      <th>round</th>\n",
       "      <th>time</th>\n",
       "      <th>redCorner_height</th>\n",
       "      <th>blueCorner_height</th>\n",
       "      <th>redCorner_reach</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex Pereira vs Khalil Rountree Jr</td>\n",
       "      <td>Alex Pereira</td>\n",
       "      <td>Khalil Rountree Jr</td>\n",
       "      <td>Alex Pereira</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Marc Goddard</td>\n",
       "      <td>KO/TKO</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4:32</td>\n",
       "      <td>6' 4\"</td>\n",
       "      <td>6' 1\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raquel Pennington vs Julianna Pena</td>\n",
       "      <td>Raquel Pennington</td>\n",
       "      <td>Julianna Pena</td>\n",
       "      <td>Julianna Pena</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Jason Herzog</td>\n",
       "      <td>Decision - Split</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>67\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jose Aldo vs Mario Bautista</td>\n",
       "      <td>Jose Aldo</td>\n",
       "      <td>Mario Bautista</td>\n",
       "      <td>Mario Bautista</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Mike Beltran</td>\n",
       "      <td>Decision - Split</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>70\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roman Dolidze vs Kevin Holland</td>\n",
       "      <td>Roman Dolidze</td>\n",
       "      <td>Kevin Holland</td>\n",
       "      <td>Roman Dolidze</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Jason Herzog</td>\n",
       "      <td>KO/TKO</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5:00</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kayla Harrison vs Ketlen Vieira</td>\n",
       "      <td>Ketlen Vieira</td>\n",
       "      <td>Kayla Harrison</td>\n",
       "      <td>Kayla Harrison</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Marc Goddard</td>\n",
       "      <td>Decision - Unanimous</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>68\"</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                fight          redCorner          blueCorner  \\\n",
       "0  Alex Pereira vs Khalil Rountree Jr       Alex Pereira  Khalil Rountree Jr   \n",
       "1  Raquel Pennington vs Julianna Pena  Raquel Pennington       Julianna Pena   \n",
       "2         Jose Aldo vs Mario Bautista          Jose Aldo      Mario Bautista   \n",
       "3      Roman Dolidze vs Kevin Holland      Roman Dolidze       Kevin Holland   \n",
       "4     Kayla Harrison vs Ketlen Vieira      Ketlen Vieira      Kayla Harrison   \n",
       "\n",
       "           winner                              event       referee  \\\n",
       "0    Alex Pereira  UFC 307: Pereira vs. Rountree Jr.  Marc Goddard   \n",
       "1   Julianna Pena  UFC 307: Pereira vs. Rountree Jr.  Jason Herzog   \n",
       "2  Mario Bautista  UFC 307: Pereira vs. Rountree Jr.  Mike Beltran   \n",
       "3   Roman Dolidze  UFC 307: Pereira vs. Rountree Jr.  Jason Herzog   \n",
       "4  Kayla Harrison  UFC 307: Pereira vs. Rountree Jr.  Marc Goddard   \n",
       "\n",
       "      method_of_victory        date         venue title_fight  ...  \\\n",
       "0                KO/TKO  10.05.2024  Delta Center         yes  ...   \n",
       "1      Decision - Split  10.05.2024  Delta Center         yes  ...   \n",
       "2      Decision - Split  10.05.2024  Delta Center          no  ...   \n",
       "3                KO/TKO  10.05.2024  Delta Center          no  ...   \n",
       "4  Decision - Unanimous  10.05.2024  Delta Center          no  ...   \n",
       "\n",
       "  redCorner_subs_attempted blueCorner_subs_attempted round  time  \\\n",
       "0                        0                         0     4  4:32   \n",
       "1                        0                         1     5  5:00   \n",
       "2                        0                         0     3  5:00   \n",
       "3                        0                         0     1  5:00   \n",
       "4                        0                         0     3  5:00   \n",
       "\n",
       "   redCorner_height  blueCorner_height  redCorner_reach  blueCorner_reach  \\\n",
       "0             6' 4\"              6' 1\"              79\"               76\"   \n",
       "1             5' 7\"              5' 6\"              67\"               69\"   \n",
       "2             5' 7\"              5' 9\"              70\"               69\"   \n",
       "3             6' 2\"              6' 3\"              76\"               81\"   \n",
       "4             5' 8\"              5' 8\"              68\"               66\"   \n",
       "\n",
       "   redCorner_stance blueCorner_stance  \n",
       "0          Orthodox          Southpaw  \n",
       "1          Orthodox          Orthodox  \n",
       "2          Orthodox            Switch  \n",
       "3          Orthodox          Orthodox  \n",
       "4          Orthodox          Southpaw  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write df to csv\n",
    "dfNew.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fight</th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>event</th>\n",
       "      <th>referee</th>\n",
       "      <th>method_of_victory</th>\n",
       "      <th>date</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>...</th>\n",
       "      <th>redCorner_subs_attempted</th>\n",
       "      <th>blueCorner_subs_attempted</th>\n",
       "      <th>round</th>\n",
       "      <th>time</th>\n",
       "      <th>redCorner_height</th>\n",
       "      <th>blueCorner_height</th>\n",
       "      <th>redCorner_reach</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex Pereira vs Khalil Rountree Jr</td>\n",
       "      <td>Alex Pereira</td>\n",
       "      <td>Khalil Rountree Jr</td>\n",
       "      <td>Alex Pereira</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Marc Goddard</td>\n",
       "      <td>KO/TKO</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4:32</td>\n",
       "      <td>6' 4\"</td>\n",
       "      <td>6' 1\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raquel Pennington vs Julianna Pena</td>\n",
       "      <td>Raquel Pennington</td>\n",
       "      <td>Julianna Pena</td>\n",
       "      <td>Julianna Pena</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Jason Herzog</td>\n",
       "      <td>Decision - Split</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>67\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jose Aldo vs Mario Bautista</td>\n",
       "      <td>Jose Aldo</td>\n",
       "      <td>Mario Bautista</td>\n",
       "      <td>Mario Bautista</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Mike Beltran</td>\n",
       "      <td>Decision - Split</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>70\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roman Dolidze vs Kevin Holland</td>\n",
       "      <td>Roman Dolidze</td>\n",
       "      <td>Kevin Holland</td>\n",
       "      <td>Roman Dolidze</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Jason Herzog</td>\n",
       "      <td>KO/TKO</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5:00</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kayla Harrison vs Ketlen Vieira</td>\n",
       "      <td>Ketlen Vieira</td>\n",
       "      <td>Kayla Harrison</td>\n",
       "      <td>Kayla Harrison</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Marc Goddard</td>\n",
       "      <td>Decision - Unanimous</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>68\"</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                fight          redCorner          blueCorner  \\\n",
       "0  Alex Pereira vs Khalil Rountree Jr       Alex Pereira  Khalil Rountree Jr   \n",
       "1  Raquel Pennington vs Julianna Pena  Raquel Pennington       Julianna Pena   \n",
       "2         Jose Aldo vs Mario Bautista          Jose Aldo      Mario Bautista   \n",
       "3      Roman Dolidze vs Kevin Holland      Roman Dolidze       Kevin Holland   \n",
       "4     Kayla Harrison vs Ketlen Vieira      Ketlen Vieira      Kayla Harrison   \n",
       "\n",
       "           winner                              event       referee  \\\n",
       "0    Alex Pereira  UFC 307: Pereira vs. Rountree Jr.  Marc Goddard   \n",
       "1   Julianna Pena  UFC 307: Pereira vs. Rountree Jr.  Jason Herzog   \n",
       "2  Mario Bautista  UFC 307: Pereira vs. Rountree Jr.  Mike Beltran   \n",
       "3   Roman Dolidze  UFC 307: Pereira vs. Rountree Jr.  Jason Herzog   \n",
       "4  Kayla Harrison  UFC 307: Pereira vs. Rountree Jr.  Marc Goddard   \n",
       "\n",
       "      method_of_victory        date         venue title_fight  ...  \\\n",
       "0                KO/TKO  10.05.2024  Delta Center         yes  ...   \n",
       "1      Decision - Split  10.05.2024  Delta Center         yes  ...   \n",
       "2      Decision - Split  10.05.2024  Delta Center          no  ...   \n",
       "3                KO/TKO  10.05.2024  Delta Center          no  ...   \n",
       "4  Decision - Unanimous  10.05.2024  Delta Center          no  ...   \n",
       "\n",
       "  redCorner_subs_attempted blueCorner_subs_attempted round  time  \\\n",
       "0                        0                         0     4  4:32   \n",
       "1                        0                         1     5  5:00   \n",
       "2                        0                         0     3  5:00   \n",
       "3                        0                         0     1  5:00   \n",
       "4                        0                         0     3  5:00   \n",
       "\n",
       "   redCorner_height  blueCorner_height  redCorner_reach  blueCorner_reach  \\\n",
       "0             6' 4\"              6' 1\"              79\"               76\"   \n",
       "1             5' 7\"              5' 6\"              67\"               69\"   \n",
       "2             5' 7\"              5' 9\"              70\"               69\"   \n",
       "3             6' 2\"              6' 3\"              76\"               81\"   \n",
       "4             5' 8\"              5' 8\"              68\"               66\"   \n",
       "\n",
       "   redCorner_stance blueCorner_stance  \n",
       "0          Orthodox          Southpaw  \n",
       "1          Orthodox          Orthodox  \n",
       "2          Orthodox            Switch  \n",
       "3          Orthodox          Orthodox  \n",
       "4          Orthodox          Southpaw  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write new data to top of csv\n",
    "dfOld = pd.read_csv(f'databaseUpdated{mostRecentDatabase}.csv')\n",
    "\n",
    "updatedData = pd.concat([dfNew, dfOld], ignore_index=True)\n",
    "\n",
    "updatedData.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get current date to track day of update\n",
    "dateToday = datetime.datetime.today().date()\n",
    "\n",
    "#df to csv file\n",
    "updatedData.to_csv(f'databaseUpdated{dateToday}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fighters Found: 4258\n",
      "Scraping Tom Aaron...\n",
      "http://ufcstats.com/fighter-details/93fe7332d16c6ad9\n",
      "Scraping Danny Abbadi...\n",
      "http://ufcstats.com/fighter-details/15df64c02b6b0fde\n",
      "Scraping Nariman Abbasov...\n",
      "http://ufcstats.com/fighter-details/59a9d6dac61c2540\n",
      "Scraping David Abbott...\n",
      "http://ufcstats.com/fighter-details/b361180739bed4b0\n",
      "Scraping Hamdy Abdelwahab...\n",
      "http://ufcstats.com/fighter-details/3329d692aea4dc28\n",
      "Scraping Mansur Abdul-Malik...\n",
      "http://ufcstats.com/fighter-details/841695e02c99a521\n",
      "Scraping Shamil Abdurakhimov...\n",
      "http://ufcstats.com/fighter-details/2f5cbecbbe18bac4\n",
      "Scraping Hiroyuki Abe...\n",
      "http://ufcstats.com/fighter-details/c0ed7b208197e8de\n",
      "Scraping Daichi Abe...\n",
      "http://ufcstats.com/fighter-details/5140122c3eecd307\n",
      "Scraping Papy Abedi...\n",
      "http://ufcstats.com/fighter-details/c9f6385af6df66d7\n",
      "Scraping Ricardo Abreu...\n",
      "http://ufcstats.com/fighter-details/aa6e591c2a2cdecd\n",
      "Scraping Klidson Abreu...\n",
      "http://ufcstats.com/fighter-details/7279654c7674cd24\n",
      "Scraping Cyborg Abreu...\n",
      "http://ufcstats.com/fighter-details/f689bd7bbd14b392\n",
      "Scraping Daniel Acacio...\n",
      "http://ufcstats.com/fighter-details/1c5879330d42255f\n",
      "Scraping John Adajar...\n",
      "http://ufcstats.com/fighter-details/989b85f6540c86b1\n",
      "Scraping Scott Adams...\n",
      "http://ufcstats.com/fighter-details/2620f3eb21c79614\n",
      "Scraping Juan Adams...\n",
      "http://ufcstats.com/fighter-details/83b00f7597e5ac83\n",
      "Scraping Anthony Adams...\n",
      "http://ufcstats.com/fighter-details/a77633a989013265\n",
      "Scraping Zarrukh Adashev...\n",
      "http://ufcstats.com/fighter-details/79cb2a690b9ba5e8\n",
      "Scraping Israel Adesanya...\n",
      "http://ufcstats.com/fighter-details/1338e2c7480bdf9e\n",
      "Scraping Sam Adkins...\n",
      "http://ufcstats.com/fighter-details/0e9869d712e81f8f\n",
      "Scraping Mohamed Ado...\n",
      "http://ufcstats.com/fighter-details/7a846fcbf182a7c8\n",
      "Scraping Nick Agallar...\n",
      "http://ufcstats.com/fighter-details/ebc5af72ad5a28cb\n",
      "Scraping Mariya Agapova...\n",
      "http://ufcstats.com/fighter-details/a08ddd04eaffd81d\n",
      "Scraping Kantharaj Agasa...\n",
      "http://ufcstats.com/fighter-details/26f4288e83188c61\n",
      "Scraping Marcelo Aguiar...\n",
      "http://ufcstats.com/fighter-details/44aa652b181bcf68\n",
      "Scraping Fabio Aguiar...\n",
      "http://ufcstats.com/fighter-details/501821d7fb7b95c1\n",
      "Scraping Edwin Aguilar...\n",
      "http://ufcstats.com/fighter-details/6cadc0a0ba7dc015\n",
      "Scraping Jessica Aguilar...\n",
      "http://ufcstats.com/fighter-details/8f382b3baa954d2a\n",
      "Scraping Kevin Aguilar...\n",
      "http://ufcstats.com/fighter-details/cf946e03ba2e7666\n",
      "Scraping Jesus Aguilar...\n",
      "http://ufcstats.com/fighter-details/c051c2e12d692b8a\n",
      "Scraping Christian Aguilera...\n",
      "http://ufcstats.com/fighter-details/ae071698e1a3ccd4\n",
      "Scraping Nick Aguirre...\n",
      "http://ufcstats.com/fighter-details/0978385b2bd9ef9b\n",
      "Scraping Mike Aina...\n",
      "http://ufcstats.com/fighter-details/9e3dbb9c68ed5d1a\n",
      "Scraping Ashiek Ajim...\n",
      "http://ufcstats.com/fighter-details/49dea784f6cfed71\n",
      "Scraping Hitomi Akano...\n",
      "http://ufcstats.com/fighter-details/2eada40ac8801559\n",
      "Scraping Omari Akhmedov...\n",
      "http://ufcstats.com/fighter-details/16690d100f995f8f\n",
      "Scraping Yoshihiro Akiyama...\n",
      "http://ufcstats.com/fighter-details/b0550072e5f0afa7\n",
      "Scraping Rostem Akman...\n",
      "http://ufcstats.com/fighter-details/1fc64507a0cb38cf\n",
      "Scraping Razak Al-Hassan...\n",
      "http://ufcstats.com/fighter-details/38b50fd1e1b5b656\n",
      "Scraping Abdul-Kareem Al-Selwady...\n",
      "http://ufcstats.com/fighter-details/597499ac7a5aac62\n",
      "Scraping Mostapha Al-Turk...\n",
      "http://ufcstats.com/fighter-details/1cf1310684a841f5\n",
      "Scraping Herdem Alacabek...\n",
      "http://ufcstats.com/fighter-details/7578cc6bd750206b\n",
      "Scraping Javi Alanis...\n",
      "http://ufcstats.com/fighter-details/2144954270be834d\n",
      "Scraping Alatengheili...\n",
      "http://ufcstats.com/fighter-details/1897b7b913736a7c\n",
      "Scraping Amir Albazi...\n",
      "http://ufcstats.com/fighter-details/6d35bf94f7d30241\n",
      "Scraping Brett Albee...\n",
      "http://ufcstats.com/fighter-details/9b28292abe3166d5\n",
      "Scraping John Albert...\n",
      "http://ufcstats.com/fighter-details/7bd94b60d7521e4a\n",
      "Scraping Junior Albini...\n",
      "http://ufcstats.com/fighter-details/c482c8605455a213\n",
      "Scraping Wes Albritton...\n",
      "http://ufcstats.com/fighter-details/184b955181bdef52\n",
      "Scraping Aleksandra Albu...\n",
      "http://ufcstats.com/fighter-details/e76d9f656ceb82ab\n",
      "Scraping Israel Albuquerque...\n",
      "http://ufcstats.com/fighter-details/dd1b90eea08887f6\n",
      "Scraping Juan Alcain...\n",
      "http://ufcstats.com/fighter-details/39f62b833e4cf126\n",
      "Scraping Iuri Alcantara...\n",
      "http://ufcstats.com/fighter-details/2f95a3c6d58b2aad\n",
      "Scraping Ildemar Alcantara...\n",
      "http://ufcstats.com/fighter-details/7c6e87729e824ef4\n",
      "Scraping Alfonso Alcarez...\n",
      "http://ufcstats.com/fighter-details/1e38bba6738b7b10\n",
      "Scraping Gilbert Aldana...\n",
      "http://ufcstats.com/fighter-details/d26934530dc5b248\n",
      "Scraping Irene Aldana...\n",
      "http://ufcstats.com/fighter-details/578ef12674df1e6a\n",
      "Scraping Hector Aldana...\n",
      "http://ufcstats.com/fighter-details/c487223b0289bda9\n",
      "Scraping Jose Alday...\n",
      "http://ufcstats.com/fighter-details/7460ddef986d3144\n",
      "Scraping Jose Aldo...\n",
      "http://ufcstats.com/fighter-details/d0f3959b4a9747e6\n",
      "Scraping JJ Aldrich...\n",
      "http://ufcstats.com/fighter-details/6fd953151d981979\n",
      "Scraping Irina Alekseeva...\n",
      "http://ufcstats.com/fighter-details/103e2e33a60683e1\n",
      "Scraping Talita Alencar...\n",
      "http://ufcstats.com/fighter-details/d35298b6df168456\n",
      "Scraping Jim Alers...\n",
      "http://ufcstats.com/fighter-details/fe5a9547479396ab\n",
      "Scraping John Alessio...\n",
      "http://ufcstats.com/fighter-details/7a15f3694c5cbc02\n",
      "Scraping Houston Alexander...\n",
      "http://ufcstats.com/fighter-details/0541480fbf719d86\n",
      "Scraping Kenneth Alexander...\n",
      "http://ufcstats.com/fighter-details/8fd76e1b49c00ae2\n",
      "Scraping Lucas Alexander...\n",
      "http://ufcstats.com/fighter-details/11583163f45c7b31\n",
      "Scraping Marcio Alexandre Junior...\n",
      "http://ufcstats.com/fighter-details/d53482bef23235ba\n",
      "Scraping Olaf Alfonso...\n",
      "http://ufcstats.com/fighter-details/b757c73f443d4fca\n",
      "Scraping Pablo Alfonso...\n",
      "http://ufcstats.com/fighter-details/4b37a0bc2ab4cae1\n",
      "Scraping Levi Alford...\n",
      "http://ufcstats.com/fighter-details/41b34b7f11f6d085\n",
      "Scraping Bill Algeo...\n",
      "http://ufcstats.com/fighter-details/9abc648e76c4493a\n",
      "Scraping Royce Alger...\n",
      "http://ufcstats.com/fighter-details/669a3cb6e394f515\n",
      "Scraping Amir Aliakbari...\n",
      "http://ufcstats.com/fighter-details/e17770faae3ca54c\n",
      "Scraping Sultan Aliev...\n",
      "http://ufcstats.com/fighter-details/e70de1859b7ee78e\n",
      "Scraping Nurullo Aliev...\n",
      "http://ufcstats.com/fighter-details/ca28cdf526d6b6e9\n",
      "Scraping Ikram Aliskerov...\n",
      "http://ufcstats.com/fighter-details/b07aed698fba8624\n",
      "Scraping Leon Aliu...\n",
      "http://ufcstats.com/fighter-details/6db394bf6c3b017c\n",
      "Scraping John Allan...\n",
      "http://ufcstats.com/fighter-details/6ebe96a116e79e52\n",
      "Scraping George Allen...\n",
      "http://ufcstats.com/fighter-details/1e13936d708bcff7\n",
      "Scraping Arnold Allen...\n",
      "http://ufcstats.com/fighter-details/040a74bb0a465c54\n",
      "Scraping Brendan Allen...\n",
      "http://ufcstats.com/fighter-details/2f181c0467965b98\n",
      "Scraping Daniel Allen...\n",
      "http://ufcstats.com/fighter-details/adf9a901308fb8e3\n",
      "Scraping Ben Alloway...\n",
      "http://ufcstats.com/fighter-details/c4fe2e9a06ea5bcb\n",
      "Scraping Asu Almabayev...\n",
      "http://ufcstats.com/fighter-details/8d3273573b85be09\n",
      "Scraping Bekzat Almakhan...\n",
      "http://ufcstats.com/fighter-details/a4dc0f2b95df4cc1\n",
      "Scraping John Dave Almanza...\n",
      "http://ufcstats.com/fighter-details/088aa1b19b2dc14a\n",
      "Scraping Ricardo Almeida...\n",
      "http://ufcstats.com/fighter-details/91186547a7f3f758\n",
      "Scraping Magno Almeida...\n",
      "http://ufcstats.com/fighter-details/d615d6a10a4704cd\n",
      "Scraping Thomas Almeida...\n",
      "http://ufcstats.com/fighter-details/2b074403b7c6cdb4\n",
      "Scraping Ericka Almeida...\n",
      "http://ufcstats.com/fighter-details/67a992d4cff22466\n",
      "Scraping Estefani Almeida...\n",
      "http://ufcstats.com/fighter-details/f16ddfa31236efed\n",
      "Scraping Jailton Almeida...\n",
      "http://ufcstats.com/fighter-details/41e83a89929d1327\n",
      "Scraping Lucas Almeida...\n",
      "http://ufcstats.com/fighter-details/710f0f8c5d5c9d41\n",
      "Scraping Cesar Almeida...\n",
      "http://ufcstats.com/fighter-details/64d47ef881a437a4\n",
      "Scraping Mauricio Alonso...\n",
      "http://ufcstats.com/fighter-details/c6bf75775b278ed8\n",
      "Scraping Sarah Alpar...\n",
      "http://ufcstats.com/fighter-details/49b130de1da2e1bf\n",
      "Scraping Ali AlQaisi...\n",
      "http://ufcstats.com/fighter-details/e87a13e02c01331d\n",
      "Scraping Rico Altamirano...\n",
      "http://ufcstats.com/fighter-details/c61b49cec6abd6b9\n",
      "Scraping Victor Altamirano...\n",
      "http://ufcstats.com/fighter-details/dc7927cd622676a7\n",
      "Scraping Mike Altman...\n",
      "http://ufcstats.com/fighter-details/c11036da9162cb5f\n",
      "Scraping Patricia Alujas...\n",
      "http://ufcstats.com/fighter-details/430c533614d45813\n",
      "Scraping Sean Alvarez...\n",
      "http://ufcstats.com/fighter-details/e741536153227386\n",
      "Scraping Eddie Alvarez...\n",
      "http://ufcstats.com/fighter-details/33a331684283900f\n",
      "Scraping Jaime Alvarez...\n",
      "http://ufcstats.com/fighter-details/4438482bd1d5a029\n",
      "Scraping Joel Alvarez...\n",
      "http://ufcstats.com/fighter-details/58bbef3770bb2dfc\n",
      "Scraping Thiago Alves...\n",
      "http://ufcstats.com/fighter-details/31ee470ef5dc8d7f\n",
      "Scraping Anthony Alves...\n",
      "http://ufcstats.com/fighter-details/bd92cf5da5413d2a\n",
      "Scraping Amilcar Alves...\n",
      "http://ufcstats.com/fighter-details/dc5a6b2fdb27e7dc\n",
      "Scraping Warlley Alves...\n",
      "http://ufcstats.com/fighter-details/d317a5e2b3f88c5f\n",
      "Scraping Rafael Alves...\n",
      "http://ufcstats.com/fighter-details/029afd138865d20a\n",
      "Scraping Sam Alvey...\n",
      "http://ufcstats.com/fighter-details/d156513a19acf856\n",
      "Scraping Andre Amado...\n",
      "http://ufcstats.com/fighter-details/20821819c401ced8\n",
      "Scraping Adlan Amagov...\n",
      "http://ufcstats.com/fighter-details/1e327b281ef6a745\n",
      "Scraping Maiara Amanajas dos Santos...\n",
      "http://ufcstats.com/fighter-details/247fbbfafea60bb1\n",
      "Scraping Chris Amarante...\n",
      "http://ufcstats.com/fighter-details/ee0b69e307c857e5\n",
      "Scraping Jimmy Ambriz...\n",
      "http://ufcstats.com/fighter-details/c912f676692c353a\n",
      "Scraping JJ Ambrose...\n",
      "http://ufcstats.com/fighter-details/d562b12b8fe88336\n",
      "Scraping Alen Amedovski...\n",
      "http://ufcstats.com/fighter-details/70fa1c64a2c439ef\n",
      "Scraping Hyder Amil...\n",
      "http://ufcstats.com/fighter-details/41cc71cbf210e0fe\n",
      "Scraping Hamid Amiri...\n",
      "http://ufcstats.com/fighter-details/6c40705cf6c0d7e2\n",
      "Scraping Makwan Amirkhani...\n",
      "http://ufcstats.com/fighter-details/87a1dc546b1c5caf\n",
      "Scraping Jaqueline Amorim...\n",
      "http://ufcstats.com/fighter-details/bc7d1ad49fcb2d08\n",
      "Scraping Bertrand Amoussou...\n",
      "http://ufcstats.com/fighter-details/53adf5b845d91e4a\n",
      "Scraping Karl Amoussou...\n",
      "http://ufcstats.com/fighter-details/23a8c33869bf5392\n",
      "Scraping Eryk Anders...\n",
      "http://ufcstats.com/fighter-details/cad24459b28592ca\n",
      "Scraping Matt Andersen...\n",
      "http://ufcstats.com/fighter-details/8738eacd62e82a32\n",
      "Scraping Andy Anderson...\n",
      "http://ufcstats.com/fighter-details/9199e0735b83dd32\n",
      "Scraping Lowell Anderson...\n",
      "http://ufcstats.com/fighter-details/1ffc38f67785797b\n",
      "Scraping Corey Anderson...\n",
      "http://ufcstats.com/fighter-details/5e4eec08896c9423\n",
      "Scraping Derek Anderson...\n",
      "http://ufcstats.com/fighter-details/19ba965651486013\n",
      "Scraping Megan Anderson...\n",
      "http://ufcstats.com/fighter-details/a0e75f4a13eb73f1\n",
      "Scraping Liam Anderson...\n",
      "http://ufcstats.com/fighter-details/b03a0c78ca45facf\n",
      "Scraping Tatsuya Ando...\n",
      "http://ufcstats.com/fighter-details/17615148dd4be6f6\n",
      "Scraping Alex Andrade...\n",
      "http://ufcstats.com/fighter-details/1562b12763cc8d67\n",
      "Scraping Jessica Andrade...\n",
      "http://ufcstats.com/fighter-details/6a1901c62ab3870f\n",
      "Scraping Viscardi Andrade...\n",
      "http://ufcstats.com/fighter-details/d221ee27afc7a60e\n",
      "Scraping Jermaine Andre...\n",
      "http://ufcstats.com/fighter-details/9bad58fa651d6196\n",
      "Scraping Juan Andres Luna...\n",
      "http://ufcstats.com/fighter-details/1fd9f744105024a8\n",
      "Scraping Fellipe Andrew...\n",
      "http://ufcstats.com/fighter-details/7977fb0fd9c5955d\n",
      "Scraping Dylan Andrews...\n",
      "http://ufcstats.com/fighter-details/00debc804e2b1cd4\n",
      "Scraping Reese Andy...\n",
      "http://ufcstats.com/fighter-details/46e2ca71fd5089cb\n",
      "Scraping Angga...\n",
      "http://ufcstats.com/fighter-details/d6a3e131ad4ba064\n",
      "Scraping Julius Anglickas...\n",
      "http://ufcstats.com/fighter-details/e20ad078a7d63361\n",
      "Scraping Collin Anglin...\n",
      "http://ufcstats.com/fighter-details/047a91d3d9c79b05\n",
      "Scraping Chad Anheliger...\n",
      "http://ufcstats.com/fighter-details/c7c39e2fb70248b3\n",
      "Scraping Yoji Anjo...\n",
      "http://ufcstats.com/fighter-details/e06fd1260ac865a7\n",
      "Scraping Magomed Ankalaev...\n",
      "http://ufcstats.com/fighter-details/d802174b0c0c1f4e\n",
      "Scraping Gadzhimurad Antigulov...\n",
      "http://ufcstats.com/fighter-details/af997f7611673880\n",
      "Scraping Adam Antolin...\n",
      "http://ufcstats.com/fighter-details/25b31165758402dd\n",
      "Scraping Angelo Antonio...\n",
      "http://ufcstats.com/fighter-details/dbd198f780286aca\n",
      "Scraping Vanilto Antunes...\n",
      "http://ufcstats.com/fighter-details/cc49ada1ea955b13\n",
      "Scraping Azunna Anyanwu...\n",
      "http://ufcstats.com/fighter-details/78d48d3874dacafd\n",
      "Scraping Shinsho Anzai...\n",
      "http://ufcstats.com/fighter-details/4665f9f909cd7214\n",
      "Scraping Shinya Aoki...\n",
      "http://ufcstats.com/fighter-details/79ded75550efc139\n",
      "Scraping Aoriqileng...\n",
      "http://ufcstats.com/fighter-details/7d420039bbfe7c1a\n",
      "Scraping Josh Appelt...\n",
      "http://ufcstats.com/fighter-details/0c1a04afca64e38f\n",
      "Scraping Erik Apple...\n",
      "http://ufcstats.com/fighter-details/1ccff7f0cfdf85eb\n",
      "Scraping Kenji Arai...\n",
      "http://ufcstats.com/fighter-details/269d103c96a4c3a5\n",
      "Scraping Romie Aram...\n",
      "http://ufcstats.com/fighter-details/73ef22f25d0f70e2\n",
      "Scraping Felipe Arantes...\n",
      "http://ufcstats.com/fighter-details/71002dbc1743b9a7\n",
      "Scraping Igor Araujo...\n",
      "http://ufcstats.com/fighter-details/dbea8c1cb327ab3d\n",
      "Scraping Viviane Araujo...\n",
      "http://ufcstats.com/fighter-details/36541f1e6c5d4955\n",
      "Scraping Julio Arce...\n",
      "http://ufcstats.com/fighter-details/1291edf2d566a71a\n",
      "Scraping Art Arciniega...\n",
      "http://ufcstats.com/fighter-details/d25e39e74efb0a77\n",
      "Scraping Alice Ardelean...\n",
      "http://ufcstats.com/fighter-details/87f8699fdcc2c404\n",
      "Scraping Tristan Arenal...\n",
      "http://ufcstats.com/fighter-details/9c9455912d917e4e\n",
      "Scraping Gabriel Arges...\n",
      "http://ufcstats.com/fighter-details/db3c4a884d704efe\n",
      "Scraping Dan Argueta...\n",
      "http://ufcstats.com/fighter-details/e4ba58725825412d\n",
      "Scraping Reza Arianto...\n",
      "http://ufcstats.com/fighter-details/90063913321e7670\n",
      "Scraping Hashem Arkhagha...\n",
      "http://ufcstats.com/fighter-details/9a7ffa80766caa51\n",
      "Scraping Andrei Arlovski...\n",
      "http://ufcstats.com/fighter-details/3738e68d2261e60f\n",
      "Scraping Garrett Armfield...\n",
      "http://ufcstats.com/fighter-details/1effd880e1f1bb30\n",
      "Scraping Joey Armstrong...\n",
      "http://ufcstats.com/fighter-details/30ad2050273d016a\n",
      "Scraping Austin Arnett...\n",
      "http://ufcstats.com/fighter-details/bf0e700106d00e55\n",
      "Scraping Ricardo Arona...\n",
      "http://ufcstats.com/fighter-details/05fbfe628658c538\n",
      "Scraping Eli Aronov...\n",
      "http://ufcstats.com/fighter-details/a90c200c3fbb22c4\n",
      "Scraping Chalid Arrab...\n",
      "http://ufcstats.com/fighter-details/770b9d4813c25902\n",
      "Scraping Akbarh Arreola...\n",
      "http://ufcstats.com/fighter-details/c136b2a8852da5bd\n",
      "Scraping Matt Arroyo...\n",
      "http://ufcstats.com/fighter-details/de62052b2ede65ba\n",
      "Scraping Antonio Arroyo...\n",
      "http://ufcstats.com/fighter-details/61fb8098ccf81c7f\n",
      "Scraping Gilles Arsene...\n",
      "http://ufcstats.com/fighter-details/2dea80c069847321\n",
      "Scraping Veta Arteaga...\n",
      "http://ufcstats.com/fighter-details/91e3388e69060e69\n",
      "Scraping Cesar Arzamendia...\n",
      "http://ufcstats.com/fighter-details/49f78022126bf4a4\n",
      "Scraping Kai Asakura...\n",
      "http://ufcstats.com/fighter-details/d33da8a3d82bdb62\n",
      "Scraping Teddy Ash...\n",
      "http://ufcstats.com/fighter-details/a373085066dbfb54\n",
      "Scraping Arman Ashimov...\n",
      "http://ufcstats.com/fighter-details/d26a0988c9dc9886\n",
      "Scraping Yanal Ashmouz...\n",
      "http://ufcstats.com/fighter-details/c739c2995a275314\n",
      "Scraping Asjabharan...\n",
      "http://ufcstats.com/fighter-details/8be9deb7d6b36354\n",
      "Scraping Askar Askar...\n",
      "http://ufcstats.com/fighter-details/2abc414136504554\n",
      "Scraping Askar Askarov...\n",
      "http://ufcstats.com/fighter-details/b1d19449397541dc\n",
      "Scraping Cyril Asker...\n",
      "http://ufcstats.com/fighter-details/9be6020024133293\n",
      "Scraping Khusein Askhabov...\n",
      "http://ufcstats.com/fighter-details/5c10da56d712ac9c\n",
      "Scraping Scott Askham...\n",
      "http://ufcstats.com/fighter-details/06827d70c53ff0d9\n",
      "Scraping Ben Askren...\n",
      "http://ufcstats.com/fighter-details/0b31f87be71ebbb1\n",
      "Scraping Ibo Aslan...\n",
      "http://ufcstats.com/fighter-details/6e8f1bcdda94ff45\n",
      "Scraping Tom Aspinall...\n",
      "http://ufcstats.com/fighter-details/399afbabc02376b5\n",
      "Scraping Bruno Assis...\n",
      "http://ufcstats.com/fighter-details/ff222167cce02919\n",
      "Scraping Junior Assuncao...\n",
      "http://ufcstats.com/fighter-details/d0d7160824278840\n",
      "Scraping Raphael Assuncao...\n",
      "http://ufcstats.com/fighter-details/2f13e4020cea5b38\n",
      "Scraping Michael Aswell...\n",
      "http://ufcstats.com/fighter-details/01c9e4013afce141\n",
      "Scraping Bazigit Atajev...\n",
      "http://ufcstats.com/fighter-details/fd7acf42bd6e7e95\n",
      "Scraping Rich Attonito...\n",
      "http://ufcstats.com/fighter-details/210935fd21670f6d\n",
      "Scraping Olivier Aubin-Mercier...\n",
      "http://ufcstats.com/fighter-details/55ee431411ccf07a\n",
      "Scraping Pat Audinwood...\n",
      "http://ufcstats.com/fighter-details/196ed28337adc630\n",
      "Scraping Jose Augusto...\n",
      "http://ufcstats.com/fighter-details/4d3b08ab127c7585\n",
      "Scraping Marcus Aurelio...\n",
      "http://ufcstats.com/fighter-details/04643fd03d9159cc\n",
      "Scraping David Avellan...\n",
      "http://ufcstats.com/fighter-details/956dcac65e7b34d6\n",
      "Scraping Blas Avena...\n",
      "http://ufcstats.com/fighter-details/8753e125f4499816\n",
      "Scraping Levi Avera...\n",
      "http://ufcstats.com/fighter-details/ba5c6eeb8ef45f5c\n",
      "Scraping Anthony Avila...\n",
      "http://ufcstats.com/fighter-details/033d19259f589457\n",
      "Scraping Chris Avila...\n",
      "http://ufcstats.com/fighter-details/4665cbf36b08193b\n",
      "Scraping Julia Avila...\n",
      "http://ufcstats.com/fighter-details/86d9dbe1bfcbade7\n",
      "Scraping Saad Awad...\n",
      "http://ufcstats.com/fighter-details/da603332ad41f165\n",
      "Scraping Javy Ayala...\n",
      "http://ufcstats.com/fighter-details/26387c19f32dda0f\n",
      "Scraping Jessin Ayari...\n",
      "http://ufcstats.com/fighter-details/6eaec40f724852f4\n",
      "Scraping Abu Azaitar...\n",
      "http://ufcstats.com/fighter-details/46d0a888d87d91ac\n",
      "Scraping Ottman Azaitar...\n",
      "http://ufcstats.com/fighter-details/ee18ff42063174df\n",
      "Scraping Luiz Azeredo...\n",
      "http://ufcstats.com/fighter-details/063649e21bc9d6d5\n",
      "Scraping Luciano Azevedo...\n",
      "http://ufcstats.com/fighter-details/9bcfb40dbcd50568\n",
      "Scraping Hunter Azure...\n",
      "http://ufcstats.com/fighter-details/2af2f2e26c4c0402\n",
      "Scraping Niklas Backstrom...\n",
      "http://ufcstats.com/fighter-details/39cc64bf0a269db9\n",
      "Scraping Seth Baczynski...\n",
      "http://ufcstats.com/fighter-details/fd5b6598a3b70c0a\n",
      "Scraping Abdul Azeem Badakhshi...\n",
      "http://ufcstats.com/fighter-details/968764372c49eab6\n",
      "Scraping Ryan Bader...\n",
      "http://ufcstats.com/fighter-details/c0ab242c40decc55\n",
      "Scraping Izabela Badurek...\n",
      "http://ufcstats.com/fighter-details/4fcf6e0c4e0e6664\n",
      "Scraping Miguel Baeza...\n",
      "http://ufcstats.com/fighter-details/82d4c957649faf9b\n",
      "Scraping Ali Bagautinov...\n",
      "http://ufcstats.com/fighter-details/3dd92ff9fb0412b3\n",
      "Scraping Mehdi Baghdad...\n",
      "http://ufcstats.com/fighter-details/e4d2564ea0e34e2b\n",
      "Scraping Melsik Baghdasaryan...\n",
      "http://ufcstats.com/fighter-details/a52bc1e62cf0b7c6\n",
      "Scraping Siyar Bahadurzada...\n",
      "http://ufcstats.com/fighter-details/aec185309b4843d0\n",
      "Scraping Ignacio Bahamondes...\n",
      "http://ufcstats.com/fighter-details/e4a47b07044ddd72\n",
      "Scraping Bahatebole Batebolati...\n",
      "http://ufcstats.com/fighter-details/8f313e9c3a39c06e\n",
      "Scraping Shamar Bailey...\n",
      "http://ufcstats.com/fighter-details/e2b8186b618b00c4\n",
      "Scraping Jordan Bailey...\n",
      "http://ufcstats.com/fighter-details/34dbcd4dbaf21a36\n",
      "Scraping Scott Baker...\n",
      "http://ufcstats.com/fighter-details/7d5b12de1625984e\n",
      "Scraping Bryan Baker...\n",
      "http://ufcstats.com/fighter-details/898337ef520fe4d3\n",
      "Scraping Jin Bala...\n",
      "http://ufcstats.com/fighter-details/371efa53bd0cf669\n",
      "Scraping Balajin...\n",
      "http://ufcstats.com/fighter-details/e626e92a8f2a9737\n",
      "Scraping Oluwale Bamgbose...\n",
      "http://ufcstats.com/fighter-details/04b39f4e8eb59d7c\n",
      "Scraping Stephen Banaszak...\n",
      "http://ufcstats.com/fighter-details/4c4b44e3cf5815b3\n",
      "Scraping Marcin Bandel...\n",
      "http://ufcstats.com/fighter-details/5c2ce761399dc9c5\n",
      "Scraping Humberto Bandenay...\n",
      "http://ufcstats.com/fighter-details/2c2caf2f2bab9df5\n",
      "Scraping Tae Hyun Bang...\n",
      "http://ufcstats.com/fighter-details/9a2d3567abc02e34\n",
      "Scraping Yohan Banks...\n",
      "http://ufcstats.com/fighter-details/c50ea21fe9ef478d\n",
      "Scraping Shauna Bannon...\n",
      "http://ufcstats.com/fighter-details/9c442aaf149ea982\n",
      "Scraping Antonio Banuelos...\n",
      "http://ufcstats.com/fighter-details/9ddfb3369a3b0394\n",
      "Scraping Renan Barao...\n",
      "http://ufcstats.com/fighter-details/2c99576fefe53c7c\n",
      "Scraping Junior Barata...\n",
      "http://ufcstats.com/fighter-details/06dced58ca24a6bd\n",
      "Scraping Maycee Barber...\n",
      "http://ufcstats.com/fighter-details/6a740daf1b279661\n",
      "Scraping Bryan Barberena...\n",
      "http://ufcstats.com/fighter-details/a331233f597090a5\n",
      "Scraping Dione Barbosa...\n",
      "http://ufcstats.com/fighter-details/27b388f0aab49780\n",
      "Scraping Edson Barboza...\n",
      "http://ufcstats.com/fighter-details/64a50dad704d1d49\n",
      "Scraping Raoni Barcelos...\n",
      "http://ufcstats.com/fighter-details/b9f28e7045fdfce7\n",
      "Scraping Daniel Barez...\n",
      "http://ufcstats.com/fighter-details/e8fe9c15d348e778\n",
      "Scraping Danny Barlow...\n",
      "http://ufcstats.com/fighter-details/b7c5eb7cdbac6a63\n",
      "Scraping Luke Barnatt...\n",
      "http://ufcstats.com/fighter-details/172c2135e70f87b7\n",
      "Scraping James Barnes...\n",
      "http://ufcstats.com/fighter-details/c06a5c95f1169c0b\n",
      "Scraping Nick Barnes...\n",
      "http://ufcstats.com/fighter-details/78a5eea49638685d\n",
      "Scraping Shonte Barnes...\n",
      "http://ufcstats.com/fighter-details/e575b6ff678c1aca\n",
      "Scraping Josh Barnett...\n",
      "http://ufcstats.com/fighter-details/ad3f53c454cbbead\n",
      "Scraping Chris Barnett...\n",
      "http://ufcstats.com/fighter-details/7a5e8c94a86f9895\n",
      "Scraping Chris Barnhizer...\n",
      "http://ufcstats.com/fighter-details/91e69a1c3c87325b\n",
      "Scraping David Baron...\n",
      "http://ufcstats.com/fighter-details/80c0bed43da0e27b\n",
      "Scraping Phil Baroni...\n",
      "http://ufcstats.com/fighter-details/1652f3213655b935\n",
      "Scraping Dan Barrera...\n",
      "http://ufcstats.com/fighter-details/f12f979b657ab876\n",
      "Scraping Carlos Barreto...\n",
      "http://ufcstats.com/fighter-details/a220be6d41d6f97d\n",
      "Scraping Jose Barreto...\n",
      "http://ufcstats.com/fighter-details/c32eab6c2119e989\n",
      "Scraping Peter Barrett...\n",
      "http://ufcstats.com/fighter-details/d21113c9ff3788ae\n",
      "Scraping Marc-Andre Barriault...\n",
      "http://ufcstats.com/fighter-details/8e9eb3fc86db0f7d\n",
      "Scraping David Barrios...\n",
      "http://ufcstats.com/fighter-details/e6015889f50075d2\n",
      "Scraping Alexandre Barros...\n",
      "http://ufcstats.com/fighter-details/8fd1f27e86661ede\n",
      "Scraping Ricardo Barros...\n",
      "http://ufcstats.com/fighter-details/d26394fc0e8e880a\n",
      "Scraping Francimar Barroso...\n",
      "http://ufcstats.com/fighter-details/b69f24c500d783e7\n",
      "Scraping Pat Barry...\n",
      "http://ufcstats.com/fighter-details/658c3465581ae46b\n",
      "Scraping Dean Barry...\n",
      "http://ufcstats.com/fighter-details/a6f3d15cb84334bb\n",
      "Scraping Enrique Barzola...\n",
      "http://ufcstats.com/fighter-details/be0b310a12eb80b4\n",
      "Scraping Javid Basharat...\n",
      "http://ufcstats.com/fighter-details/bbab3baf66128ae2\n",
      "Scraping Farid Basharat...\n",
      "http://ufcstats.com/fighter-details/a09ed60aa67a3f67\n",
      "Scraping Austin Bashi...\n",
      "http://ufcstats.com/fighter-details/d3f89fa685bd8420\n",
      "Scraping Stephen Bass...\n",
      "http://ufcstats.com/fighter-details/1cecc8fe6748a532\n",
      "Scraping Sean Bassett...\n",
      "http://ufcstats.com/fighter-details/2c733e059462c1dc\n",
      "Scraping Ryan Bastianelli...\n",
      "http://ufcstats.com/fighter-details/29508aff4d93cbbe\n",
      "Scraping Shayna Baszler...\n",
      "http://ufcstats.com/fighter-details/8ef4a91ac694b7ce\n",
      "Scraping Michel Batista...\n",
      "http://ufcstats.com/fighter-details/34218661c44ed55d\n",
      "Scraping Bryan Battle...\n",
      "http://ufcstats.com/fighter-details/f626118b6da0e020\n",
      "Scraping Alan Baudot...\n",
      "http://ufcstats.com/fighter-details/c9a94278df042f46\n",
      "Scraping Mario Bautista...\n",
      "http://ufcstats.com/fighter-details/bc711b6dd95c1af6\n",
      "Scraping Chris Beal...\n",
      "http://ufcstats.com/fighter-details/55f446032177b119\n",
      "Scraping Donovan Beard...\n",
      "http://ufcstats.com/fighter-details/3a6ac598320ca7f2\n",
      "Scraping Rudy Bears...\n",
      "http://ufcstats.com/fighter-details/74f13066b1417ef3\n",
      "Scraping Salvador Becerra...\n",
      "http://ufcstats.com/fighter-details/4fd76e7ba8313457\n",
      "Scraping Ariel Beck...\n",
      "http://ufcstats.com/fighter-details/b96939f2b8d88e82\n",
      "Scraping Jeff Bedard...\n",
      "http://ufcstats.com/fighter-details/93bf96be327fcd98\n",
      "Scraping Eric Bedard...\n",
      "http://ufcstats.com/fighter-details/ce05955c26c3c090\n",
      "Scraping Johnny Bedford...\n",
      "http://ufcstats.com/fighter-details/ffc3e6daaa6da0b7\n",
      "Scraping Rolando Bedoya...\n",
      "http://ufcstats.com/fighter-details/40a456a25d52ee65\n",
      "Scraping Chase Beebe...\n",
      "http://ufcstats.com/fighter-details/b16a7e6a627e9789\n",
      "Scraping Lyle Beerbohm...\n",
      "http://ufcstats.com/fighter-details/babc6b5745335f18\n",
      "Scraping Allan Begosso...\n",
      "http://ufcstats.com/fighter-details/d6ed764f8b78d32a\n",
      "Scraping Mirsad Bektic...\n",
      "http://ufcstats.com/fighter-details/cbd3e590a85b18c5\n",
      "Scraping Diana Belbita...\n",
      "http://ufcstats.com/fighter-details/d7e40dca3ae125be\n",
      "Scraping Alan Belcher...\n",
      "http://ufcstats.com/fighter-details/4130a743d9d22163\n",
      "Scraping Vitor Belfort...\n",
      "http://ufcstats.com/fighter-details/0ee783aa00e468f0\n",
      "Scraping Yousri Belgaroui...\n",
      "http://ufcstats.com/fighter-details/7674b836ce0698a0\n",
      "Scraping Rodolfo Bellato...\n",
      "http://ufcstats.com/fighter-details/69898645d600abdb\n",
      "Scraping Danilo Belluardo...\n",
      "http://ufcstats.com/fighter-details/c3f6db17cea09ca7\n",
      "Scraping Joey Beltran...\n",
      "http://ufcstats.com/fighter-details/46baf0f57edfa4df\n",
      "Scraping Marco Beltran...\n",
      "http://ufcstats.com/fighter-details/ec71a892fada28c7\n",
      "Scraping Joseph Benavidez...\n",
      "http://ufcstats.com/fighter-details/80eacd4da0617c57\n",
      "Scraping Mike Bencic...\n",
      "http://ufcstats.com/fighter-details/a71feb7ea7592a71\n",
      "Scraping Dave Beneteau...\n",
      "http://ufcstats.com/fighter-details/9fd1f08dd4aec14a\n",
      "Scraping Karla Benitez...\n",
      "http://ufcstats.com/fighter-details/6104730621ff318d\n",
      "Scraping Gabriel Benitez...\n",
      "http://ufcstats.com/fighter-details/436f970c9ea9169c\n",
      "Scraping Charles Bennett...\n",
      "http://ufcstats.com/fighter-details/8dc4f34c1f50d00d\n",
      "Scraping Josh Bennett...\n",
      "http://ufcstats.com/fighter-details/c3ac8d0da7b05772\n",
      "Scraping DeAnna Bennett...\n",
      "http://ufcstats.com/fighter-details/404ecb2700844072\n",
      "Scraping Benjamin Bennett...\n",
      "http://ufcstats.com/fighter-details/7030c27fc9778964\n",
      "Scraping Lance Benoist...\n",
      "http://ufcstats.com/fighter-details/5431dccc09118234\n",
      "Scraping Joe Benoit...\n",
      "http://ufcstats.com/fighter-details/a30f6d375dea5f9b\n",
      "Scraping Ryan Benoit...\n",
      "http://ufcstats.com/fighter-details/20999e27ddd94bda\n",
      "Scraping Pat Benson...\n",
      "http://ufcstats.com/fighter-details/a25f3dc0df974597\n",
      "Scraping Len Bentley...\n",
      "http://ufcstats.com/fighter-details/592d23aed850e652\n",
      "Scraping Steve Berger...\n",
      "http://ufcstats.com/fighter-details/21b1132949f2a9b0\n",
      "Scraping Kenneth Bergh...\n",
      "http://ufcstats.com/fighter-details/aa8189053b3a8994\n",
      "Scraping Bret Bergmark...\n",
      "http://ufcstats.com/fighter-details/2891c9f7b26b26fc\n",
      "Scraping Keith Berish...\n",
      "http://ufcstats.com/fighter-details/e3779ef06e98f185\n",
      "Scraping Dennis Bermudez...\n",
      "http://ufcstats.com/fighter-details/6f242453c91a5af0\n",
      "Scraping Manny Bermudez...\n",
      "http://ufcstats.com/fighter-details/2dc1bc1a02961656\n",
      "Scraping Talita Bernardo...\n",
      "http://ufcstats.com/fighter-details/5b2325cd70dbe2ea\n",
      "Scraping Dave Berry...\n",
      "http://ufcstats.com/fighter-details/b3bbe88fecd6a0d2\n",
      "Scraping Keith Berry...\n",
      "http://ufcstats.com/fighter-details/0b935b9bbbe5fc07\n",
      "Scraping Dieusel Berto...\n",
      "http://ufcstats.com/fighter-details/0db70ca89e1c7374\n",
      "Scraping Edson Berto...\n",
      "http://ufcstats.com/fighter-details/66766984842c13dc\n",
      "Scraping Allen Berube...\n",
      "http://ufcstats.com/fighter-details/aebfb84d1f6d2d8c\n",
      "Scraping Anton Berzin...\n",
      "http://ufcstats.com/fighter-details/8ba8e8d7eafa7267\n",
      "Scraping Scott Bessac...\n",
      "http://ufcstats.com/fighter-details/3f24c96753dbd9f9\n",
      "Scraping Matt Bessette...\n",
      "http://ufcstats.com/fighter-details/0b8d512c79b4baf3\n",
      "Scraping Khadzhi Bestaev...\n",
      "http://ufcstats.com/fighter-details/e05f4ce199baca91\n",
      "Scraping Fernando Bettega...\n",
      "http://ufcstats.com/fighter-details/a524710c3ef918fa\n",
      "Scraping Arjan Bhullar...\n",
      "http://ufcstats.com/fighter-details/7e511f8d842a109d\n",
      "Scraping KB Bhullar...\n",
      "http://ufcstats.com/fighter-details/9cd047a828dd7515\n",
      "Scraping Bibulatov Magomed...\n",
      "http://ufcstats.com/fighter-details/87f19d19f4cb73f8\n",
      "Scraping David Bielkheden...\n",
      "http://ufcstats.com/fighter-details/1efa064872f089d0\n",
      "Scraping Blake Bilder...\n",
      "http://ufcstats.com/fighter-details/5095b0920a3602aa\n",
      "Scraping Jonas Bilharinho...\n",
      "http://ufcstats.com/fighter-details/ebbf571f349e79d9\n",
      "Scraping Jeremiah Billington...\n",
      "http://ufcstats.com/fighter-details/b3b6e80b7d5f8f0d\n",
      "Scraping Scott Bills...\n",
      "http://ufcstats.com/fighter-details/53f02bbc41d99432\n",
      "Scraping Anthony Birchak...\n",
      "http://ufcstats.com/fighter-details/c5a126ace82a6025\n",
      "Scraping Chris Birchler...\n",
      "http://ufcstats.com/fighter-details/8a22c6b4d29880a3\n",
      "Scraping Angad Bisht...\n",
      "http://ufcstats.com/fighter-details/7b4ae3fd439a05b6\n",
      "Scraping Michael Bisping...\n",
      "http://ufcstats.com/fighter-details/2b93ebd9f5417ad2\n",
      "Scraping Amaury Bitetti...\n",
      "http://ufcstats.com/fighter-details/7a359ef685a304a7\n",
      "Scraping Caio Bittencourt...\n",
      "http://ufcstats.com/fighter-details/a653cb5eb4b39339\n",
      "Scraping Davi Bittencourt...\n",
      "http://ufcstats.com/fighter-details/dd6ec6f941c3a414\n",
      "Scraping Simon Biyong...\n",
      "http://ufcstats.com/fighter-details/27ab7257bf6a3b65\n",
      "Scraping Jan Blachowicz...\n",
      "http://ufcstats.com/fighter-details/99df7d0a2a08a8a8\n",
      "Scraping Jason Black...\n",
      "http://ufcstats.com/fighter-details/b2f743746e8dcfa2\n",
      "Scraping Brad Blackburn...\n",
      "http://ufcstats.com/fighter-details/7e69a4b0961aa555\n",
      "Scraping Jason Blackford...\n",
      "http://ufcstats.com/fighter-details/619d807fa54ae8f7\n",
      "Scraping Tom Blackledge...\n",
      "http://ufcstats.com/fighter-details/2adb11835acd815b\n",
      "Scraping Sherrard Blackledge...\n",
      "http://ufcstats.com/fighter-details/0e5c79b3594ff0ad\n",
      "Scraping Da'Mon Blackshear...\n",
      "http://ufcstats.com/fighter-details/da22387a0407a2dc\n",
      "Scraping Chasen Blair...\n",
      "http://ufcstats.com/fighter-details/0f4a536507f33576\n",
      "Scraping Erin Blanchfield...\n",
      "http://ufcstats.com/fighter-details/669970f7feba8ecd\n",
      "Scraping Maximo Blanco...\n",
      "http://ufcstats.com/fighter-details/4a1329cc8eb0928a\n",
      "Scraping David Blanco...\n",
      "http://ufcstats.com/fighter-details/ebf298f8ac7e232b\n",
      "Scraping Curtis Blaydes...\n",
      "http://ufcstats.com/fighter-details/fa6796c55d6c5440\n",
      "Scraping Tereza Bleda...\n",
      "http://ufcstats.com/fighter-details/59c438c81fbf3ece\n",
      "Scraping Arlene Blencowe...\n",
      "http://ufcstats.com/fighter-details/35d6337320a4ae48\n",
      "Scraping Byron Bloodworth...\n",
      "http://ufcstats.com/fighter-details/ecdf14f4f8643d39\n",
      "Scraping Dashawn Boatwright...\n",
      "http://ufcstats.com/fighter-details/046a85108610c0d2\n",
      "Scraping Dan Bobish...\n",
      "http://ufcstats.com/fighter-details/f348d05403fad037\n",
      "Scraping Mark Bocek...\n",
      "http://ufcstats.com/fighter-details/cf9d24e4bd0cf2ce\n",
      "Scraping Kyle Bochniak...\n",
      "http://ufcstats.com/fighter-details/c5af5750e8bae4f0\n",
      "Scraping James Bochnovic...\n",
      "http://ufcstats.com/fighter-details/984d15d5dc7bfcf9\n",
      "Scraping Jeremy Boczulak...\n",
      "http://ufcstats.com/fighter-details/1afd74f8cb0719f3\n",
      "Scraping Tim Boetsch...\n",
      "http://ufcstats.com/fighter-details/c80095f6092271a7\n",
      "Scraping Galore Bofando...\n",
      "http://ufcstats.com/fighter-details/8a56ea383fd26e52\n",
      "Scraping Jay Bogan...\n",
      "http://ufcstats.com/fighter-details/53c21779d84ceb75\n",
      "Scraping Roman Bogatov...\n",
      "http://ufcstats.com/fighter-details/d61316139d68dbe3\n",
      "Scraping Derek Bohi...\n",
      "http://ufcstats.com/fighter-details/70a1c7626b5e0599\n",
      "Scraping Jerry Bohlander...\n",
      "http://ufcstats.com/fighter-details/93892752c5fc23ca\n",
      "Scraping Mandy Bohm...\n",
      "http://ufcstats.com/fighter-details/297a2b35444c245b\n",
      "Scraping Kotetsu Boku...\n",
      "http://ufcstats.com/fighter-details/d227958e8a0c1466\n",
      "Scraping Gaston Bolanos...\n",
      "http://ufcstats.com/fighter-details/96924b0019b3aff1\n",
      "Scraping Kyle Bolt...\n",
      "http://ufcstats.com/fighter-details/9d455d5cfe6a0e35\n",
      "Scraping Denys Bondar...\n",
      "http://ufcstats.com/fighter-details/2526be54e6a0e62a\n",
      "Scraping Luc Bondole...\n",
      "http://ufcstats.com/fighter-details/8691881b31c16b88\n",
      "Scraping Tony Bonello...\n",
      "http://ufcstats.com/fighter-details/702a72aa7a266d86\n",
      "Scraping Gabriel Bonfim...\n",
      "http://ufcstats.com/fighter-details/01641ba5df0c69b0\n",
      "Scraping Ismael Bonfim...\n",
      "http://ufcstats.com/fighter-details/eb393afdbe3293d5\n",
      "Scraping Jesse Bongfeldt...\n",
      "http://ufcstats.com/fighter-details/934de214814b8ff4\n",
      "Scraping Marcos Bonilla...\n",
      "http://ufcstats.com/fighter-details/d311fbefff44a39b\n",
      "Scraping Stephan Bonnar...\n",
      "http://ufcstats.com/fighter-details/c6a33ff198aaaeeb\n",
      "Scraping Rogerio Bontorin...\n",
      "http://ufcstats.com/fighter-details/07a2bdaa0afdd831\n",
      "Scraping Ray Borg...\n",
      "http://ufcstats.com/fighter-details/a4de54ea806fb525\n",
      "Scraping Igor Borisov...\n",
      "http://ufcstats.com/fighter-details/0313bf497de9c470\n",
      "Scraping Kevin Borjas...\n",
      "http://ufcstats.com/fighter-details/34b96d52db1d26e6\n",
      "Scraping Calen Born...\n",
      "http://ufcstats.com/fighter-details/3c85e04b08a05751\n",
      "Scraping Caio Borralho...\n",
      "http://ufcstats.com/fighter-details/4126a78111c0855a\n",
      "Scraping Zachary Borrego...\n",
      "http://ufcstats.com/fighter-details/b8fdb2903a2582a8\n",
      "Scraping Viacheslav Borshchev...\n",
      "http://ufcstats.com/fighter-details/19c591115a58982c\n",
      "Scraping Tanner Boser...\n",
      "http://ufcstats.com/fighter-details/04c8b08b16a5b99e\n",
      "Scraping Steve Bosse...\n",
      "http://ufcstats.com/fighter-details/e023fa2e648ea0f1\n",
      "Scraping Marcus Bossett...\n",
      "http://ufcstats.com/fighter-details/e8fb8e53bc2e29d6\n",
      "Scraping Chris Bostick...\n",
      "http://ufcstats.com/fighter-details/239224bedeb2c7a4\n",
      "Scraping Poliana Botelho...\n",
      "http://ufcstats.com/fighter-details/5c126c6aac3ef364\n",
      "Scraping Francois Botha...\n",
      "http://ufcstats.com/fighter-details/545d549d6bf87187\n",
      "Scraping Gregory Bouchelaghem...\n",
      "http://ufcstats.com/fighter-details/59851163aaf1aed8\n",
      "Scraping Roy Boughton...\n",
      "http://ufcstats.com/fighter-details/2aaf0181432adf0b\n",
      "Scraping Rich Bouphanouvong...\n",
      "http://ufcstats.com/fighter-details/611b9c068c9e2c44\n",
      "Scraping Mike Bourke...\n",
      "http://ufcstats.com/fighter-details/dfdd0c5dd0d4bc23\n",
      "Scraping Jess Bouscal...\n",
      "http://ufcstats.com/fighter-details/38b1417ec17072da\n",
      "Scraping Tai Bowden...\n",
      "http://ufcstats.com/fighter-details/2efbc83a6b9b7f86\n",
      "Scraping Melton Bowen...\n",
      "http://ufcstats.com/fighter-details/81ca2c245b19b3c5\n",
      "Scraping Kyron Bowen...\n",
      "http://ufcstats.com/fighter-details/5488b3c67600333a\n",
      "Scraping Brian Bowles...\n",
      "http://ufcstats.com/fighter-details/b26d3e3746fb4024\n",
      "Scraping Roger Bowling...\n",
      "http://ufcstats.com/fighter-details/3b9f723e2720a238\n",
      "Scraping Blake Bowman...\n",
      "http://ufcstats.com/fighter-details/a95a0504fd73bd3e\n",
      "Scraping Ashe Bowman...\n",
      "http://ufcstats.com/fighter-details/8a0a35e7c74bebcc\n",
      "Scraping Anvar Boynazarov...\n",
      "http://ufcstats.com/fighter-details/4a191f4ea2fce7fc\n",
      "Scraping Colley  Bradford...\n",
      "http://ufcstats.com/fighter-details/1433786ac76cf777\n",
      "Scraping Kyle Bradley...\n",
      "http://ufcstats.com/fighter-details/a6959da32f0e6b5d\n",
      "Scraping Paul Bradley...\n",
      "http://ufcstats.com/fighter-details/c7011de4765d2497\n",
      "Scraping Sean Brady...\n",
      "http://ufcstats.com/fighter-details/45f7cb591c3ab00b\n",
      "Scraping Ebenezer Fontes Braga...\n",
      "http://ufcstats.com/fighter-details/dc950d59dc590aca\n",
      "Scraping Ramiz Brahimaj...\n",
      "http://ufcstats.com/fighter-details/3d074044a33825e7\n",
      "Scraping Adam Bramhald...\n",
      "http://ufcstats.com/fighter-details/3c99bd6cb5d835ef\n",
      "Scraping Joe Brammer...\n",
      "http://ufcstats.com/fighter-details/013da757877044a2\n",
      "Scraping David Branch...\n",
      "http://ufcstats.com/fighter-details/d2c55d1d2e67773b\n",
      "Scraping Billy Brand...\n",
      "http://ufcstats.com/fighter-details/edae6db2b3453632\n",
      "Scraping Diego Brandao...\n",
      "http://ufcstats.com/fighter-details/c2e3e67b5911bfb7\n",
      "Scraping Bruna Brasil...\n",
      "http://ufcstats.com/fighter-details/7138a15258dabf20\n",
      "Scraping Michael Bravo...\n",
      "http://ufcstats.com/fighter-details/dc63542668295c23\n",
      "Scraping Martin Bravo...\n",
      "http://ufcstats.com/fighter-details/9c44f290f5726d95\n",
      "Scraping Roman Bravo-Young...\n",
      "http://ufcstats.com/fighter-details/37ce890a4670b287\n",
      "Scraping Mike Breeden...\n",
      "http://ufcstats.com/fighter-details/d80ee110748171ac\n",
      "Scraping Tom Breese...\n",
      "http://ufcstats.com/fighter-details/1588b787bda7b540\n",
      "Scraping Elves Brener...\n",
      "http://ufcstats.com/fighter-details/48a9a128784d53d1\n",
      "Scraping Chris Brennan...\n",
      "http://ufcstats.com/fighter-details/b19fc66613dc75b9\n",
      "Scraping Charlie Brenneman...\n",
      "http://ufcstats.com/fighter-details/98f6da59d765ec94\n",
      "Scraping Robert Breslin...\n",
      "http://ufcstats.com/fighter-details/e319d6697d41f3cf\n",
      "Scraping Mack Brewer...\n",
      "http://ufcstats.com/fighter-details/106a925d947a0de9\n",
      "Scraping Marcos Brigagao...\n",
      "http://ufcstats.com/fighter-details/11547e29f253fb89\n",
      "Scraping Jason Brilz...\n",
      "http://ufcstats.com/fighter-details/497ba5b12a4bfc47\n",
      "Scraping Marcus Brimage...\n",
      "http://ufcstats.com/fighter-details/81801f57bd0a7c41\n",
      "Scraping Aaron Brink...\n",
      "http://ufcstats.com/fighter-details/cf1a88371c8cb690\n",
      "Scraping Henry Briones...\n",
      "http://ufcstats.com/fighter-details/01fcef7e3d051722\n",
      "Scraping Marcelo Brito...\n",
      "http://ufcstats.com/fighter-details/3a97fda0de6f1fa4\n",
      "Scraping Joanderson Brito...\n",
      "http://ufcstats.com/fighter-details/791c8437b341fba5\n",
      "Scraping Kaik Brito...\n",
      "http://ufcstats.com/fighter-details/b07f14fc0e53f8bd\n",
      "Scraping Icaro Brito...\n",
      "http://ufcstats.com/fighter-details/06dd61c8d545c63f\n",
      "Scraping Antwain Britt...\n",
      "http://ufcstats.com/fighter-details/2833f50b20e96e52\n",
      "Scraping Drew Brokenshire...\n",
      "http://ufcstats.com/fighter-details/aa571d75f80fde7d\n",
      "Scraping Mike Bronzoulis...\n",
      "http://ufcstats.com/fighter-details/df3c39573d01f55b\n",
      "Scraping Jonathan Brookins...\n",
      "http://ufcstats.com/fighter-details/b0a6124751a56bc4\n",
      "Scraping Will Brooks...\n",
      "http://ufcstats.com/fighter-details/b6e6c3b1dcaae0a1\n",
      "Scraping Jarred Brooks...\n",
      "http://ufcstats.com/fighter-details/81d9df19e255b8b6\n",
      "Scraping Rob Broughton...\n",
      "http://ufcstats.com/fighter-details/a7d687e6ecb30981\n",
      "Scraping Lee Brousseau...\n",
      "http://ufcstats.com/fighter-details/0974d8d4053a7237\n",
      "Scraping Matt Brown...\n",
      "http://ufcstats.com/fighter-details/31123249b0bbf52e\n",
      "Scraping Mike Brown...\n",
      "http://ufcstats.com/fighter-details/e0b74df14f52cd15\n",
      "Scraping Dominic Brown...\n",
      "http://ufcstats.com/fighter-details/52b3ec072ad497a4\n",
      "Scraping Todd Brown...\n",
      "http://ufcstats.com/fighter-details/9b68bf67c5695185\n",
      "Scraping Terrell Brown...\n",
      "http://ufcstats.com/fighter-details/85df85a4e276c90e\n",
      "Scraping Chris Brown...\n",
      "http://ufcstats.com/fighter-details/9e2624ac992660c6\n",
      "Scraping Frederick Brown...\n",
      "http://ufcstats.com/fighter-details/880c6b788266a3ef\n",
      "Scraping Randy Brown...\n",
      "http://ufcstats.com/fighter-details/c6aee362c7a7d482\n",
      "Scraping Damien Brown...\n",
      "http://ufcstats.com/fighter-details/d024ed963e8bf7ea\n",
      "Scraping TJ Brown...\n",
      "http://ufcstats.com/fighter-details/d31cbcdd7d69536d\n",
      "Scraping Humberto Brown Morrison...\n",
      "http://ufcstats.com/fighter-details/e9e7e1c8ff289e1b\n",
      "Scraping Travis Browne...\n",
      "http://ufcstats.com/fighter-details/3236bf606fe9fa5b\n",
      "Scraping Junie Browning...\n",
      "http://ufcstats.com/fighter-details/d74cba8566291bfa\n",
      "Scraping Jules Bruchez...\n",
      "http://ufcstats.com/fighter-details/d1dcd4e96464a53d\n",
      "Scraping Justin Bruckmann...\n",
      "http://ufcstats.com/fighter-details/5f8e00c27b7e7410\n",
      "Scraping Cody Brundage...\n",
      "http://ufcstats.com/fighter-details/f14f644d41ade29f\n",
      "Scraping Steve Bruno...\n",
      "http://ufcstats.com/fighter-details/2f3f12002564bb55\n",
      "Scraping Fernando Bruno...\n",
      "http://ufcstats.com/fighter-details/b8c0f30ee9a98b69\n",
      "Scraping Derek Brunson...\n",
      "http://ufcstats.com/fighter-details/b1a3e0aca758b322\n",
      "Scraping Josh Bryant...\n",
      "http://ufcstats.com/fighter-details/01f022fa494188e2\n",
      "Scraping Dennis Bryant...\n",
      "http://ufcstats.com/fighter-details/3b17353b8002c7d0\n",
      "Scraping Robert Bryczek...\n",
      "http://ufcstats.com/fighter-details/f96856f9d69fd7e4\n",
      "Scraping Lukasz Brzeski...\n",
      "http://ufcstats.com/fighter-details/0c25d0a5e8cdbf19\n",
      "Scraping Justin Buchholz...\n",
      "http://ufcstats.com/fighter-details/231926533134ec1f\n",
      "Scraping Zak Bucia...\n",
      "http://ufcstats.com/fighter-details/6bbb8dc6e128779e\n",
      "Scraping Courtney Buck...\n",
      "http://ufcstats.com/fighter-details/3feed7d02711d8b7\n",
      "Scraping Joaquin Buckley...\n",
      "http://ufcstats.com/fighter-details/b9437600497350f3\n",
      "Scraping Martin Buday...\n",
      "http://ufcstats.com/fighter-details/8eb046f83e82bf26\n",
      "Scraping Julia Budd...\n",
      "http://ufcstats.com/fighter-details/dcdc4503b9d49977\n",
      "Scraping Dylan Budka...\n",
      "http://ufcstats.com/fighter-details/a817e238b2747404\n",
      "Scraping Mike Budnik...\n",
      "http://ufcstats.com/fighter-details/b98209144b63ae26\n",
      "Scraping Francisco Bueno...\n",
      "http://ufcstats.com/fighter-details/a72d260b436924c4\n",
      "Scraping Mayra Bueno Silva...\n",
      "http://ufcstats.com/fighter-details/cc8c623cca88f54f\n",
      "Scraping Paul Buentello...\n",
      "http://ufcstats.com/fighter-details/f0abbb6f3444dae7\n",
      "Scraping Modestas Bukauskas...\n",
      "http://ufcstats.com/fighter-details/476fe566d2df676e\n",
      "Scraping Lee Kwan Bum...\n",
      "http://ufcstats.com/fighter-details/c0342805a1948cbb\n",
      "Scraping Josh Bumgarner...\n",
      "http://ufcstats.com/fighter-details/9900ab86a4c458bd\n",
      "Scraping Shawn Bunch...\n",
      "http://ufcstats.com/fighter-details/6e9af164ab91a229\n",
      "Scraping Felipe Bunes...\n",
      "http://ufcstats.com/fighter-details/53c10176e3bc7416\n",
      "Scraping Shane Burgos...\n",
      "http://ufcstats.com/fighter-details/98d961097baaf308\n",
      "Scraping Joshua Burkman...\n",
      "http://ufcstats.com/fighter-details/6da99156486ed6c2\n",
      "Scraping Justin Burlinson...\n",
      "http://ufcstats.com/fighter-details/dadd80ef954e54ed\n",
      "Scraping Mads Burnell...\n",
      "http://ufcstats.com/fighter-details/69f01b25dfabaf6b\n",
      "Scraping Mikey Burnett...\n",
      "http://ufcstats.com/fighter-details/4c805f5f58a75df0\n",
      "Scraping Kevin Burns...\n",
      "http://ufcstats.com/fighter-details/a6d8bfe9e0c8153b\n",
      "Scraping Gilbert Burns...\n",
      "http://ufcstats.com/fighter-details/23024fdfc966410a\n",
      "Scraping Josh Burns...\n",
      "http://ufcstats.com/fighter-details/1e092415a7eeaf65\n",
      "Scraping Derrick Burnsed...\n",
      "http://ufcstats.com/fighter-details/2213330f082f82d5\n",
      "Scraping Nah-Shon Burrell...\n",
      "http://ufcstats.com/fighter-details/2c64c035485906aa\n",
      "Scraping Martin Buschkamp...\n",
      "http://ufcstats.com/fighter-details/8fc30d8cebb17116\n",
      "Scraping George Bush...\n",
      "http://ufcstats.com/fighter-details/f0c779dc2ca3816c\n",
      "Scraping Bubba Bush...\n",
      "http://ufcstats.com/fighter-details/132505067f08c54d\n",
      "Scraping Dakota Bush...\n",
      "http://ufcstats.com/fighter-details/3033c1c080672475\n",
      "Scraping Murilo Bustamante...\n",
      "http://ufcstats.com/fighter-details/85d905f7c4f5a1af\n",
      "Scraping Nick Bustamante...\n",
      "http://ufcstats.com/fighter-details/51b1ca2a4b064101\n",
      "Scraping Eduardo Bustillos...\n",
      "http://ufcstats.com/fighter-details/f273f1b8df04c8a1\n",
      "Scraping Jason Butcher...\n",
      "http://ufcstats.com/fighter-details/30e39145fec48d25\n",
      "Scraping Todd Butler...\n",
      "http://ufcstats.com/fighter-details/3fed746acfd026dd\n",
      "Scraping Goldman Butler...\n",
      "http://ufcstats.com/fighter-details/e2d5072048b825b1\n",
      "Scraping Ian Butler...\n",
      "http://ufcstats.com/fighter-details/6b8fd98eb52363d1\n",
      "Scraping Raphael Butler...\n",
      "http://ufcstats.com/fighter-details/f941505e35fb1eae\n",
      "Scraping Jesse Butler...\n",
      "http://ufcstats.com/fighter-details/a75a48bfe776b2c2\n",
      "Scraping JP Buys...\n",
      "http://ufcstats.com/fighter-details/0b362247806341e5\n",
      "Scraping Dennis Buzukja...\n",
      "http://ufcstats.com/fighter-details/c4d039123e62f6a9\n",
      "Scraping Charles Byrd...\n",
      "http://ufcstats.com/fighter-details/76ee3d666c648f6b\n",
      "Scraping Steve Byrnes...\n",
      "http://ufcstats.com/fighter-details/43612456979e5d5e\n",
      "Scraping Michael Byrnes...\n",
      "http://ufcstats.com/fighter-details/87f0b37f153cf497\n",
      "Scraping Yan Cabral...\n",
      "http://ufcstats.com/fighter-details/7cdd3e5d3aa9cb39\n",
      "Scraping Alvin Cacdac...\n",
      "http://ufcstats.com/fighter-details/ce7871949b0ed2bf\n",
      "Scraping Alex Caceres...\n",
      "http://ufcstats.com/fighter-details/7aa3d6964eff4877\n",
      "Scraping Vince Cachero...\n",
      "http://ufcstats.com/fighter-details/ed2a8cc402173781\n",
      "Scraping Priscila Cachoeira...\n",
      "http://ufcstats.com/fighter-details/b1e5bcaad32a3cac\n",
      "Scraping Travis Calanoc...\n",
      "http://ufcstats.com/fighter-details/90d28fee0af74f2d\n",
      "Scraping Ricky Calatayud...\n",
      "http://ufcstats.com/fighter-details/800feaa25700a85f\n",
      "Scraping Carlos Calderon...\n",
      "http://ufcstats.com/fighter-details/7d4d7583df7eebf9\n",
      "Scraping Darrion Caldwell...\n",
      "http://ufcstats.com/fighter-details/b7dc25ee40ee8334\n",
      "Scraping Nicolle Caliari...\n",
      "http://ufcstats.com/fighter-details/fc0a4053eb8a3a59\n",
      "Scraping Taylor Callens...\n",
      "http://ufcstats.com/fighter-details/53d471e9bf5f2fc8\n",
      "Scraping Cynthia Calvillo...\n",
      "http://ufcstats.com/fighter-details/98215d037be5bcb7\n",
      "Scraping Joe Camacho...\n",
      "http://ufcstats.com/fighter-details/dfb965c9824425db\n",
      "Scraping Frank Camacho...\n",
      "http://ufcstats.com/fighter-details/764342d39cdaa54a\n",
      "Scraping Lucas Camacho...\n",
      "http://ufcstats.com/fighter-details/71d25689f70e4036\n",
      "Scraping Fabricio Camoes...\n",
      "http://ufcstats.com/fighter-details/7abe471b61725980\n",
      "Scraping Chris Camozzi...\n",
      "http://ufcstats.com/fighter-details/6c2030e0a143a94b\n",
      "Scraping Brian Camozzi...\n",
      "http://ufcstats.com/fighter-details/1999ffb5cebc314f\n",
      "Scraping Ricky Camp...\n",
      "http://ufcstats.com/fighter-details/4a99978a0366bb29\n",
      "Scraping Mike Campbell...\n",
      "http://ufcstats.com/fighter-details/f5585e675af7afd4\n",
      "Scraping Thomas Campbell...\n",
      "http://ufcstats.com/fighter-details/d060014a5a039829\n",
      "Scraping Shane Campbell...\n",
      "http://ufcstats.com/fighter-details/784285b7ae7dd85f\n",
      "Scraping Charlie Campbell...\n",
      "http://ufcstats.com/fighter-details/b39f7a6c2be17ee8\n",
      "Scraping John Campetella...\n",
      "http://ufcstats.com/fighter-details/31bbd46d57dfbcb7\n",
      "Scraping Wagner Campos...\n",
      "http://ufcstats.com/fighter-details/db6d5f691aea3fd3\n",
      "Scraping Derek Campos...\n",
      "http://ufcstats.com/fighter-details/aa8dc72b3a1f761c\n",
      "Scraping Will Campuzano...\n",
      "http://ufcstats.com/fighter-details/901cddcbfa079097\n",
      "Scraping Aleksa Camur...\n",
      "http://ufcstats.com/fighter-details/c2a670b22d2e196f\n",
      "Scraping Chico Camus...\n",
      "http://ufcstats.com/fighter-details/32be4b7f7de1c905\n",
      "Scraping Asbel Cancio...\n",
      "http://ufcstats.com/fighter-details/2a7afe14b3a0a058\n",
      "Scraping Carlos Candelario...\n",
      "http://ufcstats.com/fighter-details/760a55d5b6098cbe\n",
      "Scraping Ronaldo Candido...\n",
      "http://ufcstats.com/fighter-details/23fbe02caabcd214\n",
      "Scraping Luiz Cane...\n",
      "http://ufcstats.com/fighter-details/24b033b3daf1c9df\n",
      "Scraping Guido Cannetti...\n",
      "http://ufcstats.com/fighter-details/d05412b513b19621\n",
      "Scraping Jared Cannonier...\n",
      "http://ufcstats.com/fighter-details/13a0275fa13c4d26\n",
      "Scraping Jose Canseco...\n",
      "http://ufcstats.com/fighter-details/03da33a102d9a45f\n",
      "Scraping Cody Canterbury...\n",
      "http://ufcstats.com/fighter-details/23100e8f71f25a4a\n",
      "Scraping Bo Cantrell...\n",
      "http://ufcstats.com/fighter-details/6750e338922a099d\n",
      "Scraping Steve Cantwell...\n",
      "http://ufcstats.com/fighter-details/f1f9e48a0d150757\n",
      "Scraping Paul Capaldo...\n",
      "http://ufcstats.com/fighter-details/83b8fe74224dd642\n",
      "Scraping Phil Caracappa...\n",
      "http://ufcstats.com/fighter-details/bd81a97864acf098\n",
      "Scraping Frank Caracci...\n",
      "http://ufcstats.com/fighter-details/44f9c777fed7ca03\n",
      "Scraping Gina Carano...\n",
      "http://ufcstats.com/fighter-details/899eaba48fa864a6\n",
      "Scraping Dos Caras Jr....\n",
      "http://ufcstats.com/fighter-details/155a02a8b4311057\n",
      "Scraping Bryan Caraway...\n",
      "http://ufcstats.com/fighter-details/5ef0088c1b19beeb\n",
      "Scraping Remo Cardarelli...\n",
      "http://ufcstats.com/fighter-details/e5512a6aed150d8f\n",
      "Scraping Phil Cardella...\n",
      "http://ufcstats.com/fighter-details/f6a7b02c42e9fc5b\n",
      "Scraping Edgar Cardenas...\n",
      "http://ufcstats.com/fighter-details/99a86b134dccc166\n",
      "Scraping Chris Cariaso...\n",
      "http://ufcstats.com/fighter-details/b2e3aca4cd363477\n",
      "Scraping Ronald Carillo...\n",
      "http://ufcstats.com/fighter-details/cbd022eaf2ac546a\n",
      "Scraping Rafael Carino...\n",
      "http://ufcstats.com/fighter-details/08a7080ff5904661\n",
      "Scraping Don Carlo-Clauss...\n",
      "http://ufcstats.com/fighter-details/f59a6de8a5dfe297\n",
      "Scraping Antonio Carlos Junior...\n",
      "http://ufcstats.com/fighter-details/52e76bb4b3e852f3\n",
      "Scraping Spike Carlyle...\n",
      "http://ufcstats.com/fighter-details/be68b375707dcb85\n",
      "Scraping Francis Carmont...\n",
      "http://ufcstats.com/fighter-details/3591d0d5d382a381\n",
      "Scraping Liz Carmouche...\n",
      "http://ufcstats.com/fighter-details/51a0c09cbe9b8472\n",
      "Scraping Roan Carneiro...\n",
      "http://ufcstats.com/fighter-details/1c86754617d9813a\n",
      "Scraping Ariane Carnelossi...\n",
      "http://ufcstats.com/fighter-details/c0d5c0c95c59050b\n",
      "Scraping Luana Carolina...\n",
      "http://ufcstats.com/fighter-details/528b071cf3da7c56\n",
      "Scraping Tim Caron...\n",
      "http://ufcstats.com/fighter-details/b80ea4880f25c187\n",
      "Scraping Clayton Carpenter...\n",
      "http://ufcstats.com/fighter-details/b62d5280966b2460\n",
      "Scraping Gabriel Carrasco...\n",
      "http://ufcstats.com/fighter-details/89ed44801968b8e3\n",
      "Scraping Cody Carrillo...\n",
      "http://ufcstats.com/fighter-details/9346efb4bbaedd08\n",
      "Scraping Cain Carrizosa...\n",
      "http://ufcstats.com/fighter-details/064b7dc68d786254\n",
      "Scraping Roger Carroll...\n",
      "http://ufcstats.com/fighter-details/572a89dbe1f76761\n",
      "Scraping Jonny Carson...\n",
      "http://ufcstats.com/fighter-details/0d49ddc07bd8c747\n",
      "Scraping Scott Carson...\n",
      "http://ufcstats.com/fighter-details/1e3302f9ab6f549a\n",
      "Scraping Shonie Carter...\n",
      "http://ufcstats.com/fighter-details/7b6e40a73b567072\n",
      "Scraping Jack Cartwright...\n",
      "http://ufcstats.com/fighter-details/1f592bfefb0d62a3\n",
      "Scraping Bruno Carvalho...\n",
      "http://ufcstats.com/fighter-details/456c02115efc4a01\n",
      "Scraping Antonio Carvalho...\n",
      "http://ufcstats.com/fighter-details/fef3d17e27e916e7\n",
      "Scraping Rafael Carvalho...\n",
      "http://ufcstats.com/fighter-details/620d8710e89cfeae\n",
      "Scraping Shane Carwin...\n",
      "http://ufcstats.com/fighter-details/68dd7b3783c19f9c\n",
      "Scraping Johnny Case...\n",
      "http://ufcstats.com/fighter-details/1f4b04a926ef1287\n",
      "Scraping Kevin Casey...\n",
      "http://ufcstats.com/fighter-details/8d9586726252dbf7\n",
      "Scraping Cortney Casey...\n",
      "http://ufcstats.com/fighter-details/5f179af5fffeb9f6\n",
      "Scraping Brandon Cash...\n",
      "http://ufcstats.com/fighter-details/3993f7dcb7caf42a\n",
      "Scraping Bendy Casimir...\n",
      "http://ufcstats.com/fighter-details/ec7ac09293d26c05\n",
      "Scraping Dwayne Cason...\n",
      "http://ufcstats.com/fighter-details/31c01fbc2586a5eb\n",
      "Scraping Joe Cason...\n",
      "http://ufcstats.com/fighter-details/2b1c6f28039efe36\n",
      "Scraping John Castaneda...\n",
      "http://ufcstats.com/fighter-details/5fa2974cbd18e05c\n",
      "Scraping Eric Castile...\n",
      "http://ufcstats.com/fighter-details/a0a69dc9914ef6e1\n",
      "Scraping Gil Castillo...\n",
      "http://ufcstats.com/fighter-details/31ceaf0e670c1578\n",
      "Scraping Danny Castillo...\n",
      "http://ufcstats.com/fighter-details/d1e7fc58d4225cdf\n",
      "Scraping Raul Castillo...\n",
      "http://ufcstats.com/fighter-details/feeae92f951f49a9\n",
      "Scraping Jenna Castillo...\n",
      "http://ufcstats.com/fighter-details/e680418329c84ec4\n",
      "Scraping Tim Catalfo...\n",
      "http://ufcstats.com/fighter-details/6ca68b636fbc1f18\n",
      "Scraping Nick Catone...\n",
      "http://ufcstats.com/fighter-details/f8fe2053d73d7bcf\n",
      "Scraping Luke Caudillo...\n",
      "http://ufcstats.com/fighter-details/68d76fd9ecf7431d\n",
      "Scraping Gesias Cavalcante...\n",
      "http://ufcstats.com/fighter-details/2a74bbba57058f12\n",
      "Scraping Rafael Cavalcante...\n",
      "http://ufcstats.com/fighter-details/5c1ca0c72b599a3c\n",
      "Scraping Jacqueline Cavalcanti...\n",
      "http://ufcstats.com/fighter-details/e3964ece586e0635\n",
      "Scraping Igor Cavalcanti...\n",
      "http://ufcstats.com/fighter-details/9c3de7f8966326de\n",
      "Scraping Magnus Cedenblad...\n",
      "http://ufcstats.com/fighter-details/0e21976afc92e4d1\n",
      "Scraping Yosdenis Cedeno...\n",
      "http://ufcstats.com/fighter-details/3e61082025db8137\n",
      "Scraping Henry Cejudo...\n",
      "http://ufcstats.com/fighter-details/056c493bbd76a918\n",
      "Scraping Adam Cella...\n",
      "http://ufcstats.com/fighter-details/b27b8881d7444114\n",
      "Scraping Vinicius Cenci...\n",
      "http://ufcstats.com/fighter-details/f21a152aaa3e95c6\n",
      "Scraping Katlyn Cerminara...\n",
      "http://ufcstats.com/fighter-details/e872e9a9a902c045\n",
      "Scraping Rafael Cerqueira...\n",
      "http://ufcstats.com/fighter-details/09a4447655fd4b7b\n",
      "Scraping Donald Cerrone...\n",
      "http://ufcstats.com/fighter-details/1d00756835ca67c9\n",
      "Scraping Jared Chaffee...\n",
      "http://ufcstats.com/fighter-details/fdf59144e535bc38\n",
      "Scraping Luan Chagas...\n",
      "http://ufcstats.com/fighter-details/9ccf8371fd80d45d\n",
      "Scraping Edgar Chairez...\n",
      "http://ufcstats.com/fighter-details/5ef94841c4bc3f86\n",
      "Scraping Ansar Chalangov...\n",
      "http://ufcstats.com/fighter-details/7342fcc41a4817fa\n",
      "Scraping Alex Chambers...\n",
      "http://ufcstats.com/fighter-details/26b63bc5c0c1f65d\n",
      "Scraping Michael Chandler...\n",
      "http://ufcstats.com/fighter-details/4b93a88f3b1de35b\n",
      "Scraping Chelsea Chandler...\n",
      "http://ufcstats.com/fighter-details/af9efbfd63d39734\n",
      "Scraping Donnie Chappell...\n",
      "http://ufcstats.com/fighter-details/8788beb528894f33\n",
      "Scraping Joe Charles...\n",
      "http://ufcstats.com/fighter-details/19ffeb5e3fffd6d5\n",
      "Scraping Dan Charles...\n",
      "http://ufcstats.com/fighter-details/32a4f1235f0dad73\n",
      "Scraping Morgan Charriere...\n",
      "http://ufcstats.com/fighter-details/5b03b61f9d90125e\n",
      "Scraping Ernest Chavez...\n",
      "http://ufcstats.com/fighter-details/b406da701c479076\n",
      "Scraping Emilio Chavez...\n",
      "http://ufcstats.com/fighter-details/84e8920e59ff14a7\n",
      "Scraping Danny Chavez...\n",
      "http://ufcstats.com/fighter-details/0de720c0f1d4ab9c\n",
      "Scraping Gabriel Checco...\n",
      "http://ufcstats.com/fighter-details/9c5f7d5c6d084b35\n",
      "Scraping Albert Cheng...\n",
      "http://ufcstats.com/fighter-details/d8d7b24d276c8cb0\n",
      "Scraping Fabio Cherant...\n",
      "http://ufcstats.com/fighter-details/78a68f1dade6aaf7\n",
      "Scraping Ion Cherdivara...\n",
      "http://ufcstats.com/fighter-details/c713a845360d604b\n",
      "Scraping Mark Cherico...\n",
      "http://ufcstats.com/fighter-details/79a193111e3bc99b\n",
      "Scraping Macy Chiasson...\n",
      "http://ufcstats.com/fighter-details/9cdd2da1a9104a0b\n",
      "Scraping Michael Chiesa...\n",
      "http://ufcstats.com/fighter-details/c58f51dedb310998\n",
      "Scraping Giga Chikadze...\n",
      "http://ufcstats.com/fighter-details/9560ff14eb3129f7\n",
      "Scraping Khamzat Chimaev...\n",
      "http://ufcstats.com/fighter-details/767755fd74662dbf\n",
      "Scraping Sako Chivitchian...\n",
      "http://ufcstats.com/fighter-details/9f7787e56a6bc0f4\n",
      "Scraping Mu Bae Choi...\n",
      "http://ufcstats.com/fighter-details/371a1c91b24dec2b\n",
      "Scraping Hong Man Choi...\n",
      "http://ufcstats.com/fighter-details/2c104b7e59a72629\n",
      "Scraping Dooho Choi...\n",
      "http://ufcstats.com/fighter-details/e93b04e308913c2e\n",
      "Scraping SeungWoo Choi...\n",
      "http://ufcstats.com/fighter-details/a68575214ecad140\n",
      "Scraping SeungGuk Choi...\n",
      "http://ufcstats.com/fighter-details/adccbc19b22e19af\n",
      "Scraping DongHun Choi...\n",
      "http://ufcstats.com/fighter-details/3be16d817b36098b\n",
      "Scraping John Cholish...\n",
      "http://ufcstats.com/fighter-details/03c9994c5b8958ec\n",
      "Scraping Ryo Chonan...\n",
      "http://ufcstats.com/fighter-details/55a7b2d4e54ffac9\n",
      "Scraping Will Chope...\n",
      "http://ufcstats.com/fighter-details/db5dc7cb80d7d418\n",
      "Scraping Joachim Christensen...\n",
      "http://ufcstats.com/fighter-details/2d447cc91bdaa545\n",
      "Scraping Kevin Christian...\n",
      "http://ufcstats.com/fighter-details/7e9b36a9847db116\n",
      "Scraping Dan Christison...\n",
      "http://ufcstats.com/fighter-details/b369533a577fa97c\n",
      "Scraping Anthony Christodoulou...\n",
      "http://ufcstats.com/fighter-details/4f11e9ce318ffbcb\n",
      "Scraping Murad Chunkaiev...\n",
      "http://ufcstats.com/fighter-details/d4a12dfa4067742f\n",
      "Scraping Cameron Church...\n",
      "http://ufcstats.com/fighter-details/f197ce0cbe69996d\n",
      "Scraping Steven Ciaccio...\n",
      "http://ufcstats.com/fighter-details/eaebaa6801338ea1\n",
      "Scraping Mike Ciesnolevicz...\n",
      "http://ufcstats.com/fighter-details/51b0bb73a1da34bc\n",
      "Scraping Hannah Cifers...\n",
      "http://ufcstats.com/fighter-details/2244d9a2b64b8c3b\n",
      "Scraping Branko Cikatic...\n",
      "http://ufcstats.com/fighter-details/4e5bbc4566049cbf\n",
      "Scraping Nikolajus Cilkinas...\n",
      "http://ufcstats.com/fighter-details/3f3550bf126a5721\n",
      "Scraping Misha Cirkunov...\n",
      "http://ufcstats.com/fighter-details/67f272324a030d00\n",
      "Scraping Johnny Cisneros...\n",
      "http://ufcstats.com/fighter-details/42611508ba8c3298\n",
      "Scraping Laverne Clark...\n",
      "http://ufcstats.com/fighter-details/1c2f2571b18791b6\n",
      "Scraping Logan Clark...\n",
      "http://ufcstats.com/fighter-details/6776260cb0aef647\n",
      "Scraping Mychal Clark...\n",
      "http://ufcstats.com/fighter-details/69108cb8b32efe04\n",
      "Scraping Dominic Clark...\n",
      "http://ufcstats.com/fighter-details/8a64b3f87ad29d1e\n",
      "Scraping Heather Clark...\n",
      "http://ufcstats.com/fighter-details/dd4c16777fb2ccf9\n",
      "Scraping Devin Clark...\n",
      "http://ufcstats.com/fighter-details/cc7040fe76f0ef91\n",
      "Scraping Jessica-Rose Clark...\n",
      "http://ufcstats.com/fighter-details/6c8072b61c276e67\n",
      "Scraping Shannon Clark...\n",
      "http://ufcstats.com/fighter-details/7ae36b3791e0969a\n",
      "Scraping John Clarke...\n",
      "http://ufcstats.com/fighter-details/a77c71a574132188\n",
      "Scraping Mitch Clarke...\n",
      "http://ufcstats.com/fighter-details/c76ec2bc3a57666a\n",
      "Scraping Rich Clementi...\n",
      "http://ufcstats.com/fighter-details/7d21de9c6d7c98b2\n",
      "Scraping Chris Clements...\n",
      "http://ufcstats.com/fighter-details/e5ecaf884b6da2bc\n",
      "Scraping RJ Clifford...\n",
      "http://ufcstats.com/fighter-details/8e32bfcff3ec1717\n",
      "Scraping Mark Climaco...\n",
      "http://ufcstats.com/fighter-details/60098849c703e389\n",
      "Scraping Josh Clopton...\n",
      "http://ufcstats.com/fighter-details/48e96d9cea6d4ab0\n",
      "Scraping Brian Cobb...\n",
      "http://ufcstats.com/fighter-details/3138fab619faf4d1\n",
      "Scraping Darryl Cobb...\n",
      "http://ufcstats.com/fighter-details/dc6d8256ee3dfba5\n",
      "Scraping Dave Cochran...\n",
      "http://ufcstats.com/fighter-details/6dbb1107de9a4a08\n",
      "Scraping Dakota Cochrane...\n",
      "http://ufcstats.com/fighter-details/8fa7e0bc052185ce\n",
      "Scraping Marloes Coenen...\n",
      "http://ufcstats.com/fighter-details/0b77a05bcbd2de74\n",
      "Scraping Marc Cofer...\n",
      "http://ufcstats.com/fighter-details/e90d9d0681270953\n",
      "Scraping John Cofer...\n",
      "http://ufcstats.com/fighter-details/8b260672a21d1fd6\n",
      "Scraping Chris Coggins...\n",
      "http://ufcstats.com/fighter-details/a0c29b13f7a5df32\n",
      "Scraping Felipe Colares...\n",
      "http://ufcstats.com/fighter-details/dbac0a413af64bbe\n",
      "Scraping Wayne Cole...\n",
      "http://ufcstats.com/fighter-details/2eab7a6c8b0ed8cc\n",
      "Scraping Devin Cole...\n",
      "http://ufcstats.com/fighter-details/1174782eacde9b0c\n",
      "Scraping Coltin Cole...\n",
      "http://ufcstats.com/fighter-details/cecd72feb0d640e3\n",
      "Scraping Ivan Cole...\n",
      "http://ufcstats.com/fighter-details/987b80f57190d6d0\n",
      "Scraping Chandler Cole...\n",
      "http://ufcstats.com/fighter-details/5d8a9c95af50280a\n",
      "Scraping Mark Coleman...\n",
      "http://ufcstats.com/fighter-details/21b8a0f5c231096f\n",
      "Scraping Cortez Coleman...\n",
      "http://ufcstats.com/fighter-details/ffb20ae0db47ebe6\n",
      "Scraping Clay Collard...\n",
      "http://ufcstats.com/fighter-details/cc900c6a71ed23f3\n",
      "Scraping Jamie Colleen...\n",
      "http://ufcstats.com/fighter-details/6b64db453edf4c50\n",
      "Scraping Jake Collier...\n",
      "http://ufcstats.com/fighter-details/92fa1401b7927da3\n",
      "Scraping Christian Colombo...\n",
      "http://ufcstats.com/fighter-details/9123c54d0a2b72dd\n",
      "Scraping Willian Colorado...\n",
      "http://ufcstats.com/fighter-details/dfc7f0a2d91ad337\n",
      "Scraping Wes Combs...\n",
      "http://ufcstats.com/fighter-details/a85998eb79650b2c\n",
      "Scraping Rose Conceicao...\n",
      "http://ufcstats.com/fighter-details/a76c07e8e4c76e9a\n",
      "Scraping Carlos Condit...\n",
      "http://ufcstats.com/fighter-details/f9f07bb5a43535ed\n",
      "Scraping Chris Condo...\n",
      "http://ufcstats.com/fighter-details/41e77dc504a192c6\n",
      "Scraping Tristan Connelly...\n",
      "http://ufcstats.com/fighter-details/2ebfbe72ed703925\n",
      "Scraping Marcos Conrado Jr....\n",
      "http://ufcstats.com/fighter-details/d450769115a193c2\n",
      "Scraping Jeremiah Constant...\n",
      "http://ufcstats.com/fighter-details/18f5669a92e99d92\n",
      "Scraping Jonathan Contrestano...\n",
      "http://ufcstats.com/fighter-details/06d4eb8123087123\n",
      "Scraping Bob Cook...\n",
      "http://ufcstats.com/fighter-details/1c061eb6e29eaa0a\n",
      "Scraping Mike Cook...\n",
      "http://ufcstats.com/fighter-details/3ab0df1ddd5f1dc2\n",
      "Scraping Chad Cook...\n",
      "http://ufcstats.com/fighter-details/e6daf9cdbf0da889\n",
      "Scraping TJ Cook...\n",
      "http://ufcstats.com/fighter-details/fa238ecfd048f7d8\n",
      "Scraping Dewey Cooper...\n",
      "http://ufcstats.com/fighter-details/5efaaf313b652dd7\n",
      "Scraping Brett Cooper...\n",
      "http://ufcstats.com/fighter-details/88ffe9745e218dd8\n",
      "Scraping Bill Cooper...\n",
      "http://ufcstats.com/fighter-details/78bd6940d093fd33\n",
      "Scraping Bobby Cooper...\n",
      "http://ufcstats.com/fighter-details/1b51895e5572cfda\n",
      "Scraping Amanda Cooper...\n",
      "http://ufcstats.com/fighter-details/d4a31850a7457f1b\n",
      "Scraping Kit Cope...\n",
      "http://ufcstats.com/fighter-details/ce47f49e5c386a9c\n",
      "Scraping Chris Cope...\n",
      "http://ufcstats.com/fighter-details/8c8c92a12621d7e0\n",
      "Scraping Josh Copeland...\n",
      "http://ufcstats.com/fighter-details/3aa794cbe1e3484b\n",
      "Scraping Michael Cora...\n",
      "http://ufcstats.com/fighter-details/2b91eff985b532cd\n",
      "Scraping Akira Corassani...\n",
      "http://ufcstats.com/fighter-details/3f52ce18fb98008f\n",
      "Scraping Muhsin Corbbrey...\n",
      "http://ufcstats.com/fighter-details/1f9344211ca7fd60\n",
      "Scraping Daniel Cormier...\n",
      "http://ufcstats.com/fighter-details/d967f0128c323de6\n",
      "Scraping Nora Cornolle...\n",
      "http://ufcstats.com/fighter-details/f2b3f4ef3f780168\n",
      "Scraping Clint Coronel...\n",
      "http://ufcstats.com/fighter-details/fe67cd6423f7a8ad\n",
      "Scraping Henry Corrales...\n",
      "http://ufcstats.com/fighter-details/7cb0946d51b8cde7\n",
      "Scraping Bethe Correia...\n",
      "http://ufcstats.com/fighter-details/673ea7dcc786b1b3\n",
      "Scraping Wesley Correira...\n",
      "http://ufcstats.com/fighter-details/4e9fb05d7e5e61b8\n",
      "Scraping Waldo Cortes-Acosta...\n",
      "http://ufcstats.com/fighter-details/fc08099550072fe4\n",
      "Scraping Tracy Cortez...\n",
      "http://ufcstats.com/fighter-details/68d4a891e5cf2029\n",
      "Scraping Reyes Cortez Jr....\n",
      "http://ufcstats.com/fighter-details/1a7d44196949577c\n",
      "Scraping Chad Corvin...\n",
      "http://ufcstats.com/fighter-details/1267b631db78665a\n",
      "Scraping Louis Cosce...\n",
      "http://ufcstats.com/fighter-details/afe8d5b39ff7fca2\n",
      "Scraping Orion Cosce...\n",
      "http://ufcstats.com/fighter-details/2c010b26a3306969\n",
      "Scraping Miguel Cosio...\n",
      "http://ufcstats.com/fighter-details/d150c6fbdb7687f4\n",
      "Scraping Jadson Costa...\n",
      "http://ufcstats.com/fighter-details/222d6b547de2e035\n",
      "Scraping Guilherme Costa...\n",
      "http://ufcstats.com/fighter-details/28877eddb1c0b967\n",
      "Scraping Paulo Costa...\n",
      "http://ufcstats.com/fighter-details/2e5c2aa8e4ab9d82\n",
      "Scraping Randy Costa...\n",
      "http://ufcstats.com/fighter-details/325ad0dd9126d3df\n",
      "Scraping Alessandro Costa...\n",
      "http://ufcstats.com/fighter-details/3fa97913cfd205d3\n",
      "Scraping Melquizael Costa...\n",
      "http://ufcstats.com/fighter-details/20bccc9bb4ceb23e\n",
      "Scraping Oscar Cota...\n",
      "http://ufcstats.com/fighter-details/f584a6e0b5b74604\n",
      "Scraping Patrick Cote...\n",
      "http://ufcstats.com/fighter-details/9fa3bd637edd9aa2\n",
      "Scraping JC Cottrell...\n",
      "http://ufcstats.com/fighter-details/3ec1e4ba98c9c85a\n",
      "Scraping JR Coughran...\n",
      "http://ufcstats.com/fighter-details/8112c9a23dccc759\n",
      "Scraping Rashad Coulter...\n",
      "http://ufcstats.com/fighter-details/d1528ac5675558b1\n",
      "Scraping Dave Courchaine...\n",
      "http://ufcstats.com/fighter-details/79ab17db3b40831a\n",
      "Scraping Randy Couture...\n",
      "http://ufcstats.com/fighter-details/0aa92558424ced9e\n",
      "Scraping Kim Couture...\n",
      "http://ufcstats.com/fighter-details/84c43f0d25f15b0b\n",
      "Scraping Ryan Couture...\n",
      "http://ufcstats.com/fighter-details/46fd223e3ced39b3\n",
      "Scraping Nikk Covert...\n",
      "http://ufcstats.com/fighter-details/400c7b43c86d27d3\n",
      "Scraping Colby Covington...\n",
      "http://ufcstats.com/fighter-details/dc9572dd6ec74859\n",
      "Scraping Hailey Cowan...\n",
      "http://ufcstats.com/fighter-details/3c26c420584d912d\n",
      "Scraping Jeff Cox...\n",
      "http://ufcstats.com/fighter-details/c9bbf1a0285a8076\n",
      "Scraping Nathan Coy...\n",
      "http://ufcstats.com/fighter-details/15ec018d144710db\n",
      "Scraping Andrew Craig...\n",
      "http://ufcstats.com/fighter-details/8a70ceb3edbe757b\n",
      "Scraping Paul Craig...\n",
      "http://ufcstats.com/fighter-details/eabf206b162b3b83\n",
      "Scraping Dan Cramer...\n",
      "http://ufcstats.com/fighter-details/480b702debcb5433\n",
      "Scraping Alberto Crane...\n",
      "http://ufcstats.com/fighter-details/25433871e4eee0f4\n",
      "Scraping Tim Credeur...\n",
      "http://ufcstats.com/fighter-details/89b8d1bf1ff09d1d\n",
      "Scraping Paul Creighton...\n",
      "http://ufcstats.com/fighter-details/ed73c85164a5f5a4\n",
      "Scraping Helena Crevar...\n",
      "http://ufcstats.com/fighter-details/a8c3ce469cb8b130\n",
      "Scraping Alexander Crispim...\n",
      "http://ufcstats.com/fighter-details/15dedd05f8bcb475\n",
      "Scraping Alex Crispin...\n",
      "http://ufcstats.com/fighter-details/8944a0f9b2f0ce6d\n",
      "Scraping Kevin Croom...\n",
      "http://ufcstats.com/fighter-details/35b3772629e27a49\n",
      "Scraping Kiefer Crosbie...\n",
      "http://ufcstats.com/fighter-details/4729c93ba705a3bf\n",
      "Scraping Ken Cross...\n",
      "http://ufcstats.com/fighter-details/923767209632e08a\n",
      "Scraping Jeff Crotty...\n",
      "http://ufcstats.com/fighter-details/98601a40e9d96047\n",
      "Scraping Allen Crowder...\n",
      "http://ufcstats.com/fighter-details/a9d6e047ce48ab63\n",
      "Scraping Daron Cruickshank...\n",
      "http://ufcstats.com/fighter-details/5f99b2bafb10305f\n",
      "Scraping Richard Crunkilton...\n",
      "http://ufcstats.com/fighter-details/22ee260735da0d58\n",
      "Scraping Jimmy Crute...\n",
      "http://ufcstats.com/fighter-details/70e1f8a821b72c8b\n",
      "Scraping Marcio Cruz...\n",
      "http://ufcstats.com/fighter-details/6aa1cbc1466e9a0b\n",
      "Scraping Dominick Cruz...\n",
      "http://ufcstats.com/fighter-details/10f3ba6cd2f44a97\n",
      "Scraping Aalon Cruz...\n",
      "http://ufcstats.com/fighter-details/003d82fa384ca1d0\n",
      "Scraping Timmy Cuamba...\n",
      "http://ufcstats.com/fighter-details/0e46690e55a8df75\n",
      "Scraping Jay Cucciniello...\n",
      "http://ufcstats.com/fighter-details/683ea28a198936fe\n",
      "Scraping Emilio Cuellar...\n",
      "http://ufcstats.com/fighter-details/3aeb69b4a13ff0e8\n",
      "Scraping Josh Culibao...\n",
      "http://ufcstats.com/fighter-details/6751eacd16bd59bc\n",
      "Scraping Chris Culley...\n",
      "http://ufcstats.com/fighter-details/e59b13321562eed3\n",
      "Scraping Abel Cullum...\n",
      "http://ufcstats.com/fighter-details/2f8f3c69522db931\n",
      "Scraping Zak Cummings...\n",
      "http://ufcstats.com/fighter-details/4ba8d454f762005d\n",
      "Scraping Everett Cummings...\n",
      "http://ufcstats.com/fighter-details/05e4be525cb3578c\n",
      "Scraping Patrick Cummins...\n",
      "http://ufcstats.com/fighter-details/e51e5cb722bd47a8\n",
      "Scraping Luke Cummo...\n",
      "http://ufcstats.com/fighter-details/93ce4ac89e3d7652\n",
      "Scraping Hugo Cunha...\n",
      "http://ufcstats.com/fighter-details/46a17755f80f63e8\n",
      "Scraping Alton Cunningham...\n",
      "http://ufcstats.com/fighter-details/305bde44ff664788\n",
      "Scraping AJ Cunningham...\n",
      "http://ufcstats.com/fighter-details/d1053e55f00e53fe\n",
      "Scraping Santo Curatolo...\n",
      "http://ufcstats.com/fighter-details/b8b765e320a8db39\n",
      "Scraping Larry Cureton...\n",
      "http://ufcstats.com/fighter-details/46f11d15c0134fe3\n",
      "Scraping Jeff Curran...\n",
      "http://ufcstats.com/fighter-details/a8ea84cbe1655f0a\n",
      "Scraping Kailin Curran...\n",
      "http://ufcstats.com/fighter-details/05b43e0ead3df345\n",
      "Scraping Pat Curran...\n",
      "http://ufcstats.com/fighter-details/d8291d0dd63da29c\n",
      "Scraping Will Currie...\n",
      "http://ufcstats.com/fighter-details/b8ff02d5703eca3a\n",
      "Scraping Chris Curtis...\n",
      "http://ufcstats.com/fighter-details/5442f1bc4b47eaf3\n",
      "Scraping Ion Cutelaba...\n",
      "http://ufcstats.com/fighter-details/cd13728ae1151f46\n",
      "Scraping Gleidson Cutis...\n",
      "http://ufcstats.com/fighter-details/44a94bbde42246e4\n",
      "Scraping Sarah D'alelio...\n",
      "http://ufcstats.com/fighter-details/ac45450f75d14f16\n",
      "Scraping Marcos da Matta...\n",
      "http://ufcstats.com/fighter-details/3b6d84343579fd33\n",
      "Scraping Henrique da Silva...\n",
      "http://ufcstats.com/fighter-details/b0bd0c5425668b8f\n",
      "Scraping Ariane da Silva...\n",
      "http://ufcstats.com/fighter-details/6551c64fbcd1a467\n",
      "Scraping Alex Da Silva...\n",
      "http://ufcstats.com/fighter-details/c3ded6f7155f9ea4\n",
      "Scraping Henrique Da Silva Lopes...\n",
      "http://ufcstats.com/fighter-details/1f8cd7634e8286ff\n",
      "Scraping Nicolas Dalby...\n",
      "http://ufcstats.com/fighter-details/9d19d9e4aa2662e8\n",
      "Scraping Paul Daley...\n",
      "http://ufcstats.com/fighter-details/23725c826c481e7f\n",
      "Scraping Dave Dalgliesh...\n",
      "http://ufcstats.com/fighter-details/ddbd0d6259ce57cc\n",
      "Scraping Richard Dalton...\n",
      "http://ufcstats.com/fighter-details/6cd3dfc54f01287f\n",
      "Scraping Aisling Daly...\n",
      "http://ufcstats.com/fighter-details/e50cd77732d39967\n",
      "Scraping Marko Damiani...\n",
      "http://ufcstats.com/fighter-details/6e9b5c74c0860deb\n",
      "Scraping Leonardo Damiani...\n",
      "http://ufcstats.com/fighter-details/acd870570949d8a2\n",
      "Scraping Rodrigo Damm...\n",
      "http://ufcstats.com/fighter-details/a20d7dfaba74c067\n",
      "Scraping Carina Damm...\n",
      "http://ufcstats.com/fighter-details/033343da4c0cff8a\n",
      "Scraping Batgerel Danaa...\n",
      "http://ufcstats.com/fighter-details/3b0a516d2921e0d6\n",
      "Scraping Cindy Dandois...\n",
      "http://ufcstats.com/fighter-details/9eef6584fab21fbb\n",
      "Scraping Peter Danesoe...\n",
      "http://ufcstats.com/fighter-details/5f119b24c0f9679c\n",
      "Scraping Jarjis Danho...\n",
      "http://ufcstats.com/fighter-details/8614b7134913f5d5\n",
      "Scraping Raymond Daniels...\n",
      "http://ufcstats.com/fighter-details/fccb0fee256b7b4d\n",
      "Scraping Marques Daniels...\n",
      "http://ufcstats.com/fighter-details/55a80a9365bc107d\n",
      "Scraping Anvarbek Daniyalbekov...\n",
      "http://ufcstats.com/fighter-details/859e0dafd04fe1ca\n",
      "Scraping Alexandre Dantas...\n",
      "http://ufcstats.com/fighter-details/8dc46e9a7895ce1a\n",
      "Scraping Eduardo Dantas...\n",
      "http://ufcstats.com/fighter-details/676a2e5ec4d7338c\n",
      "Scraping Mac Danzig...\n",
      "http://ufcstats.com/fighter-details/86f582852a5b240a\n",
      "Scraping Karen Darabedyan...\n",
      "http://ufcstats.com/fighter-details/d2fa318f34d0aadc\n",
      "Scraping Beneil Dariush...\n",
      "http://ufcstats.com/fighter-details/08af939f41b5a57b\n",
      "Scraping Sean Daugherty...\n",
      "http://ufcstats.com/fighter-details/a683f9ddb70aa4bd\n",
      "Scraping Kyle Daukaus...\n",
      "http://ufcstats.com/fighter-details/d6c0cdd7e467c440\n",
      "Scraping Chris Daukaus...\n",
      "http://ufcstats.com/fighter-details/d0aaedcf7ccd0b45\n",
      "Scraping Brian Davidson...\n",
      "http://ufcstats.com/fighter-details/42775dc893603154\n",
      "Scraping Rick Davis...\n",
      "http://ufcstats.com/fighter-details/2549d63da9c456cb\n",
      "Scraping Marcus Davis...\n",
      "http://ufcstats.com/fighter-details/b7d524c77c27389b\n",
      "Scraping LC Davis...\n",
      "http://ufcstats.com/fighter-details/6dab8ce5e4bffe77\n",
      "Scraping Phil Davis...\n",
      "http://ufcstats.com/fighter-details/902ab9197b83d0db\n",
      "Scraping Lemont Davis...\n",
      "http://ufcstats.com/fighter-details/a993ef2dd36cea5f\n",
      "Scraping Mike Davis...\n",
      "http://ufcstats.com/fighter-details/c8661e204c66f325\n",
      "Scraping Justin Davis...\n",
      "http://ufcstats.com/fighter-details/20697b334f6c0a45\n",
      "Scraping Alexis Davis...\n",
      "http://ufcstats.com/fighter-details/4c2d90e335e6df19\n",
      "Scraping Danny Davis...\n",
      "http://ufcstats.com/fighter-details/570d40f993171b19\n",
      "Scraping Brandon Davis...\n",
      "http://ufcstats.com/fighter-details/cc351e408bbb7d43\n",
      "Scraping Mike Davis...\n",
      "http://ufcstats.com/fighter-details/fb3e61720be4690c\n",
      "Scraping Hakeem Dawodu...\n",
      "http://ufcstats.com/fighter-details/2c9d00968f818270\n",
      "Scraping Grant Dawson...\n",
      "http://ufcstats.com/fighter-details/99bd51917728c25d\n",
      "Scraping Jason Day...\n",
      "http://ufcstats.com/fighter-details/a6fd2173d5e2d7f0\n",
      "Scraping Martin Day...\n",
      "http://ufcstats.com/fighter-details/ea3dcc417c322064\n",
      "Scraping Angel De Anda...\n",
      "http://ufcstats.com/fighter-details/4b450aa602611baa\n",
      "Scraping Yorgan De Castro...\n",
      "http://ufcstats.com/fighter-details/1eff7bc0f815b270\n",
      "Scraping Geraldo de Freitas...\n",
      "http://ufcstats.com/fighter-details/9cfbfae5fa1fdd93\n",
      "Scraping Philip De Fries...\n",
      "http://ufcstats.com/fighter-details/6ef65b6a152e49d5\n",
      "Scraping Chris de la Rocha...\n",
      "http://ufcstats.com/fighter-details/e51ee8ded927fc51\n",
      "Scraping Montana De La Rosa...\n",
      "http://ufcstats.com/fighter-details/80d8aed0ca9b00f3\n",
      "Scraping Mark De La Rosa...\n",
      "http://ufcstats.com/fighter-details/f57dd0bfa8c17813\n",
      "Scraping Mike de la Torre...\n",
      "http://ufcstats.com/fighter-details/1971869b7e054261\n",
      "Scraping Rodrigo de Lima...\n",
      "http://ufcstats.com/fighter-details/a4dc47001f202bcd\n",
      "Scraping Edilberto de Oliveira...\n",
      "http://ufcstats.com/fighter-details/afdb76fbd86f6d11\n",
      "Scraping Johil de Oliveira...\n",
      "http://ufcstats.com/fighter-details/f9aa6376ae16bfb4\n",
      "Scraping Jorge de Oliveira...\n",
      "http://ufcstats.com/fighter-details/ddf3e0ea10ea6d8c\n",
      "Scraping Isabela de Padua...\n",
      "http://ufcstats.com/fighter-details/e0f959f65d0406b4\n",
      "Scraping Gloria de Paula...\n",
      "http://ufcstats.com/fighter-details/5dd180c8b3196786\n",
      "Scraping Germaine de Randamie...\n",
      "http://ufcstats.com/fighter-details/1d239d571e342453\n",
      "Scraping Reinier de Ridder...\n",
      "http://ufcstats.com/fighter-details/d549cefc7c54ab78\n",
      "Scraping Crezio de Souza...\n",
      "http://ufcstats.com/fighter-details/3746e21bb508391a\n",
      "Scraping Carl Deaton...\n",
      "http://ufcstats.com/fighter-details/914a897455693650\n",
      "Scraping Tom DeBlass...\n",
      "http://ufcstats.com/fighter-details/0bcfe2513cb3bc39\n",
      "Scraping Issac DeJesus...\n",
      "http://ufcstats.com/fighter-details/0e2c2daf11b5d8f2\n",
      "Scraping Rafael  Del Real...\n",
      "http://ufcstats.com/fighter-details/e82b2adcaeff71ec\n",
      "Scraping Shane del Rosario...\n",
      "http://ufcstats.com/fighter-details/85980f5da429c0a6\n",
      "Scraping Wallen Del Rosario...\n",
      "http://ufcstats.com/fighter-details/a62f85f6a6c19a4c\n",
      "Scraping Humberto DeLeon...\n",
      "http://ufcstats.com/fighter-details/bfaf4c87936b4fae\n",
      "Scraping Rolando Delgado...\n",
      "http://ufcstats.com/fighter-details/37b1696e6d115957\n",
      "Scraping Israel Delgado...\n",
      "http://ufcstats.com/fighter-details/01f4bcd26ac08ad5\n",
      "Scraping Jose Delgado...\n",
      "http://ufcstats.com/fighter-details/7d6ceff6747f2de2\n",
      "Scraping Ante Delija...\n",
      "http://ufcstats.com/fighter-details/7d8435c56043b0ae\n",
      "Scraping Jack Della Maddalena...\n",
      "http://ufcstats.com/fighter-details/6b453bc35a823c3f\n",
      "Scraping Roland Delorme...\n",
      "http://ufcstats.com/fighter-details/173acb3f920082b8\n",
      "Scraping Jon Delos Reyes...\n",
      "http://ufcstats.com/fighter-details/0d0351c20169a499\n",
      "Scraping Jason DeLucia...\n",
      "http://ufcstats.com/fighter-details/6ceff86fae4f6b3b\n",
      "Scraping Yadier DelValle...\n",
      "http://ufcstats.com/fighter-details/70380ccdc81915b8\n",
      "Scraping Justin DeMoney...\n",
      "http://ufcstats.com/fighter-details/985bca5a097fb3f4\n",
      "Scraping Vanessa Demopoulos...\n",
      "http://ufcstats.com/fighter-details/2c483cf443f38ece\n",
      "Scraping Chris Dempsey...\n",
      "http://ufcstats.com/fighter-details/dfae5da5676e4194\n",
      "Scraping Nick Denis...\n",
      "http://ufcstats.com/fighter-details/e4aaaa34535e32b6\n",
      "Scraping Thomas Denny...\n",
      "http://ufcstats.com/fighter-details/a11a6ee8eeb03c18\n",
      "Scraping Robert Densley...\n",
      "http://ufcstats.com/fighter-details/b72f3cafa6376e35\n",
      "Scraping Jason Dent...\n",
      "http://ufcstats.com/fighter-details/fa8b9e6b0c2269f8\n",
      "Scraping Mackenzie Dern...\n",
      "http://ufcstats.com/fighter-details/7447e9f28508106a\n",
      "Scraping Booker DeRousse...\n",
      "http://ufcstats.com/fighter-details/f2c91b67f71bbeab\n",
      "Scraping Tony DeSouza...\n",
      "http://ufcstats.com/fighter-details/6ad9058b7c7898b0\n",
      "Scraping Robelis Despaigne...\n",
      "http://ufcstats.com/fighter-details/140567899d98978a\n",
      "Scraping Cory Devela...\n",
      "http://ufcstats.com/fighter-details/48544433372ecfa6\n",
      "Scraping John Devine...\n",
      "http://ufcstats.com/fighter-details/2bcc39af95d6f2e8\n",
      "Scraping Edwin DeWees...\n",
      "http://ufcstats.com/fighter-details/75bbd2206a15319f\n",
      "Scraping Alessio Di Chirico...\n",
      "http://ufcstats.com/fighter-details/77d7295d1b22c694\n",
      "Scraping Micol Di Segni...\n",
      "http://ufcstats.com/fighter-details/8126e4dff0cdf69e\n",
      "Scraping Cyrille Diabate...\n",
      "http://ufcstats.com/fighter-details/43563a32c3f10e95\n",
      "Scraping Thomas Diagne...\n",
      "http://ufcstats.com/fighter-details/8567466ae167216b\n",
      "Scraping Marc Diakiese...\n",
      "http://ufcstats.com/fighter-details/32c355b04fc57f3a\n",
      "Scraping Tyler Diamond...\n",
      "http://ufcstats.com/fighter-details/f5f6419c5f00abad\n",
      "Scraping Blood Diamond...\n",
      "http://ufcstats.com/fighter-details/9edf2c9082cc2cd8\n",
      "Scraping Eldo Xavier Dias...\n",
      "http://ufcstats.com/fighter-details/ee5df903f80c6816\n",
      "Scraping Rafael Dias...\n",
      "http://ufcstats.com/fighter-details/b5abaa65f87938eb\n",
      "Scraping Hacran Dias...\n",
      "http://ufcstats.com/fighter-details/ed209f6618c82e41\n",
      "Scraping Victor Dias...\n",
      "http://ufcstats.com/fighter-details/f7202b3130421d27\n",
      "Scraping Nick Diaz...\n",
      "http://ufcstats.com/fighter-details/f57a8a52ca401ed9\n",
      "Scraping Nate Diaz...\n",
      "http://ufcstats.com/fighter-details/8355922d564b152c\n",
      "Scraping Michael Diaz...\n",
      "http://ufcstats.com/fighter-details/5e7a48e469770615\n",
      "Scraping Ryan Diaz...\n",
      "http://ufcstats.com/fighter-details/ceee5dd37253199a\n",
      "Scraping Adrian Diaz...\n",
      "http://ufcstats.com/fighter-details/bfa8f263815cfa2e\n",
      "Scraping Ozzy Diaz...\n",
      "http://ufcstats.com/fighter-details/6967153c7edb4d87\n",
      "Scraping Mark Dickman...\n",
      "http://ufcstats.com/fighter-details/2482ef3331a82e75\n",
      "Scraping Josh Diekmann...\n",
      "http://ufcstats.com/fighter-details/414bddf0c80c41e1\n",
      "Scraping Kyle Dietz...\n",
      "http://ufcstats.com/fighter-details/31da66df48c0c1a0\n",
      "Scraping Seth Dikun...\n",
      "http://ufcstats.com/fighter-details/eb42d4febfafefd1\n",
      "Scraping TJ Dillashaw...\n",
      "http://ufcstats.com/fighter-details/c849740a3ff51931\n",
      "Scraping Ralph Dillon...\n",
      "http://ufcstats.com/fighter-details/b4f7a2d8ecc5e0c3\n",
      "Scraping Drew Dimanlig...\n",
      "http://ufcstats.com/fighter-details/cc2ad11b1f9d818b\n",
      "Scraping Ding Meng...\n",
      "http://ufcstats.com/fighter-details/e0664abaa023fd6f\n",
      "Scraping Rodolfo Marques Diniz...\n",
      "http://ufcstats.com/fighter-details/2d2239d0f6fa83dd\n",
      "Scraping Jhonata Diniz...\n",
      "http://ufcstats.com/fighter-details/25f9a5f3e8a52618\n",
      "Scraping Helio Dipp...\n",
      "http://ufcstats.com/fighter-details/73eb2a552c92a821\n",
      "Scraping Rico DiSciullo...\n",
      "http://ufcstats.com/fighter-details/ec7f7263bf36579b\n",
      "Scraping Matt Dixon...\n",
      "http://ufcstats.com/fighter-details/1db445a4468447d0\n",
      "Scraping John Dixson...\n",
      "http://ufcstats.com/fighter-details/ad4e9055bf8cd04d\n",
      "Scraping Anthony Do...\n",
      "http://ufcstats.com/fighter-details/7c9aeba0c4d4bd78\n",
      "Scraping Russell Doane...\n",
      "http://ufcstats.com/fighter-details/f50d95223751e6ca\n",
      "Scraping Drew Dober...\n",
      "http://ufcstats.com/fighter-details/519e4fe37ce9ff75\n",
      "Scraping Shana Dobson...\n",
      "http://ufcstats.com/fighter-details/122ac9b816d8b71c\n",
      "Scraping AJ Dobson...\n",
      "http://ufcstats.com/fighter-details/009c4420727149ea\n",
      "Scraping David Dodd...\n",
      "http://ufcstats.com/fighter-details/c2a7623f398d9bd7\n",
      "Scraping John Dodson...\n",
      "http://ufcstats.com/fighter-details/99506df1af6c8b3b\n",
      "Scraping Joe Doerksen...\n",
      "http://ufcstats.com/fighter-details/dbaaf42313af90fa\n",
      "Scraping Mike Dolce...\n",
      "http://ufcstats.com/fighter-details/29b5791e51e7e832\n",
      "Scraping Roman Dolidze...\n",
      "http://ufcstats.com/fighter-details/327d5f279895110d\n",
      "Scraping Cameron Dollar...\n",
      "http://ufcstats.com/fighter-details/3bbcd63a016d9715\n",
      "Scraping CB Dollaway...\n",
      "http://ufcstats.com/fighter-details/5d7bdab5e03e3216\n",
      "Scraping Dennis Dombrow...\n",
      "http://ufcstats.com/fighter-details/4145caa2c999fbac\n",
      "Scraping OJ Dominguez...\n",
      "http://ufcstats.com/fighter-details/1a50e734bb54861a\n",
      "Scraping John Donaldson...\n",
      "http://ufcstats.com/fighter-details/1c610f900f9884ab\n",
      "Scraping Dong Huaxiang...\n",
      "http://ufcstats.com/fighter-details/bad82b681819b272\n",
      "Scraping Cody Donovan...\n",
      "http://ufcstats.com/fighter-details/7bc96507e4b38d3b\n",
      "Scraping Houston Dorr...\n",
      "http://ufcstats.com/fighter-details/312f47c3d2f83ffa\n",
      "Scraping Rafael Dos Anjos...\n",
      "http://ufcstats.com/fighter-details/6a2f7c151031653d\n",
      "Scraping Junior Dos Santos...\n",
      "http://ufcstats.com/fighter-details/63def5a5662a6917\n",
      "Scraping Geronimo dos Santos...\n",
      "http://ufcstats.com/fighter-details/b51f6791c794e289\n",
      "Scraping Antonio Dos Santos...\n",
      "http://ufcstats.com/fighter-details/81b8b3fb019dc69d\n",
      "Scraping Anderson Dos Santos...\n",
      "http://ufcstats.com/fighter-details/bbc9ab95fa766493\n",
      "Scraping Acacio Dos Santos...\n",
      "http://ufcstats.com/fighter-details/957562fdf68a725a\n",
      "Scraping Rayanne dos Santos...\n",
      "http://ufcstats.com/fighter-details/02bb48869eb7ac8f\n",
      "Scraping Felipe dos Santos...\n",
      "http://ufcstats.com/fighter-details/5cdf5339728f580d\n",
      "Scraping Tiago dos Santos e Silva...\n",
      "http://ufcstats.com/fighter-details/8ce87f7e3a9baed2\n",
      "Scraping Oleksandr Doskalchuk...\n",
      "http://ufcstats.com/fighter-details/86cb6f5b1ca98dc0\n",
      "Scraping David Douglas...\n",
      "http://ufcstats.com/fighter-details/7cf0944b88966118\n",
      "Scraping Damion Douglas...\n",
      "http://ufcstats.com/fighter-details/ce3b669e39418414\n",
      "Scraping Cedric Doumbe...\n",
      "http://ufcstats.com/fighter-details/5159e6ee100c717e\n",
      "Scraping John Dowdy...\n",
      "http://ufcstats.com/fighter-details/e780ccc79a209985\n",
      "Scraping Jordan Dowdy...\n",
      "http://ufcstats.com/fighter-details/0d9312337fdce39a\n",
      "Scraping Danny Downes...\n",
      "http://ufcstats.com/fighter-details/a66395395b5f1394\n",
      "Scraping Derek Downey...\n",
      "http://ufcstats.com/fighter-details/b05086131c6f5dc5\n",
      "Scraping John Doyle...\n",
      "http://ufcstats.com/fighter-details/0509b954421bb327\n",
      "Scraping Edson Drago...\n",
      "http://ufcstats.com/fighter-details/f9c7fe2682af3802\n",
      "Scraping Anthony Drilich...\n",
      "http://ufcstats.com/fighter-details/c2c4052f58f54988\n",
      "Scraping Kyle Driscoll...\n",
      "http://ufcstats.com/fighter-details/e5e148d4363deff8\n",
      "Scraping Chris Drumm...\n",
      "http://ufcstats.com/fighter-details/5fd834edd92c9e50\n",
      "Scraping Tomasz Drwal...\n",
      "http://ufcstats.com/fighter-details/679a9054e2815943\n",
      "Scraping Robert Drysdale...\n",
      "http://ufcstats.com/fighter-details/d2a9be6bf2de624c\n",
      "Scraping Dricus Du Plessis...\n",
      "http://ufcstats.com/fighter-details/0d7b51c9d2649a6e\n",
      "Scraping Hugo Duarte...\n",
      "http://ufcstats.com/fighter-details/706404da0775dcbc\n",
      "Scraping Antonio Duarte...\n",
      "http://ufcstats.com/fighter-details/29b5d32584e02d8d\n",
      "Scraping Joe Duarte...\n",
      "http://ufcstats.com/fighter-details/454c3e9d4cd4a1b3\n",
      "Scraping Yuneisy Duben...\n",
      "http://ufcstats.com/fighter-details/c3d2b9bcb4cead6b\n",
      "Scraping Matthieu Duclos...\n",
      "http://ufcstats.com/fighter-details/ec322adbabbfa6e7\n",
      "Scraping Emily Ducote...\n",
      "http://ufcstats.com/fighter-details/02f8fedc18cbd26c\n",
      "Scraping Viktoriia Dudakova...\n",
      "http://ufcstats.com/fighter-details/6c9b66b43663f2f7\n",
      "Scraping Milana Dudieva...\n",
      "http://ufcstats.com/fighter-details/072a10e85f7d4bff\n",
      "Scraping Adin Duenas...\n",
      "http://ufcstats.com/fighter-details/cb6c45b26b0a877a\n",
      "Scraping Todd Duffee...\n",
      "http://ufcstats.com/fighter-details/bda04c573563cc2e\n",
      "Scraping Joe Duffy...\n",
      "http://ufcstats.com/fighter-details/654ae722109a0d31\n",
      "Scraping Jack Duffy...\n",
      "http://ufcstats.com/fighter-details/cea51876d8a514a0\n",
      "Scraping Alexis Dufresne...\n",
      "http://ufcstats.com/fighter-details/4ae4049426e0161d\n",
      "Scraping Jessamyn Duke...\n",
      "http://ufcstats.com/fighter-details/a7ddae0be8b78147\n",
      "Scraping Islam Dulatov...\n",
      "http://ufcstats.com/fighter-details/e803242fb2e41112\n",
      "Scraping Isaac Dulgarian...\n",
      "http://ufcstats.com/fighter-details/a57cb948c4c70a47\n",
      "Scraping Kelly Dullanty...\n",
      "http://ufcstats.com/fighter-details/1a225f04aa6e0739\n",
      "Scraping Sedriques Dumas...\n",
      "http://ufcstats.com/fighter-details/4e6738062d469256\n",
      "Scraping Norma Dumont...\n",
      "http://ufcstats.com/fighter-details/d3f5d33d61cd00c9\n",
      "Scraping Christian Leroy Duncan...\n",
      "http://ufcstats.com/fighter-details/a93f94c923c3a9cb\n",
      "Scraping Evan Dunham...\n",
      "http://ufcstats.com/fighter-details/e5c9de15bb58b1c6\n",
      "Scraping Alex Dunworth...\n",
      "http://ufcstats.com/fighter-details/31732a614e7a3d1d\n",
      "Scraping Tom Duquesnoy...\n",
      "http://ufcstats.com/fighter-details/e979c76341f19b22\n",
      "Scraping Albert Duraev...\n",
      "http://ufcstats.com/fighter-details/6b7c7460855dbbb9\n",
      "Scraping Reuben Duran...\n",
      "http://ufcstats.com/fighter-details/4417980b3e798abf\n",
      "Scraping Cody Durden...\n",
      "http://ufcstats.com/fighter-details/7f6ed67d3ed3c036\n",
      "Scraping Luiz Dutra...\n",
      "http://ufcstats.com/fighter-details/2153a7f8396a46cc\n",
      "Scraping Rilley Dutro...\n",
      "http://ufcstats.com/fighter-details/43db649da89fac4b\n",
      "Scraping Bill Duvall...\n",
      "http://ufcstats.com/fighter-details/7df4d3c38792b083\n",
      "Scraping Merab Dvalishvili...\n",
      "http://ufcstats.com/fighter-details/c03520b5c88ed6b4\n",
      "Scraping David Dvorak...\n",
      "http://ufcstats.com/fighter-details/9ada30894bf04e19\n",
      "Scraping Matt Dwyer...\n",
      "http://ufcstats.com/fighter-details/8f0d576beba1cfcd\n",
      "Scraping Rolando Dy...\n",
      "http://ufcstats.com/fighter-details/55ed59d541f8b90c\n",
      "Scraping Ben Earwood...\n",
      "http://ufcstats.com/fighter-details/ee457ef1e1c326c1\n",
      "Scraping Cody East...\n",
      "http://ufcstats.com/fighter-details/5713c1d2fac539ac\n",
      "Scraping Marvin Eastman...\n",
      "http://ufcstats.com/fighter-details/05866d8c3a321856\n",
      "Scraping Mike Easton...\n",
      "http://ufcstats.com/fighter-details/bc7230f231701d66\n",
      "Scraping Maurice Eazel...\n",
      "http://ufcstats.com/fighter-details/4acb99524a9a81ab\n",
      "Scraping Vincent Eazelle...\n",
      "http://ufcstats.com/fighter-details/ec421d5de0aea624\n",
      "Scraping Ross Ebanez...\n",
      "http://ufcstats.com/fighter-details/a5b0bd216d8ba84e\n",
      "Scraping Brian Ebersole...\n",
      "http://ufcstats.com/fighter-details/32ba186f4b0e3267\n",
      "Scraping Roybert Echeverria...\n",
      "http://ufcstats.com/fighter-details/20b13e96668caaa4\n",
      "Scraping Mark Eddiva...\n",
      "http://ufcstats.com/fighter-details/40ff198adda94b9f\n",
      "Scraping Frankie Edgar...\n",
      "http://ufcstats.com/fighter-details/f2688492b9a525a3\n",
      "Scraping Abdul-Kerim Edilov...\n",
      "http://ufcstats.com/fighter-details/37e03538c960bac6\n",
      "Scraping Johnny Eduardo...\n",
      "http://ufcstats.com/fighter-details/528c24b99fbaab79\n",
      "Scraping Yves Edwards...\n",
      "http://ufcstats.com/fighter-details/5f04e3d58d9ce982\n",
      "Scraping Justin Edwards...\n",
      "http://ufcstats.com/fighter-details/e56daf7725a0b5ab\n",
      "Scraping Leon Edwards...\n",
      "http://ufcstats.com/fighter-details/f1fac969a1d70b08\n",
      "Scraping Te Edwards...\n",
      "http://ufcstats.com/fighter-details/ef44e4ea9050f2ea\n",
      "Scraping Adli Edwards...\n",
      "http://ufcstats.com/fighter-details/e6904a03a66e711d\n",
      "Scraping Joselyne Edwards...\n",
      "http://ufcstats.com/fighter-details/f9ab66e67240db7b\n",
      "Scraping Tom Egan...\n",
      "http://ufcstats.com/fighter-details/eae4aec1a5a8ff01\n",
      "Scraping Stephanie Egger...\n",
      "http://ufcstats.com/fighter-details/5e6294b37bbef029\n",
      "Scraping Justin Eilers...\n",
      "http://ufcstats.com/fighter-details/27fc9218a3653e3c\n",
      "Scraping Jon Olav Einemo...\n",
      "http://ufcstats.com/fighter-details/0577808d22dfe79c\n",
      "Scraping Per Eklund...\n",
      "http://ufcstats.com/fighter-details/58bc81376286b3d3\n",
      "Scraping John Elam...\n",
      "http://ufcstats.com/fighter-details/22d80fb67e50ab0b\n",
      "Scraping Evan Elder...\n",
      "http://ufcstats.com/fighter-details/d9a56ecb6e94f02e\n",
      "Scraping John Paul Elias...\n",
      "http://ufcstats.com/fighter-details/e873203fd50542f6\n",
      "Scraping Joao Elias...\n",
      "http://ufcstats.com/fighter-details/1a064688481f66e1\n",
      "Scraping Saul Elizondo...\n",
      "http://ufcstats.com/fighter-details/e295b96f135d758a\n",
      "Scraping Darren Elkins...\n",
      "http://ufcstats.com/fighter-details/92a9aa9c93192871\n",
      "Scraping Jake Ellenberger...\n",
      "http://ufcstats.com/fighter-details/d81ac739417d7f53\n",
      "Scraping Joe Ellenberger...\n",
      "http://ufcstats.com/fighter-details/8e8e4487c621aa1c\n",
      "Scraping Tim Elliott...\n",
      "http://ufcstats.com/fighter-details/c96d9178c9ed9e62\n",
      "Scraping Oban Elliott...\n",
      "http://ufcstats.com/fighter-details/6b56e94a59b7b134\n",
      "Scraping Eddy Ellis...\n",
      "http://ufcstats.com/fighter-details/e60d773a0a42048a\n",
      "Scraping Lisa Ellis...\n",
      "http://ufcstats.com/fighter-details/77350fd0e6d1dba8\n",
      "Scraping Anna Elmose...\n",
      "http://ufcstats.com/fighter-details/1536a25e16fc299b\n",
      "Scraping Cameron Else...\n",
      "http://ufcstats.com/fighter-details/5f3da9a9610d8969\n",
      "Scraping Aaron Ely...\n",
      "http://ufcstats.com/fighter-details/1741343f0ca34dd5\n",
      "Scraping Sovannahry Em...\n",
      "http://ufcstats.com/fighter-details/45c8fed13a62fe92\n",
      "Scraping Ramazan Emeev...\n",
      "http://ufcstats.com/fighter-details/abd5fb12437eda21\n",
      "Scraping Aleksander Emelianenko...\n",
      "http://ufcstats.com/fighter-details/f54200f1dfb9b5d4\n",
      "Scraping Fedor Emelianenko...\n",
      "http://ufcstats.com/fighter-details/b8da6f5c80ae2d15\n",
      "Scraping Rob Emerson...\n",
      "http://ufcstats.com/fighter-details/dc0f07928009a127\n",
      "Scraping Jamall Emmers...\n",
      "http://ufcstats.com/fighter-details/e00a3dee329a51f7\n",
      "Scraping Josh Emmett...\n",
      "http://ufcstats.com/fighter-details/fba03cd6cc28dc41\n",
      "Scraping Marius Enache...\n",
      "http://ufcstats.com/fighter-details/e3f443e4cbc3da8f\n",
      "Scraping Kevin Engel...\n",
      "http://ufcstats.com/fighter-details/d2f310b5b072e986\n",
      "Scraping Kolton Englund...\n",
      "http://ufcstats.com/fighter-details/4122da4f791b2f4f\n",
      "Scraping Oliver Enkamp...\n",
      "http://ufcstats.com/fighter-details/330bafba312face4\n",
      "Scraping Alex Enlund...\n",
      "http://ufcstats.com/fighter-details/d238217e0f8ea8e1\n",
      "Scraping Kenny Ento...\n",
      "http://ufcstats.com/fighter-details/daf9be103c1edbbd\n",
      "Scraping Ian Entwistle...\n",
      "http://ufcstats.com/fighter-details/d7adfcfdf7c6c1f8\n",
      "Scraping Andy Enz...\n",
      "http://ufcstats.com/fighter-details/993d385f5a475375\n",
      "Scraping Won Jin Eoh...\n",
      "http://ufcstats.com/fighter-details/bc7cf284c1c2f16e\n",
      "Scraping Josh Epps...\n",
      "http://ufcstats.com/fighter-details/984b0c4c6e773a1c\n",
      "Scraping Abdellah Er-Ramy...\n",
      "http://ufcstats.com/fighter-details/b593cd58b0afffb0\n",
      "Scraping Steve Erceg...\n",
      "http://ufcstats.com/fighter-details/32ab52e5de93092d\n",
      "Scraping Tom Erikson...\n",
      "http://ufcstats.com/fighter-details/7b9a85e5ff31ef47\n",
      "Scraping Konstantin Erokhin...\n",
      "http://ufcstats.com/fighter-details/22061ff217907c78\n",
      "Scraping Julian Erosa...\n",
      "http://ufcstats.com/fighter-details/902ec2cc48c8ae8a\n",
      "Scraping Jarno Errens...\n",
      "http://ufcstats.com/fighter-details/082eba4cd80f736f\n",
      "Scraping Ivan Erslan...\n",
      "http://ufcstats.com/fighter-details/64ad3e3b0efa30bb\n",
      "Scraping Nick Ertl...\n",
      "http://ufcstats.com/fighter-details/74061adb224be3cc\n",
      "Scraping Chel Erwin-Davis...\n",
      "http://ufcstats.com/fighter-details/c26ea30823f37316\n",
      "Scraping Bobby Escalante...\n",
      "http://ufcstats.com/fighter-details/f7ede18b4ec4ec1f\n",
      "Scraping Eric Esch...\n",
      "http://ufcstats.com/fighter-details/0e4daed84a8f39a6\n",
      "Scraping Pro Escobedo...\n",
      "http://ufcstats.com/fighter-details/b36874652ed7715d\n",
      "Scraping Cole Escovedo...\n",
      "http://ufcstats.com/fighter-details/5df17b3620145578\n",
      "Scraping Efrain Escudero...\n",
      "http://ufcstats.com/fighter-details/83fd97284f4bb4a4\n",
      "Scraping Evan Esguerra...\n",
      "http://ufcstats.com/fighter-details/ed220e87bef0cc64\n",
      "Scraping Carla Esparza...\n",
      "http://ufcstats.com/fighter-details/d910665038efc639\n",
      "Scraping Juan Espino...\n",
      "http://ufcstats.com/fighter-details/ccf5dc41417e9daf\n",
      "Scraping Jordan Espinosa...\n",
      "http://ufcstats.com/fighter-details/215a70f073a7b726\n",
      "Scraping Jodie Esquibel...\n",
      "http://ufcstats.com/fighter-details/411539901068522f\n",
      "Scraping Rafael Estevam...\n",
      "http://ufcstats.com/fighter-details/83455a9d17f57dae\n",
      "Scraping Achilles Estremadura...\n",
      "http://ufcstats.com/fighter-details/41f3cfdab0b22236\n",
      "Scraping Shaun Etchell...\n",
      "http://ufcstats.com/fighter-details/ea9bfe9c25037bba\n",
      "Scraping Terry Etim...\n",
      "http://ufcstats.com/fighter-details/33011768c3c4dc9a\n",
      "Scraping Fred Ettish...\n",
      "http://ufcstats.com/fighter-details/8d5daf67983b65ba\n",
      "Scraping Scott Ettling...\n",
      "http://ufcstats.com/fighter-details/74b5736f1df40be3\n",
      "Scraping Sijara Eubanks...\n",
      "http://ufcstats.com/fighter-details/4234f0097c83fa62\n",
      "Scraping Billy Evangelista...\n",
      "http://ufcstats.com/fighter-details/9766ed20b68c7c33\n",
      "Scraping Rashad Evans...\n",
      "http://ufcstats.com/fighter-details/ee779c43a8926d52\n",
      "Scraping Doug Evans...\n",
      "http://ufcstats.com/fighter-details/d3de4a24f7eefac8\n",
      "Scraping Ashlee Evans-Smith...\n",
      "http://ufcstats.com/fighter-details/fc6e681bf6658faf\n",
      "Scraping Dan Evensen...\n",
      "http://ufcstats.com/fighter-details/dd8aec6de7035943\n",
      "Scraping Tonya Evinger...\n",
      "http://ufcstats.com/fighter-details/b12a1d19ee383b7c\n",
      "Scraping Movsar Evloev...\n",
      "http://ufcstats.com/fighter-details/76e2870ffafbe38f\n",
      "Scraping Andre Ewell...\n",
      "http://ufcstats.com/fighter-details/5f6f049d54728e88\n",
      "Scraping Neal Ewing...\n",
      "http://ufcstats.com/fighter-details/0798f558681d0eb5\n",
      "Scraping Jessica Eye...\n",
      "http://ufcstats.com/fighter-details/f72465a784c1b084\n",
      "Scraping Edward Faaloloto...\n",
      "http://ufcstats.com/fighter-details/6224e8d0a34264eb\n",
      "Scraping Urijah Faber...\n",
      "http://ufcstats.com/fighter-details/78114b7199cef90c\n",
      "Scraping Melinda Fabian...\n",
      "http://ufcstats.com/fighter-details/8c020156779f7888\n",
      "Scraping Wagnney Fabiano...\n",
      "http://ufcstats.com/fighter-details/40389d39a92f5bfa\n",
      "Scraping Bartosz Fabinski...\n",
      "http://ufcstats.com/fighter-details/e17ac6410c8377f4\n",
      "Scraping Ron Faircloth...\n",
      "http://ufcstats.com/fighter-details/453ee00c3e1ae9dd\n",
      "Scraping Jason Fairn...\n",
      "http://ufcstats.com/fighter-details/adea9f0090aa8e14\n",
      "Scraping Zarah Fairn...\n",
      "http://ufcstats.com/fighter-details/862b0b3375aa4b6e\n",
      "Scraping Rinat Fakhretdinov...\n",
      "http://ufcstats.com/fighter-details/8f765fd5775a8873\n",
      "Scraping Maiquel Falcao...\n",
      "http://ufcstats.com/fighter-details/d58478ded5534695\n",
      "Scraping Pedro Falcao...\n",
      "http://ufcstats.com/fighter-details/f7be1db194e03d7e\n",
      "Scraping Brodie Farber...\n",
      "http://ufcstats.com/fighter-details/91d73ee59347ac16\n",
      "Scraping Joao Paulo Faria...\n",
      "http://ufcstats.com/fighter-details/04e9955f33e0c267\n",
      "Scraping Kalindra Faria...\n",
      "http://ufcstats.com/fighter-details/27b164b0d1833df0\n",
      "Scraping Jair Farias...\n",
      "http://ufcstats.com/fighter-details/431262bbc69215dc\n",
      "Scraping Chance Farrar...\n",
      "http://ufcstats.com/fighter-details/49c7236c737d7e59\n",
      "Scraping Rico Farrington...\n",
      "http://ufcstats.com/fighter-details/f89e6e66b9b112de\n",
      "Scraping Kelly Faszholz...\n",
      "http://ufcstats.com/fighter-details/9c42a0de8e012870\n",
      "Scraping Rodney Faverus...\n",
      "http://ufcstats.com/fighter-details/5af26b3201690d29\n",
      "Scraping Paul Felder...\n",
      "http://ufcstats.com/fighter-details/e5010b1b94ca5755\n",
      "Scraping Carlos Felipe...\n",
      "http://ufcstats.com/fighter-details/a2ea77e974c5889f\n",
      "Scraping JP Felty...\n",
      "http://ufcstats.com/fighter-details/954e3f4e2b0e6510\n",
      "Scraping Feng Pengchao...\n",
      "http://ufcstats.com/fighter-details/86597694317e5e1b\n",
      "Scraping Feng Xiaocan...\n",
      "http://ufcstats.com/fighter-details/c940b42df95bbd28\n",
      "Scraping Kevin Ferguson...\n",
      "http://ufcstats.com/fighter-details/27541033b97c076d\n",
      "Scraping Rhadi Ferguson...\n",
      "http://ufcstats.com/fighter-details/15f4550e017f6c7d\n",
      "Scraping Tony Ferguson...\n",
      "http://ufcstats.com/fighter-details/22a92d7f62195791\n",
      "Scraping Josh Ferguson...\n",
      "http://ufcstats.com/fighter-details/b0f316c60f8d3b47\n",
      "Scraping CJ Fernandes...\n",
      "http://ufcstats.com/fighter-details/979f7edbb6980b0d\n",
      "Scraping Bibiano Fernandes...\n",
      "http://ufcstats.com/fighter-details/cbc071cb20ea59c7\n",
      "Scraping Gabriella Fernandes...\n",
      "http://ufcstats.com/fighter-details/a6eb54ae17a551be\n",
      "Scraping Kaue Fernandes...\n",
      "http://ufcstats.com/fighter-details/ec13c393d029297d\n",
      "Scraping Emily Fernandez...\n",
      "http://ufcstats.com/fighter-details/7ee1babb99f30115\n",
      "Scraping Lucas Fernando...\n",
      "http://ufcstats.com/fighter-details/3df223aeaacecf3f\n",
      "Scraping Alexandre Ferreira...\n",
      "http://ufcstats.com/fighter-details/28ba5f27e473420c\n",
      "Scraping Cezar Ferreira...\n",
      "http://ufcstats.com/fighter-details/dbc17725b887860a\n",
      "Scraping Diego Ferreira...\n",
      "http://ufcstats.com/fighter-details/f53d4f21d1b5f2dc\n",
      "Scraping Erisson Ferreira...\n",
      "http://ufcstats.com/fighter-details/1c2a8915f8431507\n",
      "Scraping Brunno Ferreira...\n",
      "http://ufcstats.com/fighter-details/1e719d4b676dc19a\n",
      "Scraping Scott Ferrozzo...\n",
      "http://ufcstats.com/fighter-details/977081bc01197656\n",
      "Scraping Timo Feucht...\n",
      "http://ufcstats.com/fighter-details/8c21eb9fd7c4c203\n",
      "Scraping Andre Fialho...\n",
      "http://ufcstats.com/fighter-details/33efaf2d0941cfcf\n",
      "Scraping Drew Fickett...\n",
      "http://ufcstats.com/fighter-details/d814f5192e58fb2f\n",
      "Scraping Scott Fiedler...\n",
      "http://ufcstats.com/fighter-details/0ec821423baa26bd\n",
      "Scraping Ron Fields...\n",
      "http://ufcstats.com/fighter-details/6e380a4d73ab4f0e\n",
      "Scraping Michal Figlak...\n",
      "http://ufcstats.com/fighter-details/b4c57a8c2b773e82\n",
      "Scraping Deiveson Figueiredo...\n",
      "http://ufcstats.com/fighter-details/aa72b0f831d0bfe5\n",
      "Scraping Francisco Figueiredo...\n",
      "http://ufcstats.com/fighter-details/cdadae5363b66eef\n",
      "Scraping Anthony Figueroa...\n",
      "http://ufcstats.com/fighter-details/daff32bc96d1eabf\n",
      "Scraping Edwin Figueroa...\n",
      "http://ufcstats.com/fighter-details/bbfca6d5c27d9cd8\n",
      "Scraping Paulo Filho...\n",
      "http://ufcstats.com/fighter-details/2abdead94ce73552\n",
      "Scraping Jafel Filho...\n",
      "http://ufcstats.com/fighter-details/65adf3856c4d9256\n",
      "Scraping Andre Fili...\n",
      "http://ufcstats.com/fighter-details/8fd808923cffff82\n",
      "Scraping Mirko Filipovic...\n",
      "http://ufcstats.com/fighter-details/c32fb8c0f6471a4d\n",
      "Scraping Brady Fink...\n",
      "http://ufcstats.com/fighter-details/997b4f52f76a0b53\n",
      "Scraping Jesse Finney...\n",
      "http://ufcstats.com/fighter-details/0496cdac0bc9edd8\n",
      "Scraping Jan Finney...\n",
      "http://ufcstats.com/fighter-details/3317823959d32a05\n",
      "Scraping Torrez Finney...\n",
      "http://ufcstats.com/fighter-details/fbb60f24af5d5a02\n",
      "Scraping Luigi Fioravanti...\n",
      "http://ufcstats.com/fighter-details/9583662df31d943f\n",
      "Scraping Nick Fiore...\n",
      "http://ufcstats.com/fighter-details/036e96c1c12b8a59\n",
      "Scraping Manon Fiorot...\n",
      "http://ufcstats.com/fighter-details/34ff304266360297\n",
      "Scraping Luiz Firmino...\n",
      "http://ufcstats.com/fighter-details/16d09e800ad7ec79\n",
      "Scraping Spencer Fisher...\n",
      "http://ufcstats.com/fighter-details/f34312c2ccfa0e00\n",
      "Scraping Chris Fishgold...\n",
      "http://ufcstats.com/fighter-details/bebb4ae55ac2bf6f\n",
      "Scraping Bryanna Fissori...\n",
      "http://ufcstats.com/fighter-details/5517bd590dbbe1f8\n",
      "Scraping Jon Fitch...\n",
      "http://ufcstats.com/fighter-details/6f018c039b4d5d80\n",
      "Scraping Isi Fitikefu...\n",
      "http://ufcstats.com/fighter-details/b8dc5fbf8338adc5\n",
      "Scraping Rafael Fiziev...\n",
      "http://ufcstats.com/fighter-details/c814b4c899793af6\n",
      "Scraping Colin Fletcher...\n",
      "http://ufcstats.com/fighter-details/7d09200f6a77b20e\n",
      "Scraping AJ Fletcher...\n",
      "http://ufcstats.com/fighter-details/725b1abc9a39d873\n",
      "Scraping Nathan Fletcher...\n",
      "http://ufcstats.com/fighter-details/a2d342ffc83913ed\n",
      "Scraping Jimmy Flick...\n",
      "http://ufcstats.com/fighter-details/09e62c450e754913\n",
      "Scraping Luke Flores...\n",
      "http://ufcstats.com/fighter-details/b5f44dcb863f595b\n",
      "Scraping Ty Flores...\n",
      "http://ufcstats.com/fighter-details/4bb0f74d5e26f89a\n",
      "Scraping Alejandro Flores...\n",
      "http://ufcstats.com/fighter-details/d23d5960ac5e117c\n",
      "Scraping Kenny Florian...\n",
      "http://ufcstats.com/fighter-details/cb139171ed1b69fe\n",
      "Scraping Darrius Flowers...\n",
      "http://ufcstats.com/fighter-details/65db4065e2bc107d\n",
      "Scraping Cody Floyd...\n",
      "http://ufcstats.com/fighter-details/8164250600b7c91b\n",
      "Scraping Bobby Flynn...\n",
      "http://ufcstats.com/fighter-details/c97fc5fbf7d32b8a\n",
      "Scraping Caros Fodor...\n",
      "http://ufcstats.com/fighter-details/01d2ed8c502e3828\n",
      "Scraping Mal Foki...\n",
      "http://ufcstats.com/fighter-details/fa534853eb195270\n",
      "Scraping Matt Foki...\n",
      "http://ufcstats.com/fighter-details/5de61b03868035ff\n",
      "Scraping AJ Fonseca...\n",
      "http://ufcstats.com/fighter-details/0adf1aacda5e26ac\n",
      "Scraping Rob Font...\n",
      "http://ufcstats.com/fighter-details/05339613bf8e9808\n",
      "Scraping Claudionor Fontinelle...\n",
      "http://ufcstats.com/fighter-details/7a82635ffa9b59fe\n",
      "Scraping Jesse Forbes...\n",
      "http://ufcstats.com/fighter-details/947eccadb72f4f6f\n",
      "Scraping Sterling Ford...\n",
      "http://ufcstats.com/fighter-details/a71ce6ff0b4a9dbb\n",
      "Scraping Codale Ford...\n",
      "http://ufcstats.com/fighter-details/5340123d826ceadb\n",
      "Scraping Raheam Forest...\n",
      "http://ufcstats.com/fighter-details/90390dd1b0791e7f\n",
      "Scraping Jussier Formiga...\n",
      "http://ufcstats.com/fighter-details/b102c26727306ab6\n",
      "Scraping Renee Forte...\n",
      "http://ufcstats.com/fighter-details/44bc27bfa76dcd9e\n",
      "Scraping Brianna Fortino...\n",
      "http://ufcstats.com/fighter-details/b53c46f613f6f248\n",
      "Scraping Marcel Fortuna...\n",
      "http://ufcstats.com/fighter-details/d761b3766e38c5db\n",
      "Scraping Brian Foster...\n",
      "http://ufcstats.com/fighter-details/3dc3022232b79c7a\n",
      "Scraping Xavier Foupa-Pokam...\n",
      "http://ufcstats.com/fighter-details/ec33146e43e58933\n",
      "Scraping Mason Fowler...\n",
      "http://ufcstats.com/fighter-details/d745d4146be48679\n",
      "Scraping Brandon Foxworth...\n",
      "http://ufcstats.com/fighter-details/f65a0eb902f9476b\n",
      "Scraping Hermes Franca...\n",
      "http://ufcstats.com/fighter-details/e0ec3c3b6b611f7e\n",
      "Scraping Glaico Franca Moreira...\n",
      "http://ufcstats.com/fighter-details/00a3ff40c4b2cf21\n",
      "Scraping Francisco France...\n",
      "http://ufcstats.com/fighter-details/ecfdbf38681a59ba\n",
      "Scraping John Franchi...\n",
      "http://ufcstats.com/fighter-details/b9532d815060de7f\n",
      "Scraping Rich Franklin...\n",
      "http://ufcstats.com/fighter-details/d897897060f10a3a\n",
      "Scraping Xavier Franklin...\n",
      "http://ufcstats.com/fighter-details/90957a918e26bf9c\n",
      "Scraping Zoila Frausto...\n",
      "http://ufcstats.com/fighter-details/040d3b4c735541aa\n",
      "Scraping Stephanie Frausto...\n",
      "http://ufcstats.com/fighter-details/fee02819a271c050\n",
      "Scraping Zane Frazier...\n",
      "http://ufcstats.com/fighter-details/d3711d3784b76255\n",
      "Scraping Gary Frazier...\n",
      "http://ufcstats.com/fighter-details/3beeeafcbc8b4cbc\n",
      "Scraping Justin Frazier...\n",
      "http://ufcstats.com/fighter-details/78863e4a28204a6b\n",
      "Scraping Ian Freeman...\n",
      "http://ufcstats.com/fighter-details/b4bc2e3353a770b5\n",
      "Scraping Jason Freeman...\n",
      "http://ufcstats.com/fighter-details/5870bd1eadf4f322\n",
      "Scraping Willamy Freire...\n",
      "http://ufcstats.com/fighter-details/f1f37d667bcd0d27\n",
      "Scraping Patricio Freire...\n",
      "http://ufcstats.com/fighter-details/98a58c26c5b1ed17\n",
      "Scraping Patricky Freire...\n",
      "http://ufcstats.com/fighter-details/90e6dde9113830bd\n",
      "Scraping Jeremy  Freitag...\n",
      "http://ufcstats.com/fighter-details/a47e9ec288c91067\n",
      "Scraping Rafael Freitas...\n",
      "http://ufcstats.com/fighter-details/14b9e0f2679a2205\n",
      "Scraping Donavon Frelow...\n",
      "http://ufcstats.com/fighter-details/9aa56f004b2bca07\n",
      "Scraping Josh Fremd...\n",
      "http://ufcstats.com/fighter-details/ca43de99b07b6b40\n",
      "Scraping Clay French...\n",
      "http://ufcstats.com/fighter-details/73321668ff977f1b\n",
      "Scraping Mike French...\n",
      "http://ufcstats.com/fighter-details/756f45905fb20cb5\n",
      "Scraping Matt Frevola...\n",
      "http://ufcstats.com/fighter-details/dccb63727f2f5f74\n",
      "Scraping Jinh Yu Frey...\n",
      "http://ufcstats.com/fighter-details/d05cb1e8d1b885d8\n",
      "Scraping Artem Frolov...\n",
      "http://ufcstats.com/fighter-details/ee704df0afd74558\n",
      "Scraping Sarah Frota...\n",
      "http://ufcstats.com/fighter-details/1641ef250e9de19b\n",
      "Scraping Daniel Frunza...\n",
      "http://ufcstats.com/fighter-details/7cec3c4a5e7b6d68\n",
      "Scraping Don Frye...\n",
      "http://ufcstats.com/fighter-details/271fe91f4ba9d2c5\n",
      "Scraping Tony Fryklund...\n",
      "http://ufcstats.com/fighter-details/253de74457bd6374\n",
      "Scraping Adam Fugitt...\n",
      "http://ufcstats.com/fighter-details/a01a62132460a98d\n",
      "Scraping Jesse Fujarczyk...\n",
      "http://ufcstats.com/fighter-details/c3c38c86f5ab9b5c\n",
      "Scraping Katsuhisa Fujii...\n",
      "http://ufcstats.com/fighter-details/d71d968dc6ecfdaf\n",
      "Scraping Megumi Fujii...\n",
      "http://ufcstats.com/fighter-details/fb6c531726447ff3\n",
      "Scraping Kazuyuki Fujita...\n",
      "http://ufcstats.com/fighter-details/b1605ea39fba6af6\n",
      "Scraping Keisuke Fujiwara...\n",
      "http://ufcstats.com/fighter-details/ccd58ff71e260ed5\n",
      "Scraping Riki Fukuda...\n",
      "http://ufcstats.com/fighter-details/7c35f869033901ae\n",
      "Scraping Masio Fullen...\n",
      "http://ufcstats.com/fighter-details/4638cc6479cc0afe\n",
      "Scraping Travis Fulton...\n",
      "http://ufcstats.com/fighter-details/911fb265462f0d94\n",
      "Scraping Sam Fulton...\n",
      "http://ufcstats.com/fighter-details/1f5f75658551f2d3\n",
      "Scraping Masakatsu Funaki...\n",
      "http://ufcstats.com/fighter-details/aa3153a9941b4d44\n",
      "Scraping Ricardo Funch...\n",
      "http://ufcstats.com/fighter-details/e9e1acc96536bb4f\n",
      "Scraping Katsuaki Furuki...\n",
      "http://ufcstats.com/fighter-details/c3e2eca94b2320bc\n",
      "Scraping James Gabert...\n",
      "http://ufcstats.com/fighter-details/fcd8b623892b9a10\n",
      "Scraping Gustavo Gabriel...\n",
      "http://ufcstats.com/fighter-details/fe98f86284a6eeb3\n",
      "Scraping Claudia Gadelha...\n",
      "http://ufcstats.com/fighter-details/ec34349e7dffcde7\n",
      "Scraping Alavutdin Gadjiev...\n",
      "http://ufcstats.com/fighter-details/a7a79b8efbceaaac\n",
      "Scraping Magomed Gadzhiyasulov...\n",
      "http://ufcstats.com/fighter-details/6e344b71421103da\n",
      "Scraping Justin Gaethje...\n",
      "http://ufcstats.com/fighter-details/9e8f6c728eb01124\n",
      "Scraping Sheila Gaff...\n",
      "http://ufcstats.com/fighter-details/837d30395faca41e\n",
      "Scraping Muin Gafurov...\n",
      "http://ufcstats.com/fighter-details/a54660deb6a8489c\n",
      "Scraping Mitch Gagnon...\n",
      "http://ufcstats.com/fighter-details/b8592b4a383696cd\n",
      "Scraping Brandon Gaines...\n",
      "http://ufcstats.com/fighter-details/8e6cfbd455f0f9c2\n",
      "Scraping Travis Galbraith...\n",
      "http://ufcstats.com/fighter-details/06dc1a58663579d2\n",
      "Scraping Dave Galera...\n",
      "http://ufcstats.com/fighter-details/0876d21328cf4a45\n",
      "Scraping Zelg Galesic...\n",
      "http://ufcstats.com/fighter-details/8a1b4330c7957961\n",
      "Scraping Mickey Gall...\n",
      "http://ufcstats.com/fighter-details/9e50097a89442158\n",
      "Scraping Daniel Gallemore...\n",
      "http://ufcstats.com/fighter-details/96706c75a2b14164\n",
      "Scraping Tom Gallicchio...\n",
      "http://ufcstats.com/fighter-details/cc81c92fe2254935\n",
      "Scraping Turrell Galloway...\n",
      "http://ufcstats.com/fighter-details/7e654edcddd71550\n",
      "Scraping Eric Galvan...\n",
      "http://ufcstats.com/fighter-details/ad3fdba28a7540cf\n",
      "Scraping Andre Galvao...\n",
      "http://ufcstats.com/fighter-details/45fe6765c56d8018\n",
      "Scraping Marcos Galvao...\n",
      "http://ufcstats.com/fighter-details/e15d0a2519d6a0b5\n",
      "Scraping Lucas Gamaza...\n",
      "http://ufcstats.com/fighter-details/289a3b69b85da7cd\n",
      "Scraping Joey Gambino...\n",
      "http://ufcstats.com/fighter-details/10559c53de0b950e\n",
      "Scraping Manvel Gamburyan...\n",
      "http://ufcstats.com/fighter-details/cc6f9d1e89f3449a\n",
      "Scraping Mateusz Gamrot...\n",
      "http://ufcstats.com/fighter-details/72db2a14ffa73ece\n",
      "Scraping Shamil Gamzatov...\n",
      "http://ufcstats.com/fighter-details/0d980975001ae3d8\n",
      "Scraping Ariel Gandulla...\n",
      "http://ufcstats.com/fighter-details/41904fc4d3f5bffc\n",
      "Scraping Ciryl Gane...\n",
      "http://ufcstats.com/fighter-details/787bb1f087ccff8a\n",
      "Scraping Sean Gannon...\n",
      "http://ufcstats.com/fighter-details/6d7886b094b471ac\n",
      "Scraping Junye Gao...\n",
      "http://ufcstats.com/fighter-details/8b27d25ce0221d60\n",
      "Scraping Eduardo Garagorri...\n",
      "http://ufcstats.com/fighter-details/7bde387d50829adf\n",
      "Scraping Cody Garbrandt...\n",
      "http://ufcstats.com/fighter-details/d8c7c61b176e3994\n",
      "Scraping Leonard Garcia...\n",
      "http://ufcstats.com/fighter-details/917e53fa0adea0d3\n",
      "Scraping Edgar Garcia...\n",
      "http://ufcstats.com/fighter-details/8d49545dadf9b919\n",
      "Scraping Alejandro Garcia...\n",
      "http://ufcstats.com/fighter-details/e5dc36e0aba7e9da\n",
      "Scraping Alex Garcia...\n",
      "http://ufcstats.com/fighter-details/a2b12c3f3d60ff69\n",
      "Scraping Nick Garcia...\n",
      "http://ufcstats.com/fighter-details/8a04d94dfcfab159\n",
      "Scraping Steve Garcia...\n",
      "http://ufcstats.com/fighter-details/97cf1a2c7c5e7889\n",
      "Scraping Elias Garcia...\n",
      "http://ufcstats.com/fighter-details/ac5a7400da3a9a41\n",
      "Scraping Rafa Garcia...\n",
      "http://ufcstats.com/fighter-details/e132d47bd9efbbe0\n",
      "Scraping Fernie Garcia...\n",
      "http://ufcstats.com/fighter-details/9e92e1ca498d7244\n",
      "Scraping Rulon Gardner...\n",
      "http://ufcstats.com/fighter-details/4f7e290e71d60f87\n",
      "Scraping David Gardner...\n",
      "http://ufcstats.com/fighter-details/70167689d6a01793\n",
      "Scraping Pablo Garza...\n",
      "http://ufcstats.com/fighter-details/8e5bfd4e82352340\n",
      "Scraping Azamat Gashimov...\n",
      "http://ufcstats.com/fighter-details/a1b0715c4fd2dbd3\n",
      "Scraping Brian Gassaway...\n",
      "http://ufcstats.com/fighter-details/e4770d5ed44a3970\n",
      "Scraping Kelvin Gastelum...\n",
      "http://ufcstats.com/fighter-details/8c0580d4fff106c1\n",
      "Scraping Willie Gates...\n",
      "http://ufcstats.com/fighter-details/6ded9184b2284645\n",
      "Scraping Melissa Gatto...\n",
      "http://ufcstats.com/fighter-details/a4a80dd7336ffd59\n",
      "Scraping Sean Gauci...\n",
      "http://ufcstats.com/fighter-details/d758f272d94f5866\n",
      "Scraping Louis Gaudinot...\n",
      "http://ufcstats.com/fighter-details/b72a60a0cadff408\n",
      "Scraping Ateba Gautier...\n",
      "http://ufcstats.com/fighter-details/2f815ed5f8278ba6\n",
      "Scraping Manuel Gaxhja...\n",
      "http://ufcstats.com/fighter-details/618643d0d5c0631d\n",
      "Scraping Shamil Gaziev...\n",
      "http://ufcstats.com/fighter-details/6747ccd6d1acd266\n",
      "Scraping Charlene Gellner...\n",
      "http://ufcstats.com/fighter-details/effd0b70e6749ab2\n",
      "Scraping Chad George...\n",
      "http://ufcstats.com/fighter-details/14e797332ea32cdb\n",
      "Scraping Paul Georgieff...\n",
      "http://ufcstats.com/fighter-details/2f1700b3a4a09bc7\n",
      "Scraping Brian Geraghty...\n",
      "http://ufcstats.com/fighter-details/15edcf67ccf5be84\n",
      "Scraping Derek Getzel...\n",
      "http://ufcstats.com/fighter-details/42883268854b78be\n",
      "Scraping Karine Gevorgyan...\n",
      "http://ufcstats.com/fighter-details/2db0c114414d4f06\n",
      "Scraping Yanis Ghemmouri...\n",
      "http://ufcstats.com/fighter-details/eb70e786bbdf1d16\n",
      "Scraping Darrel Gholar...\n",
      "http://ufcstats.com/fighter-details/a24e080000fa7a35\n",
      "Scraping Tiki Ghosn...\n",
      "http://ufcstats.com/fighter-details/cb6783c39c01d896\n",
      "Scraping Christos Giagos...\n",
      "http://ufcstats.com/fighter-details/de45aaae23dfa392\n",
      "Scraping Joe Giannetti...\n",
      "http://ufcstats.com/fighter-details/946db8a378903cc3\n",
      "Scraping Nick Gibbons...\n",
      "http://ufcstats.com/fighter-details/96a221341035b701\n",
      "Scraping James Giboo...\n",
      "http://ufcstats.com/fighter-details/f74e037b97917027\n",
      "Scraping Lance Gibson...\n",
      "http://ufcstats.com/fighter-details/63eedfcc73071d41\n",
      "Scraping Lee Gibson...\n",
      "http://ufcstats.com/fighter-details/69db199087a1a792\n",
      "Scraping Cody Gibson...\n",
      "http://ufcstats.com/fighter-details/700a674c042b7a96\n",
      "Scraping Chase Gibson...\n",
      "http://ufcstats.com/fighter-details/09439946214993bc\n",
      "Scraping Kenny Giddens...\n",
      "http://ufcstats.com/fighter-details/db8b800176d26f6e\n",
      "Scraping Thomas Gifford...\n",
      "http://ufcstats.com/fighter-details/e7f51d9f9e9259e7\n",
      "Scraping Joseph Gigliotti...\n",
      "http://ufcstats.com/fighter-details/83825fad27ab3581\n",
      "Scraping Joey Gilbert...\n",
      "http://ufcstats.com/fighter-details/6bb1d2b714d4b3bc\n",
      "Scraping Trevin Giles...\n",
      "http://ufcstats.com/fighter-details/b27a1fcb56a3035a\n",
      "Scraping Kultar Gill...\n",
      "http://ufcstats.com/fighter-details/42c96a9c4802e2e1\n",
      "Scraping Jesse Gillespie...\n",
      "http://ufcstats.com/fighter-details/160b931119c1bf91\n",
      "Scraping Gregor Gillespie...\n",
      "http://ufcstats.com/fighter-details/84ff027394f7e470\n",
      "Scraping Jason Gilliam...\n",
      "http://ufcstats.com/fighter-details/91720876db0ee468\n",
      "Scraping Micheal Gillmore...\n",
      "http://ufcstats.com/fighter-details/ce175eaafe867d1f\n",
      "Scraping Krishaun Gilmore...\n",
      "http://ufcstats.com/fighter-details/10ccdcd14c3dfcf1\n",
      "Scraping Alex Gilpin...\n",
      "http://ufcstats.com/fighter-details/762c69860eef65d8\n",
      "Scraping Bob Gilstrap...\n",
      "http://ufcstats.com/fighter-details/c96518b7f6881004\n",
      "Scraping Eperaim Ginting...\n",
      "http://ufcstats.com/fighter-details/bad8ed7d714f1493\n",
      "Scraping Demetrius Gioulacos...\n",
      "http://ufcstats.com/fighter-details/a58114c6dd0add64\n",
      "Scraping Billy Giovanella...\n",
      "http://ufcstats.com/fighter-details/c1ea31a904fe08a9\n",
      "Scraping He-Man Gipson...\n",
      "http://ufcstats.com/fighter-details/3e03cec9767d37e6\n",
      "Scraping Israel Giron...\n",
      "http://ufcstats.com/fighter-details/4b4f6abdce986be6\n",
      "Scraping Brandon Girtz...\n",
      "http://ufcstats.com/fighter-details/81f1810f72df8f25\n",
      "Scraping Jason Glaza...\n",
      "http://ufcstats.com/fighter-details/fda067e842b07466\n",
      "Scraping Mike Glenn...\n",
      "http://ufcstats.com/fighter-details/ed133185689088b3\n",
      "Scraping Ricky Glenn...\n",
      "http://ufcstats.com/fighter-details/814ff3018127e8fc\n",
      "Scraping Mark Godbeer...\n",
      "http://ufcstats.com/fighter-details/ad56b3f00ca38dfd\n",
      "Scraping Clint Godfrey...\n",
      "http://ufcstats.com/fighter-details/bd85ca0bb4f26cfc\n",
      "Scraping Loopy Godinez...\n",
      "http://ufcstats.com/fighter-details/8e5d953bdb9ae5e7\n",
      "Scraping Jason Godsey...\n",
      "http://ufcstats.com/fighter-details/5ca158b1cc9cb242\n",
      "Scraping Allan Goes...\n",
      "http://ufcstats.com/fighter-details/e62b36885ecdac27\n",
      "Scraping Billy Ray Goff...\n",
      "http://ufcstats.com/fighter-details/fa07345cc9db5cc9\n",
      "Scraping Amiran Gogoladze...\n",
      "http://ufcstats.com/fighter-details/5d1636b6c1688502\n",
      "Scraping Jonny Goh...\n",
      "http://ufcstats.com/fighter-details/e86af30738a5452a\n",
      "Scraping Hannah Goldy...\n",
      "http://ufcstats.com/fighter-details/26e3f3928b1891d9\n",
      "Scraping Marcelo Golm...\n",
      "http://ufcstats.com/fighter-details/ac29d508d78384c9\n",
      "Scraping Denise Gomes...\n",
      "http://ufcstats.com/fighter-details/cffb87059e645bd1\n",
      "Scraping Sergio Gomez...\n",
      "http://ufcstats.com/fighter-details/af1e5c64b8663aa0\n",
      "Scraping Frank Gomez...\n",
      "http://ufcstats.com/fighter-details/a0a680fe2f6cc8e6\n",
      "Scraping Alan Gomez...\n",
      "http://ufcstats.com/fighter-details/0a66de3a797cf73a\n",
      "Scraping David Gomez...\n",
      "http://ufcstats.com/fighter-details/489413d3be819647\n",
      "Scraping Ulysses Gomez...\n",
      "http://ufcstats.com/fighter-details/1e35aa8955794580\n",
      "Scraping Joey Gomez...\n",
      "http://ufcstats.com/fighter-details/0778f94eb5d588a5\n",
      "Scraping Luis Gomez...\n",
      "http://ufcstats.com/fighter-details/513e84bfe65ff509\n",
      "Scraping Joey Gomez...\n",
      "http://ufcstats.com/fighter-details/3a28e1e641366308\n",
      "Scraping Edson Gomez...\n",
      "http://ufcstats.com/fighter-details/e90f4291f93708e6\n",
      "Scraping Silvana Gomez Juarez...\n",
      "http://ufcstats.com/fighter-details/b4880ef2f838d4e1\n",
      "Scraping Takanori Gomi...\n",
      "http://ufcstats.com/fighter-details/3be081c29bf734d9\n",
      "Scraping William Gomis...\n",
      "http://ufcstats.com/fighter-details/e1d40e8782d80bc2\n",
      "Scraping Akihiro Gono...\n",
      "http://ufcstats.com/fighter-details/b2acebbef8da14ea\n",
      "Scraping Gabriel Gonzaga...\n",
      "http://ufcstats.com/fighter-details/270b89c00ef0c55c\n",
      "Scraping Justin Gonzales...\n",
      "http://ufcstats.com/fighter-details/94535f76f43b466a\n",
      "Scraping Fernando Gonzalez...\n",
      "http://ufcstats.com/fighter-details/be5aab761c40ef35\n",
      "Scraping Nick Gonzalez...\n",
      "http://ufcstats.com/fighter-details/28d8638ea0a71908\n",
      "Scraping Fabian Gonzalez...\n",
      "http://ufcstats.com/fighter-details/69c071bc2621e8b0\n",
      "Scraping Lewis Gonzalez...\n",
      "http://ufcstats.com/fighter-details/2ff2e6e5abea3e53\n",
      "Scraping Jason Gonzalez...\n",
      "http://ufcstats.com/fighter-details/e45cfa47f504033a\n",
      "Scraping Pearl Gonzalez...\n",
      "http://ufcstats.com/fighter-details/1ebdcb7488d0ebee\n",
      "Scraping Jorge Gonzalez...\n",
      "http://ufcstats.com/fighter-details/ff175a137b395e2b\n",
      "Scraping Mikey Gonzalez...\n",
      "http://ufcstats.com/fighter-details/de47c33e48b0ce38\n",
      "Scraping Erick Gonzalez...\n",
      "http://ufcstats.com/fighter-details/a2ccf35a88346a91\n",
      "Scraping Jennifer Gonzalez...\n",
      "http://ufcstats.com/fighter-details/4f1a48f4e6ffb007\n",
      "Scraping Kier Gooch...\n",
      "http://ufcstats.com/fighter-details/1bda4867f1baceac\n",
      "Scraping Lyman Good...\n",
      "http://ufcstats.com/fighter-details/4e0692ad070976e4\n",
      "Scraping Jared Gooden...\n",
      "http://ufcstats.com/fighter-details/c730a0be691dc081\n",
      "Scraping Gary Goodridge...\n",
      "http://ufcstats.com/fighter-details/fbbde91f7bc2d3c5\n",
      "Scraping Jordan Goodwin...\n",
      "http://ufcstats.com/fighter-details/7f98d9d5a10fa25c\n",
      "Scraping Gerard Gordeau...\n",
      "http://ufcstats.com/fighter-details/279093302a6f44b3\n",
      "Scraping Eddie Gordon...\n",
      "http://ufcstats.com/fighter-details/8cad40a75e5c97f5\n",
      "Scraping Jared Gordon...\n",
      "http://ufcstats.com/fighter-details/7026eca45f65377b\n",
      "Scraping Tebaris Gordon...\n",
      "http://ufcstats.com/fighter-details/68c4ca70067bf282\n",
      "Scraping Malcolm Gordon...\n",
      "http://ufcstats.com/fighter-details/dee294e9717012c2\n",
      "Scraping Tresean Gore...\n",
      "http://ufcstats.com/fighter-details/147e70aa6cc48cfc\n",
      "Scraping Alex Gorgees...\n",
      "http://ufcstats.com/fighter-details/803bebcfb6d6f506\n",
      "Scraping Themba Gorimbo...\n",
      "http://ufcstats.com/fighter-details/40f3cb27fc7305a1\n",
      "Scraping Tim Gorman...\n",
      "http://ufcstats.com/fighter-details/c10eb2f12c489f6d\n",
      "Scraping Chase Gormley...\n",
      "http://ufcstats.com/fighter-details/052ceb8976695342\n",
      "Scraping Jonathan Goulet...\n",
      "http://ufcstats.com/fighter-details/fb1538b46877a695\n",
      "Scraping Thibault Gouti...\n",
      "http://ufcstats.com/fighter-details/51e86de150ee8be6\n",
      "Scraping Wilson Gouveia...\n",
      "http://ufcstats.com/fighter-details/af5b208e97f5d382\n",
      "Scraping Todd Gouwenberg...\n",
      "http://ufcstats.com/fighter-details/c44acf87e376c62b\n",
      "Scraping Hugo Govea...\n",
      "http://ufcstats.com/fighter-details/2391a73686200c5d\n",
      "Scraping Justin Governale...\n",
      "http://ufcstats.com/fighter-details/ae954fd497025462\n",
      "Scraping Damian Grabowski...\n",
      "http://ufcstats.com/fighter-details/3f11b5d4bd76a6d9\n",
      "Scraping Patryk Grabowski...\n",
      "http://ufcstats.com/fighter-details/4e163b53d1de1fbc\n",
      "Scraping Royce Gracie...\n",
      "http://ufcstats.com/fighter-details/429e7d3725852ce9\n",
      "Scraping Crosley Gracie...\n",
      "http://ufcstats.com/fighter-details/52d92050a046bc17\n",
      "Scraping Daniel Gracie...\n",
      "http://ufcstats.com/fighter-details/82d6a9ae41aac3f7\n",
      "Scraping Ralph Gracie...\n",
      "http://ufcstats.com/fighter-details/a9c45a8b21eabadc\n",
      "Scraping Renzo Gracie...\n",
      "http://ufcstats.com/fighter-details/aae0897825336b1a\n",
      "Scraping Rickson Gracie...\n",
      "http://ufcstats.com/fighter-details/194fc025f9355db6\n",
      "Scraping Rodrigo Gracie...\n",
      "http://ufcstats.com/fighter-details/36877f0e62b25b96\n",
      "Scraping Royler Gracie...\n",
      "http://ufcstats.com/fighter-details/b807814d977682eb\n",
      "Scraping Ryan Gracie...\n",
      "http://ufcstats.com/fighter-details/0c3838c8f7c620c2\n",
      "Scraping Ralek Gracie...\n",
      "http://ufcstats.com/fighter-details/84283233ec42be5f\n",
      "Scraping Rolles Gracie...\n",
      "http://ufcstats.com/fighter-details/e4a9dbade7c7e1a7\n",
      "Scraping Cesar Gracie...\n",
      "http://ufcstats.com/fighter-details/079488710f012779\n",
      "Scraping Roger Gracie...\n",
      "http://ufcstats.com/fighter-details/a6bbd3df469c6bea\n",
      "Scraping Igor Gracie...\n",
      "http://ufcstats.com/fighter-details/722b870449243083\n",
      "Scraping Neiman Gracie...\n",
      "http://ufcstats.com/fighter-details/12d855d12a624da2\n",
      "Scraping Kron Gracie...\n",
      "http://ufcstats.com/fighter-details/242d36d241b43c12\n",
      "Scraping Bogdan Grad...\n",
      "http://ufcstats.com/fighter-details/fb37795db81f93f3\n",
      "Scraping Steven Graham...\n",
      "http://ufcstats.com/fighter-details/3e514f437c51ce0a\n",
      "Scraping Scott Graham...\n",
      "http://ufcstats.com/fighter-details/6e4acc2c115215b5\n",
      "Scraping Miranda Granger...\n",
      "http://ufcstats.com/fighter-details/7559395ad833c074\n",
      "Scraping TJ Grant...\n",
      "http://ufcstats.com/fighter-details/a26198ba5093147e\n",
      "Scraping Davey Grant...\n",
      "http://ufcstats.com/fighter-details/113df4fde64735c6\n",
      "Scraping Dwight Grant...\n",
      "http://ufcstats.com/fighter-details/8be158ca1e5ea6a0\n",
      "Scraping Alexa Grasso...\n",
      "http://ufcstats.com/fighter-details/e8b731feff72294b\n",
      "Scraping Tony Gravely...\n",
      "http://ufcstats.com/fighter-details/601964f9654f911a\n",
      "Scraping Michael Graves...\n",
      "http://ufcstats.com/fighter-details/3f1d23b01c552a13\n",
      "Scraping Shelton Graves...\n",
      "http://ufcstats.com/fighter-details/642862d6d63605cd\n",
      "Scraping James Gray...\n",
      "http://ufcstats.com/fighter-details/2db65fc038c0018e\n",
      "Scraping Kevin Gray...\n",
      "http://ufcstats.com/fighter-details/bb0d290026d7681d\n",
      "Scraping Sam Greco...\n",
      "http://ufcstats.com/fighter-details/6d12031661db8ac8\n",
      "Scraping King Green...\n",
      "http://ufcstats.com/fighter-details/887961364be5ceb3\n",
      "Scraping Desmond Green...\n",
      "http://ufcstats.com/fighter-details/f046d724d2a84ac5\n",
      "Scraping Gabe Green...\n",
      "http://ufcstats.com/fighter-details/5eb50529a8418b77\n",
      "Scraping Maurice Greene...\n",
      "http://ufcstats.com/fighter-details/068f8a189a47fea6\n",
      "Scraping Matt Grice...\n",
      "http://ufcstats.com/fighter-details/bfc2fc38a0e20211\n",
      "Scraping Forrest Griffin...\n",
      "http://ufcstats.com/fighter-details/fcffee71cff5530e\n",
      "Scraping Tyson Griffin...\n",
      "http://ufcstats.com/fighter-details/20205040232ed0f3\n",
      "Scraping Max Griffin...\n",
      "http://ufcstats.com/fighter-details/b0d6a1d8ac3d563d\n",
      "Scraping Jordan Griffin...\n",
      "http://ufcstats.com/fighter-details/ebef46976554f975\n",
      "Scraping Chad Griggs...\n",
      "http://ufcstats.com/fighter-details/fdf18227faa596dd\n",
      "Scraping Charalampos Grigoriou...\n",
      "http://ufcstats.com/fighter-details/68b8ebdfce9dbb61\n",
      "Scraping Chuck Grigsby...\n",
      "http://ufcstats.com/fighter-details/7fb4234670271505\n",
      "Scraping Rodrigo Gripp de Sousa...\n",
      "http://ufcstats.com/fighter-details/dde70a112e053a6c\n",
      "Scraping Maxim Grishin...\n",
      "http://ufcstats.com/fighter-details/950d0ef5c17157c5\n",
      "Scraping Josh Grispi...\n",
      "http://ufcstats.com/fighter-details/60ba33c3f555a7a3\n",
      "Scraping Garrett Gross...\n",
      "http://ufcstats.com/fighter-details/6741218640534d8b\n",
      "Scraping Kendall Grove...\n",
      "http://ufcstats.com/fighter-details/234f3767ff0e5701\n",
      "Scraping Neil Grove...\n",
      "http://ufcstats.com/fighter-details/36a432f22144843e\n",
      "Scraping Chris Gruetzemacher...\n",
      "http://ufcstats.com/fighter-details/feaf00f3373435d6\n",
      "Scraping Vik Grujic...\n",
      "http://ufcstats.com/fighter-details/1e7483dbff40b84b\n",
      "Scraping Mike Grundy...\n",
      "http://ufcstats.com/fighter-details/56fcb2c4d99f9d1b\n",
      "Scraping Wang Guan...\n",
      "http://ufcstats.com/fighter-details/dd12382f28296f7b\n",
      "Scraping Nandor Guelmino...\n",
      "http://ufcstats.com/fighter-details/1abfb658cd4f8533\n",
      "Scraping Fabricio Guerreiro...\n",
      "http://ufcstats.com/fighter-details/2963369e327e1979\n",
      "Scraping Rainn Guerrero...\n",
      "http://ufcstats.com/fighter-details/8300a47f6fd6fe4f\n",
      "Scraping Shannon Gugerty...\n",
      "http://ufcstats.com/fighter-details/9f1641c08cf8fbe2\n",
      "Scraping Clay Guida...\n",
      "http://ufcstats.com/fighter-details/c47df9303d318c67\n",
      "Scraping Jason Guida...\n",
      "http://ufcstats.com/fighter-details/ce25b4ed82b1811b\n",
      "Scraping Melvin Guillard...\n",
      "http://ufcstats.com/fighter-details/ccd1299e0345e0ce\n",
      "Scraping Chris Guillen...\n",
      "http://ufcstats.com/fighter-details/da0f33e4255f99eb\n",
      "Scraping Marcelo Guimaraes...\n",
      "http://ufcstats.com/fighter-details/0c9c0a43d3f3f49d\n",
      "Scraping Leonardo Guimaraes...\n",
      "http://ufcstats.com/fighter-details/cc98d857b148e33a\n",
      "Scraping Brad Gumm...\n",
      "http://ufcstats.com/fighter-details/4d74641fac830182\n",
      "Scraping John Gunderson...\n",
      "http://ufcstats.com/fighter-details/a0c139b34f11421a\n",
      "Scraping John Gunther...\n",
      "http://ufcstats.com/fighter-details/3956bdc8ab2e54b3\n",
      "Scraping Jorge Gurgel...\n",
      "http://ufcstats.com/fighter-details/04d5718ed2661e8c\n",
      "Scraping Fabio Gurgel...\n",
      "http://ufcstats.com/fighter-details/8377c5572cb356f3\n",
      "Scraping Luis Gurule...\n",
      "http://ufcstats.com/fighter-details/29162be25ebef5f0\n",
      "Scraping Bogdan Guskov...\n",
      "http://ufcstats.com/fighter-details/ef5dcb10d2bd4b0f\n",
      "Scraping Gugun Gusman...\n",
      "http://ufcstats.com/fighter-details/e34e3b1fffa13a6a\n",
      "Scraping Andre Gusmao...\n",
      "http://ufcstats.com/fighter-details/cc300e9aa3063431\n",
      "Scraping Alexander Gustafsson...\n",
      "http://ufcstats.com/fighter-details/3c6976f8182d9527\n",
      "Scraping Andreas Gustafsson...\n",
      "http://ufcstats.com/fighter-details/2caf993f53541fa1\n",
      "Scraping Justin Guthrie...\n",
      "http://ufcstats.com/fighter-details/a789defa9086da46\n",
      "Scraping Horacio Gutierrez...\n",
      "http://ufcstats.com/fighter-details/cd85b48dc880fabd\n",
      "Scraping Chris Gutierrez...\n",
      "http://ufcstats.com/fighter-details/45f0cc9d18f35137\n",
      "Scraping Mando Gutierrez...\n",
      "http://ufcstats.com/fighter-details/5f33ae0620e050c5\n",
      "Scraping Mike Guymon...\n",
      "http://ufcstats.com/fighter-details/eaea0fc7b76525a8\n",
      "Scraping Chelsea Hackett...\n",
      "http://ufcstats.com/fighter-details/184b7a36d50dcc5e\n",
      "Scraping Keith Hackney...\n",
      "http://ufcstats.com/fighter-details/bf12aca029bfcc47\n",
      "Scraping Cody Haddon...\n",
      "http://ufcstats.com/fighter-details/8e6654e9f0461b8f\n",
      "Scraping Jake Hadley...\n",
      "http://ufcstats.com/fighter-details/60a42bf82447c919\n",
      "Scraping Steve Hadsel...\n",
      "http://ufcstats.com/fighter-details/99793cf88c5adeee\n",
      "Scraping Damir Hadzovic...\n",
      "http://ufcstats.com/fighter-details/38c626ca912c7bac\n",
      "Scraping Bassil Hafez...\n",
      "http://ufcstats.com/fighter-details/f4d92416da98804b\n",
      "Scraping Tim Hague...\n",
      "http://ufcstats.com/fighter-details/219a254e15d60135\n",
      "Scraping Yazan Hajeh...\n",
      "http://ufcstats.com/fighter-details/4955c524c2a71469\n",
      "Scraping Stoney Hale...\n",
      "http://ufcstats.com/fighter-details/206a7d47eb62170e\n",
      "Scraping Kevin Haley...\n",
      "http://ufcstats.com/fighter-details/439d4bbefd4e6940\n",
      "Scraping Mark Hall...\n",
      "http://ufcstats.com/fighter-details/18524b46c570730b\n",
      "Scraping Uriah Hall...\n",
      "http://ufcstats.com/fighter-details/65578a75fa7900e3\n",
      "Scraping Ryan Hall...\n",
      "http://ufcstats.com/fighter-details/8866c6f509c19089\n",
      "Scraping Dennis Hallman...\n",
      "http://ufcstats.com/fighter-details/8a8a84b743ae7699\n",
      "Scraping Piotr Hallmann...\n",
      "http://ufcstats.com/fighter-details/a3be148af5c7b088\n",
      "Scraping Tony Halme...\n",
      "http://ufcstats.com/fighter-details/bad28b7b34f334de\n",
      "Scraping Brandon Halsey...\n",
      "http://ufcstats.com/fighter-details/e763679f15326ae1\n",
      "Scraping John Halverson...\n",
      "http://ufcstats.com/fighter-details/88c8f47241d90040\n",
      "Scraping Seo Hee Ham...\n",
      "http://ufcstats.com/fighter-details/165c244bcca3ed26\n",
      "Scraping Frank Hamaker...\n",
      "http://ufcstats.com/fighter-details/c3c23c99477c041b\n",
      "Scraping Kazuhiro Hamanaka...\n",
      "http://ufcstats.com/fighter-details/1b4d6971bb18b82c\n",
      "Scraping Rami Hamed...\n",
      "http://ufcstats.com/fighter-details/a59017211b775b5d\n",
      "Scraping Matt Hamill...\n",
      "http://ufcstats.com/fighter-details/98b80a717b9bda17\n",
      "Scraping Jeremy Hamilton...\n",
      "http://ufcstats.com/fighter-details/7ada6ea792a34424\n",
      "Scraping Anthony Hamilton...\n",
      "http://ufcstats.com/fighter-details/c727c7d31c50c4cf\n",
      "Scraping CJ Hamilton...\n",
      "http://ufcstats.com/fighter-details/7da5839b223f3728\n",
      "Scraping Jared Hamman...\n",
      "http://ufcstats.com/fighter-details/23459ee7e373b98f\n",
      "Scraping James Hammortree...\n",
      "http://ufcstats.com/fighter-details/1f77fce698e80488\n",
      "Scraping Dean Hancock...\n",
      "http://ufcstats.com/fighter-details/24e9d6b0a24cff9d\n",
      "Scraping Chad Hanekom...\n",
      "http://ufcstats.com/fighter-details/98533a2738124a0d\n",
      "Scraping Joachim Hansen...\n",
      "http://ufcstats.com/fighter-details/86e388ed20761ad9\n",
      "Scraping Kay Hansen...\n",
      "http://ufcstats.com/fighter-details/4100c7a09497ad41\n",
      "Scraping Nasrat Haqparast...\n",
      "http://ufcstats.com/fighter-details/b7b84ccd221be298\n",
      "Scraping Shin Haraguchi...\n",
      "http://ufcstats.com/fighter-details/05b17ae24e6bba81\n",
      "Scraping Janay Harding...\n",
      "http://ufcstats.com/fighter-details/b9c3ee342eb72100\n",
      "Scraping Antoni Hardonk...\n",
      "http://ufcstats.com/fighter-details/69b69c0178c4004d\n",
      "Scraping George Hardwick...\n",
      "http://ufcstats.com/fighter-details/f55a6807b6bb853d\n",
      "Scraping Dan Hardy...\n",
      "http://ufcstats.com/fighter-details/473ce3aa581251a2\n",
      "Scraping Veronica Hardy...\n",
      "http://ufcstats.com/fighter-details/4798e823ada58fe9\n",
      "Scraping Greg Hardy...\n",
      "http://ufcstats.com/fighter-details/85073dbd1be65ed9\n",
      "Scraping Tobias Harila...\n",
      "http://ufcstats.com/fighter-details/4d1e92b61bcef308\n",
      "Scraping Baru Harn...\n",
      "http://ufcstats.com/fighter-details/848809f3986b4977\n",
      "Scraping Scott Harper...\n",
      "http://ufcstats.com/fighter-details/14a433bccba87016\n",
      "Scraping Josiah Harrell...\n",
      "http://ufcstats.com/fighter-details/e5864a42c80294f6\n",
      "Scraping Gerry Harris...\n",
      "http://ufcstats.com/fighter-details/30cd319d39ee689b\n",
      "Scraping Gerald Harris...\n",
      "http://ufcstats.com/fighter-details/c4b81cdecd5d6abe\n",
      "Scraping Phil Harris...\n",
      "http://ufcstats.com/fighter-details/ba043b03eb799063\n",
      "Scraping Walt Harris...\n",
      "http://ufcstats.com/fighter-details/03f982ca3735070c\n",
      "Scraping Dhafir Harris...\n",
      "http://ufcstats.com/fighter-details/0e96af5220d27ed4\n",
      "Scraping Trevor Harris...\n",
      "http://ufcstats.com/fighter-details/0e98b05d3cf6d271\n",
      "Scraping Carlston Harris...\n",
      "http://ufcstats.com/fighter-details/a53d30163304aa6e\n",
      "Scraping Kayla Harrison...\n",
      "http://ufcstats.com/fighter-details/1af1170ed937cba7\n",
      "Scraping Collin Hart...\n",
      "http://ufcstats.com/fighter-details/16bf6a73bdd302cd\n",
      "Scraping Joey Hart...\n",
      "http://ufcstats.com/fighter-details/6412da484125716b\n",
      "Scraping Dale Hartt...\n",
      "http://ufcstats.com/fighter-details/058e4e08a1ad8aba\n",
      "Scraping Luke Hartwig...\n",
      "http://ufcstats.com/fighter-details/34f3869747bf8fa9\n",
      "Scraping Clay Harvison...\n",
      "http://ufcstats.com/fighter-details/83a477a7dba1ca58\n",
      "Scraping Hidehiko Hasegawa...\n",
      "http://ufcstats.com/fighter-details/2a2eeee20ef049cf\n",
      "Scraping Chris Haseman...\n",
      "http://ufcstats.com/fighter-details/5bd533d50c8e7b8a\n",
      "Scraping Takayo Hashi...\n",
      "http://ufcstats.com/fighter-details/ae4343d29c68e9d0\n",
      "Scraping Tomohiko Hashimoto...\n",
      "http://ufcstats.com/fighter-details/a890f9a791ed615d\n",
      "Scraping Justin Haskins...\n",
      "http://ufcstats.com/fighter-details/77940e45bc86208e\n",
      "Scraping Hayder Hassan...\n",
      "http://ufcstats.com/fighter-details/cf615eb4b7862c76\n",
      "Scraping Ahmad Hassanzada...\n",
      "http://ufcstats.com/fighter-details/bf7a64d9ae343e86\n",
      "Scraping Daiki Hata...\n",
      "http://ufcstats.com/fighter-details/c76ceda100ac0fad\n",
      "Scraping John Hathaway...\n",
      "http://ufcstats.com/fighter-details/28f3c2258a1d8874\n",
      "Scraping Phil Hawes...\n",
      "http://ufcstats.com/fighter-details/547afe1017e72dbe\n",
      "Scraping Justin Hawes...\n",
      "http://ufcstats.com/fighter-details/5c7fc58e782b6842\n",
      "Scraping Chris Hawk...\n",
      "http://ufcstats.com/fighter-details/9460c867aae1987e\n",
      "Scraping Del Hawkins...\n",
      "http://ufcstats.com/fighter-details/885e7f70dcac0007\n",
      "Scraping Tommy Hayden...\n",
      "http://ufcstats.com/fighter-details/0871254cd790c250\n",
      "Scraping Mike Hayes...\n",
      "http://ufcstats.com/fighter-details/0cfbbfa0ba6d9855\n",
      "Scraping Ryan Hayes...\n",
      "http://ufcstats.com/fighter-details/a620638435de0628\n",
      "Scraping Gerric Hayes...\n",
      "http://ufcstats.com/fighter-details/7d6a3546c988cdc0\n",
      "Scraping Josh Haynes...\n",
      "http://ufcstats.com/fighter-details/6ef58dabef8beb15\n",
      "Scraping Dustin Hazelett...\n",
      "http://ufcstats.com/fighter-details/a149d6bc670cdb60\n",
      "Scraping James Head...\n",
      "http://ufcstats.com/fighter-details/19a8cce18a1cef9e\n",
      "Scraping Pat Healy...\n",
      "http://ufcstats.com/fighter-details/50d2f0018bcf9eef\n",
      "Scraping Ryan Healy...\n",
      "http://ufcstats.com/fighter-details/f3eb664db7fb1df3\n",
      "Scraping Spencer Hearns...\n",
      "http://ufcstats.com/fighter-details/d85cf12439945941\n",
      "Scraping David Heath...\n",
      "http://ufcstats.com/fighter-details/4f95f74620a6b7a4\n",
      "Scraping Chris Heatherly...\n",
      "http://ufcstats.com/fighter-details/bad8be5827ea1bf1\n",
      "Scraping Jake Hecht...\n",
      "http://ufcstats.com/fighter-details/e57fdbea1b828202\n",
      "Scraping Nick Hein...\n",
      "http://ufcstats.com/fighter-details/2816ced060a21be3\n",
      "Scraping Ian Heinisch...\n",
      "http://ufcstats.com/fighter-details/2e585c701f72fe55\n",
      "Scraping Marcin Held...\n",
      "http://ufcstats.com/fighter-details/bf43fed8f29e1671\n",
      "Scraping Delson Heleno...\n",
      "http://ufcstats.com/fighter-details/970beed85bc46b63\n",
      "Scraping Matt Helm...\n",
      "http://ufcstats.com/fighter-details/cacfd51b8e97ace0\n",
      "Scraping Elisha Helsper...\n",
      "http://ufcstats.com/fighter-details/0971be7d94e109e1\n",
      "Scraping Dan Henderson...\n",
      "http://ufcstats.com/fighter-details/1ccf4e7caff270df\n",
      "Scraping Benson Henderson...\n",
      "http://ufcstats.com/fighter-details/2676b28836a5a836\n",
      "Scraping Ron Henderson...\n",
      "http://ufcstats.com/fighter-details/498f0d066396ec59\n",
      "Scraping Josh Hendricks...\n",
      "http://ufcstats.com/fighter-details/7649c4c95b824488\n",
      "Scraping Johny Hendricks...\n",
      "http://ufcstats.com/fighter-details/0941df56f6ac954b\n",
      "Scraping Cory Hendricks...\n",
      "http://ufcstats.com/fighter-details/9ab9912e0f8fa6d6\n",
      "Scraping Luis Henrique...\n",
      "http://ufcstats.com/fighter-details/e5bda12faabfc850\n",
      "Scraping Jose Henrique...\n",
      "http://ufcstats.com/fighter-details/20a0e4cc5227c117\n",
      "Scraping Diego Henrique da Silva...\n",
      "http://ufcstats.com/fighter-details/1649770c649db6a5\n",
      "Scraping Danny Henry...\n",
      "http://ufcstats.com/fighter-details/f7d73e452b064bf2\n",
      "Scraping Victor Henry...\n",
      "http://ufcstats.com/fighter-details/eb8d8c2a95cfccb8\n",
      "Scraping TJ Hepburn...\n",
      "http://ufcstats.com/fighter-details/e1acbb6352ca3551\n",
      "Scraping Jai Herbert...\n",
      "http://ufcstats.com/fighter-details/4c88a1db5a46c6a4\n",
      "Scraping Ed Herman...\n",
      "http://ufcstats.com/fighter-details/06f36cf4bd97ec77\n",
      "Scraping Dave Herman...\n",
      "http://ufcstats.com/fighter-details/cbd6f1abf955e628\n",
      "Scraping Jack Hermansson...\n",
      "http://ufcstats.com/fighter-details/0a1942069c9ad6b6\n",
      "Scraping Noe Hernandez...\n",
      "http://ufcstats.com/fighter-details/df2cf66d8c0123db\n",
      "Scraping Joe Hernandez...\n",
      "http://ufcstats.com/fighter-details/4a76daef28549957\n",
      "Scraping Ramiro Hernandez...\n",
      "http://ufcstats.com/fighter-details/915c8d39d4a0e7d1\n",
      "Scraping Alexander Hernandez...\n",
      "http://ufcstats.com/fighter-details/262a7d06203657e6\n",
      "Scraping Anthony Hernandez...\n",
      "http://ufcstats.com/fighter-details/093e1f5bb73850be\n",
      "Scraping Nohelin Hernandez...\n",
      "http://ufcstats.com/fighter-details/f97c5433c77522d3\n",
      "Scraping Carlos Hernandez...\n",
      "http://ufcstats.com/fighter-details/798e48f9e7f6ba22\n",
      "Scraping Leslie Hernandez...\n",
      "http://ufcstats.com/fighter-details/fc8610cc15674ae2\n",
      "Scraping Paul Herrera...\n",
      "http://ufcstats.com/fighter-details/440c9dbab63528fb\n",
      "Scraping Chris Herrera...\n",
      "http://ufcstats.com/fighter-details/f71028a6e5128856\n",
      "Scraping Geane Herrera...\n",
      "http://ufcstats.com/fighter-details/c169545ab0825f44\n",
      "Scraping Alvaro Herrera Mendoza...\n",
      "http://ufcstats.com/fighter-details/74d35fbc9c6a61bd\n",
      "Scraping Felice Herrig...\n",
      "http://ufcstats.com/fighter-details/b6850671a008bf9a\n",
      "Scraping Heath Herring...\n",
      "http://ufcstats.com/fighter-details/7450525c7ba032a0\n",
      "Scraping Jon Hess...\n",
      "http://ufcstats.com/fighter-details/32a3025d5db456ae\n",
      "Scraping Clint Hester...\n",
      "http://ufcstats.com/fighter-details/92b62174c175ce19\n",
      "Scraping Brandon Hester...\n",
      "http://ufcstats.com/fighter-details/13150cf89a5b81e0\n",
      "Scraping Jimy Hettes...\n",
      "http://ufcstats.com/fighter-details/893d51aaf024eddd\n",
      "Scraping Conor Heun...\n",
      "http://ufcstats.com/fighter-details/fdb02029556ff4ed\n",
      "Scraping Marcus Hicks...\n",
      "http://ufcstats.com/fighter-details/e69c5ce12f4e762b\n",
      "Scraping Jay Hieron...\n",
      "http://ufcstats.com/fighter-details/5bb0a618ad03ac64\n",
      "Scraping Brady Hiestand...\n",
      "http://ufcstats.com/fighter-details/7af33fc4435017f1\n",
      "Scraping Lee Higgins...\n",
      "http://ufcstats.com/fighter-details/88432fe79d5091d9\n",
      "Scraping Jason High...\n",
      "http://ufcstats.com/fighter-details/e5d03e4d966126bd\n",
      "Scraping Richie Hightower...\n",
      "http://ufcstats.com/fighter-details/318e629d1eb7aa49\n",
      "Scraping Alex Higley...\n",
      "http://ufcstats.com/fighter-details/2af2d675f7d847e3\n",
      "Scraping Corey Hill...\n",
      "http://ufcstats.com/fighter-details/abbc737317f66b81\n",
      "Scraping Isaiah Hill...\n",
      "http://ufcstats.com/fighter-details/86b30a86664cb6e4\n",
      "Scraping Angela Hill...\n",
      "http://ufcstats.com/fighter-details/f0feeb2192937424\n",
      "Scraping Tyler Hill...\n",
      "http://ufcstats.com/fighter-details/006efbb0c1621fd7\n",
      "Scraping Jamahal Hill...\n",
      "http://ufcstats.com/fighter-details/5444c5a201d3ee5a\n",
      "Scraping Kailan Hill...\n",
      "http://ufcstats.com/fighter-details/bc7efc037c5f6550\n",
      "Scraping Branden Lee Hinkle...\n",
      "http://ufcstats.com/fighter-details/06f0ffa6446c5b6d\n",
      "Scraping Hatsu Hioki...\n",
      "http://ufcstats.com/fighter-details/ef7fa30364cbe7f2\n",
      "Scraping Alan Hiro...\n",
      "http://ufcstats.com/fighter-details/483b3170b3c05cf0\n",
      "Scraping Kuniyoshi Hironaka...\n",
      "http://ufcstats.com/fighter-details/9d4522df6fc49a47\n",
      "Scraping Mizuto Hirota...\n",
      "http://ufcstats.com/fighter-details/35faad160d346839\n",
      "Scraping Yuji Hisamatsu...\n",
      "http://ufcstats.com/fighter-details/8332a607df696345\n",
      "Scraping An Tuan Ho...\n",
      "http://ufcstats.com/fighter-details/6c9384138c82962f\n",
      "Scraping Kwan Ho Kwak...\n",
      "http://ufcstats.com/fighter-details/c13042265355a290\n",
      "Scraping Matt Hobar...\n",
      "http://ufcstats.com/fighter-details/b57edace7b647f07\n",
      "Scraping Bobby Hoffman...\n",
      "http://ufcstats.com/fighter-details/afaad7d6a581e307\n",
      "Scraping Chris Hofmann...\n",
      "http://ufcstats.com/fighter-details/33fb306278dbb3e5\n",
      "Scraping Sam Hoger...\n",
      "http://ufcstats.com/fighter-details/84a067c46306a737\n",
      "Scraping Andrew Holbrook...\n",
      "http://ufcstats.com/fighter-details/66ab58d0b3783607\n",
      "Scraping Sean Holden...\n",
      "http://ufcstats.com/fighter-details/acbb9c76f5894e36\n",
      "Scraping Chris Holdsworth...\n",
      "http://ufcstats.com/fighter-details/fc60ecf0671b9489\n",
      "Scraping Kevin Holland...\n",
      "http://ufcstats.com/fighter-details/3a46b268013afede\n",
      "Scraping Roger Hollett...\n",
      "http://ufcstats.com/fighter-details/27d65e9d0fba61ea\n",
      "Scraping Max Holloway...\n",
      "http://ufcstats.com/fighter-details/150ff4cc642270b9\n",
      "Scraping Gabrielle Holloway...\n",
      "http://ufcstats.com/fighter-details/e30715382f42b772\n",
      "Scraping Jeremie Holloway...\n",
      "http://ufcstats.com/fighter-details/ee28aa7f1043756c\n",
      "Scraping Holly Holm...\n",
      "http://ufcstats.com/fighter-details/634e2fb70bde3fd5\n",
      "Scraping Rex Holman...\n",
      "http://ufcstats.com/fighter-details/b5ea750025697880\n",
      "Scraping Joseph Holmes...\n",
      "http://ufcstats.com/fighter-details/8d20d76af3f213ce\n",
      "Scraping Kurt Holobaugh...\n",
      "http://ufcstats.com/fighter-details/a7151778b3381036\n",
      "Scraping Paddy Holohan...\n",
      "http://ufcstats.com/fighter-details/6e7c758f5cdec01a\n",
      "Scraping Ben Holscher...\n",
      "http://ufcstats.com/fighter-details/6070f16bcfd89fcf\n",
      "Scraping Mark Holst...\n",
      "http://ufcstats.com/fighter-details/c11f50e9c1513ce9\n",
      "Scraping Scott Holtzman...\n",
      "http://ufcstats.com/fighter-details/df1eb4354d18a906\n",
      "Scraping Sabah Homasi...\n",
      "http://ufcstats.com/fighter-details/71f048adbfed5b49\n",
      "Scraping Mark Hominick...\n",
      "http://ufcstats.com/fighter-details/0a97691039c4bbfb\n",
      "Scraping Barb Honchak...\n",
      "http://ufcstats.com/fighter-details/472f6f6e6d962f40\n",
      "Scraping Chris Honeycutt...\n",
      "http://ufcstats.com/fighter-details/4d2e3320d815f687\n",
      "Scraping JunYoung Hong...\n",
      "http://ufcstats.com/fighter-details/b24666e26bd750a3\n",
      "Scraping SeongChan Hong...\n",
      "http://ufcstats.com/fighter-details/10d4575f497face4\n",
      "Scraping Satoshi Honma...\n",
      "http://ufcstats.com/fighter-details/d2b1c1317a39f6c6\n",
      "Scraping David Hood...\n",
      "http://ufcstats.com/fighter-details/5af480a3b2e1726b\n",
      "Scraping Lorenzo Hood...\n",
      "http://ufcstats.com/fighter-details/7f9abc4db2d05764\n",
      "Scraping Dan Hooker...\n",
      "http://ufcstats.com/fighter-details/193b9d1858bc4df3\n",
      "Scraping Chase Hooper...\n",
      "http://ufcstats.com/fighter-details/971246648e162f0d\n",
      "Scraping Darrell Horcher...\n",
      "http://ufcstats.com/fighter-details/18e8b7070228e728\n",
      "Scraping Moti Horenstein...\n",
      "http://ufcstats.com/fighter-details/baf942f4bcb09894\n",
      "Scraping Yoshinori Horie...\n",
      "http://ufcstats.com/fighter-details/3fa7688bfe48a493\n",
      "Scraping Kyoji Horiguchi...\n",
      "http://ufcstats.com/fighter-details/98aa60cf58071fd6\n",
      "Scraping Yuma Horiuchi...\n",
      "http://ufcstats.com/fighter-details/f6c1ce7cfd600662\n",
      "Scraping Jeremy Horn...\n",
      "http://ufcstats.com/fighter-details/8d26912cd2aeb366\n",
      "Scraping Matt Horning...\n",
      "http://ufcstats.com/fighter-details/21632ba272c0785a\n",
      "Scraping Chris Horodecki...\n",
      "http://ufcstats.com/fighter-details/e29cf523ebd155c5\n",
      "Scraping Jamey-Lyn Horth...\n",
      "http://ufcstats.com/fighter-details/5c637af9472ae7cc\n",
      "Scraping Matt Horwich...\n",
      "http://ufcstats.com/fighter-details/049d698d773eb3e1\n",
      "Scraping John Hosman...\n",
      "http://ufcstats.com/fighter-details/57591bbf1623574e\n",
      "Scraping Saeed Hosseini...\n",
      "http://ufcstats.com/fighter-details/21f2974fd08085e3\n",
      "Scraping Jeff Hougland...\n",
      "http://ufcstats.com/fighter-details/97a8f39186f489db\n",
      "Scraping Trey Houston...\n",
      "http://ufcstats.com/fighter-details/c6668eeb261588d3\n",
      "Scraping Jamie Houston...\n",
      "http://ufcstats.com/fighter-details/4b1896310a907656\n",
      "Scraping Brian Houston...\n",
      "http://ufcstats.com/fighter-details/36fbaa49a09ff997\n",
      "Scraping Harold Howard...\n",
      "http://ufcstats.com/fighter-details/a2b06ca02bca14c0\n",
      "Scraping John Howard...\n",
      "http://ufcstats.com/fighter-details/fc31f896cde2bc2e\n",
      "Scraping Shane Howell...\n",
      "http://ufcstats.com/fighter-details/a7de976620f2ed13\n",
      "Scraping Hu Yaozong...\n",
      "http://ufcstats.com/fighter-details/f1175ea3aafbf351\n",
      "Scraping Carlos Huachin...\n",
      "http://ufcstats.com/fighter-details/225def29ecfe0fc1\n",
      "Scraping Brady Huang...\n",
      "http://ufcstats.com/fighter-details/1ec1b6a7a29ffc71\n",
      "Scraping Yuele Huang...\n",
      "http://ufcstats.com/fighter-details/1c8b9f4d89b92e1b\n",
      "Scraping Huang Feier...\n",
      "http://ufcstats.com/fighter-details/e71c75f533a30daa\n",
      "Scraping Austin Hubbard...\n",
      "http://ufcstats.com/fighter-details/d2cd7a69cc55e7ed\n",
      "Scraping Collin Huckbody...\n",
      "http://ufcstats.com/fighter-details/f372a848d250e006\n",
      "Scraping Alex Huddleston...\n",
      "http://ufcstats.com/fighter-details/8b9197746bd3e005\n",
      "Scraping Roger Huerta...\n",
      "http://ufcstats.com/fighter-details/daf1b84aebd6602b\n",
      "Scraping Casey Huffman...\n",
      "http://ufcstats.com/fighter-details/737d93a42b8c2e94\n",
      "Scraping Matt Hughes...\n",
      "http://ufcstats.com/fighter-details/621a6c59f88a44fe\n",
      "Scraping Mark Hughes...\n",
      "http://ufcstats.com/fighter-details/d62bb4d84a7267ba\n",
      "Scraping Jeff Hughes...\n",
      "http://ufcstats.com/fighter-details/6a11e325aa60ad02\n",
      "Scraping Sam Hughes...\n",
      "http://ufcstats.com/fighter-details/e94085e821bd81de\n",
      "Scraping Victor Hugo...\n",
      "http://ufcstats.com/fighter-details/f264ba50b007f39e\n",
      "Scraping David Hulett...\n",
      "http://ufcstats.com/fighter-details/b0718335e9868cfd\n",
      "Scraping Dominik Humburger...\n",
      "http://ufcstats.com/fighter-details/e4cbc82c36e47299\n",
      "Scraping Bryan Humes...\n",
      "http://ufcstats.com/fighter-details/b9c75e7fc910f587\n",
      "Scraping Abongo Humphrey...\n",
      "http://ufcstats.com/fighter-details/cb1b4d237b0079e6\n",
      "Scraping Harry Hunsucker...\n",
      "http://ufcstats.com/fighter-details/f703250471acaf96\n",
      "Scraping Mark Hunt...\n",
      "http://ufcstats.com/fighter-details/eef9b891edbd4604\n",
      "Scraping Alex Hunter...\n",
      "http://ufcstats.com/fighter-details/baa5358456803df8\n",
      "Scraping Adam Hunter...\n",
      "http://ufcstats.com/fighter-details/edc9eb3051f444fa\n",
      "Scraping Joe Hurley...\n",
      "http://ufcstats.com/fighter-details/21b54430c8eeb9cc\n",
      "Scraping Solomon Hutcherson...\n",
      "http://ufcstats.com/fighter-details/155bfc7ed36622df\n",
      "Scraping Young Hwang...\n",
      "http://ufcstats.com/fighter-details/8588d14c4952b9fa\n",
      "Scraping Al Iaquinta...\n",
      "http://ufcstats.com/fighter-details/59279a7c978f7da0\n",
      "Scraping Khadis Ibragimov...\n",
      "http://ufcstats.com/fighter-details/c3218c810959d279\n",
      "Scraping Minoki Ichihara...\n",
      "http://ufcstats.com/fighter-details/4565d435005319c0\n",
      "Scraping Dan Ige...\n",
      "http://ufcstats.com/fighter-details/82a5152216251682\n",
      "Scraping Valeri Ignatov...\n",
      "http://ufcstats.com/fighter-details/7b6ce3a9460565b5\n",
      "Scraping Sergey Ignatov...\n",
      "http://ufcstats.com/fighter-details/df9e9c1f65805d29\n",
      "Scraping Fabiano Iha...\n",
      "http://ufcstats.com/fighter-details/263ebd4a669e1e98\n",
      "Scraping Seichi Ikemoto...\n",
      "http://ufcstats.com/fighter-details/81f38d1640c4e70d\n",
      "Scraping Mikhail Iloukhine...\n",
      "http://ufcstats.com/fighter-details/b71667c778b6d9e5\n",
      "Scraping Zelim Imadaev...\n",
      "http://ufcstats.com/fighter-details/7f0f171414d0a287\n",
      "Scraping Yusuke Imamura...\n",
      "http://ufcstats.com/fighter-details/2ce6541127b0e232\n",
      "Scraping Masakazu Imanari...\n",
      "http://ufcstats.com/fighter-details/a4dd5c9a75763295\n",
      "Scraping Nassourdine Imavov...\n",
      "http://ufcstats.com/fighter-details/881bf86d4cba8578\n",
      "Scraping Brad Imes...\n",
      "http://ufcstats.com/fighter-details/4908c5ee68a50ee5\n",
      "Scraping Michael Imperato...\n",
      "http://ufcstats.com/fighter-details/59e52d56bab2b1ee\n",
      "Scraping Chris Indich...\n",
      "http://ufcstats.com/fighter-details/d5b7fac960e58920\n",
      "Scraping Chris Inman...\n",
      "http://ufcstats.com/fighter-details/f0a381ba65d2a933\n",
      "Scraping Guto Inocente...\n",
      "http://ufcstats.com/fighter-details/e7fe5315b1efeb92\n",
      "Scraping Enson Inoue...\n",
      "http://ufcstats.com/fighter-details/0cf935519d439ba6\n",
      "Scraping Egan Inoue...\n",
      "http://ufcstats.com/fighter-details/37a6c95201592fea\n",
      "Scraping Katsuya Inoue...\n",
      "http://ufcstats.com/fighter-details/b5882371e2a3900d\n",
      "Scraping Takeshi Inoue...\n",
      "http://ufcstats.com/fighter-details/a61a0cd2829e5d4e\n",
      "Scraping Naoki Inoue...\n",
      "http://ufcstats.com/fighter-details/199eb7cf6ae90294\n",
      "Scraping Jorge Interiano...\n",
      "http://ufcstats.com/fighter-details/1e75e6c9de99fa76\n",
      "Scraping Jason Ireland...\n",
      "http://ufcstats.com/fighter-details/05a0556072931f01\n",
      "Scraping James Irvin...\n",
      "http://ufcstats.com/fighter-details/a7f4d0902bb64092\n",
      "Scraping Eric Irvin...\n",
      "http://ufcstats.com/fighter-details/a47c2a6e24757932\n",
      "Scraping Issa Isakov...\n",
      "http://ufcstats.com/fighter-details/e9095aeb36f2aeb8\n",
      "Scraping Mitsuhiro Ishida...\n",
      "http://ufcstats.com/fighter-details/82f5c81f4e3c3eb5\n",
      "Scraping Teruto Ishihara...\n",
      "http://ufcstats.com/fighter-details/88cd34d836b4ebcd\n",
      "Scraping Satoshi Ishii...\n",
      "http://ufcstats.com/fighter-details/c8a49ff2acb6f3c5\n",
      "Scraping Yuki Ishikawa...\n",
      "http://ufcstats.com/fighter-details/119ebea97e914dcf\n",
      "Scraping Eiji Ishikawa...\n",
      "http://ufcstats.com/fighter-details/eb89dc31949a1427\n",
      "Scraping Tokimitsu Ishizawa...\n",
      "http://ufcstats.com/fighter-details/f3155a94ca420126\n",
      "Scraping Damir Ismagulov...\n",
      "http://ufcstats.com/fighter-details/135d124172a0bea3\n",
      "Scraping Wallid Ismail...\n",
      "http://ufcstats.com/fighter-details/da6dfd09cca1d705\n",
      "Scraping Leandro Issa...\n",
      "http://ufcstats.com/fighter-details/d1e1fdcea7c8a90a\n",
      "Scraping Blagoy Ivanov...\n",
      "http://ufcstats.com/fighter-details/1788eee370f077b7\n",
      "Scraping Anthony Ivy...\n",
      "http://ufcstats.com/fighter-details/3c5005b66696d790\n",
      "Scraping Tomomi Iwama...\n",
      "http://ufcstats.com/fighter-details/ac5f67109accb482\n",
      "Scraping Tatsuya Iwasaki...\n",
      "http://ufcstats.com/fighter-details/243b07fc65ccbb16\n",
      "Scraping Taiga Iwasaki...\n",
      "http://ufcstats.com/fighter-details/5b08af4fbc987f9c\n",
      "Scraping Saygid Izagakhmaev...\n",
      "http://ufcstats.com/fighter-details/de26d906f2874dd4\n",
      "Scraping Yoislandy Izquierdo...\n",
      "http://ufcstats.com/fighter-details/afc2a7ce0c763bd5\n",
      "Scraping Hiroshi Izumi...\n",
      "http://ufcstats.com/fighter-details/53e4e21f4c688801\n",
      "Scraping Yves Jabouin...\n",
      "http://ufcstats.com/fighter-details/b4eeac608fc82f88\n",
      "Scraping Kevin Jackson...\n",
      "http://ufcstats.com/fighter-details/13b2f59210dda9cc\n",
      "Scraping Eugene Jackson...\n",
      "http://ufcstats.com/fighter-details/ce783bf73b5131f9\n",
      "Scraping Quinton Jackson...\n",
      "http://ufcstats.com/fighter-details/ffc088e64fab57e9\n",
      "Scraping Jeremy Jackson...\n",
      "http://ufcstats.com/fighter-details/ad32471f01e7b1a5\n",
      "Scraping Damon Jackson...\n",
      "http://ufcstats.com/fighter-details/29af297d9f1de0f8\n",
      "Scraping Kenyon Jackson...\n",
      "http://ufcstats.com/fighter-details/56c5132870a526d5\n",
      "Scraping Mike Jackson...\n",
      "http://ufcstats.com/fighter-details/0641c21bec209472\n",
      "Scraping Jason Jackson...\n",
      "http://ufcstats.com/fighter-details/ca8da445dfa82d56\n",
      "Scraping Montel Jackson...\n",
      "http://ufcstats.com/fighter-details/cc1a8b4b38b92c6d\n",
      "Scraping Eric Jacob...\n",
      "http://ufcstats.com/fighter-details/ba17afef01ed78b6\n",
      "Scraping Richard Jacobi...\n",
      "http://ufcstats.com/fighter-details/46f557bd44da630e\n",
      "Scraping Dustin Jacoby...\n",
      "http://ufcstats.com/fighter-details/e4277e87a789d687\n",
      "Scraping Justin James...\n",
      "http://ufcstats.com/fighter-details/1ea8df62b3f8fea6\n",
      "Scraping Nate James...\n",
      "http://ufcstats.com/fighter-details/a34fecf2f4e5a317\n",
      "Scraping Virna Jandiroba...\n",
      "http://ufcstats.com/fighter-details/7dda2cf308f24a02\n",
      "Scraping Ryan Janes...\n",
      "http://ufcstats.com/fighter-details/b59037262c8fe060\n",
      "Scraping Josh Janousek...\n",
      "http://ufcstats.com/fighter-details/8f7380fb0916dc77\n",
      "Scraping Dave Jansen...\n",
      "http://ufcstats.com/fighter-details/335ad945324c3a2e\n",
      "Scraping Jaime Jara...\n",
      "http://ufcstats.com/fighter-details/805ad1801eb26abb\n",
      "Scraping Gigo Jara...\n",
      "http://ufcstats.com/fighter-details/99d5cf1eda8b25c1\n",
      "Scraping Keith Jardine...\n",
      "http://ufcstats.com/fighter-details/b9d0fd83bb8a147a\n",
      "Scraping Brock Jardine...\n",
      "http://ufcstats.com/fighter-details/64959f90b6dd9759\n",
      "Scraping Josh Jarvis...\n",
      "http://ufcstats.com/fighter-details/32e8e0e8498f03c2\n",
      "Scraping Rony Jason...\n",
      "http://ufcstats.com/fighter-details/b71ce838b01f2cad\n",
      "Scraping Jasmine Jasudavicius...\n",
      "http://ufcstats.com/fighter-details/a9e260472d321361\n",
      "Scraping Louis Jauregui...\n",
      "http://ufcstats.com/fighter-details/0e8744ded08ee5fb\n",
      "Scraping Yazmin Jauregui...\n",
      "http://ufcstats.com/fighter-details/40cb680ae1cd331f\n",
      "Scraping Justin Jaynes...\n",
      "http://ufcstats.com/fighter-details/304a21d0595e1a08\n",
      "Scraping Joanna Jedrzejczyk...\n",
      "http://ufcstats.com/fighter-details/3d6749c4267da18f\n",
      "Scraping Aaron Jeffery...\n",
      "http://ufcstats.com/fighter-details/ccdcb20370be62a3\n",
      "Scraping Trent Jenkins...\n",
      "http://ufcstats.com/fighter-details/02fc8f50f56eb307\n",
      "Scraping Bubba Jenkins...\n",
      "http://ufcstats.com/fighter-details/5e841bb3752b6e86\n",
      "Scraping Adrienna Jenkins...\n",
      "http://ufcstats.com/fighter-details/dae85a6a83f53215\n",
      "Scraping Brandon Jenkins...\n",
      "http://ufcstats.com/fighter-details/6a8928652fc01bee\n",
      "Scraping Jack Jenkins...\n",
      "http://ufcstats.com/fighter-details/a9da3158dd2c2b5a\n",
      "Scraping Steve Jennum...\n",
      "http://ufcstats.com/fighter-details/ad047e3073a775f3\n",
      "Scraping Ryan Jensen...\n",
      "http://ufcstats.com/fighter-details/aae99701b21554e4\n",
      "Scraping Kyle Jensen...\n",
      "http://ufcstats.com/fighter-details/aec273fcb765330d\n",
      "Scraping Chan-Mi Jeon...\n",
      "http://ufcstats.com/fighter-details/24174a3f44ce8e03\n",
      "Scraping Maciej Jewtuszko...\n",
      "http://ufcstats.com/fighter-details/6b5b9be990774f0e\n",
      "Scraping Ronald Jhun...\n",
      "http://ufcstats.com/fighter-details/b9e871af730f826c\n",
      "Scraping Baergeng Jieleyisi...\n",
      "http://ufcstats.com/fighter-details/8677e67a75d65b8e\n",
      "Scraping Gilbert Jimenez...\n",
      "http://ufcstats.com/fighter-details/59d36ddfcb27b7dc\n",
      "Scraping Art Jimmerson...\n",
      "http://ufcstats.com/fighter-details/a5c53b3ddb31cc7d\n",
      "Scraping Ryan Jimmo...\n",
      "http://ufcstats.com/fighter-details/bc3ec52ef70fc155\n",
      "Scraping Jinensibieke Asikeerbai...\n",
      "http://ufcstats.com/fighter-details/4eccb78d628b2238\n",
      "Scraping Jiniushiyue...\n",
      "http://ufcstats.com/fighter-details/c14a683dac2ebc4c\n",
      "Scraping Sung Bin Jo...\n",
      "http://ufcstats.com/fighter-details/6e0e977beb909837\n",
      "Scraping Carls John De Tomas...\n",
      "http://ufcstats.com/fighter-details/2a4200ead401a9ce\n",
      "Scraping Phil Johns...\n",
      "http://ufcstats.com/fighter-details/a8fa0c4e95512806\n",
      "Scraping Brett Johns...\n",
      "http://ufcstats.com/fighter-details/ec52462a1b41f714\n",
      "Scraping Miles Johns...\n",
      "http://ufcstats.com/fighter-details/46e0d677f91bacc0\n",
      "Scraping Anthony Johnson...\n",
      "http://ufcstats.com/fighter-details/365fee2da473b177\n",
      "Scraping DaMarques Johnson...\n",
      "http://ufcstats.com/fighter-details/322a56923b396b4d\n",
      "Scraping Devin Johnson...\n",
      "http://ufcstats.com/fighter-details/22f4b6cb6b1bd7fd\n",
      "Scraping Travis Johnson...\n",
      "http://ufcstats.com/fighter-details/443835675e8fc6ca\n",
      "Scraping Ricky Johnson...\n",
      "http://ufcstats.com/fighter-details/fa2fca260beeb9c0\n",
      "Scraping Tony Johnson...\n",
      "http://ufcstats.com/fighter-details/3641a0d117e9bc6c\n",
      "Scraping Lavar Johnson...\n",
      "http://ufcstats.com/fighter-details/e6c5908910cc26e4\n",
      "Scraping Demetrious Johnson...\n",
      "http://ufcstats.com/fighter-details/8a304bfd6bf04a57\n",
      "Scraping Michael Johnson...\n",
      "http://ufcstats.com/fighter-details/511e82663651438d\n",
      "Scraping Deshaun Johnson...\n",
      "http://ufcstats.com/fighter-details/bf97ad31eae89429\n",
      "Scraping Kajan Johnson...\n",
      "http://ufcstats.com/fighter-details/633a45d131192ffe\n",
      "Scraping Dashon Johnson...\n",
      "http://ufcstats.com/fighter-details/36207c58e854cae5\n",
      "Scraping Timothy Johnson...\n",
      "http://ufcstats.com/fighter-details/cc900af167fbedfd\n",
      "Scraping Tony Johnson...\n",
      "http://ufcstats.com/fighter-details/a45bab49951a45cd\n",
      "Scraping Jordan Johnson...\n",
      "http://ufcstats.com/fighter-details/99bcdf5eac39898f\n",
      "Scraping Taylor Johnson...\n",
      "http://ufcstats.com/fighter-details/552b09cbf13b6328\n",
      "Scraping Chad Johnson...\n",
      "http://ufcstats.com/fighter-details/6ce9a012e4c6020c\n",
      "Scraping Jose Johnson...\n",
      "http://ufcstats.com/fighter-details/84f727cf0166d6f2\n",
      "Scraping Charles Johnson...\n",
      "http://ufcstats.com/fighter-details/814e5233e2acf2ee\n",
      "Scraping Brian Johnston...\n",
      "http://ufcstats.com/fighter-details/1c3f5e85b59ec710\n",
      "Scraping Liana Jojua...\n",
      "http://ufcstats.com/fighter-details/eebc23626e38f5dc\n",
      "Scraping Daniel Jolly...\n",
      "http://ufcstats.com/fighter-details/eeabcd4dc6619129\n",
      "Scraping Paul Jones...\n",
      "http://ufcstats.com/fighter-details/f341f9551ba744e2\n",
      "Scraping Jon Jones...\n",
      "http://ufcstats.com/fighter-details/07f72a2a7591b409\n",
      "Scraping Nathan Jones...\n",
      "http://ufcstats.com/fighter-details/f54fb3b9c4228142\n",
      "Scraping Marcus Jones...\n",
      "http://ufcstats.com/fighter-details/8fa2b06572365321\n",
      "Scraping Carlton Jones...\n",
      "http://ufcstats.com/fighter-details/f117c3e8c1aa7b9e\n",
      "Scraping Jesse Jones...\n",
      "http://ufcstats.com/fighter-details/bc0f994de0521926\n",
      "Scraping Tito Jones...\n",
      "http://ufcstats.com/fighter-details/7b223a22a6c26868\n",
      "Scraping Roy Jones...\n",
      "http://ufcstats.com/fighter-details/be8dfcf0442812b1\n",
      "Scraping Justin Jones...\n",
      "http://ufcstats.com/fighter-details/9b75954db8db2a08\n",
      "Scraping Ben Jones...\n",
      "http://ufcstats.com/fighter-details/329aff8e958a2997\n",
      "Scraping Victor Jones...\n",
      "http://ufcstats.com/fighter-details/04f0471f221db717\n",
      "Scraping Chris Jones...\n",
      "http://ufcstats.com/fighter-details/509319d35664369e\n",
      "Scraping Roshaun Jones...\n",
      "http://ufcstats.com/fighter-details/8a9f54b9056b07f5\n",
      "Scraping Jamelle Jones...\n",
      "http://ufcstats.com/fighter-details/1dda22d0ac3d1271\n",
      "Scraping Antonio Jones...\n",
      "http://ufcstats.com/fighter-details/f1fd494586ab8d5f\n",
      "Scraping Trevin Jones...\n",
      "http://ufcstats.com/fighter-details/ec23c1be628d8057\n",
      "Scraping Mason Jones...\n",
      "http://ufcstats.com/fighter-details/f6ad6a1e4d600e0d\n",
      "Scraping Craig Jones...\n",
      "http://ufcstats.com/fighter-details/e947b563eb744a21\n",
      "Scraping Jacobi Jones...\n",
      "http://ufcstats.com/fighter-details/08b01ed84044c6bc\n",
      "Scraping Jocelyn Jones-Lybarger...\n",
      "http://ufcstats.com/fighter-details/1a98c9dbb7fc3959\n",
      "Scraping Kevin Jordan...\n",
      "http://ufcstats.com/fighter-details/02e52b3a595f0786\n",
      "Scraping Joe Jordan...\n",
      "http://ufcstats.com/fighter-details/712c4db78b9373d1\n",
      "Scraping Shawn Jordan...\n",
      "http://ufcstats.com/fighter-details/ca2efc9d7d523c43\n",
      "Scraping Ivan Jorge...\n",
      "http://ufcstats.com/fighter-details/19db7ac26308178f\n",
      "Scraping Scott Jorgensen...\n",
      "http://ufcstats.com/fighter-details/0b64d0fed453ef7f\n",
      "Scraping Gareth Joseph...\n",
      "http://ufcstats.com/fighter-details/8ecb9f42da5ef5ac\n",
      "Scraping Dwight Joseph...\n",
      "http://ufcstats.com/fighter-details/34ca93f1791a5c50\n",
      "Scraping Jeff Joslin...\n",
      "http://ufcstats.com/fighter-details/388abbf8832b5adf\n",
      "Scraping Krzysztof Jotko...\n",
      "http://ufcstats.com/fighter-details/4e06913c91da5200\n",
      "Scraping Alan Jouban...\n",
      "http://ufcstats.com/fighter-details/cf65d56b0755ed3b\n",
      "Scraping Charles Jourdain...\n",
      "http://ufcstats.com/fighter-details/f1d64ae34e088832\n",
      "Scraping Kevin Jousset...\n",
      "http://ufcstats.com/fighter-details/dda15dbfafb792df\n",
      "Scraping Mike Joy...\n",
      "http://ufcstats.com/fighter-details/35080a7f406f9ab3\n",
      "Scraping Dustin Joynson...\n",
      "http://ufcstats.com/fighter-details/791367e8c35cfb6a\n",
      "Scraping Tony Juarez...\n",
      "http://ufcstats.com/fighter-details/97f3692d5444a80a\n",
      "Scraping Jesse Juarez...\n",
      "http://ufcstats.com/fighter-details/cd039ff136d89ded\n",
      "Scraping Ernie Juarez...\n",
      "http://ufcstats.com/fighter-details/410898e8dd6ca9b6\n",
      "Scraping Anshul Jubli...\n",
      "http://ufcstats.com/fighter-details/a72a2a769fa5a2be\n",
      "Scraping Carli Judice...\n",
      "http://ufcstats.com/fighter-details/f1ab6f37492c630a\n",
      "Scraping Steve Judson...\n",
      "http://ufcstats.com/fighter-details/6ece1d2ab1bed31d\n",
      "Scraping Luke Jumeau...\n",
      "http://ufcstats.com/fighter-details/4c288a2b250bb576\n",
      "Scraping Bu-Kyung Jung...\n",
      "http://ufcstats.com/fighter-details/b35d1650c78c2948\n",
      "Scraping Chan Sung Jung...\n",
      "http://ufcstats.com/fighter-details/c451d67c09c55418\n",
      "Scraping Young Sam Jung...\n",
      "http://ufcstats.com/fighter-details/13104eaed3ae96c3\n",
      "Scraping Da Woon Jung...\n",
      "http://ufcstats.com/fighter-details/74f9448b97bf8bec\n",
      "Scraping Scott Junk...\n",
      "http://ufcstats.com/fighter-details/ac70a4f1db1b8c40\n",
      "Scraping Myles Jury...\n",
      "http://ufcstats.com/fighter-details/08e908ed6d18d6a0\n",
      "Scraping Cristiane Justino...\n",
      "http://ufcstats.com/fighter-details/634bb0de2eb043b4\n",
      "Scraping Patrick Kaase...\n",
      "http://ufcstats.com/fighter-details/b180f05acb24d430\n",
      "Scraping Emily Kagan...\n",
      "http://ufcstats.com/fighter-details/c1ea9d56cd953586\n",
      "Scraping Oron Kahlon...\n",
      "http://ufcstats.com/fighter-details/00a35c92b03992b0\n",
      "Scraping Kaiwen...\n",
      "http://ufcstats.com/fighter-details/0565706b1e7f7e7c\n",
      "Scraping Sirwan Kakai...\n",
      "http://ufcstats.com/fighter-details/2525a853486ee670\n",
      "Scraping Saidyokub Kakhramonov...\n",
      "http://ufcstats.com/fighter-details/50a28b9f8314e008\n",
      "Scraping Geza Kalman...\n",
      "http://ufcstats.com/fighter-details/304fcd812f12c589\n",
      "Scraping Bryson Kamaka...\n",
      "http://ufcstats.com/fighter-details/9336e86cfd4ceaa1\n",
      "Scraping Kai Kamaka...\n",
      "http://ufcstats.com/fighter-details/eee0ef3e2b14816b\n",
      "Scraping Shuya Kamikubo...\n",
      "http://ufcstats.com/fighter-details/a46fa1c7972548d0\n",
      "Scraping Martin Kampmann...\n",
      "http://ufcstats.com/fighter-details/8b69839f3555a67b\n",
      "Scraping Koya Kanda...\n",
      "http://ufcstats.com/fighter-details/b42d3a1469dab722\n",
      "Scraping Bharat Kandare...\n",
      "http://ufcstats.com/fighter-details/efd2b3e9bb7965a4\n",
      "Scraping Hiromitsu Kanehara...\n",
      "http://ufcstats.com/fighter-details/eda579d906cf0ca2\n",
      "Scraping Masanori Kanehara...\n",
      "http://ufcstats.com/fighter-details/f3a078277b3b8ff4\n",
      "Scraping Ken Kaneko...\n",
      "http://ufcstats.com/fighter-details/5345f86680378fc1\n",
      "Scraping Denis Kang...\n",
      "http://ufcstats.com/fighter-details/3c241737a6069b9f\n",
      "Scraping Kyung Ho Kang...\n",
      "http://ufcstats.com/fighter-details/a7897d200692ab64\n",
      "Scraping Manel Kape...\n",
      "http://ufcstats.com/fighter-details/5d1b7e3dd9e11074\n",
      "Scraping David Kaplan...\n",
      "http://ufcstats.com/fighter-details/5669b828e7e11329\n",
      "Scraping Kai Kara-France...\n",
      "http://ufcstats.com/fighter-details/853eb0dd5c0e2149\n",
      "Scraping Georgi Karakhanyan...\n",
      "http://ufcstats.com/fighter-details/43292ecf0e72c143\n",
      "Scraping Alex Karalexis...\n",
      "http://ufcstats.com/fighter-details/e361e5c858af6ff1\n",
      "Scraping Ernesta Kareckaite...\n",
      "http://ufcstats.com/fighter-details/e4faa79383c9f214\n",
      "Scraping Impa Kasanganay...\n",
      "http://ufcstats.com/fighter-details/257b0c8d6f199895\n",
      "Scraping Jinnosuke Kashimura...\n",
      "http://ufcstats.com/fighter-details/4a9120fa47bafef0\n",
      "Scraping Nadia Kassem...\n",
      "http://ufcstats.com/fighter-details/6e7506127408aa9e\n",
      "Scraping Yusuke Kasuya...\n",
      "http://ufcstats.com/fighter-details/3058888c33149a53\n",
      "Scraping Tetsuji Kato...\n",
      "http://ufcstats.com/fighter-details/542db012217ecb83\n",
      "Scraping Hisaki Kato...\n",
      "http://ufcstats.com/fighter-details/ebf1c247b2cba375\n",
      "Scraping Brad Katona...\n",
      "http://ufcstats.com/fighter-details/7b433309b0fd12aa\n",
      "Scraping Calvin Kattar...\n",
      "http://ufcstats.com/fighter-details/751de04455cfaac0\n",
      "Scraping Sarah Kaufman...\n",
      "http://ufcstats.com/fighter-details/36df8e119aec6175\n",
      "Scraping Lone'er Kavanagh...\n",
      "http://ufcstats.com/fighter-details/bb2c3c3a466224af\n",
      "Scraping Yusuke Kawaguchi...\n",
      "http://ufcstats.com/fighter-details/fa2320781bfe4f49\n",
      "Scraping Canaan Kawaihae...\n",
      "http://ufcstats.com/fighter-details/58d42b9e920b25fc\n",
      "Scraping Tatsuya Kawajiri...\n",
      "http://ufcstats.com/fighter-details/80d918336163b80c\n",
      "Scraping Ryo Kawamura...\n",
      "http://ufcstats.com/fighter-details/9e91d7fd2720e241\n",
      "Scraping Masuto Kawana...\n",
      "http://ufcstats.com/fighter-details/49f4171f14f54220\n",
      "Scraping Doug Kay...\n",
      "http://ufcstats.com/fighter-details/547c5611bd366988\n",
      "Scraping Toshiomi Kazama...\n",
      "http://ufcstats.com/fighter-details/148bb103cfbf123e\n",
      "Scraping Julie Kedzie...\n",
      "http://ufcstats.com/fighter-details/981ab7a0576f76a0\n",
      "Scraping Ryan Keenan...\n",
      "http://ufcstats.com/fighter-details/a72b20136239ba39\n",
      "Scraping CJ Keith...\n",
      "http://ufcstats.com/fighter-details/c0eecd851dbf3146\n",
      "Scraping Chris Kelades...\n",
      "http://ufcstats.com/fighter-details/56c9acc4e86046a2\n",
      "Scraping Brian Kelleher...\n",
      "http://ufcstats.com/fighter-details/7be14eaed4c74856\n",
      "Scraping Mayana Kellem...\n",
      "http://ufcstats.com/fighter-details/c788481ae19e798d\n",
      "Scraping Tony Kelley...\n",
      "http://ufcstats.com/fighter-details/1a08b01fdabb6ae2\n",
      "Scraping Paul Kelly...\n",
      "http://ufcstats.com/fighter-details/aac5ac38148f0528\n",
      "Scraping John Kelly...\n",
      "http://ufcstats.com/fighter-details/ace83095105dd205\n",
      "Scraping Daniel Kelly...\n",
      "http://ufcstats.com/fighter-details/bdcbb976816fd256\n",
      "Scraping Tim Kennedy...\n",
      "http://ufcstats.com/fighter-details/3c660c90d48fc80d\n",
      "Scraping Steve Kennedy...\n",
      "http://ufcstats.com/fighter-details/185fb0200a4605e6\n",
      "Scraping Jeremy Kennedy...\n",
      "http://ufcstats.com/fighter-details/68f6e96c5fa6e044\n",
      "Scraping Waylon Kennell...\n",
      "http://ufcstats.com/fighter-details/9b8a73b59be8d786\n",
      "Scraping Casey Kenney...\n",
      "http://ufcstats.com/fighter-details/e7bba7ce4d6c7b07\n",
      "Scraping Maimaitituoheti Keremuaili...\n",
      "http://ufcstats.com/fighter-details/772022b989534f0d\n",
      "Scraping Aurelijus Kerpe...\n",
      "http://ufcstats.com/fighter-details/c1e4ae143cce7398\n",
      "Scraping Mark Kerr...\n",
      "http://ufcstats.com/fighter-details/a7b48e18ca27795d\n",
      "Scraping Will Kerr...\n",
      "http://ufcstats.com/fighter-details/ef61d9f5176b3200\n",
      "Scraping Ron Keslar...\n",
      "http://ufcstats.com/fighter-details/b84f34b425dfd24b\n",
      "Scraping Rustam Khabilov...\n",
      "http://ufcstats.com/fighter-details/9b7694d064a8a0ad\n",
      "Scraping Adam Khaliev...\n",
      "http://ufcstats.com/fighter-details/1aba18b5f15d4956\n",
      "Scraping Sergey Khandozhko...\n",
      "http://ufcstats.com/fighter-details/90da09db03e41748\n",
      "Scraping Sergei Kharitonov...\n",
      "http://ufcstats.com/fighter-details/0693b2eab79198ea\n",
      "Scraping Alfred Khashakyan...\n",
      "http://ufcstats.com/fighter-details/3929efe0c0a83d07\n",
      "Scraping Aliaskhab Khizriev...\n",
      "http://ufcstats.com/fighter-details/7ab478c397cd68ef\n",
      "Scraping WonBin Ki...\n",
      "http://ufcstats.com/fighter-details/aaeb55084b198a39\n",
      "Scraping Pannie Kianzad...\n",
      "http://ufcstats.com/fighter-details/91dac5e69e28d5b5\n",
      "Scraping Akira Kikuchi...\n",
      "http://ufcstats.com/fighter-details/9c37681096c6f3a9\n",
      "Scraping Katsunori Kikuno...\n",
      "http://ufcstats.com/fighter-details/44470bfd9483c7ad\n",
      "Scraping Sanae Kikuta...\n",
      "http://ufcstats.com/fighter-details/e4bde462b043d3e1\n",
      "Scraping Jacob Kilburn...\n",
      "http://ufcstats.com/fighter-details/637bd06c32219f0b\n",
      "Scraping Dong Hyun Kim...\n",
      "http://ufcstats.com/fighter-details/9bcf8603ceb25680\n",
      "Scraping Jin Oh Kim...\n",
      "http://ufcstats.com/fighter-details/8d04923f2db59b7f\n",
      "Scraping Dae Won Kim...\n",
      "http://ufcstats.com/fighter-details/354808cf38d9d73c\n",
      "Scraping Jong Wang Kim...\n",
      "http://ufcstats.com/fighter-details/380e8b023290d091\n",
      "Scraping Jong Won Kim...\n",
      "http://ufcstats.com/fighter-details/9e0f28d1f639ad73\n",
      "Scraping Min Soo Kim...\n",
      "http://ufcstats.com/fighter-details/831b937811804dad\n",
      "Scraping Jong Man Kim...\n",
      "http://ufcstats.com/fighter-details/dba230fe33011201\n",
      "Scraping Ji Yeon Kim...\n",
      "http://ufcstats.com/fighter-details/a20f234df70f2182\n",
      "Scraping MinWoo Kim...\n",
      "http://ufcstats.com/fighter-details/6343a95f1d9e6a33\n",
      "Scraping HanSeul Kim...\n",
      "http://ufcstats.com/fighter-details/2bc47c7cc6c05bd7\n",
      "Scraping KyeungPyo Kim...\n",
      "http://ufcstats.com/fighter-details/5a9f7b5ffebdd6e7\n",
      "Scraping Sangwook Kim...\n",
      "http://ufcstats.com/fighter-details/a264d4e9a4d6bfe4\n",
      "Scraping SangWon Kim...\n",
      "http://ufcstats.com/fighter-details/e9712cad24948ce1\n",
      "Scraping KyuSung Kim...\n",
      "http://ufcstats.com/fighter-details/e7ecfab8fd86d3e1\n",
      "Scraping So Yul Kim...\n",
      "http://ufcstats.com/fighter-details/864c07a7ff90caae\n",
      "Scraping Jeremy Kimball...\n",
      "http://ufcstats.com/fighter-details/917a5cb9821df261\n",
      "Scraping Rob Kimmons...\n",
      "http://ufcstats.com/fighter-details/054defd5420a551f\n",
      "Scraping Dustin Kimura...\n",
      "http://ufcstats.com/fighter-details/fe91d254db77a7fc\n",
      "Scraping Taiei Kin...\n",
      "http://ufcstats.com/fighter-details/c7ac79839e86ce33\n",
      "Scraping Mike King...\n",
      "http://ufcstats.com/fighter-details/564c2f5f9eb45d67\n",
      "Scraping Kyle Kingsbury...\n",
      "http://ufcstats.com/fighter-details/b959e8c7fd8390d2\n",
      "Scraping Yusaku Kinoshita...\n",
      "http://ufcstats.com/fighter-details/21b5c82c1b89dab1\n",
      "Scraping Kamuela Kirk...\n",
      "http://ufcstats.com/fighter-details/c7d7fda69ec410d3\n",
      "Scraping Yurij Kiseliov...\n",
      "http://ufcstats.com/fighter-details/51d2aaaca56e5b40\n",
      "Scraping Justine Kish...\n",
      "http://ufcstats.com/fighter-details/928ae2e5b5f7a9ec\n",
      "Scraping Koji Kitao...\n",
      "http://ufcstats.com/fighter-details/2a6f8136da1e52c0\n",
      "Scraping Satoru Kitaoka...\n",
      "http://ufcstats.com/fighter-details/e2ac5bb645f33088\n",
      "Scraping Top Noi Kiwram...\n",
      "http://ufcstats.com/fighter-details/e065b4a42a6c2c79\n",
      "Scraping Ludovit Klein...\n",
      "http://ufcstats.com/fighter-details/5b86d491d63890c5\n",
      "Scraping Nick Klein...\n",
      "http://ufcstats.com/fighter-details/7eaa5e31c2dd86aa\n",
      "Scraping Seth Kleinbeck...\n",
      "http://ufcstats.com/fighter-details/8ad022dd81224f61\n",
      "Scraping Stefan Klever...\n",
      "http://ufcstats.com/fighter-details/bc3876891e155bb5\n",
      "Scraping Fatima Kline...\n",
      "http://ufcstats.com/fighter-details/745fa7b605f8e2da\n",
      "Scraping Felix Klinkhammer...\n",
      "http://ufcstats.com/fighter-details/8276f28f1ad087de\n",
      "Scraping Drakkar Klose...\n",
      "http://ufcstats.com/fighter-details/7cbf7c78d3b34218\n",
      "Scraping Michael Knaap...\n",
      "http://ufcstats.com/fighter-details/02f0e04acf102ea9\n",
      "Scraping Kevin Knabjian...\n",
      "http://ufcstats.com/fighter-details/1fac46d466abd5b8\n",
      "Scraping Jason Knight...\n",
      "http://ufcstats.com/fighter-details/bb1a2cdad6ff34db\n",
      "Scraping William Knight...\n",
      "http://ufcstats.com/fighter-details/5da33b8fbfa5ee95\n",
      "Scraping Josefine Knutsson...\n",
      "http://ufcstats.com/fighter-details/971dba22c622af12\n",
      "Scraping Seokhyeon Ko...\n",
      "http://ufcstats.com/fighter-details/4a07b1988477502c\n",
      "Scraping Isao Kobayashi...\n",
      "http://ufcstats.com/fighter-details/a02652d063ef5baa\n",
      "Scraping Kelly Kobold...\n",
      "http://ufcstats.com/fighter-details/c398235fcaf8d71d\n",
      "Scraping Erik Koch...\n",
      "http://ufcstats.com/fighter-details/99bd87a300079ed9\n",
      "Scraping Sokun Koh...\n",
      "http://ufcstats.com/fighter-details/6d8ef8706781c49e\n",
      "Scraping Shingo Kohara...\n",
      "http://ufcstats.com/fighter-details/44c233770075cea1\n",
      "Scraping Brad Kohler...\n",
      "http://ufcstats.com/fighter-details/13c4313ed0f744f3\n",
      "Scraping Charlie Kohler...\n",
      "http://ufcstats.com/fighter-details/5717efc6f271cd52\n",
      "Scraping Tsuyoshi Kohsaka...\n",
      "http://ufcstats.com/fighter-details/b76ed59283d3559c\n",
      "Scraping Kaloyan Kolev...\n",
      "http://ufcstats.com/fighter-details/33de378ce1734638\n",
      "Scraping John Kolosci...\n",
      "http://ufcstats.com/fighter-details/5f6038bcdb95e3e4\n",
      "Scraping Yuki Kondo...\n",
      "http://ufcstats.com/fighter-details/1fe7adb23b3eedfb\n",
      "Scraping Syuri Kondo...\n",
      "http://ufcstats.com/fighter-details/a851c35f58199231\n",
      "Scraping Cheick Kongo...\n",
      "http://ufcstats.com/fighter-details/1eacf73d6a0055dc\n",
      "Scraping Andrei Kopylov...\n",
      "http://ufcstats.com/fighter-details/dd39f1ca787a3d9d\n",
      "Scraping Roman Kopylov...\n",
      "http://ufcstats.com/fighter-details/9d83f6da776ff7d6\n",
      "Scraping Bruno Korea...\n",
      "http://ufcstats.com/fighter-details/6c011be66326ad97\n",
      "Scraping Andrey Koreshkov...\n",
      "http://ufcstats.com/fighter-details/aee885b8ca29ab4f\n",
      "Scraping Josh Koscheck...\n",
      "http://ufcstats.com/fighter-details/dd37fd509af89f15\n",
      "Scraping Steven Koslow...\n",
      "http://ufcstats.com/fighter-details/84512339473dd300\n",
      "Scraping Naoyuki Kotani...\n",
      "http://ufcstats.com/fighter-details/bc8f6b42767e28df\n",
      "Scraping Ilya Kotau...\n",
      "http://ufcstats.com/fighter-details/a68d57ae177a5815\n",
      "Scraping Iouri Kotchkine...\n",
      "http://ufcstats.com/fighter-details/c6becb722706c7d8\n",
      "Scraping Matt Kovacs...\n",
      "http://ufcstats.com/fighter-details/8fbcd82bf7f352bf\n",
      "Scraping Marcus Kowal...\n",
      "http://ufcstats.com/fighter-details/ad0e42800a0d8977\n",
      "Scraping Karolina Kowalkiewicz...\n",
      "http://ufcstats.com/fighter-details/d7c3816669784109\n",
      "Scraping Steve Kozola...\n",
      "http://ufcstats.com/fighter-details/fc36e2352dccf2a4\n",
      "Scraping Derrick Krantz...\n",
      "http://ufcstats.com/fighter-details/714e1e0681ddb703\n",
      "Scraping James Krause...\n",
      "http://ufcstats.com/fighter-details/8f6a18831a120817\n",
      "Scraping Pascal Krauss...\n",
      "http://ufcstats.com/fighter-details/a01e84abefd85ec0\n",
      "Scraping Rene Kronvold...\n",
      "http://ufcstats.com/fighter-details/db05271715bb4874\n",
      "Scraping Kaynan Kruschewsky...\n",
      "http://ufcstats.com/fighter-details/ca36633b80be4a78\n",
      "Scraping Jorgen Kruth...\n",
      "http://ufcstats.com/fighter-details/6071d786f6187810\n",
      "Scraping Nikita Krylov...\n",
      "http://ufcstats.com/fighter-details/1091d4d957141094\n",
      "Scraping Mariusz Ksiazkiewicz...\n",
      "http://ufcstats.com/fighter-details/ab16537dd1e5e81d\n",
      "Scraping Junya Kudo...\n",
      "http://ufcstats.com/fighter-details/487c170da059857d\n",
      "Scraping John Kuhner...\n",
      "http://ufcstats.com/fighter-details/a272656ad662ac53\n",
      "Scraping Michael Kuiper...\n",
      "http://ufcstats.com/fighter-details/b7f38813485745da\n",
      "Scraping Anton Kuivanen...\n",
      "http://ufcstats.com/fighter-details/706f8e2b34e8e18b\n",
      "Scraping Maiju Kujala...\n",
      "http://ufcstats.com/fighter-details/4e77d070239699e2\n",
      "Scraping Sumit Kumar...\n",
      "http://ufcstats.com/fighter-details/a0a625221e0dd339\n",
      "Scraping Aleksei Kunchenko...\n",
      "http://ufcstats.com/fighter-details/e2ccd9a9ace60de7\n",
      "Scraping Rizvan Kuniev...\n",
      "http://ufcstats.com/fighter-details/739fd4fbb5d862f4\n",
      "Scraping Keigo Kunihara...\n",
      "http://ufcstats.com/fighter-details/782a2a17d3e38fdf\n",
      "Scraping Kiichi Kunimoto...\n",
      "http://ufcstats.com/fighter-details/71df36d6d8cf0d74\n",
      "Scraping Leo Kuntz...\n",
      "http://ufcstats.com/fighter-details/6905d45bd71b50a9\n",
      "Scraping Korey Kuppe...\n",
      "http://ufcstats.com/fighter-details/780a2897055e3ee3\n",
      "Scraping Ramazan Kuramagomedov...\n",
      "http://ufcstats.com/fighter-details/b6a73e6f11a8835c\n",
      "Scraping Tsuyoshi Kurihara...\n",
      "http://ufcstats.com/fighter-details/032b65d5fff611b2\n",
      "Scraping Eldari Kurtanidze...\n",
      "http://ufcstats.com/fighter-details/4c78fc005a53831d\n",
      "Scraping Kyle Kurtz...\n",
      "http://ufcstats.com/fighter-details/b490def93478ae29\n",
      "Scraping Guram Kutateladze...\n",
      "http://ufcstats.com/fighter-details/7772b283d288dbe2\n",
      "Scraping Vadym Kutsyi...\n",
      "http://ufcstats.com/fighter-details/aeb2bcd4371f40d5\n",
      "Scraping Lina Kvokov...\n",
      "http://ufcstats.com/fighter-details/843dd76c50cae0f6\n",
      "Scraping Kaleo Kwan...\n",
      "http://ufcstats.com/fighter-details/2545c7f47a65bca3\n",
      "Scraping Jarrod Kwitty...\n",
      "http://ufcstats.com/fighter-details/849d15ed7e3a0e97\n",
      "Scraping Mike Kyle...\n",
      "http://ufcstats.com/fighter-details/56b8b24f65f9f057\n",
      "Scraping Lisa Kyriacou...\n",
      "http://ufcstats.com/fighter-details/edbc609a3b0d2aba\n",
      "Scraping Achmed Labasanov...\n",
      "http://ufcstats.com/fighter-details/b3fb8d2293e17a59\n",
      "Scraping Josh LaBerge...\n",
      "http://ufcstats.com/fighter-details/5108b169b5fe1f86\n",
      "Scraping Jeremiah Labiano...\n",
      "http://ufcstats.com/fighter-details/4fe1d105af549845\n",
      "Scraping Daniel Lacerda...\n",
      "http://ufcstats.com/fighter-details/31bb0772f21cabd8\n",
      "Scraping Luan Lacerda...\n",
      "http://ufcstats.com/fighter-details/6fc506e1099afe20\n",
      "Scraping Kemran Lachinov...\n",
      "http://ufcstats.com/fighter-details/eb84192d1a97f69e\n",
      "Scraping Aspen Ladd...\n",
      "http://ufcstats.com/fighter-details/d4691518d012b9e7\n",
      "Scraping Ryan LaFlare...\n",
      "http://ufcstats.com/fighter-details/4c7781da8c6cae93\n",
      "Scraping Corinne Laframboise...\n",
      "http://ufcstats.com/fighter-details/fbe9f4efc2153be2\n",
      "Scraping Ben Lagman...\n",
      "http://ufcstats.com/fighter-details/b40e65d71a8d4ce5\n",
      "Scraping Noad Lahat...\n",
      "http://ufcstats.com/fighter-details/9f755fb04cc21499\n",
      "Scraping Tina Lahdemaki...\n",
      "http://ufcstats.com/fighter-details/e5ca2bc2451a5956\n",
      "Scraping Yohan Lainesse...\n",
      "http://ufcstats.com/fighter-details/f998f5c102250d6e\n",
      "Scraping Tim Lajcik...\n",
      "http://ufcstats.com/fighter-details/c7e9d15cfce52f1d\n",
      "Scraping Todd Lally...\n",
      "http://ufcstats.com/fighter-details/7d06092326c52528\n",
      "Scraping Sean Lally...\n",
      "http://ufcstats.com/fighter-details/e62ce041bb7aeb1f\n",
      "Scraping Ricardo Lamas...\n",
      "http://ufcstats.com/fighter-details/3974fa35c917af1d\n",
      "Scraping Jason Lambert...\n",
      "http://ufcstats.com/fighter-details/5be86bb2f78fef2f\n",
      "Scraping Jose Landi-Jons...\n",
      "http://ufcstats.com/fighter-details/7e062824c175f975\n",
      "Scraping Nate Landwehr...\n",
      "http://ufcstats.com/fighter-details/583ee11abddfc581\n",
      "Scraping Austen Lane...\n",
      "http://ufcstats.com/fighter-details/be9bdec19b7e9ffe\n",
      "Scraping Aaron Lanfranco...\n",
      "http://ufcstats.com/fighter-details/d73e856f150744b2\n",
      "Scraping Jeremy Lang...\n",
      "http://ufcstats.com/fighter-details/09422812370fbdfe\n",
      "Scraping Lionel Lanham...\n",
      "http://ufcstats.com/fighter-details/b8980dd7e8fc5976\n",
      "Scraping Lina Lansberg...\n",
      "http://ufcstats.com/fighter-details/2eeaefbfc7f9fcff\n",
      "Scraping Taylor Lapilus...\n",
      "http://ufcstats.com/fighter-details/8b1ed83b02303075\n",
      "Scraping Chad Laprise...\n",
      "http://ufcstats.com/fighter-details/c03a5022f8439f2a\n",
      "Scraping Anthony Lapsley...\n",
      "http://ufcstats.com/fighter-details/f3a853544e4413c4\n",
      "Scraping TJ Laramie...\n",
      "http://ufcstats.com/fighter-details/cd2e5a390821fb48\n",
      "Scraping Icho Larenas...\n",
      "http://ufcstats.com/fighter-details/49efbdc6c9f650c4\n",
      "Scraping Lorenz Larkin...\n",
      "http://ufcstats.com/fighter-details/9450848a71d53776\n",
      "Scraping Jeremy Larsen...\n",
      "http://ufcstats.com/fighter-details/c3bd649a9194e50c\n",
      "Scraping Brock Larson...\n",
      "http://ufcstats.com/fighter-details/5eedbf1e9601be35\n",
      "Scraping Ryan Larson...\n",
      "http://ufcstats.com/fighter-details/7107e53ebd7435fb\n",
      "Scraping Bobby Lashley...\n",
      "http://ufcstats.com/fighter-details/b0826525fa17231d\n",
      "Scraping Ilir Latifi...\n",
      "http://ufcstats.com/fighter-details/e9a3aeb207578eea\n",
      "Scraping Sione Latu...\n",
      "http://ufcstats.com/fighter-details/5898357a45a73674\n",
      "Scraping Phillip Latu...\n",
      "http://ufcstats.com/fighter-details/09224b76d27007ee\n",
      "Scraping Jenel Lausa...\n",
      "http://ufcstats.com/fighter-details/ec664422b22d9787\n",
      "Scraping Joe Lauzon...\n",
      "http://ufcstats.com/fighter-details/3bad7ef643840f67\n",
      "Scraping Dan Lauzon...\n",
      "http://ufcstats.com/fighter-details/4c8d6fde2dde07c4\n",
      "Scraping Sandra Lavado...\n",
      "http://ufcstats.com/fighter-details/aa6da8cb3a26da04\n",
      "Scraping Chatt Lavender...\n",
      "http://ufcstats.com/fighter-details/5449dcccd972ff83\n",
      "Scraping Muhammed Lawal...\n",
      "http://ufcstats.com/fighter-details/a571770c4016736f\n",
      "Scraping Robbie Lawler...\n",
      "http://ufcstats.com/fighter-details/f2925e6db404bf1d\n",
      "Scraping Tom Lawlor...\n",
      "http://ufcstats.com/fighter-details/4d44f37107f01b9b\n",
      "Scraping Justin Lawrence...\n",
      "http://ufcstats.com/fighter-details/879f6cae48d25baa\n",
      "Scraping Lance Lawrence...\n",
      "http://ufcstats.com/fighter-details/ce039df1994b18f0\n",
      "Scraping Ronnie Lawrence...\n",
      "http://ufcstats.com/fighter-details/e7e01e266a9d4342\n",
      "Scraping Eric Lawson...\n",
      "http://ufcstats.com/fighter-details/38e5d9dcb0fddc42\n",
      "Scraping Jimmy Lawson...\n",
      "http://ufcstats.com/fighter-details/e43eefb10d440cb0\n",
      "Scraping Valmir Lazaro...\n",
      "http://ufcstats.com/fighter-details/777dea713da2441d\n",
      "Scraping Zviad Lazishvili...\n",
      "http://ufcstats.com/fighter-details/41498c2d1a87b154\n",
      "Scraping Mounir Lazzez...\n",
      "http://ufcstats.com/fighter-details/49ee5024966efc0d\n",
      "Scraping Cung Le...\n",
      "http://ufcstats.com/fighter-details/d4f364dd076bb0e2\n",
      "Scraping Thanh Le...\n",
      "http://ufcstats.com/fighter-details/882b3f5a0774d575\n",
      "Scraping Quang Le...\n",
      "http://ufcstats.com/fighter-details/32feae6d9a1e5047\n",
      "Scraping Jordan Leavitt...\n",
      "http://ufcstats.com/fighter-details/ac026518a9b4dc0f\n",
      "Scraping Jerome LeBanner...\n",
      "http://ufcstats.com/fighter-details/2d0b10789feafddb\n",
      "Scraping Chris Leben...\n",
      "http://ufcstats.com/fighter-details/d43a048a880efdff\n",
      "Scraping Mickael Lebout...\n",
      "http://ufcstats.com/fighter-details/c575ab451e3c5b1d\n",
      "Scraping Stephen Ledbetter...\n",
      "http://ufcstats.com/fighter-details/56ec58954158966a\n",
      "Scraping Justin Ledet...\n",
      "http://ufcstats.com/fighter-details/ba1e6cb3d43f7430\n",
      "Scraping James Lee...\n",
      "http://ufcstats.com/fighter-details/863d06a7ef8bc98c\n",
      "Scraping David Lee...\n",
      "http://ufcstats.com/fighter-details/8caca5857ce0e30b\n",
      "Scraping Jackie Lee...\n",
      "http://ufcstats.com/fighter-details/4985113c0928aa62\n",
      "Scraping Eun Soo Lee...\n",
      "http://ufcstats.com/fighter-details/39c568f8c579913e\n",
      "Scraping Tae Hyun Lee...\n",
      "http://ufcstats.com/fighter-details/de99da2c0d18d34a\n",
      "Scraping Tommy Lee...\n",
      "http://ufcstats.com/fighter-details/806975e1b4f47b27\n",
      "Scraping Matt Lee...\n",
      "http://ufcstats.com/fighter-details/d9e3743bae8d703d\n",
      "Scraping Imani Lee...\n",
      "http://ufcstats.com/fighter-details/0802be3516ef8f66\n",
      "Scraping Vaughan Lee...\n",
      "http://ufcstats.com/fighter-details/8bb6f4479685bbcc\n",
      "Scraping Kevin Lee...\n",
      "http://ufcstats.com/fighter-details/ee9ebceabfd16fa7\n",
      "Scraping Rocky Lee...\n",
      "http://ufcstats.com/fighter-details/0d1c163b206e8c5f\n",
      "Scraping Andrea Lee...\n",
      "http://ufcstats.com/fighter-details/05fa626cb33d15b8\n",
      "Scraping JeongYeong Lee...\n",
      "http://ufcstats.com/fighter-details/d008d785f6347dc2\n",
      "Scraping JungHyun Lee...\n",
      "http://ufcstats.com/fighter-details/b6033505c245e28b\n",
      "Scraping ChangHo Lee...\n",
      "http://ufcstats.com/fighter-details/117a06469813e4ef\n",
      "Scraping Ricky Legere Jr....\n",
      "http://ufcstats.com/fighter-details/5817df778cc27274\n",
      "Scraping Sherron Leggett...\n",
      "http://ufcstats.com/fighter-details/4f670b7972fa0a2e\n",
      "Scraping Cheyden Leialoha...\n",
      "http://ufcstats.com/fighter-details/98cbbc06074c68a4\n",
      "Scraping Claudia Leite...\n",
      "http://ufcstats.com/fighter-details/90550a08f0b02b6f\n",
      "Scraping Thales Leites...\n",
      "http://ufcstats.com/fighter-details/cfb65863d5099327\n",
      "Scraping Stefan Leko...\n",
      "http://ufcstats.com/fighter-details/d56bb6dff2ae77eb\n",
      "Scraping Gabe Lemley...\n",
      "http://ufcstats.com/fighter-details/fd4578cac86d75ca\n",
      "Scraping Amanda Lemos...\n",
      "http://ufcstats.com/fighter-details/3df5493bb279226f\n",
      "Scraping Giacomo Lemos...\n",
      "http://ufcstats.com/fighter-details/f37822d5b3e47517\n",
      "Scraping Christophe Leninger...\n",
      "http://ufcstats.com/fighter-details/7269329bd87eb479\n",
      "Scraping Jesse Lennox...\n",
      "http://ufcstats.com/fighter-details/3ae10ac4df3df05c\n",
      "Scraping Jean Francois Lenogue...\n",
      "http://ufcstats.com/fighter-details/e60201cfab7d656d\n",
      "Scraping Nik Lentz...\n",
      "http://ufcstats.com/fighter-details/6fb1ba67bef41b37\n",
      "Scraping Alberta Cerra Leon...\n",
      "http://ufcstats.com/fighter-details/6e02c318762f52f1\n",
      "Scraping Victoria Leonardo...\n",
      "http://ufcstats.com/fighter-details/9dedfdd91070ddd8\n",
      "Scraping Anthony Leone...\n",
      "http://ufcstats.com/fighter-details/86b9b51a81e9c339\n",
      "Scraping Chad Leonhardt...\n",
      "http://ufcstats.com/fighter-details/657d0ed181f04215\n",
      "Scraping Kimo Leopoldo...\n",
      "http://ufcstats.com/fighter-details/08ae5cd9aef7ddd3\n",
      "Scraping Michael Lerma...\n",
      "http://ufcstats.com/fighter-details/f1fd8ec1023c89b3\n",
      "Scraping Lukasz Les...\n",
      "http://ufcstats.com/fighter-details/5a8e30ed38a5bc6f\n",
      "Scraping Brock Lesnar...\n",
      "http://ufcstats.com/fighter-details/513c6f1715e547a8\n",
      "Scraping Frank Lester...\n",
      "http://ufcstats.com/fighter-details/edd8d5d8089a35f8\n",
      "Scraping Valerie Letourneau...\n",
      "http://ufcstats.com/fighter-details/46a2f24feb258ae0\n",
      "Scraping Leah Letson...\n",
      "http://ufcstats.com/fighter-details/8cb78f3a6c2a08f7\n",
      "Scraping Justin Levens...\n",
      "http://ufcstats.com/fighter-details/8c3f3c43c8ceb778\n",
      "Scraping Marcus LeVesseur...\n",
      "http://ufcstats.com/fighter-details/182f2b78582de3d8\n",
      "Scraping David Levicki...\n",
      "http://ufcstats.com/fighter-details/49590e0508b2c19f\n",
      "Scraping Kyle Levinton...\n",
      "http://ufcstats.com/fighter-details/81ddc98fceb30086\n",
      "Scraping Natan Levy...\n",
      "http://ufcstats.com/fighter-details/a29db9cd4f9ccea5\n",
      "Scraping John Lewis...\n",
      "http://ufcstats.com/fighter-details/4a01dc8376736ef5\n",
      "Scraping Derrick Lewis...\n",
      "http://ufcstats.com/fighter-details/d3df1add9d9a7efb\n",
      "Scraping Bevon Lewis...\n",
      "http://ufcstats.com/fighter-details/899923ff6ab13917\n",
      "Scraping Brandon Lewis...\n",
      "http://ufcstats.com/fighter-details/6623cb1c27025634\n",
      "Scraping Malik Lewis...\n",
      "http://ufcstats.com/fighter-details/f60dbe6e05489c4f\n",
      "Scraping Chi Lewis-Parry...\n",
      "http://ufcstats.com/fighter-details/a307a10414d0ad00\n",
      "Scraping Li Jingliang...\n",
      "http://ufcstats.com/fighter-details/e64b96c07d7ce999\n",
      "Scraping Li Yunfeng...\n",
      "http://ufcstats.com/fighter-details/4c7afd56ef1947ac\n",
      "Scraping Liang Na...\n",
      "http://ufcstats.com/fighter-details/ec0dcceace7d25a3\n",
      "Scraping Jess Liaudin...\n",
      "http://ufcstats.com/fighter-details/a8aba6fd8a463043\n",
      "Scraping Chuck Liddell...\n",
      "http://ufcstats.com/fighter-details/a390eb8a9b2df298\n",
      "Scraping Rodrigo Lidio...\n",
      "http://ufcstats.com/fighter-details/11b5a809c3120e27\n",
      "Scraping Sam Liera...\n",
      "http://ufcstats.com/fighter-details/421ccfc6ddb17958\n",
      "Scraping Zach Light...\n",
      "http://ufcstats.com/fighter-details/5d7c18191b8aa432\n",
      "Scraping Scott Lighty...\n",
      "http://ufcstats.com/fighter-details/998c8890a8dde1eb\n",
      "Scraping Chris Liguori...\n",
      "http://ufcstats.com/fighter-details/0e31bfd26cc8c503\n",
      "Scraping Donnie Liles...\n",
      "http://ufcstats.com/fighter-details/a1bf037613180253\n",
      "Scraping Jae Suk Lim...\n",
      "http://ufcstats.com/fighter-details/bbb15f301e4a490a\n",
      "Scraping Hyun Gyu Lim...\n",
      "http://ufcstats.com/fighter-details/203c957eac95dd87\n",
      "Scraping Juliana Lima...\n",
      "http://ufcstats.com/fighter-details/75a6a390fd5dca46\n",
      "Scraping Dhiego Lima...\n",
      "http://ufcstats.com/fighter-details/e9213f53ddeca978\n",
      "Scraping Douglas Lima...\n",
      "http://ufcstats.com/fighter-details/264111bf62662fbf\n",
      "Scraping Mabelly Lima...\n",
      "http://ufcstats.com/fighter-details/6135fd9665fbb74e\n",
      "Scraping Andre Lima...\n",
      "http://ufcstats.com/fighter-details/b1f21ce050035d58\n",
      "Scraping Felipe Lima...\n",
      "http://ufcstats.com/fighter-details/9256f591b30c073e\n",
      "Scraping Miguel Linares...\n",
      "http://ufcstats.com/fighter-details/18c49685296c60e6\n",
      "Scraping Emiliano Linares...\n",
      "http://ufcstats.com/fighter-details/a4ef92274a45143d\n",
      "Scraping Matt Lindland...\n",
      "http://ufcstats.com/fighter-details/0e041d43a47d2e4b\n",
      "Scraping Jake Lindsey...\n",
      "http://ufcstats.com/fighter-details/33e00249ef08d3a4\n",
      "Scraping John Lineker...\n",
      "http://ufcstats.com/fighter-details/c268b2cfebccf652\n",
      "Scraping Austin Lingo...\n",
      "http://ufcstats.com/fighter-details/305d73ede05e31ad\n",
      "Scraping Lucio Linhares...\n",
      "http://ufcstats.com/fighter-details/a780d16cf7eed44d\n",
      "Scraping Philipe Lins...\n",
      "http://ufcstats.com/fighter-details/53c943c873cffe90\n",
      "Scraping Tainara Lisboa...\n",
      "http://ufcstats.com/fighter-details/2c5f5749569eef66\n",
      "Scraping Dean Lister...\n",
      "http://ufcstats.com/fighter-details/68c6cd5287b473a7\n",
      "Scraping Wesley Little...\n",
      "http://ufcstats.com/fighter-details/008c6e1a25751575\n",
      "Scraping James Llontop...\n",
      "http://ufcstats.com/fighter-details/93b2b7caa457cbea\n",
      "Scraping Abner Lloveras...\n",
      "http://ufcstats.com/fighter-details/6448e57a9533b7e4\n",
      "Scraping Brian Lo-A-Njoe...\n",
      "http://ufcstats.com/fighter-details/7abce81b72fbbd9b\n",
      "Scraping John Lober...\n",
      "http://ufcstats.com/fighter-details/31652c9267606d54\n",
      "Scraping Artem Lobov...\n",
      "http://ufcstats.com/fighter-details/02f2a9702ba3d167\n",
      "Scraping Dylan Lockard...\n",
      "http://ufcstats.com/fighter-details/9caa254991a5a698\n",
      "Scraping Ryan Loder...\n",
      "http://ufcstats.com/fighter-details/d5bab53a1a603aac\n",
      "Scraping Sean Loeffler...\n",
      "http://ufcstats.com/fighter-details/d3d1ff3f3dfa0931\n",
      "Scraping Christian Lohsen...\n",
      "http://ufcstats.com/fighter-details/4ab36d70d1b28b58\n",
      "Scraping David Loiseau...\n",
      "http://ufcstats.com/fighter-details/22e47b53e4ceb27c\n",
      "Scraping Hector Lombard...\n",
      "http://ufcstats.com/fighter-details/db1f2ed63b54b9a7\n",
      "Scraping Michael Lombardo...\n",
      "http://ufcstats.com/fighter-details/6d6b9a6cb063b60d\n",
      "Scraping Rocky Long...\n",
      "http://ufcstats.com/fighter-details/10e04e5e81f391a0\n",
      "Scraping Thomas Longacre...\n",
      "http://ufcstats.com/fighter-details/989be26791d0aad4\n",
      "Scraping Loma Lookboonmee...\n",
      "http://ufcstats.com/fighter-details/4e30e4250cb08b61\n",
      "Scraping Ange Loosa...\n",
      "http://ufcstats.com/fighter-details/1497e735d9f2560a\n",
      "Scraping Lucas Lopes...\n",
      "http://ufcstats.com/fighter-details/1f70dd67ad507990\n",
      "Scraping Dileno Lopes...\n",
      "http://ufcstats.com/fighter-details/8270c00fae24c922\n",
      "Scraping Diego Lopes...\n",
      "http://ufcstats.com/fighter-details/f166e93d04a8c274\n",
      "Scraping Bruno Lopes...\n",
      "http://ufcstats.com/fighter-details/0abcf6bc47191219\n",
      "Scraping Arthur Lopes...\n",
      "http://ufcstats.com/fighter-details/2aa481e98185e261\n",
      "Scraping Ivan Lopez...\n",
      "http://ufcstats.com/fighter-details/0db9d2486d564a3c\n",
      "Scraping Steve Lopez...\n",
      "http://ufcstats.com/fighter-details/6085ceb59087514b\n",
      "Scraping Federico Lopez...\n",
      "http://ufcstats.com/fighter-details/9681e0ce67dc978b\n",
      "Scraping Jorge Lopez...\n",
      "http://ufcstats.com/fighter-details/ee624ee2a18f2a43\n",
      "Scraping Christopher Lopez...\n",
      "http://ufcstats.com/fighter-details/5148a665aa527865\n",
      "Scraping Matthew Lopez...\n",
      "http://ufcstats.com/fighter-details/2fc7e9701642ca38\n",
      "Scraping Benito Lopez...\n",
      "http://ufcstats.com/fighter-details/773f7feacf96153e\n",
      "Scraping Gustavo Lopez...\n",
      "http://ufcstats.com/fighter-details/93b62c5f2ba18e51\n",
      "Scraping Brendan Loughnane...\n",
      "http://ufcstats.com/fighter-details/b788862dd1c11eac\n",
      "Scraping Nate Loughran...\n",
      "http://ufcstats.com/fighter-details/cbf94e4c4af4ff6d\n",
      "Scraping Caolan Loughran...\n",
      "http://ufcstats.com/fighter-details/42ac4020cba261ad\n",
      "Scraping Rashard Lovelace...\n",
      "http://ufcstats.com/fighter-details/e601d71cf8e5be22\n",
      "Scraping Ian Loveland...\n",
      "http://ufcstats.com/fighter-details/eea0274e153256a0\n",
      "Scraping Jakob Lovstad...\n",
      "http://ufcstats.com/fighter-details/ad044be25c94dcfd\n",
      "Scraping Waylon Lowe...\n",
      "http://ufcstats.com/fighter-details/28f62d866c59c709\n",
      "Scraping Brandon Lowe...\n",
      "http://ufcstats.com/fighter-details/78ac94d54aa7f378\n",
      "Scraping Joe Lowry...\n",
      "http://ufcstats.com/fighter-details/86248c84834238e7\n",
      "Scraping Lu Kai...\n",
      "http://ufcstats.com/fighter-details/a2d23e684b3db732\n",
      "Scraping Lu Zhengyong...\n",
      "http://ufcstats.com/fighter-details/dc1bfd47c3b21ad3\n",
      "Scraping Robert Lucarelli...\n",
      "http://ufcstats.com/fighter-details/96087e90d900f0ef\n",
      "Scraping Matt Lucas...\n",
      "http://ufcstats.com/fighter-details/668222c99c5c311d\n",
      "Scraping Cleber Luciano...\n",
      "http://ufcstats.com/fighter-details/9bdebbf2735d14c2\n",
      "Scraping Stephanie Luciano...\n",
      "http://ufcstats.com/fighter-details/1b35af4d1529adf6\n",
      "Scraping Iasmin Lucindo...\n",
      "http://ufcstats.com/fighter-details/abcf2cc6efc42031\n",
      "Scraping Duane Ludwig...\n",
      "http://ufcstats.com/fighter-details/84ac950d4c1722dd\n",
      "Scraping Mike Lullo...\n",
      "http://ufcstats.com/fighter-details/e26882820f9e8df5\n",
      "Scraping Paula Luna...\n",
      "http://ufcstats.com/fighter-details/5b1effb0db45273a\n",
      "Scraping Dalcha Lungiambula...\n",
      "http://ufcstats.com/fighter-details/ce632027bf2a871b\n",
      "Scraping Alexandru Lungu...\n",
      "http://ufcstats.com/fighter-details/4887e5bc4dbb73ff\n",
      "Scraping Vicente Luque...\n",
      "http://ufcstats.com/fighter-details/6d4b63c767106d3a\n",
      "Scraping Thaddeus Luster...\n",
      "http://ufcstats.com/fighter-details/505934897b8b4824\n",
      "Scraping Travis Lutter...\n",
      "http://ufcstats.com/fighter-details/622f015c81a9b13a\n",
      "Scraping Joilton Lutterbach...\n",
      "http://ufcstats.com/fighter-details/12630a4aa0894da8\n",
      "Scraping Tucker Lutz...\n",
      "http://ufcstats.com/fighter-details/7832f2f62f04178f\n",
      "Scraping Lv Zhenhong...\n",
      "http://ufcstats.com/fighter-details/5a4913108a3b9190\n",
      "Scraping Stevie Lynch...\n",
      "http://ufcstats.com/fighter-details/710d93f1508f7104\n",
      "Scraping Adam Lynn...\n",
      "http://ufcstats.com/fighter-details/edfe95e3c33a4bf8\n",
      "Scraping Chris Lytle...\n",
      "http://ufcstats.com/fighter-details/91acd6910b802a9e\n",
      "Scraping Dong Hyun Ma...\n",
      "http://ufcstats.com/fighter-details/98a6b2361045898f\n",
      "Scraping Pawan Maan...\n",
      "http://ufcstats.com/fighter-details/450bacdacd706bcd\n",
      "Scraping William Macario...\n",
      "http://ufcstats.com/fighter-details/ed74afc8b5b47a61\n",
      "Scraping Jason MacDonald...\n",
      "http://ufcstats.com/fighter-details/2be6596a9db33bf5\n",
      "Scraping Rob MacDonald...\n",
      "http://ufcstats.com/fighter-details/f3388d2cf7ab3f64\n",
      "Scraping Rory MacDonald...\n",
      "http://ufcstats.com/fighter-details/cbd5d3cdd862e90e\n",
      "Scraping Ryan MacDonald...\n",
      "http://ufcstats.com/fighter-details/35e1f9984ed64206\n",
      "Scraping Clayton MacFarlane...\n",
      "http://ufcstats.com/fighter-details/39831e62d12e7ad1\n",
      "Scraping Ilima Macfarlane...\n",
      "http://ufcstats.com/fighter-details/8cf90e41646491fd\n",
      "Scraping Valesca Machado...\n",
      "http://ufcstats.com/fighter-details/a1a91dbf41a029c4\n",
      "Scraping Caio Machado...\n",
      "http://ufcstats.com/fighter-details/89839250eb25c9c1\n",
      "Scraping Ian Machado Garry...\n",
      "http://ufcstats.com/fighter-details/442c9011034ae1fd\n",
      "Scraping Lyoto Machida...\n",
      "http://ufcstats.com/fighter-details/f7a7f7118d4b01b6\n",
      "Scraping War Machine...\n",
      "http://ufcstats.com/fighter-details/cd7bafbeee1f29a0\n",
      "Scraping Anthony Macias...\n",
      "http://ufcstats.com/fighter-details/dedc3bb440d09554\n",
      "Scraping Pauline Macias...\n",
      "http://ufcstats.com/fighter-details/e88b83dea18f5d31\n",
      "Scraping Reza Madadi...\n",
      "http://ufcstats.com/fighter-details/e25bcbcdaf6537a1\n",
      "Scraping Don Madge...\n",
      "http://ufcstats.com/fighter-details/68c7ad953455c73f\n",
      "Scraping Ryan Madigan...\n",
      "http://ufcstats.com/fighter-details/a8d521d913df4e31\n",
      "Scraping Victor Madrigal...\n",
      "http://ufcstats.com/fighter-details/cc63a5f0089d8ba9\n",
      "Scraping Jon Madsen...\n",
      "http://ufcstats.com/fighter-details/7691a80e6ca3e55b\n",
      "Scraping Mark Madsen...\n",
      "http://ufcstats.com/fighter-details/da0995f19b749cfa\n",
      "Scraping Yoshiro Maeda...\n",
      "http://ufcstats.com/fighter-details/a4bf17bd3ba3423b\n",
      "Scraping Leonardo Mafra...\n",
      "http://ufcstats.com/fighter-details/8bbc0cfc01bc1ba1\n",
      "Scraping Vinny Magalhaes...\n",
      "http://ufcstats.com/fighter-details/88a9bc81271ccd89\n",
      "Scraping Vinicius Magalhaes...\n",
      "http://ufcstats.com/fighter-details/1b583c64c23f0c7f\n",
      "Scraping Caio Magalhaes...\n",
      "http://ufcstats.com/fighter-details/0c5c66ddd1886b83\n",
      "Scraping Bernardo Magalhaes...\n",
      "http://ufcstats.com/fighter-details/7a613f78dd7ee8f8\n",
      "Scraping Eric Magana...\n",
      "http://ufcstats.com/fighter-details/8db1b36dde268ef6\n",
      "Scraping Brandon Magana...\n",
      "http://ufcstats.com/fighter-details/2015c944226ad2df\n",
      "Scraping Angela Magana...\n",
      "http://ufcstats.com/fighter-details/bd878a638e0e3be3\n",
      "Scraping Neil Magny...\n",
      "http://ufcstats.com/fighter-details/84b3e7d38f2d2ec5\n",
      "Scraping Raimond Magomedaliev...\n",
      "http://ufcstats.com/fighter-details/d16373b3568678d4\n",
      "Scraping Ibragim Magomedov...\n",
      "http://ufcstats.com/fighter-details/e7e970d508529bf3\n",
      "Scraping Rashid Magomedov...\n",
      "http://ufcstats.com/fighter-details/7ea1f74cef32f906\n",
      "Scraping Ruslan Magomedov...\n",
      "http://ufcstats.com/fighter-details/369e1ce458ef50a6\n",
      "Scraping Abus Magomedov...\n",
      "http://ufcstats.com/fighter-details/36b8f265bcd1b7a4\n",
      "Scraping Shara Magomedov...\n",
      "http://ufcstats.com/fighter-details/06734ca9d88dec3a\n",
      "Scraping Zabit Magomedsharipov...\n",
      "http://ufcstats.com/fighter-details/87aa9fb63d6b51a1\n",
      "Scraping John Maguire...\n",
      "http://ufcstats.com/fighter-details/1a7745388839e52b\n",
      "Scraping Lolohea Mahe...\n",
      "http://ufcstats.com/fighter-details/fb0b6593cec84356\n",
      "Scraping Michelle Maher...\n",
      "http://ufcstats.com/fighter-details/118463dd8db16e7f\n",
      "Scraping Maheshate...\n",
      "http://ufcstats.com/fighter-details/8c1ca54b5089d199\n",
      "Scraping Bill Mahood...\n",
      "http://ufcstats.com/fighter-details/ae58685caf8e4a0d\n",
      "Scraping Klayton Mai...\n",
      "http://ufcstats.com/fighter-details/7a9c1bb08a743d7f\n",
      "Scraping Demian Maia...\n",
      "http://ufcstats.com/fighter-details/427b5953ac8e3a27\n",
      "Scraping Jennifer Maia...\n",
      "http://ufcstats.com/fighter-details/8e1f36476ef02a6a\n",
      "Scraping Nayara Maia...\n",
      "http://ufcstats.com/fighter-details/03b1b79b34eaf217\n",
      "Scraping Roshan Mainam...\n",
      "http://ufcstats.com/fighter-details/b301292b1bc92bdb\n",
      "Scraping Levan Makashvili...\n",
      "http://ufcstats.com/fighter-details/938ad489fb7a1f31\n",
      "Scraping John Makdessi...\n",
      "http://ufcstats.com/fighter-details/c21a036b4e012f1c\n",
      "Scraping Islam Makhachev...\n",
      "http://ufcstats.com/fighter-details/275aca31f61ba28c\n",
      "Scraping Aliev Makhmud...\n",
      "http://ufcstats.com/fighter-details/3d481aa374c954a1\n",
      "Scraping Zach Makovsky...\n",
      "http://ufcstats.com/fighter-details/57ab4d7c0bc09a30\n",
      "Scraping Azat Maksum...\n",
      "http://ufcstats.com/fighter-details/7f1bf0c255ec8756\n",
      "Scraping Jeremy Malaterre...\n",
      "http://ufcstats.com/fighter-details/110404b505fb562c\n",
      "Scraping Fabio Maldonado...\n",
      "http://ufcstats.com/fighter-details/1fb80f46d3c105d9\n",
      "Scraping Marvin Maldonado...\n",
      "http://ufcstats.com/fighter-details/e5ce754b01f922be\n",
      "Scraping Bea Malecki...\n",
      "http://ufcstats.com/fighter-details/b60c980f79b87ce8\n",
      "Scraping Nazareno Malegarie...\n",
      "http://ufcstats.com/fighter-details/d38e8c6ae2dfc051\n",
      "Scraping Carl Malenko...\n",
      "http://ufcstats.com/fighter-details/a314687f372b2cec\n",
      "Scraping Jacob Malkoun...\n",
      "http://ufcstats.com/fighter-details/d4270315cbcf2569\n",
      "Scraping Mike Malott...\n",
      "http://ufcstats.com/fighter-details/dd6103dd7127db1d\n",
      "Scraping Dan Manasoiu...\n",
      "http://ufcstats.com/fighter-details/eefc73b53d4a05d7\n",
      "Scraping Troy Mandaloniz...\n",
      "http://ufcstats.com/fighter-details/725a834930c2b5bf\n",
      "Scraping Nate Maness...\n",
      "http://ufcstats.com/fighter-details/6e9f40c706f91f32\n",
      "Scraping Michael Mangan...\n",
      "http://ufcstats.com/fighter-details/9297ce6eee046f7a\n",
      "Scraping Gary Mangat...\n",
      "http://ufcstats.com/fighter-details/1c0ffc63d8ec8f45\n",
      "Scraping Melvin Manhoef...\n",
      "http://ufcstats.com/fighter-details/e5767ed355a937c2\n",
      "Scraping Melchor Manibusan...\n",
      "http://ufcstats.com/fighter-details/b6c6d1731ff00eeb\n",
      "Scraping Jon Manley...\n",
      "http://ufcstats.com/fighter-details/a0602dd050bebefc\n",
      "Scraping Steve Mann...\n",
      "http://ufcstats.com/fighter-details/0eef1bf99afd4ff2\n",
      "Scraping Marnic Mann...\n",
      "http://ufcstats.com/fighter-details/b6203e0492a9336c\n",
      "Scraping Dylan Mantello...\n",
      "http://ufcstats.com/fighter-details/e192ebb85b68fa9e\n",
      "Scraping Chris Manuel...\n",
      "http://ufcstats.com/fighter-details/a23e63184c65f5b8\n",
      "Scraping Jimi Manuwa...\n",
      "http://ufcstats.com/fighter-details/1e1dbd1cc5a7469e\n",
      "Scraping Cristiano Marcello...\n",
      "http://ufcstats.com/fighter-details/ff4c3ab594c7fac3\n",
      "Scraping Daniel Marcos...\n",
      "http://ufcstats.com/fighter-details/850266b3dc4e506e\n",
      "Scraping Jose Maria...\n",
      "http://ufcstats.com/fighter-details/b35ba64b6a2bbcb3\n",
      "Scraping Marcos Mariano...\n",
      "http://ufcstats.com/fighter-details/72e5e5a6edfa8223\n",
      "Scraping Enrique Marin...\n",
      "http://ufcstats.com/fighter-details/23a6e307077c6ccc\n",
      "Scraping Chepe Mariscal...\n",
      "http://ufcstats.com/fighter-details/e0c6edcb5b5d0b90\n",
      "Scraping Ronny Markes...\n",
      "http://ufcstats.com/fighter-details/bd21a1e3d41c97ee\n",
      "Scraping Rory Markham...\n",
      "http://ufcstats.com/fighter-details/23a16ebe733e3041\n",
      "Scraping Randa Markos...\n",
      "http://ufcstats.com/fighter-details/4a57ebb14315b251\n",
      "Scraping Christina Marks...\n",
      "http://ufcstats.com/fighter-details/c7be22a47a58365a\n",
      "Scraping Brendon Marotte...\n",
      "http://ufcstats.com/fighter-details/d7fe8c6b7d2872e5\n",
      "Scraping Nate Marquardt...\n",
      "http://ufcstats.com/fighter-details/a8e6a69796280f17\n",
      "Scraping Danilo Marques...\n",
      "http://ufcstats.com/fighter-details/687c15b2eddfaa63\n",
      "Scraping Julian Marquez...\n",
      "http://ufcstats.com/fighter-details/d0e1b42d41dab603\n",
      "Scraping Carmelo Marrero...\n",
      "http://ufcstats.com/fighter-details/aa03a3ca00ac6827\n",
      "Scraping Cesar Marscucci...\n",
      "http://ufcstats.com/fighter-details/e8efeb9cf33b1941\n",
      "Scraping John Marsh...\n",
      "http://ufcstats.com/fighter-details/b6b12014698cc345\n",
      "Scraping CJ Marsh...\n",
      "http://ufcstats.com/fighter-details/4c91eb190d5e0dd9\n",
      "Scraping Eliot Marshall...\n",
      "http://ufcstats.com/fighter-details/a08d909a5be6f410\n",
      "Scraping Doug Marshall...\n",
      "http://ufcstats.com/fighter-details/0c1773639c795466\n",
      "Scraping David Marshall...\n",
      "http://ufcstats.com/fighter-details/0a2813f89a758ff7\n",
      "Scraping Francis Marshall...\n",
      "http://ufcstats.com/fighter-details/5d495dec23d7c68e\n",
      "Scraping Jack Marshman...\n",
      "http://ufcstats.com/fighter-details/045f25b3a4c08e81\n",
      "Scraping Terry Martin...\n",
      "http://ufcstats.com/fighter-details/6a92caba39b64752\n",
      "Scraping Eric Martin...\n",
      "http://ufcstats.com/fighter-details/abbc4fc02e0d84b3\n",
      "Scraping Justin Martin...\n",
      "http://ufcstats.com/fighter-details/3da19339ee7051d5\n",
      "Scraping Dave Martin...\n",
      "http://ufcstats.com/fighter-details/92c96df8bdab5fea\n",
      "Scraping Joe Martin...\n",
      "http://ufcstats.com/fighter-details/325550dab63fb25a\n",
      "Scraping Anthony Rocco Martin...\n",
      "http://ufcstats.com/fighter-details/5331b25a60417ffb\n",
      "Scraping Mallory Martin...\n",
      "http://ufcstats.com/fighter-details/19b7738321cfae42\n",
      "Scraping Michal Martinek...\n",
      "http://ufcstats.com/fighter-details/9acf42aebe9bb895\n",
      "Scraping Rainy Martinez...\n",
      "http://ufcstats.com/fighter-details/577ec7e108b94be3\n",
      "Scraping Danny Martinez...\n",
      "http://ufcstats.com/fighter-details/8a9c6c4301f6d088\n",
      "Scraping Alonzo Martinez...\n",
      "http://ufcstats.com/fighter-details/feffee4fc6da3aa3\n",
      "Scraping Henry Martinez...\n",
      "http://ufcstats.com/fighter-details/76729a829623e266\n",
      "Scraping Jonathan Martinez...\n",
      "http://ufcstats.com/fighter-details/f2477cf43c4975cc\n",
      "Scraping Poppies Martinez...\n",
      "http://ufcstats.com/fighter-details/8851bb0418d27d28\n",
      "Scraping Andrew Martinez...\n",
      "http://ufcstats.com/fighter-details/f8c2aba4815876b5\n",
      "Scraping Mana Martinez...\n",
      "http://ufcstats.com/fighter-details/c0386644627a7ee5\n",
      "Scraping Victor Martinez...\n",
      "http://ufcstats.com/fighter-details/3e708ce33b6b18e6\n",
      "Scraping Roque Martinez...\n",
      "http://ufcstats.com/fighter-details/2c5a0b8317f8f27a\n",
      "Scraping Melissa Martinez...\n",
      "http://ufcstats.com/fighter-details/3f4c3bc822bea45d\n",
      "Scraping Julieta Martinez...\n",
      "http://ufcstats.com/fighter-details/f77afa72da84c9a8\n",
      "Scraping David Martinez...\n",
      "http://ufcstats.com/fighter-details/9a97acbfd5a08bfa\n",
      "Scraping Wagner da Conceicao Martins...\n",
      "http://ufcstats.com/fighter-details/563d051c9e769b24\n",
      "Scraping Adriano Martins...\n",
      "http://ufcstats.com/fighter-details/7dcf06c1967801c1\n",
      "Scraping Lucas Martins...\n",
      "http://ufcstats.com/fighter-details/7413b80dbb0f8f9f\n",
      "Scraping Max Martyniouk...\n",
      "http://ufcstats.com/fighter-details/69d3fa376ff2595e\n",
      "Scraping Bristol Marunde...\n",
      "http://ufcstats.com/fighter-details/a17322f99ddfd8e9\n",
      "Scraping Shoji Maruyama...\n",
      "http://ufcstats.com/fighter-details/c046100aea0dba9a\n",
      "Scraping Kazuma Maruyama...\n",
      "http://ufcstats.com/fighter-details/aa1a873d05acc7eb\n",
      "Scraping Islem Masraf...\n",
      "http://ufcstats.com/fighter-details/6dedfe07640a9acc\n",
      "Scraping Mike Massenzio...\n",
      "http://ufcstats.com/fighter-details/5b2d7906aa894274\n",
      "Scraping Jameel Massouh...\n",
      "http://ufcstats.com/fighter-details/883922e5cd6d8473\n",
      "Scraping Tiffany Masters...\n",
      "http://ufcstats.com/fighter-details/ca743f96dd2063d5\n",
      "Scraping Jorge Masvidal...\n",
      "http://ufcstats.com/fighter-details/47b9e0e7703a4868\n",
      "Scraping Al Matavao...\n",
      "http://ufcstats.com/fighter-details/eec3fe66a8b11a26\n",
      "Scraping Tateki Matsuda...\n",
      "http://ufcstats.com/fighter-details/3a524c6700addc24\n",
      "Scraping Daijiro Matsui...\n",
      "http://ufcstats.com/fighter-details/cd42bbe8887bba90\n",
      "Scraping Toki Matsui...\n",
      "http://ufcstats.com/fighter-details/56cc76c55cee8410\n",
      "Scraping Koichiro Matsumoto...\n",
      "http://ufcstats.com/fighter-details/2fb6f197d1fbc779\n",
      "Scraping Jean Matsumoto...\n",
      "http://ufcstats.com/fighter-details/ffd3224638c01b57\n",
      "Scraping Koyomi Matsushima...\n",
      "http://ufcstats.com/fighter-details/5ad226da6c74a48e\n",
      "Scraping Naoki Matsushita...\n",
      "http://ufcstats.com/fighter-details/990060b2a68a7b82\n",
      "Scraping AJ Matthews...\n",
      "http://ufcstats.com/fighter-details/18e4f61f16f458c6\n",
      "Scraping Jake Matthews...\n",
      "http://ufcstats.com/fighter-details/a845f0735bc67405\n",
      "Scraping Connor Matthews...\n",
      "http://ufcstats.com/fighter-details/36e78278a77006d4\n",
      "Scraping Claudio Mattos...\n",
      "http://ufcstats.com/fighter-details/6e2b1d631832921d\n",
      "Scraping John Matua...\n",
      "http://ufcstats.com/fighter-details/c933d423ebdbbbdb\n",
      "Scraping Francesco Maturi...\n",
      "http://ufcstats.com/fighter-details/d3b5ad3b15a64a18\n",
      "Scraping Vladimir Matyushenko...\n",
      "http://ufcstats.com/fighter-details/ccdd90bd1fc7dab6\n",
      "Scraping Miranda Maverick...\n",
      "http://ufcstats.com/fighter-details/f29a6350c69f4a33\n",
      "Scraping Nick Maximov...\n",
      "http://ufcstats.com/fighter-details/12585614e0ed2626\n",
      "Scraping Elaina Maxwell...\n",
      "http://ufcstats.com/fighter-details/a16ce18149021139\n",
      "Scraping Jeremy May...\n",
      "http://ufcstats.com/fighter-details/c32fdfe75cda5b22\n",
      "Scraping Jack May...\n",
      "http://ufcstats.com/fighter-details/2c6e81426dd7573c\n",
      "Scraping Don'Tale Mayes...\n",
      "http://ufcstats.com/fighter-details/1a9480fc288e55d7\n",
      "Scraping Gray Maynard...\n",
      "http://ufcstats.com/fighter-details/7d96bc577e5178b2\n",
      "Scraping Brooke Mayo...\n",
      "http://ufcstats.com/fighter-details/1b41c21d947d6f2f\n",
      "Scraping Gina Mazany...\n",
      "http://ufcstats.com/fighter-details/016a8d958883167c\n",
      "Scraping Sabina Mazo...\n",
      "http://ufcstats.com/fighter-details/70d2329a92864fdb\n",
      "Scraping Francesco Mazzeo...\n",
      "http://ufcstats.com/fighter-details/7b3c13fe33556a21\n",
      "Scraping Scott McAfee...\n",
      "http://ufcstats.com/fighter-details/7e7d81bf162a5ec1\n",
      "Scraping Bobby McAndrews...\n",
      "http://ufcstats.com/fighter-details/ef6f45095119d416\n",
      "Scraping Michael McBride...\n",
      "http://ufcstats.com/fighter-details/443f60bec7c3c3d5\n",
      "Scraping Ian McCall...\n",
      "http://ufcstats.com/fighter-details/701e057d63c124d9\n",
      "Scraping Molly McCann...\n",
      "http://ufcstats.com/fighter-details/51018a31ddf31eb2\n",
      "Scraping Charles McCarthy...\n",
      "http://ufcstats.com/fighter-details/da97d6c97d09c030\n",
      "Scraping Sean McCorkle...\n",
      "http://ufcstats.com/fighter-details/008dc37cca279def\n",
      "Scraping Danni McCormack...\n",
      "http://ufcstats.com/fighter-details/2a9f9db24cd032ba\n",
      "Scraping Kris McCray...\n",
      "http://ufcstats.com/fighter-details/baed16f18348908e\n",
      "Scraping Tamdan McCrory...\n",
      "http://ufcstats.com/fighter-details/eff47295daf721a6\n",
      "Scraping Rob McCullough...\n",
      "http://ufcstats.com/fighter-details/11e3fd7546359fc5\n",
      "Scraping Justin McCully...\n",
      "http://ufcstats.com/fighter-details/75f871836d41f90f\n",
      "Scraping Robert McDaniel...\n",
      "http://ufcstats.com/fighter-details/5cafbc97dba2e797\n",
      "Scraping Michael McDonald...\n",
      "http://ufcstats.com/fighter-details/d52ef694108f8235\n",
      "Scraping Scott McDonald...\n",
      "http://ufcstats.com/fighter-details/08ae3100bf2100ed\n",
      "Scraping Michael McDonald...\n",
      "http://ufcstats.com/fighter-details/d0314416a7f26527\n",
      "Scraping Josh McDonald...\n",
      "http://ufcstats.com/fighter-details/b507a76087e3ed9f\n",
      "Scraping Miles McDonald...\n",
      "http://ufcstats.com/fighter-details/a3f8356ace5e3eb5\n",
      "Scraping Justin McElfresh...\n",
      "http://ufcstats.com/fighter-details/49c29e57d4e2be6f\n",
      "Scraping Drew McFedries...\n",
      "http://ufcstats.com/fighter-details/1fd4fbdcc67de844\n",
      "Scraping Liam McGeary...\n",
      "http://ufcstats.com/fighter-details/e4e0993befecdaf8\n",
      "Scraping Gan McGee...\n",
      "http://ufcstats.com/fighter-details/d90b630e0561818b\n",
      "Scraping Court McGee...\n",
      "http://ufcstats.com/fighter-details/523fa774700d7d3f\n",
      "Scraping Marcus McGhee...\n",
      "http://ufcstats.com/fighter-details/c0ac37a4a1133da9\n",
      "Scraping Ryan McGillivray...\n",
      "http://ufcstats.com/fighter-details/1f9c371c93dfd3a9\n",
      "Scraping Ryan McGivern...\n",
      "http://ufcstats.com/fighter-details/856ec65948b7d234\n",
      "Scraping Jack McGlaughlin...\n",
      "http://ufcstats.com/fighter-details/237187ed9f419285\n",
      "Scraping Conor McGregor...\n",
      "http://ufcstats.com/fighter-details/f4c49976c75c5ab2\n",
      "Scraping Greg McIntyre...\n",
      "http://ufcstats.com/fighter-details/00a905a4a4a2b071\n",
      "Scraping Antonio McKee...\n",
      "http://ufcstats.com/fighter-details/3414b50b08a10600\n",
      "Scraping AJ McKee...\n",
      "http://ufcstats.com/fighter-details/f3ec0214794a699e\n",
      "Scraping Rhys McKee...\n",
      "http://ufcstats.com/fighter-details/f748267c4ab6c127\n",
      "Scraping Cory McKenna...\n",
      "http://ufcstats.com/fighter-details/3351aa64aa83c4d9\n",
      "Scraping Tim McKenzie...\n",
      "http://ufcstats.com/fighter-details/9ca265dfe8323db3\n",
      "Scraping Cody McKenzie...\n",
      "http://ufcstats.com/fighter-details/7be63795363029e8\n",
      "Scraping Terrance McKinney...\n",
      "http://ufcstats.com/fighter-details/809bd1a871491508\n",
      "Scraping Brian McLaughlin...\n",
      "http://ufcstats.com/fighter-details/6488729da7ac1c79\n",
      "Scraping Jason McLean...\n",
      "http://ufcstats.com/fighter-details/8336d7a85ce45481\n",
      "Scraping Garreth McLellan...\n",
      "http://ufcstats.com/fighter-details/f215cfbd4ba3c270\n",
      "Scraping Sara McMann...\n",
      "http://ufcstats.com/fighter-details/7be74a12d7352df2\n",
      "Scraping Tommy McMillen...\n",
      "http://ufcstats.com/fighter-details/6b0a6def604de298\n",
      "Scraping James McSweeney...\n",
      "http://ufcstats.com/fighter-details/cac08b8685387ca5\n",
      "Scraping Charles McTorry...\n",
      "http://ufcstats.com/fighter-details/acd8a53f7c0ce85e\n",
      "Scraping Daniel McWilliams...\n",
      "http://ufcstats.com/fighter-details/7b03d9df5910917d\n",
      "Scraping Tim Means...\n",
      "http://ufcstats.com/fighter-details/4b47e71384a9522f\n",
      "Scraping Yancy Medeiros...\n",
      "http://ufcstats.com/fighter-details/813550bc53b15fb0\n",
      "Scraping Anistavio Medeiros...\n",
      "http://ufcstats.com/fighter-details/2937cb502dda0808\n",
      "Scraping Kaline Medeiros...\n",
      "http://ufcstats.com/fighter-details/263af068bd986548\n",
      "Scraping MarQuel Mederos...\n",
      "http://ufcstats.com/fighter-details/e2be0c1a9b886d92\n",
      "Scraping Uros Medic...\n",
      "http://ufcstats.com/fighter-details/681399317dbf4701\n",
      "Scraping Todd Medina...\n",
      "http://ufcstats.com/fighter-details/b60391da771deefe\n",
      "Scraping Jason Medina...\n",
      "http://ufcstats.com/fighter-details/f53fb9d9e57cc38e\n",
      "Scraping Jose Daniel Medina...\n",
      "http://ufcstats.com/fighter-details/baa9be02c3e3e038\n",
      "Scraping Emil Meek...\n",
      "http://ufcstats.com/fighter-details/103b06d8707895a9\n",
      "Scraping Sanford Alton Meeks...\n",
      "http://ufcstats.com/fighter-details/27c59ac201539d10\n",
      "Scraping Gerald Meerschaert...\n",
      "http://ufcstats.com/fighter-details/6ac9bc2953c47345\n",
      "Scraping Frank Megallon...\n",
      "http://ufcstats.com/fighter-details/c0a93b52096b7682\n",
      "Scraping Derrick Mehmen...\n",
      "http://ufcstats.com/fighter-details/6c7dafd03b6cc3f8\n",
      "Scraping Miika Mehmet...\n",
      "http://ufcstats.com/fighter-details/41dca66f9dadfc86\n",
      "Scraping Jordan Mein...\n",
      "http://ufcstats.com/fighter-details/2aa49b3766a59bcd\n",
      "Scraping Bryce Mejia...\n",
      "http://ufcstats.com/fighter-details/6eae26c44e505775\n",
      "Scraping Brian Melancon...\n",
      "http://ufcstats.com/fighter-details/eee7dafac7d672b5\n",
      "Scraping Brandon Melendez...\n",
      "http://ufcstats.com/fighter-details/2b06b6ad5db63348\n",
      "Scraping Gilbert Melendez...\n",
      "http://ufcstats.com/fighter-details/aa5b4eff51bdc7d1\n",
      "Scraping Nair Melikyan...\n",
      "http://ufcstats.com/fighter-details/64b8561624d3b15e\n",
      "Scraping Marcelo Mello...\n",
      "http://ufcstats.com/fighter-details/672ef06fd9f41f7d\n",
      "Scraping Fabio Mello...\n",
      "http://ufcstats.com/fighter-details/8a028648f3f0761d\n",
      "Scraping Vanessa Melo...\n",
      "http://ufcstats.com/fighter-details/9b7dfb3b7d99926a\n",
      "Scraping Antonio Mendes...\n",
      "http://ufcstats.com/fighter-details/3795fca327cbcf23\n",
      "Scraping Chad Mendes...\n",
      "http://ufcstats.com/fighter-details/b5b684eac99ae0a3\n",
      "Scraping Augusto Mendes...\n",
      "http://ufcstats.com/fighter-details/3d5b1ce6097dbb49\n",
      "Scraping Eddie Mendez...\n",
      "http://ufcstats.com/fighter-details/49e49b54e5901d0d\n",
      "Scraping Mateus Mendonca...\n",
      "http://ufcstats.com/fighter-details/48812daf291a4e23\n",
      "Scraping Luis Mendoza...\n",
      "http://ufcstats.com/fighter-details/28200bc87367614f\n",
      "Scraping Pietro Menga...\n",
      "http://ufcstats.com/fighter-details/869d68b5383131fd\n",
      "Scraping Alonzo Menifield...\n",
      "http://ufcstats.com/fighter-details/a495f599e787614f\n",
      "Scraping Ivan Menjivar...\n",
      "http://ufcstats.com/fighter-details/5755960ebd0b16f6\n",
      "Scraping Dave Menne...\n",
      "http://ufcstats.com/fighter-details/275cafc9de131c83\n",
      "Scraping Steve Mensing...\n",
      "http://ufcstats.com/fighter-details/3bc27ec15facbcf3\n",
      "Scraping Buck Meredith...\n",
      "http://ufcstats.com/fighter-details/36120738148f203f\n",
      "Scraping Adam Meredith...\n",
      "http://ufcstats.com/fighter-details/c1135a6892e916db\n",
      "Scraping Nick Meregali...\n",
      "http://ufcstats.com/fighter-details/2f6dc878d653c442\n",
      "Scraping Joe Merritt...\n",
      "http://ufcstats.com/fighter-details/e82d5f54daa85a7e\n",
      "Scraping Jeremiah Metcalf...\n",
      "http://ufcstats.com/fighter-details/5bdcbd8dd681a257\n",
      "Scraping Jonathan Meunier...\n",
      "http://ufcstats.com/fighter-details/5823ceab56741617\n",
      "Scraping Yaotzin Meza...\n",
      "http://ufcstats.com/fighter-details/3623bd267a2eef2e\n",
      "Scraping Guy Mezger...\n",
      "http://ufcstats.com/fighter-details/946f341df6472ee0\n",
      "Scraping Jonathan Micallef...\n",
      "http://ufcstats.com/fighter-details/f782f953bfe7b5f2\n",
      "Scraping Brandon Michaels...\n",
      "http://ufcstats.com/fighter-details/f5e4ce11afbdfb61\n",
      "Scraping Andreas Michailidis...\n",
      "http://ufcstats.com/fighter-details/79325a3c1a5c3bf4\n",
      "Scraping David Michaud...\n",
      "http://ufcstats.com/fighter-details/49f4b511932f71e9\n",
      "Scraping Chris Mickle...\n",
      "http://ufcstats.com/fighter-details/f903967fd320da38\n",
      "Scraping Zachary Micklewright...\n",
      "http://ufcstats.com/fighter-details/a36a14985a57a1c6\n",
      "Scraping Kristof Midoux...\n",
      "http://ufcstats.com/fighter-details/5b5b9c6f6f270369\n",
      "Scraping Keith Mielke...\n",
      "http://ufcstats.com/fighter-details/f62850b3c7480db9\n",
      "Scraping Chris Mierzwiak...\n",
      "http://ufcstats.com/fighter-details/2b284840ca89876a\n",
      "Scraping Gabriel Miglioli...\n",
      "http://ufcstats.com/fighter-details/a6fa5dd90528e9f7\n",
      "Scraping Bojan Mihajlovic...\n",
      "http://ufcstats.com/fighter-details/d6285cba1d1052e0\n",
      "Scraping Billy Miles...\n",
      "http://ufcstats.com/fighter-details/3c48019bc387b80c\n",
      "Scraping Pat Miletich...\n",
      "http://ufcstats.com/fighter-details/cedfdf8d423d500c\n",
      "Scraping Curtis Millender...\n",
      "http://ufcstats.com/fighter-details/f1928a52590c5532\n",
      "Scraping Phillip Miller...\n",
      "http://ufcstats.com/fighter-details/18aecaf50f52e4c3\n",
      "Scraping Jason Miller...\n",
      "http://ufcstats.com/fighter-details/b2f88c04c4dd43ce\n",
      "Scraping Dan Miller...\n",
      "http://ufcstats.com/fighter-details/d0c29452d3272603\n",
      "Scraping Jim Miller...\n",
      "http://ufcstats.com/fighter-details/d1941565abf50b16\n",
      "Scraping Cole Miller...\n",
      "http://ufcstats.com/fighter-details/282fa667ff9c51ed\n",
      "Scraping Henry Miller...\n",
      "http://ufcstats.com/fighter-details/45a2ba3ef82b9700\n",
      "Scraping Micah Miller...\n",
      "http://ufcstats.com/fighter-details/3ff0d0dc7a14bb50\n",
      "Scraping Aaron Miller...\n",
      "http://ufcstats.com/fighter-details/a4d055f1435d6d75\n",
      "Scraping Mo Miller...\n",
      "http://ufcstats.com/fighter-details/39019970ac8543e9\n",
      "Scraping Juliana Miller...\n",
      "http://ufcstats.com/fighter-details/aa0c573da7119292\n",
      "Scraping Eddy Millis...\n",
      "http://ufcstats.com/fighter-details/f2c934689243fe4e\n",
      "Scraping Che Mills...\n",
      "http://ufcstats.com/fighter-details/6cadfd8f1d9e7685\n",
      "Scraping Adam Milstead...\n",
      "http://ufcstats.com/fighter-details/72ffecf712673af1\n",
      "Scraping Alberto Mina...\n",
      "http://ufcstats.com/fighter-details/4b1d46a1b5c0fd11\n",
      "Scraping Vitaly Minakov...\n",
      "http://ufcstats.com/fighter-details/56c975c4a2b357a5\n",
      "Scraping Darrick Minner...\n",
      "http://ufcstats.com/fighter-details/34e516ab361afb1c\n",
      "Scraping Mike Minniger...\n",
      "http://ufcstats.com/fighter-details/c8aa3541bec4042e\n",
      "Scraping Ikuhisa Minowa...\n",
      "http://ufcstats.com/fighter-details/ce6065baef021cf3\n",
      "Scraping Carlton Minus...\n",
      "http://ufcstats.com/fighter-details/40d8b74488743800\n",
      "Scraping Stipe Miocic...\n",
      "http://ufcstats.com/fighter-details/d28dee5c705991df\n",
      "Scraping Frank Mir...\n",
      "http://ufcstats.com/fighter-details/1ff9589f9065a9ed\n",
      "Scraping Juan Miranda...\n",
      "http://ufcstats.com/fighter-details/be8ad887e4d674b0\n",
      "Scraping Mario Miranda...\n",
      "http://ufcstats.com/fighter-details/df2bf09c99594848\n",
      "Scraping Vitor Miranda...\n",
      "http://ufcstats.com/fighter-details/4bcb6eb12b4ad4aa\n",
      "Scraping Gabriel Miranda...\n",
      "http://ufcstats.com/fighter-details/b909a9a9688b5284\n",
      "Scraping Damir Mirenic...\n",
      "http://ufcstats.com/fighter-details/992c82450d96f726\n",
      "Scraping Kazuo Misaki...\n",
      "http://ufcstats.com/fighter-details/5e7a28f20927d64a\n",
      "Scraping Toby Misech...\n",
      "http://ufcstats.com/fighter-details/3f87218a7aca84c4\n",
      "Scraping Dokonjonosuke Mishima...\n",
      "http://ufcstats.com/fighter-details/b14a68c533f4a4aa\n",
      "Scraping Felix Lee Mitchell...\n",
      "http://ufcstats.com/fighter-details/6cbb7661c3258617\n",
      "Scraping David Mitchell...\n",
      "http://ufcstats.com/fighter-details/8f3df4c579cfbb69\n",
      "Scraping Danny Mitchell...\n",
      "http://ufcstats.com/fighter-details/c06d554ce1713fd3\n",
      "Scraping Brad Mitchell...\n",
      "http://ufcstats.com/fighter-details/7263e0dc082adc87\n",
      "Scraping Clay Mitchell...\n",
      "http://ufcstats.com/fighter-details/3d960455f880bb25\n",
      "Scraping Bryce Mitchell...\n",
      "http://ufcstats.com/fighter-details/d9c6f19f958643e9\n",
      "Scraping Maurice Mitchell...\n",
      "http://ufcstats.com/fighter-details/568bebed6366b667\n",
      "Scraping Terrence Mitchell...\n",
      "http://ufcstats.com/fighter-details/f3ca6908f78efebe\n",
      "Scraping Roman Mitichyan...\n",
      "http://ufcstats.com/fighter-details/2961be02cfb0d2c1\n",
      "Scraping Matt Mitrione...\n",
      "http://ufcstats.com/fighter-details/ba280572acfba13f\n",
      "Scraping Eiji Mitsuoka...\n",
      "http://ufcstats.com/fighter-details/2b4faacc16d66898\n",
      "Scraping Hiromitsu Miura...\n",
      "http://ufcstats.com/fighter-details/509697e08673d2e5\n",
      "Scraping Jonathan  Mix...\n",
      "http://ufcstats.com/fighter-details/f64e4ecd214c6378\n",
      "Scraping Tomoya Miyashita...\n",
      "http://ufcstats.com/fighter-details/c9885b1b7c7055a0\n",
      "Scraping Kazuyuki Miyata...\n",
      "http://ufcstats.com/fighter-details/af70d268e5352186\n",
      "Scraping Motoki Miyazawa...\n",
      "http://ufcstats.com/fighter-details/9649d75defe0dedb\n",
      "Scraping Takeya Mizugaki...\n",
      "http://ufcstats.com/fighter-details/48e093ea1f43a053\n",
      "Scraping Mizuki...\n",
      "http://ufcstats.com/fighter-details/43a59ce3bb40449e\n",
      "Scraping Tatsuya Mizuno...\n",
      "http://ufcstats.com/fighter-details/478c8706bdb92440\n",
      "Scraping Roxanne Modafferi...\n",
      "http://ufcstats.com/fighter-details/4498b382c65a7faa\n",
      "Scraping Bobby Moffett...\n",
      "http://ufcstats.com/fighter-details/d76ad9a08c4408ff\n",
      "Scraping Bronson Mohika...\n",
      "http://ufcstats.com/fighter-details/65239fccecd03404\n",
      "Scraping Nate Mohr...\n",
      "http://ufcstats.com/fighter-details/04c15b52c3cc1cab\n",
      "Scraping Renato Moicano...\n",
      "http://ufcstats.com/fighter-details/b6452706b373eea1\n",
      "Scraping Thiago Moises...\n",
      "http://ufcstats.com/fighter-details/d945aae53e3e54e6\n",
      "Scraping Muhammad Mokaev...\n",
      "http://ufcstats.com/fighter-details/75353550928a7921\n",
      "Scraping Ashkan Mokhtarian...\n",
      "http://ufcstats.com/fighter-details/e9bc5748e6a76bb6\n",
      "Scraping Suman Mokhtarian...\n",
      "http://ufcstats.com/fighter-details/192520689012c7e4\n",
      "Scraping Dan Molina...\n",
      "http://ufcstats.com/fighter-details/606136dee6f6ecea\n",
      "Scraping Jeff Molina...\n",
      "http://ufcstats.com/fighter-details/008ea710276c9606\n",
      "Scraping Rudyard Moncayo...\n",
      "http://ufcstats.com/fighter-details/02d276b7d62b3472\n",
      "Scraping Hidetaka Monma...\n",
      "http://ufcstats.com/fighter-details/a8e133139286df84\n",
      "Scraping Jeff Monson...\n",
      "http://ufcstats.com/fighter-details/cbfd1d34356a004c\n",
      "Scraping Darrell Montague...\n",
      "http://ufcstats.com/fighter-details/bffeb123b21c9aad\n",
      "Scraping Andrew Montanez...\n",
      "http://ufcstats.com/fighter-details/72c9c2eadfc3277e\n",
      "Scraping Augusto Montano...\n",
      "http://ufcstats.com/fighter-details/94508d80e1f885fc\n",
      "Scraping Erick Montano...\n",
      "http://ufcstats.com/fighter-details/8163cd7de0342652\n",
      "Scraping Nicco Montano...\n",
      "http://ufcstats.com/fighter-details/1de9ad94de18eeaf\n",
      "Scraping Antonio Monteiro...\n",
      "http://ufcstats.com/fighter-details/3e38b1ea16bd4d86\n",
      "Scraping Alberto Montes...\n",
      "http://ufcstats.com/fighter-details/a112097ad877a48f\n",
      "Scraping Steve Montgomery...\n",
      "http://ufcstats.com/fighter-details/6e92eb1242b46636\n",
      "Scraping James Moontasri...\n",
      "http://ufcstats.com/fighter-details/c06a9b48d4132c8e\n",
      "Scraping Homer Moore...\n",
      "http://ufcstats.com/fighter-details/e56df3c1d8b4b1cc\n",
      "Scraping Todd Moore...\n",
      "http://ufcstats.com/fighter-details/e31502e3f79d00c5\n",
      "Scraping Nate Moore...\n",
      "http://ufcstats.com/fighter-details/518e5202a91980d4\n",
      "Scraping Dustin Moore...\n",
      "http://ufcstats.com/fighter-details/831de97afe326478\n",
      "Scraping Taylor Moore...\n",
      "http://ufcstats.com/fighter-details/26927dab41dbd5fc\n",
      "Scraping Sergio Moraes...\n",
      "http://ufcstats.com/fighter-details/1bcaac2d99b90fce\n",
      "Scraping Marlon Moraes...\n",
      "http://ufcstats.com/fighter-details/fea79f9bc8c68769\n",
      "Scraping Sheymon Moraes...\n",
      "http://ufcstats.com/fighter-details/0d62719b1dcf7c40\n",
      "Scraping John Moraga...\n",
      "http://ufcstats.com/fighter-details/92437c6775b3f7d1\n",
      "Scraping Ricardo Morais...\n",
      "http://ufcstats.com/fighter-details/2dc7f1762dc0a7ef\n",
      "Scraping Leonardo Morales...\n",
      "http://ufcstats.com/fighter-details/45230be0641f3f53\n",
      "Scraping Albert Morales...\n",
      "http://ufcstats.com/fighter-details/544d7460b3e44393\n",
      "Scraping Joseph Morales...\n",
      "http://ufcstats.com/fighter-details/2fe9032955c2e013\n",
      "Scraping Vince Morales...\n",
      "http://ufcstats.com/fighter-details/37098a6e6c27fb66\n",
      "Scraping Omar Morales...\n",
      "http://ufcstats.com/fighter-details/a0e6753c42698f13\n",
      "Scraping Michael Morales...\n",
      "http://ufcstats.com/fighter-details/c32aeb1a59e6272d\n",
      "Scraping Sarah Moras...\n",
      "http://ufcstats.com/fighter-details/539ed332b3078821\n",
      "Scraping Christian Morecraft...\n",
      "http://ufcstats.com/fighter-details/80779d7441af1b52\n",
      "Scraping Joe Moreira...\n",
      "http://ufcstats.com/fighter-details/df85d6ec3493d120\n",
      "Scraping Richardson Moreira...\n",
      "http://ufcstats.com/fighter-details/9147679e1a4ad4a3\n",
      "Scraping Gisele Moreira...\n",
      "http://ufcstats.com/fighter-details/6a125ba3ec37e27e\n",
      "Scraping Vinicius Moreira...\n",
      "http://ufcstats.com/fighter-details/acb36c908d415c4a\n",
      "Scraping Jesse Moreng...\n",
      "http://ufcstats.com/fighter-details/2e2cdb6e9eb84bb9\n",
      "Scraping Brandon Moreno...\n",
      "http://ufcstats.com/fighter-details/792be9a24df82ed6\n",
      "Scraping Mike Moreno...\n",
      "http://ufcstats.com/fighter-details/bb2eee4fb3259c01\n",
      "Scraping Dan Moret...\n",
      "http://ufcstats.com/fighter-details/66e98b3bb5fc5250\n",
      "Scraping Sammy Morgan...\n",
      "http://ufcstats.com/fighter-details/2067a177a2842fbf\n",
      "Scraping Peggy Morgan...\n",
      "http://ufcstats.com/fighter-details/92b36014314b028b\n",
      "Scraping Alexander Morgan...\n",
      "http://ufcstats.com/fighter-details/938ea36fe9c269f0\n",
      "Scraping Alex Morono...\n",
      "http://ufcstats.com/fighter-details/cdb96af67d096b1e\n",
      "Scraping Maryna Moroz...\n",
      "http://ufcstats.com/fighter-details/b4192a975027aab6\n",
      "Scraping Sergey Morozov...\n",
      "http://ufcstats.com/fighter-details/2f6a993c7f547c13\n",
      "Scraping Brad Morris...\n",
      "http://ufcstats.com/fighter-details/6803d4d6908354ac\n",
      "Scraping Scott Morris...\n",
      "http://ufcstats.com/fighter-details/be9d259be012e8a4\n",
      "Scraping Anthony Morrison...\n",
      "http://ufcstats.com/fighter-details/dab0e6cb8c932162\n",
      "Scraping Jack Morrison...\n",
      "http://ufcstats.com/fighter-details/38fccd44d669bb2f\n",
      "Scraping Harry Moskowitz...\n",
      "http://ufcstats.com/fighter-details/4dc496aa0cfc0d95\n",
      "Scraping Carlos Mota...\n",
      "http://ufcstats.com/fighter-details/b15862fcd6ded451\n",
      "Scraping Miki Motono...\n",
      "http://ufcstats.com/fighter-details/a5fa51a81d0c5ed9\n",
      "Scraping Juan Mott...\n",
      "http://ufcstats.com/fighter-details/5da4e8dc02e50ac0\n",
      "Scraping Nikolas Motta...\n",
      "http://ufcstats.com/fighter-details/37f560436d745c18\n",
      "Scraping Flavio Luiz Moura...\n",
      "http://ufcstats.com/fighter-details/ab35634d1a8c7a11\n",
      "Scraping Eduarda Moura...\n",
      "http://ufcstats.com/fighter-details/de594b35c45c2e9a\n",
      "Scraping Gegard Mousasi...\n",
      "http://ufcstats.com/fighter-details/232c582f29f8f65e\n",
      "Scraping Kris Moutinho...\n",
      "http://ufcstats.com/fighter-details/9c27f3217891f3f0\n",
      "Scraping Kin Moy...\n",
      "http://ufcstats.com/fighter-details/ae922e7d9e852d7a\n",
      "Scraping Jamie Moyle...\n",
      "http://ufcstats.com/fighter-details/882d62561063a927\n",
      "Scraping Askar Mozharov...\n",
      "http://ufcstats.com/fighter-details/e92901944ce91909\n",
      "Scraping Garrett Mueller...\n",
      "http://ufcstats.com/fighter-details/d0c325dfefdde31f\n",
      "Scraping Lauren Mueller...\n",
      "http://ufcstats.com/fighter-details/f923e012414c883e\n",
      "Scraping Belal Muhammad...\n",
      "http://ufcstats.com/fighter-details/b1b0729d27936f2f\n",
      "Scraping Fazlo Mulabitinovic...\n",
      "http://ufcstats.com/fighter-details/2252b2c892397f0d\n",
      "Scraping Quinn Mulhern...\n",
      "http://ufcstats.com/fighter-details/16af2d5a6f28bee2\n",
      "Scraping James Mulheron...\n",
      "http://ufcstats.com/fighter-details/8d5350fa18b79e9a\n",
      "Scraping Jamie Mullarkey...\n",
      "http://ufcstats.com/fighter-details/af9f42e6894047fc\n",
      "Scraping Jim Mullen...\n",
      "http://ufcstats.com/fighter-details/1a49e0670dfaca31\n",
      "Scraping Melissa Mullins...\n",
      "http://ufcstats.com/fighter-details/bd532e9a2b93870c\n",
      "Scraping Pedro Munhoz...\n",
      "http://ufcstats.com/fighter-details/6bd02119599741a4\n",
      "Scraping Andre Muniz...\n",
      "http://ufcstats.com/fighter-details/886264a0c9f4ea5e\n",
      "Scraping Mark Munoz...\n",
      "http://ufcstats.com/fighter-details/179f1948dc234f1f\n",
      "Scraping Alexander Munoz...\n",
      "http://ufcstats.com/fighter-details/f8f1ec513bcfef43\n",
      "Scraping Johnny Munoz...\n",
      "http://ufcstats.com/fighter-details/f6bcbd91b114ff58\n",
      "Scraping Andy Murad...\n",
      "http://ufcstats.com/fighter-details/fd0b4e3eb18eafb7\n",
      "Scraping Olivier Murad...\n",
      "http://ufcstats.com/fighter-details/c3dd69333eb8085a\n",
      "Scraping Makhmud Muradov...\n",
      "http://ufcstats.com/fighter-details/ea7e5bc78d9de658\n",
      "Scraping Kazunari Murakami...\n",
      "http://ufcstats.com/fighter-details/cfbccfed4e4796fe\n",
      "Scraping Ryuichi Murata...\n",
      "http://ufcstats.com/fighter-details/e3a6c6d6d0ac0815\n",
      "Scraping Kanako Murata...\n",
      "http://ufcstats.com/fighter-details/e0b0cf71e0d69dd0\n",
      "Scraping Ailiya Muratbek...\n",
      "http://ufcstats.com/fighter-details/9b6dcc335ad03696\n",
      "Scraping Vince Murdock...\n",
      "http://ufcstats.com/fighter-details/4b90384d7c3519b8\n",
      "Scraping Samandar Murodov...\n",
      "http://ufcstats.com/fighter-details/6f4d199c0adc06f5\n",
      "Scraping Tom Murphy...\n",
      "http://ufcstats.com/fighter-details/62918a2118de08b2\n",
      "Scraping Ian Murphy...\n",
      "http://ufcstats.com/fighter-details/de25520d54eab12d\n",
      "Scraping Jon Murphy...\n",
      "http://ufcstats.com/fighter-details/1b5c146ee7b86e34\n",
      "Scraping Lauren Murphy...\n",
      "http://ufcstats.com/fighter-details/729d4bd5a6cd0a97\n",
      "Scraping Patrick Murphy...\n",
      "http://ufcstats.com/fighter-details/eca7e064746c161a\n",
      "Scraping Lerone Murphy...\n",
      "http://ufcstats.com/fighter-details/396fe87b84ac2e1c\n",
      "Scraping Lee Murray...\n",
      "http://ufcstats.com/fighter-details/32016899d0a222a3\n",
      "Scraping Jesse Murray...\n",
      "http://ufcstats.com/fighter-details/d0147e906106cd2e\n",
      "Scraping Khalid Murtazaliev...\n",
      "http://ufcstats.com/fighter-details/231cae8b77fbbcc1\n",
      "Scraping Azamat Murzakanov...\n",
      "http://ufcstats.com/fighter-details/e90a2f22417af68e\n",
      "Scraping Josias Musasa...\n",
      "http://ufcstats.com/fighter-details/723b64c0e9a8f348\n",
      "Scraping Nicholas Musoke...\n",
      "http://ufcstats.com/fighter-details/8b5f9ea38184ded3\n",
      "Scraping Andre Mussi...\n",
      "http://ufcstats.com/fighter-details/d0d43cb9b14f231c\n",
      "Scraping Magomed Mustafaev...\n",
      "http://ufcstats.com/fighter-details/31d7446b184e3305\n",
      "Scraping Max Mustaki...\n",
      "http://ufcstats.com/fighter-details/f4c40f8a64d3151d\n",
      "Scraping Elvis Mutapcic...\n",
      "http://ufcstats.com/fighter-details/28c55b4087a6f136\n",
      "Scraping Fiona Muxlow...\n",
      "http://ufcstats.com/fighter-details/062e57ca1a3c95a8\n",
      "Scraping Ho Bae Myeon...\n",
      "http://ufcstats.com/fighter-details/2719f300b0439039\n",
      "Scraping Katsuhiko Nagata...\n",
      "http://ufcstats.com/fighter-details/d5ae8074631762fc\n",
      "Scraping Yuji Nagata...\n",
      "http://ufcstats.com/fighter-details/e49c2db95e572dc8\n",
      "Scraping Greg Nagy...\n",
      "http://ufcstats.com/fighter-details/342422bb6ced1e8d\n",
      "Scraping Logan Nail...\n",
      "http://ufcstats.com/fighter-details/47e0b5833e6bc91a\n",
      "Scraping Muhammad Naimov...\n",
      "http://ufcstats.com/fighter-details/8d11d9c13e2ccdf7\n",
      "Scraping Yukiya Naito...\n",
      "http://ufcstats.com/fighter-details/7be328bb3c2ea22e\n",
      "Scraping Yura Naito...\n",
      "http://ufcstats.com/fighter-details/50c469e0cb73be10\n",
      "Scraping Andrews Nakahara...\n",
      "http://ufcstats.com/fighter-details/7a9ca95a92d7b64c\n",
      "Scraping Rin Nakai...\n",
      "http://ufcstats.com/fighter-details/f9ae6914f604aa9f\n",
      "Scraping Kazuhiro Nakamura...\n",
      "http://ufcstats.com/fighter-details/b034747dc1d15491\n",
      "Scraping Keita Nakamura...\n",
      "http://ufcstats.com/fighter-details/65ddc8a9ac4e8531\n",
      "Scraping Daisuke Nakamura...\n",
      "http://ufcstats.com/fighter-details/a196332ee4aa8a82\n",
      "Scraping Yusaku Nakamura...\n",
      "http://ufcstats.com/fighter-details/03e8df49c4a059ba\n",
      "Scraping Rinya Nakamura...\n",
      "http://ufcstats.com/fighter-details/d8c811df0386d5e8\n",
      "Scraping Tokitaka Nakanishi...\n",
      "http://ufcstats.com/fighter-details/eb9446a4f44e19cf\n",
      "Scraping Jutaro Nakao...\n",
      "http://ufcstats.com/fighter-details/95eb112a85601a0a\n",
      "Scraping Yoshihiro Nakao...\n",
      "http://ufcstats.com/fighter-details/e18012194473e8b0\n",
      "Scraping Yui Chul Nam...\n",
      "http://ufcstats.com/fighter-details/a00ec21cfbba17b6\n",
      "Scraping Tyson Nam...\n",
      "http://ufcstats.com/fighter-details/6e00cfffd54653c4\n",
      "Scraping Rose Namajunas...\n",
      "http://ufcstats.com/fighter-details/47b63240018d5d86\n",
      "Scraping Yasuhito Namekawa...\n",
      "http://ufcstats.com/fighter-details/6083f497c22cc075\n",
      "Scraping Nad Narimani...\n",
      "http://ufcstats.com/fighter-details/776a58a67665a171\n",
      "Scraping Roger Narvaez...\n",
      "http://ufcstats.com/fighter-details/3a12a2f096a6d975\n",
      "Scraping Fabio Nascimento...\n",
      "http://ufcstats.com/fighter-details/307064d3e0f036c2\n",
      "Scraping Allan Nascimento...\n",
      "http://ufcstats.com/fighter-details/253076a23d03dcd0\n",
      "Scraping Rodrigo Nascimento...\n",
      "http://ufcstats.com/fighter-details/d31a5546c0e9b213\n",
      "Scraping Bobby Nash...\n",
      "http://ufcstats.com/fighter-details/7dfb56f24fe5ddea\n",
      "Scraping Reza Nasri...\n",
      "http://ufcstats.com/fighter-details/d41937647eae9a34\n",
      "Scraping Nasrudin Nasrudinov...\n",
      "http://ufcstats.com/fighter-details/769fa803bf9d2e3b\n",
      "Scraping Pawel Nastula...\n",
      "http://ufcstats.com/fighter-details/154a6b3ffae264cd\n",
      "Scraping Rafael Natal...\n",
      "http://ufcstats.com/fighter-details/0dba4df5f34d5ff0\n",
      "Scraping Kevin Natividad...\n",
      "http://ufcstats.com/fighter-details/0c258d1d8e16e5f1\n",
      "Scraping Ismail Naurdiev...\n",
      "http://ufcstats.com/fighter-details/6a96ad1bc34fb113\n",
      "Scraping Danny Navarro...\n",
      "http://ufcstats.com/fighter-details/618f72750ec50b05\n",
      "Scraping Marcio Navarro...\n",
      "http://ufcstats.com/fighter-details/52f7d300738961ac\n",
      "Scraping Tafon Nchukwi...\n",
      "http://ufcstats.com/fighter-details/6aae253467e8f9ce\n",
      "Scraping Dustin Neace...\n",
      "http://ufcstats.com/fighter-details/e503aa5c252a1b4d\n",
      "Scraping Josh Neal...\n",
      "http://ufcstats.com/fighter-details/0b534765dca35e71\n",
      "Scraping Joe Neal...\n",
      "http://ufcstats.com/fighter-details/5751267660c734cb\n",
      "Scraping Geoff Neal...\n",
      "http://ufcstats.com/fighter-details/b997be68943010fc\n",
      "Scraping Stanislav Nedkov...\n",
      "http://ufcstats.com/fighter-details/1d4bbaabd8b60173\n",
      "Scraping Josh Neer...\n",
      "http://ufcstats.com/fighter-details/d1a1314976c50bef\n",
      "Scraping Nicolae Negumereanu...\n",
      "http://ufcstats.com/fighter-details/8c57c7b8c3bab0eb\n",
      "Scraping Steve Nelmark...\n",
      "http://ufcstats.com/fighter-details/13e62d766b709aa6\n",
      "Scraping Shane Nelson...\n",
      "http://ufcstats.com/fighter-details/2db7fa8db6bc9632\n",
      "Scraping Roy Nelson...\n",
      "http://ufcstats.com/fighter-details/3f7c14c7eca7195d\n",
      "Scraping Gunnar Nelson...\n",
      "http://ufcstats.com/fighter-details/fd55393021a8c255\n",
      "Scraping Kyle Nelson...\n",
      "http://ufcstats.com/fighter-details/31f8081c7600da93\n",
      "Scraping Lissette Neri...\n",
      "http://ufcstats.com/fighter-details/f4db63258ecf0613\n",
      "Scraping Mario Neto...\n",
      "http://ufcstats.com/fighter-details/1209b5134401ca53\n",
      "Scraping Antonio Braga Neto...\n",
      "http://ufcstats.com/fighter-details/fae67903c4fe636b\n",
      "Scraping Eduardo Neves...\n",
      "http://ufcstats.com/fighter-details/1d688fa375d9431c\n",
      "Scraping Julio Cesar Neves Jr....\n",
      "http://ufcstats.com/fighter-details/195d0d3e14a2e256\n",
      "Scraping Nick Newell...\n",
      "http://ufcstats.com/fighter-details/f562238becb9ec50\n",
      "Scraping Journey Newson...\n",
      "http://ufcstats.com/fighter-details/78f485f851891d68\n",
      "Scraping Jeff Newton...\n",
      "http://ufcstats.com/fighter-details/94609dd91731d428\n",
      "Scraping Carlos Newton...\n",
      "http://ufcstats.com/fighter-details/952f6fa06f25a0ec\n",
      "Scraping Emanuel Newton...\n",
      "http://ufcstats.com/fighter-details/fbbbc68d368832fa\n",
      "Scraping Francis Ngannou...\n",
      "http://ufcstats.com/fighter-details/8d03ce87ca14e778\n",
      "Scraping Ben Nguyen...\n",
      "http://ufcstats.com/fighter-details/840d2c82ea68b9aa\n",
      "Scraping Steven Nguyen...\n",
      "http://ufcstats.com/fighter-details/69037fc7730e4225\n",
      "Scraping Alex Nicholson...\n",
      "http://ufcstats.com/fighter-details/2b6d855c6e280fb1\n",
      "Scraping Bo Nickal...\n",
      "http://ufcstats.com/fighter-details/35673bf5204524ee\n",
      "Scraping Mike Nickels...\n",
      "http://ufcstats.com/fighter-details/330ec26453c44a59\n",
      "Scraping Matheus Nicolau...\n",
      "http://ufcstats.com/fighter-details/1a31ef98efce7a79\n",
      "Scraping Stewart Nicoll...\n",
      "http://ufcstats.com/fighter-details/2bd98ab77a8daa75\n",
      "Scraping Jaimelene Nievera...\n",
      "http://ufcstats.com/fighter-details/3edf45e1717fa764\n",
      "Scraping Khomkrit Niimi...\n",
      "http://ufcstats.com/fighter-details/52a003d768f10d91\n",
      "Scraping Tom Niinimaki...\n",
      "http://ufcstats.com/fighter-details/5fceb45939fc0c8a\n",
      "Scraping Ramsey Nijem...\n",
      "http://ufcstats.com/fighter-details/22aa91e402d0fe1f\n",
      "Scraping Hans Nijman...\n",
      "http://ufcstats.com/fighter-details/4956f60b7fa57c1a\n",
      "Scraping Fedor Nikolov...\n",
      "http://ufcstats.com/fighter-details/346f789951e85f3f\n",
      "Scraping Jack Nilson...\n",
      "http://ufcstats.com/fighter-details/53e533db1b8e9712\n",
      "Scraping Mats Nilsson...\n",
      "http://ufcstats.com/fighter-details/a9bcf8717dd12532\n",
      "Scraping Guangyou Ning...\n",
      "http://ufcstats.com/fighter-details/2c1170b825f58e57\n",
      "Scraping Soichi Nishida...\n",
      "http://ufcstats.com/fighter-details/6810d8d2dd557cf9\n",
      "Scraping Yosuke Nishijima...\n",
      "http://ufcstats.com/fighter-details/5cde96e0a1a1fffe\n",
      "Scraping Yamato Nishikawa...\n",
      "http://ufcstats.com/fighter-details/7beecbe0a08cf002\n",
      "Scraping Akiyo Nishiura...\n",
      "http://ufcstats.com/fighter-details/6c9383ffab2725a5\n",
      "Scraping Anthony Njokuani...\n",
      "http://ufcstats.com/fighter-details/6bf5a7d3e081ade2\n",
      "Scraping Chidi Njokuani...\n",
      "http://ufcstats.com/fighter-details/c68c68efaa5ca6ef\n",
      "Scraping Derrick Noble...\n",
      "http://ufcstats.com/fighter-details/21321cdfba797c52\n",
      "Scraping Kyle Noblitt...\n",
      "http://ufcstats.com/fighter-details/4acf03bdec2025d7\n",
      "Scraping Pedro Nobre...\n",
      "http://ufcstats.com/fighter-details/e983c62faf677ab2\n",
      "Scraping Jacob Noe...\n",
      "http://ufcstats.com/fighter-details/9bff1b4c37ebbede\n",
      "Scraping Antonio Rodrigo Nogueira...\n",
      "http://ufcstats.com/fighter-details/ee9d73f4fee9cbdd\n",
      "Scraping Rogerio Nogueira...\n",
      "http://ufcstats.com/fighter-details/73e09f837f3b5ecc\n",
      "Scraping Alexandre Franca Nogueira...\n",
      "http://ufcstats.com/fighter-details/4c27ca8c8481f79a\n",
      "Scraping Talita Nogueira...\n",
      "http://ufcstats.com/fighter-details/a3d1d060f9af97fe\n",
      "Scraping Kyle Noke...\n",
      "http://ufcstats.com/fighter-details/7339d340aa2889cb\n",
      "Scraping Tom Nolan...\n",
      "http://ufcstats.com/fighter-details/6c3b2525436cf5d4\n",
      "Scraping Nick Nolte...\n",
      "http://ufcstats.com/fighter-details/d665de9b4da87c22\n",
      "Scraping KJ Noons...\n",
      "http://ufcstats.com/fighter-details/b7ffa72aa148599a\n",
      "Scraping Sage Northcutt...\n",
      "http://ufcstats.com/fighter-details/ed9d8ee3a4239b1c\n",
      "Scraping Jan Nortje...\n",
      "http://ufcstats.com/fighter-details/bd4389b71fdc0ce2\n",
      "Scraping Scott Norton...\n",
      "http://ufcstats.com/fighter-details/f21a3d68fb9df387\n",
      "Scraping Shohei Nose...\n",
      "http://ufcstats.com/fighter-details/6b0e83b094f816ac\n",
      "Scraping Jonatas Novaes...\n",
      "http://ufcstats.com/fighter-details/9e8e5c529057fe60\n",
      "Scraping Jason Novelli...\n",
      "http://ufcstats.com/fighter-details/459e4dc69ec669b2\n",
      "Scraping Phillipe Nover...\n",
      "http://ufcstats.com/fighter-details/64360e618823a8e4\n",
      "Scraping Taiyilake Nueraji...\n",
      "http://ufcstats.com/fighter-details/7498b3ac79a3b948\n",
      "Scraping Shayilan Nuerdanbieke...\n",
      "http://ufcstats.com/fighter-details/0a73acff6325c1e2\n",
      "Scraping Diego Nunes...\n",
      "http://ufcstats.com/fighter-details/3a24769a4855040a\n",
      "Scraping Amanda Nunes...\n",
      "http://ufcstats.com/fighter-details/80fa8218c99f9c58\n",
      "Scraping Nina Nunes...\n",
      "http://ufcstats.com/fighter-details/d343df8ba11f4c4e\n",
      "Scraping Istela Nunes...\n",
      "http://ufcstats.com/fighter-details/efc67b07eed39794\n",
      "Scraping Josiane Nunes...\n",
      "http://ufcstats.com/fighter-details/68d35296f566792b\n",
      "Scraping Diyar Nurgozhay...\n",
      "http://ufcstats.com/fighter-details/709fadb644ee3f51\n",
      "Scraping Khabib Nurmagomedov...\n",
      "http://ufcstats.com/fighter-details/032cc3922d871c7f\n",
      "Scraping Said Nurmagomedov...\n",
      "http://ufcstats.com/fighter-details/0fd5f4b838e890cc\n",
      "Scraping Abubakar Nurmagomedov...\n",
      "http://ufcstats.com/fighter-details/029e1293e609fd74\n",
      "Scraping Umar Nurmagomedov...\n",
      "http://ufcstats.com/fighter-details/2b6fc1c02736833d\n",
      "Scraping Kennedy Nzechukwu...\n",
      "http://ufcstats.com/fighter-details/8667caa0451d245b\n",
      "Scraping Jake O'Brien...\n",
      "http://ufcstats.com/fighter-details/20bcc9966affb19c\n",
      "Scraping TJ O'Brien...\n",
      "http://ufcstats.com/fighter-details/d25b93992f285953\n",
      "Scraping Sean O'Connell...\n",
      "http://ufcstats.com/fighter-details/cb52f9490c2dc069\n",
      "Scraping Dan O'Connor...\n",
      "http://ufcstats.com/fighter-details/69ea0119f6f0dfe0\n",
      "Scraping Sean O'Haire...\n",
      "http://ufcstats.com/fighter-details/46effbd1135423c5\n",
      "Scraping Sean O'Malley...\n",
      "http://ufcstats.com/fighter-details/b50a426a33da0012\n",
      "Scraping Jeremiah O'Neal...\n",
      "http://ufcstats.com/fighter-details/338fda4ec7034c5d\n",
      "Scraping Chuck O'Neil...\n",
      "http://ufcstats.com/fighter-details/56bc9ccb609df534\n",
      "Scraping Casey O'Neill...\n",
      "http://ufcstats.com/fighter-details/04835018f90b118c\n",
      "Scraping Brendan O'Reilly...\n",
      "http://ufcstats.com/fighter-details/494b0bfdbac74502\n",
      "Scraping Takahiro Oba...\n",
      "http://ufcstats.com/fighter-details/7139cd2ae4bf6a29\n",
      "Scraping Nobuhiro Obiya...\n",
      "http://ufcstats.com/fighter-details/6e3282d57d2467a0\n",
      "Scraping Jose Ochoa...\n",
      "http://ufcstats.com/fighter-details/88be62d6c1e6dadb\n",
      "Scraping Christian Ocon...\n",
      "http://ufcstats.com/fighter-details/2d6d6ffe5a446ea2\n",
      "Scraping Richard Odoms...\n",
      "http://ufcstats.com/fighter-details/f43907e75f8d9baa\n",
      "Scraping Volkan Oezdemir...\n",
      "http://ufcstats.com/fighter-details/0845c81e37d3bcb3\n",
      "Scraping Kaan Ofli...\n",
      "http://ufcstats.com/fighter-details/7facc9c45d792985\n",
      "Scraping Naoya Ogawa...\n",
      "http://ufcstats.com/fighter-details/4b2390cfaceb91d8\n",
      "Scraping Trey Ogden...\n",
      "http://ufcstats.com/fighter-details/cfc3e7bb44685289\n",
      "Scraping Andy Ogle...\n",
      "http://ufcstats.com/fighter-details/b6c4451cb13c9303\n",
      "Scraping Ho Taek Oh...\n",
      "http://ufcstats.com/fighter-details/5c020ee6ab450870\n",
      "Scraping Michiyoshi Ohara...\n",
      "http://ufcstats.com/fighter-details/6a8a06b542e1516d\n",
      "Scraping Koji Oishi...\n",
      "http://ufcstats.com/fighter-details/01daf32100ed7517\n",
      "Scraping Takayuki Okada...\n",
      "http://ufcstats.com/fighter-details/32541eb5d12668b4\n",
      "Scraping Yushin Okami...\n",
      "http://ufcstats.com/fighter-details/acff437707625fc7\n",
      "Scraping JJ Okanovich...\n",
      "http://ufcstats.com/fighter-details/aa40fe6038db56cb\n",
      "Scraping Bolaji Oki...\n",
      "http://ufcstats.com/fighter-details/4bdedbdeedff7d1d\n",
      "Scraping Kazuki Okubo...\n",
      "http://ufcstats.com/fighter-details/33454ad90754cb49\n",
      "Scraping Masakatsu Okuda...\n",
      "http://ufcstats.com/fighter-details/02a65a55f25fb4f3\n",
      "Scraping Aleksei Oleinik...\n",
      "http://ufcstats.com/fighter-details/98c23cb6da5b3352\n",
      "Scraping Michal Oleksiejczuk...\n",
      "http://ufcstats.com/fighter-details/0d65c432720accb9\n",
      "Scraping Rafaello Oliveira...\n",
      "http://ufcstats.com/fighter-details/15b1b21cd743d652\n",
      "Scraping Charles Oliveira...\n",
      "http://ufcstats.com/fighter-details/07225ba28ae309b6\n",
      "Scraping Jorge Oliveira...\n",
      "http://ufcstats.com/fighter-details/bec2746f033802c3\n",
      "Scraping Ednaldo Oliveira...\n",
      "http://ufcstats.com/fighter-details/acd9513399a8b09b\n",
      "Scraping Alex Oliveira...\n",
      "http://ufcstats.com/fighter-details/57b10fca4f9c9a7a\n",
      "Scraping Maria Oliveira...\n",
      "http://ufcstats.com/fighter-details/37d752ec41ed84bb\n",
      "Scraping Bruno Oliveira...\n",
      "http://ufcstats.com/fighter-details/1e85912c9bab7e2b\n",
      "Scraping Saimon Oliveira...\n",
      "http://ufcstats.com/fighter-details/72ea1984c52019b5\n",
      "Scraping Vinicius Oliveira...\n",
      "http://ufcstats.com/fighter-details/18d01f7f8338ae72\n",
      "Scraping Ravena Oliveira...\n",
      "http://ufcstats.com/fighter-details/4948e412fa6ab67d\n",
      "Scraping Wendell Oliveira Marques...\n",
      "http://ufcstats.com/fighter-details/32c03df3c9760069\n",
      "Scraping Felipe Olivieri...\n",
      "http://ufcstats.com/fighter-details/948880beac71f028\n",
      "Scraping Andy Ologun...\n",
      "http://ufcstats.com/fighter-details/e96d8538d3f9d0ed\n",
      "Scraping Shana Olsen...\n",
      "http://ufcstats.com/fighter-details/dfbb95ca0c143988\n",
      "Scraping Casey Olson...\n",
      "http://ufcstats.com/fighter-details/7613773461b276f4\n",
      "Scraping Dennis Olson...\n",
      "http://ufcstats.com/fighter-details/8e0709784259402d\n",
      "Scraping Cameron Olson...\n",
      "http://ufcstats.com/fighter-details/5a9104718439ef44\n",
      "Scraping Gadzhi Omargadzhiev...\n",
      "http://ufcstats.com/fighter-details/684d3aee255a3d09\n",
      "Scraping Alan Omer...\n",
      "http://ufcstats.com/fighter-details/f2ad06f1007c481a\n",
      "Scraping Daniel Omielanczuk...\n",
      "http://ufcstats.com/fighter-details/470fedbc8563ac47\n",
      "Scraping Michihiro Omigawa...\n",
      "http://ufcstats.com/fighter-details/9f842be1a5337be6\n",
      "Scraping David Onama...\n",
      "http://ufcstats.com/fighter-details/ffe9703408fb5964\n",
      "Scraping Charlie Ontiveros...\n",
      "http://ufcstats.com/fighter-details/318572f6f74b760d\n",
      "Scraping Chibwikem Onyenegecha...\n",
      "http://ufcstats.com/fighter-details/887e09328cd63df1\n",
      "Scraping Myktybek Orolbai...\n",
      "http://ufcstats.com/fighter-details/bf2c8e01b07d3eb1\n",
      "Scraping Sam Oropeza...\n",
      "http://ufcstats.com/fighter-details/6b8db407d49c6e4b\n",
      "Scraping Brian Ortega...\n",
      "http://ufcstats.com/fighter-details/def8166ff24bd237\n",
      "Scraping Tito Ortiz...\n",
      "http://ufcstats.com/fighter-details/2f732dd9210d301f\n",
      "Scraping Jorge Ortiz...\n",
      "http://ufcstats.com/fighter-details/9c5828c6fd9dc948\n",
      "Scraping Dustin Ortiz...\n",
      "http://ufcstats.com/fighter-details/f53c1f4ceeed8c08\n",
      "Scraping Kenji Osawa...\n",
      "http://ufcstats.com/fighter-details/8eb239a52fc4ec14\n",
      "Scraping Ode Osbourne...\n",
      "http://ufcstats.com/fighter-details/6d68c1afe954f121\n",
      "Scraping Kurt Osiander...\n",
      "http://ufcstats.com/fighter-details/f84dfc5a8d178403\n",
      "Scraping Nick Osipczak...\n",
      "http://ufcstats.com/fighter-details/5b407acfe0ef9b76\n",
      "Scraping Nissen Osterneck...\n",
      "http://ufcstats.com/fighter-details/d632d156c0549e07\n",
      "Scraping Rachael Ostovich...\n",
      "http://ufcstats.com/fighter-details/01784fbc27c68b14\n",
      "Scraping Pedro Otavio...\n",
      "http://ufcstats.com/fighter-details/4512e46543b960ad\n",
      "Scraping Alexander Otsuka...\n",
      "http://ufcstats.com/fighter-details/865aa315ea62c511\n",
      "Scraping Takafumi Otsuka...\n",
      "http://ufcstats.com/fighter-details/6b8f28da9a483049\n",
      "Scraping Quemuel Ottoni...\n",
      "http://ufcstats.com/fighter-details/7ce21433c2a53168\n",
      "Scraping Zak Ottow...\n",
      "http://ufcstats.com/fighter-details/47cd337b86b1af92\n",
      "Scraping Artur Oumakhanov...\n",
      "http://ufcstats.com/fighter-details/1ef0eae31904e534\n",
      "Scraping Sidney Outlaw...\n",
      "http://ufcstats.com/fighter-details/871ce0b4a01922b6\n",
      "Scraping Alistair Overeem...\n",
      "http://ufcstats.com/fighter-details/b4ad3a06ee4d660c\n",
      "Scraping Valentijn Overeem...\n",
      "http://ufcstats.com/fighter-details/20e403a1acfef130\n",
      "Scraping Craig Oxley...\n",
      "http://ufcstats.com/fighter-details/4bb9d7a32d02a03e\n",
      "Scraping Shungo Oyama...\n",
      "http://ufcstats.com/fighter-details/47b7e4e60813b7b2\n",
      "Scraping Ren Ozaki...\n",
      "http://ufcstats.com/fighter-details/8997ee20b6a43d76\n",
      "Scraping Alptekin Ozkilic...\n",
      "http://ufcstats.com/fighter-details/e18a19001a3f7c7d\n",
      "Scraping Raquel Pa'aluhi...\n",
      "http://ufcstats.com/fighter-details/373be586f370d400\n",
      "Scraping Nick Pace...\n",
      "http://ufcstats.com/fighter-details/8cb76103cd8a1562\n",
      "Scraping Larissa Pacheco...\n",
      "http://ufcstats.com/fighter-details/16b89be2f5c16fba\n",
      "Scraping Angel Pacheco...\n",
      "http://ufcstats.com/fighter-details/07797f10b9569cfc\n",
      "Scraping Teemu Packalen...\n",
      "http://ufcstats.com/fighter-details/8f4eeaf7a0df7c1a\n",
      "Scraping George Pacurariu...\n",
      "http://ufcstats.com/fighter-details/c51da79b0346b5b7\n",
      "Scraping Cyrillo Padilha...\n",
      "http://ufcstats.com/fighter-details/856c4d2668a875f9\n",
      "Scraping Gary Padilla...\n",
      "http://ufcstats.com/fighter-details/01dd4cdc2446f665\n",
      "Scraping Fernando Padilla...\n",
      "http://ufcstats.com/fighter-details/d2f43cfaf8ca3560\n",
      "Scraping Chris Padilla...\n",
      "http://ufcstats.com/fighter-details/06626b6287e1ae1e\n",
      "Scraping Damacio Page...\n",
      "http://ufcstats.com/fighter-details/c96e2ae6021144a1\n",
      "Scraping Michael Page...\n",
      "http://ufcstats.com/fighter-details/a67d071163962af8\n",
      "Scraping Dustin Pague...\n",
      "http://ufcstats.com/fighter-details/55f80a8aeffcdb33\n",
      "Scraping Josh Paiva...\n",
      "http://ufcstats.com/fighter-details/1e12c1dbbb1e2dda\n",
      "Scraping Raulian Paiva...\n",
      "http://ufcstats.com/fighter-details/82b4e942781b1046\n",
      "Scraping Dinis Paiva Jr....\n",
      "http://ufcstats.com/fighter-details/ad3a5e465c76e499\n",
      "Scraping Fredson Paixao...\n",
      "http://ufcstats.com/fighter-details/320edfb0332b7073\n",
      "Scraping Luis Pajuelo...\n",
      "http://ufcstats.com/fighter-details/e530df53922f413e\n",
      "Scraping Jose Palacios...\n",
      "http://ufcstats.com/fighter-details/de20ffb3fc2e7629\n",
      "Scraping Ricky Palacios...\n",
      "http://ufcstats.com/fighter-details/797ddccda75f169f\n",
      "Scraping Bart Palaszewski...\n",
      "http://ufcstats.com/fighter-details/4304992c2acc187b\n",
      "Scraping Sasha Palatnikov...\n",
      "http://ufcstats.com/fighter-details/a6c20202c701e5ca\n",
      "Scraping Soa Palelei...\n",
      "http://ufcstats.com/fighter-details/60029bcf496bd707\n",
      "Scraping Rousimar Palhares...\n",
      "http://ufcstats.com/fighter-details/8ddf9c51c5fdea75\n",
      "Scraping Tulio Palhares...\n",
      "http://ufcstats.com/fighter-details/e8c170a64dc920ac\n",
      "Scraping Stephen Palling...\n",
      "http://ufcstats.com/fighter-details/ab7c212de9f66af0\n",
      "Scraping Eduardo Pamplona...\n",
      "http://ufcstats.com/fighter-details/f31c0905045fa100\n",
      "Scraping Ruel Panales...\n",
      "http://ufcstats.com/fighter-details/2742f028399bf8c7\n",
      "Scraping Yuri Panferov...\n",
      "http://ufcstats.com/fighter-details/36d811b015635b67\n",
      "Scraping Alexandre Pantoja...\n",
      "http://ufcstats.com/fighter-details/a0f0004aadf10b71\n",
      "Scraping Jared Papazian...\n",
      "http://ufcstats.com/fighter-details/edad57b3dddf2168\n",
      "Scraping Kathryn Paprocki...\n",
      "http://ufcstats.com/fighter-details/bd381cde8426077a\n",
      "Scraping Joe Pardo...\n",
      "http://ufcstats.com/fighter-details/74fefd43f073cd2f\n",
      "Scraping Bryan Pardoe...\n",
      "http://ufcstats.com/fighter-details/56116537d71a578c\n",
      "Scraping Remco Pardoel...\n",
      "http://ufcstats.com/fighter-details/749685d24e2cac50\n",
      "Scraping Ido Pariente...\n",
      "http://ufcstats.com/fighter-details/7573d25a078b5732\n",
      "Scraping Josh Parisian...\n",
      "http://ufcstats.com/fighter-details/b5da8f7d05e85a55\n",
      "Scraping Karo Parisyan...\n",
      "http://ufcstats.com/fighter-details/349aaa3da11eb587\n",
      "Scraping Won Sik Park...\n",
      "http://ufcstats.com/fighter-details/9df394db5ca103eb\n",
      "Scraping JunYong Park...\n",
      "http://ufcstats.com/fighter-details/285ae0b4a68221f4\n",
      "Scraping Harvey Park...\n",
      "http://ufcstats.com/fighter-details/b709b534b6873744\n",
      "Scraping HyunSung Park...\n",
      "http://ufcstats.com/fighter-details/b671bdf981ad527d\n",
      "Scraping Jae Hyun Park...\n",
      "http://ufcstats.com/fighter-details/fe1595732dfb08fc\n",
      "Scraping Norman Parke...\n",
      "http://ufcstats.com/fighter-details/14ff46596ad80609\n",
      "Scraping Ryan Parker...\n",
      "http://ufcstats.com/fighter-details/6a0b80a24f22e152\n",
      "Scraping Larry Parker...\n",
      "http://ufcstats.com/fighter-details/c0231720fe516994\n",
      "Scraping Tyra Parker...\n",
      "http://ufcstats.com/fighter-details/64be3dc99eaa42b6\n",
      "Scraping Mick Parkin...\n",
      "http://ufcstats.com/fighter-details/0d5cc0170c1a7e71\n",
      "Scraping Willie Parks...\n",
      "http://ufcstats.com/fighter-details/86ad0ae839331bd7\n",
      "Scraping Jordan Parsons...\n",
      "http://ufcstats.com/fighter-details/8b2a18d3c6735083\n",
      "Scraping Preston Parsons...\n",
      "http://ufcstats.com/fighter-details/9fe7af8b3fbe00a0\n",
      "Scraping Jonny Parsons...\n",
      "http://ufcstats.com/fighter-details/2975297f505e9447\n",
      "Scraping Onassis Parungao...\n",
      "http://ufcstats.com/fighter-details/96d173b7f92aa520\n",
      "Scraping Ramona Pascual...\n",
      "http://ufcstats.com/fighter-details/3eb4dc9a7d4ac906\n",
      "Scraping Billy Pasulatan...\n",
      "http://ufcstats.com/fighter-details/e5a59983f4603621\n",
      "Scraping Jhonoven Pati...\n",
      "http://ufcstats.com/fighter-details/6b16024d44eb03a2\n",
      "Scraping Windri Patilima...\n",
      "http://ufcstats.com/fighter-details/66d42e9503fa108e\n",
      "Scraping Jorge Patino...\n",
      "http://ufcstats.com/fighter-details/c8cca8f3de5be4b4\n",
      "Scraping Russell Patrick...\n",
      "http://ufcstats.com/fighter-details/eafedba0617ced81\n",
      "Scraping Claude Patrick...\n",
      "http://ufcstats.com/fighter-details/56116a79e4deed06\n",
      "Scraping Michael Patt...\n",
      "http://ufcstats.com/fighter-details/83d0de122f2f9664\n",
      "Scraping Justin Patterson...\n",
      "http://ufcstats.com/fighter-details/2dc7c49cfaeb867c\n",
      "Scraping Sam Patterson...\n",
      "http://ufcstats.com/fighter-details/8b6e5dc2ba1edbe7\n",
      "Scraping Zac Pauga...\n",
      "http://ufcstats.com/fighter-details/56f7d7ee06be4aab\n",
      "Scraping Julio Paulino...\n",
      "http://ufcstats.com/fighter-details/60c72f7459827881\n",
      "Scraping Thomas Paull...\n",
      "http://ufcstats.com/fighter-details/dda67d7d3df6b406\n",
      "Scraping Sergei Pavlovich...\n",
      "http://ufcstats.com/fighter-details/f14cf73e51b29254\n",
      "Scraping Pawel Pawlak...\n",
      "http://ufcstats.com/fighter-details/9310418684bc896f\n",
      "Scraping Sarah Payant...\n",
      "http://ufcstats.com/fighter-details/748d4e35f846a029\n",
      "Scraping Roland Payne...\n",
      "http://ufcstats.com/fighter-details/2e04a3b4a2011b97\n",
      "Scraping Jonathan Pearce...\n",
      "http://ufcstats.com/fighter-details/87c0b1c696ddfb43\n",
      "Scraping Joe Pearson...\n",
      "http://ufcstats.com/fighter-details/122806b56775a53a\n",
      "Scraping Ross Pearson...\n",
      "http://ufcstats.com/fighter-details/4f732e58ed907eff\n",
      "Scraping Andre Pederneiras...\n",
      "http://ufcstats.com/fighter-details/bba678d312590087\n",
      "Scraping Carlo Pedersoli Jr....\n",
      "http://ufcstats.com/fighter-details/198994b47f395af0\n",
      "Scraping Matt Pedro...\n",
      "http://ufcstats.com/fighter-details/f354c50b8d63d9b3\n",
      "Scraping Tyson Pedro...\n",
      "http://ufcstats.com/fighter-details/49e96ff8ab781589\n",
      "Scraping Trevor Peek...\n",
      "http://ufcstats.com/fighter-details/0bc697c5936a2d0a\n",
      "Scraping Willie Peeters...\n",
      "http://ufcstats.com/fighter-details/e7bfdb5e0112891e\n",
      "Scraping Filip Pejic...\n",
      "http://ufcstats.com/fighter-details/38ed5a2299230227\n",
      "Scraping Kurt Pellegrino...\n",
      "http://ufcstats.com/fighter-details/aa1952ec0b3dd8e1\n",
      "Scraping Yan Pellerin...\n",
      "http://ufcstats.com/fighter-details/bfe95ec546692b13\n",
      "Scraping Julianna Pena...\n",
      "http://ufcstats.com/fighter-details/3253b16d38ae087d\n",
      "Scraping Luis Pena...\n",
      "http://ufcstats.com/fighter-details/2844b047183a1adb\n",
      "Scraping Felipe Pena...\n",
      "http://ufcstats.com/fighter-details/566ff9546fc29acd\n",
      "Scraping Matej Penaz...\n",
      "http://ufcstats.com/fighter-details/abd64006fd37298d\n",
      "Scraping Sherman Pendergarst...\n",
      "http://ufcstats.com/fighter-details/e670f8cc2969a789\n",
      "Scraping Drew Pendleton...\n",
      "http://ufcstats.com/fighter-details/34b634cb2471bdde\n",
      "Scraping Cathal Pendred...\n",
      "http://ufcstats.com/fighter-details/99c7610aa74995d3\n",
      "Scraping BJ Penn...\n",
      "http://ufcstats.com/fighter-details/73c7cfa551289285\n",
      "Scraping Jessica Penne...\n",
      "http://ufcstats.com/fighter-details/c742287ed86a09bc\n",
      "Scraping Nick Penner...\n",
      "http://ufcstats.com/fighter-details/879b8df81523d91b\n",
      "Scraping Justin Pennington...\n",
      "http://ufcstats.com/fighter-details/0699c4b2a7c3c76f\n",
      "Scraping Raquel Pennington...\n",
      "http://ufcstats.com/fighter-details/fc169c387b4b465d\n",
      "Scraping Tecia Pennington...\n",
      "http://ufcstats.com/fighter-details/31ef8b67e13495b3\n",
      "Scraping Jerron Peoples...\n",
      "http://ufcstats.com/fighter-details/a2ac473d74eb157c\n",
      "Scraping Godofredo Pepey...\n",
      "http://ufcstats.com/fighter-details/fa37628269132d1a\n",
      "Scraping Ray Perales...\n",
      "http://ufcstats.com/fighter-details/9a70f67ad2187fa3\n",
      "Scraping Robert Peralta...\n",
      "http://ufcstats.com/fighter-details/960d6cae8879ba2b\n",
      "Scraping Viviane Pereira...\n",
      "http://ufcstats.com/fighter-details/d50382dc0565a9e1\n",
      "Scraping Michel Pereira...\n",
      "http://ufcstats.com/fighter-details/595db60957de51d3\n",
      "Scraping Alex Pereira...\n",
      "http://ufcstats.com/fighter-details/e5549c82bfb5582d\n",
      "Scraping Daniel Pereira...\n",
      "http://ufcstats.com/fighter-details/44f46b0592ca0814\n",
      "Scraping Luciano Pereira...\n",
      "http://ufcstats.com/fighter-details/d7ee49bf3c779fa6\n",
      "Scraping Rolando Perez...\n",
      "http://ufcstats.com/fighter-details/4a9e305633f3ef47\n",
      "Scraping Philip Perez...\n",
      "http://ufcstats.com/fighter-details/eee8efec7b951d84\n",
      "Scraping Erik Perez...\n",
      "http://ufcstats.com/fighter-details/af62f99eb7606308\n",
      "Scraping Alejandro Perez...\n",
      "http://ufcstats.com/fighter-details/80daefbed11ce998\n",
      "Scraping Frankie Perez...\n",
      "http://ufcstats.com/fighter-details/96c336b463e0662c\n",
      "Scraping Jose Perez...\n",
      "http://ufcstats.com/fighter-details/89578ae236ee04e9\n",
      "Scraping Alex Perez...\n",
      "http://ufcstats.com/fighter-details/ab2b4ff41d6ebe0f\n",
      "Scraping Markus Perez...\n",
      "http://ufcstats.com/fighter-details/2ac4628c08ec5125\n",
      "Scraping Ailin Perez...\n",
      "http://ufcstats.com/fighter-details/06e4245d16fc5315\n",
      "Scraping Anthony Perosh...\n",
      "http://ufcstats.com/fighter-details/4b4753d19489297f\n",
      "Scraping Thiago Perpetuo...\n",
      "http://ufcstats.com/fighter-details/c1a5d3843596df92\n",
      "Scraping Hernani Perpetuo...\n",
      "http://ufcstats.com/fighter-details/575360be653ad6a6\n",
      "Scraping Jay Perrin...\n",
      "http://ufcstats.com/fighter-details/01fed6f61ebea01f\n",
      "Scraping Mike Perry...\n",
      "http://ufcstats.com/fighter-details/f2b6fdb20675b11c\n",
      "Scraping Raphael Pessoa...\n",
      "http://ufcstats.com/fighter-details/41f90012b86a11bf\n",
      "Scraping Viktor Pesta...\n",
      "http://ufcstats.com/fighter-details/202b0467521c9d6f\n",
      "Scraping Leiticia Pestova...\n",
      "http://ufcstats.com/fighter-details/f3743d8ef5dde970\n",
      "Scraping Tony Petarra...\n",
      "http://ufcstats.com/fighter-details/c61f66d8c3fd5f07\n",
      "Scraping Tommy Petersen...\n",
      "http://ufcstats.com/fighter-details/7aabd61419f747d1\n",
      "Scraping Thomas Petersen...\n",
      "http://ufcstats.com/fighter-details/764d39074a352e33\n",
      "Scraping Cory Peterson...\n",
      "http://ufcstats.com/fighter-details/5df10509264586e5\n",
      "Scraping Steven Peterson...\n",
      "http://ufcstats.com/fighter-details/b93c06d09d1c4ac0\n",
      "Scraping Vitor Petrino...\n",
      "http://ufcstats.com/fighter-details/71171fc96445bf65\n",
      "Scraping Andre Petroski...\n",
      "http://ufcstats.com/fighter-details/5f61780fe5e9b6d0\n",
      "Scraping Armen Petrosyan...\n",
      "http://ufcstats.com/fighter-details/369ea36e450ae62a\n",
      "Scraping Ivana Petrovic...\n",
      "http://ufcstats.com/fighter-details/38c5817ade8a8014\n",
      "Scraping Seth Petruzelli...\n",
      "http://ufcstats.com/fighter-details/93b9496275bbbf80\n",
      "Scraping Peter Petties...\n",
      "http://ufcstats.com/fighter-details/7ea5d60d2e6a8ad0\n",
      "Scraping Anthony Pettis...\n",
      "http://ufcstats.com/fighter-details/cbb682f5fcc44bfc\n",
      "Scraping Sergio Pettis...\n",
      "http://ufcstats.com/fighter-details/de75d1c45a39e221\n",
      "Scraping Forrest Petz...\n",
      "http://ufcstats.com/fighter-details/e86bc32f5997a8f7\n",
      "Scraping Dino Pezao...\n",
      "http://ufcstats.com/fighter-details/81b57acd6975ac06\n",
      "Scraping Cody Pfister...\n",
      "http://ufcstats.com/fighter-details/5904b0b38dc6718d\n",
      "Scraping Nam Phan...\n",
      "http://ufcstats.com/fighter-details/80dbeb1dd5b53e64\n",
      "Scraping Constantinos Philippou...\n",
      "http://ufcstats.com/fighter-details/05560764359161e4\n",
      "Scraping Wayne Phillips...\n",
      "http://ufcstats.com/fighter-details/09a82bd51ff61376\n",
      "Scraping Dave Phillips...\n",
      "http://ufcstats.com/fighter-details/99020eeb8cd5689d\n",
      "Scraping Aaron Phillips...\n",
      "http://ufcstats.com/fighter-details/34c2b3656f88f7ef\n",
      "Scraping Elizabeth Phillips...\n",
      "http://ufcstats.com/fighter-details/dcbf01d605681ad1\n",
      "Scraping John Phillips...\n",
      "http://ufcstats.com/fighter-details/e9ac7bfb65c25497\n",
      "Scraping Kyler Phillips...\n",
      "http://ufcstats.com/fighter-details/60425d07ef4b91a7\n",
      "Scraping Mario Piazzon...\n",
      "http://ufcstats.com/fighter-details/44f234a36324e6c8\n",
      "Scraping Nick Pica...\n",
      "http://ufcstats.com/fighter-details/7922e8269adcc25a\n",
      "Scraping Nick Piccininni...\n",
      "http://ufcstats.com/fighter-details/a5cb1c29461853ca\n",
      "Scraping Adam Piccolotti...\n",
      "http://ufcstats.com/fighter-details/fa399f7f6e17f7f5\n",
      "Scraping Vinc Pichel...\n",
      "http://ufcstats.com/fighter-details/c77a953488e5607d\n",
      "Scraping Brad Pickett...\n",
      "http://ufcstats.com/fighter-details/c945adc22c2bfe8f\n",
      "Scraping Jamie Pickett...\n",
      "http://ufcstats.com/fighter-details/830f60497fab345a\n",
      "Scraping Fabiola Pidroni...\n",
      "http://ufcstats.com/fighter-details/9561eb5f0d63ffcc\n",
      "Scraping Oskar Piechota...\n",
      "http://ufcstats.com/fighter-details/1cf7ccf64a5bf24e\n",
      "Scraping Nick Piedmont...\n",
      "http://ufcstats.com/fighter-details/df7d386a54e07446\n",
      "Scraping Mike Pierce...\n",
      "http://ufcstats.com/fighter-details/236a37d96d476164\n",
      "Scraping Joao Pierini...\n",
      "http://ufcstats.com/fighter-details/9a967e8e43dcef63\n",
      "Scraping Paddy Pimblett...\n",
      "http://ufcstats.com/fighter-details/7826923b47f8d72a\n",
      "Scraping Daniel Pineda...\n",
      "http://ufcstats.com/fighter-details/361d49960a196976\n",
      "Scraping Jesus Pinedo...\n",
      "http://ufcstats.com/fighter-details/25af5e832f17b474\n",
      "Scraping Pingyuan Liu...\n",
      "http://ufcstats.com/fighter-details/31bbd39c0a075d4e\n",
      "Scraping Luana Pinheiro...\n",
      "http://ufcstats.com/fighter-details/a3a542074109b347\n",
      "Scraping Mario Pinto...\n",
      "http://ufcstats.com/fighter-details/39d309957c5c210d\n",
      "Scraping Gaetano Pirrello...\n",
      "http://ufcstats.com/fighter-details/8765559b6a29a421\n",
      "Scraping Maki Pitolo...\n",
      "http://ufcstats.com/fighter-details/c549573c0df4d676\n",
      "Scraping Dmitry Poberezhets...\n",
      "http://ufcstats.com/fighter-details/9756095cb76b67c3\n",
      "Scraping Jamal Pogues...\n",
      "http://ufcstats.com/fighter-details/f41b9f5efc7162d6\n",
      "Scraping Ross Pointon...\n",
      "http://ufcstats.com/fighter-details/7215953cd5c6254d\n",
      "Scraping Dustin Poirier...\n",
      "http://ufcstats.com/fighter-details/029eaff01e6bb8f0\n",
      "Scraping Igor Pokrajac...\n",
      "http://ufcstats.com/fighter-details/53278852bcd91e11\n",
      "Scraping John Polakowski...\n",
      "http://ufcstats.com/fighter-details/b18fb36a4aa00093\n",
      "Scraping Julia Polastri...\n",
      "http://ufcstats.com/fighter-details/abb68e3c7ca128f2\n",
      "Scraping Brandon Polcare...\n",
      "http://ufcstats.com/fighter-details/543cd2258f4fa339\n",
      "Scraping Mike Polchlopek...\n",
      "http://ufcstats.com/fighter-details/3bb030257966b022\n",
      "Scraping Santiago Ponzinibbio...\n",
      "http://ufcstats.com/fighter-details/6d1bffff14897645\n",
      "Scraping Grigory Popov...\n",
      "http://ufcstats.com/fighter-details/d3fa5c5955397532\n",
      "Scraping Alexander Poppeck...\n",
      "http://ufcstats.com/fighter-details/56bf3ed155bd0fcd\n",
      "Scraping Felipe Portela...\n",
      "http://ufcstats.com/fighter-details/303e017a9074f3aa\n",
      "Scraping Parker Porter...\n",
      "http://ufcstats.com/fighter-details/ac40f7e3cbecdda4\n",
      "Scraping Ihor Potieria...\n",
      "http://ufcstats.com/fighter-details/260bd4cef10b033f\n",
      "Scraping Callan Potter...\n",
      "http://ufcstats.com/fighter-details/8fc9ae9c7527dfcb\n",
      "Scraping Dylan Potter...\n",
      "http://ufcstats.com/fighter-details/61e47575b24a06bf\n",
      "Scraping Ruan Potts...\n",
      "http://ufcstats.com/fighter-details/7e208569469c8bc8\n",
      "Scraping Devin Powell...\n",
      "http://ufcstats.com/fighter-details/065eb44700e641a4\n",
      "Scraping Marcin Prachnio...\n",
      "http://ufcstats.com/fighter-details/6370c1c1e12723d5\n",
      "Scraping Wagner Prado...\n",
      "http://ufcstats.com/fighter-details/7f6ef4e1227600bc\n",
      "Scraping Francisco Prado...\n",
      "http://ufcstats.com/fighter-details/3920d0cc288f9b0d\n",
      "Scraping Trevor Prangley...\n",
      "http://ufcstats.com/fighter-details/f5ff7bcdcfeba3ad\n",
      "Scraping Ricardo Prasel...\n",
      "http://ufcstats.com/fighter-details/b51d0ed3782a1bf5\n",
      "Scraping Carlo Prater...\n",
      "http://ufcstats.com/fighter-details/4f853e98886283cf\n",
      "Scraping Carlos Prates...\n",
      "http://ufcstats.com/fighter-details/7ee0fd831c0fe7c3\n",
      "Scraping Michel Prazeres...\n",
      "http://ufcstats.com/fighter-details/e51fcd9cd84c0b93\n",
      "Scraping Philip Preece...\n",
      "http://ufcstats.com/fighter-details/6597b611f1c32555\n",
      "Scraping Kyle Prepolec...\n",
      "http://ufcstats.com/fighter-details/873626e5547b5235\n",
      "Scraping Dorian Price...\n",
      "http://ufcstats.com/fighter-details/ee4b670e159f4a33\n",
      "Scraping Chris Price...\n",
      "http://ufcstats.com/fighter-details/0597a4528ebd1307\n",
      "Scraping Niko Price...\n",
      "http://ufcstats.com/fighter-details/d8da10db80131bec\n",
      "Scraping Shane Primm...\n",
      "http://ufcstats.com/fighter-details/5114f1b5ad4cdf72\n",
      "Scraping Brent Primus...\n",
      "http://ufcstats.com/fighter-details/46caf130099206cd\n",
      "Scraping Jiri Prochazka...\n",
      "http://ufcstats.com/fighter-details/009341ed974bad72\n",
      "Scraping Lara Procopio...\n",
      "http://ufcstats.com/fighter-details/e99821959a840bb8\n",
      "Scraping Joe Proctor...\n",
      "http://ufcstats.com/fighter-details/a36556bb1565e32d\n",
      "Scraping Cole Province...\n",
      "http://ufcstats.com/fighter-details/2a470ad41c22c25a\n",
      "Scraping Daniel Puder...\n",
      "http://ufcstats.com/fighter-details/66e0a70352fef46a\n",
      "Scraping Lucie Pudilova...\n",
      "http://ufcstats.com/fighter-details/3cf66c62d9069f43\n",
      "Scraping Claudio Puelles...\n",
      "http://ufcstats.com/fighter-details/d747eb273a40a920\n",
      "Scraping Juan Puerta...\n",
      "http://ufcstats.com/fighter-details/fdba548aff9763d9\n",
      "Scraping Bubba Pugh...\n",
      "http://ufcstats.com/fighter-details/6cf2352cdb3de59d\n",
      "Scraping Juan Manuel Puig...\n",
      "http://ufcstats.com/fighter-details/85d0fafb8b75d634\n",
      "Scraping Hugh Pulley...\n",
      "http://ufcstats.com/fighter-details/308279bd246c211f\n",
      "Scraping Josh Pulsifer...\n",
      "http://ufcstats.com/fighter-details/16867810070dc520\n",
      "Scraping Jens Pulver...\n",
      "http://ufcstats.com/fighter-details/44260175069b6276\n",
      "Scraping Andrey Pulyaev...\n",
      "http://ufcstats.com/fighter-details/22e07d3da1aa3475\n",
      "Scraping CM Punk...\n",
      "http://ufcstats.com/fighter-details/a8c9d16fe2a14d72\n",
      "Scraping Joe Pyfer...\n",
      "http://ufcstats.com/fighter-details/c1085e1701b13eca\n",
      "Scraping Mike Pyle...\n",
      "http://ufcstats.com/fighter-details/f5990c11974d8e9c\n",
      "Scraping Pat Pytlik...\n",
      "http://ufcstats.com/fighter-details/4fd140eea593526e\n",
      "Scraping Qiu Lun...\n",
      "http://ufcstats.com/fighter-details/126bdc1710a8cbf4\n",
      "Scraping Bao Quach...\n",
      "http://ufcstats.com/fighter-details/d365ee924f5cc3fc\n",
      "Scraping Gary Quan...\n",
      "http://ufcstats.com/fighter-details/f7b4cbe93f3bac06\n",
      "Scraping Billy Quarantillo...\n",
      "http://ufcstats.com/fighter-details/aa171d55d4b5208f\n",
      "Scraping Nate Quarry...\n",
      "http://ufcstats.com/fighter-details/52cae54377b433b7\n",
      "Scraping Vinicius Queiroz...\n",
      "http://ufcstats.com/fighter-details/2a8502954f49e682\n",
      "Scraping Jimmy Quinlan...\n",
      "http://ufcstats.com/fighter-details/ddbe4fa2ea573393\n",
      "Scraping Josh Quinlan...\n",
      "http://ufcstats.com/fighter-details/876f478f796495f7\n",
      "Scraping Ryan Quinn...\n",
      "http://ufcstats.com/fighter-details/cc23ed51619421a3\n",
      "Scraping Michel Quinones...\n",
      "http://ufcstats.com/fighter-details/5e84a859c6a82288\n",
      "Scraping Landon Quinones...\n",
      "http://ufcstats.com/fighter-details/267f4a6568abe245\n",
      "Scraping Jose Quinonez...\n",
      "http://ufcstats.com/fighter-details/36549928f90f1d36\n",
      "Scraping Cristian Quinonez...\n",
      "http://ufcstats.com/fighter-details/7debc13b36343605\n",
      "Scraping Benji Radach...\n",
      "http://ufcstats.com/fighter-details/01b39decaf0abf6a\n",
      "Scraping Jordan Radev...\n",
      "http://ufcstats.com/fighter-details/45bc8f98d62bd096\n",
      "Scraping Charles Radtke...\n",
      "http://ufcstats.com/fighter-details/feedf3053472fe56\n",
      "Scraping Loik Radzhabov...\n",
      "http://ufcstats.com/fighter-details/8c169fbe1ac33637\n",
      "Scraping Gilbert Rael...\n",
      "http://ufcstats.com/fighter-details/6cc25d19a891f435\n",
      "Scraping Josh Rafferty...\n",
      "http://ufcstats.com/fighter-details/ff2c606c8bc365e3\n",
      "Scraping Amir Rahnavardi...\n",
      "http://ufcstats.com/fighter-details/bc7f7f0ba3db74d2\n",
      "Scraping Ricky Rainey...\n",
      "http://ufcstats.com/fighter-details/9b1e3fb4f8cbd5b7\n",
      "Scraping Shavkat Rakhmonov...\n",
      "http://ufcstats.com/fighter-details/01afe0916a40c7c5\n",
      "Scraping Sora Rakhmonova...\n",
      "http://ufcstats.com/fighter-details/63ff619c52ff7976\n",
      "Scraping Aleksandar Rakic...\n",
      "http://ufcstats.com/fighter-details/333b9e5c723ac873\n",
      "Scraping Jessica Rakoczy...\n",
      "http://ufcstats.com/fighter-details/ffdeb4fbea09ce75\n",
      "Scraping Zygimantas Ramaska...\n",
      "http://ufcstats.com/fighter-details/641ca2c2ed91b93c\n",
      "Scraping Thomas Ramirez...\n",
      "http://ufcstats.com/fighter-details/ea398c802d9998ee\n",
      "Scraping Hector Ramirez...\n",
      "http://ufcstats.com/fighter-details/d1759b2b7be9be56\n",
      "Scraping Matt Ramirez...\n",
      "http://ufcstats.com/fighter-details/96c05ba5ab9eccaf\n",
      "Scraping Steve Ramirez...\n",
      "http://ufcstats.com/fighter-details/4311e9d23604205c\n",
      "Scraping Amador Ramirez...\n",
      "http://ufcstats.com/fighter-details/ac31f869959860bc\n",
      "Scraping Mitch Ramirez...\n",
      "http://ufcstats.com/fighter-details/e99eb0ef25885de5\n",
      "Scraping Andrew Ramm...\n",
      "http://ufcstats.com/fighter-details/3b5f2faaa2f2c1f6\n",
      "Scraping Ian Rammel...\n",
      "http://ufcstats.com/fighter-details/abc8e1423cf5b74e\n",
      "Scraping Luis Ramos...\n",
      "http://ufcstats.com/fighter-details/7bc475b0fc2020ab\n",
      "Scraping Ricardo Ramos...\n",
      "http://ufcstats.com/fighter-details/1ae8f3c723aacff4\n",
      "Scraping Davi Ramos...\n",
      "http://ufcstats.com/fighter-details/0052de90691d4a93\n",
      "Scraping Dorian Ramos...\n",
      "http://ufcstats.com/fighter-details/fa4dcb2c8de482ee\n",
      "Scraping Vernon Ramos Ho...\n",
      "http://ufcstats.com/fighter-details/30b577b112bef42d\n",
      "Scraping Kevin Randleman...\n",
      "http://ufcstats.com/fighter-details/6859f67468ba8489\n",
      "Scraping Raou Raou...\n",
      "http://ufcstats.com/fighter-details/ed069a95aaaf4f56\n",
      "Scraping Mitch Raposo...\n",
      "http://ufcstats.com/fighter-details/0be6776db31d98ec\n",
      "Scraping Hussain Rasouli...\n",
      "http://ufcstats.com/fighter-details/9d61d8cb1c354867\n",
      "Scraping David Rasouri...\n",
      "http://ufcstats.com/fighter-details/31e1ea6fe6b682f8\n",
      "Scraping Ed Ratcliff...\n",
      "http://ufcstats.com/fighter-details/8c90c1563972e44d\n",
      "Scraping Bec Rawlings...\n",
      "http://ufcstats.com/fighter-details/907e60fd13407e1e\n",
      "Scraping Gideon Ray...\n",
      "http://ufcstats.com/fighter-details/ea3ef6206c7907d5\n",
      "Scraping Joe Ray...\n",
      "http://ufcstats.com/fighter-details/d92e6e17f637fe4d\n",
      "Scraping Stevie Ray...\n",
      "http://ufcstats.com/fighter-details/31a13532e724ca2b\n",
      "Scraping Keenan Raymond...\n",
      "http://ufcstats.com/fighter-details/bdd16cd6b29cb499\n",
      "Scraping Iony Razafiarison...\n",
      "http://ufcstats.com/fighter-details/a303588c33d8c5ae\n",
      "Scraping Abdul Razak Alhassan...\n",
      "http://ufcstats.com/fighter-details/eae431e70064e046\n",
      "Scraping Antony Rea...\n",
      "http://ufcstats.com/fighter-details/c36e1f4fa755ffb4\n",
      "Scraping Mateusz Rebecki...\n",
      "http://ufcstats.com/fighter-details/849c5d9979df5357\n",
      "Scraping Rafael Rebello...\n",
      "http://ufcstats.com/fighter-details/972197a8c61ac413\n",
      "Scraping Greg Rebello...\n",
      "http://ufcstats.com/fighter-details/49d78120e0a4f607\n",
      "Scraping Paul Redmond...\n",
      "http://ufcstats.com/fighter-details/3f56b99447f00607\n",
      "Scraping Dennis Reed...\n",
      "http://ufcstats.com/fighter-details/4a35913bd9aa4161\n",
      "Scraping Karl Reed...\n",
      "http://ufcstats.com/fighter-details/11337d069261bf3a\n",
      "Scraping Elise Reed...\n",
      "http://ufcstats.com/fighter-details/ac7c765882f2c68c\n",
      "Scraping John Reedy...\n",
      "http://ufcstats.com/fighter-details/fb4ca5c7e4448645\n",
      "Scraping Johnny Rees...\n",
      "http://ufcstats.com/fighter-details/3ba3b5cc94498437\n",
      "Scraping James Reese...\n",
      "http://ufcstats.com/fighter-details/e9ec08ebb3f92aa3\n",
      "Scraping Zachary Reese...\n",
      "http://ufcstats.com/fighter-details/23dec7c47cb418f8\n",
      "Scraping Stephen Regman...\n",
      "http://ufcstats.com/fighter-details/24d98df7556ac8af\n",
      "Scraping Chad Reiner...\n",
      "http://ufcstats.com/fighter-details/d8022d5526b1d937\n",
      "Scraping Jason Reinhardt...\n",
      "http://ufcstats.com/fighter-details/02500fb9fd79a974\n",
      "Scraping Wilson Reis...\n",
      "http://ufcstats.com/fighter-details/5aedf14771ca82d2\n",
      "Scraping Ben Reiter...\n",
      "http://ufcstats.com/fighter-details/ee7b7768a4e6dc45\n",
      "Scraping Goran Reljic...\n",
      "http://ufcstats.com/fighter-details/132f860d02953f4c\n",
      "Scraping Leigh Remedios...\n",
      "http://ufcstats.com/fighter-details/918db42c3637916f\n",
      "Scraping Paulo Renato Junior...\n",
      "http://ufcstats.com/fighter-details/01dfb60661153735\n",
      "Scraping Chance Rencountre...\n",
      "http://ufcstats.com/fighter-details/1ddb480b601cefb1\n",
      "Scraping Montserrat Rendon...\n",
      "http://ufcstats.com/fighter-details/60193e707634e560\n",
      "Scraping Marion Reneau...\n",
      "http://ufcstats.com/fighter-details/c7d297714d9ab1a4\n",
      "Scraping Solomon Renfro...\n",
      "http://ufcstats.com/fighter-details/ce6b5b93a96dd15b\n",
      "Scraping John Renken...\n",
      "http://ufcstats.com/fighter-details/1507214bbc7a79e2\n",
      "Scraping Herman Renting...\n",
      "http://ufcstats.com/fighter-details/f57cf3d54a641385\n",
      "Scraping Marco Polo Reyes...\n",
      "http://ufcstats.com/fighter-details/edd02825c29028fe\n",
      "Scraping Dominick Reyes...\n",
      "http://ufcstats.com/fighter-details/2e19380f34871c6a\n",
      "Scraping Alex Reyes...\n",
      "http://ufcstats.com/fighter-details/dc07493a87dc0a6e\n",
      "Scraping Kyle Reyes...\n",
      "http://ufcstats.com/fighter-details/7333d6e0f6428acb\n",
      "Scraping Victor Reyna...\n",
      "http://ufcstats.com/fighter-details/e9bbcc6530e4cbe6\n",
      "Scraping Gaston Reyno...\n",
      "http://ufcstats.com/fighter-details/64db35f7782fe274\n",
      "Scraping Johnny Rhodes...\n",
      "http://ufcstats.com/fighter-details/319fa1bd3176bded\n",
      "Scraping Mike Rhodes...\n",
      "http://ufcstats.com/fighter-details/b7ad576b8ae115e6\n",
      "Scraping Lucrezia Ria...\n",
      "http://ufcstats.com/fighter-details/042cc07ad5a53a33\n",
      "Scraping Amanda Ribas...\n",
      "http://ufcstats.com/fighter-details/beecb672a279223e\n",
      "Scraping Vitor Ribeiro...\n",
      "http://ufcstats.com/fighter-details/a757c06bbdba61d2\n",
      "Scraping Will Ribeiro...\n",
      "http://ufcstats.com/fighter-details/8f4616698508f24d\n",
      "Scraping Claudio Ribeiro...\n",
      "http://ufcstats.com/fighter-details/972c456ff38b2015\n",
      "Scraping Brendson Ribeiro...\n",
      "http://ufcstats.com/fighter-details/49edd0d90f60fb7d\n",
      "Scraping Esteban Ribovics...\n",
      "http://ufcstats.com/fighter-details/323d4ca260dfa0ba\n",
      "Scraping Mike Ricci...\n",
      "http://ufcstats.com/fighter-details/3c921b1a30fdcbdd\n",
      "Scraping Alex Ricci...\n",
      "http://ufcstats.com/fighter-details/bf9bc96336922271\n",
      "Scraping Tabatha Ricci...\n",
      "http://ufcstats.com/fighter-details/d25240135aee03e5\n",
      "Scraping Matt Ricehouse...\n",
      "http://ufcstats.com/fighter-details/343d57cde1a14338\n",
      "Scraping John Richard...\n",
      "http://ufcstats.com/fighter-details/b3e5a460b6851080\n",
      "Scraping Rex Richards...\n",
      "http://ufcstats.com/fighter-details/ad23903ef3af7406\n",
      "Scraping Mike Richman...\n",
      "http://ufcstats.com/fighter-details/d6a740cf6e898e27\n",
      "Scraping Dave Rickels...\n",
      "http://ufcstats.com/fighter-details/98b76850b5f1e836\n",
      "Scraping Haisam Rida...\n",
      "http://ufcstats.com/fighter-details/d8a58e797518f011\n",
      "Scraping Brad Riddell...\n",
      "http://ufcstats.com/fighter-details/37ed1ab2f8b819f4\n",
      "Scraping Matthew Riddle...\n",
      "http://ufcstats.com/fighter-details/d023ae89a2a4a41e\n",
      "Scraping Joe Riggs...\n",
      "http://ufcstats.com/fighter-details/d512d9f204059f57\n",
      "Scraping Jeremiah Riggs...\n",
      "http://ufcstats.com/fighter-details/f1a9ad7485e5024a\n",
      "Scraping Aaron Riley...\n",
      "http://ufcstats.com/fighter-details/f2c8ebbeafd45f2b\n",
      "Scraping Jason Riley...\n",
      "http://ufcstats.com/fighter-details/995af04c697d78b7\n",
      "Scraping Luke Riley...\n",
      "http://ufcstats.com/fighter-details/b1de86d835638319\n",
      "Scraping Moise Rimbon...\n",
      "http://ufcstats.com/fighter-details/9be3728f3f7badb2\n",
      "Scraping Jordan Rinaldi...\n",
      "http://ufcstats.com/fighter-details/c07efc18b231f170\n",
      "Scraping Nick Ring...\n",
      "http://ufcstats.com/fighter-details/b13da0b1a3aed3e7\n",
      "Scraping Robbie Ring...\n",
      "http://ufcstats.com/fighter-details/fa9746fa5d23c202\n",
      "Scraping Mike Rio...\n",
      "http://ufcstats.com/fighter-details/af90b10c785ced3e\n",
      "Scraping Albert Rios...\n",
      "http://ufcstats.com/fighter-details/868a78f2e810a837\n",
      "Scraping Rafael Rios...\n",
      "http://ufcstats.com/fighter-details/2f5754b48eab1486\n",
      "Scraping Maria Rios...\n",
      "http://ufcstats.com/fighter-details/9ec12134b1515f12\n",
      "Scraping Shannon Ritch...\n",
      "http://ufcstats.com/fighter-details/1c7cce2f5c17160d\n",
      "Scraping Diego Rivas...\n",
      "http://ufcstats.com/fighter-details/09f579be4520394a\n",
      "Scraping Jorge Rivera...\n",
      "http://ufcstats.com/fighter-details/cb46dface0e28a2c\n",
      "Scraping Dante Rivera...\n",
      "http://ufcstats.com/fighter-details/288aaa8f82040e02\n",
      "Scraping Mario Rivera...\n",
      "http://ufcstats.com/fighter-details/0f7210aa8d61af8d\n",
      "Scraping Francisco Rivera...\n",
      "http://ufcstats.com/fighter-details/7ea4a9f07df33a45\n",
      "Scraping Jonathan Rivera...\n",
      "http://ufcstats.com/fighter-details/145df84ea4dfd904\n",
      "Scraping Jimmie Rivera...\n",
      "http://ufcstats.com/fighter-details/9c907996820d2d69\n",
      "Scraping Irwin Rivera...\n",
      "http://ufcstats.com/fighter-details/06a80a685ea98573\n",
      "Scraping Jerome Rivera...\n",
      "http://ufcstats.com/fighter-details/c9587d81e1d33925\n",
      "Scraping Nicdali Rivera-Calanoc...\n",
      "http://ufcstats.com/fighter-details/60917f79b7271d83\n",
      "Scraping Pedro Rizzo...\n",
      "http://ufcstats.com/fighter-details/b44f39a5c6596953\n",
      "Scraping Theo Rlayang...\n",
      "http://ufcstats.com/fighter-details/8aabef76351401d0\n",
      "Scraping Justin Robbins...\n",
      "http://ufcstats.com/fighter-details/3b2485c8d5c8b580\n",
      "Scraping Kali Robbins...\n",
      "http://ufcstats.com/fighter-details/610caee730f9b89e\n",
      "Scraping Karl Roberson...\n",
      "http://ufcstats.com/fighter-details/37d5b176d438d2a5\n",
      "Scraping Andre Roberts...\n",
      "http://ufcstats.com/fighter-details/a54a35a670d8e852\n",
      "Scraping David Roberts...\n",
      "http://ufcstats.com/fighter-details/775bad6d700d2302\n",
      "Scraping Joey Roberts...\n",
      "http://ufcstats.com/fighter-details/c058823a2595ab09\n",
      "Scraping Tyrone Roberts...\n",
      "http://ufcstats.com/fighter-details/d1e6a6536ee62517\n",
      "Scraping Ryan Roberts...\n",
      "http://ufcstats.com/fighter-details/35dc6220b113b7ec\n",
      "Scraping Taylor Roberts...\n",
      "http://ufcstats.com/fighter-details/c5ec23983dc2d8f4\n",
      "Scraping Daniel Roberts...\n",
      "http://ufcstats.com/fighter-details/22edaf53ad59a967\n",
      "Scraping Buddy Roberts...\n",
      "http://ufcstats.com/fighter-details/b2a2da86546ddb19\n",
      "Scraping Danny Roberts...\n",
      "http://ufcstats.com/fighter-details/a6cba6bb66c1a8c9\n",
      "Scraping Roosevelt Roberts...\n",
      "http://ufcstats.com/fighter-details/37c5366d18ed6c05\n",
      "Scraping Kenny Robertson...\n",
      "http://ufcstats.com/fighter-details/6e0273f9478be71e\n",
      "Scraping Gillian Robertson...\n",
      "http://ufcstats.com/fighter-details/38c7f72747f4f712\n",
      "Scraping Chad Robichaux...\n",
      "http://ufcstats.com/fighter-details/b2aa1e07b5b3306e\n",
      "Scraping Mark Robinson...\n",
      "http://ufcstats.com/fighter-details/4604ab1de9058474\n",
      "Scraping Colin Robinson...\n",
      "http://ufcstats.com/fighter-details/1a1a4d7a29041d77\n",
      "Scraping Alvin Robinson...\n",
      "http://ufcstats.com/fighter-details/cbe79765d44bd172\n",
      "Scraping Damonte Robinson...\n",
      "http://ufcstats.com/fighter-details/2782235b078b72a7\n",
      "Scraping Vagner Rocha...\n",
      "http://ufcstats.com/fighter-details/d403b1a6f278c95e\n",
      "Scraping Carlos Eduardo Rocha...\n",
      "http://ufcstats.com/fighter-details/4f736494fc733095\n",
      "Scraping Pedro Rocha...\n",
      "http://ufcstats.com/fighter-details/5921fd3f889afa3b\n",
      "Scraping Lucas Rocha...\n",
      "http://ufcstats.com/fighter-details/e0d3d9b564f95635\n",
      "Scraping Keith Rockel...\n",
      "http://ufcstats.com/fighter-details/c75b99887c8c3f5a\n",
      "Scraping Luke Rockhold...\n",
      "http://ufcstats.com/fighter-details/00e11b5c8b7bfeeb\n",
      "Scraping Kevin Roddy...\n",
      "http://ufcstats.com/fighter-details/1abf785143f8d5ec\n",
      "Scraping Gregory Rodrigues...\n",
      "http://ufcstats.com/fighter-details/d1c65d2cf2925ddd\n",
      "Scraping Kleydson Rodrigues...\n",
      "http://ufcstats.com/fighter-details/102a8fdf8cbf7467\n",
      "Scraping Paul Rodriguez...\n",
      "http://ufcstats.com/fighter-details/26eddcda9d6b2ffe\n",
      "Scraping Ricco Rodriguez...\n",
      "http://ufcstats.com/fighter-details/50cc91ce2982785d\n",
      "Scraping Manuel Rodriguez...\n",
      "http://ufcstats.com/fighter-details/5a6e4d2f0c76a242\n",
      "Scraping Yair Rodriguez...\n",
      "http://ufcstats.com/fighter-details/cbf5e6f231b55443\n",
      "Scraping Mike Rodriguez...\n",
      "http://ufcstats.com/fighter-details/18b602842a24f7c5\n",
      "Scraping Marina Rodriguez...\n",
      "http://ufcstats.com/fighter-details/cd2c4d30c6e13b47\n",
      "Scraping Daniel Rodriguez...\n",
      "http://ufcstats.com/fighter-details/8a1f3b5c526cd6e6\n",
      "Scraping Ray Rodriguez...\n",
      "http://ufcstats.com/fighter-details/90e0985df05e51bc\n",
      "Scraping Ronaldo Rodriguez...\n",
      "http://ufcstats.com/fighter-details/f2900678e98f6d6a\n",
      "Scraping Drako Rodriguez...\n",
      "http://ufcstats.com/fighter-details/dc3b9cf7641b7ab6\n",
      "Scraping Victor Rodriguez...\n",
      "http://ufcstats.com/fighter-details/f6e5972c9d16c40e\n",
      "Scraping Piera Rodriguez...\n",
      "http://ufcstats.com/fighter-details/e375cb5caf4717b6\n",
      "Scraping Christian Rodriguez...\n",
      "http://ufcstats.com/fighter-details/5ec591b78349ba7e\n",
      "Scraping Pete Rodriguez...\n",
      "http://ufcstats.com/fighter-details/776d4262c4da38bf\n",
      "Scraping Nick Roehrick...\n",
      "http://ufcstats.com/fighter-details/7195e2a932686f82\n",
      "Scraping Marcos Rogerio de Lima...\n",
      "http://ufcstats.com/fighter-details/ab943cd2c3c17825\n",
      "Scraping Brett Rogers...\n",
      "http://ufcstats.com/fighter-details/9141bb39310773c7\n",
      "Scraping Brian Rogers...\n",
      "http://ufcstats.com/fighter-details/f304aff405c4a8fa\n",
      "Scraping Pete Rogers Jr....\n",
      "http://ufcstats.com/fighter-details/36f3d235493d35ad\n",
      "Scraping Max Rohskopf...\n",
      "http://ufcstats.com/fighter-details/59a27d2e6d0802ac\n",
      "Scraping Marcelo Rojo...\n",
      "http://ufcstats.com/fighter-details/2804ce8dadab5770\n",
      "Scraping Shane Roller...\n",
      "http://ufcstats.com/fighter-details/75e0d3cc2262b732\n",
      "Scraping Jared Rollins...\n",
      "http://ufcstats.com/fighter-details/c4b6099f0d25f75e\n",
      "Scraping Tim Roman...\n",
      "http://ufcstats.com/fighter-details/3b83fec860a45ca1\n",
      "Scraping Alexandr Romanov...\n",
      "http://ufcstats.com/fighter-details/c0badf3243907e59\n",
      "Scraping Ricardo Romero...\n",
      "http://ufcstats.com/fighter-details/744e098e065cfdbe\n",
      "Scraping Yoel Romero...\n",
      "http://ufcstats.com/fighter-details/f77c68bb4be8516d\n",
      "Scraping Anthony Romero...\n",
      "http://ufcstats.com/fighter-details/6f81399074fcdbba\n",
      "Scraping Kaleio Romero...\n",
      "http://ufcstats.com/fighter-details/33df417d0017eb0c\n",
      "Scraping Mara Romero Borella...\n",
      "http://ufcstats.com/fighter-details/82cbb809d5ee565c\n",
      "Scraping Cortavious Romious...\n",
      "http://ufcstats.com/fighter-details/8173f134396cb971\n",
      "Scraping Juancamilo Ronderos...\n",
      "http://ufcstats.com/fighter-details/4a043165cf47cab2\n",
      "Scraping Rongzhu...\n",
      "http://ufcstats.com/fighter-details/a13d755965a4ec9f\n",
      "Scraping Jesse Ronson...\n",
      "http://ufcstats.com/fighter-details/5580771f383e141f\n",
      "Scraping George Roop...\n",
      "http://ufcstats.com/fighter-details/3c0437fbeda06962\n",
      "Scraping Joao Roque...\n",
      "http://ufcstats.com/fighter-details/0f6528b461e47462\n",
      "Scraping Aaron Rosa...\n",
      "http://ufcstats.com/fighter-details/11f8860028b68fcf\n",
      "Scraping Charles Rosa...\n",
      "http://ufcstats.com/fighter-details/40093d1d2d78394e\n",
      "Scraping Karol Rosa...\n",
      "http://ufcstats.com/fighter-details/351c4ec637380ad5\n",
      "Scraping Jacob Rosales...\n",
      "http://ufcstats.com/fighter-details/f7faf5b19e0dec2e\n",
      "Scraping Raul Rosas Jr....\n",
      "http://ufcstats.com/fighter-details/fe2babf95de24fb1\n",
      "Scraping Hilarie Rose...\n",
      "http://ufcstats.com/fighter-details/b9163ec845c3bfc8\n",
      "Scraping Jake Rosholt...\n",
      "http://ufcstats.com/fighter-details/4f2fcbefb668689d\n",
      "Scraping Jared Rosholt...\n",
      "http://ufcstats.com/fighter-details/91ea901c458e95dd\n",
      "Scraping Kevin Rosier...\n",
      "http://ufcstats.com/fighter-details/598a58db87b890ee\n",
      "Scraping Zach Rosol...\n",
      "http://ufcstats.com/fighter-details/208b6926916867c7\n",
      "Scraping Shannon Ross...\n",
      "http://ufcstats.com/fighter-details/51c655162e462ceb\n",
      "Scraping Nick Rossborough...\n",
      "http://ufcstats.com/fighter-details/ff3a915256b899c0\n",
      "Scraping Kristian Rothaermel...\n",
      "http://ufcstats.com/fighter-details/af49a6c491ca22a3\n",
      "Scraping Ben Rothwell...\n",
      "http://ufcstats.com/fighter-details/bd58d34e39b7b12a\n",
      "Scraping Rick Roufus...\n",
      "http://ufcstats.com/fighter-details/872b018076f831b0\n",
      "Scraping Khalil Rountree Jr....\n",
      "http://ufcstats.com/fighter-details/749f572d1d3161fb\n",
      "Scraping Ronda Rousey...\n",
      "http://ufcstats.com/fighter-details/8bdac25ce0bb874d\n",
      "Scraping Ray Routh...\n",
      "http://ufcstats.com/fighter-details/cba3a2dfbc06ce79\n",
      "Scraping Roberta Rovel...\n",
      "http://ufcstats.com/fighter-details/9d7fbf438766791f\n",
      "Scraping Phil Rowe...\n",
      "http://ufcstats.com/fighter-details/8e382b585a92affe\n",
      "Scraping Cam Rowston...\n",
      "http://ufcstats.com/fighter-details/8ebc3a8da015d70c\n",
      "Scraping Kain Royer...\n",
      "http://ufcstats.com/fighter-details/712aa894b3a344df\n",
      "Scraping Brad Royster...\n",
      "http://ufcstats.com/fighter-details/09f8c233de88998d\n",
      "Scraping Brandon Royval...\n",
      "http://ufcstats.com/fighter-details/6e15f63b6c2e2c15\n",
      "Scraping Jairzinho Rozenstruik...\n",
      "http://ufcstats.com/fighter-details/2cd428e9606856fd\n",
      "Scraping Mauricio Rua...\n",
      "http://ufcstats.com/fighter-details/140745cbbcb023ac\n",
      "Scraping Murilo Rua...\n",
      "http://ufcstats.com/fighter-details/90e7447d8b7f3f35\n",
      "Scraping Marco Ruas...\n",
      "http://ufcstats.com/fighter-details/597db668b01c442c\n",
      "Scraping Rodrigo Ruas...\n",
      "http://ufcstats.com/fighter-details/94070f6544c4b2a5\n",
      "Scraping Rodolfo Rubio Perez...\n",
      "http://ufcstats.com/fighter-details/c4731f43693b96b8\n",
      "Scraping Gabe Ruediger...\n",
      "http://ufcstats.com/fighter-details/ccba80d4820ef557\n",
      "Scraping Mauricio Ruffy...\n",
      "http://ufcstats.com/fighter-details/9c393e836a852f30\n",
      "Scraping Eddie Ruiz...\n",
      "http://ufcstats.com/fighter-details/7b9aa973e5c04624\n",
      "Scraping Anthony Ruiz...\n",
      "http://ufcstats.com/fighter-details/657c21cb133f1445\n",
      "Scraping Paul Ruiz...\n",
      "http://ufcstats.com/fighter-details/babc0b19e89cec6e\n",
      "Scraping Montserrat Conejo Ruiz...\n",
      "http://ufcstats.com/fighter-details/1235b31de15d0c6e\n",
      "Scraping Mike Russow...\n",
      "http://ufcstats.com/fighter-details/353de740bb6c7e75\n",
      "Scraping Bas Rutten...\n",
      "http://ufcstats.com/fighter-details/03688dc3c3af3ac1\n",
      "Scraping Nursulton Ruziboev...\n",
      "http://ufcstats.com/fighter-details/49d2a08964c5eb11\n",
      "Scraping Casey Ryan...\n",
      "http://ufcstats.com/fighter-details/5b1b383265433f51\n",
      "Scraping Yusup Saadulaev...\n",
      "http://ufcstats.com/fighter-details/b1669a810fae4220\n",
      "Scraping Cameron Saaiman...\n",
      "http://ufcstats.com/fighter-details/3c8a5200436e19f3\n",
      "Scraping Pete Sabala...\n",
      "http://ufcstats.com/fighter-details/7956f026e2672c47\n",
      "Scraping Danny Sabatello...\n",
      "http://ufcstats.com/fighter-details/cb7ee07982de2a28\n",
      "Scraping Pat Sabatini...\n",
      "http://ufcstats.com/fighter-details/b8bbdeff718dbb7d\n",
      "Scraping Amir Sadollah...\n",
      "http://ufcstats.com/fighter-details/2650e2f846a30f64\n",
      "Scraping Nazim Sadykhov...\n",
      "http://ufcstats.com/fighter-details/ff62013d2fce6d13\n",
      "Scraping Frankie Saenz...\n",
      "http://ufcstats.com/fighter-details/9ba2226646046b63\n",
      "Scraping Saparbeg Safarov...\n",
      "http://ufcstats.com/fighter-details/88d7b6d8230e1f3f\n",
      "Scraping Tarec Saffiedine...\n",
      "http://ufcstats.com/fighter-details/0749d968e932df53\n",
      "Scraping Jason Saggo...\n",
      "http://ufcstats.com/fighter-details/4ac1ecf8ce59ef23\n",
      "Scraping Kiru Sahota...\n",
      "http://ufcstats.com/fighter-details/296a120cb880477b\n",
      "Scraping Tatsuya Saika...\n",
      "http://ufcstats.com/fighter-details/cc4e571964b084d4\n",
      "Scraping Benoit Saint Denis...\n",
      "http://ufcstats.com/fighter-details/c2299ec916bc7c56\n",
      "Scraping Lukasz Sajewski...\n",
      "http://ufcstats.com/fighter-details/fb41432b622992a9\n",
      "Scraping Yukio Sakaguchi...\n",
      "http://ufcstats.com/fighter-details/94a5aaf573f780ad\n",
      "Scraping Augusto Sakai...\n",
      "http://ufcstats.com/fighter-details/441eacbe20e0e80b\n",
      "Scraping Alessio Sakara...\n",
      "http://ufcstats.com/fighter-details/7f955f71fa2ce7ac\n",
      "Scraping Wataru Sakata...\n",
      "http://ufcstats.com/fighter-details/d7907a9a968e4d29\n",
      "Scraping Gokhan Saki...\n",
      "http://ufcstats.com/fighter-details/4690d47bf725fd98\n",
      "Scraping Kazushi Sakuraba...\n",
      "http://ufcstats.com/fighter-details/9b5b5a75523728f3\n",
      "Scraping Hayato Sakurai...\n",
      "http://ufcstats.com/fighter-details/85e26e2468b4e82f\n",
      "Scraping Ryuta Sakurai...\n",
      "http://ufcstats.com/fighter-details/ff9578cdbfabd323\n",
      "Scraping Justin Salas...\n",
      "http://ufcstats.com/fighter-details/9b198c73e3d0d289\n",
      "Scraping Ivan Salaverry...\n",
      "http://ufcstats.com/fighter-details/394f55ebca199124\n",
      "Scraping Roman Salazar...\n",
      "http://ufcstats.com/fighter-details/72c4b253d2f5ebf2\n",
      "Scraping Luis Saldana...\n",
      "http://ufcstats.com/fighter-details/12e0fdc606f7e274\n",
      "Scraping John Salgado...\n",
      "http://ufcstats.com/fighter-details/3e36811b7bc1f6ad\n",
      "Scraping Muslim Salikhov...\n",
      "http://ufcstats.com/fighter-details/447f9858ae78f921\n",
      "Scraping Gabriel Salinas-Jones...\n",
      "http://ufcstats.com/fighter-details/74d5f71eeb0c66c7\n",
      "Scraping Brandon Saling...\n",
      "http://ufcstats.com/fighter-details/a049aa06508b9c7b\n",
      "Scraping Quillan Salkilld...\n",
      "http://ufcstats.com/fighter-details/17734443a833cdf7\n",
      "Scraping Sean Salmon...\n",
      "http://ufcstats.com/fighter-details/7c0847d3854a95f2\n",
      "Scraping Boston Salmon...\n",
      "http://ufcstats.com/fighter-details/98e946879ba20c0f\n",
      "Scraping John Salter...\n",
      "http://ufcstats.com/fighter-details/010986ee359fb863\n",
      "Scraping Vinicius Salvador...\n",
      "http://ufcstats.com/fighter-details/65cdf4ec31143d86\n",
      "Scraping Dylan Salvador...\n",
      "http://ufcstats.com/fighter-details/a7a3fb5f6c67b122\n",
      "Scraping Josh Samman...\n",
      "http://ufcstats.com/fighter-details/9deff9e3e8d94d47\n",
      "Scraping Johnny Sampaio...\n",
      "http://ufcstats.com/fighter-details/b23388ff8ac6637b\n",
      "Scraping Josh Sampo...\n",
      "http://ufcstats.com/fighter-details/f65dcb22dada2223\n",
      "Scraping Josh San Diego...\n",
      "http://ufcstats.com/fighter-details/983e281d257c24dc\n",
      "Scraping Diego Sanchez...\n",
      "http://ufcstats.com/fighter-details/82e7929bf6c2b689\n",
      "Scraping Eddie Sanchez...\n",
      "http://ufcstats.com/fighter-details/7f0b4a75ef3039a3\n",
      "Scraping Julian Sanchez...\n",
      "http://ufcstats.com/fighter-details/c6da1c24fe473418\n",
      "Scraping Bobby Sanchez...\n",
      "http://ufcstats.com/fighter-details/6a0047ac8c99fece\n",
      "Scraping Donald Sanchez...\n",
      "http://ufcstats.com/fighter-details/bb140b121283acbb\n",
      "Scraping Joby Sanchez...\n",
      "http://ufcstats.com/fighter-details/b12fc8a41e82d3a2\n",
      "Scraping Emmanuel Sanchez...\n",
      "http://ufcstats.com/fighter-details/243a336eaa2d2eb4\n",
      "Scraping Erick Sanchez...\n",
      "http://ufcstats.com/fighter-details/ef3663798164adf0\n",
      "Scraping Andrew Sanchez...\n",
      "http://ufcstats.com/fighter-details/fccf811c1e8b01c7\n",
      "Scraping Robert Sanchez...\n",
      "http://ufcstats.com/fighter-details/546f8599a63c29da\n",
      "Scraping Jesse Sanders...\n",
      "http://ufcstats.com/fighter-details/59aaf2730b84698a\n",
      "Scraping Luke Sanders...\n",
      "http://ufcstats.com/fighter-details/96428b9e9bd048ea\n",
      "Scraping Jerrod Sanders...\n",
      "http://ufcstats.com/fighter-details/12f1b140e248bdb9\n",
      "Scraping Cory Sandhagen...\n",
      "http://ufcstats.com/fighter-details/65f09bacd3957381\n",
      "Scraping Hugo Sandoval...\n",
      "http://ufcstats.com/fighter-details/9d51bcc281aa0514\n",
      "Scraping Raul Sandoval...\n",
      "http://ufcstats.com/fighter-details/f9ad10f6a49e5452\n",
      "Scraping Joseph Sandoval...\n",
      "http://ufcstats.com/fighter-details/696002b59f09d73b\n",
      "Scraping Hector Sandoval...\n",
      "http://ufcstats.com/fighter-details/449c890bd90f3374\n",
      "Scraping Roldan Sangcha'an...\n",
      "http://ufcstats.com/fighter-details/57887765f831e228\n",
      "Scraping Yuhi Sano...\n",
      "http://ufcstats.com/fighter-details/4c12aa7ca246e7a4\n",
      "Scraping Martin Sano...\n",
      "http://ufcstats.com/fighter-details/16a64f93f6678b7b\n",
      "Scraping Jonathan Santa Maria...\n",
      "http://ufcstats.com/fighter-details/3143e5daff9e5b71\n",
      "Scraping Duda Santana...\n",
      "http://ufcstats.com/fighter-details/d6ead04919a894b1\n",
      "Scraping Shaheen Santana...\n",
      "http://ufcstats.com/fighter-details/19809d475ed832d5\n",
      "Scraping Sean Santella...\n",
      "http://ufcstats.com/fighter-details/39792c2f42c9f527\n",
      "Scraping Jorge Santiago...\n",
      "http://ufcstats.com/fighter-details/f8dc544e7077d014\n",
      "Scraping Will Santiago...\n",
      "http://ufcstats.com/fighter-details/4920292f5d9b76df\n",
      "Scraping Richie Santiago...\n",
      "http://ufcstats.com/fighter-details/9f95d6b5b459cc6b\n",
      "Scraping Jose Santibanez...\n",
      "http://ufcstats.com/fighter-details/8299206ccebc44a7\n",
      "Scraping Art Santore...\n",
      "http://ufcstats.com/fighter-details/012fc7cd0779c09a\n",
      "Scraping Adriano Santos...\n",
      "http://ufcstats.com/fighter-details/c6e6926a81adcd00\n",
      "Scraping Paulo Santos...\n",
      "http://ufcstats.com/fighter-details/7ca4c3f8aa8bacae\n",
      "Scraping Evangelista Santos...\n",
      "http://ufcstats.com/fighter-details/99bf06f20491cb54\n",
      "Scraping Luis Santos...\n",
      "http://ufcstats.com/fighter-details/7701377be464d2ef\n",
      "Scraping Iliarde Santos...\n",
      "http://ufcstats.com/fighter-details/14aa21bc82cac57d\n",
      "Scraping Leonardo Santos...\n",
      "http://ufcstats.com/fighter-details/9c65736747ca92ec\n",
      "Scraping Thiago Santos...\n",
      "http://ufcstats.com/fighter-details/dea070ed4a2a8281\n",
      "Scraping Bruno Santos...\n",
      "http://ufcstats.com/fighter-details/da1d8d76404bb6b5\n",
      "Scraping Andre Santos...\n",
      "http://ufcstats.com/fighter-details/5b5b78116d1fc3eb\n",
      "Scraping Gleristone Santos...\n",
      "http://ufcstats.com/fighter-details/d12ee718fb35c35c\n",
      "Scraping Yana Santos...\n",
      "http://ufcstats.com/fighter-details/3143bf892608139a\n",
      "Scraping Taila Santos...\n",
      "http://ufcstats.com/fighter-details/f7467152fd9f18a2\n",
      "Scraping Marilia Santos...\n",
      "http://ufcstats.com/fighter-details/4cb79988b2a9bd07\n",
      "Scraping Edivan Santos...\n",
      "http://ufcstats.com/fighter-details/78719f6663ad9160\n",
      "Scraping Daniel Santos...\n",
      "http://ufcstats.com/fighter-details/b67d6bacc68d4c92\n",
      "Scraping Gabriel Santos...\n",
      "http://ufcstats.com/fighter-details/f2f140ce7532e327\n",
      "Scraping Luana Santos...\n",
      "http://ufcstats.com/fighter-details/5078e1dacf9d25f4\n",
      "Scraping Djorden Santos...\n",
      "http://ufcstats.com/fighter-details/312f7d7b2b2f7de4\n",
      "Scraping Mairon Santos...\n",
      "http://ufcstats.com/fighter-details/480779d7f9a424d3\n",
      "Scraping Nick Sanzo...\n",
      "http://ufcstats.com/fighter-details/1d147d4163a6989b\n",
      "Scraping Bob Sapp...\n",
      "http://ufcstats.com/fighter-details/9f3d6ddef3d3cccc\n",
      "Scraping Daniel Sarafian...\n",
      "http://ufcstats.com/fighter-details/7e47047d0971d566\n",
      "Scraping Jeka Saragih...\n",
      "http://ufcstats.com/fighter-details/57186c150c645200\n",
      "Scraping Diego Saraiva...\n",
      "http://ufcstats.com/fighter-details/4f4dac51adc1af4f\n",
      "Scraping Harris Sarmiento...\n",
      "http://ufcstats.com/fighter-details/026b4f7049085842\n",
      "Scraping Alexander Sarnavskiy...\n",
      "http://ufcstats.com/fighter-details/2097b1a5ff47dfb0\n",
      "Scraping Yuki Sasaki...\n",
      "http://ufcstats.com/fighter-details/e5c38954c006f15c\n",
      "Scraping Kyosuke Sasaki...\n",
      "http://ufcstats.com/fighter-details/23bd78c3f89bdb54\n",
      "Scraping Yuta Sasaki...\n",
      "http://ufcstats.com/fighter-details/7c3c48cf54a2848e\n",
      "Scraping Paul Sass...\n",
      "http://ufcstats.com/fighter-details/7b143a54451263d9\n",
      "Scraping Keisuke Sasu...\n",
      "http://ufcstats.com/fighter-details/b7bcf6dfbbb7c16c\n",
      "Scraping Masaaki Satake...\n",
      "http://ufcstats.com/fighter-details/f4a031ac205ac580\n",
      "Scraping Takenori Sato...\n",
      "http://ufcstats.com/fighter-details/276c60b14b571dd4\n",
      "Scraping Takashi Sato...\n",
      "http://ufcstats.com/fighter-details/8abac218746e04ca\n",
      "Scraping Uran Satybaldiev...\n",
      "http://ufcstats.com/fighter-details/02f484417a6fa69d\n",
      "Scraping Jeimeson Saudino...\n",
      "http://ufcstats.com/fighter-details/f6f9d41669dd3eaa\n",
      "Scraping Tom Sauer...\n",
      "http://ufcstats.com/fighter-details/36ab6af06e312b41\n",
      "Scraping Townsend Saunders...\n",
      "http://ufcstats.com/fighter-details/20bd6c3e03c46ee6\n",
      "Scraping Ben Saunders...\n",
      "http://ufcstats.com/fighter-details/484acc7b0f856ce9\n",
      "Scraping Chad W. Saunders...\n",
      "http://ufcstats.com/fighter-details/4fe9492959834bf7\n",
      "Scraping Chris Saunders...\n",
      "http://ufcstats.com/fighter-details/b35a159f525764eb\n",
      "Scraping Christien Savoie...\n",
      "http://ufcstats.com/fighter-details/67f0d1b1b0b39bec\n",
      "Scraping Lumumba Sayers...\n",
      "http://ufcstats.com/fighter-details/402ea3b5ee233852\n",
      "Scraping Matt Sayles...\n",
      "http://ufcstats.com/fighter-details/5b8ba8f5512893b1\n",
      "Scraping Brandon Sayles...\n",
      "http://ufcstats.com/fighter-details/72b7c071910990b1\n",
      "Scraping Mikheil Sazhiniani...\n",
      "http://ufcstats.com/fighter-details/22a1f83edb865aee\n",
      "Scraping Mark Scanlon...\n",
      "http://ufcstats.com/fighter-details/771b60ff889661c8\n",
      "Scraping Eric Schafer...\n",
      "http://ufcstats.com/fighter-details/f59f1d3a2ff13edd\n",
      "Scraping Kerry Schall...\n",
      "http://ufcstats.com/fighter-details/030f08370fd1c2bb\n",
      "Scraping Eric Schambari...\n",
      "http://ufcstats.com/fighter-details/66e981516e2476d1\n",
      "Scraping Brendan Schaub...\n",
      "http://ufcstats.com/fighter-details/89a407032911e27e\n",
      "Scraping Matheus Scheffel...\n",
      "http://ufcstats.com/fighter-details/a296ad1d238d97df\n",
      "Scraping Antonio Schembri...\n",
      "http://ufcstats.com/fighter-details/a3244e3238541482\n",
      "Scraping Fabiano Scherner...\n",
      "http://ufcstats.com/fighter-details/0bc7e61d204f2137\n",
      "Scraping Samy Schiavo...\n",
      "http://ufcstats.com/fighter-details/1208ffc5be6e31ad\n",
      "Scraping Pat Schilling...\n",
      "http://ufcstats.com/fighter-details/de12bd65e2f46478\n",
      "Scraping Joe Schilling...\n",
      "http://ufcstats.com/fighter-details/f41fad444939056b\n",
      "Scraping Semmy Schilt...\n",
      "http://ufcstats.com/fighter-details/d5ed14b2153c6ed2\n",
      "Scraping Adam Schindler...\n",
      "http://ufcstats.com/fighter-details/89ea01f5a7ada40c\n",
      "Scraping Daniel Schmitt...\n",
      "http://ufcstats.com/fighter-details/bd02e222a6166d50\n",
      "Scraping Colleen Schneider...\n",
      "http://ufcstats.com/fighter-details/aa943b9bc00cb0ed\n",
      "Scraping Matt Schnell...\n",
      "http://ufcstats.com/fighter-details/67c1d46f4ed16f9e\n",
      "Scraping Alex Schoenauer...\n",
      "http://ufcstats.com/fighter-details/fdfef29ba17ee525\n",
      "Scraping Bailey Schoenfelder...\n",
      "http://ufcstats.com/fighter-details/b0353e7f5038dd09\n",
      "Scraping Darrill Schoonover...\n",
      "http://ufcstats.com/fighter-details/5a558ba1ff5e9121\n",
      "Scraping Bob Schrijber...\n",
      "http://ufcstats.com/fighter-details/d86e913c548c07c2\n",
      "Scraping Nate Schroeder...\n",
      "http://ufcstats.com/fighter-details/040426baba8a45e8\n",
      "Scraping Lacey Schuckman...\n",
      "http://ufcstats.com/fighter-details/e44c679c30403cba\n",
      "Scraping Mark Schultz...\n",
      "http://ufcstats.com/fighter-details/c1684f00c626f4c0\n",
      "Scraping Wes Schultz...\n",
      "http://ufcstats.com/fighter-details/b4443fae47e7eb9d\n",
      "Scraping Eric Schwartz...\n",
      "http://ufcstats.com/fighter-details/79cbdf233e5e0496\n",
      "Scraping Justin Scoggins...\n",
      "http://ufcstats.com/fighter-details/9fa568ad2bf2cb0b\n",
      "Scraping Brad Scott...\n",
      "http://ufcstats.com/fighter-details/34e552520a934063\n",
      "Scraping Greg Scott...\n",
      "http://ufcstats.com/fighter-details/0b235384fe23fc9c\n",
      "Scraping Louis Lee Scott...\n",
      "http://ufcstats.com/fighter-details/4327506eb9ee342f\n",
      "Scraping Mike Seal...\n",
      "http://ufcstats.com/fighter-details/0c01568b1ac77bff\n",
      "Scraping Matt Secor...\n",
      "http://ufcstats.com/fighter-details/d1ce40aca99a9b70\n",
      "Scraping Kenneth Seegrist...\n",
      "http://ufcstats.com/fighter-details/55e94a9b525dcf45\n",
      "Scraping Neil Seery...\n",
      "http://ufcstats.com/fighter-details/49a74b9fb2e45fdf\n",
      "Scraping Rony Sefo...\n",
      "http://ufcstats.com/fighter-details/d6b68eaf4b68b160\n",
      "Scraping Ray Sefo...\n",
      "http://ufcstats.com/fighter-details/646d5dbe509accd4\n",
      "Scraping Brendan Seguin...\n",
      "http://ufcstats.com/fighter-details/e4bb7e483c4ad318\n",
      "Scraping Tetsuya Seki...\n",
      "http://ufcstats.com/fighter-details/5e1062e066c601e6\n",
      "Scraping Stefan Sekulic...\n",
      "http://ufcstats.com/fighter-details/348dff4e03bd18c6\n",
      "Scraping Pete Sell...\n",
      "http://ufcstats.com/fighter-details/0359313549d230a1\n",
      "Scraping Matthew Semelsberger...\n",
      "http://ufcstats.com/fighter-details/4aa58269d0664b5b\n",
      "Scraping Andrei Semenov...\n",
      "http://ufcstats.com/fighter-details/5f2f0da6fd6a84fd\n",
      "Scraping Mackens Semerzier...\n",
      "http://ufcstats.com/fighter-details/51b1e2fd9872005b\n",
      "Scraping Brandon Sene...\n",
      "http://ufcstats.com/fighter-details/3ed134d85dfbd7b4\n",
      "Scraping YeDam Seo...\n",
      "http://ufcstats.com/fighter-details/762572d67204fadb\n",
      "Scraping Kim In Seok...\n",
      "http://ufcstats.com/fighter-details/88b250ba222c3a98\n",
      "Scraping Ray Seraille...\n",
      "http://ufcstats.com/fighter-details/2f04c4183523be2e\n",
      "Scraping Ivan Serati...\n",
      "http://ufcstats.com/fighter-details/b23fca14c7b79935\n",
      "Scraping Alex Serdyukov...\n",
      "http://ufcstats.com/fighter-details/253d3f9e97ca149a\n",
      "Scraping Nicholas Sergiacomi...\n",
      "http://ufcstats.com/fighter-details/efab191f204ffa17\n",
      "Scraping Matt Serra...\n",
      "http://ufcstats.com/fighter-details/86dfed7cc24a9fa7\n",
      "Scraping Nick Serra...\n",
      "http://ufcstats.com/fighter-details/1975c2272ba40e71\n",
      "Scraping Adrian Serrano...\n",
      "http://ufcstats.com/fighter-details/e7ec11096eac0282\n",
      "Scraping Fredy Serrano...\n",
      "http://ufcstats.com/fighter-details/0ccab7c889ede9ea\n",
      "Scraping Carl Seumanutafa...\n",
      "http://ufcstats.com/fighter-details/dadaeb402526dca5\n",
      "Scraping Igor Severino...\n",
      "http://ufcstats.com/fighter-details/6ad8e4296f7522d9\n",
      "Scraping Dan Severn...\n",
      "http://ufcstats.com/fighter-details/c670aa48827d6be6\n",
      "Scraping Rosi Sexton...\n",
      "http://ufcstats.com/fighter-details/5dfe71ade71f3a4b\n",
      "Scraping Scott Shaffer...\n",
      "http://ufcstats.com/fighter-details/5c38639f860a5542\n",
      "Scraping Edmen Shahbazyan...\n",
      "http://ufcstats.com/fighter-details/4144798612ef96e5\n",
      "Scraping Leon Shahbazyan...\n",
      "http://ufcstats.com/fighter-details/9eed2bcc9e0b92af\n",
      "Scraping Don Shainis...\n",
      "http://ufcstats.com/fighter-details/da4628f173337902\n",
      "Scraping Liliya Shakirova...\n",
      "http://ufcstats.com/fighter-details/f300763147320d12\n",
      "Scraping Kamal Shalorus...\n",
      "http://ufcstats.com/fighter-details/ece280745f8727b8\n",
      "Scraping Ken Shamrock...\n",
      "http://ufcstats.com/fighter-details/63b65af1c5cb02cb\n",
      "Scraping Frank Shamrock...\n",
      "http://ufcstats.com/fighter-details/fcaae0385b514f11\n",
      "Scraping Shang Zhifa...\n",
      "http://ufcstats.com/fighter-details/5a7350645bc9bd6e\n",
      "Scraping Sean Sharaf...\n",
      "http://ufcstats.com/fighter-details/0f3a990526c5e706\n",
      "Scraping Priya Sharma...\n",
      "http://ufcstats.com/fighter-details/5f23eaf9e9c34667\n",
      "Scraping Jason Sharp...\n",
      "http://ufcstats.com/fighter-details/285e32e41f61a5b1\n",
      "Scraping Eric Shelton...\n",
      "http://ufcstats.com/fighter-details/a0c64f272b65d441\n",
      "Scraping Sean Sherk...\n",
      "http://ufcstats.com/fighter-details/029880cdbf5ca089\n",
      "Scraping Chase Sherman...\n",
      "http://ufcstats.com/fighter-details/01b352b6a9074d5c\n",
      "Scraping Valentina Shevchenko...\n",
      "http://ufcstats.com/fighter-details/132deb59abae64b1\n",
      "Scraping Antonina Shevchenko...\n",
      "http://ufcstats.com/fighter-details/d7338bcb141abd2c\n",
      "Scraping Shi Ming...\n",
      "http://ufcstats.com/fighter-details/d683f4870742b273\n",
      "Scraping Katsuyori Shibata...\n",
      "http://ufcstats.com/fighter-details/d4da8995fc91e7ef\n",
      "Scraping Jake Shields...\n",
      "http://ufcstats.com/fighter-details/fe435e440b5de0ff\n",
      "Scraping Henrique Shiguemoto...\n",
      "http://ufcstats.com/fighter-details/5d1700cfbaafbe06\n",
      "Scraping Shunichi Shimizu...\n",
      "http://ufcstats.com/fighter-details/10657c60ce349e0f\n",
      "Scraping Wade Shipp...\n",
      "http://ufcstats.com/fighter-details/a9a314cc77d90b6e\n",
      "Scraping Raja Shippen...\n",
      "http://ufcstats.com/fighter-details/d9e1942637bd57a4\n",
      "Scraping Yuya Shirai...\n",
      "http://ufcstats.com/fighter-details/a79bfbc01b2264d6\n",
      "Scraping Wes Shivers...\n",
      "http://ufcstats.com/fighter-details/ad863b0d57952c57\n",
      "Scraping Alexander Shlemenko...\n",
      "http://ufcstats.com/fighter-details/ed3ea649b34ddb6c\n",
      "Scraping Josh Shockley...\n",
      "http://ufcstats.com/fighter-details/1d36f1ac66cf689d\n",
      "Scraping Josh Shockman...\n",
      "http://ufcstats.com/fighter-details/821cd80aab70d5f9\n",
      "Scraping Akira Shoji...\n",
      "http://ufcstats.com/fighter-details/b0c95dc8e858452c\n",
      "Scraping Liudvik Sholinian...\n",
      "http://ufcstats.com/fighter-details/1a54231796e24a3f\n",
      "Scraping Jack Shore...\n",
      "http://ufcstats.com/fighter-details/b8a85389d115e35a\n",
      "Scraping Landon Showalter...\n",
      "http://ufcstats.com/fighter-details/35cc17760b06f36d\n",
      "Scraping Ivan Shtyrkov...\n",
      "http://ufcstats.com/fighter-details/1f4b1d7d12601c5f\n",
      "Scraping Brandon Shuey...\n",
      "http://ufcstats.com/fighter-details/585f9ffdb0cd0466\n",
      "Scraping Ronal Siahaan...\n",
      "http://ufcstats.com/fighter-details/762226efa2b01654\n",
      "Scraping Sam Sicilia...\n",
      "http://ufcstats.com/fighter-details/b8aef0faf4ce9b31\n",
      "Scraping Kiril Sidelnikov...\n",
      "http://ufcstats.com/fighter-details/cf772fb504842dc3\n",
      "Scraping Serhiy Sidey...\n",
      "http://ufcstats.com/fighter-details/1a2bf44edb8055b6\n",
      "Scraping Steven Siler...\n",
      "http://ufcstats.com/fighter-details/d188a3b817860ec6\n",
      "Scraping Siala Siliga...\n",
      "http://ufcstats.com/fighter-details/3cf68c1d17f66af7\n",
      "Scraping Xavier Siller...\n",
      "http://ufcstats.com/fighter-details/9a08c2753184ac6d\n",
      "Scraping Assuerio Silva...\n",
      "http://ufcstats.com/fighter-details/e091482fa6648261\n",
      "Scraping Anderson Silva...\n",
      "http://ufcstats.com/fighter-details/1f454354805b6f75\n",
      "Scraping Wanderlei Silva...\n",
      "http://ufcstats.com/fighter-details/a1f6999fe57236e0\n",
      "Scraping Thiago Silva...\n",
      "http://ufcstats.com/fighter-details/2924886ee9c4c527\n",
      "Scraping Paulo Cesar Silva...\n",
      "http://ufcstats.com/fighter-details/55b8dc4e54fe2c59\n",
      "Scraping Jean Silva...\n",
      "http://ufcstats.com/fighter-details/9211aae062b799d6\n",
      "Scraping Edson Silva...\n",
      "http://ufcstats.com/fighter-details/a1153013cb5f628f\n",
      "Scraping Sidney Silva...\n",
      "http://ufcstats.com/fighter-details/a6c32678efd4f434\n",
      "Scraping Jay Silva...\n",
      "http://ufcstats.com/fighter-details/53bb0d40905b87c0\n",
      "Scraping Antonio Silva...\n",
      "http://ufcstats.com/fighter-details/8349d55cdecd393a\n",
      "Scraping Fabio Silva...\n",
      "http://ufcstats.com/fighter-details/2ba479b409011527\n",
      "Scraping Erick Silva...\n",
      "http://ufcstats.com/fighter-details/5866fc86183a9fb8\n",
      "Scraping Leandro Silva...\n",
      "http://ufcstats.com/fighter-details/159da492e000afbf\n",
      "Scraping Claudio Silva...\n",
      "http://ufcstats.com/fighter-details/6f7c616b98e18c29\n",
      "Scraping Wagner Silva...\n",
      "http://ufcstats.com/fighter-details/fb79582c410d049e\n",
      "Scraping Rafael Silva...\n",
      "http://ufcstats.com/fighter-details/a31358d90d4bb40a\n",
      "Scraping Joaquim Silva...\n",
      "http://ufcstats.com/fighter-details/ae7fe94f117f98cf\n",
      "Scraping Felipe Silva...\n",
      "http://ufcstats.com/fighter-details/1b38a2b897f6209c\n",
      "Scraping Dayana Silva...\n",
      "http://ufcstats.com/fighter-details/b19aecbfbb5508cc\n",
      "Scraping Bruno Silva...\n",
      "http://ufcstats.com/fighter-details/294aa73dbf37d281\n",
      "Scraping Bruno Silva...\n",
      "http://ufcstats.com/fighter-details/12ebd7d157e91701\n",
      "Scraping Gabriel Silva...\n",
      "http://ufcstats.com/fighter-details/002ca196477ce572\n",
      "Scraping Jacob Silva...\n",
      "http://ufcstats.com/fighter-details/f6f2ea21a67be3a7\n",
      "Scraping Natalia Silva...\n",
      "http://ufcstats.com/fighter-details/262d32ebda89efc4\n",
      "Scraping Jansey Silva...\n",
      "http://ufcstats.com/fighter-details/0d09efd31eb9fadf\n",
      "Scraping Maria Silva...\n",
      "http://ufcstats.com/fighter-details/4408865b4e65e374\n",
      "Scraping Karine Silva...\n",
      "http://ufcstats.com/fighter-details/9d62c2d8ee151f08\n",
      "Scraping Erik Silva...\n",
      "http://ufcstats.com/fighter-details/21b813b919776d90\n",
      "Scraping Janaina Silva...\n",
      "http://ufcstats.com/fighter-details/4784a5b4a452464a\n",
      "Scraping Jhonata Silva...\n",
      "http://ufcstats.com/fighter-details/4e33534d1e036444\n",
      "Scraping Jean Silva...\n",
      "http://ufcstats.com/fighter-details/52ef95b5860fb28c\n",
      "Scraping Danny Silva...\n",
      "http://ufcstats.com/fighter-details/d964a59c48381cb6\n",
      "Scraping Douglas Silva de Andrade...\n",
      "http://ufcstats.com/fighter-details/3a314d9fa7c6825d\n",
      "Scraping Leonardo Silva de Oliveira...\n",
      "http://ufcstats.com/fighter-details/28e088bbcaaa6366\n",
      "Scraping Marcus Silveira...\n",
      "http://ufcstats.com/fighter-details/f717b6002486f73f\n",
      "Scraping Elias Silverio...\n",
      "http://ufcstats.com/fighter-details/52ba464d9068d871\n",
      "Scraping Sim Kai Xiong...\n",
      "http://ufcstats.com/fighter-details/79e2cb1e813f881b\n",
      "Scraping Jamey Simmons...\n",
      "http://ufcstats.com/fighter-details/f0fad0e9f3b65752\n",
      "Scraping Ricky Simon...\n",
      "http://ufcstats.com/fighter-details/5987b2458f4b5290\n",
      "Scraping Aaron Simpson...\n",
      "http://ufcstats.com/fighter-details/d5f820c11a121050\n",
      "Scraping Wes Sims...\n",
      "http://ufcstats.com/fighter-details/e0f7c4f3f67bc808\n",
      "Scraping Marlon Sims...\n",
      "http://ufcstats.com/fighter-details/9eedac48b497de5a\n",
      "Scraping Tony Sims...\n",
      "http://ufcstats.com/fighter-details/57bad6a84230f0c9\n",
      "Scraping Everett Sims...\n",
      "http://ufcstats.com/fighter-details/59c6d5af765df641\n",
      "Scraping Lodune Sincaid...\n",
      "http://ufcstats.com/fighter-details/265589bdd93e7ce5\n",
      "Scraping Rob Sinclair...\n",
      "http://ufcstats.com/fighter-details/3b65c9dd39741bc4\n",
      "Scraping Rory Singer...\n",
      "http://ufcstats.com/fighter-details/546015aa2ad945fd\n",
      "Scraping Rana Rudra Pratap Singh...\n",
      "http://ufcstats.com/fighter-details/254ed71756cfd18c\n",
      "Scraping Kiran Singh...\n",
      "http://ufcstats.com/fighter-details/f985ca2370a37078\n",
      "Scraping Elvis Sinosic...\n",
      "http://ufcstats.com/fighter-details/817e0bdf08efce2e\n",
      "Scraping Mitchell Sipe...\n",
      "http://ufcstats.com/fighter-details/71ef1111bf829b82\n",
      "Scraping Gian Siqueira...\n",
      "http://ufcstats.com/fighter-details/a46fdda658fee832\n",
      "Scraping Jeremia Siregar...\n",
      "http://ufcstats.com/fighter-details/a7ac3b1b0c4146db\n",
      "Scraping AJ Siscoe...\n",
      "http://ufcstats.com/fighter-details/fce9b4056a8ef559\n",
      "Scraping Yokthai Sithoar...\n",
      "http://ufcstats.com/fighter-details/436cdea7bdfdc016\n",
      "Scraping Jeri Sitzes...\n",
      "http://ufcstats.com/fighter-details/44a1dd0ef4373edc\n",
      "Scraping Dennis Siver...\n",
      "http://ufcstats.com/fighter-details/5f87a5c00b3d17ed\n",
      "Scraping Chas Skelly...\n",
      "http://ufcstats.com/fighter-details/4bd6b4800070b069\n",
      "Scraping Matt Skelton...\n",
      "http://ufcstats.com/fighter-details/caced97768818230\n",
      "Scraping Zach Skinner...\n",
      "http://ufcstats.com/fighter-details/c337c3c85b1871e0\n",
      "Scraping Brian Sleeman...\n",
      "http://ufcstats.com/fighter-details/9db861c26b63daa8\n",
      "Scraping Joe Slick...\n",
      "http://ufcstats.com/fighter-details/80e6d71e14c1d356\n",
      "Scraping Ray Sloan...\n",
      "http://ufcstats.com/fighter-details/a2d1d3d144fed708\n",
      "Scraping Kestutis Smirnovas...\n",
      "http://ufcstats.com/fighter-details/1979c80150f630c4\n",
      "Scraping Maurice Smith...\n",
      "http://ufcstats.com/fighter-details/33e33d51f289d2a1\n",
      "Scraping Patrick Smith...\n",
      "http://ufcstats.com/fighter-details/46c8ec317aff28ac\n",
      "Scraping Scott Smith...\n",
      "http://ufcstats.com/fighter-details/3410cf010558dc8b\n",
      "Scraping Eric Smith...\n",
      "http://ufcstats.com/fighter-details/9114c8ded5ccd71d\n",
      "Scraping Josh Smith...\n",
      "http://ufcstats.com/fighter-details/f626aa1c85f8af03\n",
      "Scraping David Smith...\n",
      "http://ufcstats.com/fighter-details/e955046551f8c7dd\n",
      "Scraping Adam Smith...\n",
      "http://ufcstats.com/fighter-details/754968e325d6f60d\n",
      "Scraping Dillon Smith...\n",
      "http://ufcstats.com/fighter-details/ffee353f55e3aa2c\n",
      "Scraping Trevor Smith...\n",
      "http://ufcstats.com/fighter-details/f797f0c57a83353e\n",
      "Scraping Anthony Smith...\n",
      "http://ufcstats.com/fighter-details/d4c9dcd330403612\n",
      "Scraping Colton Smith...\n",
      "http://ufcstats.com/fighter-details/2e25c1d983c26311\n",
      "Scraping Gilbert Smith...\n",
      "http://ufcstats.com/fighter-details/54ed8dc6f8c31207\n",
      "Scraping Leslie Smith...\n",
      "http://ufcstats.com/fighter-details/76984112f697631f\n",
      "Scraping Devonte Smith...\n",
      "http://ufcstats.com/fighter-details/207773daeb4afa7b\n",
      "Scraping Cole Smith...\n",
      "http://ufcstats.com/fighter-details/56709e66f1c6008f\n",
      "Scraping Nate Smith...\n",
      "http://ufcstats.com/fighter-details/0bbb69f69c9a2eea\n",
      "Scraping Braxton Smith...\n",
      "http://ufcstats.com/fighter-details/eaa9402e5a7990ad\n",
      "Scraping Elijah Smith...\n",
      "http://ufcstats.com/fighter-details/7478b7f959ba61f5\n",
      "Scraping Jacobe Smith...\n",
      "http://ufcstats.com/fighter-details/85497ffd934ecf7e\n",
      "Scraping Walter Smith-Cotito...\n",
      "http://ufcstats.com/fighter-details/625b65b45c1c6888\n",
      "Scraping Justin Smitley...\n",
      "http://ufcstats.com/fighter-details/c5776fa8f4bf77aa\n",
      "Scraping Dmitrii Smoliakov...\n",
      "http://ufcstats.com/fighter-details/75afb06215a07341\n",
      "Scraping Louis Smolka...\n",
      "http://ufcstats.com/fighter-details/d2bc285ead803db0\n",
      "Scraping Cameron Smotherman...\n",
      "http://ufcstats.com/fighter-details/5c84f673b7bb7c15\n",
      "Scraping Shimon Smotritsky...\n",
      "http://ufcstats.com/fighter-details/1b0491ef0f9c965e\n",
      "Scraping Richie Smullen...\n",
      "http://ufcstats.com/fighter-details/f75c5ca0d91b9115\n",
      "Scraping Devin Smyth...\n",
      "http://ufcstats.com/fighter-details/7684c8137b4545ba\n",
      "Scraping Denis Sobolev...\n",
      "http://ufcstats.com/fighter-details/03b1e846b09f721d\n",
      "Scraping Peter Sobotta...\n",
      "http://ufcstats.com/fighter-details/1fcfc3709fe58151\n",
      "Scraping Renato Sobral...\n",
      "http://ufcstats.com/fighter-details/d468288756ae3982\n",
      "Scraping Rameau Thierry Sokoudjou...\n",
      "http://ufcstats.com/fighter-details/d1152823307d7e7c\n",
      "Scraping Alexander Soldatkin...\n",
      "http://ufcstats.com/fighter-details/f1451d605bad178e\n",
      "Scraping Chris Solomon...\n",
      "http://ufcstats.com/fighter-details/324c7a749128df8d\n",
      "Scraping Joe Son...\n",
      "http://ufcstats.com/fighter-details/83b743fedde154fb\n",
      "Scraping Paul Song...\n",
      "http://ufcstats.com/fighter-details/9775eabcb1be1a00\n",
      "Scraping Song Kenan...\n",
      "http://ufcstats.com/fighter-details/32490e80ddab1e5a\n",
      "Scraping Emrah Sonmez...\n",
      "http://ufcstats.com/fighter-details/fe759b24e344d7eb\n",
      "Scraping Chael Sonnen...\n",
      "http://ufcstats.com/fighter-details/48d1f690b763934c\n",
      "Scraping Cody Sons...\n",
      "http://ufcstats.com/fighter-details/3324129f3745b300\n",
      "Scraping Jin Soo Son...\n",
      "http://ufcstats.com/fighter-details/7c9c6a884be167fe\n",
      "Scraping Benardo Sopaj...\n",
      "http://ufcstats.com/fighter-details/b6c37948cb226e8c\n",
      "Scraping Emiliano Sordi...\n",
      "http://ufcstats.com/fighter-details/4c9b84d559822830\n",
      "Scraping Sean Soriano...\n",
      "http://ufcstats.com/fighter-details/bd5403efbaa445c0\n",
      "Scraping Punahele Soriano...\n",
      "http://ufcstats.com/fighter-details/64facb6cc564262d\n",
      "Scraping Dmitry Sosnovskiy...\n",
      "http://ufcstats.com/fighter-details/85ff1b9471d35238\n",
      "Scraping Ben Sosoli...\n",
      "http://ufcstats.com/fighter-details/326f94d6cfb1bf25\n",
      "Scraping Krzysztof Soszynski...\n",
      "http://ufcstats.com/fighter-details/59583ff832fe9d68\n",
      "Scraping George Sotiropoulos...\n",
      "http://ufcstats.com/fighter-details/896c322f56b8be5a\n",
      "Scraping Greg Soto...\n",
      "http://ufcstats.com/fighter-details/9c669abd35b2522f\n",
      "Scraping Alex Soto...\n",
      "http://ufcstats.com/fighter-details/d18dbcb0f8e2b55d\n",
      "Scraping Joe Soto...\n",
      "http://ufcstats.com/fighter-details/a4e85a58fbce64b2\n",
      "Scraping Mario Soto...\n",
      "http://ufcstats.com/fighter-details/cac3aaa66c20bee1\n",
      "Scraping Andre Soukhamthath...\n",
      "http://ufcstats.com/fighter-details/d0e50a3d1b250708\n",
      "Scraping Mario Sousa...\n",
      "http://ufcstats.com/fighter-details/72782745eb47161a\n",
      "Scraping Bobby Southworth...\n",
      "http://ufcstats.com/fighter-details/aee8eecfc4bfb1e7\n",
      "Scraping Jacare Souza...\n",
      "http://ufcstats.com/fighter-details/7a703c565ccaa18f\n",
      "Scraping Edimilson Souza...\n",
      "http://ufcstats.com/fighter-details/6c7020b859c7a3ce\n",
      "Scraping Livinha Souza...\n",
      "http://ufcstats.com/fighter-details/dab8cfbb6b1db10a\n",
      "Scraping Bruno Souza...\n",
      "http://ufcstats.com/fighter-details/0e5c4e72237461bb\n",
      "Scraping Ketlen Souza...\n",
      "http://ufcstats.com/fighter-details/8bd4200561c77a62\n",
      "Scraping Heraldo Souza...\n",
      "http://ufcstats.com/fighter-details/22b43be04d7454d0\n",
      "Scraping Charon Spain...\n",
      "http://ufcstats.com/fighter-details/c278e8843b8abfec\n",
      "Scraping Chris Spang...\n",
      "http://ufcstats.com/fighter-details/411d012af19ecb59\n",
      "Scraping Andreas Spang...\n",
      "http://ufcstats.com/fighter-details/b9eb5b4ed07d1525\n",
      "Scraping Ryan Spann...\n",
      "http://ufcstats.com/fighter-details/a67f5afa8d6a1b80\n",
      "Scraping Ron Sparks...\n",
      "http://ufcstats.com/fighter-details/743fd9080892501d\n",
      "Scraping Tommy Speer...\n",
      "http://ufcstats.com/fighter-details/1411c630ba711b64\n",
      "Scraping Patrick Speight...\n",
      "http://ufcstats.com/fighter-details/ae4650eb56ab6a11\n",
      "Scraping Sean Spencer...\n",
      "http://ufcstats.com/fighter-details/ab850a77a0fa487d\n",
      "Scraping Felicia Spencer...\n",
      "http://ufcstats.com/fighter-details/39d91e95949de3d9\n",
      "Scraping Sam Spengler...\n",
      "http://ufcstats.com/fighter-details/221b2a3070c7ce3e\n",
      "Scraping Nick Sperling...\n",
      "http://ufcstats.com/fighter-details/7d68f3bec89e08ec\n",
      "Scraping Mario Sperry...\n",
      "http://ufcstats.com/fighter-details/5f2197acaba7d5ef\n",
      "Scraping Eric Spicely...\n",
      "http://ufcstats.com/fighter-details/b9664eae2ac75262\n",
      "Scraping Waachiim Spiritwolf...\n",
      "http://ufcstats.com/fighter-details/71caa995674203aa\n",
      "Scraping Daniel Spitz...\n",
      "http://ufcstats.com/fighter-details/f86cb5f25d545e0e\n",
      "Scraping Serghei Spivac...\n",
      "http://ufcstats.com/fighter-details/e2f6b2769aaedd6c\n",
      "Scraping Daniel Spohn...\n",
      "http://ufcstats.com/fighter-details/87f3bbf52e6c9dc9\n",
      "Scraping Pete Spratt...\n",
      "http://ufcstats.com/fighter-details/c3ea8deeba00462b\n",
      "Scraping Austin Springer...\n",
      "http://ufcstats.com/fighter-details/37cc294027f55e4d\n",
      "Scraping Georges St-Pierre...\n",
      "http://ufcstats.com/fighter-details/6506c1d34da9c013\n",
      "Scraping Bobby Stack...\n",
      "http://ufcstats.com/fighter-details/6436029b50a9c255\n",
      "Scraping Andreas Stahl...\n",
      "http://ufcstats.com/fighter-details/69a400af4420cd6a\n",
      "Scraping Ron Stallings...\n",
      "http://ufcstats.com/fighter-details/6dd758d34da8d254\n",
      "Scraping Cody Stamann...\n",
      "http://ufcstats.com/fighter-details/bf7ad5628363eec9\n",
      "Scraping Cristina Stanciu...\n",
      "http://ufcstats.com/fighter-details/175852708cb55776\n",
      "Scraping Brian Stann...\n",
      "http://ufcstats.com/fighter-details/579fcdfcabd23a7b\n",
      "Scraping Josh Stansbury...\n",
      "http://ufcstats.com/fighter-details/30ea504870f8597b\n",
      "Scraping Dion Staring...\n",
      "http://ufcstats.com/fighter-details/289a57039d742bfe\n",
      "Scraping Lucas Stark...\n",
      "http://ufcstats.com/fighter-details/93e4754d0984c82f\n",
      "Scraping Clifford Starks...\n",
      "http://ufcstats.com/fighter-details/5abf827d62f98fee\n",
      "Scraping Kalib Starnes...\n",
      "http://ufcstats.com/fighter-details/c8136ab8aa32c974\n",
      "Scraping Laureano Staropoli...\n",
      "http://ufcstats.com/fighter-details/a12a8314adc1c1c9\n",
      "Scraping Damian Stasiak...\n",
      "http://ufcstats.com/fighter-details/42a7e90605df3c8a\n",
      "Scraping Adam Steele...\n",
      "http://ufcstats.com/fighter-details/16044bd8762cf794\n",
      "Scraping Dominique Steele...\n",
      "http://ufcstats.com/fighter-details/68c11c27d4d56572\n",
      "Scraping Ricky Steele...\n",
      "http://ufcstats.com/fighter-details/09a6ed4ee97a5606\n",
      "Scraping Kody Steele...\n",
      "http://ufcstats.com/fighter-details/aebaa8cec15b083d\n",
      "Scraping Eric Steenberg...\n",
      "http://ufcstats.com/fighter-details/377bc9dc0b2745f9\n",
      "Scraping Steve Steinbeiss...\n",
      "http://ufcstats.com/fighter-details/0b5b6876c2a4723f\n",
      "Scraping Ray Steinbeiss...\n",
      "http://ufcstats.com/fighter-details/6000b5ae6c462142\n",
      "Scraping Dmitri Stepanov...\n",
      "http://ufcstats.com/fighter-details/738acab0c6934dd8\n",
      "Scraping Aljamain Sterling...\n",
      "http://ufcstats.com/fighter-details/cb696ebfb6598724\n",
      "Scraping Marc Stevens...\n",
      "http://ufcstats.com/fighter-details/310c4d4b2b32796b\n",
      "Scraping Joe Stevenson...\n",
      "http://ufcstats.com/fighter-details/79899ecf62020f6d\n",
      "Scraping Maia Stevenson...\n",
      "http://ufcstats.com/fighter-details/2fee10d5cf86bfca\n",
      "Scraping Luke Stewart...\n",
      "http://ufcstats.com/fighter-details/27b1a406ac171b19\n",
      "Scraping Darren Stewart...\n",
      "http://ufcstats.com/fighter-details/a17ad5a5048e8c3f\n",
      "Scraping Kyle Stewart...\n",
      "http://ufcstats.com/fighter-details/bb61823f76361297\n",
      "Scraping Alex Stiebling...\n",
      "http://ufcstats.com/fighter-details/df5a77121ba84a5d\n",
      "Scraping Tyler Stinson...\n",
      "http://ufcstats.com/fighter-details/2cf520143e76cd2e\n",
      "Scraping Navajo Stirling...\n",
      "http://ufcstats.com/fighter-details/b4b496ec2197ee3e\n",
      "Scraping Dan Stittgen...\n",
      "http://ufcstats.com/fighter-details/cc3147b49c7d7d92\n",
      "Scraping Lazar Stojadinovic...\n",
      "http://ufcstats.com/fighter-details/4d25497994da569c\n",
      "Scraping Denis Stojnic...\n",
      "http://ufcstats.com/fighter-details/a421465acbe59c77\n",
      "Scraping Julija Stoliarenko...\n",
      "http://ufcstats.com/fighter-details/a78a87d8c2bbb1cb\n",
      "Scraping Dustin Stoltzfus...\n",
      "http://ufcstats.com/fighter-details/71505842fb6455c3\n",
      "Scraping Niklas Stolze...\n",
      "http://ufcstats.com/fighter-details/62f7097c04311193\n",
      "Scraping Ken Stone...\n",
      "http://ufcstats.com/fighter-details/fbf0947399d14323\n",
      "Scraping Ryan Stonitsch...\n",
      "http://ufcstats.com/fighter-details/8d477c3fbe001f9d\n",
      "Scraping George Stork...\n",
      "http://ufcstats.com/fighter-details/61dd409cb40d1a55\n",
      "Scraping Rick Story...\n",
      "http://ufcstats.com/fighter-details/5b5307450405abf0\n",
      "Scraping Darko Stosic...\n",
      "http://ufcstats.com/fighter-details/025f0b1b58fbad01\n",
      "Scraping Greg Stott...\n",
      "http://ufcstats.com/fighter-details/91181b29be041f1c\n",
      "Scraping Sam Stout...\n",
      "http://ufcstats.com/fighter-details/501b07aec9b8fc2d\n",
      "Scraping Tim Stout...\n",
      "http://ufcstats.com/fighter-details/e1a4568fec1fc24f\n",
      "Scraping Jesse Strader...\n",
      "http://ufcstats.com/fighter-details/8c39367b53eadf8a\n",
      "Scraping Gennaro Strangis...\n",
      "http://ufcstats.com/fighter-details/495add4fbede0a44\n",
      "Scraping Dave Strasser...\n",
      "http://ufcstats.com/fighter-details/980b4e712489098e\n",
      "Scraping Daniel Straus...\n",
      "http://ufcstats.com/fighter-details/15347cd4cdf01b03\n",
      "Scraping Gerald Strebendt...\n",
      "http://ufcstats.com/fighter-details/04f9fe830cf13482\n",
      "Scraping Sean Strickland...\n",
      "http://ufcstats.com/fighter-details/0d8011111be000b2\n",
      "Scraping Mark Striegl...\n",
      "http://ufcstats.com/fighter-details/ef1182eb28c17d4e\n",
      "Scraping Hans Stringer...\n",
      "http://ufcstats.com/fighter-details/523f6ad11dbe9b53\n",
      "Scraping Stefan Struve...\n",
      "http://ufcstats.com/fighter-details/ebc1f40e00e0c481\n",
      "Scraping Josh Stuart...\n",
      "http://ufcstats.com/fighter-details/601cf40c09090853\n",
      "Scraping Mike Stumpf...\n",
      "http://ufcstats.com/fighter-details/c0c36a5b3d5bbdd5\n",
      "Scraping Kyle Sturgeon...\n",
      "http://ufcstats.com/fighter-details/d30415ec5e8783cd\n",
      "Scraping Tatiana Suarez...\n",
      "http://ufcstats.com/fighter-details/b08012bbe542592a\n",
      "Scraping Masanori Suda...\n",
      "http://ufcstats.com/fighter-details/3a7513372f79c8c8\n",
      "Scraping Genki Sudo...\n",
      "http://ufcstats.com/fighter-details/99dd0147dc4ef80c\n",
      "Scraping Lucasz Sudolski...\n",
      "http://ufcstats.com/fighter-details/b160e4f251283d70\n",
      "Scraping Daisuke Sugie...\n",
      "http://ufcstats.com/fighter-details/8215e4fe24e8e81b\n",
      "Scraping Takashi Sugiura...\n",
      "http://ufcstats.com/fighter-details/06c60fc2c8dcd7bd\n",
      "Scraping Naho Sugiyuma...\n",
      "http://ufcstats.com/fighter-details/b205d4f2ff44bc89\n",
      "Scraping George Sullivan...\n",
      "http://ufcstats.com/fighter-details/6c7e25571490aa3b\n",
      "Scraping Amar Suloev...\n",
      "http://ufcstats.com/fighter-details/7aa88401f93ce836\n",
      "Scraping Magomed Sultanakhmedov...\n",
      "http://ufcstats.com/fighter-details/fe1fdc6be470f773\n",
      "Scraping Justin Sumter...\n",
      "http://ufcstats.com/fighter-details/31f9a1f56cbb6ac5\n",
      "Scraping Sumudaerji...\n",
      "http://ufcstats.com/fighter-details/3cf18e01cb6cbde3\n",
      "Scraping Rama Supandhi...\n",
      "http://ufcstats.com/fighter-details/6d537248fe7cccf1\n",
      "Scraping Aji Susilo...\n",
      "http://ufcstats.com/fighter-details/22af3546bd967280\n",
      "Scraping Jason Suttie...\n",
      "http://ufcstats.com/fighter-details/cc5834a495d1ea08\n",
      "Scraping Joel Sutton...\n",
      "http://ufcstats.com/fighter-details/a6a9ab5a824e8f66\n",
      "Scraping Chad Sutton...\n",
      "http://ufcstats.com/fighter-details/556347e2b0e33979\n",
      "Scraping Danilo Suzart...\n",
      "http://ufcstats.com/fighter-details/3d99e5aa85d7576a\n",
      "Scraping Martin Svensson...\n",
      "http://ufcstats.com/fighter-details/bcad7223af3c19da\n",
      "Scraping Daniel Swain...\n",
      "http://ufcstats.com/fighter-details/cc39185f2d7d89e4\n",
      "Scraping Cub Swanson...\n",
      "http://ufcstats.com/fighter-details/d247691a6c0e9034\n",
      "Scraping Mike Swick...\n",
      "http://ufcstats.com/fighter-details/9fe85152f351e737\n",
      "Scraping Floyd Sword...\n",
      "http://ufcstats.com/fighter-details/5330fe7e4c3af81c\n",
      "Scraping Oumar Sy...\n",
      "http://ufcstats.com/fighter-details/46e2011d92463b7e\n",
      "Scraping Bentley Syler...\n",
      "http://ufcstats.com/fighter-details/abd2109bc4cb0291\n",
      "Scraping Kevin Syler...\n",
      "http://ufcstats.com/fighter-details/9094a881a7513de3\n",
      "Scraping Leo Sylvest...\n",
      "http://ufcstats.com/fighter-details/58a36b4ccf5dc30e\n",
      "Scraping Tony Sylvester...\n",
      "http://ufcstats.com/fighter-details/87b7df65c30008c4\n",
      "Scraping Tim Sylvia...\n",
      "http://ufcstats.com/fighter-details/2a542ee8a8b83559\n",
      "Scraping Kevin Szaflarski...\n",
      "http://ufcstats.com/fighter-details/d2d05dda5f887f87\n",
      "Scraping Bartosz Szewczyk...\n",
      "http://ufcstats.com/fighter-details/224050896306f00c\n",
      "Scraping Osamu Tachihikari...\n",
      "http://ufcstats.com/fighter-details/e7bc606d269896aa\n",
      "Scraping Amber Tackett...\n",
      "http://ufcstats.com/fighter-details/bb01bc3c57f39b04\n",
      "Scraping Eugenio Tadeu...\n",
      "http://ufcstats.com/fighter-details/f70144caea5c4c80\n",
      "Scraping Justin Tafa...\n",
      "http://ufcstats.com/fighter-details/e13abac8089a801a\n",
      "Scraping Junior Tafa...\n",
      "http://ufcstats.com/fighter-details/c15fa95b9a12fde4\n",
      "Scraping Khalid Taha...\n",
      "http://ufcstats.com/fighter-details/b4537562f88ac582\n",
      "Scraping Joe Taimanglo...\n",
      "http://ufcstats.com/fighter-details/9bf126927843e184\n",
      "Scraping Tatsuro Taira...\n",
      "http://ufcstats.com/fighter-details/4461d7e47375a895\n",
      "Scraping Mairbek Taisumov...\n",
      "http://ufcstats.com/fighter-details/8f5c8850b2484173\n",
      "Scraping Nobuhiko Takada...\n",
      "http://ufcstats.com/fighter-details/a25b71fe5e31fa97\n",
      "Scraping Yoshiki Takahashi...\n",
      "http://ufcstats.com/fighter-details/6420efac0578988b\n",
      "Scraping Yoko Takahashi...\n",
      "http://ufcstats.com/fighter-details/01f86e2d604e2f3c\n",
      "Scraping Daiju Takase...\n",
      "http://ufcstats.com/fighter-details/4f74c8be51db8a37\n",
      "Scraping Hiroyuki Takaya...\n",
      "http://ufcstats.com/fighter-details/0d16bdb7d32e88e9\n",
      "Scraping Yoshihiro Takayama...\n",
      "http://ufcstats.com/fighter-details/d856a0080ac09ed7\n",
      "Scraping Makoto Takimoto...\n",
      "http://ufcstats.com/fighter-details/a7724f51e32e763e\n",
      "Scraping Oleg Taktarov...\n",
      "http://ufcstats.com/fighter-details/1dc56b59cb28425d\n",
      "Scraping Payton Talbott...\n",
      "http://ufcstats.com/fighter-details/6e743a33d56bdaa4\n",
      "Scraping Nordine Taleb...\n",
      "http://ufcstats.com/fighter-details/49858bf46dabf6fb\n",
      "Scraping Murtaza Talha...\n",
      "http://ufcstats.com/fighter-details/6aab5c20395ee722\n",
      "Scraping Tsuyoshi Tamakairiki...\n",
      "http://ufcstats.com/fighter-details/eaa0a728cc91ef60\n",
      "Scraping Eli Tamez...\n",
      "http://ufcstats.com/fighter-details/bfd4d50591033a1f\n",
      "Scraping Kiyoshi Tamura...\n",
      "http://ufcstats.com/fighter-details/30e8b4505f5ccf92\n",
      "Scraping Akitoshi Tamura...\n",
      "http://ufcstats.com/fighter-details/c95fbc085e17a532\n",
      "Scraping Issei Tamura...\n",
      "http://ufcstats.com/fighter-details/57bf89d42364d39e\n",
      "Scraping Jason Tan...\n",
      "http://ufcstats.com/fighter-details/ad3041e61896b975\n",
      "Scraping Michinori Tanaka...\n",
      "http://ufcstats.com/fighter-details/64788ee44b062ded\n",
      "Scraping Evan Tanner...\n",
      "http://ufcstats.com/fighter-details/8f2d9ee27f206f1f\n",
      "Scraping Kasey Tanner...\n",
      "http://ufcstats.com/fighter-details/078b732efa497f49\n",
      "Scraping Otari Tanzilovi...\n",
      "http://ufcstats.com/fighter-details/b9124c308671e303\n",
      "Scraping Manny Tapia...\n",
      "http://ufcstats.com/fighter-details/0eec866a077889f0\n",
      "Scraping Gary Tapusoa...\n",
      "http://ufcstats.com/fighter-details/37ac9e0f4fc86171\n",
      "Scraping Miesha Tate...\n",
      "http://ufcstats.com/fighter-details/b96619b3acd7d9da\n",
      "Scraping Aaron Tau...\n",
      "http://ufcstats.com/fighter-details/7abf7f8778472b7b\n",
      "Scraping Deividas Taurosevicius...\n",
      "http://ufcstats.com/fighter-details/ef927e4fe2117ab8\n",
      "Scraping Thiago Tavares...\n",
      "http://ufcstats.com/fighter-details/8a59d346dc976a10\n",
      "Scraping Jeremy Tavares...\n",
      "http://ufcstats.com/fighter-details/681d07e328798ec0\n",
      "Scraping Brad Tavares...\n",
      "http://ufcstats.com/fighter-details/0c6d9ea8306c029e\n",
      "Scraping Ramon Taveras...\n",
      "http://ufcstats.com/fighter-details/c5ccd878231c5407\n",
      "Scraping Paul Taylor...\n",
      "http://ufcstats.com/fighter-details/9b74de674c355425\n",
      "Scraping Jesse Taylor...\n",
      "http://ufcstats.com/fighter-details/dd992d569aaebee6\n",
      "Scraping Torrance Taylor...\n",
      "http://ufcstats.com/fighter-details/88e53ec16b801740\n",
      "Scraping Louis Taylor...\n",
      "http://ufcstats.com/fighter-details/49bddfee9ed54cf3\n",
      "Scraping Anthony Taylor...\n",
      "http://ufcstats.com/fighter-details/637a4d8825464c62\n",
      "Scraping Danielle Taylor...\n",
      "http://ufcstats.com/fighter-details/b76c6268dc1d3c05\n",
      "Scraping J.T Taylor...\n",
      "http://ufcstats.com/fighter-details/17c6e35e4da505b0\n",
      "Scraping James Te Huna...\n",
      "http://ufcstats.com/fighter-details/f5431394fb284bb9\n",
      "Scraping Cam Teague...\n",
      "http://ufcstats.com/fighter-details/b47c9ea5f2895d6e\n",
      "Scraping Shawn Teed...\n",
      "http://ufcstats.com/fighter-details/5bb70ebd65075c5c\n",
      "Scraping Glover Teixeira...\n",
      "http://ufcstats.com/fighter-details/7ff97850e8c32bda\n",
      "Scraping John Teixeira...\n",
      "http://ufcstats.com/fighter-details/86061eaba822bfea\n",
      "Scraping Ewerton Teixeira...\n",
      "http://ufcstats.com/fighter-details/de9e331b3e6bae70\n",
      "Scraping Tallison Teixeira...\n",
      "http://ufcstats.com/fighter-details/17923f676f100e16\n",
      "Scraping Tra Telligman...\n",
      "http://ufcstats.com/fighter-details/1dab0d1d81dd06db\n",
      "Scraping Ramazan Temirov...\n",
      "http://ufcstats.com/fighter-details/7d0a1968b38ca439\n",
      "Scraping Taneisha Tennant...\n",
      "http://ufcstats.com/fighter-details/87911d22a79d3203\n",
      "Scraping Herman Terrado...\n",
      "http://ufcstats.com/fighter-details/61d6368013f8637f\n",
      "Scraping Dave Terrel...\n",
      "http://ufcstats.com/fighter-details/b9aa0024f295609e\n",
      "Scraping David Terrell...\n",
      "http://ufcstats.com/fighter-details/4123fd4dcc1fe937\n",
      "Scraping James Terry...\n",
      "http://ufcstats.com/fighter-details/5befa793316d3469\n",
      "Scraping Jeff Terry...\n",
      "http://ufcstats.com/fighter-details/60f86c449cd31e23\n",
      "Scraping David Teymur...\n",
      "http://ufcstats.com/fighter-details/2747c60e42d9d75f\n",
      "Scraping Daniel Teymur...\n",
      "http://ufcstats.com/fighter-details/fbf0537e420e698e\n",
      "Scraping Motonobu Tezuka...\n",
      "http://ufcstats.com/fighter-details/d34636a85f0f4c90\n",
      "Scraping Jason Thacker...\n",
      "http://ufcstats.com/fighter-details/f0264252e191da22\n",
      "Scraping Alexia Thainara...\n",
      "http://ufcstats.com/fighter-details/545092d13c67aa49\n",
      "Scraping Brandon Thatch...\n",
      "http://ufcstats.com/fighter-details/638cfec7ec559d6e\n",
      "Scraping Elias Theodorou...\n",
      "http://ufcstats.com/fighter-details/34f88592c0ab7a54\n",
      "Scraping Nik Theotikos...\n",
      "http://ufcstats.com/fighter-details/ca936c67687789e9\n",
      "Scraping Paulo Thiago...\n",
      "http://ufcstats.com/fighter-details/30a09e43f15f1d75\n",
      "Scraping Din Thomas...\n",
      "http://ufcstats.com/fighter-details/40a604761ca7d64d\n",
      "Scraping Ryan Thomas...\n",
      "http://ufcstats.com/fighter-details/b732b326c362fb62\n",
      "Scraping Noah Thomas...\n",
      "http://ufcstats.com/fighter-details/319c15b8aac5bfde\n",
      "Scraping Joel Thomas...\n",
      "http://ufcstats.com/fighter-details/2b33e57c4d0a4502\n",
      "Scraping Treston Thomison...\n",
      "http://ufcstats.com/fighter-details/ed5f04f833459877\n",
      "Scraping Nick Thompson...\n",
      "http://ufcstats.com/fighter-details/7d3caf0f96f1b33d\n",
      "Scraping James Thompson...\n",
      "http://ufcstats.com/fighter-details/9e30f69cc0869301\n",
      "Scraping Oli Thompson...\n",
      "http://ufcstats.com/fighter-details/dcdd511ff757f15c\n",
      "Scraping Stephen Thompson...\n",
      "http://ufcstats.com/fighter-details/4a28cb716c19157a\n",
      "Scraping Josh Thomson...\n",
      "http://ufcstats.com/fighter-details/a566371ba2ad7152\n",
      "Scraping Simeon Thoresen...\n",
      "http://ufcstats.com/fighter-details/fea8acf9bfcf09ec\n",
      "Scraping Josh Thornburg...\n",
      "http://ufcstats.com/fighter-details/083e15da67d9b0fa\n",
      "Scraping Gleison Tibau...\n",
      "http://ufcstats.com/fighter-details/75e5fec9f72910ef\n",
      "Scraping Chris Tickle...\n",
      "http://ufcstats.com/fighter-details/1d1b85389a05df69\n",
      "Scraping Nolan Ticman...\n",
      "http://ufcstats.com/fighter-details/9eb069062a0cfc13\n",
      "Scraping Darren Till...\n",
      "http://ufcstats.com/fighter-details/9ce6d5a03af801b7\n",
      "Scraping Brett Tillis...\n",
      "http://ufcstats.com/fighter-details/7b461ccae8270207\n",
      "Scraping Denis Tiuliulin...\n",
      "http://ufcstats.com/fighter-details/0112352cb32f5026\n",
      "Scraping Ryan Tobar...\n",
      "http://ufcstats.com/fighter-details/57481f1f10530c61\n",
      "Scraping Andrew Todhunter...\n",
      "http://ufcstats.com/fighter-details/274ca7b799b402cc\n",
      "Scraping Dusko Todorovic...\n",
      "http://ufcstats.com/fighter-details/866fd7b1a6c90e7f\n",
      "Scraping Tuco Tokkos...\n",
      "http://ufcstats.com/fighter-details/3e8118c1ab52f211\n",
      "Scraping Hideo Tokoro...\n",
      "http://ufcstats.com/fighter-details/2d5fbe2103f97053\n",
      "Scraping Anatoly Tokov...\n",
      "http://ufcstats.com/fighter-details/679ae8c4fd022c6b\n",
      "Scraping Kazuki Tokudome...\n",
      "http://ufcstats.com/fighter-details/c4af2feb4b58bc3b\n",
      "Scraping Puja Tomar...\n",
      "http://ufcstats.com/fighter-details/19f8a2f6eecd92ac\n",
      "Scraping Tyler Toner...\n",
      "http://ufcstats.com/fighter-details/8e893f269d5696b2\n",
      "Scraping James Toney...\n",
      "http://ufcstats.com/fighter-details/d10b35152277cf98\n",
      "Scraping Masanori Tonooka...\n",
      "http://ufcstats.com/fighter-details/9de7c97e1c0d7927\n",
      "Scraping Carl Toomey...\n",
      "http://ufcstats.com/fighter-details/5ee87e0432205755\n",
      "Scraping Ilia Topuria...\n",
      "http://ufcstats.com/fighter-details/54f64b5e283b0ce7\n",
      "Scraping Aleksandre Topuria...\n",
      "http://ufcstats.com/fighter-details/4a6dff1b260bcf61\n",
      "Scraping Anthony Torres...\n",
      "http://ufcstats.com/fighter-details/918d9d89d4d52acc\n",
      "Scraping Miguel Torres...\n",
      "http://ufcstats.com/fighter-details/33b2f68ef95252e0\n",
      "Scraping Ronys Torres...\n",
      "http://ufcstats.com/fighter-details/cce79e827569f26e\n",
      "Scraping Haven Torres...\n",
      "http://ufcstats.com/fighter-details/1ff10dee2f7ae60c\n",
      "Scraping Alex Torres...\n",
      "http://ufcstats.com/fighter-details/e4e0f310b3cf23a8\n",
      "Scraping Abram Torres...\n",
      "http://ufcstats.com/fighter-details/e175a261a280f7cb\n",
      "Scraping Jose Torres...\n",
      "http://ufcstats.com/fighter-details/d2036f31c035e0d1\n",
      "Scraping Desmond Torres...\n",
      "http://ufcstats.com/fighter-details/971aebf56267de20\n",
      "Scraping Manuel Torres...\n",
      "http://ufcstats.com/fighter-details/2e7878927067fdca\n",
      "Scraping Eduardo Torres Caut...\n",
      "http://ufcstats.com/fighter-details/c8d46028907bcece\n",
      "Scraping Salim Touahri...\n",
      "http://ufcstats.com/fighter-details/cbf1c7ba5408a66f\n",
      "Scraping Dequan Townsend...\n",
      "http://ufcstats.com/fighter-details/3f7dab21b6c971bc\n",
      "Scraping Minoru Toyonaga...\n",
      "http://ufcstats.com/fighter-details/04076783ca83d6ae\n",
      "Scraping Slim Trabelsi...\n",
      "http://ufcstats.com/fighter-details/ff2ec83f44000f78\n",
      "Scraping Roberto Traven...\n",
      "http://ufcstats.com/fighter-details/20ec0061400178ca\n",
      "Scraping Bryan Travers...\n",
      "http://ufcstats.com/fighter-details/008cf84faae9c7a5\n",
      "Scraping Alexander Trevino...\n",
      "http://ufcstats.com/fighter-details/73abb7a5c57fb443\n",
      "Scraping Francisco Trevino...\n",
      "http://ufcstats.com/fighter-details/97a6bbe6e6566a94\n",
      "Scraping Angelo Trevino...\n",
      "http://ufcstats.com/fighter-details/0cf9f5518d6063bb\n",
      "Scraping Frank Trigg...\n",
      "http://ufcstats.com/fighter-details/d2d37e8eeb3abc8d\n",
      "Scraping Francisco Trinaldo...\n",
      "http://ufcstats.com/fighter-details/a8283a4f415e1eb9\n",
      "Scraping Damien Trites...\n",
      "http://ufcstats.com/fighter-details/cb1c09c8126dbee0\n",
      "Scraping Michael Trizano...\n",
      "http://ufcstats.com/fighter-details/5bf31a46becc1204\n",
      "Scraping Antonio Trocoli...\n",
      "http://ufcstats.com/fighter-details/6d48a2df51749d91\n",
      "Scraping Tor Troeng...\n",
      "http://ufcstats.com/fighter-details/8abf70f79e9e27c2\n",
      "Scraping Aaron Trujillo...\n",
      "http://ufcstats.com/fighter-details/cc18abc046b382c9\n",
      "Scraping Reynaldo Trujillo...\n",
      "http://ufcstats.com/fighter-details/e6b233a007cb06c4\n",
      "Scraping Abel Trujillo...\n",
      "http://ufcstats.com/fighter-details/e14b5aa06eea9653\n",
      "Scraping Arman Tsarukyan...\n",
      "http://ufcstats.com/fighter-details/eae48ff31db420c2\n",
      "Scraping Rei Tsuruya...\n",
      "http://ufcstats.com/fighter-details/2f43a3e82661fa99\n",
      "Scraping Chris Tuchscherer...\n",
      "http://ufcstats.com/fighter-details/df05aa15b2d66f57\n",
      "Scraping Jon Tuck...\n",
      "http://ufcstats.com/fighter-details/53ec9cb470e1a4ea\n",
      "Scraping Gavin Tucker...\n",
      "http://ufcstats.com/fighter-details/da816417a579a0bd\n",
      "Scraping Jumabieke Tuerxun...\n",
      "http://ufcstats.com/fighter-details/1ed32eaaba9ffe10\n",
      "Scraping Tom Tuggle...\n",
      "http://ufcstats.com/fighter-details/b9aa7d230865b5fe\n",
      "Scraping Blair Tugman...\n",
      "http://ufcstats.com/fighter-details/63f8775391301891\n",
      "Scraping Tai Tuivasa...\n",
      "http://ufcstats.com/fighter-details/c62fbc117d57b943\n",
      "Scraping Zubaira Tukhugov...\n",
      "http://ufcstats.com/fighter-details/aceffa19749c4dc0\n",
      "Scraping Teila Tuli...\n",
      "http://ufcstats.com/fighter-details/96eff1a628adcc7f\n",
      "Scraping Marco Tulio...\n",
      "http://ufcstats.com/fighter-details/9384e71bca6c409d\n",
      "Scraping Nyamjargal Tumendemberel...\n",
      "http://ufcstats.com/fighter-details/17cb6d8e8187f304\n",
      "Scraping Albert Tumenov...\n",
      "http://ufcstats.com/fighter-details/ff6a1f63c254127e\n",
      "Scraping Ricky Turcios...\n",
      "http://ufcstats.com/fighter-details/cd3d7e37ff2d679c\n",
      "Scraping Anton Turkalj...\n",
      "http://ufcstats.com/fighter-details/82529ce93cd9a2cf\n",
      "Scraping Wellington Turman...\n",
      "http://ufcstats.com/fighter-details/4dcfb28c011c11b2\n",
      "Scraping Courtney Turner...\n",
      "http://ufcstats.com/fighter-details/56f4b81ec4db61af\n",
      "Scraping Jalin Turner...\n",
      "http://ufcstats.com/fighter-details/4d8fa64202cee4c1\n",
      "Scraping Austin Tweedy...\n",
      "http://ufcstats.com/fighter-details/885adaff8fe15cf7\n",
      "Scraping Marcin Tybura...\n",
      "http://ufcstats.com/fighter-details/c9cf753cfdf77fc2\n",
      "Scraping Takeru Uchida...\n",
      "http://ufcstats.com/fighter-details/1d76f07ffdd765c2\n",
      "Scraping Alberto Uda...\n",
      "http://ufcstats.com/fighter-details/8f2deefe8c5dfb5d\n",
      "Scraping Ryuki Ueyama...\n",
      "http://ufcstats.com/fighter-details/bcd124bcd3d5be46\n",
      "Scraping Christian Uflacker...\n",
      "http://ufcstats.com/fighter-details/10ccf4ec9913cadc\n",
      "Scraping Andy Uhrich...\n",
      "http://ufcstats.com/fighter-details/4a1a492f299581d9\n",
      "Scraping Tagir Ulanbekov...\n",
      "http://ufcstats.com/fighter-details/f00ac08ab056af5d\n",
      "Scraping Carlos Ulberg...\n",
      "http://ufcstats.com/fighter-details/9014c02eff8b3d62\n",
      "Scraping Gasan Umalatov...\n",
      "http://ufcstats.com/fighter-details/7a39bbac8cc0fa70\n",
      "Scraping Jeremy Umphries...\n",
      "http://ufcstats.com/fighter-details/4793a2d90f5ab8ae\n",
      "Scraping Zach Underwood...\n",
      "http://ufcstats.com/fighter-details/1e310618d02ff93b\n",
      "Scraping Caol Uno...\n",
      "http://ufcstats.com/fighter-details/eb1723480fa2f96c\n",
      "Scraping Kengo Ura...\n",
      "http://ufcstats.com/fighter-details/58258914525740a5\n",
      "Scraping Logan Urban...\n",
      "http://ufcstats.com/fighter-details/5e23f30e9c6ed74e\n",
      "Scraping Hector Urbina...\n",
      "http://ufcstats.com/fighter-details/4b8fb0453a596b8e\n",
      "Scraping Elias Urbina...\n",
      "http://ufcstats.com/fighter-details/47fcdcaccb58ca80\n",
      "Scraping Gilbert Urbina...\n",
      "http://ufcstats.com/fighter-details/b12fb759e02378de\n",
      "Scraping Nick Urso...\n",
      "http://ufcstats.com/fighter-details/e78c4c3d329c531b\n",
      "Scraping Yasuhiro Urushitani...\n",
      "http://ufcstats.com/fighter-details/c34e5849184b08c3\n",
      "Scraping Sho Patrick Usami...\n",
      "http://ufcstats.com/fighter-details/fe30c5f5cc3e028b\n",
      "Scraping Kamaru Usman...\n",
      "http://ufcstats.com/fighter-details/f1b2aa7853d1ed6e\n",
      "Scraping Mohammed Usman...\n",
      "http://ufcstats.com/fighter-details/da7f113b5ea39c43\n",
      "Scraping Darren Uyenoyama...\n",
      "http://ufcstats.com/fighter-details/6546af7ab545b90c\n",
      "Scraping Richie Vaculik...\n",
      "http://ufcstats.com/fighter-details/54578e5927adea53\n",
      "Scraping Artem Vakhitov...\n",
      "http://ufcstats.com/fighter-details/43e549b803ec7375\n",
      "Scraping Egidijus Valavicius...\n",
      "http://ufcstats.com/fighter-details/fc1868f56d3036eb\n",
      "Scraping Genaro Valdez...\n",
      "http://ufcstats.com/fighter-details/cda1099995b46cc2\n",
      "Scraping Charlie Valencia...\n",
      "http://ufcstats.com/fighter-details/8a0be41c0380188d\n",
      "Scraping Robert Valentin...\n",
      "http://ufcstats.com/fighter-details/0cd0456d6029cec2\n",
      "Scraping Victor Valenzuela...\n",
      "http://ufcstats.com/fighter-details/de277a4abcfeea46\n",
      "Scraping Ivan Valenzuela...\n",
      "http://ufcstats.com/fighter-details/45b82ebf0b9e0fd2\n",
      "Scraping Timur Valiev...\n",
      "http://ufcstats.com/fighter-details/45e738622ea2c02c\n",
      "Scraping Victor Valimaki...\n",
      "http://ufcstats.com/fighter-details/663b76da637402c3\n",
      "Scraping Andrew Valladerez...\n",
      "http://ufcstats.com/fighter-details/2a898bf9fb7710b3\n",
      "Scraping Kevin Vallejos...\n",
      "http://ufcstats.com/fighter-details/239d8e5359022f3b\n",
      "Scraping Isaac Vallie-Flagg...\n",
      "http://ufcstats.com/fighter-details/c295de4e10acd4c9\n",
      "Scraping Joshua Van...\n",
      "http://ufcstats.com/fighter-details/17e97649403ba428\n",
      "Scraping Mike van Arsdale...\n",
      "http://ufcstats.com/fighter-details/2ee09ec2a0695eb9\n",
      "Scraping Matt Van Buren...\n",
      "http://ufcstats.com/fighter-details/7b39035fae7268b8\n",
      "Scraping Ron van Clief...\n",
      "http://ufcstats.com/fighter-details/23ab42947c1990e3\n",
      "Scraping Lloyd Van Dams...\n",
      "http://ufcstats.com/fighter-details/02177caefe7c07d4\n",
      "Scraping Alain Van der Merckt...\n",
      "http://ufcstats.com/fighter-details/f6bbc6ba4f06ad60\n",
      "Scraping Cameron VanCamp...\n",
      "http://ufcstats.com/fighter-details/87e2468b986ebb79\n",
      "Scraping Chad Vance...\n",
      "http://ufcstats.com/fighter-details/26d61e92a6069cd2\n",
      "Scraping Jared Vanderaa...\n",
      "http://ufcstats.com/fighter-details/2b68d9f125d07b42\n",
      "Scraping Austin Vanderford...\n",
      "http://ufcstats.com/fighter-details/32c3ee378671a5d9\n",
      "Scraping Lando Vannata...\n",
      "http://ufcstats.com/fighter-details/f9b200db02b488d9\n",
      "Scraping Paige VanZant...\n",
      "http://ufcstats.com/fighter-details/4d5197f331c47290\n",
      "Scraping Paul Varelans...\n",
      "http://ufcstats.com/fighter-details/07a18ae55dfc3cd9\n",
      "Scraping Kazula Vargas...\n",
      "http://ufcstats.com/fighter-details/ec18eb918121787c\n",
      "Scraping Jamie Varner...\n",
      "http://ufcstats.com/fighter-details/a54fc2d6fc224dc3\n",
      "Scraping Guilherme Vasconcelos...\n",
      "http://ufcstats.com/fighter-details/d6d5da3c209884bc\n",
      "Scraping Linton Vassell...\n",
      "http://ufcstats.com/fighter-details/a148dfe3485be79d\n",
      "Scraping Billy Vaughan...\n",
      "http://ufcstats.com/fighter-details/61428ed51f5ff465\n",
      "Scraping Yuri Vaulin...\n",
      "http://ufcstats.com/fighter-details/4679a38cced7c64a\n",
      "Scraping Javier Vazquez...\n",
      "http://ufcstats.com/fighter-details/be5cfd73617a5b1a\n",
      "Scraping Manny Vazquez...\n",
      "http://ufcstats.com/fighter-details/8d4d25fd9218860b\n",
      "Scraping Matt Veach...\n",
      "http://ufcstats.com/fighter-details/5731cc327790b731\n",
      "Scraping Joe Vedepo...\n",
      "http://ufcstats.com/fighter-details/d35c3ed553b71fa2\n",
      "Scraping Kelly Velasco...\n",
      "http://ufcstats.com/fighter-details/93c9897f0f9f5dab\n",
      "Scraping Greg Velasco...\n",
      "http://ufcstats.com/fighter-details/34a81ebbce32b06b\n",
      "Scraping Cain Velasquez...\n",
      "http://ufcstats.com/fighter-details/0ff11cc094e887bc\n",
      "Scraping David Velasquez...\n",
      "http://ufcstats.com/fighter-details/09c44b317c98bf96\n",
      "Scraping Bojan Velickovic...\n",
      "http://ufcstats.com/fighter-details/fcce75a25c14a804\n",
      "Scraping Karlos Vemola...\n",
      "http://ufcstats.com/fighter-details/d23ccf4a6c221284\n",
      "Scraping Luigi Vendramini...\n",
      "http://ufcstats.com/fighter-details/2f1a257d6777096d\n",
      "Scraping Jerrel Venetiaan...\n",
      "http://ufcstats.com/fighter-details/602bb270f2bdbf02\n",
      "Scraping Scott Ventimiglia...\n",
      "http://ufcstats.com/fighter-details/6e62bb64f7cc5026\n",
      "Scraping Brandon Vera...\n",
      "http://ufcstats.com/fighter-details/fa315e6c77eee106\n",
      "Scraping Kerry Vera...\n",
      "http://ufcstats.com/fighter-details/df0a1c1e11ad199b\n",
      "Scraping Marlon Vera...\n",
      "http://ufcstats.com/fighter-details/7c7332319c14094c\n",
      "Scraping Carlos Vera...\n",
      "http://ufcstats.com/fighter-details/07f959e6596307bb\n",
      "Scraping Isis Verbeek...\n",
      "http://ufcstats.com/fighter-details/d6f58b8cd1a6ff52\n",
      "Scraping Ernie Verdicia...\n",
      "http://ufcstats.com/fighter-details/2b1587a3376ab743\n",
      "Scraping Joe Veres...\n",
      "http://ufcstats.com/fighter-details/c6d8ae3b016d5ad5\n",
      "Scraping Nikolay Veretennikov...\n",
      "http://ufcstats.com/fighter-details/0f1efce7d2571d10\n",
      "Scraping CJ Vergara...\n",
      "http://ufcstats.com/fighter-details/077e3ace32b72be9\n",
      "Scraping Renato Verissimo...\n",
      "http://ufcstats.com/fighter-details/c24b1db4b809d41b\n",
      "Scraping Bryan Vetell...\n",
      "http://ufcstats.com/fighter-details/13a0fb8fbdafb54f\n",
      "Scraping Marvin Vettori...\n",
      "http://ufcstats.com/fighter-details/7acbb0972e75281a\n",
      "Scraping Hugo Viana...\n",
      "http://ufcstats.com/fighter-details/f95381efb3051d81\n",
      "Scraping Guilherme Viana...\n",
      "http://ufcstats.com/fighter-details/393b8e03fb410a78\n",
      "Scraping Polyana Viana...\n",
      "http://ufcstats.com/fighter-details/9673a497a9da119a\n",
      "Scraping Vitor Vianna...\n",
      "http://ufcstats.com/fighter-details/744f50016c39c26c\n",
      "Scraping James Vick...\n",
      "http://ufcstats.com/fighter-details/6256b2b1562cb8e1\n",
      "Scraping Tamires Vidal...\n",
      "http://ufcstats.com/fighter-details/4f3064faf17aa711\n",
      "Scraping Milton Vieira...\n",
      "http://ufcstats.com/fighter-details/7cf20446453f852b\n",
      "Scraping Reginaldo Vieira...\n",
      "http://ufcstats.com/fighter-details/f9081770e28ea2e1\n",
      "Scraping Ketlen Vieira...\n",
      "http://ufcstats.com/fighter-details/b9706f80d005036c\n",
      "Scraping Rodolfo Vieira...\n",
      "http://ufcstats.com/fighter-details/260e9e0d4954aea6\n",
      "Scraping Steve Vigneault...\n",
      "http://ufcstats.com/fighter-details/6888e31ce88f5b17\n",
      "Scraping Alejandro Villalobos...\n",
      "http://ufcstats.com/fighter-details/2e88f2030d8a928a\n",
      "Scraping DeMarco Villalona...\n",
      "http://ufcstats.com/fighter-details/0275e33febc2818c\n",
      "Scraping Gian Villante...\n",
      "http://ufcstats.com/fighter-details/fcd448a2fe1a23cc\n",
      "Scraping Ike Villanueva...\n",
      "http://ufcstats.com/fighter-details/f9d0cae37dabfafc\n",
      "Scraping Ruben Villareal...\n",
      "http://ufcstats.com/fighter-details/39f68882def7a507\n",
      "Scraping Armando Villarreal...\n",
      "http://ufcstats.com/fighter-details/454c1f0b638972ab\n",
      "Scraping Pablo Villaseca...\n",
      "http://ufcstats.com/fighter-details/34f93dfbd43b2144\n",
      "Scraping Joey Villasenor...\n",
      "http://ufcstats.com/fighter-details/15515e797aedc137\n",
      "Scraping Danillo Villefort...\n",
      "http://ufcstats.com/fighter-details/fd87b1bbfcde9d5e\n",
      "Scraping Yuri Villefort...\n",
      "http://ufcstats.com/fighter-details/0fb1e2694a39a02f\n",
      "Scraping Marcos Vinicius...\n",
      "http://ufcstats.com/fighter-details/e363b21261814830\n",
      "Scraping Brandon Visher...\n",
      "http://ufcstats.com/fighter-details/7c4ec656d8fcb867\n",
      "Scraping Falaniko Vitale...\n",
      "http://ufcstats.com/fighter-details/445a98acb8985970\n",
      "Scraping Cheyanne Vlismas...\n",
      "http://ufcstats.com/fighter-details/4959f10a62f3fec3\n",
      "Scraping Bobby Voelker...\n",
      "http://ufcstats.com/fighter-details/fb8a3025ae722e64\n",
      "Scraping Mateo Vogel...\n",
      "http://ufcstats.com/fighter-details/90b57b19d20e1969\n",
      "Scraping Danylo Voievodkin...\n",
      "http://ufcstats.com/fighter-details/d73a7c36746fbc5b\n",
      "Scraping Alexander Volkanovski...\n",
      "http://ufcstats.com/fighter-details/e1248941344b3288\n",
      "Scraping Jacob Volkmann...\n",
      "http://ufcstats.com/fighter-details/6f81b6de2557739a\n",
      "Scraping Alexander Volkov...\n",
      "http://ufcstats.com/fighter-details/279566840aa55bf2\n",
      "Scraping Jason Von Flue...\n",
      "http://ufcstats.com/fighter-details/c4b9296214f4c09c\n",
      "Scraping Milco Voorn...\n",
      "http://ufcstats.com/fighter-details/277ffed20cf07aea\n",
      "Scraping Mark Vorgeas...\n",
      "http://ufcstats.com/fighter-details/ef0344ed552d8a22\n",
      "Scraping Igor Vovchanchyn...\n",
      "http://ufcstats.com/fighter-details/7929be8290289a47\n",
      "Scraping Jordan Vucenic...\n",
      "http://ufcstats.com/fighter-details/6d38e41efa47a72d\n",
      "Scraping James Wade...\n",
      "http://ufcstats.com/fighter-details/6291decf7f3b6608\n",
      "Scraping Chris Wade...\n",
      "http://ufcstats.com/fighter-details/c8097968da5e5f13\n",
      "Scraping Neil Wain...\n",
      "http://ufcstats.com/fighter-details/6b7bc7eaf2465387\n",
      "Scraping TJ Waldburger...\n",
      "http://ufcstats.com/fighter-details/8f2939f5fd9cca1e\n",
      "Scraping Chase Waldon...\n",
      "http://ufcstats.com/fighter-details/aeb6c57b9bd8bc3a\n",
      "Scraping Andre Walker...\n",
      "http://ufcstats.com/fighter-details/18944a1a6ac1becf\n",
      "Scraping Herschel Walker...\n",
      "http://ufcstats.com/fighter-details/bd92e38aef641673\n",
      "Scraping Donny Walker...\n",
      "http://ufcstats.com/fighter-details/e6147d5ab3685899\n",
      "Scraping Johnny Walker...\n",
      "http://ufcstats.com/fighter-details/c21f26bbde777573\n",
      "Scraping Brogan Walker...\n",
      "http://ufcstats.com/fighter-details/4333a8e70a672eb7\n",
      "Scraping Valter Walker...\n",
      "http://ufcstats.com/fighter-details/f5779a2303ed76ec\n",
      "Scraping Ben Wall...\n",
      "http://ufcstats.com/fighter-details/1ad381c8994c4e5b\n",
      "Scraping Crafton Wallace...\n",
      "http://ufcstats.com/fighter-details/bf41b5131545da12\n",
      "Scraping Rodney Wallace...\n",
      "http://ufcstats.com/fighter-details/b9415726dc3ec526\n",
      "Scraping Jeremy Wallace...\n",
      "http://ufcstats.com/fighter-details/b87c3f460709f74c\n",
      "Scraping Randall Wallace...\n",
      "http://ufcstats.com/fighter-details/95cf6be9071e68b0\n",
      "Scraping James Wallace...\n",
      "http://ufcstats.com/fighter-details/4078de7181a19142\n",
      "Scraping Jim Wallhead...\n",
      "http://ufcstats.com/fighter-details/0c670b443c3d269f\n",
      "Scraping Cory Walmsley...\n",
      "http://ufcstats.com/fighter-details/83c6c3e0f8bde8ee\n",
      "Scraping Richard Walsh...\n",
      "http://ufcstats.com/fighter-details/303a05a7aa3ff761\n",
      "Scraping Patrick Walsh...\n",
      "http://ufcstats.com/fighter-details/b4c96c3d9139bf0e\n",
      "Scraping Erick Wanderlei...\n",
      "http://ufcstats.com/fighter-details/d57e6a8971b6d2bd\n",
      "Scraping Dimitiri Wanderley...\n",
      "http://ufcstats.com/fighter-details/a1d6b308781aa2f5\n",
      "Scraping Andy Wang...\n",
      "http://ufcstats.com/fighter-details/476414d2f18cd059\n",
      "Scraping Sai Wang...\n",
      "http://ufcstats.com/fighter-details/efb9a43415a56d34\n",
      "Scraping Anying Wang...\n",
      "http://ufcstats.com/fighter-details/69e8c632135af48b\n",
      "Scraping Wang Cong...\n",
      "http://ufcstats.com/fighter-details/2997e7fe3c9d3d4a\n",
      "Scraping Joshua Wang-Kim...\n",
      "http://ufcstats.com/fighter-details/d538f13ab21d9633\n",
      "Scraping Curt Warburton...\n",
      "http://ufcstats.com/fighter-details/2721bb808bb2523c\n",
      "Scraping Brennan Ward...\n",
      "http://ufcstats.com/fighter-details/67cd6495280b0a57\n",
      "Scraping Charlie Ward...\n",
      "http://ufcstats.com/fighter-details/e81dd0bb8a64b550\n",
      "Scraping Terrion Ware...\n",
      "http://ufcstats.com/fighter-details/ba5e253af86db1a8\n",
      "Scraping Joe Warren...\n",
      "http://ufcstats.com/fighter-details/c0c1bc0766df4c00\n",
      "Scraping Brian Warren...\n",
      "http://ufcstats.com/fighter-details/c4c4c7dd26c15d91\n",
      "Scraping Merritt Warren...\n",
      "http://ufcstats.com/fighter-details/1e47dba648ea438c\n",
      "Scraping Idris Wasi...\n",
      "http://ufcstats.com/fighter-details/8a19676a3388845a\n",
      "Scraping Kengo Watanabe...\n",
      "http://ufcstats.com/fighter-details/2abe38b81d68a24a\n",
      "Scraping Kazuhisa Watanabe...\n",
      "http://ufcstats.com/fighter-details/951ffadfc4e917ea\n",
      "Scraping Ron Waterman...\n",
      "http://ufcstats.com/fighter-details/efaf544314bb5c2e\n",
      "Scraping Andy Waters...\n",
      "http://ufcstats.com/fighter-details/103e2e67919379c5\n",
      "Scraping Dominic Waters...\n",
      "http://ufcstats.com/fighter-details/2de91c2244ad7e89\n",
      "Scraping Trey Waters...\n",
      "http://ufcstats.com/fighter-details/31dbfbe4e7a6727c\n",
      "Scraping Michelle Waterson-Gomez...\n",
      "http://ufcstats.com/fighter-details/eb04b9d31e938edb\n",
      "Scraping Sam Watford...\n",
      "http://ufcstats.com/fighter-details/1836639ecf9b6e7f\n",
      "Scraping Blake Watkins...\n",
      "http://ufcstats.com/fighter-details/117580b232409824\n",
      "Scraping Kyle Watson...\n",
      "http://ufcstats.com/fighter-details/d7b2c0b53883ee80\n",
      "Scraping Maka Watson...\n",
      "http://ufcstats.com/fighter-details/a31dfd9e8b2dc6ca\n",
      "Scraping Walel Watson...\n",
      "http://ufcstats.com/fighter-details/92aafa8f4b26269b\n",
      "Scraping Tom Watson...\n",
      "http://ufcstats.com/fighter-details/6809c31286b08d97\n",
      "Scraping Enrique Watson...\n",
      "http://ufcstats.com/fighter-details/a99d4aa689bdca18\n",
      "Scraping Brok Weaver...\n",
      "http://ufcstats.com/fighter-details/7c9f96f9a6a5cd50\n",
      "Scraping Jonavin Webb...\n",
      "http://ufcstats.com/fighter-details/f40ec51dd4de47c3\n",
      "Scraping Stephanie Webber...\n",
      "http://ufcstats.com/fighter-details/d44a84409bf0da64\n",
      "Scraping Royston Wee...\n",
      "http://ufcstats.com/fighter-details/b9c03e7a4557e542\n",
      "Scraping Darian Weeks...\n",
      "http://ufcstats.com/fighter-details/326a001926ffb7ec\n",
      "Scraping Joshua Weems...\n",
      "http://ufcstats.com/fighter-details/69888118d968ba52\n",
      "Scraping Daniel Weichel...\n",
      "http://ufcstats.com/fighter-details/7b9dade6bedaabbe\n",
      "Scraping Chris Weidman...\n",
      "http://ufcstats.com/fighter-details/3a8176e15b9887c1\n",
      "Scraping Mark Weir...\n",
      "http://ufcstats.com/fighter-details/9ccdd2ce45903f34\n",
      "Scraping Christian Wellisch...\n",
      "http://ufcstats.com/fighter-details/f1b2a4365799c48b\n",
      "Scraping Malcolm Wellmaker...\n",
      "http://ufcstats.com/fighter-details/2e45d08b3f2f02c8\n",
      "Scraping Jeremiah Wells...\n",
      "http://ufcstats.com/fighter-details/d66a46de8d705353\n",
      "Scraping Fabricio Werdum...\n",
      "http://ufcstats.com/fighter-details/492b202d2064e7a9\n",
      "Scraping Mike Wessel...\n",
      "http://ufcstats.com/fighter-details/b51841e7c594090d\n",
      "Scraping Dustin West...\n",
      "http://ufcstats.com/fighter-details/5f5763b3a4de8dd4\n",
      "Scraping Sheldon Westcott...\n",
      "http://ufcstats.com/fighter-details/ec2d13a87d3d9541\n",
      "Scraping Aaron Wetherspoon...\n",
      "http://ufcstats.com/fighter-details/1ce7998e0a215caa\n",
      "Scraping Coty Wheeler...\n",
      "http://ufcstats.com/fighter-details/e57f0b06ea39e360\n",
      "Scraping Vernon White...\n",
      "http://ufcstats.com/fighter-details/12458872d6afae1b\n",
      "Scraping Steve White...\n",
      "http://ufcstats.com/fighter-details/d181689653115b6a\n",
      "Scraping Alex White...\n",
      "http://ufcstats.com/fighter-details/c17041f1bb5768d8\n",
      "Scraping Craig White...\n",
      "http://ufcstats.com/fighter-details/3dd949593346dbc3\n",
      "Scraping Patrik White...\n",
      "http://ufcstats.com/fighter-details/4debc6c4c6249690\n",
      "Scraping Robert Whiteford...\n",
      "http://ufcstats.com/fighter-details/1dafccb62a0f98ec\n",
      "Scraping Mike Whitehead...\n",
      "http://ufcstats.com/fighter-details/22d1e00e1aabb7c9\n",
      "Scraping Garett Whiteley...\n",
      "http://ufcstats.com/fighter-details/129537073431e52e\n",
      "Scraping Mitch Whitesel...\n",
      "http://ufcstats.com/fighter-details/b6debbda44d4a5a0\n",
      "Scraping Emily Whitmire...\n",
      "http://ufcstats.com/fighter-details/b3d21b2610dcfaeb\n",
      "Scraping Robert Whittaker...\n",
      "http://ufcstats.com/fighter-details/e1147d3d2dabe1ce\n",
      "Scraping Josh Wick...\n",
      "http://ufcstats.com/fighter-details/13935768cf8aeb86\n",
      "Scraping Adam Wieczorek...\n",
      "http://ufcstats.com/fighter-details/efa1f6b42c86793c\n",
      "Scraping Orlando Wiet...\n",
      "http://ufcstats.com/fighter-details/a6c2f5381d575920\n",
      "Scraping Jonathan Wiezorek...\n",
      "http://ufcstats.com/fighter-details/60884f31ead1609c\n",
      "Scraping Justin Wilcox...\n",
      "http://ufcstats.com/fighter-details/4a482a0100cfcd0a\n",
      "Scraping Joe Wilk...\n",
      "http://ufcstats.com/fighter-details/781014fb7e8e647a\n",
      "Scraping Aaron Wilkinson...\n",
      "http://ufcstats.com/fighter-details/338a11d3674eb2d4\n",
      "Scraping Mike Wilkinson...\n",
      "http://ufcstats.com/fighter-details/cfaf010d5b389c09\n",
      "Scraping Rob Wilkinson...\n",
      "http://ufcstats.com/fighter-details/826475cc758e60e6\n",
      "Scraping James Wilks...\n",
      "http://ufcstats.com/fighter-details/852454c572675334\n",
      "Scraping Tedd Williams...\n",
      "http://ufcstats.com/fighter-details/b63e800c18e011b5\n",
      "Scraping Pete Williams...\n",
      "http://ufcstats.com/fighter-details/6291ac0a3726732f\n",
      "Scraping Rubin Williams...\n",
      "http://ufcstats.com/fighter-details/6f812143641ceff8\n",
      "Scraping Carter Williams...\n",
      "http://ufcstats.com/fighter-details/b8e2f10efb6eca85\n",
      "Scraping Patrick Williams...\n",
      "http://ufcstats.com/fighter-details/39330403ad27c2bb\n",
      "Scraping Tim Williams...\n",
      "http://ufcstats.com/fighter-details/990bd63726a577f8\n",
      "Scraping Jordan Williams...\n",
      "http://ufcstats.com/fighter-details/e26bd53b751d61d9\n",
      "Scraping Cole Williams...\n",
      "http://ufcstats.com/fighter-details/f9a20a17d712ef7c\n",
      "Scraping Khaos Williams...\n",
      "http://ufcstats.com/fighter-details/2558ae2e5671e318\n",
      "Scraping Karl Williams...\n",
      "http://ufcstats.com/fighter-details/d35f734c56a89103\n",
      "Scraping Karl Willis...\n",
      "http://ufcstats.com/fighter-details/95883dbdab4fcf0f\n",
      "Scraping Justin Willis...\n",
      "http://ufcstats.com/fighter-details/ce1e867808ef5fce\n",
      "Scraping Chris Wilson...\n",
      "http://ufcstats.com/fighter-details/a56607a451e4c70d\n",
      "Scraping Greg Wilson...\n",
      "http://ufcstats.com/fighter-details/9cc84087ee768342\n",
      "Scraping Jonathan Wilson...\n",
      "http://ufcstats.com/fighter-details/cd01f0b768a32475\n",
      "Scraping Sean Wilson...\n",
      "http://ufcstats.com/fighter-details/b8e6393c39cb9740\n",
      "Scraping Westin Wilson...\n",
      "http://ufcstats.com/fighter-details/7b3503352cd53abb\n",
      "Scraping Matt Wiman...\n",
      "http://ufcstats.com/fighter-details/eb29176b03dfa888\n",
      "Scraping Eddie Wineland...\n",
      "http://ufcstats.com/fighter-details/fc9a9559a05f2704\n",
      "Scraping Deron Winn...\n",
      "http://ufcstats.com/fighter-details/483a953b18d73bb3\n",
      "Scraping Andre Winner...\n",
      "http://ufcstats.com/fighter-details/b45d6b73f4ca4467\n",
      "Scraping Eric Wisely...\n",
      "http://ufcstats.com/fighter-details/53f84637dfffab7a\n",
      "Scraping Keith Wisniewski...\n",
      "http://ufcstats.com/fighter-details/cd12227edd3f134b\n",
      "Scraping Jason Witt...\n",
      "http://ufcstats.com/fighter-details/5f3805dda9661cba\n",
      "Scraping Travis Wiuff...\n",
      "http://ufcstats.com/fighter-details/7f9f528cb72a6ed1\n",
      "Scraping Ray Wizard...\n",
      "http://ufcstats.com/fighter-details/ea0ad155451ed1f5\n",
      "Scraping Karolina Wojcik...\n",
      "http://ufcstats.com/fighter-details/b99b3620839ea911\n",
      "Scraping Danyelle Wolf...\n",
      "http://ufcstats.com/fighter-details/a7e3f02fe2b2fe30\n",
      "Scraping Brandon Wolff...\n",
      "http://ufcstats.com/fighter-details/aa79d5399571068e\n",
      "Scraping Xue Do Won...\n",
      "http://ufcstats.com/fighter-details/daa89f01e1c0f42a\n",
      "Scraping Joanne Wood...\n",
      "http://ufcstats.com/fighter-details/12f91bfa8f1f723b\n",
      "Scraping Nathaniel Wood...\n",
      "http://ufcstats.com/fighter-details/329e403448756217\n",
      "Scraping Val Woodburn...\n",
      "http://ufcstats.com/fighter-details/7a47e068f8017019\n",
      "Scraping Tyron Woodley...\n",
      "http://ufcstats.com/fighter-details/effd9de9937996f8\n",
      "Scraping Salvador Woods...\n",
      "http://ufcstats.com/fighter-details/8de471543d9c933e\n",
      "Scraping Logan Woods...\n",
      "http://ufcstats.com/fighter-details/133a9d2e6efd8a50\n",
      "Scraping Sean Woodson...\n",
      "http://ufcstats.com/fighter-details/4682bc59d5f55145\n",
      "Scraping Cal Worsham...\n",
      "http://ufcstats.com/fighter-details/de3ed2e152520c8d\n",
      "Scraping Hunter Worsham...\n",
      "http://ufcstats.com/fighter-details/8fb808fc2e145bd6\n",
      "Scraping Khama Worthy...\n",
      "http://ufcstats.com/fighter-details/78e501478a36a018\n",
      "Scraping Eric Wray...\n",
      "http://ufcstats.com/fighter-details/eb6edce3028f05c0\n",
      "Scraping Justin Wren...\n",
      "http://ufcstats.com/fighter-details/e78f601035d677f2\n",
      "Scraping JW Wright...\n",
      "http://ufcstats.com/fighter-details/2a0b19a96f848eff\n",
      "Scraping Chris Wright...\n",
      "http://ufcstats.com/fighter-details/7182146226dabe22\n",
      "Scraping Jordan Wright...\n",
      "http://ufcstats.com/fighter-details/c878270af633eb11\n",
      "Scraping Marcin Wrzosek...\n",
      "http://ufcstats.com/fighter-details/aac6edb0d5e0b7e9\n",
      "Scraping Wu Yanan...\n",
      "http://ufcstats.com/fighter-details/fdbefee0827e1567\n",
      "Scraping Wulijiburen...\n",
      "http://ufcstats.com/fighter-details/2296125b6c362355\n",
      "Scraping Wuziazibieke Jiahefu...\n",
      "http://ufcstats.com/fighter-details/2d077e22886298be\n",
      "Scraping Rubens Xavier...\n",
      "http://ufcstats.com/fighter-details/e6dac752a2418a88\n",
      "Scraping Eddie Yagin...\n",
      "http://ufcstats.com/fighter-details/cc84b68f862b466f\n",
      "Scraping Rani Yahya...\n",
      "http://ufcstats.com/fighter-details/94527830000ab715\n",
      "Scraping Mohammad Yahya...\n",
      "http://ufcstats.com/fighter-details/3753714927f18437\n",
      "Scraping Alexander Yakovlev...\n",
      "http://ufcstats.com/fighter-details/d06f8869449ba7bd\n",
      "Scraping Keiichiro Yamamiya...\n",
      "http://ufcstats.com/fighter-details/6014d25e73b669c9\n",
      "Scraping Kenichi Yamamoto...\n",
      "http://ufcstats.com/fighter-details/9f488f520ed25bbf\n",
      "Scraping Yoshihisa Yamamoto...\n",
      "http://ufcstats.com/fighter-details/eed2b71d77d95416\n",
      "Scraping Atsushi Yamamoto...\n",
      "http://ufcstats.com/fighter-details/351264d11286d09a\n",
      "Scraping Norifumi Yamamoto...\n",
      "http://ufcstats.com/fighter-details/4834ff149dc9542a\n",
      "Scraping Hiroko Yamanaka...\n",
      "http://ufcstats.com/fighter-details/283645128ae57eda\n",
      "Scraping Goiti Yamauchi...\n",
      "http://ufcstats.com/fighter-details/9e1a7101fefe9746\n",
      "Scraping Takeshi Yamazaki...\n",
      "http://ufcstats.com/fighter-details/d1d20e651e6cbc02\n",
      "Scraping Yan Xiaonan...\n",
      "http://ufcstats.com/fighter-details/c41d426cc7326d1b\n",
      "Scraping Petr Yan...\n",
      "http://ufcstats.com/fighter-details/d661ce4da776fc20\n",
      "Scraping Yan Qihui...\n",
      "http://ufcstats.com/fighter-details/5c9c2e247c836b67\n",
      "Scraping Adam Yandiev...\n",
      "http://ufcstats.com/fighter-details/0a95c474e61a6c44\n",
      "Scraping Adrian Yanez...\n",
      "http://ufcstats.com/fighter-details/0232cabbc30a2372\n",
      "Scraping Dongi Yang...\n",
      "http://ufcstats.com/fighter-details/aed06011bf62237b\n",
      "Scraping Jianping Yang...\n",
      "http://ufcstats.com/fighter-details/d3c554d6e11fc9d6\n",
      "Scraping Masutatsu Yano...\n",
      "http://ufcstats.com/fighter-details/d56caaa5e123f518\n",
      "Scraping Emmanuel Yarborough...\n",
      "http://ufcstats.com/fighter-details/2299605af59fd309\n",
      "Scraping Cale Yarbrough...\n",
      "http://ufcstats.com/fighter-details/a0b91014e9d16a76\n",
      "Scraping Tadao Yasuda...\n",
      "http://ufcstats.com/fighter-details/49e7e05f902479ca\n",
      "Scraping Yoshiaki Yatsu...\n",
      "http://ufcstats.com/fighter-details/620be7e0712d431b\n",
      "Scraping Chris Yee...\n",
      "http://ufcstats.com/fighter-details/920632ca1b78fae5\n",
      "Scraping Yibugele...\n",
      "http://ufcstats.com/fighter-details/cc2fcae2c0dc501d\n",
      "Scraping Yin Shuai...\n",
      "http://ufcstats.com/fighter-details/a78dc3910554dbae\n",
      "Scraping Yizha...\n",
      "http://ufcstats.com/fighter-details/3f11fd1751fa83b1\n",
      "Scraping Ashley Yoder...\n",
      "http://ufcstats.com/fighter-details/b4c6c904a9ffc5e8\n",
      "Scraping Hirotaka Yokoi...\n",
      "http://ufcstats.com/fighter-details/35585d970300d45a\n",
      "Scraping Kazunori Yokota...\n",
      "http://ufcstats.com/fighter-details/a8e8587a06e73c87\n",
      "Scraping John Yoo...\n",
      "http://ufcstats.com/fighter-details/40eb2aef4d5577d4\n",
      "Scraping SangHoon Yoo...\n",
      "http://ufcstats.com/fighter-details/00b490982afd1b17\n",
      "Scraping Dong Sik Yoon...\n",
      "http://ufcstats.com/fighter-details/ad99fa5325519169\n",
      "Scraping Yoshiyuki Yoshida...\n",
      "http://ufcstats.com/fighter-details/ab8900ae1f1dfd4c\n",
      "Scraping Hidehiko Yoshida...\n",
      "http://ufcstats.com/fighter-details/2eae41f61776c60f\n",
      "Scraping SuYoung You...\n",
      "http://ufcstats.com/fighter-details/a474aade8eb3a8f0\n",
      "Scraping Kaitlin Young...\n",
      "http://ufcstats.com/fighter-details/79ff6545b0abc685\n",
      "Scraping Artenus Young...\n",
      "http://ufcstats.com/fighter-details/8d4943a9ce9f521b\n",
      "Scraping Trenell Young...\n",
      "http://ufcstats.com/fighter-details/bf5183e1c1afc3b2\n",
      "Scraping Jason Young...\n",
      "http://ufcstats.com/fighter-details/f59e9e49ef85b469\n",
      "Scraping Shane Young...\n",
      "http://ufcstats.com/fighter-details/4cd8b03aee1d0138\n",
      "Scraping Shanna Young...\n",
      "http://ufcstats.com/fighter-details/568bbad0eaced57c\n",
      "Scraping Gauge Young...\n",
      "http://ufcstats.com/fighter-details/b2a78df161bd67f9\n",
      "Scraping Besam Yousef...\n",
      "http://ufcstats.com/fighter-details/98ec9f385cca47fc\n",
      "Scraping Han Ten Yun...\n",
      "http://ufcstats.com/fighter-details/67ec58d7cf599835\n",
      "Scraping Rob Yundt...\n",
      "http://ufcstats.com/fighter-details/42078a86d3dd037b\n",
      "Scraping Sodiq Yusuff...\n",
      "http://ufcstats.com/fighter-details/94426bb170c88115\n",
      "Scraping Gilbert Yvel...\n",
      "http://ufcstats.com/fighter-details/d29b5c4f22c6357d\n",
      "Scraping Luke Zachrich...\n",
      "http://ufcstats.com/fighter-details/2284092f8b63273b\n",
      "Scraping Anton Zafir...\n",
      "http://ufcstats.com/fighter-details/8c822811eedc11ad\n",
      "Scraping Aiemann Zahabi...\n",
      "http://ufcstats.com/fighter-details/24656ef4d605c96f\n",
      "Scraping Joao Zaiden...\n",
      "http://ufcstats.com/fighter-details/6b614bda982f5214\n",
      "Scraping Youssef Zalal...\n",
      "http://ufcstats.com/fighter-details/52c2ae6d2f2d2613\n",
      "Scraping Elizeu Zaleski dos Santos...\n",
      "http://ufcstats.com/fighter-details/8adcbd525fab8d9b\n",
      "Scraping Zach Zane...\n",
      "http://ufcstats.com/fighter-details/cc3878d1ab41a5fa\n",
      "Scraping Roger Zapata...\n",
      "http://ufcstats.com/fighter-details/fe5ca7ef93c3f6a7\n",
      "Scraping Marius Zaromskis...\n",
      "http://ufcstats.com/fighter-details/abcf7e55a0a9ed89\n",
      "Scraping David Zawada...\n",
      "http://ufcstats.com/fighter-details/3bb2dc8e87b10a46\n",
      "Scraping Manolo Zecchini...\n",
      "http://ufcstats.com/fighter-details/fd7ab338e4953644\n",
      "Scraping Joao Zeferino...\n",
      "http://ufcstats.com/fighter-details/be4076c9e8d791e3\n",
      "Scraping Daniel Zellhuber...\n",
      "http://ufcstats.com/fighter-details/4148802ae4a50768\n",
      "Scraping Craig Zellner...\n",
      "http://ufcstats.com/fighter-details/3794e5e0bb0defb6\n",
      "Scraping Rickson Zenidim...\n",
      "http://ufcstats.com/fighter-details/c879d8620261b1a3\n",
      "Scraping Roman Zentsov...\n",
      "http://ufcstats.com/fighter-details/3144121470023e9a\n",
      "Scraping Carlos Zevallos...\n",
      "http://ufcstats.com/fighter-details/cbf69fa846c7e3ee\n",
      "Scraping Zhang Tiequan...\n",
      "http://ufcstats.com/fighter-details/c23e3d4875340d8d\n",
      "Scraping Zhang Lipeng...\n",
      "http://ufcstats.com/fighter-details/7b310409440c9102\n",
      "Scraping Zhang Weili...\n",
      "http://ufcstats.com/fighter-details/1ebe20ebbfa15e29\n",
      "Scraping Zhang Mingyang...\n",
      "http://ufcstats.com/fighter-details/8a65fd9ba31fd3f7\n",
      "Scraping Daermisi Zhawupasi...\n",
      "http://ufcstats.com/fighter-details/fd52e5f9ab25c94c\n",
      "Scraping Daria Zhelezniakova...\n",
      "http://ufcstats.com/fighter-details/07047eb7d17fb0a2\n",
      "Scraping Yao Zhikui...\n",
      "http://ufcstats.com/fighter-details/5ea918ea81b7dee2\n",
      "Scraping Zhu Kangjie...\n",
      "http://ufcstats.com/fighter-details/6f4ec5aa3eced219\n",
      "Scraping Zhalgas Zhumagulov...\n",
      "http://ufcstats.com/fighter-details/55fa6ce3e522c8bb\n",
      "Scraping Fares Ziam...\n",
      "http://ufcstats.com/fighter-details/1e4f273069fb9e85\n",
      "Scraping Mike Zichelle...\n",
      "http://ufcstats.com/fighter-details/6d3398b910461f2f\n",
      "Scraping James Zikic...\n",
      "http://ufcstats.com/fighter-details/4b4fc3ddc307bc73\n",
      "Scraping Errol Zimmerman...\n",
      "http://ufcstats.com/fighter-details/0aa74d04c196800c\n",
      "Scraping Cat Zingano...\n",
      "http://ufcstats.com/fighter-details/3ecd936bd8814108\n",
      "Scraping Igor Zinoviev...\n",
      "http://ufcstats.com/fighter-details/108afe61a26bcbf4\n",
      "Scraping Dave Zitanick...\n",
      "http://ufcstats.com/fighter-details/be124bdd60fab7d5\n",
      "Scraping Alex Zuniga...\n",
      "http://ufcstats.com/fighter-details/02d808afb96669de\n",
      "Scraping George Zuniga...\n",
      "http://ufcstats.com/fighter-details/1291dd6b8ab4d952\n",
      "Scraping Allan Zuniga...\n",
      "http://ufcstats.com/fighter-details/523af801b3429015\n",
      "Scraping Virgil Zwicker...\n",
      "http://ufcstats.com/fighter-details/0c277f3ff66b0208\n"
     ]
    }
   ],
   "source": [
    "#parse site using alphabet\n",
    "all_fighter_links = []\n",
    "alphabet = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "for i in range(len(alphabet)):\n",
    "    url=f'http://ufcstats.com/statistics/fighters?char={alphabet[i]}&page=all'\n",
    "    headers = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246\"}\n",
    "    \n",
    "    #site request\n",
    "    site = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(site.content, 'html.parser')\n",
    "\n",
    "    #scrape fighters from each page\n",
    "    fighterLinks = []\n",
    "    fighter_links = soup.find_all('a', class_=re.compile(\"b-link b-link_style_black\"))\n",
    "\n",
    "    #find hrefs\n",
    "    for link in fighter_links:\n",
    "        href = link['href']\n",
    "        if href:\n",
    "            fighterLinks.append(href)\n",
    "\n",
    "    #remove link dups\n",
    "    fighterLinks = list(dict.fromkeys(fighterLinks))\n",
    "    all_fighter_links.append(fighterLinks)\n",
    "\n",
    "all_fighter_links = list(itertools.chain.from_iterable(all_fighter_links))\n",
    "print(f'Fighters Found: {len(all_fighter_links)}')\n",
    "\n",
    "\n",
    "    \n",
    "#scrape individual fighter stats\n",
    "fighters_statistics = []\n",
    "for i in all_fighter_links:\n",
    "    try:\n",
    "        site = requests.get(i, headers=headers)\n",
    "        soup = BeautifulSoup(site.content, 'html.parser')\n",
    "\n",
    "        #initialize stats\n",
    "        name = None\n",
    "        nickname = None\n",
    "        wins = None\n",
    "        losses = None\n",
    "        draws = None\n",
    "        height = None\n",
    "        weight = None\n",
    "        reach = None\n",
    "        stance = None\n",
    "        dOB = None\n",
    "        sig_strikes_landed_per_min = None\n",
    "        sig_striking_accuracy = None\n",
    "        sig_strike_absorbed_per_min = None\n",
    "        sig_strike_defense = None\n",
    "        takedown_average = None\n",
    "        takedown_accuracy = None\n",
    "        takedown_defense = None\n",
    "        sub_average = None\n",
    "\n",
    "\n",
    "        #scrape + clean nickname\n",
    "        try:\n",
    "            nick = soup.find('p', class_=re.compile('b-content__Nickname'))\n",
    "            nickname = nick.text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        #scrape name\n",
    "        tempName = soup.find_all('span', class_=re.compile(\"b-content__title-highlight\"))\n",
    "        #clean name\n",
    "        name = tempName[0].text.strip()\n",
    "\n",
    "        #scrape records\n",
    "        tempRecord = soup.find_all('span', class_=re.compile('b-content__title-record'))\n",
    "        #clean wins + losses + draws\n",
    "        record = tempRecord[0].text.strip()\n",
    "        listRecord = record.split('-')\n",
    "        for idx, ele in enumerate(listRecord):\n",
    "            listRecord[idx] = ele.replace('Record: ', '')\n",
    "        wins = listRecord[0]\n",
    "        losses = listRecord[1]\n",
    "        draws = listRecord[2]\n",
    "        \n",
    "        #clean soup for rest of stats\n",
    "        i_tags = soup.find_all('i')\n",
    "        for itags in i_tags:\n",
    "            itags.decompose()\n",
    "        \n",
    "        #clean stats\n",
    "        tempRest = soup.find_all('li', class_=re.compile('b-list__box-list-item b-list__box-list-item_type_block'))\n",
    "    \n",
    "    \n",
    "        height = tempRest[0].text.strip()\n",
    "        weight = tempRest[1].text.strip()\n",
    "        reach = tempRest[2].text.strip()\n",
    "        stance = tempRest[3].text.strip()\n",
    "        dOB = tempRest[4].text.strip()\n",
    "        sig_strikes_landed_per_min = tempRest[5].text.strip()\n",
    "        sig_striking_accuracy = tempRest[6].text.strip()\n",
    "        sig_strike_absorbed_per_min = tempRest[7].text.strip()\n",
    "        sig_strike_defense = tempRest[8].text.strip()\n",
    "        takedown_average = tempRest[10].text.strip()\n",
    "        takedown_accuracy = tempRest[11].text.strip()\n",
    "        takedown_defense = tempRest[12].text.strip()\n",
    "        sub_average = tempRest[13].text.strip()\n",
    "        \n",
    "        #notification of scrape\n",
    "        print(f'Scraping {name}...')\n",
    "        print(i)\n",
    "\n",
    "\n",
    "        #adding stats to fighters_statistics to prepare for csv\n",
    "        fighters_statistics.append([name, nickname, wins, losses, draws, height, weight, reach, stance, dOB, sig_strikes_landed_per_min, sig_striking_accuracy, sig_strike_absorbed_per_min, sig_strike_defense, takedown_average, takedown_accuracy, takedown_defense, sub_average])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    #create csv file\n",
    "    head = ['name', 'nickname', 'wins', 'losses', 'draws', 'height', 'weight', 'reach', 'stance', 'dOB', 'sig_strikes_landed_per_min', 'sig_striking_accuracy_%', 'sig_strike_absorbed_per_min', 'sig_strike_defense(%_of_sig_strikes_not_landed_by_opponent)', 'takedown_average(average_takedown_landed_per_fifteen_min)', 'takedown_accuracy_%', 'takedown_defense(%_of_opponent_takedown_not_landed)', 'sub_average(average_subs_attempted_per_15_mins)']\n",
    "\n",
    "    with open(f'ufc_fighters_statistics{dateToday}.csv', 'w', encoding='UTF8', newline='') as scrapedStats:\n",
    "        writer = csv.writer(scrapedStats)\n",
    "        writer.writerow(head)\n",
    "        writer.writerows(fighters_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensure site is accessible\n",
    "def getProxyUserAgentUFC():\n",
    "    for i in proxylist:\n",
    "        #test to see if website is accessible\n",
    "        userAgents = ['Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/116.0','Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/115.0','Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36','Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36','Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36','Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0','Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/116.0','Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36 Edg/115.0.1901.188','insomnia/8.4.5','Mozilla/5.0 (Linux; Android 13; Pixel 6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (Linux; Android 13; Pixel 6a) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (Linux; Android 13; Pixel 6 Pro) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (Linux; Android 13; Pixel 7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (Linux; Android 13; Pixel 7 Pro) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (Linux; Android 12; moto g pure) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (Linux; Android 12; moto g stylus 5G) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36v','Mozilla/5.0 (Linux; Android 13; SM-G998U) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (iPhone; CPU iPhone OS 12_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) FxiOS/13.2b11866 Mobile/16A366 Safari/605.1.15','Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/11.0 Mobile/15A372 Safari/604.1']\n",
    "        userAgent = userAgents[random.randint(0,len(userAgents)-1)]\n",
    "        try:\n",
    "            #site request\n",
    "            url = \"https://www.ufc.com/athletes/all\"\n",
    "\n",
    "            pageRandom = random.randint(0, 100)\n",
    "            querystring = {\"page\":f\"{pageRandom}\"}\n",
    "\n",
    "            payload = \"\"\n",
    "            headers = {\n",
    "                \"cookie\": \"STYXKEY_region=USA.US.en.Default\",\n",
    "                \"User-Agent\": f'{userAgent}'\n",
    "            }\n",
    "\n",
    "            response = requests.request(\"GET\", url, data=payload, headers=headers, params=querystring, proxies={'http': f\"http://{i}\"})\n",
    "            if response.status_code == 200:\n",
    "                proxyheader = [i,userAgent]\n",
    "                return proxyheader\n",
    "        except:\n",
    "            pass\n",
    "        #check to see if user agent was the issue\n",
    "        try:\n",
    "            userAgents.remove(userAgent)\n",
    "            userAgent = userAgents[random.randint(0,len(userAgents)-1)]\n",
    "            #site request\n",
    "            url = \"https://www.ufc.com/athletes/all\"\n",
    "\n",
    "            pageRandom = random.randint(0, 100)\n",
    "            querystring = {\"page\":f\"{pageRandom}\"}\n",
    "\n",
    "            payload = \"\"\n",
    "            headers = {\n",
    "                \"cookie\": \"STYXKEY_region=USA.US.en.Default\",\n",
    "                \"User-Agent\": f'{userAgent}'\n",
    "            }\n",
    "\n",
    "            response = requests.request(\"GET\", url, data=payload, headers=headers, params=querystring, proxies={'http': f\"http://{i}\"})\n",
    "            if response.status_code == 200:\n",
    "                proxyheader = [i,userAgent]\n",
    "                return proxyheader\n",
    "        #if user agent is not new issue, wait for next IP\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            print(\"Waiting for new IP...\")\n",
    "            ipurl = \"https://ipecho.net/plain\"\n",
    "            ipHeader = {\"User-Agent\": \"insomnia/8.4.5\"}\n",
    "            ipr = requests.request(\"GET\", url=ipurl, headers=ipHeader)\n",
    "            soup = BeautifulSoup(ipr.content, 'html.parser')\n",
    "            currentIp = soup.text.strip()\n",
    "            newIP = soup.text.strip()\n",
    "            while(currentIp == newIP):\n",
    "                ipurl = \"https://ipecho.net/plain\"\n",
    "                ipHeader = {\"User-Agent\": \"insomnia/8.4.5\"}\n",
    "                ipr = requests.request(\"GET\", url=ipurl, headers=ipHeader)\n",
    "                soup = BeautifulSoup(ipr.content, 'html.parser')\n",
    "                newIP = soup.text.strip()\n",
    "                time.sleep(15)\n",
    "            userAgents.remove(userAgent)\n",
    "            userAgent = userAgents[random.randint(0,len(userAgents)-1)]\n",
    "            #site request\n",
    "            url = \"https://www.ufc.com/athletes/all\"\n",
    "\n",
    "            pageRandom = random.randint(0, 100)\n",
    "            querystring = {\"page\":f\"{pageRandom}\"}\n",
    "\n",
    "            payload = \"\"\n",
    "            headers = {\n",
    "                \"cookie\": \"STYXKEY_region=USA.US.en.Default\",\n",
    "                \"User-Agent\": f'{userAgent}'\n",
    "            }\n",
    "\n",
    "            response = requests.request(\"GET\", url, data=payload, headers=headers, params=querystring, proxies={'http': f\"http://{i}\"})\n",
    "            if response.status_code == 200:\n",
    "                proxyheader = [i,userAgent]\n",
    "                return proxyheader\n",
    "        except:\n",
    "            print(\"Maintenence required...\")\n",
    "            input(\"Press enter to continue\")\n",
    "            userAgents.remove(userAgent)\n",
    "            userAgent = userAgents[random.randint(0,len(userAgents)-1)]\n",
    "            #site request\n",
    "            url = \"https://www.ufc.com/athletes/all\"\n",
    "\n",
    "            pageRandom = random.randint(0, 100)\n",
    "            querystring = {\"page\":f\"{pageRandom}\"}\n",
    "\n",
    "            payload = \"\"\n",
    "            headers = {\n",
    "                \"cookie\": \"STYXKEY_region=USA.US.en.Default\",\n",
    "                \"User-Agent\": f'{userAgent}'\n",
    "            }\n",
    "\n",
    "            response = requests.request(\"GET\", url, data=payload, headers=headers, params=querystring, proxies={'http': f\"http://{i}\"})\n",
    "            if response.status_code == 200:\n",
    "                proxyheader = [i,userAgent]\n",
    "                return proxyheader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Athletes found: 2994\n",
      "273\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "Waiting for new IP... (no func)\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "Waiting for new IP...\n",
      "Maintenence required...\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "Waiting for new IP... (no func)\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "Fighter links found: 2971\n",
      "Scraping Danny Abbadi...\n",
      "https://www.ufc.com/athlete/danny-abbadi\n",
      "Scraping Nariman Abbassov...\n",
      "https://www.ufc.com/athlete/nariman-abbassov\n",
      "Scraping Tank Abbott...\n",
      "https://www.ufc.com/athlete/tank-abbott\n",
      "Scraping Hamdy Abdelwahab...\n",
      "https://www.ufc.com/athlete/hamdy-abdelwahab\n",
      "Scraping Mansur Abdul-Malik...\n",
      "https://www.ufc.com/athlete/mansur-abdul-malik\n",
      "Scraping Shamil Abdurakhimov...\n",
      "https://www.ufc.com/athlete/shamil-abdurakhimov\n",
      "Scraping Daichi Abe...\n",
      "https://www.ufc.com/athlete/daichi-abe\n",
      "Scraping Papy Abedi...\n",
      "https://www.ufc.com/athlete/papy-abedi\n",
      "Scraping Klidson Abreu...\n",
      "https://www.ufc.com/athlete/klidson-abreu\n",
      "Scraping Ricardo Abreu...\n",
      "https://www.ufc.com/athlete/ricardo-abreu\n",
      "Scraping John Adajar...\n",
      "https://www.ufc.com/athlete/john-adajar\n",
      "Scraping Juan Adams...\n",
      "https://www.ufc.com/athlete/juan-adams\n",
      "Scraping Scott Adams...\n",
      "https://www.ufc.com/athlete/tenk-ebbott\n",
      "Scraping Anthony Adams...\n",
      "https://www.ufc.com/athlete/anthony-adams\n",
      "Scraping Zarrukh Adashev...\n",
      "https://www.ufc.com/athlete/zarrukh-adashev\n",
      "Waiting for new IP...\n",
      "Maintenence required...\n",
      "Scraping Israel Adesanya...\n",
      "https://www.ufc.com/athlete/israel-adesanya\n",
      "Scraping Sam Adkins...\n",
      "https://www.ufc.com/athlete/sam-adkins\n",
      "Scraping Nick Agallar...\n",
      "https://www.ufc.com/athlete/nick-agallar\n",
      "Scraping Mariya Agapova...\n",
      "https://www.ufc.com/athlete/mariya-agapova\n",
      "Scraping Fabio Agu...\n",
      "https://www.ufc.com/athlete/fabio-agu\n",
      "Scraping Marcello Aguiar...\n",
      "https://www.ufc.com/athlete/marcello-aguiar\n",
      "Scraping Kevin Aguilar...\n",
      "https://www.ufc.com/athlete/kevin-aguilar\n",
      "Scraping Jessica Aguilar...\n",
      "https://www.ufc.com/athlete/jessica-aguilar\n",
      "Scraping Jesus Aguilar...\n",
      "https://www.ufc.com/athlete/jesus-aguilar\n",
      "Scraping Christian Aguilera...\n",
      "https://www.ufc.com/athlete/christian-aguilera\n",
      "Scraping Nick Aguirre...\n",
      "https://www.ufc.com/athlete/nick-aguirre\n",
      "Scraping Ashiek Ajim...\n",
      "https://www.ufc.com/athlete/ashiek-ajim\n",
      "Scraping Omari Akhmedov...\n",
      "https://www.ufc.com/athlete/omari-akhmedov\n",
      "Scraping Yoshihiro Akiyama...\n",
      "https://www.ufc.com/athlete/yoshihiro-akiyama\n",
      "Scraping Rostem Akman...\n",
      "https://www.ufc.com/athlete/rostam-akman\n",
      "Scraping Mostapha Al Turk...\n",
      "https://www.ufc.com/athlete/mostapha-al-turk\n",
      "Scraping Razak Al-Hassan...\n",
      "https://www.ufc.com/athlete/razak-al-hassan\n",
      "Scraping Herdem Alacabek...\n",
      "https://www.ufc.com/athlete/herdem-alacabek\n",
      "Scraping Alatengheili...\n",
      "https://www.ufc.com/athlete/heili-alateng\n",
      "Scraping John Albert...\n",
      "https://www.ufc.com/athlete/john-albert\n",
      "Scraping Junior Albini...\n",
      "https://www.ufc.com/athlete/junior-albini\n",
      "Scraping Wes Albritton...\n",
      "https://www.ufc.com/athlete/wes-albritton\n",
      "Scraping Alexandra Albu...\n",
      "https://www.ufc.com/athlete/alexandra-albu\n",
      "Scraping Ildemar Alcantara...\n",
      "https://www.ufc.com/athlete/igor-araudzho-1\n",
      "Scraping Iuri Alcantara...\n",
      "https://www.ufc.com/athlete/iuri-alcantara\n",
      "Scraping Alfonso Alcarez...\n",
      "https://www.ufc.com/athlete/alfonso-alcarez\n",
      "Scraping Gilbert Aldana...\n",
      "https://www.ufc.com/athlete/gilbert-aldana\n",
      "Scraping Hector Aldana...\n",
      "https://www.ufc.com/athlete/hector-aldana\n",
      "Scraping Irene Aldana...\n",
      "https://www.ufc.com/athlete/irene-aldana\n",
      "Scraping Jose Alday...\n",
      "https://www.ufc.com/athlete/jose-alday\n",
      "Scraping Jos Aldo...\n",
      "https://www.ufc.com/athlete/jose-aldo\n",
      "Scraping JJ Aldrich...\n",
      "https://www.ufc.com/athlete/jj-aldrich\n",
      "Scraping Irina Alekseeva...\n",
      "https://www.ufc.com/athlete/irina-alekseeva\n",
      "Scraping Talita Alencar...\n",
      "https://www.ufc.com/athlete/talita-alencar\n",
      "Scraping Jim Alers...\n",
      "https://www.ufc.com/athlete/jim-alers\n",
      "Scraping John Alessio...\n",
      "https://www.ufc.com/athlete/john-alessio\n",
      "Scraping Houston Alexander...\n",
      "https://www.ufc.com/athlete/houston-alexander\n",
      "Scraping Lucas Alexander...\n",
      "https://www.ufc.com/athlete/lucas-alexander\n",
      "Scraping Marcio Alexandre...\n",
      "https://www.ufc.com/athlete/marcio-alexandre\n",
      "Scraping Olaf Alfonso...\n",
      "https://www.ufc.com/athlete/olaf-alfonso\n",
      "Scraping Bill Algeo...\n",
      "https://www.ufc.com/athlete/bill-algeo\n",
      "Scraping Royce Alger...\n",
      "https://www.ufc.com/athlete/royce-alger\n",
      "Scraping Abdul Razak Alhassan...\n",
      "https://www.ufc.com/athlete/abdul-razak-alhassan\n",
      "Scraping Amir Aliakbari...\n",
      "https://www.ufc.com/athlete/amir-aliakbari\n",
      "Scraping Sultan Aliev...\n",
      "https://www.ufc.com/athlete/sultan-aliev\n",
      "Scraping Nurullo Aliev...\n",
      "https://www.ufc.com/athlete/nurullo-aliev\n",
      "Scraping Ikram Aliskerov...\n",
      "https://www.ufc.com/athlete/ikram-aliskerov\n",
      "Scraping Leon Aliu...\n",
      "https://www.ufc.com/athlete/leon-aliu\n",
      "Scraping John Allan...\n",
      "https://www.ufc.com/athlete/john-allan\n",
      "Scraping Arnold Allen...\n",
      "https://www.ufc.com/athlete/arnold-allen\n",
      "Scraping Brendan Allen...\n",
      "https://www.ufc.com/athlete/brendan-allen\n",
      "Scraping Benny Alloway...\n",
      "https://www.ufc.com/athlete/benny-alloway\n",
      "Scraping Asu Almabayev...\n",
      "https://www.ufc.com/athlete/assu-almabayev\n",
      "Scraping Bekzat Almakhan...\n",
      "https://www.ufc.com/athlete/bekzat-almakhan\n",
      "Scraping Estefani Almeida...\n",
      "https://www.ufc.com/athlete/estefani-almeida\n",
      "Scraping Thomas Almeida...\n",
      "https://www.ufc.com/athlete/thomas-almeida\n",
      "Scraping Ericka Almeida...\n",
      "https://www.ufc.com/athlete/ericka-almeida\n",
      "Scraping Ricardo Almeida...\n",
      "https://www.ufc.com/athlete/ricardo-almeida\n",
      "Scraping Lucas Almeida...\n",
      "https://www.ufc.com/athlete/lucas-almeida\n",
      "Scraping Cesar Almeida...\n",
      "https://www.ufc.com/athlete/cesar-almeida\n",
      "Scraping Jailton Almeida...\n",
      "https://www.ufc.com/athlete/jailton-almeida\n",
      "Scraping Sarah Alpar...\n",
      "https://www.ufc.com/athlete/sarah-alpar\n",
      "Scraping Victor Altamirano...\n",
      "https://www.ufc.com/athlete/victor-altamirano\n",
      "Scraping Patricia Alujas...\n",
      "https://www.ufc.com/athlete/patricia-alujas\n",
      "Scraping Eddie Alvarez...\n",
      "https://www.ufc.com/athlete/eddie-alvarez\n",
      "Scraping Jaime Alvarez...\n",
      "https://www.ufc.com/athlete/jaime-alvarez\n",
      "Scraping Sean Alvarez...\n",
      "https://www.ufc.com/athlete/sean-alvarez\n",
      "Scraping Joel lvarez...\n",
      "https://www.ufc.com/athlete/joel-alvarez\n",
      "Scraping Amilcar Alves...\n",
      "https://www.ufc.com/athlete/amilcar-alves\n",
      "Scraping Thiago Alves...\n",
      "https://www.ufc.com/athlete/thiago-alves\n",
      "Scraping Warlley Alves...\n",
      "https://www.ufc.com/athlete/warlley-alves\n",
      "Scraping Rafael Alves...\n",
      "https://www.ufc.com/athlete/rafael-alves\n",
      "Scraping Sam Alvey...\n",
      "https://www.ufc.com/athlete/sam-alvey\n",
      "Scraping Adlan Amagov...\n",
      "https://www.ufc.com/athlete/adlan-amagov\n",
      "Scraping Alen Amedovski...\n",
      "https://www.ufc.com/athlete/alen-amedovski\n",
      "Scraping Hyder Amil...\n",
      "https://www.ufc.com/athlete/hyder-amil\n",
      "Scraping Makwan Amirkhani...\n",
      "https://www.ufc.com/athlete/makwan-amirkhani\n",
      "Scraping Jaqueline Amorim...\n",
      "https://www.ufc.com/athlete/jaqueline-amorim\n",
      "Scraping Eryk Anders...\n",
      "https://www.ufc.com/athlete/eryk-anders\n",
      "Scraping Matt Andersen...\n",
      "https://www.ufc.com/athlete/matt-andersen\n",
      "Scraping Andy Anderson...\n",
      "https://www.ufc.com/athlete/andy-anderson\n",
      "Scraping Lowell Anderson...\n",
      "https://www.ufc.com/athlete/shon-alvarez-1\n",
      "Scraping Corey Anderson...\n",
      "https://www.ufc.com/athlete/corey-anderson\n",
      "Scraping Megan Anderson...\n",
      "https://www.ufc.com/athlete/megan-anderson\n",
      "Scraping Tatsuya Ando...\n",
      "https://www.ufc.com/athlete/tatsuya-ando\n",
      "Scraping Alex Andrade...\n",
      "https://www.ufc.com/athlete/alex-andrade\n",
      "Scraping Viscardi Andrade...\n",
      "https://www.ufc.com/athlete/viscardi-andrade\n",
      "Scraping Jssica Andrade...\n",
      "https://www.ufc.com/athlete/jessica-andrade\n",
      "Scraping Jermaine Andre...\n",
      "https://www.ufc.com/athlete/shon-alvarez-2\n",
      "Scraping Juan Andres Luna...\n",
      "https://www.ufc.com/athlete/juan-andres-luna\n",
      "Scraping Dylan Andrews...\n",
      "https://www.ufc.com/athlete/dylan-andrews\n",
      "Scraping Reese Andy...\n",
      "https://www.ufc.com/athlete/reese-andy\n",
      "Scraping Julius Anglickas...\n",
      "https://www.ufc.com/athlete/julius-anglickas\n",
      "Scraping Collin Anglin...\n",
      "https://www.ufc.com/athlete/collin-anglin\n",
      "Scraping Chad Anheliger...\n",
      "https://www.ufc.com/athlete/chad-anheliger\n",
      "Scraping Yoji Anjo...\n",
      "https://www.ufc.com/athlete/yoji-anjo\n",
      "Scraping Magomed Ankalaev...\n",
      "https://www.ufc.com/athlete/magomed-ankalaev\n",
      "Scraping Nina Nunes...\n",
      "https://www.ufc.com/athlete/nina-nunes\n",
      "Scraping Gadzhimurad Antigulov...\n",
      "https://www.ufc.com/athlete/gadzhimurad-antigulov\n",
      "Scraping Adam Antolin...\n",
      "https://www.ufc.com/athlete/adam-antolin\n",
      "Scraping Zu Anyanwu...\n",
      "https://www.ufc.com/athlete/zu-anyanwu\n",
      "Scraping Wang Anying...\n",
      "https://www.ufc.com/athlete/wang-anying\n",
      "Scraping Shinsho Anzai...\n",
      "https://www.ufc.com/athlete/shinsho-anzai\n",
      "Scraping Aoriqileng...\n",
      "https://www.ufc.com/athlete/aoriqileng\n",
      "Scraping Josh Appelt...\n",
      "https://www.ufc.com/athlete/josh-appelt\n",
      "Scraping Romie Aram...\n",
      "https://www.ufc.com/athlete/romie-aram\n",
      "Scraping Felipe Arantes...\n",
      "https://www.ufc.com/athlete/felipe-arantes\n",
      "Scraping Igor Araujo...\n",
      "https://www.ufc.com/athlete/igor-araujo\n",
      "Scraping Viviane Arajo...\n",
      "https://www.ufc.com/athlete/viviane-araujo\n",
      "Scraping Julio Arce...\n",
      "https://www.ufc.com/athlete/julio-arce\n",
      "Scraping Carrese Archer...\n",
      "https://www.ufc.com/athlete/carrese-archer\n",
      "Scraping Alice Ardelean...\n",
      "https://www.ufc.com/athlete/alice-ardelean\n",
      "Scraping Dan Argueta...\n",
      "https://www.ufc.com/athlete/daniel-argueta\n",
      "Scraping Rheza Arianto...\n",
      "https://www.ufc.com/athlete/rheza-arianto\n",
      "Scraping Hashem Arkhagha...\n",
      "https://www.ufc.com/athlete/hashem-arkhagha\n",
      "Scraping Andrei Arlovski...\n",
      "https://www.ufc.com/athlete/andrei-arlovski\n",
      "Scraping Garrett Armfield...\n",
      "https://www.ufc.com/athlete/garrett-armfield\n",
      "Scraping Austin Arnett...\n",
      "https://www.ufc.com/athlete/austin-arnett\n",
      "Scraping Eli Aronov...\n",
      "https://www.ufc.com/athlete/eli-aronov\n",
      "Scraping Akbarh Arreola...\n",
      "https://www.ufc.com/athlete/akbarh-arreola\n",
      "Scraping Antonio Arroyo...\n",
      "https://www.ufc.com/athlete/antonio-arroyo\n",
      "Scraping Matt Arroyo...\n",
      "https://www.ufc.com/athlete/matt-arroyo\n",
      "Scraping Cesar Arzamendia...\n",
      "https://www.ufc.com/athlete/cesar-arzamendia\n",
      "Scraping Teddy Ash...\n",
      "https://www.ufc.com/athlete/teddy-ash\n",
      "Scraping Arman Ashimov...\n",
      "https://www.ufc.com/athlete/arman-ashimov\n",
      "Scraping Yanal Ashmouz...\n",
      "https://www.ufc.com/athlete/yanal-ashmouz\n",
      "Scraping Askar Askar...\n",
      "https://www.ufc.com/athlete/askar-askar\n",
      "Scraping Askar Askarov...\n",
      "https://www.ufc.com/athlete/askar-askarov\n",
      "Scraping Cyril Asker...\n",
      "https://www.ufc.com/athlete/cyril-asker\n",
      "Scraping Khusein Askhabov...\n",
      "https://www.ufc.com/athlete/khusein-askhabov\n",
      "Scraping Scott Askham...\n",
      "https://www.ufc.com/athlete/scott-askham\n",
      "Scraping Ben Askren...\n",
      "https://www.ufc.com/athlete/ben-askren\n",
      "Scraping Ibo Aslan...\n",
      "https://www.ufc.com/athlete/ibo-aslan\n",
      "Scraping Tom Aspinall...\n",
      "https://www.ufc.com/athlete/tom-aspinall\n",
      "Scraping Bruno Assis...\n",
      "https://www.ufc.com/athlete/bruno-assis\n",
      "Scraping Junior Assuncao...\n",
      "https://www.ufc.com/athlete/junior-assuncao\n",
      "Scraping Raphael Assuno...\n",
      "https://www.ufc.com/athlete/raphael-assuncao\n",
      "Scraping Rich Attonito...\n",
      "https://www.ufc.com/athlete/rich-attonito\n",
      "Scraping Olivier Aubin-Mercier...\n",
      "https://www.ufc.com/athlete/olivier-aubin-mercier\n",
      "Scraping Pat Audinwood...\n",
      "https://www.ufc.com/athlete/pat-audinwood\n",
      "Scraping Jose Augusto...\n",
      "https://www.ufc.com/athlete/jose-augusto\n",
      "Scraping Leonardo Augusto Leleco...\n",
      "https://www.ufc.com/athlete/leonardo-augusto-leleco\n",
      "Scraping Marcus Aurelio...\n",
      "https://www.ufc.com/athlete/marcus-aurelio\n",
      "Scraping Chris Avila...\n",
      "https://www.ufc.com/athlete/chris-avila\n",
      "Scraping Julia Avila...\n",
      "https://www.ufc.com/athlete/julia-avila\n",
      "Scraping Jessin Ayari...\n",
      "https://www.ufc.com/athlete/jessin-ayari\n",
      "Scraping Ottman Azaitar...\n",
      "https://www.ufc.com/athlete/ottman-azaitar\n",
      "Scraping Abu Azaitar...\n",
      "https://www.ufc.com/athlete/abu-azaitar\n",
      "Scraping Hunter Azure...\n",
      "https://www.ufc.com/athlete/hunter-azure\n",
      "Scraping Niklas Backstrom...\n",
      "https://www.ufc.com/athlete/niklas-backstrom\n",
      "Scraping Seth Baczynski...\n",
      "https://www.ufc.com/athlete/seth-baczynski\n",
      "Scraping Abdul Azeem Badakhshi...\n",
      "https://www.ufc.com/athlete/abdul-azeem-badakhshi\n",
      "Scraping Ryan Bader...\n",
      "https://www.ufc.com/athlete/ryan-bader\n",
      "Scraping Izabela Badurek...\n",
      "https://www.ufc.com/athlete/izabela-badurek\n",
      "Scraping Miguel Baeza...\n",
      "https://www.ufc.com/athlete/miguel-baeza\n",
      "Scraping Ali Bagautinov...\n",
      "https://www.ufc.com/athlete/ali-bagautinov\n",
      "Scraping Mehdi Baghdad...\n",
      "https://www.ufc.com/athlete/mehdi-baghdad\n",
      "Scraping Melsik Baghdasaryan...\n",
      "https://www.ufc.com/athlete/melsik-baghdasaryan\n",
      "Scraping Siyar Bahadurzada...\n",
      "https://www.ufc.com/athlete/siyar-bahadurzada\n",
      "Scraping Ignacio Bahamondes...\n",
      "https://www.ufc.com/athlete/ignacio-bahamondes\n",
      "Scraping Shamar Bailey...\n",
      "https://www.ufc.com/athlete/shamar-bailey\n",
      "Scraping Scott Baker...\n",
      "https://www.ufc.com/athlete/scott-baker\n",
      "Scraping Oluwale Bamgbose...\n",
      "https://www.ufc.com/athlete/oluwale-bamgbose\n",
      "Scraping Marcin Bandel...\n",
      "https://www.ufc.com/athlete/marcin-bandel\n",
      "Scraping Humberto Bandenay...\n",
      "https://www.ufc.com/athlete/humberto-bandenay\n",
      "Scraping Tae Hyun Bang...\n",
      "https://www.ufc.com/athlete/tae-hyun-bang\n",
      "Scraping Shauna Bannon...\n",
      "https://www.ufc.com/athlete/shauna-bannon\n",
      "Scraping Antonio Banuelos...\n",
      "https://www.ufc.com/athlete/antonio-banuelos\n",
      "Scraping Renan Barao...\n",
      "https://www.ufc.com/athlete/renan-barao\n",
      "Scraping Maycee Barber...\n",
      "https://www.ufc.com/athlete/maycee-barber\n",
      "Scraping Bryan Barberena...\n",
      "https://www.ufc.com/athlete/bryan-barberena\n",
      "Scraping Dione Barbosa...\n",
      "https://www.ufc.com/athlete/dione-barbosa\n",
      "Scraping Edson Barboza...\n",
      "https://www.ufc.com/athlete/edson-barboza\n",
      "Scraping Raoni Barcelos...\n",
      "https://www.ufc.com/athlete/raoni-barcelos\n",
      "Scraping Carlos Baretto...\n",
      "https://www.ufc.com/athlete/carlos-baretto\n",
      "Scraping Daniel Barez...\n",
      "https://www.ufc.com/athlete/daniel-barez\n",
      "Scraping Danny Barlow...\n",
      "https://www.ufc.com/athlete/danny-barlow\n",
      "Scraping Luke Barnatt...\n",
      "https://www.ufc.com/athlete/luke-barnatt\n",
      "Scraping James Barnes...\n",
      "https://www.ufc.com/athlete/james-barnes\n",
      "Scraping Shonte Barnes...\n",
      "https://www.ufc.com/athlete/shonte-barnes\n",
      "Scraping Josh Barnett...\n",
      "https://www.ufc.com/athlete/josh-barnett\n",
      "Scraping Chris Barnett...\n",
      "https://www.ufc.com/athlete/chris-barnett\n",
      "Scraping David Baron...\n",
      "https://www.ufc.com/athlete/david-baron\n",
      "Scraping Phil Baroni...\n",
      "https://www.ufc.com/athlete/phil-baroni\n",
      "Scraping Dan Barrera...\n",
      "https://www.ufc.com/athlete/dan-barrera\n",
      "Scraping Peter Barrett...\n",
      "https://www.ufc.com/athlete/peter-barrett\n",
      "Scraping Marc-Andre Barriault...\n",
      "https://www.ufc.com/athlete/marc-andre-barriault\n",
      "Scraping Alexandre Barros...\n",
      "https://www.ufc.com/athlete/alexandre-barros\n",
      "Scraping Francimar Barroso...\n",
      "https://www.ufc.com/athlete/francimar-barroso\n",
      "Scraping Pat Barry...\n",
      "https://www.ufc.com/athlete/pat-barry\n",
      "Scraping Dean Barry...\n",
      "https://www.ufc.com/athlete/dean-barry\n",
      "Scraping Enrique Barzola...\n",
      "https://www.ufc.com/athlete/enrique-barzola\n",
      "Scraping Farid Basharat...\n",
      "https://www.ufc.com/athlete/farid-basharat\n",
      "Scraping Javid Basharat...\n",
      "https://www.ufc.com/athlete/javid-basharat\n",
      "Scraping Austin Bashi...\n",
      "https://www.ufc.com/athlete/austin-bashi\n",
      "Scraping Stephen Bass...\n",
      "https://www.ufc.com/athlete/stephen-bass\n",
      "Scraping Shayna Baszler...\n",
      "https://www.ufc.com/athlete/shayna-baszler\n",
      "Scraping Bahatebole Batebolati...\n",
      "https://www.ufc.com/athlete/bahatebole-batebolati\n",
      "Scraping Cameron Bates...\n",
      "https://www.ufc.com/athlete/cameron-bates\n",
      "Scraping Michel Batista...\n",
      "https://www.ufc.com/athlete/michel-batista\n",
      "Scraping Bryan Battle...\n",
      "https://www.ufc.com/athlete/bryan-battle\n",
      "Scraping Alan Baudot...\n",
      "https://www.ufc.com/athlete/alan-baudot\n",
      "Scraping Mario Bautista...\n",
      "https://www.ufc.com/athlete/mario-bautista\n",
      "Scraping Chris Beal...\n",
      "https://www.ufc.com/athlete/chris-beal\n",
      "Scraping Donavan Beard...\n",
      "https://www.ufc.com/athlete/donavan-beard\n",
      "Scraping Ariel Beck...\n",
      "https://www.ufc.com/athlete/ariel-beck\n",
      "Scraping Johnny Bedford...\n",
      "https://www.ufc.com/athlete/johnny-bedford\n",
      "Scraping Rolando Bedoya...\n",
      "https://www.ufc.com/athlete/rolando-bedoya\n",
      "Scraping Allan Begosso...\n",
      "https://www.ufc.com/athlete/allan-begosso\n",
      "Scraping Mirsad Bektic...\n",
      "https://www.ufc.com/athlete/mirsad-bektic\n",
      "Scraping Diana Belbita...\n",
      "https://www.ufc.com/athlete/diana-belbita\n",
      "Scraping Alan Belcher...\n",
      "https://www.ufc.com/athlete/alan-belcher\n",
      "Scraping Vitor Belfort...\n",
      "https://www.ufc.com/athlete/vitor-belfort\n",
      "Scraping Yousri Belgaroui...\n",
      "https://www.ufc.com/athlete/yousri-belgaroui\n",
      "Scraping Cody Belisle...\n",
      "https://www.ufc.com/athlete/cody-belisle\n",
      "Scraping Rodolfo Bellato...\n",
      "https://www.ufc.com/athlete/rodolfo-bellato\n",
      "Scraping Danilo Belluardo...\n",
      "https://www.ufc.com/athlete/danilo-belluardo\n",
      "Scraping Joey Beltran...\n",
      "https://www.ufc.com/athlete/joey-beltran\n",
      "Scraping Marco Beltran...\n",
      "https://www.ufc.com/athlete/marco-beltran\n",
      "Scraping Joseph Benavidez...\n",
      "https://www.ufc.com/athlete/joseph-benavidez\n",
      "Scraping Dave Beneteau...\n",
      "https://www.ufc.com/athlete/dave-beneteau\n",
      "Scraping Gabriel Benitez...\n",
      "https://www.ufc.com/athlete/gabriel-benitez\n",
      "Scraping DeAnna Bennett...\n",
      "https://www.ufc.com/athlete/deanna-bennett\n",
      "Scraping Lance Benoist...\n",
      "https://www.ufc.com/athlete/lance-benoist\n",
      "Scraping Ryan Benoit...\n",
      "https://www.ufc.com/athlete/ryan-benoit\n",
      "Scraping Steve Berger...\n",
      "https://www.ufc.com/athlete/steve-berger\n",
      "Scraping Kenneth Bergh...\n",
      "https://www.ufc.com/athlete/kenneth-bergh\n",
      "Scraping Keith Berish...\n",
      "https://www.ufc.com/athlete/keith-berish\n",
      "Scraping Manny Bermudez...\n",
      "https://www.ufc.com/athlete/manny-bermudez\n",
      "Scraping Dennis Bermudez...\n",
      "https://www.ufc.com/athlete/tenisu-hamiyutesu\n",
      "Scraping Talita Bernardo...\n",
      "https://www.ufc.com/athlete/talita-bernardo\n",
      "Scraping Dave Berry...\n",
      "https://www.ufc.com/athlete/skott-beyker-0\n",
      "Scraping Dieusel Berto...\n",
      "https://www.ufc.com/athlete/deyv-beneto-0\n",
      "Scraping Allen Berube...\n",
      "https://www.ufc.com/athlete/allen-berube\n",
      "Scraping Anton Berzin...\n",
      "https://www.ufc.com/athlete/anton-berzin\n",
      "Scraping Scott Bessac...\n",
      "https://www.ufc.com/athlete/skott-beyker-1\n",
      "Scraping Matt Bessette...\n",
      "https://www.ufc.com/athlete/matt-bessette\n",
      "Scraping Khadzhimurat Bestaev...\n",
      "https://www.ufc.com/athlete/khadzhimurat-bestaev\n",
      "Scraping KB Bhullar...\n",
      "https://www.ufc.com/athlete/kb-bhullar\n",
      "Scraping Magomed Bibulatov...\n",
      "https://www.ufc.com/athlete/magomed-bibulatov\n",
      "Scraping David Bielkheden...\n",
      "https://www.ufc.com/athlete/david-bielkheden\n",
      "Scraping Blake Bilder...\n",
      "https://www.ufc.com/athlete/blake-bilder\n",
      "Scraping Jonas Bilharinho...\n",
      "https://www.ufc.com/athlete/jonas-bilharinho\n",
      "Scraping Xie Bin...\n",
      "https://www.ufc.com/athlete/xie-bin\n",
      "Scraping Anthony Birchak...\n",
      "https://www.ufc.com/athlete/anthony-birchak\n",
      "Scraping Chris Birchler...\n",
      "https://www.ufc.com/athlete/chris-birchler\n",
      "Scraping Michael Bisping...\n",
      "https://www.ufc.com/athlete/michael-bisping\n",
      "Scraping Amaury Bitetti...\n",
      "https://www.ufc.com/athlete/amaury-bitetti\n",
      "Scraping Caio Bittencourt...\n",
      "https://www.ufc.com/athlete/caio-bittencourt\n",
      "Scraping Simon Biyong...\n",
      "https://www.ufc.com/athlete/simon-biyong\n",
      "Scraping Jan Bachowicz...\n",
      "https://www.ufc.com/athlete/jan-blachowicz\n",
      "Scraping Jason Black...\n",
      "https://www.ufc.com/athlete/jason-black\n",
      "Scraping Brad Blackburn...\n",
      "https://www.ufc.com/athlete/brad-blackburn\n",
      "Scraping Tom Blackledge...\n",
      "https://www.ufc.com/athlete/tom-blackledge\n",
      "Scraping Sherrard Blackledge...\n",
      "https://www.ufc.com/athlete/sherrard-blackledge\n",
      "Scraping Da'Mon Blackshear...\n",
      "https://www.ufc.com/athlete/damon-blackshear\n",
      "Scraping Erin Blanchfield...\n",
      "https://www.ufc.com/athlete/erin-blanchfield\n",
      "Scraping Maximo Blanco...\n",
      "https://www.ufc.com/athlete/maximo-blanco\n",
      "Scraping Curtis Blaydes...\n",
      "https://www.ufc.com/athlete/curtis-blaydes\n",
      "Scraping Tereza Bleda...\n",
      "https://www.ufc.com/athlete/tereza-bleda\n",
      "Scraping Byron Bloodworth...\n",
      "https://www.ufc.com/athlete/byron-bloodworth\n",
      "Scraping Dashawn Boatwright...\n",
      "https://www.ufc.com/athlete/dashawn-boatwright\n",
      "Scraping Daniel Bobish...\n",
      "https://www.ufc.com/athlete/daniel-bobish\n",
      "Scraping Mark Bocek...\n",
      "https://www.ufc.com/athlete/mark-bocek\n",
      "Scraping Kyle Bochniak...\n",
      "https://www.ufc.com/athlete/kyle-bochniak\n",
      "Scraping James Bochnovic...\n",
      "https://www.ufc.com/athlete/james-bochnovic\n",
      "Scraping Tim Boetsch...\n",
      "https://www.ufc.com/athlete/tim-boetsch\n",
      "Scraping Galore Bofando...\n",
      "https://www.ufc.com/athlete/galore-bofando\n",
      "Scraping Roman Bogatov...\n",
      "https://www.ufc.com/athlete/roman-bogatov\n",
      "Scraping Jerry Bohlander...\n",
      "https://www.ufc.com/athlete/jerry-bohlander\n",
      "Scraping Mandy Bhm...\n",
      "https://www.ufc.com/athlete/mandy-bohm\n",
      "Scraping Gaston Bolanos...\n",
      "https://www.ufc.com/athlete/gaston-bolanos\n",
      "Scraping Denys Bondar...\n",
      "https://www.ufc.com/athlete/denys-bondar\n",
      "Scraping Gabriel Bonfim...\n",
      "https://www.ufc.com/athlete/gabriel-bonfim\n",
      "Scraping Ismael Bonfim...\n",
      "https://www.ufc.com/athlete/ismael-bonfim\n",
      "Scraping Jesse Bongfeldt...\n",
      "https://www.ufc.com/athlete/jesse-bongfeldt\n",
      "Scraping Stephan Bonnar...\n",
      "https://www.ufc.com/athlete/stephan-bonnar\n",
      "Scraping Michael Bonnette...\n",
      "https://www.ufc.com/athlete/michael-bonnette\n",
      "Scraping Rogerio Bontorin...\n",
      "https://www.ufc.com/athlete/rogerio-bontorin\n",
      "Scraping Branden Bordeaux...\n",
      "https://www.ufc.com/athlete/branden-bordeaux\n",
      "Scraping Ray Borg...\n",
      "https://www.ufc.com/athlete/ray-borg\n",
      "Scraping Kevin Borjas...\n",
      "https://www.ufc.com/athlete/kevin-borjas\n",
      "Scraping Calen Born...\n",
      "https://www.ufc.com/athlete/calen-born\n",
      "Scraping Caio Borralho...\n",
      "https://www.ufc.com/athlete/caio-borralho\n",
      "Scraping Zach Borrego...\n",
      "https://www.ufc.com/athlete/zach-borrego\n",
      "Scraping Viacheslav Borshchev...\n",
      "https://www.ufc.com/athlete/viacheslav-borshchev\n",
      "Scraping Tanner Boser...\n",
      "https://www.ufc.com/athlete/tanner-boser\n",
      "Scraping Steve Bosse...\n",
      "https://www.ufc.com/athlete/steve-bosse\n",
      "Scraping Marcus Bossett...\n",
      "https://www.ufc.com/athlete/skott-beyker-2\n",
      "Scraping Poliana Botelho...\n",
      "https://www.ufc.com/athlete/poliana-botelho\n",
      "Scraping Tai Bowden...\n",
      "https://www.ufc.com/athlete/skott-beyker-3\n",
      "Scraping Melton Bowen...\n",
      "https://www.ufc.com/athlete/melton-bowen\n",
      "Scraping Kyron Bowen...\n",
      "https://www.ufc.com/athlete/kyron-bowen\n",
      "Scraping Brian Bowles...\n",
      "https://www.ufc.com/athlete/brian-bowles\n",
      "Scraping Roger Bowling...\n",
      "https://www.ufc.com/athlete/roger-bowling\n",
      "Scraping Anvar Boynazarov...\n",
      "https://www.ufc.com/athlete/anvar-boynazarov\n",
      "Scraping Kyle Bradley...\n",
      "https://www.ufc.com/athlete/kayl-dakas\n",
      "Scraping Paul Bradley...\n",
      "https://www.ufc.com/athlete/paul-bradley-0\n",
      "Scraping Sean Brady...\n",
      "https://www.ufc.com/athlete/sean-brady\n",
      "Scraping Ebenezer Braga...\n",
      "https://www.ufc.com/athlete/kayl-dakas-0\n",
      "Scraping Ramiz Brahimaj...\n",
      "https://www.ufc.com/athlete/ramiz-brahimaj\n",
      "Scraping Joe Brammer...\n",
      "https://www.ufc.com/athlete/joe-brammer\n",
      "Scraping David Branch...\n",
      "https://www.ufc.com/athlete/david-branch\n",
      "Scraping Diego Brandao...\n",
      "https://www.ufc.com/athlete/diego-brandao\n",
      "Scraping Bruna Brasil...\n",
      "https://www.ufc.com/athlete/bruna-brasil\n",
      "Scraping Martin Bravo...\n",
      "https://www.ufc.com/athlete/martin-bravo\n",
      "Scraping Mike Breeden...\n",
      "https://www.ufc.com/athlete/mike-breeden\n",
      "Scraping Tom Breese...\n",
      "https://www.ufc.com/athlete/tom-breese\n",
      "Scraping Elves Brener...\n",
      "https://www.ufc.com/athlete/elves-brener\n",
      "Scraping Chris Brennan...\n",
      "https://www.ufc.com/athlete/kris-avila-0\n",
      "Scraping Charlie Brenneman...\n",
      "https://www.ufc.com/athlete/charlie-brenneman\n",
      "Scraping Marcos Brigagao...\n",
      "https://www.ufc.com/athlete/marcos-brigagao\n",
      "Scraping Jason Brilz...\n",
      "https://www.ufc.com/athlete/jason-brilz\n",
      "Scraping Marcus Brimage...\n",
      "https://www.ufc.com/athlete/marcus-brimage\n",
      "Scraping Aaron Brink...\n",
      "https://www.ufc.com/athlete/aaron-brink\n",
      "Scraping Henry Briones...\n",
      "https://www.ufc.com/athlete/henry-briones\n",
      "Scraping Kaik Brito...\n",
      "https://www.ufc.com/athlete/kaik-brito\n",
      "Scraping Joanderson Brito...\n",
      "https://www.ufc.com/athlete/joanderson-brito\n",
      "Scraping Antwain Britt...\n",
      "https://www.ufc.com/athlete/antwain-britt\n",
      "Scraping Will Brooks...\n",
      "https://www.ufc.com/athlete/will-brooks\n",
      "Scraping Jarred Brooks...\n",
      "https://www.ufc.com/athlete/jarred-brooks\n",
      "Scraping Rob Broughton...\n",
      "https://www.ufc.com/athlete/rob-broughton\n",
      "Scraping Todd Brown...\n",
      "https://www.ufc.com/athlete/todd-brown\n",
      "Scraping Matt Brown...\n",
      "https://www.ufc.com/athlete/matt-brown\n",
      "Scraping Humberto Brown...\n",
      "https://www.ufc.com/athlete/humberto-brown\n",
      "Scraping Damien Brown...\n",
      "https://www.ufc.com/athlete/damien-brown\n",
      "Scraping Randy Brown...\n",
      "https://www.ufc.com/athlete/randy-brown\n",
      "Scraping Mike Brown...\n",
      "https://www.ufc.com/athlete/mike-brown\n",
      "Scraping TJ Brown...\n",
      "https://www.ufc.com/athlete/tj-brown\n",
      "Scraping Travis Browne...\n",
      "https://www.ufc.com/athlete/travis-browne\n",
      "Scraping Junie Browning...\n",
      "https://www.ufc.com/athlete/junie-browning\n",
      "Scraping Jules Bruchez...\n",
      "https://www.ufc.com/athlete/jules-bruchez\n",
      "Scraping Stephanie Luciano...\n",
      "https://www.ufc.com/athlete/stephanie-bruna-luciano\n",
      "Scraping Cody Brundage...\n",
      "https://www.ufc.com/athlete/cody-brundage\n",
      "Scraping Steve Bruno...\n",
      "https://www.ufc.com/athlete/steve-bruno\n",
      "Scraping Derek Brunson...\n",
      "https://www.ufc.com/athlete/derek-brunson\n",
      "Scraping Dennis Bryant...\n",
      "https://www.ufc.com/athlete/dennis-bryant\n",
      "Scraping Josh Bryant...\n",
      "https://www.ufc.com/athlete/josh-bryant\n",
      "Scraping Robert Bryczek...\n",
      "https://www.ufc.com/athlete/robert-bryczek\n",
      "Scraping Lukasz Brzeski...\n",
      "https://www.ufc.com/athlete/lukasz-brzeski\n",
      "Scraping Justin Buchholz...\n",
      "https://www.ufc.com/athlete/justin-buchholz\n",
      "Scraping Joaquin Buckley...\n",
      "https://www.ufc.com/athlete/joaquin-buckley\n",
      "Scraping Martin Buday...\n",
      "https://www.ufc.com/athlete/martin-buday\n",
      "Scraping Dylan Budka...\n",
      "https://www.ufc.com/athlete/dylan-budka\n",
      "Scraping Paul Buentello...\n",
      "https://www.ufc.com/athlete/paul-buentello\n",
      "Scraping Modestas Bukauskas...\n",
      "https://www.ufc.com/athlete/modestas-bukauskas\n",
      "Scraping Felipe Bunes...\n",
      "https://www.ufc.com/athlete/felipe-bunes\n",
      "Scraping Wuliji Buren...\n",
      "https://www.ufc.com/athlete/wuliji-buren\n",
      "Scraping Shane Burgos...\n",
      "https://www.ufc.com/athlete/shane-burgos\n",
      "Scraping Joshua Burkman...\n",
      "https://www.ufc.com/athlete/joshua-burkman\n",
      "Scraping Justin Burlinson...\n",
      "https://www.ufc.com/athlete/justin-burlinson\n",
      "Scraping Nate Burnard...\n",
      "https://www.ufc.com/athlete/nate-burnard\n",
      "Scraping Mads Burnell...\n",
      "https://www.ufc.com/athlete/mads-burnell\n",
      "Scraping Mikey Burnett...\n",
      "https://www.ufc.com/athlete/mikey-burnett\n",
      "Scraping Kevin Burns...\n",
      "https://www.ufc.com/athlete/kevin-burns\n",
      "Scraping Gilbert Burns...\n",
      "https://www.ufc.com/athlete/gilbert-burns\n",
      "Scraping Herbert Burns...\n",
      "https://www.ufc.com/athlete/herbert-burns\n",
      "Scraping Nah-Shon Burrell...\n",
      "https://www.ufc.com/athlete/nah-shon-burrell\n",
      "Scraping Martin Buschkamp...\n",
      "https://www.ufc.com/athlete/martin-buschkamp\n",
      "Scraping Bubba Bush...\n",
      "https://www.ufc.com/athlete/bubba-bush\n",
      "Scraping Dakota Bush...\n",
      "https://www.ufc.com/athlete/dakota-bush\n",
      "Scraping Murilo Bustamante...\n",
      "https://www.ufc.com/athlete/murilo-bustamante\n",
      "Scraping Todd Butler...\n",
      "https://www.ufc.com/athlete/kevin-byorns-1\n",
      "Scraping Jesse Butler...\n",
      "https://www.ufc.com/athlete/jesse-butler\n",
      "Scraping JP Buys...\n",
      "https://www.ufc.com/athlete/jp-buys\n",
      "Scraping Dennis Buzukja...\n",
      "https://www.ufc.com/athlete/dennis-buzukja\n",
      "Scraping Charles Byrd...\n",
      "https://www.ufc.com/athlete/charles-byrd\n",
      "Scraping Steve Byrnes...\n",
      "https://www.ufc.com/athlete/kevin-byorns-2\n",
      "Scraping Yan Cabral...\n",
      "https://www.ufc.com/athlete/yan-cabral\n",
      "Scraping Alex Caceres...\n",
      "https://www.ufc.com/athlete/alex-caceres\n",
      "Scraping Vince Cachero...\n",
      "https://www.ufc.com/athlete/vince-cachero\n",
      "Scraping Priscila Cachoeira...\n",
      "https://www.ufc.com/athlete/priscila-cachoeira\n",
      "Scraping Ricky Calatayud...\n",
      "https://www.ufc.com/athlete/ricky-calatayud\n",
      "Scraping Nicolle Caliari...\n",
      "https://www.ufc.com/athlete/nicolle-caliari\n",
      "Scraping Taylor Callens...\n",
      "https://www.ufc.com/athlete/taylor-callens\n",
      "Scraping Cynthia Calvillo...\n",
      "https://www.ufc.com/athlete/cynthia-calvillo\n",
      "Scraping Frank Camacho...\n",
      "https://www.ufc.com/athlete/frank-camacho\n",
      "Scraping Fabricio Camoes...\n",
      "https://www.ufc.com/athlete/fabricio-camoes\n",
      "Scraping Chris Camozzi...\n",
      "https://www.ufc.com/athlete/chris-camozzi\n",
      "Scraping Brian Camozzi...\n",
      "https://www.ufc.com/athlete/brian-camozzi\n",
      "Scraping Ricky Camp...\n",
      "https://www.ufc.com/athlete/ricky-camp\n",
      "Scraping Shane Campbell...\n",
      "https://www.ufc.com/athlete/shane-campbell\n",
      "Scraping Charlie Campbell...\n",
      "https://www.ufc.com/athlete/charlie-campbell\n",
      "Scraping John Campetella...\n",
      "https://www.ufc.com/athlete/kevin-byorns-3\n",
      "Scraping Wagner Campos...\n",
      "https://www.ufc.com/athlete/volkan-ozdemir-0\n",
      "Scraping Will Campuzano...\n",
      "https://www.ufc.com/athlete/will-campuzano\n",
      "Scraping Aleksa Camur...\n",
      "https://www.ufc.com/athlete/aleksa-camur\n",
      "Scraping Chico Camus...\n",
      "https://www.ufc.com/athlete/chico-camus\n",
      "Scraping Asbel Cancio...\n",
      "https://www.ufc.com/athlete/artem-lobov-0\n",
      "Scraping Carlos Candelario...\n",
      "https://www.ufc.com/athlete/carlos-candelario\n",
      "Scraping Ronaldo Candido...\n",
      "https://www.ufc.com/athlete/ronaldo-candido\n",
      "Scraping Luiz Cane...\n",
      "https://www.ufc.com/athlete/luiz-cane\n",
      "Scraping Guido Cannetti...\n",
      "https://www.ufc.com/athlete/guido-cannetti\n",
      "Scraping Jared Cannonier...\n",
      "https://www.ufc.com/athlete/jared-cannonier\n",
      "Scraping Steve Cantwell...\n",
      "https://www.ufc.com/athlete/steve-cantwell\n",
      "Scraping Paul Capaldo...\n",
      "https://www.ufc.com/athlete/paul-capaldo\n",
      "Scraping Phil Caracappa...\n",
      "https://www.ufc.com/athlete/phil-caracappa\n",
      "Scraping Frank Caracci...\n",
      "https://www.ufc.com/athlete/skott-beyker-4\n",
      "Scraping Gina Carano...\n",
      "https://www.ufc.com/athlete/gina-carano\n",
      "Scraping Bryan Caraway...\n",
      "https://www.ufc.com/athlete/bryan-caraway\n",
      "Scraping Chris Cariaso...\n",
      "https://www.ufc.com/athlete/chris-cariaso\n",
      "Scraping Rafael Carino...\n",
      "https://www.ufc.com/athlete/stiv-kantvell-0\n",
      "Scraping Antonio Carlos Junior...\n",
      "https://www.ufc.com/athlete/antonio-carlos-junior\n",
      "Scraping Spike Carlyle...\n",
      "https://www.ufc.com/athlete/spike-carlyle\n",
      "Scraping Francis Carmont...\n",
      "https://www.ufc.com/athlete/francis-carmont\n",
      "Scraping Liz Carmouche...\n",
      "https://www.ufc.com/athlete/risu-kamushiyu\n",
      "Scraping Roan Carneiro...\n",
      "https://www.ufc.com/athlete/roan-carneiro\n",
      "Scraping Ariane Carnelossi...\n",
      "https://www.ufc.com/athlete/ariane-carnelossi\n",
      "Scraping Luana Carolina...\n",
      "https://www.ufc.com/athlete/luana-carolina\n",
      "Scraping Tim Caron...\n",
      "https://www.ufc.com/athlete/tim-caron\n",
      "Scraping Clayton Carpenter...\n",
      "https://www.ufc.com/athlete/clayton-carpenter\n",
      "Scraping Cain Carrizosa...\n",
      "https://www.ufc.com/athlete/cain-carrizosa\n",
      "Scraping Shonie Carter...\n",
      "https://www.ufc.com/athlete/shonie-carter\n",
      "Scraping Jack Cartwright...\n",
      "https://www.ufc.com/athlete/jack-cartwright\n",
      "Scraping Antonio Carvalho...\n",
      "https://www.ufc.com/athlete/antonio-carvalho\n",
      "Scraping Shane Carwin...\n",
      "https://www.ufc.com/athlete/shane-carwin\n",
      "Scraping Johnny Case...\n",
      "https://www.ufc.com/athlete/johnny-case\n",
      "Scraping Cortney Casey...\n",
      "https://www.ufc.com/athlete/cortney-casey\n",
      "Scraping Kevin Casey...\n",
      "https://www.ufc.com/athlete/kevin-casey\n",
      "Scraping Duane Cason...\n",
      "https://www.ufc.com/athlete/duane-cason\n",
      "Scraping John Castaneda...\n",
      "https://www.ufc.com/athlete/john-castaneda\n",
      "Scraping Danny Castillo...\n",
      "https://www.ufc.com/athlete/danny-castillo\n",
      "Scraping Gil Castillo...\n",
      "https://www.ufc.com/athlete/gil-castillo\n",
      "Scraping Nick Catone...\n",
      "https://www.ufc.com/athlete/nick-catone\n",
      "Scraping Luke Caudillo...\n",
      "https://www.ufc.com/athlete/luke-caudillo\n",
      "Scraping Rafael Cavalcante...\n",
      "https://www.ufc.com/athlete/rafael-cavalcante\n",
      "Scraping Jacqueline Cavalcanti...\n",
      "https://www.ufc.com/athlete/jacqueline-cavalcanti\n",
      "Scraping Magnus Cedenblad...\n",
      "https://www.ufc.com/athlete/magnus-cedenblad\n",
      "Scraping Yosdenis Cedeno...\n",
      "https://www.ufc.com/athlete/yosdenis-cedeno\n",
      "Scraping Henry Cejudo...\n",
      "https://www.ufc.com/athlete/henry-cejudo\n",
      "Scraping Adam Cella...\n",
      "https://www.ufc.com/athlete/abner-lloveras-3\n",
      "Scraping Vinicius Cenci...\n",
      "https://www.ufc.com/athlete/vinicius-cenci\n",
      "Scraping Katlyn Cerminara...\n",
      "https://www.ufc.com/athlete/katlyn-cerminara\n",
      "Scraping Rafael Cerqueira...\n",
      "https://www.ufc.com/athlete/rafael-cerqueira\n",
      "Scraping Alberta Cerra...\n",
      "https://www.ufc.com/athlete/alberta-cerra\n",
      "Scraping Donald Cerrone...\n",
      "https://www.ufc.com/athlete/donald-cerrone\n",
      "Scraping Luan Chagas...\n",
      "https://www.ufc.com/athlete/luan-chagas\n",
      "Scraping Edgar Chairez...\n",
      "https://www.ufc.com/athlete/edgar-chairez\n",
      "Scraping Ansar Chalangov...\n",
      "https://www.ufc.com/athlete/ansar-chalangov\n",
      "Scraping Alex Chambers...\n",
      "https://www.ufc.com/athlete/alex-chambers\n",
      "Scraping Michael Chandler...\n",
      "https://www.ufc.com/athlete/michael-chandler\n",
      "Scraping Chelsea Chandler...\n",
      "https://www.ufc.com/athlete/chelsea-chandler\n",
      "Scraping Donnie Chappell...\n",
      "https://www.ufc.com/athlete/donnie-chappell\n",
      "Scraping Joe Charles...\n",
      "https://www.ufc.com/athlete/maykl-chendler-0\n",
      "Scraping Morgan Charriere...\n",
      "https://www.ufc.com/athlete/morgan-charriere\n",
      "Scraping Ernest Chavez...\n",
      "https://www.ufc.com/athlete/ernest-chavez\n",
      "Scraping Danny Chavez...\n",
      "https://www.ufc.com/athlete/danny-chavez\n",
      "Scraping Gabriel Checco...\n",
      "https://www.ufc.com/athlete/gabriel-checco\n",
      "Scraping Albert Cheng...\n",
      "https://www.ufc.com/athlete/albert-cheng\n",
      "Scraping Fabio Cherant...\n",
      "https://www.ufc.com/athlete/fabio-cherant\n",
      "Scraping Mark Cherico...\n",
      "https://www.ufc.com/athlete/mark-cherico\n",
      "Scraping Macy Chiasson...\n",
      "https://www.ufc.com/athlete/macy-chiasson\n",
      "Scraping Michael Chiesa...\n",
      "https://www.ufc.com/athlete/michael-chiesa\n",
      "Scraping Giga Chikadze...\n",
      "https://www.ufc.com/athlete/giga-chikadze\n",
      "Scraping Khamzat Chimaev...\n",
      "https://www.ufc.com/athlete/khamzat-chimaev\n",
      "Scraping Sako Chivitchian...\n",
      "https://www.ufc.com/athlete/sako-chivitchian\n",
      "Scraping Seungwoo Choi...\n",
      "https://www.ufc.com/athlete/seungwoo-choi\n",
      "Scraping Dooho Choi...\n",
      "https://www.ufc.com/athlete/dooho-choi\n",
      "Scraping SeungGuk Choi...\n",
      "https://www.ufc.com/athlete/seungguk-choi\n",
      "Scraping John Cholish...\n",
      "https://www.ufc.com/athlete/john-cholish\n",
      "Scraping Ryo Chonan...\n",
      "https://www.ufc.com/athlete/ryo-chonan\n",
      "Scraping Will Chope...\n",
      "https://www.ufc.com/athlete/will-chope\n",
      "Scraping Joachim Christensen...\n",
      "https://www.ufc.com/athlete/joachim-christensen\n",
      "Scraping Kevin Christian...\n",
      "https://www.ufc.com/athlete/kevin-christian\n",
      "Scraping Dan Christison...\n",
      "https://www.ufc.com/athlete/dan-christison\n",
      "Scraping Anthony Christodoulou...\n",
      "https://www.ufc.com/athlete/anthony-christodoulou\n",
      "Scraping Yui Chul Nam...\n",
      "https://www.ufc.com/athlete/yui-chul-nam\n",
      "Scraping Cameron Church...\n",
      "https://www.ufc.com/athlete/cameron-church\n",
      "Scraping Mike Ciesnolevicz...\n",
      "https://www.ufc.com/athlete/mike-ciesnolevicz\n",
      "Scraping Hannah Cifers...\n",
      "https://www.ufc.com/athlete/hannah-cifers\n",
      "Scraping Misha Cirkunov...\n",
      "https://www.ufc.com/athlete/misha-cirkunov\n",
      "Scraping Heather Jo Clark...\n",
      "https://www.ufc.com/athlete/heather-jo-clark\n",
      "Scraping Logan Clark...\n",
      "https://www.ufc.com/athlete/logan-clark\n",
      "Scraping Jessica-Rose Clark...\n",
      "https://www.ufc.com/athlete/jessica-rose-clark\n",
      "Scraping Devin Clark...\n",
      "https://www.ufc.com/athlete/devin-clark\n",
      "Scraping Laverne Clark...\n",
      "https://www.ufc.com/athlete/laverne-clark\n",
      "Scraping Mitch Clarke...\n",
      "https://www.ufc.com/athlete/mitsuchi-kuraku\n",
      "Scraping Rich Clementi...\n",
      "https://www.ufc.com/athlete/rich-clementi\n",
      "Scraping Chris Clements...\n",
      "https://www.ufc.com/athlete/chris-clements\n",
      "Scraping Mark Climaco...\n",
      "https://www.ufc.com/athlete/mark-climaco\n",
      "Scraping Josh Clopton...\n",
      "https://www.ufc.com/athlete/josh-clopton\n",
      "Scraping Brian Cobb...\n",
      "https://www.ufc.com/athlete/brian-cobb\n",
      "Scraping John Cofer...\n",
      "https://www.ufc.com/athlete/john-cofer\n",
      "Scraping Felipe Colares...\n",
      "https://www.ufc.com/athlete/felipe-colares\n",
      "Scraping Chandler Cole...\n",
      "https://www.ufc.com/athlete/chandler-cole\n",
      "Scraping Coltin Cole...\n",
      "https://www.ufc.com/athlete/coltin-cole-0\n",
      "Scraping Mark Coleman...\n",
      "https://www.ufc.com/athlete/mark-coleman\n",
      "Scraping Clay Collard...\n",
      "https://www.ufc.com/athlete/clay-collard\n",
      "Scraping Jamie Colleen...\n",
      "https://www.ufc.com/athlete/jamie-colleen\n",
      "Scraping Jake Collier...\n",
      "https://www.ufc.com/athlete/jake-collier\n",
      "Scraping Christian Colombo...\n",
      "https://www.ufc.com/athlete/christian-colombo\n",
      "Scraping Wes Combs...\n",
      "https://www.ufc.com/athlete/wes-combs\n",
      "Scraping Carlos Condit...\n",
      "https://www.ufc.com/athlete/carlos-condit\n",
      "Scraping Chris Condo...\n",
      "https://www.ufc.com/athlete/chris-condo\n",
      "Scraping Wang Cong...\n",
      "https://www.ufc.com/athlete/wang-cong\n",
      "Scraping Tristan Connelly...\n",
      "https://www.ufc.com/athlete/tristan-connelly\n",
      "Scraping Marcos Conrado Junior...\n",
      "https://www.ufc.com/athlete/marcos-conrado-junior\n",
      "Scraping Bob Cook...\n",
      "https://www.ufc.com/athlete/brayen-kobb-2\n",
      "Scraping Amanda Cooper...\n",
      "https://www.ufc.com/athlete/amanda-cooper\n",
      "Scraping Kit Cope...\n",
      "https://www.ufc.com/athlete/kit-cope\n",
      "Scraping Chris Cope...\n",
      "https://www.ufc.com/athlete/chris-cope\n",
      "Scraping Josh Copeland...\n",
      "https://www.ufc.com/athlete/josh-copeland\n",
      "Scraping Michael Cora...\n",
      "https://www.ufc.com/athlete/michael-cora\n",
      "Scraping Akira Corassani...\n",
      "https://www.ufc.com/athlete/akira-corassani\n",
      "Scraping Cory Corbin...\n",
      "https://www.ufc.com/athlete/cory-corbin\n",
      "Scraping Daniel Cormier...\n",
      "https://www.ufc.com/athlete/daniel-cormier\n",
      "Scraping Nora Cornolle...\n",
      "https://www.ufc.com/athlete/nora-cornolle\n",
      "Scraping Jonathan Correa...\n",
      "https://www.ufc.com/athlete/jonathan-correa\n",
      "Scraping Bethe Correia...\n",
      "https://www.ufc.com/athlete/bethe-correia\n",
      "Scraping Wesley Correira...\n",
      "https://www.ufc.com/athlete/wesley-correira\n",
      "Scraping Waldo Cortes Acosta...\n",
      "https://www.ufc.com/athlete/waldo-cortes-acosta\n",
      "Scraping Reyes Cortez...\n",
      "https://www.ufc.com/athlete/reyes-cortez\n",
      "Scraping Tracy Cortez...\n",
      "https://www.ufc.com/athlete/tracy-cortez\n",
      "Scraping Orion Cosce...\n",
      "https://www.ufc.com/athlete/orion-cosce\n",
      "Scraping Louis Cosce...\n",
      "https://www.ufc.com/athlete/louis-cosce\n",
      "Scraping Randy Costa...\n",
      "https://www.ufc.com/athlete/randy-costa\n",
      "Scraping Melquizael Costa...\n",
      "https://www.ufc.com/athlete/melquizael-costa\n",
      "Scraping Davi Costa...\n",
      "https://www.ufc.com/athlete/davi-costa\n",
      "Scraping Alessandro Costa...\n",
      "https://www.ufc.com/athlete/alessandro-costa\n",
      "Scraping Paulo Costa...\n",
      "https://www.ufc.com/athlete/paulo-costa\n",
      "Scraping Oscar Cota...\n",
      "https://www.ufc.com/athlete/oscar-cota\n",
      "Scraping Patrick Cote...\n",
      "https://www.ufc.com/athlete/patrick-cote\n",
      "Scraping J.C. Cottrell...\n",
      "https://www.ufc.com/athlete/jc-cottrell\n",
      "Scraping JR Coughran...\n",
      "https://www.ufc.com/athlete/jr-coughran-0\n",
      "Scraping Rashad Coulter...\n",
      "https://www.ufc.com/athlete/rashad-coulter\n",
      "Scraping Randy Couture...\n",
      "https://www.ufc.com/athlete/randy-couture\n",
      "Scraping Ryan Couture...\n",
      "https://www.ufc.com/athlete/ryan-couture\n",
      "Scraping Colby Covington...\n",
      "https://www.ufc.com/athlete/colby-covington\n",
      "Scraping Hailey Cowan...\n",
      "https://www.ufc.com/athlete/hailey-cowan\n",
      "Scraping Jeff Cox...\n",
      "https://www.ufc.com/athlete/jeff-cox\n",
      "Scraping Nathan Coy...\n",
      "https://www.ufc.com/athlete/neisan-koi\n",
      "Scraping Paul Craig...\n",
      "https://www.ufc.com/athlete/paul-craig\n",
      "Scraping Andrew Craig...\n",
      "https://www.ufc.com/athlete/andrew-craig\n",
      "Scraping Dan Cramer...\n",
      "https://www.ufc.com/athlete/dan-cramer\n",
      "Scraping Alberto Crane...\n",
      "https://www.ufc.com/athlete/alberto-crane\n",
      "Scraping Tim Credeur...\n",
      "https://www.ufc.com/athlete/tim-credeur\n",
      "Scraping Paul Creighton...\n",
      "https://www.ufc.com/athlete/paul-creighton\n",
      "Scraping Mirko Cro Cop...\n",
      "https://www.ufc.com/athlete/mirko-cro-cop\n",
      "Scraping Edilberto Crocota...\n",
      "https://www.ufc.com/athlete/edilberto-crocota\n",
      "Scraping Kevin Croom...\n",
      "https://www.ufc.com/athlete/kevin-croom\n",
      "Scraping Kiefer Crosbie...\n",
      "https://www.ufc.com/athlete/kiefer-crosbie\n",
      "Scraping Kenneth Cross...\n",
      "https://www.ufc.com/athlete/kenneth-cross\n",
      "Scraping Allen Crowder...\n",
      "https://www.ufc.com/athlete/allen-crowder\n",
      "Scraping Daron Cruickshank...\n",
      "https://www.ufc.com/athlete/daron-cruickshank\n",
      "Scraping Richard Crunkilton Jr....\n",
      "https://www.ufc.com/athlete/richard-crunkilton-jr\n",
      "Scraping Jimmy Crute...\n",
      "https://www.ufc.com/athlete/jim-crute\n",
      "Scraping Aalon Cruz...\n",
      "https://www.ufc.com/athlete/aalon-cruz\n",
      "Scraping Marcio Cruz...\n",
      "https://www.ufc.com/athlete/marcio-cruz\n",
      "Scraping Dominick Cruz...\n",
      "https://www.ufc.com/athlete/dominick-cruz\n",
      "Scraping Timmy Cuamba...\n",
      "https://www.ufc.com/athlete/timothy-cuamba\n",
      "Scraping Jay Cucciniello...\n",
      "https://www.ufc.com/athlete/jay-cucciniello\n",
      "Scraping Emilio Cuellar...\n",
      "https://www.ufc.com/athlete/emilio-cuellar\n",
      "Scraping Josh Culibao...\n",
      "https://www.ufc.com/athlete/joshua-culibao\n",
      "Scraping Zak Cummings...\n",
      "https://www.ufc.com/athlete/satsuku-kaminkusu\n",
      "Scraping Patrick Cummins...\n",
      "https://www.ufc.com/athlete/hatoritsuku-kaminsu\n",
      "Scraping Luke Cummo...\n",
      "https://www.ufc.com/athlete/luke-cummo\n",
      "Scraping Hugo Cunha...\n",
      "https://www.ufc.com/athlete/hugo-cunha\n",
      "Scraping Alton Cunningham...\n",
      "https://www.ufc.com/athlete/alton-cunningham\n",
      "Scraping AJ Cunningham...\n",
      "https://www.ufc.com/athlete/aj-cunningham\n",
      "Scraping Santo Curatolo...\n",
      "https://www.ufc.com/athlete/santo-curatolo\n",
      "Scraping Larry Cureton...\n",
      "https://www.ufc.com/athlete/lyuk-kummo-0\n",
      "Scraping Kailin Curran...\n",
      "https://www.ufc.com/athlete/kailin-curran\n",
      "Scraping Jeff Curran...\n",
      "https://www.ufc.com/athlete/jeff-curran\n",
      "Scraping Chris Curtis...\n",
      "https://www.ufc.com/athlete/chris-curtis\n",
      "Scraping Ion Cutelaba...\n",
      "https://www.ufc.com/athlete/ion-cutelaba\n",
      "Scraping Gleidson Cutis...\n",
      "https://www.ufc.com/athlete/gleidson-cutis\n",
      "Scraping Cris Cyborg...\n",
      "https://www.ufc.com/athlete/cris-cyborg\n",
      "Scraping Diego Henrique da Silva...\n",
      "https://www.ufc.com/athlete/diego-henrique-da-silva\n",
      "Scraping Alex da Silva...\n",
      "https://www.ufc.com/athlete/alex-da-silva\n",
      "Scraping Henrique da Silva...\n",
      "https://www.ufc.com/athlete/henrique-da-silva\n",
      "Scraping Ariane da Silva...\n",
      "https://www.ufc.com/athlete/ariane-lipski\n",
      "Scraping Henrique Da Silva Lopes...\n",
      "https://www.ufc.com/athlete/henrique-da-silva-lopes\n",
      "Scraping Dayana da Silva Santos...\n",
      "https://www.ufc.com/athlete/dayana-da-silva-santos\n",
      "Scraping Marcus Da Silviera...\n",
      "https://www.ufc.com/athlete/marcus-da-silviera\n",
      "Scraping Nicolas Dalby...\n",
      "https://www.ufc.com/athlete/nicolas-dalby\n",
      "Scraping Paul Daley...\n",
      "https://www.ufc.com/athlete/paul-daley\n",
      "Scraping Aisling Daly...\n",
      "https://www.ufc.com/athlete/aisling-daly\n",
      "Scraping Leonardo Damiani...\n",
      "https://www.ufc.com/athlete/leonardo-damiani\n",
      "Scraping Rodrigo Damm...\n",
      "https://www.ufc.com/athlete/rodrigo-damm\n",
      "Scraping Batgerel Danaa...\n",
      "https://www.ufc.com/athlete/batgerel-danaa\n",
      "Scraping Cindy Dandois...\n",
      "https://www.ufc.com/athlete/cindy-dandois\n",
      "Scraping Peter Danesoe...\n",
      "https://www.ufc.com/athlete/peter-danesoe\n",
      "Scraping Jarjis Danho...\n",
      "https://www.ufc.com/athlete/jarjis-danho\n",
      "Scraping Jose Daniel Medina...\n",
      "https://www.ufc.com/athlete/jose-daniel-medina\n",
      "Scraping Alexandre Dantas...\n",
      "https://www.ufc.com/athlete/alexandre-dantas\n",
      "Scraping Mac Danzig...\n",
      "https://www.ufc.com/athlete/mac-danzig\n",
      "Scraping Beneil Dariush...\n",
      "https://www.ufc.com/athlete/beneil-dariush\n",
      "Scraping Sean Daughtery...\n",
      "https://www.ufc.com/athlete/sean-daughtery\n",
      "Scraping Chris Daukaus...\n",
      "https://www.ufc.com/athlete/chris-daukaus\n",
      "Scraping Kyle Daukaus...\n",
      "https://www.ufc.com/athlete/kyle-daukaus\n",
      "Scraping Phil Davis...\n",
      "https://www.ufc.com/athlete/phil-davis\n",
      "Scraping Marcus Davis...\n",
      "https://www.ufc.com/athlete/marcus-davis\n",
      "Scraping Rick Davis...\n",
      "https://www.ufc.com/athlete/rick-davis\n",
      "Scraping Brandon Davis...\n",
      "https://www.ufc.com/athlete/brandon-davis\n",
      "Scraping Mike Davis...\n",
      "https://www.ufc.com/athlete/mike-davis\n",
      "Scraping Alexis Davis...\n",
      "https://www.ufc.com/athlete/arekushisu-teihisu\n",
      "Scraping Hakeem Dawodu...\n",
      "https://www.ufc.com/athlete/hakeem-dawodu\n",
      "Scraping Grant Dawson...\n",
      "https://www.ufc.com/athlete/grant-dawson\n",
      "Scraping Jason Day...\n",
      "https://www.ufc.com/athlete/jason-day\n",
      "Scraping Martin Day...\n",
      "https://www.ufc.com/athlete/martin-day\n",
      "Scraping Angel De Anda...\n",
      "https://www.ufc.com/athlete/angel-de-anda\n",
      "Scraping Yorgan De Castro...\n",
      "https://www.ufc.com/athlete/yorgan-de-castro\n",
      "Scraping Rafael de Freitas...\n",
      "https://www.ufc.com/athlete/rafael-de-freitas\n",
      "Scraping Geraldo de Freitas Jr....\n",
      "https://www.ufc.com/athlete/gerlado-de-freitas-jr\n",
      "Scraping Phil De Fries...\n",
      "https://www.ufc.com/athlete/phil-de-fries\n",
      "Scraping Chris De La Rocha...\n",
      "https://www.ufc.com/athlete/chris-de-la-rocha\n",
      "Scraping Mark De La Rosa...\n",
      "https://www.ufc.com/athlete/mark-de-la-rosa\n",
      "Scraping Montana De La Rosa...\n",
      "https://www.ufc.com/athlete/montana-de-la-rosa\n",
      "Scraping Mike De La Torre...\n",
      "https://www.ufc.com/athlete/mike-de-la-torre\n",
      "Scraping Rodrigo de Lima...\n",
      "https://www.ufc.com/athlete/rodrigo-de-lima\n",
      "Scraping Marcos Rogerio de Lima...\n",
      "https://www.ufc.com/athlete/marcos-rogerio-de-lima\n",
      "Scraping Jorge de Oliveira...\n",
      "https://www.ufc.com/athlete/jorge-de-oliveira\n",
      "Scraping Leonardo De Oliveira...\n",
      "https://www.ufc.com/athlete/leonardo-de-oliveira\n",
      "Scraping Isabela De Padua...\n",
      "https://www.ufc.com/athlete/isabela-de-padua\n",
      "Scraping Gloria de Paula...\n",
      "https://www.ufc.com/athlete/gloria-de-paula\n",
      "Scraping Germaine de Randamie...\n",
      "https://www.ufc.com/athlete/germaine-de-randamie\n",
      "Scraping Reinier de Ridder...\n",
      "https://www.ufc.com/athlete/reinier-de-ridder\n",
      "Scraping Carls John De Tomas...\n",
      "https://www.ufc.com/athlete/carls-john-de-tomas\n",
      "Scraping Carl Deaton...\n",
      "https://www.ufc.com/athlete/carl-deaton\n",
      "Scraping Tom DeBlass...\n",
      "https://www.ufc.com/athlete/tom-aspinell-0\n",
      "Scraping Shane Del Rosario...\n",
      "https://www.ufc.com/athlete/shane-del-rosario\n",
      "Scraping Wallen Del Rosario...\n",
      "https://www.ufc.com/athlete/wallen-del-rosario\n",
      "Scraping Rolando Delgado...\n",
      "https://www.ufc.com/athlete/rolando-delgado\n",
      "Scraping Jose Delgado...\n",
      "https://www.ufc.com/athlete/jose-delgado\n",
      "Scraping Ante Delija...\n",
      "https://www.ufc.com/athlete/ante-delija\n",
      "Scraping Jack Della Maddalena...\n",
      "https://www.ufc.com/athlete/jack-della-maddalena\n",
      "Scraping Roland Delorme...\n",
      "https://www.ufc.com/athlete/roland-delorme\n",
      "Scraping Jason DeLucia...\n",
      "https://www.ufc.com/athlete/jason-delucia\n",
      "Scraping Vanessa Demopoulos...\n",
      "https://www.ufc.com/athlete/vanessa-demopoulos\n",
      "Scraping Chris Dempsey...\n",
      "https://www.ufc.com/athlete/chris-dempsey\n",
      "Scraping Nick Denis...\n",
      "https://www.ufc.com/athlete/nick-denis\n",
      "Scraping Jason Dent...\n",
      "https://www.ufc.com/athlete/jason-dent\n",
      "Scraping Mackenzie Dern...\n",
      "https://www.ufc.com/athlete/mackenzie-dern\n",
      "Scraping Tony DeSouza...\n",
      "https://www.ufc.com/athlete/tony-desouza\n",
      "Scraping Robelis Despaigne...\n",
      "https://www.ufc.com/athlete/robelis-despaigne\n",
      "Scraping Edwin Dewees...\n",
      "https://www.ufc.com/athlete/edwin-dewees\n",
      "Scraping Alessio Di Chirico...\n",
      "https://www.ufc.com/athlete/alessio-di-chirico\n",
      "Scraping Micol Di Segni...\n",
      "https://www.ufc.com/athlete/micol-di-segni\n",
      "Scraping Cyrille Diabate...\n",
      "https://www.ufc.com/athlete/cyrille-diabate\n",
      "Scraping Marc Diakiese...\n",
      "https://www.ufc.com/athlete/marc-diakiese\n",
      "Scraping Tyler Diamond...\n",
      "https://www.ufc.com/athlete/tyler-diamond\n",
      "Scraping Blood Diamond...\n",
      "https://www.ufc.com/athlete/mike-diamond\n",
      "Scraping Hacran Dias...\n",
      "https://www.ufc.com/athlete/hacran-dias\n",
      "Scraping Victor Dias...\n",
      "https://www.ufc.com/athlete/victor-dias\n",
      "Scraping Eldo Xavier Dias...\n",
      "https://www.ufc.com/athlete/eldo-xavier-dias\n",
      "Scraping Nate Diaz...\n",
      "https://www.ufc.com/athlete/nate-diaz\n",
      "Scraping Adrian Diaz...\n",
      "https://www.ufc.com/athlete/adrian-diaz\n",
      "Scraping Nick Diaz...\n",
      "https://www.ufc.com/athlete/nick-diaz\n",
      "Scraping Ozzy Diaz...\n",
      "https://www.ufc.com/athlete/ozzy-diaz\n",
      "Scraping TJ Dillashaw...\n",
      "https://www.ufc.com/athlete/tj-dillashaw\n",
      "Scraping Jhonata Diniz...\n",
      "https://www.ufc.com/athlete/jhonata-diniz\n",
      "Scraping Rico DiSciullo...\n",
      "https://www.ufc.com/athlete/rico-disciullo\n",
      "Scraping Matt Dixon...\n",
      "https://www.ufc.com/athlete/matt-dixon\n",
      "Scraping Russell Doane...\n",
      "https://www.ufc.com/athlete/russell-doane\n",
      "Scraping Drew Dober...\n",
      "https://www.ufc.com/athlete/drew-dober\n",
      "Scraping Shana Dobson...\n",
      "https://www.ufc.com/athlete/shana-dobson\n",
      "Scraping AJ Dobson...\n",
      "https://www.ufc.com/athlete/aj-dobson\n",
      "Scraping David Dodd...\n",
      "https://www.ufc.com/athlete/david-dodd\n",
      "Scraping John Dodson...\n",
      "https://www.ufc.com/athlete/shiyon-totsutoson\n",
      "Scraping Joe Doerksen...\n",
      "https://www.ufc.com/athlete/joe-doerksen\n",
      "Scraping Roman Dolidze...\n",
      "https://www.ufc.com/athlete/roman-dolidze\n",
      "Scraping Cameron Dollar...\n",
      "https://www.ufc.com/athlete/cameron-dollar\n",
      "Scraping CB Dollaway...\n",
      "https://www.ufc.com/athlete/cb-dollaway\n",
      "Scraping Montserrat Rendon...\n",
      "https://www.ufc.com/athlete/montserrat-rendon\n",
      "Scraping Cody Donovan...\n",
      "https://www.ufc.com/athlete/kodi-stemenn-0\n",
      "Scraping Houston Dorr...\n",
      "https://www.ufc.com/athlete/houston-dorr\n",
      "Scraping Rafael Dos Anjos...\n",
      "https://www.ufc.com/athlete/rafael-dos-anjos\n",
      "Scraping Anderson dos Santos...\n",
      "https://www.ufc.com/athlete/anderson-dos-santos\n",
      "Scraping Junior Dos Santos...\n",
      "https://www.ufc.com/athlete/junior-dos-santos\n",
      "Scraping Antonio dos Santos...\n",
      "https://www.ufc.com/athlete/antonio-dos-santos\n",
      "Scraping Elizeu Zaleski dos Santos...\n",
      "https://www.ufc.com/athlete/elizeu-dos-santos\n",
      "Scraping Geronimo dos Santos...\n",
      "https://www.ufc.com/athlete/geronimo-dos-santos\n",
      "Scraping Acacio dos Santos...\n",
      "https://www.ufc.com/athlete/acacio-dos-santos\n",
      "Scraping Felipe dos Santos...\n",
      "https://www.ufc.com/athlete/felipe-dos-santos\n",
      "Scraping Maiara Amajanas Dos Santos...\n",
      "https://www.ufc.com/athlete/maiara-amajanas-dos-santos\n",
      "Scraping Rayanne dos Santos...\n",
      "https://www.ufc.com/athlete/rayanne-dos-santos\n",
      "Scraping Oleksandr Doskalchuk...\n",
      "https://www.ufc.com/athlete/oleksandr-doskalchuk\n",
      "Scraping Cedric Doumbe...\n",
      "https://www.ufc.com/athlete/cedric-doumbe\n",
      "Scraping John Dowdy...\n",
      "https://www.ufc.com/athlete/khyuston-dorr-0\n",
      "Scraping Dan Downes...\n",
      "https://www.ufc.com/athlete/dan-downes\n",
      "Scraping Derek Downey...\n",
      "https://www.ufc.com/athlete/derek-downey\n",
      "Scraping Kyle Driscoll...\n",
      "https://www.ufc.com/athlete/kyle-driscoll\n",
      "Scraping Tomasz Drwal...\n",
      "https://www.ufc.com/athlete/tomasz-drwal\n",
      "Scraping Robert Drysdale...\n",
      "https://www.ufc.com/athlete/robert-drysdale\n",
      "Scraping Dricus Du Plessis...\n",
      "https://www.ufc.com/athlete/dricus-du-plessis\n",
      "Scraping Hugo Duarte...\n",
      "https://www.ufc.com/athlete/hugo-duarte\n",
      "Scraping Yuneisy Duben...\n",
      "https://www.ufc.com/athlete/yuneisy-duben\n",
      "Scraping Emily Ducote...\n",
      "https://www.ufc.com/athlete/emily-ducote\n",
      "Scraping Viktoriia Dudakova...\n",
      "https://www.ufc.com/athlete/viktoriia-dudakova\n",
      "Scraping Milana Dudieva...\n",
      "https://www.ufc.com/athlete/milana-dudieva\n",
      "Scraping Todd Duffee...\n",
      "https://www.ufc.com/athlete/todd-duffee\n",
      "Scraping Joe Duffy...\n",
      "https://www.ufc.com/athlete/joe-duffy\n",
      "Scraping Alexis Dufresne...\n",
      "https://www.ufc.com/athlete/alexis-dufresne\n",
      "Scraping Jessamyn Duke...\n",
      "https://www.ufc.com/athlete/jessamyn-duke\n",
      "Scraping Islam Dulatov...\n",
      "https://www.ufc.com/athlete/islam-dulatov\n",
      "Scraping Isaac Dulgarian...\n",
      "https://www.ufc.com/athlete/isaac-dulgarian\n",
      "Scraping Kelly Dullanty...\n",
      "https://www.ufc.com/athlete/kelly-dullanty\n",
      "Scraping Sedriques Dumas...\n",
      "https://www.ufc.com/athlete/sedriques-dumas\n",
      "Scraping Norma Dumont...\n",
      "https://www.ufc.com/athlete/norma-dumont\n",
      "Scraping Christian Leroy Duncan...\n",
      "https://www.ufc.com/athlete/christian-leroy-duncan\n",
      "Scraping Chris Duncan...\n",
      "https://www.ufc.com/athlete/chris-duncan\n",
      "Scraping Evan Dunham...\n",
      "https://www.ufc.com/athlete/evan-dunham\n",
      "Scraping Tom Duquesnoy...\n",
      "https://www.ufc.com/athlete/tom-duquesnoy\n",
      "Scraping Albert Duraev...\n",
      "https://www.ufc.com/athlete/albert-duraev\n",
      "Scraping Reuben Duran...\n",
      "https://www.ufc.com/athlete/reuben-duran\n",
      "Scraping Cody Durden...\n",
      "https://www.ufc.com/athlete/cody-durden\n",
      "Scraping Luiz Dutra...\n",
      "https://www.ufc.com/athlete/luiz-dutra\n",
      "Scraping Riley Dutro...\n",
      "https://www.ufc.com/athlete/riley-dutro\n",
      "Scraping Merab Dvalishvili...\n",
      "https://www.ufc.com/athlete/merab-dvalishvili\n",
      "Scraping David Dvorak...\n",
      "https://www.ufc.com/athlete/david-dvorak\n",
      "Scraping Matt Dwyer...\n",
      "https://www.ufc.com/athlete/matt-dwyer\n",
      "Scraping Rolando Dy...\n",
      "https://www.ufc.com/athlete/rolando-dy\n",
      "Scraping Ben Earwood...\n",
      "https://www.ufc.com/athlete/ben-earwood\n",
      "Scraping Cody East...\n",
      "https://www.ufc.com/athlete/cody-east\n",
      "Scraping Marvin Eastman...\n",
      "https://www.ufc.com/athlete/marvin-eastman\n",
      "Scraping Mike Easton...\n",
      "https://www.ufc.com/athlete/mike-easton\n",
      "Scraping Brian Ebersole...\n",
      "https://www.ufc.com/athlete/brian-ebersole\n",
      "Scraping Roybert Echeverria...\n",
      "https://www.ufc.com/athlete/roy-echeverria\n",
      "Scraping Mark Eddiva...\n",
      "https://www.ufc.com/athlete/mark-eddiva\n",
      "Scraping Frankie Edgar...\n",
      "https://www.ufc.com/athlete/frankie-edgar\n",
      "Scraping Abdul-Kerim Edilov...\n",
      "https://www.ufc.com/athlete/abdul-kerim-edilov\n",
      "Scraping Johnny Eduardo...\n",
      "https://www.ufc.com/athlete/johnny-eduardo\n",
      "Scraping Te Edwards...\n",
      "https://www.ufc.com/athlete/te-edwards\n",
      "Scraping Justin Edwards...\n",
      "https://www.ufc.com/athlete/justin-edwards\n",
      "Scraping Yves Edwards...\n",
      "https://www.ufc.com/athlete/yves-edwards\n",
      "Scraping Adli Edwards...\n",
      "https://www.ufc.com/athlete/adli-edwards\n",
      "Scraping Joselyne Edwards...\n",
      "https://www.ufc.com/athlete/joselyne-edwards\n",
      "Scraping Leon Edwards...\n",
      "https://www.ufc.com/athlete/leon-edwards\n",
      "Scraping Tom Egan...\n",
      "https://www.ufc.com/athlete/tom-egan\n",
      "Scraping Stephanie Egger...\n",
      "https://www.ufc.com/athlete/stephanie-egger\n",
      "Scraping Justin Eilers...\n",
      "https://www.ufc.com/athlete/justin-eilers\n",
      "Scraping John-Olav Einemo...\n",
      "https://www.ufc.com/athlete/john-olav-einemo\n",
      "Scraping Per Eklund...\n",
      "https://www.ufc.com/athlete/per-eklund\n",
      "Scraping Evan Elder...\n",
      "https://www.ufc.com/athlete/evan-elder\n",
      "Scraping Joao Elias...\n",
      "https://www.ufc.com/athlete/joao-elias\n",
      "Scraping Darren Elkins...\n",
      "https://www.ufc.com/athlete/darren-elkins\n",
      "Scraping Jake Ellenberger...\n",
      "https://www.ufc.com/athlete/jake-ellenberger\n",
      "Scraping Joe Ellenberger...\n",
      "https://www.ufc.com/athlete/joe-ellenberger\n",
      "Scraping Oban Elliott...\n",
      "https://www.ufc.com/athlete/oban-elliott\n",
      "Scraping Tim Elliott...\n",
      "https://www.ufc.com/athlete/tim-elliott\n",
      "Scraping Lisa Ellis...\n",
      "https://www.ufc.com/athlete/lisa-ellis\n",
      "Scraping Brian Ellis...\n",
      "https://www.ufc.com/athlete/brian-ellis\n",
      "Scraping Anna Elmose...\n",
      "https://www.ufc.com/athlete/anna-elmose\n",
      "Scraping Cameron Else...\n",
      "https://www.ufc.com/athlete/cameron-else\n",
      "Scraping Sovannahry Em...\n",
      "https://www.ufc.com/athlete/sovannahry-em\n",
      "Scraping Ramazan Emeev...\n",
      "https://www.ufc.com/athlete/ramazan-emeev\n",
      "Scraping Rob Emerson...\n",
      "https://www.ufc.com/athlete/rob-emerson\n",
      "Scraping Freddy Emiliano Linares...\n",
      "https://www.ufc.com/athlete/freddy-emiliano-linares\n",
      "Scraping Jamall Emmers...\n",
      "https://www.ufc.com/athlete/jamall-emmers\n",
      "Scraping Josh Emmett...\n",
      "https://www.ufc.com/athlete/josh-emmett\n",
      "Scraping Kolton Englund...\n",
      "https://www.ufc.com/athlete/kolton-englund\n",
      "Scraping Oliver Enkamp...\n",
      "https://www.ufc.com/athlete/oliver-enkamp\n",
      "Scraping Alex Enlund...\n",
      "https://www.ufc.com/athlete/alex-enlund\n",
      "Scraping Ian Entwistle...\n",
      "https://www.ufc.com/athlete/ian-entwistle\n",
      "Scraping Andy Enz...\n",
      "https://www.ufc.com/athlete/andy-enz\n",
      "Scraping Steve Erceg...\n",
      "https://www.ufc.com/athlete/steve-erceg\n",
      "Scraping Konstantin Erokhin...\n",
      "https://www.ufc.com/athlete/konstantin-erokhin\n",
      "Scraping Julian Erosa...\n",
      "https://www.ufc.com/athlete/julian-erosa\n",
      "Scraping Jarno Errens...\n",
      "https://www.ufc.com/athlete/jarno-errens\n",
      "Scraping Ivan Erslan...\n",
      "https://www.ufc.com/athlete/ivan-erslan\n",
      "Scraping Cole Escovedo...\n",
      "https://www.ufc.com/athlete/cole-escovedo\n",
      "Scraping Efrain Escudero...\n",
      "https://www.ufc.com/athlete/efrain-escudero\n",
      "Scraping Carla Esparza...\n",
      "https://www.ufc.com/athlete/carla-esparza\n",
      "Scraping Juan Espino...\n",
      "https://www.ufc.com/athlete/juan-espino\n",
      "Scraping Jordan Espinosa...\n",
      "https://www.ufc.com/athlete/jordan-espinosa\n",
      "Scraping Jodie Esquibel...\n",
      "https://www.ufc.com/athlete/jodie-esquibel\n",
      "Scraping Rafael Estevam...\n",
      "https://www.ufc.com/athlete/rafael-estevam\n",
      "Scraping Achilles Estremadura...\n",
      "https://www.ufc.com/athlete/achilles-estremadura\n",
      "Scraping Shaun Etchell...\n",
      "https://www.ufc.com/athlete/shaun-etchell\n",
      "Scraping Terry Etim...\n",
      "https://www.ufc.com/athlete/terry-etim\n",
      "Scraping Fred Ettish...\n",
      "https://www.ufc.com/athlete/fred-ettish\n",
      "Scraping Sijara Eubanks...\n",
      "https://www.ufc.com/athlete/sijara-eubanks\n",
      "Scraping Rashad Evans...\n",
      "https://www.ufc.com/athlete/rashad-evans\n",
      "Scraping Doug Evans...\n",
      "https://www.ufc.com/athlete/doug-evans\n",
      "Scraping Ashlee Evans-Smith...\n",
      "https://www.ufc.com/athlete/ashlee-evans-smith\n",
      "Scraping Dan Evensen...\n",
      "https://www.ufc.com/athlete/dan-evensen\n",
      "Scraping Tonya Evinger...\n",
      "https://www.ufc.com/athlete/tonya-evinger\n",
      "Scraping Movsar Evloev...\n",
      "https://www.ufc.com/athlete/movsar-evloev\n",
      "Scraping Andre Ewell...\n",
      "https://www.ufc.com/athlete/andre-ewell\n",
      "Scraping Jessica Eye...\n",
      "https://www.ufc.com/athlete/jessica-eye\n",
      "Scraping Edward Faaloloto...\n",
      "https://www.ufc.com/athlete/edward-faaloloto\n",
      "Scraping Urijah Faber...\n",
      "https://www.ufc.com/athlete/urijah-faber\n",
      "Scraping Melinda Fbin...\n",
      "https://www.ufc.com/athlete/melinda-fabian\n",
      "Scraping Wagnney Fabiano...\n",
      "https://www.ufc.com/athlete/wagnney-fabiano\n",
      "Scraping Bartosz Fabinski...\n",
      "https://www.ufc.com/athlete/bartosz-fabinski\n",
      "Scraping Ron Faircloth...\n",
      "https://www.ufc.com/athlete/ron-faircloth\n",
      "Scraping Zarah Fairn...\n",
      "https://www.ufc.com/athlete/zarah-fairn\n",
      "Scraping Jason Fairn...\n",
      "https://www.ufc.com/athlete/jason-fairn\n",
      "Scraping Rinat Fakhretdinov...\n",
      "https://www.ufc.com/athlete/rinat-fakhretdinov\n",
      "Scraping Maiquel Falcao...\n",
      "https://www.ufc.com/athlete/maiquel-falcao\n",
      "Scraping Pedro Falcao...\n",
      "https://www.ufc.com/athlete/pedro-falcao\n",
      "Scraping Brodie Farber...\n",
      "https://www.ufc.com/athlete/brodie-farber\n",
      "Scraping Kalindra Faria...\n",
      "https://www.ufc.com/athlete/kalindra-faria\n",
      "Scraping Jair Farias...\n",
      "https://www.ufc.com/athlete/jair-farias\n",
      "Scraping Rico Farrington...\n",
      "https://www.ufc.com/athlete/rico-farrington\n",
      "Scraping Kelly Faszholz...\n",
      "https://www.ufc.com/athlete/kelly-faszholz\n",
      "Scraping Paul Felder...\n",
      "https://www.ufc.com/athlete/paul-felder\n",
      "Scraping Carlos Felipe...\n",
      "https://www.ufc.com/athlete/carlos-felipe\n",
      "Scraping Josh Ferguson...\n",
      "https://www.ufc.com/athlete/josh-ferguson\n",
      "Scraping Tony Ferguson...\n",
      "https://www.ufc.com/athlete/tony-ferguson\n",
      "Scraping CJ Fernandes...\n",
      "https://www.ufc.com/athlete/cj-fernandes\n",
      "Scraping Kau Fernandes...\n",
      "https://www.ufc.com/athlete/kaue-fernandes\n",
      "Scraping Gabriella Fernandes...\n",
      "https://www.ufc.com/athlete/gabriella-fernandes\n",
      "Scraping Lucas Fernando...\n",
      "https://www.ufc.com/athlete/lucas-fernando\n",
      "Scraping Alexandre Ferreira...\n",
      "https://www.ufc.com/athlete/alexandre-ferreira\n",
      "Scraping Diego Ferreira...\n",
      "https://www.ufc.com/athlete/diego-ferreira\n",
      "Scraping Cezar Ferreira...\n",
      "https://www.ufc.com/athlete/cezar-ferreira\n",
      "Scraping Brunno Ferreira...\n",
      "https://www.ufc.com/athlete/brunno-ferreira\n",
      "Scraping Erisson Ferreira...\n",
      "https://www.ufc.com/athlete/erisson-ferreira-da-silva\n",
      "Scraping Scott Ferrozzo...\n",
      "https://www.ufc.com/athlete/scott-ferrozzo\n",
      "Scraping Timo Feucht...\n",
      "https://www.ufc.com/athlete/timo-feucht\n",
      "Scraping Andre Fialho...\n",
      "https://www.ufc.com/athlete/andre-fialho\n",
      "Scraping Drew Fickett...\n",
      "https://www.ufc.com/athlete/drew-fickett\n",
      "Scraping Scott Fielder...\n",
      "https://www.ufc.com/athlete/skott-ferrozzo-0\n",
      "Scraping Test Fighter2...\n",
      "https://www.ufc.com/athlete/test-fighter2\n",
      "Scraping Michal Figlak...\n",
      "https://www.ufc.com/athlete/michal-figlak\n",
      "Scraping Francisco Figueiredo...\n",
      "https://www.ufc.com/athlete/francisco-figueiredo\n",
      "Scraping Deiveson Figueiredo...\n",
      "https://www.ufc.com/athlete/deiveson-figueiredo\n",
      "Scraping Edwin Figueroa...\n",
      "https://www.ufc.com/athlete/edwin-figueroa\n",
      "Scraping Jafel Filho...\n",
      "https://www.ufc.com/athlete/jafel-filho\n",
      "Scraping Andre Fili...\n",
      "https://www.ufc.com/athlete/andre-fili\n",
      "Scraping Luigi Fioravanti...\n",
      "https://www.ufc.com/athlete/luigi-fioravanti\n",
      "Scraping Nick Fiore...\n",
      "https://www.ufc.com/athlete/nick-fiore\n",
      "Scraping Manon Fiorot...\n",
      "https://www.ufc.com/athlete/manon-fiorot\n",
      "Scraping Spencer Fisher...\n",
      "https://www.ufc.com/athlete/spencer-fisher\n",
      "Scraping Chris Fishgold...\n",
      "https://www.ufc.com/athlete/chris-fishgold\n",
      "Scraping Jon Fitch...\n",
      "https://www.ufc.com/athlete/jon-fitch\n",
      "Scraping Isi Fitikefu...\n",
      "https://www.ufc.com/athlete/isi-fitikefu\n",
      "Scraping Rafael Fiziev...\n",
      "https://www.ufc.com/athlete/rafael-fiziev\n",
      "Scraping Nathan Fletcher...\n",
      "https://www.ufc.com/athlete/nathan-fletcher\n",
      "Scraping Colin Fletcher...\n",
      "https://www.ufc.com/athlete/colin-fletcher\n",
      "Scraping AJ Fletcher...\n",
      "https://www.ufc.com/athlete/aj-fletcher\n",
      "Scraping Jimmy Flick...\n",
      "https://www.ufc.com/athlete/jimmy-flick\n",
      "Scraping Luke Flores...\n",
      "https://www.ufc.com/athlete/luke-flores\n",
      "Scraping Alejandro Flores...\n",
      "https://www.ufc.com/athlete/alejandro-flores\n",
      "Scraping Ty Flores...\n",
      "https://www.ufc.com/athlete/ty-flores\n",
      "Scraping Kenny Florian...\n",
      "https://www.ufc.com/athlete/kenny-florian\n",
      "Scraping Darrius Flowers...\n",
      "https://www.ufc.com/athlete/darrius-flowers\n",
      "Scraping Caros Fodor...\n",
      "https://www.ufc.com/athlete/caros-fodor\n",
      "Scraping Rob Font...\n",
      "https://www.ufc.com/athlete/rob-font\n",
      "Scraping Jesse Forbes...\n",
      "https://www.ufc.com/athlete/jesse-forbes\n",
      "Scraping Jussier Formiga...\n",
      "https://www.ufc.com/athlete/jussier-formiga\n",
      "Scraping Brianna Fortino...\n",
      "https://www.ufc.com/athlete/brianna-van-buren\n",
      "Scraping Marcel Fortuna...\n",
      "https://www.ufc.com/athlete/marcel-fortuna\n",
      "Scraping Brian Foster...\n",
      "https://www.ufc.com/athlete/brian-foster\n",
      "Scraping Xavier Foupa-Pokam...\n",
      "https://www.ufc.com/athlete/xavier-foupa-pokam\n",
      "Scraping Glaico Franca...\n",
      "https://www.ufc.com/athlete/glaico-franca\n",
      "Scraping Hermes Franca...\n",
      "https://www.ufc.com/athlete/hermes-franca\n",
      "Scraping Kai Kara-France...\n",
      "https://www.ufc.com/athlete/kai-kara-france\n",
      "Scraping Rich Franklin...\n",
      "https://www.ufc.com/athlete/rich-franklin\n",
      "Scraping Stephanie Frausto...\n",
      "https://www.ufc.com/athlete/stephanie-frausto\n",
      "Scraping Justin Frazier...\n",
      "https://www.ufc.com/athlete/justin-frazier\n",
      "Scraping Zane Frazier...\n",
      "https://www.ufc.com/athlete/zane-frazier\n",
      "Scraping Ian Freeman...\n",
      "https://www.ufc.com/athlete/ian-freeman\n",
      "Scraping Willamy Freire...\n",
      "https://www.ufc.com/athlete/willamy-freire\n",
      "Scraping Donavon Frelow...\n",
      "https://www.ufc.com/athlete/donavon-frelow\n",
      "Scraping Josh Fremd...\n",
      "https://www.ufc.com/athlete/josh-fremd\n",
      "Scraping Matt Frevola...\n",
      "https://www.ufc.com/athlete/matt-frevola\n",
      "Scraping Jinh Yu Frey...\n",
      "https://www.ufc.com/athlete/jinh-yu-frey\n",
      "Scraping Artem Frolov...\n",
      "https://www.ufc.com/athlete/artem-frolov\n",
      "Scraping Sarah Frota...\n",
      "https://www.ufc.com/athlete/sarah-frota\n",
      "Scraping Daniel Frunza...\n",
      "https://www.ufc.com/athlete/daniel-frunza\n",
      "Scraping Don Frye...\n",
      "https://www.ufc.com/athlete/don-frye\n",
      "Scraping Anthony Fryklund...\n",
      "https://www.ufc.com/athlete/anthony-fryklund\n",
      "Scraping Adam Fugitt...\n",
      "https://www.ufc.com/athlete/adam-fugitt\n",
      "Scraping Katsuhisa Fuji...\n",
      "https://www.ufc.com/athlete/katsuhisa-fuji\n",
      "Scraping Riki Fukuda...\n",
      "https://www.ufc.com/athlete/riki-fukuda\n",
      "Scraping Masio Fullen...\n",
      "https://www.ufc.com/athlete/masio-fullen\n",
      "Scraping Sam Fulton...\n",
      "https://www.ufc.com/athlete/sam-fulton\n",
      "Scraping Travis Fulton...\n",
      "https://www.ufc.com/athlete/travis-fulton\n",
      "Scraping Ricardo Funch...\n",
      "https://www.ufc.com/athlete/ricardo-funch\n",
      "Scraping Gustavo Gabriel...\n",
      "https://www.ufc.com/athlete/gustavo-gabriel\n",
      "Scraping Claudia Gadelha...\n",
      "https://www.ufc.com/athlete/claudia-gadelha\n",
      "Scraping Magomed Gadzhiyasulov...\n",
      "https://www.ufc.com/athlete/magomed-gadzhiyasulov\n",
      "Scraping Justin Gaethje...\n",
      "https://www.ufc.com/athlete/justin-gaethje\n",
      "Scraping Sheila Gaff...\n",
      "https://www.ufc.com/athlete/sheila-gaff\n",
      "Scraping Muin Gafurov...\n",
      "https://www.ufc.com/athlete/muin-gafurov\n",
      "Scraping Mitch Gagnon...\n",
      "https://www.ufc.com/athlete/mitch-gagnon\n",
      "Scraping Dave Galera...\n",
      "https://www.ufc.com/athlete/david-zavada\n",
      "Scraping Mickey Gall...\n",
      "https://www.ufc.com/athlete/mickey-gall\n",
      "Scraping Daniel Gallemore...\n",
      "https://www.ufc.com/athlete/daniel-gallemore\n",
      "Scraping Tom Gallicchio...\n",
      "https://www.ufc.com/athlete/tom-gallicchio\n",
      "Scraping Joey Gambino...\n",
      "https://www.ufc.com/athlete/joey-gambino\n",
      "Scraping Manny Gamburyan...\n",
      "https://www.ufc.com/athlete/manny-gamburyan\n",
      "Scraping Mateusz Gamrot...\n",
      "https://www.ufc.com/athlete/mateusz-gamrot\n",
      "Scraping Shamil Gamzatov...\n",
      "https://www.ufc.com/athlete/shamil-gamzatov\n",
      "Scraping Ariel Gandulla...\n",
      "https://www.ufc.com/athlete/ariel-gandulla\n",
      "Scraping Ciryl Gane...\n",
      "https://www.ufc.com/athlete/ciryl-gane\n",
      "Scraping Sean Gannon...\n",
      "https://www.ufc.com/athlete/sean-gannon\n",
      "Scraping Junye Gao...\n",
      "https://www.ufc.com/athlete/junye-gao\n",
      "Scraping Luiz Garagorri...\n",
      "https://www.ufc.com/athlete/luiz-garagorri\n",
      "Scraping Cody Garbrandt...\n",
      "https://www.ufc.com/athlete/cody-garbrandt\n",
      "Scraping Alex Garcia...\n",
      "https://www.ufc.com/athlete/alex-garcia\n",
      "Scraping Leonard Garcia...\n",
      "https://www.ufc.com/athlete/leonard-garcia\n",
      "Scraping Elias Garcia...\n",
      "https://www.ufc.com/athlete/elias-garcia\n",
      "Scraping Edgar Garcia...\n",
      "https://www.ufc.com/athlete/edgar-garcia\n",
      "Scraping Harrison Garcia...\n",
      "https://www.ufc.com/athlete/harrison-garcia\n",
      "Scraping Fernie Garcia...\n",
      "https://www.ufc.com/athlete/fernie-garcia\n",
      "Scraping Steve Garcia...\n",
      "https://www.ufc.com/athlete/steve-garcia\n",
      "Scraping Rafa Garcia...\n",
      "https://www.ufc.com/athlete/rafa-garcia\n",
      "Scraping Pablo Garza...\n",
      "https://www.ufc.com/athlete/pablo-garza\n",
      "Scraping Azamat Gashimov...\n",
      "https://www.ufc.com/athlete/azamat-gashimov\n",
      "Scraping Brian Gassaway...\n",
      "https://www.ufc.com/athlete/brian-gassaway\n",
      "Scraping Kelvin Gastelum...\n",
      "https://www.ufc.com/athlete/kelvin-gastelum\n",
      "Scraping Willie Gates...\n",
      "https://www.ufc.com/athlete/willie-gates\n",
      "Scraping Melissa Gatto...\n",
      "https://www.ufc.com/athlete/melissa-gatto\n",
      "Scraping Louis Gaudinot...\n",
      "https://www.ufc.com/athlete/louis-gaudinot\n",
      "Scraping Manuel Gaxhja...\n",
      "https://www.ufc.com/athlete/manuel-gaxhja\n",
      "Scraping Shamil Gaziev...\n",
      "https://www.ufc.com/athlete/shamil-gaziev\n",
      "Scraping Paul Georgieff...\n",
      "https://www.ufc.com/athlete/paul-georgieff\n",
      "Scraping Brian Geraghty...\n",
      "https://www.ufc.com/athlete/brian-geraghty\n",
      "Scraping Karine Gevorgyan...\n",
      "https://www.ufc.com/athlete/karine-gevorgyan\n",
      "Scraping Yanis Ghemmouri...\n",
      "https://www.ufc.com/athlete/yanis-ghemmouri\n",
      "Scraping Darrel Gholar...\n",
      "https://www.ufc.com/athlete/brayen-gesevey-2\n",
      "Scraping Tiki Ghosn...\n",
      "https://www.ufc.com/athlete/tiki-ghosn\n",
      "Scraping Christos Giagos...\n",
      "https://www.ufc.com/athlete/christos-giagos\n",
      "Scraping Joe Giannetti...\n",
      "https://www.ufc.com/athlete/joe-giannetti\n",
      "Scraping James Giboo...\n",
      "https://www.ufc.com/athlete/james-giboo\n",
      "Scraping Cody Gibson...\n",
      "https://www.ufc.com/athlete/cody-gibson\n",
      "Scraping Chase Gibson...\n",
      "https://www.ufc.com/athlete/chase-gibson\n",
      "Scraping Thomas Gifford...\n",
      "https://www.ufc.com/athlete/thomas-gifford\n",
      "Scraping Joe Gigliotti...\n",
      "https://www.ufc.com/athlete/joe-gigliotti\n",
      "Scraping Joey Gilbert...\n",
      "https://www.ufc.com/athlete/joey-gilbert\n",
      "Scraping Trevin Giles...\n",
      "https://www.ufc.com/athlete/trevin-giles\n",
      "Scraping Gregor Gillespie...\n",
      "https://www.ufc.com/athlete/gregor-gillespie\n",
      "Scraping Jason Gilliam...\n",
      "https://www.ufc.com/athlete/jason-gilliam\n",
      "Scraping Micheal Gillmore...\n",
      "https://www.ufc.com/athlete/micheal-gillmore\n",
      "Scraping Alex Gilpin...\n",
      "https://www.ufc.com/athlete/alex-gilpin\n",
      "Scraping Bob Gilstrap...\n",
      "https://www.ufc.com/athlete/stiv-garsiya-0\n",
      "Scraping Eperaim Ginting...\n",
      "https://www.ufc.com/athlete/eperaim-ginting\n",
      "Scraping He-Man Gipson...\n",
      "https://www.ufc.com/athlete/dzheyson-gilliam-0\n",
      "Scraping Ricky Glenn...\n",
      "https://www.ufc.com/athlete/ricky-glenn\n",
      "Scraping Mark Godbeer...\n",
      "https://www.ufc.com/athlete/mark-godbeer\n",
      "Scraping Loopy Godinez...\n",
      "https://www.ufc.com/athlete/loopy-godinez\n",
      "Scraping Allan Goes...\n",
      "https://www.ufc.com/athlete/allan-goes\n",
      "Scraping Billy Ray Goff...\n",
      "https://www.ufc.com/athlete/billy-goff\n",
      "Scraping Amiran Gogoladze...\n",
      "https://www.ufc.com/athlete/amiran-gogoladze\n",
      "Scraping Hannah Goldy...\n",
      "https://www.ufc.com/athlete/hannah-goldy\n",
      "Scraping Marcelo Golm...\n",
      "https://www.ufc.com/athlete/marcelo-golm\n",
      "Scraping Denise Gomes...\n",
      "https://www.ufc.com/athlete/denise-gomes\n",
      "Scraping Luis Gomez...\n",
      "https://www.ufc.com/athlete/luis-gomez\n",
      "Scraping Joey Gomez...\n",
      "https://www.ufc.com/athlete/joey-gomez\n",
      "Scraping Ulysses Gomez...\n",
      "https://www.ufc.com/athlete/tayson-pedro-0\n",
      "Scraping Joey Gomez...\n",
      "https://www.ufc.com/athlete/joey-gomez-0\n",
      "Scraping Edson Gomez...\n",
      "https://www.ufc.com/athlete/edson-gomez\n",
      "Scraping Takanori Gomi...\n",
      "https://www.ufc.com/athlete/takanori-gomi\n",
      "Scraping William Gomis...\n",
      "https://www.ufc.com/athlete/william-gomis\n",
      "Scraping Akihiro Gono...\n",
      "https://www.ufc.com/athlete/akihiro-gono\n",
      "Scraping Gabriel Gonzaga...\n",
      "https://www.ufc.com/athlete/gabriel-gonzaga\n",
      "Scraping Justin Gonzales...\n",
      "https://www.ufc.com/athlete/justin-gonzales\n",
      "Scraping Pearl Gonzalez...\n",
      "https://www.ufc.com/athlete/pearl-gonzalez\n",
      "Scraping Jason Gonzalez...\n",
      "https://www.ufc.com/athlete/jason-gonzalez\n",
      "Scraping Lewis Gonzalez...\n",
      "https://www.ufc.com/athlete/lewis-gonzalez\n",
      "Scraping Mikey Gonzalez...\n",
      "https://www.ufc.com/athlete/mikey-gonzalez\n",
      "Scraping Jennifer Gonzalez...\n",
      "https://www.ufc.com/athlete/jennifer-gonzalez\n",
      "Scraping Erick Gonzalez...\n",
      "https://www.ufc.com/athlete/erick-gonzalez\n",
      "Scraping Jorge Gonzalez...\n",
      "https://www.ufc.com/athlete/jorge-gonzalez\n",
      "Scraping Lyman Good...\n",
      "https://www.ufc.com/athlete/lyman-good\n",
      "Scraping Jared Gooden...\n",
      "https://www.ufc.com/athlete/jared-gooden\n",
      "Scraping Gary Goodridge...\n",
      "https://www.ufc.com/athlete/gary-goodridge\n",
      "Scraping Gerard Gordeau...\n",
      "https://www.ufc.com/athlete/gerard-gordeau\n",
      "Scraping Tebaris Gordon...\n",
      "https://www.ufc.com/athlete/tebaris-gordon\n",
      "Scraping Eddie Gordon...\n",
      "https://www.ufc.com/athlete/eddie-gordon\n",
      "Scraping Jared Gordon...\n",
      "https://www.ufc.com/athlete/jared-gordon\n",
      "Scraping Malcolm Gordon...\n",
      "https://www.ufc.com/athlete/malcolm-gordon\n",
      "Scraping Tresean Gore...\n",
      "https://www.ufc.com/athlete/tresean-gore\n",
      "Scraping Alex Gorgees...\n",
      "https://www.ufc.com/athlete/alex-gorgees\n",
      "Scraping Themba Gorimbo...\n",
      "https://www.ufc.com/athlete/themba-gorimbo\n",
      "Scraping Tim Gorman...\n",
      "https://www.ufc.com/athlete/tim-gorman\n",
      "Scraping Chase Gormley...\n",
      "https://www.ufc.com/athlete/chase-gormley\n",
      "Scraping Jonathan Goulet...\n",
      "https://www.ufc.com/athlete/jonathan-goulet\n",
      "Scraping Thibault Gouti...\n",
      "https://www.ufc.com/athlete/thibault-gouti\n",
      "Scraping Wilson Gouveia...\n",
      "https://www.ufc.com/athlete/wilson-gouveia\n",
      "Scraping Damian Grabowski...\n",
      "https://www.ufc.com/athlete/damian-grabowski\n",
      "Scraping Kron Gracie...\n",
      "https://www.ufc.com/athlete/kron-gracie\n",
      "Scraping Rolles Gracie...\n",
      "https://www.ufc.com/athlete/rolles-gracie\n",
      "Scraping Renzo Gracie...\n",
      "https://www.ufc.com/athlete/renzo-gracie\n",
      "Scraping Royce Gracie...\n",
      "https://www.ufc.com/athlete/royce-gracie\n",
      "Scraping Roger Gracie...\n",
      "https://www.ufc.com/athlete/roger-gracie\n",
      "Scraping Bogdan Grad...\n",
      "https://www.ufc.com/athlete/bogdan-grad\n",
      "Scraping Miranda Granger...\n",
      "https://www.ufc.com/athlete/miranda-granger\n",
      "Scraping Dwight Grant...\n",
      "https://www.ufc.com/athlete/dwight-grant\n",
      "Scraping Davey Grant...\n",
      "https://www.ufc.com/athlete/davey-grant\n",
      "Scraping TJ Grant...\n",
      "https://www.ufc.com/athlete/tj-grant\n",
      "Scraping Alexa Grasso...\n",
      "https://www.ufc.com/athlete/alexa-grasso\n",
      "Scraping Tony Gravely...\n",
      "https://www.ufc.com/athlete/tony-gravely\n",
      "Scraping Shelton Graves...\n",
      "https://www.ufc.com/athlete/shelton-graves\n",
      "Scraping Michael Graves...\n",
      "https://www.ufc.com/athlete/michael-graves\n",
      "Scraping Kevin Gray...\n",
      "https://www.ufc.com/athlete/kevin-gray\n",
      "Scraping James Gray...\n",
      "https://www.ufc.com/athlete/james-gray\n",
      "Scraping Desmond Green...\n",
      "https://www.ufc.com/athlete/desmond-green\n",
      "Scraping King Green...\n",
      "https://www.ufc.com/athlete/bobby-green\n",
      "Scraping Gabe Green...\n",
      "https://www.ufc.com/athlete/gabe-green\n",
      "Scraping Maurice Greene...\n",
      "https://www.ufc.com/athlete/maurice-greene\n",
      "Scraping Logan Greenhalgh...\n",
      "https://www.ufc.com/athlete/logan-greenhalgh\n",
      "Scraping Matt Grice...\n",
      "https://www.ufc.com/athlete/matt-grice\n",
      "Scraping Jordan Griffin...\n",
      "https://www.ufc.com/athlete/jordan-griffin\n",
      "Scraping Max Griffin...\n",
      "https://www.ufc.com/athlete/max-griffin\n",
      "Scraping Forrest Griffin...\n",
      "https://www.ufc.com/athlete/forrest-griffin\n",
      "Scraping Tyson Griffin...\n",
      "https://www.ufc.com/athlete/tyson-griffin\n",
      "Scraping Chad Griggs...\n",
      "https://www.ufc.com/athlete/chad-griggs\n",
      "Scraping Charalampos Grigoriou...\n",
      "https://www.ufc.com/athlete/charalampos-grigoriou\n",
      "Scraping Garrett Grimes...\n",
      "https://www.ufc.com/athlete/garrett-grimes\n",
      "Scraping Max Grishin...\n",
      "https://www.ufc.com/athlete/max-grishin\n",
      "Scraping Josh Grispi...\n",
      "https://www.ufc.com/athlete/josh-grispi\n",
      "Scraping Garrett Gross...\n",
      "https://www.ufc.com/athlete/garrett-gross\n",
      "Scraping Neil Grove...\n",
      "https://www.ufc.com/athlete/neil-grove\n",
      "Scraping Kendall Grove...\n",
      "https://www.ufc.com/athlete/kendall-grove\n",
      "Scraping Chris Gruetzemacher...\n",
      "https://www.ufc.com/athlete/kurisu-kuretsutsuemaka\n",
      "Scraping Vik Grujic...\n",
      "https://www.ufc.com/athlete/vik-grujic\n",
      "Scraping Mike Grundy...\n",
      "https://www.ufc.com/athlete/mike-grundy\n",
      "Scraping Wang Guan...\n",
      "https://www.ufc.com/athlete/wang-guan\n",
      "Scraping Ning Guangyou...\n",
      "https://www.ufc.com/athlete/ning-guangyou\n",
      "Scraping Nandor Guelmino...\n",
      "https://www.ufc.com/athlete/nandor-guelmino\n",
      "Scraping Rainn Guerrero...\n",
      "https://www.ufc.com/athlete/rainn-guerrero\n",
      "Scraping Shannon Gugerty...\n",
      "https://www.ufc.com/athlete/shannon-gugerty\n",
      "Scraping Clay Guida...\n",
      "https://www.ufc.com/athlete/clay-guida\n",
      "Scraping Melvin Guillard...\n",
      "https://www.ufc.com/athlete/melvin-guillard\n",
      "Scraping Marcelo Guimaraes...\n",
      "https://www.ufc.com/athlete/marcelo-guimaraes\n",
      "Scraping Brad Gumm...\n",
      "https://www.ufc.com/athlete/shennon-gugerti-0\n",
      "Scraping John Gunderson...\n",
      "https://www.ufc.com/athlete/john-gunderson\n",
      "Scraping John Gunther...\n",
      "https://www.ufc.com/athlete/john-gunther\n",
      "Scraping Jorge Gurgel...\n",
      "https://www.ufc.com/athlete/jorge-gurgel\n",
      "Scraping Fabio Gurgel...\n",
      "https://www.ufc.com/athlete/dzhon-gunderson-1\n",
      "Scraping Bogdan Guskov...\n",
      "https://www.ufc.com/athlete/bogdan-guskov\n",
      "Scraping Gugun Gusman...\n",
      "https://www.ufc.com/athlete/gugun-gusman\n",
      "Scraping Andre Gusmao...\n",
      "https://www.ufc.com/athlete/andre-gusmao\n",
      "Scraping Alexander Gustafsson...\n",
      "https://www.ufc.com/athlete/alexander-gustafsson\n",
      "Scraping Andreas Gustafsson...\n",
      "https://www.ufc.com/athlete/andreas-gustafsson\n",
      "Scraping Chris Gutierrez...\n",
      "https://www.ufc.com/athlete/chris-gutierrez\n",
      "Scraping Horacio Gutierrez...\n",
      "https://www.ufc.com/athlete/horacio-gutierrez\n",
      "Scraping Mando Gutierrez...\n",
      "https://www.ufc.com/athlete/mando-gutierrez\n",
      "Scraping Mike Guymon...\n",
      "https://www.ufc.com/athlete/mike-guymon\n",
      "Scraping Chelsea Hackett...\n",
      "https://www.ufc.com/athlete/chelsea-hackett\n",
      "Scraping Keith Hackney...\n",
      "https://www.ufc.com/athlete/keith-hackney\n",
      "Scraping Cody Haddon...\n",
      "https://www.ufc.com/athlete/cody-haddon\n",
      "Scraping Jake Hadley...\n",
      "https://www.ufc.com/athlete/jake-hadley\n",
      "Scraping Damir Hadzovic...\n",
      "https://www.ufc.com/athlete/tamia-hasohitsuku\n",
      "Scraping Bassil Hafez...\n",
      "https://www.ufc.com/athlete/bassil-hafez\n",
      "Scraping Tim Hague...\n",
      "https://www.ufc.com/athlete/tim-hague\n",
      "Scraping Yazan Hajeh...\n",
      "https://www.ufc.com/athlete/yazan-hajeh\n",
      "Scraping Mark Hall...\n",
      "https://www.ufc.com/athlete/tim-kheyg-0\n",
      "Scraping Ryan Hall...\n",
      "https://www.ufc.com/athlete/ryan-hall\n",
      "Scraping Uriah Hall...\n",
      "https://www.ufc.com/athlete/uriah-hall\n",
      "Scraping Dennis Hallman...\n",
      "https://www.ufc.com/athlete/dennis-hallman\n",
      "Scraping Piotr Hallmann...\n",
      "https://www.ufc.com/athlete/piotr-hallmann\n",
      "Scraping Tony Halme...\n",
      "https://www.ufc.com/athlete/tony-halme\n",
      "Scraping John Halverson...\n",
      "https://www.ufc.com/athlete/john-halverson\n",
      "Scraping Seohee Ham...\n",
      "https://www.ufc.com/athlete/seohee-ham\n",
      "Scraping Frank Hamaker...\n",
      "https://www.ufc.com/athlete/frank-hamaker\n",
      "Scraping Rami Hamed...\n",
      "https://www.ufc.com/athlete/rami-hamed\n",
      "Scraping Matt Hamill...\n",
      "https://www.ufc.com/athlete/matt-hamill\n",
      "Scraping Anthony Hamilton...\n",
      "https://www.ufc.com/athlete/anthony-hamilton\n",
      "Scraping CJ Hamilton...\n",
      "https://www.ufc.com/athlete/cj-hamilton\n",
      "Scraping Jared Hamman...\n",
      "https://www.ufc.com/athlete/jared-hamman\n",
      "Scraping James Hammortree...\n",
      "https://www.ufc.com/athlete/james-hammortree\n",
      "Scraping Chad Hanekom...\n",
      "https://www.ufc.com/athlete/chad-hanekom\n",
      "Scraping Kay Hansen...\n",
      "https://www.ufc.com/athlete/kay-hansen\n",
      "Scraping Nasrat Haqparast...\n",
      "https://www.ufc.com/athlete/nasrat-haqparast\n",
      "Scraping Shin Haraguchi...\n",
      "https://www.ufc.com/athlete/shin-haraguchi\n",
      "Scraping Janay Harding...\n",
      "https://www.ufc.com/athlete/janay-harding\n",
      "Scraping Antoni Hardonk...\n",
      "https://www.ufc.com/athlete/antoni-hardonk\n",
      "Scraping George Hardwick...\n",
      "https://www.ufc.com/athlete/george-hardwick\n",
      "Scraping Dan Hardy...\n",
      "https://www.ufc.com/athlete/dan-hardy\n",
      "Scraping Greg Hardy...\n",
      "https://www.ufc.com/athlete/greg-hardy\n",
      "Scraping Josiah Harrell...\n",
      "https://www.ufc.com/athlete/josiah-harrell\n",
      "Scraping Gerald Harris...\n",
      "https://www.ufc.com/athlete/gerald-harris\n",
      "Scraping Phil Harris...\n",
      "https://www.ufc.com/athlete/phil-harris\n",
      "Scraping Walt Harris...\n",
      "https://www.ufc.com/athlete/walt-harris\n",
      "Scraping Gerry Harris...\n",
      "https://www.ufc.com/athlete/dzheyms-khemmortri-0\n",
      "Scraping Carlston Harris...\n",
      "https://www.ufc.com/athlete/carlston-harris\n",
      "Scraping Kayla Harrison...\n",
      "https://www.ufc.com/athlete/kayla-harrison\n",
      "Scraping Collin Hart...\n",
      "https://www.ufc.com/athlete/collin-hart\n",
      "Scraping Dale Hartt...\n",
      "https://www.ufc.com/athlete/dale-hartt\n",
      "Scraping Clay Harvison...\n",
      "https://www.ufc.com/athlete/clay-harvison\n",
      "Scraping Chris Haseman...\n",
      "https://www.ufc.com/athlete/chris-haseman\n",
      "Scraping Hayder Hassan...\n",
      "https://www.ufc.com/athlete/hayder-hassan\n",
      "Scraping Ahmad Hassanzada...\n",
      "https://www.ufc.com/athlete/ahmad-hassanzada\n",
      "Scraping John Hathaway...\n",
      "https://www.ufc.com/athlete/john-hathaway\n",
      "Scraping Phil Hawes...\n",
      "https://www.ufc.com/athlete/phillip-hawes\n",
      "Scraping Tommy Hayden...\n",
      "https://www.ufc.com/athlete/tommy-hayden\n",
      "Scraping Josh Haynes...\n",
      "https://www.ufc.com/athlete/josh-haynes\n",
      "Scraping Dustin Hazelett...\n",
      "https://www.ufc.com/athlete/dustin-hazelett\n",
      "Scraping James Head...\n",
      "https://www.ufc.com/athlete/james-head\n",
      "Scraping Pat Healy...\n",
      "https://www.ufc.com/athlete/pat-healy\n",
      "Scraping David Heath...\n",
      "https://www.ufc.com/athlete/david-heath\n",
      "Scraping Chris Heatherly...\n",
      "https://www.ufc.com/athlete/chris-heatherly\n",
      "Scraping Jake Hecht...\n",
      "https://www.ufc.com/athlete/jake-hecht\n",
      "Scraping Nick Hein...\n",
      "https://www.ufc.com/athlete/nick-hein\n",
      "Scraping Ian Heinisch...\n",
      "https://www.ufc.com/athlete/ian-heinisch\n",
      "Scraping Marcin Held...\n",
      "https://www.ufc.com/athlete/marcin-held\n",
      "Scraping Delson Heleno...\n",
      "https://www.ufc.com/athlete/delson-heleno\n",
      "Scraping Dan Henderson...\n",
      "https://www.ufc.com/athlete/dan-henderson\n",
      "Scraping Benson Henderson...\n",
      "https://www.ufc.com/athlete/benson-henderson\n",
      "Scraping Josh Hendricks...\n",
      "https://www.ufc.com/athlete/josh-hendricks\n",
      "Scraping Johny Hendricks...\n",
      "https://www.ufc.com/athlete/johny-hendricks\n",
      "Scraping Cory Hendricks...\n",
      "https://www.ufc.com/athlete/cory-hendricks\n",
      "Scraping Luis Henrique...\n",
      "https://www.ufc.com/athlete/luis-henrique\n",
      "Scraping Jos Henrique...\n",
      "https://www.ufc.com/athlete/jose-henrique\n",
      "Scraping Danny Henry...\n",
      "https://www.ufc.com/athlete/danny-henry\n",
      "Scraping Victor Henry...\n",
      "https://www.ufc.com/athlete/victor-henry\n",
      "Scraping Jai Herbert...\n",
      "https://www.ufc.com/athlete/jai-herbert\n",
      "Scraping Dave Herman...\n",
      "https://www.ufc.com/athlete/dave-herman\n",
      "Scraping Ed Herman...\n",
      "https://www.ufc.com/athlete/ed-herman\n",
      "Scraping Jack Hermansson...\n",
      "https://www.ufc.com/athlete/jack-hermansson\n",
      "Scraping Nohelin Hernandez...\n",
      "https://www.ufc.com/athlete/nohelin-hernandez\n",
      "Scraping Noe Hernandez...\n",
      "https://www.ufc.com/athlete/frenk-khamaker-0\n",
      "Scraping Junior Hernandez...\n",
      "https://www.ufc.com/athlete/junior-hernandez\n",
      "Scraping Carlos Hernandez...\n",
      "https://www.ufc.com/athlete/carlos-hernandez\n",
      "Scraping Alexander Hernandez...\n",
      "https://www.ufc.com/athlete/alexander-hernandez\n",
      "Scraping Anthony Hernandez...\n",
      "https://www.ufc.com/athlete/anthony-hernandez\n",
      "Scraping Paul Herrera...\n",
      "https://www.ufc.com/athlete/paul-herrera\n",
      "Scraping Alvaro Herrera...\n",
      "https://www.ufc.com/athlete/alvaro-herrera\n",
      "Scraping Geane Herrera...\n",
      "https://www.ufc.com/athlete/geane-herrera\n",
      "Scraping Felice Herrig...\n",
      "https://www.ufc.com/athlete/felice-herrig\n",
      "Scraping Heath Herring...\n",
      "https://www.ufc.com/athlete/heath-herring\n",
      "Scraping Jon Hess...\n",
      "https://www.ufc.com/athlete/khit-kherring-0\n",
      "Scraping Clint Hester...\n",
      "https://www.ufc.com/athlete/clint-hester\n",
      "Scraping Jimy Hettes...\n",
      "https://www.ufc.com/athlete/jimy-hettes\n",
      "Scraping Jay Hieron...\n",
      "https://www.ufc.com/athlete/jay-hieron\n",
      "Scraping Brady Hiestand...\n",
      "https://www.ufc.com/athlete/brady-hiestand\n",
      "Scraping Jason High...\n",
      "https://www.ufc.com/athlete/jason-high\n",
      "Scraping Richie Hightower...\n",
      "https://www.ufc.com/athlete/richie-hightower\n",
      "Scraping Tyler Hill...\n",
      "https://www.ufc.com/athlete/tyler-hill\n",
      "Scraping Corey Hill...\n",
      "https://www.ufc.com/athlete/corey-hill\n",
      "Scraping Kailan Hill...\n",
      "https://www.ufc.com/athlete/kailan-hill\n",
      "Scraping Jamahal Hill...\n",
      "https://www.ufc.com/athlete/jamahal-hill\n",
      "Scraping Angela Hill...\n",
      "https://www.ufc.com/athlete/angela-hill\n",
      "Scraping Branden Lee Hinkle...\n",
      "https://www.ufc.com/athlete/branden-lee-hinkle\n",
      "Scraping Hatsu Hioki...\n",
      "https://www.ufc.com/athlete/hatsu-hioki\n",
      "Scraping Kuniyoshi Hironaka...\n",
      "https://www.ufc.com/athlete/kuniyoshi-hironaka\n",
      "Scraping Mizuto Hirota...\n",
      "https://www.ufc.com/athlete/guangtian-ruiren\n",
      "Scraping Matt Hobar...\n",
      "https://www.ufc.com/athlete/matt-hobar\n",
      "Scraping Bobby Hoffman...\n",
      "https://www.ufc.com/athlete/bobby-hoffman\n",
      "Scraping Chris Hofmann...\n",
      "https://www.ufc.com/athlete/chris-hofmann\n",
      "Scraping Sam Hoger...\n",
      "https://www.ufc.com/athlete/sam-hoger\n",
      "Scraping Andrew Holbrook...\n",
      "https://www.ufc.com/athlete/andrew-holbrook\n",
      "Scraping Chris Holdsworth...\n",
      "https://www.ufc.com/athlete/chris-holdsworth\n",
      "Scraping Frank Holland...\n",
      "https://www.ufc.com/athlete/frank-holland\n",
      "Scraping Kevin Holland...\n",
      "https://www.ufc.com/athlete/kevin-holland\n",
      "Scraping Roger Hollett...\n",
      "https://www.ufc.com/athlete/roger-hollett\n",
      "Scraping Max Holloway...\n",
      "https://www.ufc.com/athlete/max-holloway\n",
      "Scraping Holly Holm...\n",
      "https://www.ufc.com/athlete/holly-holm\n",
      "Scraping Rex Holman...\n",
      "https://www.ufc.com/athlete/rex-holman\n",
      "Scraping Joseph Holmes...\n",
      "https://www.ufc.com/athlete/joseph-holmes\n",
      "Scraping Kurt Holobaugh...\n",
      "https://www.ufc.com/athlete/kurt-holobaugh\n",
      "Scraping Paddy Holohan...\n",
      "https://www.ufc.com/athlete/paddy-holohan\n",
      "Scraping Mark Holst...\n",
      "https://www.ufc.com/athlete/mark-holst\n",
      "Scraping Scott Holtzman...\n",
      "https://www.ufc.com/athlete/scott-holtzman\n",
      "Scraping Sabah Homasi...\n",
      "https://www.ufc.com/athlete/saha-homashi\n",
      "Scraping Mark Hominick...\n",
      "https://www.ufc.com/athlete/mark-hominick\n",
      "Scraping Barb Honchak...\n",
      "https://www.ufc.com/athlete/barb-honchak\n",
      "Scraping JunYoung Hong...\n",
      "https://www.ufc.com/athlete/junyoung-hong\n",
      "Scraping SeongChan Hong...\n",
      "https://www.ufc.com/athlete/seongchan-hong\n",
      "Scraping Satoshi Honma...\n",
      "https://www.ufc.com/athlete/satoshi-honma\n",
      "Scraping David Hood...\n",
      "https://www.ufc.com/athlete/mark-khominik-1\n",
      "Scraping Lorenzo Hood...\n",
      "https://www.ufc.com/athlete/lorenzo-hood\n",
      "Scraping Dan Hooker...\n",
      "https://www.ufc.com/athlete/dan-hooker\n",
      "Scraping Chase Hooper...\n",
      "https://www.ufc.com/athlete/chase-hooper\n",
      "Scraping Darrell Horcher...\n",
      "https://www.ufc.com/athlete/darrell-horcher\n",
      "Scraping Moti Horenstein...\n",
      "https://www.ufc.com/athlete/mark-khominik-2\n",
      "Scraping Yoshinori Horie...\n",
      "https://www.ufc.com/athlete/yoshinori-horie\n",
      "Scraping Kyoji Horiguchi...\n",
      "https://www.ufc.com/athlete/kyoji-horiguchi\n",
      "Scraping Yuma Horiuchi...\n",
      "https://www.ufc.com/athlete/yuma-horiuchi\n",
      "Scraping Jeremy Horn...\n",
      "https://www.ufc.com/athlete/jeremy-horn\n",
      "Scraping Jamey-Lyn Horth...\n",
      "https://www.ufc.com/athlete/jamey-lyn-horth\n",
      "Scraping Matt Horwich...\n",
      "https://www.ufc.com/athlete/matt-horwich-0\n",
      "Scraping Saeed Hosseini...\n",
      "https://www.ufc.com/athlete/saeed-hosseini\n",
      "Scraping Jeff Hougland...\n",
      "https://www.ufc.com/athlete/jeff-hougland\n",
      "Scraping Brian Houston...\n",
      "https://www.ufc.com/athlete/brian-houston\n",
      "Scraping Harold Howard...\n",
      "https://www.ufc.com/athlete/harold-howard\n",
      "Scraping John Howard...\n",
      "https://www.ufc.com/athlete/john-howard\n",
      "Scraping Shane Howell...\n",
      "https://www.ufc.com/athlete/shane-howell\n",
      "Scraping Carlos Huachin...\n",
      "https://www.ufc.com/athlete/carlos-huachin\n",
      "Scraping Brady Huang...\n",
      "https://www.ufc.com/athlete/brady-huang\n",
      "Scraping Austin Hubbard...\n",
      "https://www.ufc.com/athlete/austin-hubbard\n",
      "Scraping Collin Huckbody...\n",
      "https://www.ufc.com/athlete/collin-huckbody\n",
      "Scraping Roger Huerta...\n",
      "https://www.ufc.com/athlete/roger-huerta\n",
      "Scraping Matt Hughes...\n",
      "https://www.ufc.com/athlete/matt-hughes\n",
      "Scraping Jeff Hughes...\n",
      "https://www.ufc.com/athlete/jeff-hughes\n",
      "Scraping Mark Hughes...\n",
      "https://www.ufc.com/athlete/mark-hughes\n",
      "Scraping Sam Hughes...\n",
      "https://www.ufc.com/athlete/sam-hughes\n",
      "Scraping Victor Hugo...\n",
      "https://www.ufc.com/athlete/victor-hugo\n",
      "Scraping Harry Hunsucker...\n",
      "https://www.ufc.com/athlete/harry-hunsucker\n",
      "Scraping Mark Hunt...\n",
      "https://www.ufc.com/athlete/mark-hunt\n",
      "Scraping Adam Hunter...\n",
      "https://www.ufc.com/athlete/adam-hunter\n",
      "Scraping Alex Hunter...\n",
      "https://www.ufc.com/athlete/alex-hunter\n",
      "Scraping Solomon Hutcherson...\n",
      "https://www.ufc.com/athlete/solomon-hutcherson\n",
      "Scraping Al Iaquinta...\n",
      "https://www.ufc.com/athlete/al-iaquinta\n",
      "Scraping Khadis Ibragimov...\n",
      "https://www.ufc.com/athlete/khadis-ibragimov\n",
      "Scraping Minoki Ichihara...\n",
      "https://www.ufc.com/athlete/minoki-ichihara\n",
      "Scraping Dan Ige...\n",
      "https://www.ufc.com/athlete/dan-ige\n",
      "Scraping Valeri Ignatov...\n",
      "https://www.ufc.com/athlete/saiid-khosseyni-0\n",
      "Scraping Fabiano Iha...\n",
      "https://www.ufc.com/athlete/fabiano-iha\n",
      "Scraping Nassourdine Imavov...\n",
      "https://www.ufc.com/athlete/nassourdine-imavov\n",
      "Scraping Brad Imes...\n",
      "https://www.ufc.com/athlete/brad-imes\n",
      "Scraping Chris Indich...\n",
      "https://www.ufc.com/athlete/chris-indich\n",
      "Scraping Guto Inocente...\n",
      "https://www.ufc.com/athlete/gunnar-nelson-1\n",
      "Scraping Mizuki...\n",
      "https://www.ufc.com/athlete/mizuki\n",
      "Scraping Naoki Inoue...\n",
      "https://www.ufc.com/athlete/naoki-inoue\n",
      "Scraping Enson Inoue...\n",
      "https://www.ufc.com/athlete/enson-inoue\n",
      "Scraping James Irvin...\n",
      "https://www.ufc.com/athlete/james-irvin\n",
      "Scraping Issa Isakov...\n",
      "https://www.ufc.com/athlete/issa-isakov\n",
      "Scraping Teruto Ishihara...\n",
      "https://www.ufc.com/athlete/teruto-ishihara\n",
      "Scraping Damir Ismagulov...\n",
      "https://www.ufc.com/athlete/damir-ismagulov\n",
      "Scraping Wallid Ismail...\n",
      "https://www.ufc.com/athlete/wallid-ismail\n",
      "Scraping Leandro Issa...\n",
      "https://www.ufc.com/athlete/leandro-issa\n",
      "Scraping Alvaro Ivan Lopez Rodrigues...\n",
      "https://www.ufc.com/athlete/alvaro-ivan-lopez-rodrigues\n",
      "Scraping Blagoy Ivanov...\n",
      "https://www.ufc.com/athlete/blagoy-ivanov\n",
      "Scraping Anthony Ivy...\n",
      "https://www.ufc.com/athlete/anthony-ivy\n",
      "Scraping Yoislandy Izquierdo...\n",
      "https://www.ufc.com/athlete/yoislandy-izquierdo\n",
      "Scraping Yves Jabouin...\n",
      "https://www.ufc.com/athlete/yves-jabouin\n",
      "Scraping Eugene Jackson...\n",
      "https://www.ufc.com/athlete/eugene-jackson\n",
      "Scraping Kevin Jackson...\n",
      "https://www.ufc.com/athlete/dzheyms-irvin-1\n",
      "Scraping Rampage Jackson...\n",
      "https://www.ufc.com/athlete/rampage-jackson\n",
      "Scraping Damon Jackson...\n",
      "https://www.ufc.com/athlete/damon-jackson\n",
      "Scraping Mike Jackson...\n",
      "https://www.ufc.com/athlete/mike-jackson\n",
      "Scraping Jason Jackson...\n",
      "https://www.ufc.com/athlete/jason-jackson\n",
      "Scraping Jeremy Jackson...\n",
      "https://www.ufc.com/athlete/jeremy-jackson\n",
      "Scraping Jordan Jackson...\n",
      "https://www.ufc.com/athlete/jordan-jackson\n",
      "Scraping Brian Jackson...\n",
      "https://www.ufc.com/athlete/brian-jackson\n",
      "Scraping Montel Jackson...\n",
      "https://www.ufc.com/athlete/montel-jackson\n",
      "Scraping Richard Jacobi...\n",
      "https://www.ufc.com/athlete/richard-jacobi\n",
      "Scraping Dustin Jacoby...\n",
      "https://www.ufc.com/athlete/dustin-jacoby\n",
      "Scraping Justin James...\n",
      "https://www.ufc.com/athlete/justin-james\n",
      "Scraping Virna Jandiroba...\n",
      "https://www.ufc.com/athlete/virna-jandiroba\n",
      "Scraping Ryan Janes...\n",
      "https://www.ufc.com/athlete/ryan-janes\n",
      "Scraping Keith Jardine...\n",
      "https://www.ufc.com/athlete/keith-jardine\n",
      "Scraping Brock Jardine...\n",
      "https://www.ufc.com/athlete/brock-jardine\n",
      "Scraping Rony Jason...\n",
      "https://www.ufc.com/athlete/rony-jason\n",
      "Scraping Jasmine Jasudavicius...\n",
      "https://www.ufc.com/athlete/jasmine-jasudavicius\n",
      "Scraping Yazmin Jauregui...\n",
      "https://www.ufc.com/athlete/yazmin-jauregui\n",
      "Scraping Justin Jaynes...\n",
      "https://www.ufc.com/athlete/justin-jaynes\n",
      "Scraping Joanna Jdrzejczyk...\n",
      "https://www.ufc.com/athlete/joanna-jedrzejczyk\n",
      "Scraping Aaron Jeffery...\n",
      "https://www.ufc.com/athlete/aaron-jeffery\n",
      "Scraping Trent Jenkins...\n",
      "https://www.ufc.com/athlete/trent-jenkins\n",
      "Scraping Jack Jenkins...\n",
      "https://www.ufc.com/athlete/jack-jenkins\n",
      "Scraping Brandon Jenkins...\n",
      "https://www.ufc.com/athlete/brandon-jenkins\n",
      "Scraping Steve Jennum...\n",
      "https://www.ufc.com/athlete/steve-jennum\n",
      "Scraping Ryan Jensen...\n",
      "https://www.ufc.com/athlete/ryan-jensen\n",
      "Scraping Kyle Jensen...\n",
      "https://www.ufc.com/athlete/kyle-jensen\n",
      "Scraping Chanmi Jeon...\n",
      "https://www.ufc.com/athlete/chanmi-jeon\n",
      "Scraping Ronald Jhun...\n",
      "https://www.ufc.com/athlete/ronald-jhun\n",
      "Scraping Niushiyue Ji...\n",
      "https://www.ufc.com/athlete/niushiyue-ji\n",
      "Scraping Wuziazibieke Jiahefu...\n",
      "https://www.ufc.com/athlete/wuziazibieke-jiahefu\n",
      "Scraping Baergeng Jieleyisi...\n",
      "https://www.ufc.com/athlete/baergeng-jieleyisi\n",
      "Scraping Art Jimmerson...\n",
      "https://www.ufc.com/athlete/art-jimmerson\n",
      "Scraping Ryan Jimmo...\n",
      "https://www.ufc.com/athlete/ryan-jimmo\n",
      "Scraping Asikeerbai Jinensibieke...\n",
      "https://www.ufc.com/athlete/asikeerbai-jinensibieke\n",
      "Scraping Asikerbai Jinensibieke...\n",
      "https://www.ufc.com/athlete/asikerbai-jinensibieke\n",
      "Scraping Li Jingliang...\n",
      "https://www.ufc.com/athlete/li-jingliang\n",
      "Scraping Sung Bin Jo...\n",
      "https://www.ufc.com/athlete/sung-bin-jo\n",
      "Scraping Miles Johns...\n",
      "https://www.ufc.com/athlete/miles-johns\n",
      "Scraping Phil Johns...\n",
      "https://www.ufc.com/athlete/phil-johns\n",
      "Scraping Brett Johns...\n",
      "https://www.ufc.com/athlete/brett-johns\n",
      "Scraping Demetrious Johnson...\n",
      "https://www.ufc.com/athlete/temetoriasu-shiyonson\n",
      "Scraping Lavar Johnson...\n",
      "https://www.ufc.com/athlete/loren-myorfi-0\n",
      "Scraping Michael Johnson...\n",
      "https://www.ufc.com/athlete/michael-johnson\n",
      "Scraping Anthony Johnson...\n",
      "https://www.ufc.com/athlete/anthony-johnson\n",
      "Scraping Timothy Johnson...\n",
      "https://www.ufc.com/athlete/timothy-johnson\n",
      "Scraping Dashon Johnson...\n",
      "https://www.ufc.com/athlete/dashon-johnson\n",
      "Scraping Kajan Johnson...\n",
      "https://www.ufc.com/athlete/kajan-johnson\n",
      "Scraping Jordan Johnson...\n",
      "https://www.ufc.com/athlete/jordan-johnson\n",
      "Scraping DaMarques Johnson...\n",
      "https://www.ufc.com/athlete/damarques-johnson\n",
      "Scraping Jose Johnson...\n",
      "https://www.ufc.com/athlete/jose-johnson\n",
      "Scraping Tony Johnson...\n",
      "https://www.ufc.com/athlete/tony-johnson\n",
      "Scraping Chad Johnson...\n",
      "https://www.ufc.com/athlete/chad-johnson\n",
      "Scraping Taylor Johnson...\n",
      "https://www.ufc.com/athlete/taylor-johnson\n",
      "Scraping Charles Johnson...\n",
      "https://www.ufc.com/athlete/charles-johnson\n",
      "Scraping Brian Johnston...\n",
      "https://www.ufc.com/athlete/damarkes-dzhonson-0\n",
      "Scraping Liana Jojua...\n",
      "https://www.ufc.com/athlete/liana-jojua\n",
      "Scraping Daniel Jolly...\n",
      "https://www.ufc.com/athlete/daniel-jolly\n",
      "Scraping Jon Jones...\n",
      "https://www.ufc.com/athlete/jon-jones\n",
      "Scraping Marcus Jones...\n",
      "https://www.ufc.com/athlete/marcus-jones\n",
      "Scraping Justin Jones...\n",
      "https://www.ufc.com/athlete/justin-jones\n",
      "Scraping Jamelle Jones...\n",
      "https://www.ufc.com/athlete/jamelle-jones\n",
      "Scraping Antonio Jones...\n",
      "https://www.ufc.com/athlete/antonio-jones\n",
      "Scraping Paul Jones...\n",
      "https://www.ufc.com/athlete/saiid-khosseyni-1\n",
      "Scraping Mason Jones...\n",
      "https://www.ufc.com/athlete/mason-jones\n",
      "Scraping Trevin Jones...\n",
      "https://www.ufc.com/athlete/trevin-jones\n",
      "Scraping Jocelyn Jones-Lybarger...\n",
      "https://www.ufc.com/athlete/jocelyn-jones-lybarger\n",
      "Scraping Kevin Jordan...\n",
      "https://www.ufc.com/athlete/kevin-jordan\n",
      "Scraping Shawn Jordan...\n",
      "https://www.ufc.com/athlete/shawn-jordan\n",
      "Scraping Ivan Jorge...\n",
      "https://www.ufc.com/athlete/ivan-jorge\n",
      "Scraping Scott Jorgensen...\n",
      "https://www.ufc.com/athlete/scott-jorgensen\n",
      "Scraping Dwight Joseph...\n",
      "https://www.ufc.com/athlete/dwight-joseph\n",
      "Scraping Jeff Joslin...\n",
      "https://www.ufc.com/athlete/jeff-joslin\n",
      "Scraping Krzysztof Jotko...\n",
      "https://www.ufc.com/athlete/krzysztof-jotko\n",
      "Scraping Alan Jouban...\n",
      "https://www.ufc.com/athlete/alan-jouban\n",
      "Scraping Charles Jourdain...\n",
      "https://www.ufc.com/athlete/charles-jourdain\n",
      "Scraping Kevin Jousset...\n",
      "https://www.ufc.com/athlete/kevin-jousset\n",
      "Scraping Dustin Joynson...\n",
      "https://www.ufc.com/athlete/dustin-joynson\n",
      "Scraping Silvana Gomez Juarez...\n",
      "https://www.ufc.com/athlete/silvana-juarez\n",
      "Scraping Anshul Jubli...\n",
      "https://www.ufc.com/athlete/anshul-jubli\n",
      "Scraping Carli Judice...\n",
      "https://www.ufc.com/athlete/carli-judice\n",
      "Scraping Steve Judson...\n",
      "https://www.ufc.com/athlete/saiid-khosseyni-2\n",
      "Scraping Luke Jumeau...\n",
      "https://www.ufc.com/athlete/luke-jumeau\n",
      "Scraping Chan Sung Jung...\n",
      "https://www.ufc.com/athlete/chan-sung-jung\n",
      "Scraping Da Woon Jung...\n",
      "https://www.ufc.com/athlete/da-woon-jung\n",
      "Scraping Scott Junk...\n",
      "https://www.ufc.com/athlete/scott-junk\n",
      "Scraping Myles Jury...\n",
      "https://www.ufc.com/athlete/myles-jury\n",
      "Scraping Geza Kahlman Jr...\n",
      "https://www.ufc.com/athlete/saiid-khosseyni-3\n",
      "Scraping Oron Kahlon...\n",
      "https://www.ufc.com/athlete/oron-kahlon\n",
      "Scraping Lu Kai...\n",
      "https://www.ufc.com/athlete/lu-kai\n",
      "Scraping Sim Kai Xiong...\n",
      "https://www.ufc.com/athlete/sim-kai-xiong\n",
      "Scraping Li Kaiwen...\n",
      "https://www.ufc.com/athlete/li-kaiwen\n",
      "Scraping Sirwan Kakai...\n",
      "https://www.ufc.com/athlete/sirwan-kakai\n",
      "Scraping Saidyokub Kakhramonov...\n",
      "https://www.ufc.com/athlete/saidyokub-kakhramonov\n",
      "Scraping Kai Kamaka...\n",
      "https://www.ufc.com/athlete/kai-kamaka\n",
      "Scraping Shuya Kamikubo...\n",
      "https://www.ufc.com/athlete/shuya-kamikubo\n",
      "Scraping Martin Kampmann...\n",
      "https://www.ufc.com/athlete/martin-kampmann\n",
      "Scraping Koya Kanda...\n",
      "https://www.ufc.com/athlete/koya-kanda\n",
      "Scraping Bharat Kandare...\n",
      "https://www.ufc.com/athlete/bharat-kandare\n",
      "Scraping Masanori Kanehara...\n",
      "https://www.ufc.com/athlete/masanori-kanehara\n",
      "Scraping Denis Kang...\n",
      "https://www.ufc.com/athlete/denis-kang\n",
      "Scraping Kyung Ho Kang...\n",
      "https://www.ufc.com/athlete/kyung-ho-kang\n",
      "Scraping Manel Kape...\n",
      "https://www.ufc.com/athlete/manel-kape\n",
      "Scraping Dave Kaplan...\n",
      "https://www.ufc.com/athlete/dave-kaplan\n",
      "Scraping Alex Karalexis...\n",
      "https://www.ufc.com/athlete/alex-karalexis\n",
      "Scraping Ernesta Kareckait...\n",
      "https://www.ufc.com/athlete/ernesta-kareckaite\n",
      "Scraping Impa Kasanganay...\n",
      "https://www.ufc.com/athlete/impa-kasanganay\n",
      "Scraping Jinnosuke Kashimura...\n",
      "https://www.ufc.com/athlete/jinnosuke-kashimura\n",
      "Scraping Kerry Kasik...\n",
      "https://www.ufc.com/athlete/kerry-kasik\n",
      "Scraping Nadia Kassem...\n",
      "https://www.ufc.com/athlete/nadia-kassem\n",
      "Scraping Yusuke Kasuya...\n",
      "https://www.ufc.com/athlete/yusuke-kasuya\n",
      "Scraping Brad Katona...\n",
      "https://www.ufc.com/athlete/brad-katona\n",
      "Scraping Calvin Kattar...\n",
      "https://www.ufc.com/athlete/calvin-kattar\n",
      "Scraping Sarah Kaufman...\n",
      "https://www.ufc.com/athlete/sarah-kaufman\n",
      "Scraping Loneer Kavanagh...\n",
      "https://www.ufc.com/athlete/loneer-kavanagh\n",
      "Scraping Canaan Kawaihae...\n",
      "https://www.ufc.com/athlete/canaan-kawaihae\n",
      "Scraping Tatsuya Kawajiri...\n",
      "https://www.ufc.com/athlete/tatsuya-kawajiri\n",
      "Scraping Toshiomi Kazama...\n",
      "https://www.ufc.com/athlete/toshiomi-kazama\n",
      "Scraping Julie Kedzie...\n",
      "https://www.ufc.com/athlete/julie-kedzie\n",
      "Scraping C.J. Keith...\n",
      "https://www.ufc.com/athlete/cj-keith\n",
      "Scraping Chris Kelades...\n",
      "https://www.ufc.com/athlete/chris-kelades\n",
      "Scraping Brian Kelleher...\n",
      "https://www.ufc.com/athlete/brian-kelleher\n",
      "Scraping Mayana Kellem...\n",
      "https://www.ufc.com/athlete/mayana-kellem\n",
      "Scraping Tony Kelley...\n",
      "https://www.ufc.com/athlete/tony-kelley\n",
      "Scraping Paul Kelly...\n",
      "https://www.ufc.com/athlete/paul-kelly\n",
      "Scraping Daniel Kelly...\n",
      "https://www.ufc.com/athlete/daniel-kelly\n",
      "Scraping Song Kenan...\n",
      "https://www.ufc.com/athlete/song-kenan\n",
      "Scraping Tim Kennedy...\n",
      "https://www.ufc.com/athlete/tim-kennedy\n",
      "Scraping Jeremy Kennedy...\n",
      "https://www.ufc.com/athlete/jeremy-kennedy\n",
      "Scraping Steven Kennedy...\n",
      "https://www.ufc.com/athlete/steven-kennedy\n",
      "Scraping Casey Kenney...\n",
      "https://www.ufc.com/athlete/casey-kenney\n",
      "Scraping Casey Kenney...\n",
      "https://www.ufc.com/athlete/casey-kenney-0\n",
      "Scraping Maimaitituoheti Keremuaili...\n",
      "https://www.ufc.com/athlete/maimaitituoheti-keremuaili\n",
      "Scraping Mark Kerr...\n",
      "https://www.ufc.com/athlete/mark-kerr\n",
      "Scraping Rustam Khabilov...\n",
      "https://www.ufc.com/athlete/rustam-khabilov\n",
      "Scraping Adam Khaliev...\n",
      "https://www.ufc.com/athlete/adam-khaliev\n",
      "Scraping Sergey Khandozhko...\n",
      "https://www.ufc.com/athlete/sergey-khandozhko\n",
      "Scraping Alfred Khashakyan...\n",
      "https://www.ufc.com/athlete/alfred-khashakyan\n",
      "Scraping Aliaskhab Khizriev...\n",
      "https://www.ufc.com/athlete/aliaskhab-khizriev\n",
      "Scraping WonBin Ki...\n",
      "https://www.ufc.com/athlete/wonbin-ki\n",
      "Scraping Pannie Kianzad...\n",
      "https://www.ufc.com/athlete/pannie-kianzad\n",
      "Scraping Katsunori Kikuno...\n",
      "https://www.ufc.com/athlete/katsunori-kikuno\n",
      "Scraping Sinae Kikuta...\n",
      "https://www.ufc.com/athlete/sinae-kikuta\n",
      "Scraping Jacob Kilburn...\n",
      "https://www.ufc.com/athlete/jacob-kilburn\n",
      "Scraping Ji Yeon Kim...\n",
      "https://www.ufc.com/athlete/ji-yeon-kim\n",
      "Scraping HanSeul Kim...\n",
      "https://www.ufc.com/athlete/hanseul-kim\n",
      "Scraping MinWoo Kim...\n",
      "https://www.ufc.com/athlete/minwoo-kim\n",
      "Scraping Sang Won Kim...\n",
      "https://www.ufc.com/athlete/sang-won-kim\n",
      "Scraping KyeongPyo Kim...\n",
      "https://www.ufc.com/athlete/kyeongpyo-kim\n",
      "Scraping Sangwook Kim...\n",
      "https://www.ufc.com/athlete/sangwook-kim\n",
      "Scraping Dong Hyun Kim...\n",
      "https://www.ufc.com/athlete/dong-hyun-kim-0\n",
      "Scraping Jeremy Kimball...\n",
      "https://www.ufc.com/athlete/jeremy-kimball\n",
      "Scraping Rob Kimmons...\n",
      "https://www.ufc.com/athlete/rob-kimmons\n",
      "Scraping Dustin Kimura...\n",
      "https://www.ufc.com/athlete/dustin-kimura\n",
      "Scraping Mike King...\n",
      "https://www.ufc.com/athlete/mike-king\n",
      "Scraping Kyle Kingsbury...\n",
      "https://www.ufc.com/athlete/kyle-kingsbury\n",
      "Scraping Yusaku Kinoshita...\n",
      "https://www.ufc.com/athlete/yusaku-kinoshita\n",
      "Scraping Kamuela Kirk...\n",
      "https://www.ufc.com/athlete/kamuela-kirk\n",
      "Scraping Justine Kish...\n",
      "https://www.ufc.com/athlete/justine-kish\n",
      "Scraping Koji Kitao...\n",
      "https://www.ufc.com/athlete/koji-kitao\n",
      "Scraping Top Noi Kiwram...\n",
      "https://www.ufc.com/athlete/top-kiwram\n",
      "Scraping Ludovit Klein...\n",
      "https://www.ufc.com/athlete/ludovit-klein\n",
      "Scraping Fatima Kline...\n",
      "https://www.ufc.com/athlete/fatima-kline\n",
      "Scraping Felix Klinkhammer...\n",
      "https://www.ufc.com/athlete/felix-klinkhammer\n",
      "Scraping Drakkar Klose...\n",
      "https://www.ufc.com/athlete/drakkar-klose\n",
      "Scraping Jason Knight...\n",
      "https://www.ufc.com/athlete/jason-knight\n",
      "Scraping William Knight...\n",
      "https://www.ufc.com/athlete/william-knight\n",
      "Scraping Josefine Knutsson...\n",
      "https://www.ufc.com/athlete/josefine-knutsson\n",
      "Scraping Seokhyeon Ko...\n",
      "https://www.ufc.com/athlete/seokhyeon-ko\n",
      "Scraping Erik Koch...\n",
      "https://www.ufc.com/athlete/erik-koch\n",
      "Scraping Brad Kohler...\n",
      "https://www.ufc.com/athlete/brad-kohler\n",
      "Scraping Kaloyan Kolev...\n",
      "https://www.ufc.com/athlete/kaloyan-kolev\n",
      "Scraping John Kolosci...\n",
      "https://www.ufc.com/athlete/john-kolosci\n",
      "Scraping Yuki Kondo...\n",
      "https://www.ufc.com/athlete/yuki-kondo\n",
      "Scraping Syuri Kondo...\n",
      "https://www.ufc.com/athlete/syuri-kondo\n",
      "Scraping Cheick Kongo...\n",
      "https://www.ufc.com/athlete/cheick-kongo\n",
      "Scraping Jon Koppenhaver...\n",
      "https://www.ufc.com/athlete/jon-koppenhaver\n",
      "Scraping Roman Kopylov...\n",
      "https://www.ufc.com/athlete/roman-kopylov\n",
      "Scraping Bruno Korea...\n",
      "https://www.ufc.com/athlete/bruno-korea\n",
      "Scraping Tsuyoshi Kosaka...\n",
      "https://www.ufc.com/athlete/tsuyoshi-kosaka\n",
      "Scraping Josh Koscheck...\n",
      "https://www.ufc.com/athlete/josh-koscheck\n",
      "Scraping Steven Koslow...\n",
      "https://www.ufc.com/athlete/steven-koslow\n",
      "Scraping Naoyuki Kotani...\n",
      "https://www.ufc.com/athlete/naoyuki-kotani\n",
      "Scraping Karolina Kowalkiewicz...\n",
      "https://www.ufc.com/athlete/karolina-kowalkiewicz\n",
      "Scraping Derrick Krantz...\n",
      "https://www.ufc.com/athlete/derrick-krantz\n",
      "Scraping James Krause...\n",
      "https://www.ufc.com/athlete/james-krause\n",
      "Scraping Pascal Krauss...\n",
      "https://www.ufc.com/athlete/pascal-krauss\n",
      "Scraping Kaynan Kruschewsky...\n",
      "https://www.ufc.com/athlete/kaynan-kruschewsky\n",
      "Scraping Jorgen Kruth...\n",
      "https://www.ufc.com/athlete/jorgen-kruth\n",
      "Scraping Nikita Krylov...\n",
      "https://www.ufc.com/athlete/nikita-krylov\n",
      "Scraping Mariusz Ksiazkiewicz...\n",
      "https://www.ufc.com/athlete/mariusz-ksiazkiewicz\n",
      "Scraping Michael Kuiper...\n",
      "https://www.ufc.com/athlete/michael-kuiper\n",
      "Scraping Anton Kuivanen...\n",
      "https://www.ufc.com/athlete/anton-kuivanen\n",
      "Scraping Sumit Kumar...\n",
      "https://www.ufc.com/athlete/sumit-kumar\n",
      "Scraping Aleksei Kunchenko...\n",
      "https://www.ufc.com/athlete/aleksei-kunchenko\n",
      "Scraping Rizvan Kuniev...\n",
      "https://www.ufc.com/athlete/rizvan-kuniev\n",
      "Scraping Keigo Kunihara...\n",
      "https://www.ufc.com/athlete/keigo-kunihara\n",
      "Scraping Kiichi Kunimoto...\n",
      "https://www.ufc.com/athlete/kiichi-kunimoto\n",
      "Scraping Leo Kuntz...\n",
      "https://www.ufc.com/athlete/leo-kuntz\n",
      "Scraping Korey Kuppe...\n",
      "https://www.ufc.com/athlete/korey-kuppe\n",
      "Scraping Ramazan Kuramagomedov...\n",
      "https://www.ufc.com/athlete/ramazan-kuramagomedov\n",
      "Scraping Guram Kutateladze...\n",
      "https://www.ufc.com/athlete/guram-kutateladze\n",
      "Scraping Kwan Ho Kwak...\n",
      "https://www.ufc.com/athlete/kwan-ho-kwak\n",
      "Scraping Mike Kyle...\n",
      "https://www.ufc.com/athlete/mike-kyle\n",
      "Scraping Luan Lacerda...\n",
      "https://www.ufc.com/athlete/luan-lacerda\n",
      "Scraping Daniel Lacerda...\n",
      "https://www.ufc.com/athlete/daniel-da-silva\n",
      "Scraping Aspen Ladd...\n",
      "https://www.ufc.com/athlete/aspen-ladd\n",
      "Scraping Ryan LaFlare...\n",
      "https://www.ufc.com/athlete/ryan-laflare\n",
      "Scraping Corinne Laframboise...\n",
      "https://www.ufc.com/athlete/corinne-laframboise\n",
      "Scraping Noad Lahat...\n",
      "https://www.ufc.com/athlete/noad-lahat\n",
      "Scraping Tina Lahdemaki...\n",
      "https://www.ufc.com/athlete/tina-lahdemaki\n",
      "Scraping Yohan Lainesse...\n",
      "https://www.ufc.com/athlete/yohan-lainesse\n",
      "Scraping Tim Lajcik...\n",
      "https://www.ufc.com/athlete/tim-lajcik\n",
      "Scraping Sean Lally...\n",
      "https://www.ufc.com/athlete/sean-lally\n",
      "Scraping Ricardo Lamas...\n",
      "https://www.ufc.com/athlete/ricardo-lamas\n",
      "Scraping Jason Lambert...\n",
      "https://www.ufc.com/athlete/jason-lambert\n",
      "Scraping Nate Landwehr...\n",
      "https://www.ufc.com/athlete/nate-landwehr\n",
      "Scraping Austen Lane...\n",
      "https://www.ufc.com/athlete/austen-lane\n",
      "Scraping Lina Lansberg...\n",
      "https://www.ufc.com/athlete/lina-lansberg\n",
      "Scraping Taylor Lapilus...\n",
      "https://www.ufc.com/athlete/taylor-lapilus\n",
      "Scraping Chad Laprise...\n",
      "https://www.ufc.com/athlete/chad-laprise\n",
      "Scraping Anthony Lapsley...\n",
      "https://www.ufc.com/athlete/anthony-lapsley\n",
      "Scraping TJ Laramie...\n",
      "https://www.ufc.com/athlete/tj-laramie\n",
      "Scraping Icho Larenas...\n",
      "https://www.ufc.com/athlete/icho-larenas\n",
      "Scraping Lorenz Larkin...\n",
      "https://www.ufc.com/athlete/lorenz-larkin\n",
      "Scraping Jeremy Larsen...\n",
      "https://www.ufc.com/athlete/jeremy-larsen\n",
      "Scraping Brock Larson...\n",
      "https://www.ufc.com/athlete/brock-larson\n",
      "Scraping Ilir Latifi...\n",
      "https://www.ufc.com/athlete/ilir-latifi\n",
      "Scraping Sione Latu...\n",
      "https://www.ufc.com/athlete/saiid-khosseyni-4\n",
      "Scraping Jenel Lausa...\n",
      "https://www.ufc.com/athlete/jenel-lausa\n",
      "Scraping Dan Lauzon...\n",
      "https://www.ufc.com/athlete/dan-lauzon\n",
      "Scraping Joe Lauzon...\n",
      "https://www.ufc.com/athlete/joe-lauzon\n",
      "Scraping Sandra Lavado...\n",
      "https://www.ufc.com/athlete/sandra-lavado\n",
      "Scraping Robbie Lawler...\n",
      "https://www.ufc.com/athlete/robbie-lawler\n",
      "Scraping Tom Lawlor...\n",
      "https://www.ufc.com/athlete/tom-lawlor\n",
      "Scraping Justin Lawrence...\n",
      "https://www.ufc.com/athlete/justin-lawrence\n",
      "Scraping Lance Lawrence...\n",
      "https://www.ufc.com/athlete/lance-lawrence\n",
      "Scraping Ronnie Lawrence...\n",
      "https://www.ufc.com/athlete/ronnie-lawrence\n",
      "Scraping Jimmy Lawson...\n",
      "https://www.ufc.com/athlete/jimmy-lawson\n",
      "Scraping Valmir Lazaro...\n",
      "https://www.ufc.com/athlete/valmir-lazaro\n",
      "Scraping Zviad Lazishvili...\n",
      "https://www.ufc.com/athlete/zviad-lazishvili\n",
      "Scraping Mounir Lazzez...\n",
      "https://www.ufc.com/athlete/mounir-lazzez\n",
      "Scraping Thanh Le...\n",
      "https://www.ufc.com/athlete/thanh-le\n",
      "Scraping Quang Le...\n",
      "https://www.ufc.com/athlete/quang-le\n",
      "Scraping Cung Le...\n",
      "https://www.ufc.com/athlete/cung-le\n",
      "Scraping Jordan Leavitt...\n",
      "https://www.ufc.com/athlete/jordan-leavitt\n",
      "Scraping Chris Leben...\n",
      "https://www.ufc.com/athlete/chris-leben\n",
      "Scraping Mickael Lebout...\n",
      "https://www.ufc.com/athlete/mickael-lebout\n",
      "Scraping Justin Ledet...\n",
      "https://www.ufc.com/athlete/justin-ledet\n",
      "Scraping James Lee...\n",
      "https://www.ufc.com/athlete/james-lee\n",
      "Scraping Kevin Lee...\n",
      "https://www.ufc.com/athlete/kevin-lee\n",
      "Scraping Andrea Lee...\n",
      "https://www.ufc.com/athlete/andrea-lee\n",
      "Scraping Rocky Lee...\n",
      "https://www.ufc.com/athlete/rocky-lee\n",
      "Scraping Vaughan Lee...\n",
      "https://www.ufc.com/athlete/vaughan-lee\n",
      "Scraping David Lee...\n",
      "https://www.ufc.com/athlete/david-lee\n",
      "Scraping Jackie Lee...\n",
      "https://www.ufc.com/athlete/saiid-khosseyni-6\n",
      "Scraping Jung Hyun Lee...\n",
      "https://www.ufc.com/athlete/jung-hyun-lee\n",
      "Scraping JeongYeong Lee...\n",
      "https://www.ufc.com/athlete/jeongyeong-lee\n",
      "Scraping ChangHo Lee...\n",
      "https://www.ufc.com/athlete/chang-ho-lee\n",
      "Scraping Cheyden Leialoha...\n",
      "https://www.ufc.com/athlete/cheyden-leialoha\n",
      "Scraping Christophe Leininger...\n",
      "https://www.ufc.com/athlete/christophe-leininger\n",
      "Scraping Claudia Leite...\n",
      "https://www.ufc.com/athlete/claudia-leite\n",
      "Scraping Thales Leites...\n",
      "https://www.ufc.com/athlete/thales-leites\n",
      "Scraping Giacomo Lemos...\n",
      "https://www.ufc.com/athlete/giacomo-lemos\n",
      "Scraping Amanda Lemos...\n",
      "https://www.ufc.com/athlete/amanda-lemos\n",
      "Scraping Jesse Lennox...\n",
      "https://www.ufc.com/athlete/jesse-lennox\n",
      "Scraping Nik Lentz...\n",
      "https://www.ufc.com/athlete/nitsuku-rentsu\n",
      "Scraping Alberto Cerro Leon...\n",
      "https://www.ufc.com/athlete/alberto-cerro-leon\n",
      "Scraping Victoria Leonardo...\n",
      "https://www.ufc.com/athlete/victoria-leonardo\n",
      "Scraping Anthony Leone...\n",
      "https://www.ufc.com/athlete/anthony-leone\n",
      "Scraping Kimo Leopoldo...\n",
      "https://www.ufc.com/athlete/kimo-leopoldo\n",
      "Scraping Brock Lesnar...\n",
      "https://www.ufc.com/athlete/brock-lesnar\n",
      "Scraping Frank Lester...\n",
      "https://www.ufc.com/athlete/frank-lester\n",
      "Scraping Valerie Letourneau...\n",
      "https://www.ufc.com/athlete/valerie-letourneau\n",
      "Scraping Leah Letson...\n",
      "https://www.ufc.com/athlete/leah-letson\n",
      "Scraping Justin Levens...\n",
      "https://www.ufc.com/athlete/justin-levens\n",
      "Scraping Marcus LeVesseur...\n",
      "https://www.ufc.com/athlete/marcus-levesseur\n",
      "Scraping David Levicki...\n",
      "https://www.ufc.com/athlete/david-levicki\n",
      "Scraping Natan Levy...\n",
      "https://www.ufc.com/athlete/natan-levy\n",
      "Scraping John Lewis...\n",
      "https://www.ufc.com/athlete/devid-leviki-0\n",
      "Scraping Bevon Lewis...\n",
      "https://www.ufc.com/athlete/bevon-lewis\n",
      "Scraping Malik Lewis...\n",
      "https://www.ufc.com/athlete/malik-lewis\n",
      "Scraping Brandon Lewis...\n",
      "https://www.ufc.com/athlete/brandon-lewis\n",
      "Scraping Derrick Lewis...\n",
      "https://www.ufc.com/athlete/derrick-lewis\n",
      "Scraping Chi Lewis-Parry...\n",
      "https://www.ufc.com/athlete/chi-lewis-parry\n",
      "Scraping Liang Na...\n",
      "https://www.ufc.com/athlete/liang-na\n",
      "Scraping Jess Liaudin...\n",
      "https://www.ufc.com/athlete/jess-liaudin\n",
      "Scraping Chuck Liddell...\n",
      "https://www.ufc.com/athlete/chuck-liddell\n",
      "Scraping Rodrigo Lidio...\n",
      "https://www.ufc.com/athlete/rodrigo-lidio\n",
      "Scraping Zach Light...\n",
      "https://www.ufc.com/athlete/zach-light\n",
      "Scraping Chris Ligouri...\n",
      "https://www.ufc.com/athlete/chris-ligouri\n",
      "Scraping Hyun Gyu Lim...\n",
      "https://www.ufc.com/athlete/hyun-gyu-lim\n",
      "Scraping Mabelly Lima...\n",
      "https://www.ufc.com/athlete/mabelly-lima\n",
      "Scraping Juliana Lima...\n",
      "https://www.ufc.com/athlete/juliana-lima\n",
      "Scraping Dhiego Lima...\n",
      "https://www.ufc.com/athlete/dhiego-lima\n",
      "Scraping Felipe Lima...\n",
      "https://www.ufc.com/athlete/felipe-lima\n",
      "Scraping Andre Lima...\n",
      "https://www.ufc.com/athlete/andre-lima\n",
      "Scraping Matt Lindland...\n",
      "https://www.ufc.com/athlete/matt-lindland\n",
      "Scraping Jake Lindsey...\n",
      "https://www.ufc.com/athlete/jake-lindsey\n",
      "Scraping John Lineker...\n",
      "https://www.ufc.com/athlete/john-lineker\n",
      "Scraping Austin Lingo...\n",
      "https://www.ufc.com/athlete/austin-lingo\n",
      "Scraping Lucio Linhares...\n",
      "https://www.ufc.com/athlete/lucio-linhares\n",
      "Scraping Philipe Lins...\n",
      "https://www.ufc.com/athlete/philipe-lins\n",
      "Scraping Zhang Lipeng...\n",
      "https://www.ufc.com/athlete/zhang-lipeng\n",
      "Scraping Tainara Lisboa...\n",
      "https://www.ufc.com/athlete/tainara-lisboa\n",
      "Scraping Dean Lister...\n",
      "https://www.ufc.com/athlete/dean-lister\n",
      "Scraping Pingyuan Liu...\n",
      "https://www.ufc.com/athlete/pingyuan-liu\n",
      "Scraping James Llontop...\n",
      "https://www.ufc.com/athlete/james-llontop\n",
      "Scraping Abner Lloveras...\n",
      "https://www.ufc.com/athlete/abner-lloveras\n",
      "Scraping John Lober...\n",
      "https://www.ufc.com/athlete/john-lober\n",
      "Scraping Artem Lobov...\n",
      "https://www.ufc.com/athlete/artem-lobov\n",
      "Scraping Dylan Lockard...\n",
      "https://www.ufc.com/athlete/dylan-lockard\n",
      "Scraping Ryan Loder...\n",
      "https://www.ufc.com/athlete/ryan-loder\n",
      "Scraping Sean Loeffler...\n",
      "https://www.ufc.com/athlete/sean-loeffler\n",
      "Scraping Christian Lohsen...\n",
      "https://www.ufc.com/athlete/christian-lohsen\n",
      "Scraping David Loiseau...\n",
      "https://www.ufc.com/athlete/david-loiseau\n",
      "Scraping Hector Lombard...\n",
      "https://www.ufc.com/athlete/hector-lombard\n",
      "Scraping Michael Lombardo...\n",
      "https://www.ufc.com/athlete/michael-lombardo\n",
      "Scraping Xiao Long...\n",
      "https://www.ufc.com/athlete/xiao-long\n",
      "Scraping Loma Lookboonmee...\n",
      "https://www.ufc.com/athlete/loma-lookboonmee\n",
      "Scraping Ange Loosa...\n",
      "https://www.ufc.com/athlete/ange-loosa\n",
      "Scraping Dileno Lopes...\n",
      "https://www.ufc.com/athlete/dileno-lopes\n",
      "Scraping Bruno Lopes...\n",
      "https://www.ufc.com/athlete/bruno-lopes\n",
      "Scraping Diego Lopes...\n",
      "https://www.ufc.com/athlete/diego-lopes\n",
      "Scraping Steve Lopez...\n",
      "https://www.ufc.com/athlete/steve-lopez\n",
      "Scraping Benito Lopez...\n",
      "https://www.ufc.com/athlete/benito-lopez\n",
      "Scraping Matthew Lopez...\n",
      "https://www.ufc.com/athlete/matthew-lopez\n",
      "Scraping Jorge Lopez...\n",
      "https://www.ufc.com/athlete/jorge-lopez\n",
      "Scraping Gustavo Lopez...\n",
      "https://www.ufc.com/athlete/gustavo-lopez\n",
      "Scraping Aaron Lott...\n",
      "https://www.ufc.com/athlete/aaron-lott\n",
      "Scraping Brendan Loughnane...\n",
      "https://www.ufc.com/athlete/brendan-loughnane\n",
      "Scraping Nate Loughran...\n",
      "https://www.ufc.com/athlete/nate-loughran\n",
      "Scraping Caoln Loughran...\n",
      "https://www.ufc.com/athlete/caolan-loughran\n",
      "Scraping Ian Loveland...\n",
      "https://www.ufc.com/athlete/ian-loveland\n",
      "Scraping Waylon Lowe...\n",
      "https://www.ufc.com/athlete/waylon-lowe\n",
      "Scraping Joseph Lowry...\n",
      "https://www.ufc.com/athlete/joseph-lowry\n",
      "Scraping Robert Lucarelli...\n",
      "https://www.ufc.com/athlete/robert-lucarelli\n",
      "Scraping Matt Lucas...\n",
      "https://www.ufc.com/athlete/matt-lucas\n",
      "Scraping Iasmin Lucindo...\n",
      "https://www.ufc.com/athlete/iasmin-lucindo\n",
      "Scraping Duane Ludwig...\n",
      "https://www.ufc.com/athlete/duane-ludwig\n",
      "Scraping Mike Lullo...\n",
      "https://www.ufc.com/athlete/mike-lullo\n",
      "Scraping Qiu Lun...\n",
      "https://www.ufc.com/athlete/qiu-lun\n",
      "Scraping Dalcha Lungiambula...\n",
      "https://www.ufc.com/athlete/dalcha-lungiambula\n",
      "Scraping Vicente Luque...\n",
      "https://www.ufc.com/athlete/vicente-luque\n",
      "Scraping Thaddeus Luster...\n",
      "https://www.ufc.com/athlete/thaddeus-luster\n",
      "Scraping Travis Lutter...\n",
      "https://www.ufc.com/athlete/travis-lutter\n",
      "Scraping Tucker Lutz...\n",
      "https://www.ufc.com/athlete/tucker-lutz\n",
      "Scraping Stevie Lynch...\n",
      "https://www.ufc.com/athlete/trevis-latter-0\n",
      "Scraping Chris Lytle...\n",
      "https://www.ufc.com/athlete/chris-lytle\n",
      "Scraping Dong Hyun Ma...\n",
      "https://www.ufc.com/athlete/dong-hyun-kim\n",
      "Scraping Pawan Maan...\n",
      "https://www.ufc.com/athlete/pawan-maan\n",
      "Scraping William Macario...\n",
      "https://www.ufc.com/athlete/william-macario\n",
      "Scraping Ryan MacDonald...\n",
      "https://www.ufc.com/athlete/ryan-macdonald\n",
      "Scraping Rory MacDonald...\n",
      "https://www.ufc.com/athlete/rory-macdonald\n",
      "Scraping Rob MacDonald...\n",
      "https://www.ufc.com/athlete/rob-macdonald\n",
      "Scraping Jason MacDonald...\n",
      "https://www.ufc.com/athlete/jason-macdonald\n",
      "Scraping Veronica Hardy...\n",
      "https://www.ufc.com/athlete/veronica-hardy\n",
      "Scraping Valesca Machado...\n",
      "https://www.ufc.com/athlete/valesca-machado\n",
      "Scraping Caio Machado...\n",
      "https://www.ufc.com/athlete/caio-machado\n",
      "Scraping Ian Machado Garry...\n",
      "https://www.ufc.com/athlete/ian-garry\n",
      "Scraping Lyoto Machida...\n",
      "https://www.ufc.com/athlete/lyoto-machida\n",
      "Scraping Anthony Macias...\n",
      "https://www.ufc.com/athlete/anthony-macias\n",
      "Scraping Pauline Macias...\n",
      "https://www.ufc.com/athlete/pauline-macias\n",
      "Scraping Reza Madadi...\n",
      "https://www.ufc.com/athlete/resa-matatei\n",
      "Scraping Don Madge...\n",
      "https://www.ufc.com/athlete/don-madge\n",
      "Scraping Ryan Madigan...\n",
      "https://www.ufc.com/athlete/ryan-madigan\n",
      "Scraping Victor Madrigal...\n",
      "https://www.ufc.com/athlete/victor-madrigal\n",
      "Scraping Mark Madsen...\n",
      "https://www.ufc.com/athlete/mark-madsen\n",
      "Scraping Jon Madsen...\n",
      "https://www.ufc.com/athlete/jon-madsen\n",
      "Scraping Leonardo Mafra...\n",
      "https://www.ufc.com/athlete/leonardo-mafra\n",
      "Scraping Vinny Magalhaes...\n",
      "https://www.ufc.com/athlete/vinny-magalhaes\n",
      "Scraping Caio Magalhaes...\n",
      "https://www.ufc.com/athlete/caio-magalhaes\n",
      "Scraping Bernardo Magalhaes...\n",
      "https://www.ufc.com/athlete/bernardo-magalhaes\n",
      "Scraping Angela Magana...\n",
      "https://www.ufc.com/athlete/angela-magana\n",
      "Scraping Neil Magny...\n",
      "https://www.ufc.com/athlete/neil-magny\n",
      "Scraping Raimond Magomedaliev...\n",
      "https://www.ufc.com/athlete/raimond-magomedaliev\n",
      "Scraping Ruslan Magomedov...\n",
      "https://www.ufc.com/athlete/ruslan-magomedov\n",
      "Scraping Rashid Magomedov...\n",
      "https://www.ufc.com/athlete/rashid-magomedov\n",
      "Scraping Abus Magomedov...\n",
      "https://www.ufc.com/athlete/abus-magomedov\n",
      "Scraping Shara Magomedov...\n",
      "https://www.ufc.com/athlete/shara-magomedov\n",
      "Scraping Zabit Magomedsharipov...\n",
      "https://www.ufc.com/athlete/zabit-magomedsharipov\n",
      "Scraping John Maguire...\n",
      "https://www.ufc.com/athlete/john-maguire\n",
      "Scraping Maheshate...\n",
      "https://www.ufc.com/athlete/hayisaer-maheshate\n",
      "Scraping Bill Mahood...\n",
      "https://www.ufc.com/athlete/bill-mahood\n",
      "Scraping Demian Maia...\n",
      "https://www.ufc.com/athlete/demian-maia\n",
      "Scraping Jennifer Maia...\n",
      "https://www.ufc.com/athlete/jennifer-maia\n",
      "Scraping Nayara Maia...\n",
      "https://www.ufc.com/athlete/nayara-maia\n",
      "Scraping Roshan Mainam...\n",
      "https://www.ufc.com/athlete/roshan-mainam\n",
      "Scraping Levan Makashvili...\n",
      "https://www.ufc.com/athlete/levan-makashvili\n",
      "Scraping John Makdessi...\n",
      "https://www.ufc.com/athlete/john-makdessi\n",
      "Scraping Islam Makhachev...\n",
      "https://www.ufc.com/athlete/islam-makhachev\n",
      "Scraping Bilyal Makhov...\n",
      "https://www.ufc.com/athlete/bilyal-makhov\n",
      "Scraping Zach Makovsky...\n",
      "https://www.ufc.com/athlete/zach-makovsky\n",
      "Scraping Azat Maksum...\n",
      "https://www.ufc.com/athlete/azat-maksum\n",
      "Scraping Fabio Maldonado...\n",
      "https://www.ufc.com/athlete/fabio-maldonado\n",
      "Scraping Bea Malecki...\n",
      "https://www.ufc.com/athlete/bea-malecki\n",
      "Scraping Nazareno Malegarie...\n",
      "https://www.ufc.com/athlete/nazareno-malegarie\n",
      "Scraping Jacob Malkoun...\n",
      "https://www.ufc.com/athlete/jacob-malkoun\n",
      "Scraping Mike Malott...\n",
      "https://www.ufc.com/athlete/mike-malott\n",
      "Scraping Troy Mandaloniz...\n",
      "https://www.ufc.com/athlete/troy-mandaloniz\n",
      "Scraping Nate Maness...\n",
      "https://www.ufc.com/athlete/nate-maness\n",
      "Scraping Gary Mangat...\n",
      "https://www.ufc.com/athlete/gary-mangat\n",
      "Scraping Jon Manley...\n",
      "https://www.ufc.com/athlete/jon-manley\n",
      "Scraping Marnic Mann...\n",
      "https://www.ufc.com/athlete/marnic-mann\n",
      "Scraping Jimi Manuwa...\n",
      "https://www.ufc.com/athlete/jimi-manuwa\n",
      "Scraping William Marcario...\n",
      "https://www.ufc.com/athlete/william-marcario\n",
      "Scraping Cristiano Marcello...\n",
      "https://www.ufc.com/athlete/cristiano-marcello\n",
      "Scraping Daniel Marcos...\n",
      "https://www.ufc.com/athlete/daniel-marcos\n",
      "Scraping Jose Maria...\n",
      "https://www.ufc.com/athlete/jose-maria\n",
      "Scraping Enrique Marin...\n",
      "https://www.ufc.com/athlete/enrique-marin\n",
      "Scraping Jesse Mariotti...\n",
      "https://www.ufc.com/athlete/jesse-mariotti\n",
      "Scraping Chepe Mariscal...\n",
      "https://www.ufc.com/athlete/chepe-mariscal\n",
      "Scraping Ronny Markes...\n",
      "https://www.ufc.com/athlete/ronny-markes\n",
      "Scraping Rory Markham...\n",
      "https://www.ufc.com/athlete/rory-markham\n",
      "Scraping Randa Markos...\n",
      "https://www.ufc.com/athlete/randa-markos\n",
      "Scraping Christina Marks...\n",
      "https://www.ufc.com/athlete/christina-marks\n",
      "Scraping Brendon Marotte...\n",
      "https://www.ufc.com/athlete/brendon-marotte\n",
      "Scraping Nate Marquardt...\n",
      "https://www.ufc.com/athlete/nate-marquardt\n",
      "Scraping Danilo Marques...\n",
      "https://www.ufc.com/athlete/danilo-marques\n",
      "Scraping Julian Marquez...\n",
      "https://www.ufc.com/athlete/julian-marquez\n",
      "Scraping Carmelo Marrero...\n",
      "https://www.ufc.com/athlete/carmelo-marrero\n",
      "Scraping Dallas Marron...\n",
      "https://www.ufc.com/athlete/dallas-marron\n",
      "Scraping Cesar Marscucci...\n",
      "https://www.ufc.com/athlete/cesar-marscucci\n",
      "Scraping John Marsh...\n",
      "https://www.ufc.com/athlete/john-marsh\n",
      "Scraping Eliot Marshall...\n",
      "https://www.ufc.com/athlete/eliot-marshall\n",
      "Scraping Doug Marshall...\n",
      "https://www.ufc.com/athlete/doug-marshall\n",
      "Scraping Francis Marshall...\n",
      "https://www.ufc.com/athlete/francis-marshall\n",
      "Scraping Jack Marshman...\n",
      "https://www.ufc.com/athlete/jack-marshman\n",
      "Scraping Mallory Martin...\n",
      "https://www.ufc.com/athlete/mallory-martin\n",
      "Scraping Anthony Rocco Martin...\n",
      "https://www.ufc.com/athlete/anthony-rocco-martin\n",
      "Scraping Terry Martin...\n",
      "https://www.ufc.com/athlete/terry-martin\n",
      "Scraping Eric Martin...\n",
      "https://www.ufc.com/athlete/taddeus-laster-3\n",
      "Scraping Justin Martin...\n",
      "https://www.ufc.com/athlete/justin-martin-0\n",
      "Scraping Michal Martinek...\n",
      "https://www.ufc.com/athlete/michal-martinek\n",
      "Scraping Danny Martinez...\n",
      "https://www.ufc.com/athlete/danny-martinez\n",
      "Scraping Henry Martinez...\n",
      "https://www.ufc.com/athlete/henry-martinez\n",
      "Scraping Rainy Martinez...\n",
      "https://www.ufc.com/athlete/terri-martin-0\n",
      "Scraping Mana Martinez...\n",
      "https://www.ufc.com/athlete/mana-martinez\n",
      "Scraping Victor Martinez...\n",
      "https://www.ufc.com/athlete/victor-martinez\n",
      "Scraping Roque Martinez...\n",
      "https://www.ufc.com/athlete/roque-martinez\n",
      "Scraping Jonathan Martinez...\n",
      "https://www.ufc.com/athlete/jonathan-martinez\n",
      "Scraping Melissa Martinez...\n",
      "https://www.ufc.com/athlete/melissa-martinez\n",
      "Scraping Lucas Martins...\n",
      "https://www.ufc.com/athlete/lucas-martins\n",
      "Scraping Adriano Martins...\n",
      "https://www.ufc.com/athlete/adriano-martins\n",
      "Scraping Bristol Marunde...\n",
      "https://www.ufc.com/athlete/bristol-marunde\n",
      "Scraping Kazuma Maruyama...\n",
      "https://www.ufc.com/athlete/kazuma-maruyama\n",
      "Scraping Mike Massenzio...\n",
      "https://www.ufc.com/athlete/mike-massenzio\n",
      "Scraping Tiffany Masters...\n",
      "https://www.ufc.com/athlete/tiffany-masters\n",
      "Scraping Jorge Masvidal...\n",
      "https://www.ufc.com/athlete/jorge-masvidal\n",
      "Scraping Al Matavao...\n",
      "https://www.ufc.com/athlete/al-matavao\n",
      "Scraping Eduardo Matias Torres...\n",
      "https://www.ufc.com/athlete/eduardo-matias-torres\n",
      "Scraping Tateki Matsuda...\n",
      "https://www.ufc.com/athlete/tateki-matsuda\n",
      "Scraping Jean Matsumoto...\n",
      "https://www.ufc.com/athlete/jean-matsumoto\n",
      "Scraping Koyomi Matsushima...\n",
      "https://www.ufc.com/athlete/koyomi-matsushima\n",
      "Scraping Jake Matthews...\n",
      "https://www.ufc.com/athlete/jake-matthews\n",
      "Scraping Connor Matthews...\n",
      "https://www.ufc.com/athlete/connor-matthews\n",
      "Scraping John Matua...\n",
      "https://www.ufc.com/athlete/john-matua\n",
      "Scraping Francesco Maturi...\n",
      "https://www.ufc.com/athlete/taddeus-laster-0\n",
      "Scraping Vladimir Matyushenko...\n",
      "https://www.ufc.com/athlete/vladimir-matyushenko\n",
      "Scraping Miranda Maverick...\n",
      "https://www.ufc.com/athlete/miranda-maverick\n",
      "Scraping Nick Maximov...\n",
      "https://www.ufc.com/athlete/nick-maximov\n",
      "Scraping Jack May...\n",
      "https://www.ufc.com/athlete/jack-may\n",
      "Scraping Don'Tale Mayes...\n",
      "https://www.ufc.com/athlete/dontale-mayes\n",
      "Scraping Gray Maynard...\n",
      "https://www.ufc.com/athlete/gray-maynard\n",
      "Scraping Gina Mazany...\n",
      "https://www.ufc.com/athlete/gina-mazany\n",
      "Scraping Sabina Mazo...\n",
      "https://www.ufc.com/athlete/sabina-mazo\n",
      "Scraping Scott McAfee...\n",
      "https://www.ufc.com/athlete/scott-mcafee\n",
      "Scraping Michael McBride...\n",
      "https://www.ufc.com/athlete/michael-mcbride\n",
      "Scraping Ian McCall...\n",
      "https://www.ufc.com/athlete/ian-mccall\n",
      "Scraping Molly McCann...\n",
      "https://www.ufc.com/athlete/molly-mccann\n",
      "Scraping Charles McCarthy...\n",
      "https://www.ufc.com/athlete/charles-mccarthy\n",
      "Scraping Sean McCorkle...\n",
      "https://www.ufc.com/athlete/sean-mccorkle\n",
      "Scraping Kris McCray...\n",
      "https://www.ufc.com/athlete/kris-mccray\n",
      "Scraping Tamdan McCrory...\n",
      "https://www.ufc.com/athlete/tamdan-mccrory\n",
      "Scraping Justin McCully...\n",
      "https://www.ufc.com/athlete/justin-mccully\n",
      "Scraping Bubba McDaniel...\n",
      "https://www.ufc.com/athlete/bubba-mcdaniel\n",
      "Scraping Michael McDonald...\n",
      "https://www.ufc.com/athlete/michael-mcdonald\n",
      "Scraping Drew McFedries...\n",
      "https://www.ufc.com/athlete/drew-mcfedries\n",
      "Scraping Gan McGee...\n",
      "https://www.ufc.com/athlete/gan-mcgee\n",
      "Scraping Court McGee...\n",
      "https://www.ufc.com/athlete/court-mcgee\n",
      "Scraping Marcus McGhee...\n",
      "https://www.ufc.com/athlete/marcus-mcghee\n",
      "Scraping Ryan McGilivray...\n",
      "https://www.ufc.com/athlete/ryan-mcgilivray\n",
      "Scraping Jack McGlaughlin...\n",
      "https://www.ufc.com/athlete/taddeus-laster-1\n",
      "Scraping Conor McGregor...\n",
      "https://www.ufc.com/athlete/conor-mcgregor\n",
      "Scraping Sean Mcinerney...\n",
      "https://www.ufc.com/athlete/sean-mcinerney\n",
      "Scraping Antonio McKee...\n",
      "https://www.ufc.com/athlete/antonio-mckee\n",
      "Scraping Rhys McKee...\n",
      "https://www.ufc.com/athlete/rhys-mckee\n",
      "Scraping Cory McKenna...\n",
      "https://www.ufc.com/athlete/cory-mckenna\n",
      "Scraping Tim McKenzie...\n",
      "https://www.ufc.com/athlete/tim-mckenzie\n",
      "Scraping Cody McKenzie...\n",
      "https://www.ufc.com/athlete/cody-mckenzie\n",
      "Scraping Terrance McKinney...\n",
      "https://www.ufc.com/athlete/terrance-mckinney\n",
      "Scraping Garreth McLellan...\n",
      "https://www.ufc.com/athlete/garreth-mclellan\n",
      "Scraping Sara McMann...\n",
      "https://www.ufc.com/athlete/sara-mcmann\n",
      "Scraping James McSweeney...\n",
      "https://www.ufc.com/athlete/james-mcsweeney\n",
      "Scraping Tim Means...\n",
      "https://www.ufc.com/athlete/tim-means\n",
      "Scraping Yancy Medeiros...\n",
      "https://www.ufc.com/athlete/yancy-medeiros\n",
      "Scraping Anistavio Medeiros...\n",
      "https://www.ufc.com/athlete/andzhela-khill-1\n",
      "Scraping MarQuel Mederos...\n",
      "https://www.ufc.com/athlete/marquel-mederos\n",
      "Scraping Uro Medi...\n",
      "https://www.ufc.com/athlete/uros-medic\n",
      "Scraping Todd Medina...\n",
      "https://www.ufc.com/athlete/kodi-makkenzi-1\n",
      "Scraping Emil Meek...\n",
      "https://www.ufc.com/athlete/emil-meek\n",
      "Scraping Alton Meeks...\n",
      "https://www.ufc.com/athlete/alton-meeks\n",
      "Scraping Gerald Meerschaert...\n",
      "https://www.ufc.com/athlete/gerald-meerschaert\n",
      "Scraping Jordan Mein...\n",
      "https://www.ufc.com/athlete/shiyotan-mein\n",
      "Scraping Brian Melancon...\n",
      "https://www.ufc.com/athlete/brian-melancon\n",
      "Scraping Gilbert Melendez...\n",
      "https://www.ufc.com/athlete/gilbert-melendez\n",
      "Scraping Dominik Melendez...\n",
      "https://www.ufc.com/athlete/dominik-melendez\n",
      "Scraping Marcello Mello...\n",
      "https://www.ufc.com/athlete/taddeus-laster-2\n",
      "Scraping Vanessa Melo...\n",
      "https://www.ufc.com/athlete/vanessa-melo\n",
      "Scraping Chad Mendes...\n",
      "https://www.ufc.com/athlete/chad-mendes\n",
      "Scraping Antonio Mendes...\n",
      "https://www.ufc.com/athlete/antonio-mendes\n",
      "Scraping Augusto Mendes...\n",
      "https://www.ufc.com/athlete/augusto-mendes\n",
      "Scraping Eddie Mendez...\n",
      "https://www.ufc.com/athlete/eddie-mendez\n",
      "Scraping Mateus Mendona...\n",
      "https://www.ufc.com/athlete/mateus-mendonca\n",
      "Scraping Pietro Menga...\n",
      "https://www.ufc.com/athlete/pietro-menga\n",
      "Scraping Alonzo Menifield...\n",
      "https://www.ufc.com/athlete/alonzo-menifield\n",
      "Scraping Ivan Menjivar...\n",
      "https://www.ufc.com/athlete/ivan-menjivar\n",
      "Scraping Dave Menne...\n",
      "https://www.ufc.com/athlete/darrik-minner-2\n",
      "Scraping Joe Merritt...\n",
      "https://www.ufc.com/athlete/joe-merritt\n",
      "Scraping Jonathan Meunier...\n",
      "https://www.ufc.com/athlete/jonathan-meunier\n",
      "Scraping Yaotzin Meza...\n",
      "https://www.ufc.com/athlete/yaotzin-meza\n",
      "Scraping Guy Mezger...\n",
      "https://www.ufc.com/athlete/guy-mezger\n",
      "Scraping Andreas Michailidis...\n",
      "https://www.ufc.com/athlete/andreas-michailidis\n",
      "Scraping David Michaud...\n",
      "https://www.ufc.com/athlete/david-michaud\n",
      "Scraping Christophe Midoux...\n",
      "https://www.ufc.com/athlete/christophe-midoux\n",
      "Scraping Keith Mielke...\n",
      "https://www.ufc.com/athlete/keith-mielke\n",
      "Scraping Bojan Mihajlovic...\n",
      "https://www.ufc.com/athlete/bojan-mihajlovic\n",
      "Scraping Pat Miletich...\n",
      "https://www.ufc.com/athlete/pat-miletich\n",
      "Scraping Curtis Millender...\n",
      "https://www.ufc.com/athlete/curtis-millender\n",
      "Scraping Jim Miller...\n",
      "https://www.ufc.com/athlete/jim-miller\n",
      "Scraping Dan Miller...\n",
      "https://www.ufc.com/athlete/dan-miller\n",
      "Scraping Cole Miller...\n",
      "https://www.ufc.com/athlete/cole-miller\n",
      "Scraping Jason Miller...\n",
      "https://www.ufc.com/athlete/jason-miller\n",
      "Scraping Phillip Miller...\n",
      "https://www.ufc.com/athlete/phillip-miller\n",
      "Scraping Juliana Miller...\n",
      "https://www.ufc.com/athlete/juliana-miller\n",
      "Scraping Mo Miller...\n",
      "https://www.ufc.com/athlete/mo-miller\n",
      "Scraping Che Mills...\n",
      "https://www.ufc.com/athlete/che-mills\n",
      "Scraping Adam Milstead...\n",
      "https://www.ufc.com/athlete/adam-milstead\n",
      "Scraping Alberto Mina...\n",
      "https://www.ufc.com/athlete/alberto-mina\n",
      "Scraping Zhang Mingyang...\n",
      "https://www.ufc.com/athlete/zhang-mingyang\n",
      "Scraping Darrick Minner...\n",
      "https://www.ufc.com/athlete/darrick-minner\n",
      "Scraping Ikuhisa Minowa...\n",
      "https://www.ufc.com/athlete/ikuhisa-minowa\n",
      "Scraping Carlton Minus...\n",
      "https://www.ufc.com/athlete/carlton-minus\n",
      "Scraping Stipe Miocic...\n",
      "https://www.ufc.com/athlete/stipe-miocic\n",
      "Scraping Frank Mir...\n",
      "https://www.ufc.com/athlete/frank-mir\n",
      "Scraping Mario Miranda...\n",
      "https://www.ufc.com/athlete/mario-miranda\n",
      "Scraping Vitor Miranda...\n",
      "https://www.ufc.com/athlete/vitor-miranda\n",
      "Scraping Gabriel Miranda...\n",
      "https://www.ufc.com/athlete/gabriel-miranda\n",
      "Scraping Kazuo Misaki...\n",
      "https://www.ufc.com/athlete/kazuo-misaki\n",
      "Scraping Toby Misech...\n",
      "https://www.ufc.com/athlete/toby-misech\n",
      "Scraping Dokonjonosuke Mishima...\n",
      "https://www.ufc.com/athlete/dokonjonosuke-mishima\n",
      "Scraping Martin Mishtaku...\n",
      "https://www.ufc.com/athlete/martin-mishtaku\n",
      "Scraping Maurice Mitchell...\n",
      "https://www.ufc.com/athlete/maurice-mitchell\n",
      "Scraping Danny Mitchell...\n",
      "https://www.ufc.com/athlete/danny-mitchell\n",
      "Scraping Felix Lee Mitchell...\n",
      "https://www.ufc.com/athlete/dokonzhonosuke-mishima-0\n",
      "Scraping Terrence Mitchell...\n",
      "https://www.ufc.com/athlete/terrence-mitchell\n",
      "Scraping Bryce Mitchell...\n",
      "https://www.ufc.com/athlete/bryce-mitchell\n",
      "Scraping Roman Mitichyan...\n",
      "https://www.ufc.com/athlete/roman-mitichyan\n",
      "Scraping Matt Mitrione...\n",
      "https://www.ufc.com/athlete/matt-mitrione\n",
      "Scraping Eiji Mitsuoka...\n",
      "https://www.ufc.com/athlete/eiji-mitsuoka\n",
      "Scraping Takeya Mizugaki...\n",
      "https://www.ufc.com/athlete/takeya-mizugaki\n",
      "Scraping Roxanne Modafferi...\n",
      "https://www.ufc.com/athlete/roxanne-modafferi\n",
      "Scraping Bobby Moffett...\n",
      "https://www.ufc.com/athlete/bobby-moffett\n",
      "Scraping Nate Mohr...\n",
      "https://www.ufc.com/athlete/nate-mohr\n",
      "Scraping Renato Moicano...\n",
      "https://www.ufc.com/athlete/renato-moicano\n",
      "Scraping Thiago Moiss...\n",
      "https://www.ufc.com/athlete/thiago-moises\n",
      "Scraping Muhammad Mokaev...\n",
      "https://www.ufc.com/athlete/muhammad-mokaev\n",
      "Scraping Suman Mokhtarian...\n",
      "https://www.ufc.com/athlete/suman-mokhtarian\n",
      "Scraping Ashkan Mokhtarian...\n",
      "https://www.ufc.com/athlete/ashkan-mokhtarian\n",
      "Scraping Jeffrey Molina...\n",
      "https://www.ufc.com/athlete/jeffrey-molina\n",
      "Scraping Rudyard Moncayo...\n",
      "https://www.ufc.com/athlete/neyt-mor-0\n",
      "Scraping Jeff Monson...\n",
      "https://www.ufc.com/athlete/jeff-monson\n",
      "Scraping Darrell Montague...\n",
      "https://www.ufc.com/athlete/darrell-montague\n",
      "Scraping Augusto Montano...\n",
      "https://www.ufc.com/athlete/augusto-montano\n",
      "Scraping Nicco Montano...\n",
      "https://www.ufc.com/athlete/nicco-montano\n",
      "Scraping Erick Montano...\n",
      "https://www.ufc.com/athlete/erick-montano\n",
      "Scraping Alberto Montes...\n",
      "https://www.ufc.com/athlete/alberto-montes\n",
      "Scraping Steve Montgomery...\n",
      "https://www.ufc.com/athlete/steve-montgomery\n",
      "Scraping James Moontasri...\n",
      "https://www.ufc.com/athlete/james-moontasri\n",
      "Scraping Homer Moore...\n",
      "https://www.ufc.com/athlete/homer-moore\n",
      "Scraping Taylor Moore...\n",
      "https://www.ufc.com/athlete/taylor-moore\n",
      "Scraping Sheymon Moraes...\n",
      "https://www.ufc.com/athlete/sheymon-moraes\n",
      "Scraping Marlon Moraes...\n",
      "https://www.ufc.com/athlete/marlon-moraes\n",
      "Scraping Sergio Moraes...\n",
      "https://www.ufc.com/athlete/sergio-moraes\n",
      "Scraping John Moraga...\n",
      "https://www.ufc.com/athlete/john-moraga\n",
      "Scraping Vince Morales...\n",
      "https://www.ufc.com/athlete/vince-morales\n",
      "Scraping Leonardo Morales...\n",
      "https://www.ufc.com/athlete/leonardo-morales\n",
      "Scraping Joseph Morales...\n",
      "https://www.ufc.com/athlete/joseph-morales\n",
      "Scraping Albert Morales...\n",
      "https://www.ufc.com/athlete/albert-morales\n",
      "Scraping Michael Morales...\n",
      "https://www.ufc.com/athlete/michael-morales\n",
      "Scraping Omar Morales...\n",
      "https://www.ufc.com/athlete/omar-morales\n",
      "Scraping Sarah Moras...\n",
      "https://www.ufc.com/athlete/sarah-moras\n",
      "Scraping Christian Morecraft...\n",
      "https://www.ufc.com/athlete/christian-morecraft\n",
      "Scraping Gisele Moreira...\n",
      "https://www.ufc.com/athlete/gisele-moreira\n",
      "Scraping Vinicius Moreira...\n",
      "https://www.ufc.com/athlete/vinicius-castro\n",
      "Scraping Richardson Moreira...\n",
      "https://www.ufc.com/athlete/richardson-moreira\n",
      "Scraping Brandon Moreno...\n",
      "https://www.ufc.com/athlete/brandon-moreno\n",
      "Scraping Dan Moret...\n",
      "https://www.ufc.com/athlete/dan-moret\n",
      "Scraping Sammy Morgan...\n",
      "https://www.ufc.com/athlete/sammy-morgan\n",
      "Scraping Peggy Morgan...\n",
      "https://www.ufc.com/athlete/peggy-morgan\n",
      "Scraping Alexander Morgan...\n",
      "https://www.ufc.com/athlete/alexander-morgan\n",
      "Scraping Joe Moriera...\n",
      "https://www.ufc.com/athlete/joe-moriera\n",
      "Scraping Alex Morono...\n",
      "https://www.ufc.com/athlete/alex-morono\n",
      "Scraping Maryna Moroz...\n",
      "https://www.ufc.com/athlete/maryna-moroz\n",
      "Scraping Sergey Morozov...\n",
      "https://www.ufc.com/athlete/sergey-morozov\n",
      "Scraping Brad Morris...\n",
      "https://www.ufc.com/athlete/brad-morris\n",
      "Scraping Scott Morris...\n",
      "https://www.ufc.com/athlete/scott-morris\n",
      "Scraping Anthony Morrison...\n",
      "https://www.ufc.com/athlete/anthony-morrison\n",
      "Scraping Harry Moskowitz...\n",
      "https://www.ufc.com/athlete/harry-moskowitz\n",
      "Scraping Carlos Mota...\n",
      "https://www.ufc.com/athlete/carlos-mota\n",
      "Scraping Nikolas Motta...\n",
      "https://www.ufc.com/athlete/nikolas-motta\n",
      "Scraping Flavio Moura...\n",
      "https://www.ufc.com/athlete/garri-moskovic-0\n",
      "Scraping Eduarda Moura...\n",
      "https://www.ufc.com/athlete/eduarda-moura\n",
      "Scraping Gegard Mousasi...\n",
      "https://www.ufc.com/athlete/gegard-mousasi\n",
      "Scraping Kris Moutinho...\n",
      "https://www.ufc.com/athlete/kris-moutinho\n",
      "Scraping Jamie Moyle...\n",
      "https://www.ufc.com/athlete/jamie-moyle\n",
      "Scraping Askar Mozharov...\n",
      "https://www.ufc.com/athlete/askar-mozharov\n",
      "Scraping Sumudaerji...\n",
      "https://www.ufc.com/athlete/su-mudaerji\n",
      "Scraping Lauren Mueller...\n",
      "https://www.ufc.com/athlete/lauren-mueller\n",
      "Scraping Belal Muhammad...\n",
      "https://www.ufc.com/athlete/belal-muhammad\n",
      "Scraping Quinn Mulhern...\n",
      "https://www.ufc.com/athlete/quinn-mulhern\n",
      "Scraping James Mulheron...\n",
      "https://www.ufc.com/athlete/james-mulheron\n",
      "Scraping Jamie Mullarkey...\n",
      "https://www.ufc.com/athlete/jamie-mullarkey\n",
      "Scraping Jim Mullen...\n",
      "https://www.ufc.com/athlete/garri-moskovic-2\n",
      "Scraping Melissa Mullins...\n",
      "https://www.ufc.com/athlete/melissa-mullins\n",
      "Scraping Pedro Munhoz...\n",
      "https://www.ufc.com/athlete/pedro-munhoz\n",
      "Scraping Andre Muniz...\n",
      "https://www.ufc.com/athlete/andre-muniz\n",
      "Scraping Mark Munoz...\n",
      "https://www.ufc.com/athlete/mark-munoz\n",
      "Scraping Alexander Munoz...\n",
      "https://www.ufc.com/athlete/alexander-munoz\n",
      "Scraping Johnny Munoz...\n",
      "https://www.ufc.com/athlete/johnny-munoz\n",
      "Scraping Olivier Murad...\n",
      "https://www.ufc.com/athlete/olivier-murad\n",
      "Scraping Makhmud Muradov...\n",
      "https://www.ufc.com/athlete/makhmud-muradov\n",
      "Scraping Kanako Murata...\n",
      "https://www.ufc.com/athlete/kanako-murata\n",
      "Scraping Aili Muratbek...\n",
      "https://www.ufc.com/athlete/aili-muratbek\n",
      "Scraping Vince Murdock...\n",
      "https://www.ufc.com/athlete/vince-murdock\n",
      "Scraping Samandar Murodov...\n",
      "https://www.ufc.com/athlete/samandar-murodov\n",
      "Scraping Tom Murphy...\n",
      "https://www.ufc.com/athlete/tom-murphy\n",
      "Scraping Lauren Murphy...\n",
      "https://www.ufc.com/athlete/lauren-murphy\n",
      "Scraping Lerone Murphy...\n",
      "https://www.ufc.com/athlete/lerone-murphy\n",
      "Scraping Lee Murray...\n",
      "https://www.ufc.com/athlete/lee-murray\n",
      "Scraping Jesse Murray...\n",
      "https://www.ufc.com/athlete/jesse-murray\n",
      "Scraping Khalid Murtazaliev...\n",
      "https://www.ufc.com/athlete/khalid-murtazaliev\n",
      "Scraping Azamat Murzakanov...\n",
      "https://www.ufc.com/athlete/azamat-murzakanov\n",
      "Scraping Josias Musasa...\n",
      "https://www.ufc.com/athlete/josias-musasa\n",
      "Scraping Nico Musoke...\n",
      "https://www.ufc.com/athlete/nico-musoke\n",
      "Scraping Magomed Mustafaev...\n",
      "https://www.ufc.com/athlete/magomed-mustafaev\n",
      "Scraping Max Mustaki...\n",
      "https://www.ufc.com/athlete/max-mustaki\n",
      "Scraping Elvis Mutapcic...\n",
      "https://www.ufc.com/athlete/elvis-mutapcic\n",
      "Scraping Przemyslaw Mysiala...\n",
      "https://www.ufc.com/athlete/przemyslaw-mysiala\n",
      "Scraping Muhammad Naimov...\n",
      "https://www.ufc.com/athlete/Muhammad-Naimov\n",
      "Scraping Rin Nakai...\n",
      "https://www.ufc.com/athlete/rin-nakai\n",
      "Scraping Keita Nakamura...\n",
      "https://www.ufc.com/athlete/keita-nakamura\n",
      "Scraping Kazuhiro Nakamura...\n",
      "https://www.ufc.com/athlete/kazuhiro-nakamura\n",
      "Scraping Rinya Nakamura...\n",
      "https://www.ufc.com/athlete/rinya-nakamura\n",
      "Scraping Jutaro Nakao...\n",
      "https://www.ufc.com/athlete/jutaro-nakao\n",
      "Scraping Tyson Nam...\n",
      "https://www.ufc.com/athlete/tyson-nam\n",
      "Scraping Rose Namajunas...\n",
      "https://www.ufc.com/athlete/rose-namajunas\n",
      "Scraping Nad Narimani...\n",
      "https://www.ufc.com/athlete/nad-narimani\n",
      "Scraping Roger Narvaez...\n",
      "https://www.ufc.com/athlete/roger-narvaez\n",
      "Scraping Allan Nascimento...\n",
      "https://www.ufc.com/athlete/allan-nascimento\n",
      "Scraping Rodrigo Nascimento...\n",
      "https://www.ufc.com/athlete/rodrigo-nascimento-ferreira\n",
      "Scraping Bobby Nash...\n",
      "https://www.ufc.com/athlete/bobby-nash\n",
      "Scraping Nasrudin Nasrudinov...\n",
      "https://www.ufc.com/athlete/nasrudin-nasrudinov\n",
      "Scraping Rafael Natal...\n",
      "https://www.ufc.com/athlete/rafael-natal\n",
      "Scraping Kevin Natividad...\n",
      "https://www.ufc.com/athlete/kevin-natividad\n",
      "Scraping Ismail Naurdiev...\n",
      "https://www.ufc.com/athlete/ismail-naurdiev\n",
      "Scraping Reza Nazri...\n",
      "https://www.ufc.com/athlete/kazukhiro-nakamura-0\n",
      "Scraping Tafon Nchukwi...\n",
      "https://www.ufc.com/athlete/tafon-nchukwi\n",
      "Scraping Dustin Neace...\n",
      "https://www.ufc.com/athlete/dustin-neace\n",
      "Scraping Geoff Neal...\n",
      "https://www.ufc.com/athlete/geoff-neal\n",
      "Scraping Stanislav Nedkov...\n",
      "https://www.ufc.com/athlete/stanislav-nedkov\n",
      "Scraping Josh Neer...\n",
      "https://www.ufc.com/athlete/josh-neer\n",
      "Scraping Nicolae Negumereanu...\n",
      "https://www.ufc.com/athlete/nicolae-negumereanu\n",
      "Scraping Nair Nelikyan...\n",
      "https://www.ufc.com/athlete/nair-nelikyan\n",
      "Scraping Steve Nelmark...\n",
      "https://www.ufc.com/athlete/steve-nelmark\n",
      "Scraping Kyle Nelson...\n",
      "https://www.ufc.com/athlete/kyle-nelson\n",
      "Scraping Shane Nelson...\n",
      "https://www.ufc.com/athlete/shane-nelson\n",
      "Scraping Roy Nelson...\n",
      "https://www.ufc.com/athlete/roy-nelson\n",
      "Scraping Gunnar Nelson...\n",
      "https://www.ufc.com/athlete/gunnar-nelson\n",
      "Scraping Antonio Braga Neto...\n",
      "https://www.ufc.com/athlete/antonio-braga-neto\n",
      "Scraping Mario Neto...\n",
      "https://www.ufc.com/athlete/mario-neto\n",
      "Scraping Eduardo Neves...\n",
      "https://www.ufc.com/athlete/eduardo-neves\n",
      "Scraping Nick Newell...\n",
      "https://www.ufc.com/athlete/nick-newell\n",
      "Scraping Journey Newson...\n",
      "https://www.ufc.com/athlete/journey-newson\n",
      "Scraping Jeff Newton...\n",
      "https://www.ufc.com/athlete/jeff-newton\n",
      "Scraping Carlos Newton...\n",
      "https://www.ufc.com/athlete/carlos-newton\n",
      "Scraping Francis Ngannou...\n",
      "https://www.ufc.com/athlete/francis-ngannou\n",
      "Scraping Ben Nguyen...\n",
      "https://www.ufc.com/athlete/ben-nguyen\n",
      "Scraping Steven Nguyen...\n",
      "https://www.ufc.com/athlete/steven-nguyen\n",
      "Scraping Alex Nicholson...\n",
      "https://www.ufc.com/athlete/alex-nicholson\n",
      "Scraping Bo Nickal...\n",
      "https://www.ufc.com/athlete/bo-nickal\n",
      "Scraping Mike Nickels...\n",
      "https://www.ufc.com/athlete/mike-nickels\n",
      "Scraping Matheus Nicolau...\n",
      "https://www.ufc.com/athlete/matheus-nicolau\n",
      "Scraping Stewart Nicoll...\n",
      "https://www.ufc.com/athlete/stewart-nicoll\n",
      "Scraping Jaimee Nievera...\n",
      "https://www.ufc.com/athlete/jaimee-nievera\n",
      "Scraping Tom Niinimaki...\n",
      "https://www.ufc.com/athlete/tom-niinimaki\n",
      "Scraping Ramsey Nijem...\n",
      "https://www.ufc.com/athlete/ramsey-nijem\n",
      "Scraping Mats Nilsson...\n",
      "https://www.ufc.com/athlete/mats-nilsson\n",
      "Scraping Jack Nilsson...\n",
      "https://www.ufc.com/athlete/jack-nilsson\n",
      "Scraping Yamato Nishikawa...\n",
      "https://www.ufc.com/athlete/yamato-nishikawa\n",
      "Scraping Anthony Njokuani...\n",
      "https://www.ufc.com/athlete/anthony-njokuani\n",
      "Scraping Chidi Njokuani...\n",
      "https://www.ufc.com/athlete/chidi-njokuani\n",
      "Scraping Derrick Noble...\n",
      "https://www.ufc.com/athlete/derrick-noble\n",
      "Scraping Kyle Noblitt...\n",
      "https://www.ufc.com/athlete/kyle-noblitt\n",
      "Scraping Pedro Nobre...\n",
      "https://www.ufc.com/athlete/pedro-nobre\n",
      "Scraping Antonio Rogerio Nogueira...\n",
      "https://www.ufc.com/athlete/antonio-rogerio-nogueira\n",
      "Scraping Alexandre Nogueira...\n",
      "https://www.ufc.com/athlete/alexandre-nogueira\n",
      "Scraping Minotauro Nogueira...\n",
      "https://www.ufc.com/athlete/minotauro-nogueira\n",
      "Scraping Kyle Noke...\n",
      "https://www.ufc.com/athlete/kyle-noke\n",
      "Scraping Tom Nolan...\n",
      "https://www.ufc.com/athlete/tom-nolan\n",
      "Scraping KJ Noons...\n",
      "https://www.ufc.com/athlete/kj-noons\n",
      "Scraping Sage Northcutt...\n",
      "https://www.ufc.com/athlete/sage-northcutt\n",
      "Scraping Shohei Nose...\n",
      "https://www.ufc.com/athlete/shohei-nose\n",
      "Scraping Jason Novelli...\n",
      "https://www.ufc.com/athlete/jason-novelli\n",
      "Scraping Phillipe Nover...\n",
      "https://www.ufc.com/athlete/phillipe-nover\n",
      "Scraping Taiyilake Nueraji...\n",
      "https://www.ufc.com/athlete/taiyilake-nueraji\n",
      "Scraping Shayilan Nuerdanbieke...\n",
      "https://www.ufc.com/athlete/shayilan-nuerdanbieke\n",
      "Scraping Istela Nunes...\n",
      "https://www.ufc.com/athlete/istela-nunes\n",
      "Scraping Diego Nunes...\n",
      "https://www.ufc.com/athlete/diego-nunes\n",
      "Scraping Amanda Nunes...\n",
      "https://www.ufc.com/athlete/amanda-nunes\n",
      "Scraping Josiane Nunes...\n",
      "https://www.ufc.com/athlete/josiane-nunes\n",
      "Scraping Abubakar Nurmagomedov...\n",
      "https://www.ufc.com/athlete/abubakar-nurmagomedov\n",
      "Scraping Said Nurmagomedov...\n",
      "https://www.ufc.com/athlete/said-nurmagomedov\n",
      "Scraping Khabib Nurmagomedov...\n",
      "https://www.ufc.com/athlete/khabib-nurmagomedov\n",
      "Scraping Umar Nurmagomedov...\n",
      "https://www.ufc.com/athlete/umar-nurmagomedov\n",
      "Scraping Kennedy Nzechukwu...\n",
      "https://www.ufc.com/athlete/kennedy-nzechukwu\n",
      "Scraping TJ O'Brien...\n",
      "https://www.ufc.com/athlete/tj-obrien\n",
      "Scraping Jake O'Brien...\n",
      "https://www.ufc.com/athlete/jake-obrien\n",
      "Scraping Sean O'Connell...\n",
      "https://www.ufc.com/athlete/sean-oconnell\n",
      "Scraping Sean O'Malley...\n",
      "https://www.ufc.com/athlete/sean-omalley\n",
      "Scraping Chuck O'Neil...\n",
      "https://www.ufc.com/athlete/chuck-oneil\n",
      "Scraping Casey O'Neill...\n",
      "https://www.ufc.com/athlete/casey-oneill\n",
      "Scraping Brendan O'Reilly...\n",
      "https://www.ufc.com/athlete/brendan-oreilly\n",
      "Scraping Jose Ochoa...\n",
      "https://www.ufc.com/athlete/jose-ochoa\n",
      "Scraping Christian Ocon...\n",
      "https://www.ufc.com/athlete/christian-ocon\n",
      "Scraping Richard Odoms...\n",
      "https://www.ufc.com/athlete/richard-odoms\n",
      "Scraping Volkan Oezdemir...\n",
      "https://www.ufc.com/athlete/volkan-oezdemir\n",
      "Scraping Kaan Ofli...\n",
      "https://www.ufc.com/athlete/kaan-ofli\n",
      "Scraping Trey Ogden...\n",
      "https://www.ufc.com/athlete/trey-ogden\n",
      "Scraping Andy Ogle...\n",
      "https://www.ufc.com/athlete/andy-ogle\n",
      "Scraping Ho Taek Oh...\n",
      "https://www.ufc.com/athlete/ho-taek-oh\n",
      "Scraping Koji Oishi...\n",
      "https://www.ufc.com/athlete/koji-oishi\n",
      "Scraping Yushin Okami...\n",
      "https://www.ufc.com/athlete/yushin-okami\n",
      "Scraping JJ Okanovich...\n",
      "https://www.ufc.com/athlete/jj-okanovich\n",
      "Scraping Bolaji Oki...\n",
      "https://www.ufc.com/athlete/bolaji-oki\n",
      "Scraping Aleksei Oleinik...\n",
      "https://www.ufc.com/athlete/aleksei-oleinik\n",
      "Scraping Michal Oleksiejczuk...\n",
      "https://www.ufc.com/athlete/michal-oleksiejczuk\n",
      "Scraping Maria Oliveira...\n",
      "https://www.ufc.com/athlete/maria-oliveira\n",
      "Scraping Rafaello Oliveira...\n",
      "https://www.ufc.com/athlete/rafaello-oliveira\n",
      "Scraping Wendell Oliveira...\n",
      "https://www.ufc.com/athlete/wendell-oliveira\n",
      "Scraping Alex Oliveira...\n",
      "https://www.ufc.com/athlete/alex-oliveira\n",
      "Scraping Ednaldo Oliveira...\n",
      "https://www.ufc.com/athlete/ednaldo-oliveira\n",
      "Scraping Vinicius Oliveira...\n",
      "https://www.ufc.com/athlete/vinicius-oliveira\n",
      "Scraping Saimon Oliveira...\n",
      "https://www.ufc.com/athlete/saimon-oliveira\n",
      "Scraping Bruno Oliveira...\n",
      "https://www.ufc.com/athlete/bruno-oliveira\n",
      "Scraping Charles Oliveira...\n",
      "https://www.ufc.com/athlete/charles-oliveira\n",
      "Scraping Ravena Oliveira...\n",
      "https://www.ufc.com/athlete/ravena-oliveira\n",
      "Scraping Felipe Olivieri...\n",
      "https://www.ufc.com/athlete/felipe-olivieri\n",
      "Scraping Cameron Olson...\n",
      "https://www.ufc.com/athlete/cameron-olson\n",
      "Scraping Ode Osbourne...\n",
      "https://www.ufc.com/athlete/ode-osbourne\n",
      "Scraping Nick Osipczak...\n",
      "https://www.ufc.com/athlete/nick-osipczak\n",
      "Scraping Nissen Osterneck...\n",
      "https://www.ufc.com/athlete/nissen-osterneck\n",
      "Scraping Rachael Ostovich...\n",
      "https://www.ufc.com/athlete/rachael-ostovich\n",
      "Scraping Zak Ottow...\n",
      "https://www.ufc.com/athlete/zak-ottow\n",
      "Scraping Sidney Outlaw...\n",
      "https://www.ufc.com/athlete/sidney-outlaw\n",
      "Scraping Alistair Overeem...\n",
      "https://www.ufc.com/athlete/alistair-overeem\n",
      "Scraping Alptekin Ozkilic...\n",
      "https://www.ufc.com/athlete/alptekin-ozkilic\n",
      "Scraping Nick Pace...\n",
      "https://www.ufc.com/athlete/nick-pace\n",
      "Scraping Larissa Pacheco...\n",
      "https://www.ufc.com/athlete/larissa-pacheco\n",
      "Scraping Angel Pacheco...\n",
      "https://www.ufc.com/athlete/angel-pacheco\n",
      "Scraping Teemu Packalen...\n",
      "https://www.ufc.com/athlete/teemu-packalen\n",
      "Scraping Chris Padilla...\n",
      "https://www.ufc.com/athlete/chris-padilla\n",
      "Scraping Fernando Padilla...\n",
      "https://www.ufc.com/athlete/fernando-padilla\n",
      "Scraping Michael Page...\n",
      "https://www.ufc.com/athlete/michael-page\n",
      "Scraping Dustin Pague...\n",
      "https://www.ufc.com/athlete/dustin-pague\n",
      "Scraping Raulian Paiva...\n",
      "https://www.ufc.com/athlete/raulian-paiva\n",
      "Scraping Dinis Paiva...\n",
      "https://www.ufc.com/athlete/dinis-paiva\n",
      "Scraping Fredson Paixao...\n",
      "https://www.ufc.com/athlete/fredson-paixao\n",
      "Scraping Luis Pajuelo...\n",
      "https://www.ufc.com/athlete/luis-pajuelo\n",
      "Scraping Rick Palacios...\n",
      "https://www.ufc.com/athlete/rick-palacios\n",
      "Scraping Bart Palaszewski...\n",
      "https://www.ufc.com/athlete/bart-palaszewski\n",
      "Scraping Sasha Palatnikov...\n",
      "https://www.ufc.com/athlete/sasha-palatnikov\n",
      "Scraping Soa Palelei...\n",
      "https://www.ufc.com/athlete/soa-palelei\n",
      "Scraping Tulio Palhares...\n",
      "https://www.ufc.com/athlete/nissen-osternek-0\n",
      "Scraping Rousimar Palhares...\n",
      "https://www.ufc.com/athlete/rousimar-palhares\n",
      "Scraping Alexandre Pantoja...\n",
      "https://www.ufc.com/athlete/alexandre-pantoja\n",
      "Scraping Jared Papazian...\n",
      "https://www.ufc.com/athlete/jared-papazian\n",
      "Scraping Kathryn Paprocki...\n",
      "https://www.ufc.com/athlete/kathryn-paprocki\n",
      "Scraping Joe Pardo...\n",
      "https://www.ufc.com/athlete/nissen-osternek-1\n",
      "Scraping Remco Pardoel...\n",
      "https://www.ufc.com/athlete/remco-pardoel\n",
      "Scraping Josh Parisian...\n",
      "https://www.ufc.com/athlete/josh-parisian\n",
      "Scraping Karo Parisyan...\n",
      "https://www.ufc.com/athlete/karo-parisyan\n",
      "Scraping HyunSung Park...\n",
      "https://www.ufc.com/athlete/hyunsung-park\n",
      "Scraping Jae Hyun Park...\n",
      "https://www.ufc.com/athlete/jae-hyun-park\n",
      "Scraping Harvey Park...\n",
      "https://www.ufc.com/athlete/harvey-park\n",
      "Scraping JunYong Park...\n",
      "https://www.ufc.com/athlete/jun-yong-park\n",
      "Scraping Norman Parke...\n",
      "https://www.ufc.com/athlete/norman-parke\n",
      "Scraping Ryan Parker...\n",
      "https://www.ufc.com/athlete/nissen-osternek-3\n",
      "Scraping Mick Parkin...\n",
      "https://www.ufc.com/athlete/mick-parkin\n",
      "Scraping Jonny Parsons...\n",
      "https://www.ufc.com/athlete/jonny-parsons\n",
      "Scraping Preston Parsons...\n",
      "https://www.ufc.com/athlete/preston-parsons\n",
      "Scraping Onassis Parungao...\n",
      "https://www.ufc.com/athlete/remko-pardoel-0\n",
      "Scraping Ramona Pascual...\n",
      "https://www.ufc.com/athlete/ramona-pascual\n",
      "Scraping Billy Pasulatan...\n",
      "https://www.ufc.com/athlete/billy-pasulatan\n",
      "Scraping Jhonoven Pati...\n",
      "https://www.ufc.com/athlete/jhonoven-pati\n",
      "Scraping Wendri Patilima...\n",
      "https://www.ufc.com/athlete/wendri-patilima\n",
      "Scraping Jorge Patino...\n",
      "https://www.ufc.com/athlete/jorge-patino\n",
      "Scraping Claude Patrick...\n",
      "https://www.ufc.com/athlete/claude-patrick\n",
      "Scraping Alan Patrick...\n",
      "https://www.ufc.com/athlete/alan-patrick\n",
      "Scraping Michael Patt...\n",
      "https://www.ufc.com/athlete/michael-patt\n",
      "Scraping Sam Patterson...\n",
      "https://www.ufc.com/athlete/sam-patterson\n",
      "Scraping Zac Pauga...\n",
      "https://www.ufc.com/athlete/zac-pauga\n",
      "Scraping Julio Paulino...\n",
      "https://www.ufc.com/athlete/julio-paulino\n",
      "Scraping Thomas Paull...\n",
      "https://www.ufc.com/athlete/thomas-paull\n",
      "Scraping Sergei Pavlovich...\n",
      "https://www.ufc.com/athlete/sergei-pavlovich\n",
      "Scraping Pawel Pawlak...\n",
      "https://www.ufc.com/athlete/pawel-pawlak\n",
      "Scraping Estevan Payan...\n",
      "https://www.ufc.com/athlete/ernest-chavez-1\n",
      "Scraping Roland Payne...\n",
      "https://www.ufc.com/athlete/roland-payne\n",
      "Scraping Jonathan Pearce...\n",
      "https://www.ufc.com/athlete/jonathan-pearce\n",
      "Scraping Ross Pearson...\n",
      "https://www.ufc.com/athlete/ross-pearson\n",
      "Scraping Andre Pederneiras...\n",
      "https://www.ufc.com/athlete/andre-pederneiras\n",
      "Scraping Carlo Pedersoli...\n",
      "https://www.ufc.com/athlete/carlo-pedersoli\n",
      "Scraping Tyson Pedro...\n",
      "https://www.ufc.com/athlete/tyson-pedro\n",
      "Scraping Trevor Peek...\n",
      "https://www.ufc.com/athlete/trevor-peek\n",
      "Scraping Filip Pejic...\n",
      "https://www.ufc.com/athlete/filip-pejic\n",
      "Scraping Kurt Pellegrino...\n",
      "https://www.ufc.com/athlete/kurt-pellegrino\n",
      "Scraping Luis Pena...\n",
      "https://www.ufc.com/athlete/luis-pena\n",
      "Scraping Julianna Pea...\n",
      "https://www.ufc.com/athlete/julianna-pena\n",
      "Scraping Matj Pez...\n",
      "https://www.ufc.com/athlete/matej-penaz\n",
      "Scraping Sherman Pendergarst...\n",
      "https://www.ufc.com/athlete/sherman-pendergarst\n",
      "Scraping Cathal Pendred...\n",
      "https://www.ufc.com/athlete/cathal-pendred\n",
      "Scraping Feng Pengchao...\n",
      "https://www.ufc.com/athlete/feng-pengchao\n",
      "Scraping BJ Penn...\n",
      "https://www.ufc.com/athlete/bj-penn\n",
      "Scraping Jessica Penne...\n",
      "https://www.ufc.com/athlete/shieshika-hene\n",
      "Scraping Nick Penner...\n",
      "https://www.ufc.com/athlete/nick-penner\n",
      "Scraping Tecia Pennington...\n",
      "https://www.ufc.com/athlete/tecia-pennington\n",
      "Scraping Raquel Pennington...\n",
      "https://www.ufc.com/athlete/raquel-pennington\n",
      "Scraping Robbie Peralta...\n",
      "https://www.ufc.com/athlete/robbie-peralta\n",
      "Scraping Alberto Pereira...\n",
      "https://www.ufc.com/athlete/alberto-pereira\n",
      "Scraping Viviane Pereira...\n",
      "https://www.ufc.com/athlete/viviane-pereira\n",
      "Scraping Daniel Pereira...\n",
      "https://www.ufc.com/athlete/daniel-pereira\n",
      "Scraping Alex Pereira...\n",
      "https://www.ufc.com/athlete/alex-pereira\n",
      "Scraping Michel Pereira...\n",
      "https://www.ufc.com/athlete/michel-pereira\n",
      "Scraping Alejandro Prez...\n",
      "https://www.ufc.com/athlete/alejandro-perez\n",
      "Scraping Frankie Perez...\n",
      "https://www.ufc.com/athlete/frankie-perez\n",
      "Scraping Markus Perez...\n",
      "https://www.ufc.com/athlete/markus-perez\n",
      "Scraping Erik Perez...\n",
      "https://www.ufc.com/athlete/erik-perez\n",
      "Scraping Ailin Perez...\n",
      "https://www.ufc.com/athlete/ailin-perez\n",
      "Scraping Alex Perez...\n",
      "https://www.ufc.com/athlete/alex-perez\n",
      "Scraping Anthony Perosh...\n",
      "https://www.ufc.com/athlete/anthony-perosh\n",
      "Scraping Hernani Perpetuo...\n",
      "https://www.ufc.com/athlete/hernani-perpetuo\n",
      "Scraping Thiago Perptuo...\n",
      "https://www.ufc.com/athlete/thiago-perpetuo\n",
      "Scraping Jay Perrin...\n",
      "https://www.ufc.com/athlete/jay-perrin\n",
      "Scraping Mike Perry...\n",
      "https://www.ufc.com/athlete/mike-perry\n",
      "Scraping Raphael Pessoa Nunes...\n",
      "https://www.ufc.com/athlete/raphael-pessoa-nunes\n",
      "Scraping Viktor Pesta...\n",
      "https://www.ufc.com/athlete/viktor-pesta\n",
      "Scraping Tony Peterra...\n",
      "https://www.ufc.com/athlete/tiago-perpetuo\n",
      "Scraping Emily Peters Kagan...\n",
      "https://www.ufc.com/athlete/emily-peters-kagan\n",
      "Scraping Thomas Petersen...\n",
      "https://www.ufc.com/athlete/thomas-petersen\n",
      "Scraping Steven Peterson...\n",
      "https://www.ufc.com/athlete/steven-peterson\n",
      "Scraping Vitor Petrino...\n",
      "https://www.ufc.com/athlete/vitor-petrino\n",
      "Scraping Andre Petroski...\n",
      "https://www.ufc.com/athlete/andre-petroski\n",
      "Scraping Armen Petrosyan...\n",
      "https://www.ufc.com/athlete/armen-petrosyan\n",
      "Scraping Ivana Petrovic...\n",
      "https://www.ufc.com/athlete/ivana-petrovic\n",
      "Scraping Seth Petruzelli...\n",
      "https://www.ufc.com/athlete/seth-petruzelli\n",
      "Scraping Peter Petties...\n",
      "https://www.ufc.com/athlete/peter-petties\n",
      "Scraping Sergio Pettis...\n",
      "https://www.ufc.com/athlete/sergio-pettis\n",
      "Scraping Anthony Pettis...\n",
      "https://www.ufc.com/athlete/anthony-pettis\n",
      "Scraping Forrest Petz...\n",
      "https://www.ufc.com/athlete/forrest-petz\n",
      "Scraping Cody Pfister...\n",
      "https://www.ufc.com/athlete/cody-pfister\n",
      "Scraping Nam Phan...\n",
      "https://www.ufc.com/athlete/nam-phan\n",
      "Scraping Costas Philippou...\n",
      "https://www.ufc.com/athlete/costas-philippou\n",
      "Scraping Elizabeth Phillips...\n",
      "https://www.ufc.com/athlete/elizabeth-phillips\n",
      "Scraping Aaron Phillips...\n",
      "https://www.ufc.com/athlete/aaron-phillips\n",
      "Scraping John Phillips...\n",
      "https://www.ufc.com/athlete/john-phillips\n",
      "Scraping Kyler Phillips...\n",
      "https://www.ufc.com/athlete/kyler-phillips\n",
      "Scraping Vinc Pichel...\n",
      "https://www.ufc.com/athlete/vinc-pichel\n",
      "Scraping Brad Pickett...\n",
      "https://www.ufc.com/athlete/brad-pickett\n",
      "Scraping Jamie Pickett...\n",
      "https://www.ufc.com/athlete/jamie-pickett\n",
      "Scraping Fabiola Pidroni...\n",
      "https://www.ufc.com/athlete/fabiola-pidroni\n",
      "Scraping Oskar Piechota...\n",
      "https://www.ufc.com/athlete/oskar-piechota\n",
      "Scraping Mike Pierce...\n",
      "https://www.ufc.com/athlete/mike-pierce\n",
      "Scraping Joao Pierini...\n",
      "https://www.ufc.com/athlete/joao-pierini\n",
      "Scraping Sean Pierson...\n",
      "https://www.ufc.com/athlete/sean-pierson\n",
      "Scraping Domingo Pilarte...\n",
      "https://www.ufc.com/athlete/domingo-pilarte\n",
      "Scraping Paddy Pimblett...\n",
      "https://www.ufc.com/athlete/paddy-pimblett\n",
      "Scraping Daniel Pineda...\n",
      "https://www.ufc.com/athlete/daniel-pineda\n",
      "Scraping Jesus Pinedo...\n",
      "https://www.ufc.com/athlete/jesus-pinedo\n",
      "Scraping Luana Pinheiro...\n",
      "https://www.ufc.com/athlete/luana-pinheiro\n",
      "Scraping Mario Pinto...\n",
      "https://www.ufc.com/athlete/mario-pinto\n",
      "Scraping Gaetano Pirrello...\n",
      "https://www.ufc.com/athlete/gaetano-pirrello\n",
      "Scraping Maki Pitolo...\n",
      "https://www.ufc.com/athlete/maki-pitolo\n",
      "Scraping Dmitry Poberezhets...\n",
      "https://www.ufc.com/athlete/dmitry-poberezhets\n",
      "Scraping Jamal Pogues...\n",
      "https://www.ufc.com/athlete/jamal-pogues\n",
      "Scraping Ross Pointon...\n",
      "https://www.ufc.com/athlete/ross-pointon\n",
      "Scraping Dustin Poirier...\n",
      "https://www.ufc.com/athlete/dustin-poirier\n",
      "Scraping Igor Pokrajac...\n",
      "https://www.ufc.com/athlete/igor-pokrajac\n",
      "Scraping John Polakowski...\n",
      "https://www.ufc.com/athlete/john-polakowski\n",
      "Scraping Julia Polastri...\n",
      "https://www.ufc.com/athlete/julia-polastri\n",
      "Scraping Santiago Ponzinibbio...\n",
      "https://www.ufc.com/athlete/santiago-ponzinibbio\n",
      "Scraping Grigory Popov...\n",
      "https://www.ufc.com/athlete/grigory-popov\n",
      "Scraping Alexander Poppeck...\n",
      "https://www.ufc.com/athlete/alexander-poppeck\n",
      "Scraping Parker Porter...\n",
      "https://www.ufc.com/athlete/parker-porter\n",
      "Scraping Ihor Potieria...\n",
      "https://www.ufc.com/athlete/ihor-potieria\n",
      "Scraping Callan Potter...\n",
      "https://www.ufc.com/athlete/callan-potter\n",
      "Scraping Dylan Potter...\n",
      "https://www.ufc.com/athlete/dylan-potter\n",
      "Scraping Ruan Potts...\n",
      "https://www.ufc.com/athlete/ruan-potts\n",
      "Scraping Devin Powell...\n",
      "https://www.ufc.com/athlete/devin-powell\n",
      "Scraping Marcin Prachnio...\n",
      "https://www.ufc.com/athlete/marcin-prachnio\n",
      "Scraping Wagner Prado...\n",
      "https://www.ufc.com/athlete/volkan-ozdemir-1\n",
      "Scraping Francisco Prado...\n",
      "https://www.ufc.com/athlete/francisco-prado\n",
      "Scraping Trevor Prangley...\n",
      "https://www.ufc.com/athlete/trevor-prangley\n",
      "Scraping Ricardo Prasel...\n",
      "https://www.ufc.com/athlete/ricardo-prasel\n",
      "Scraping Rana Rudra Pratap Singh...\n",
      "https://www.ufc.com/athlete/rana-rudra-pratap-singh\n",
      "Scraping Carlo Prater...\n",
      "https://www.ufc.com/athlete/carlo-prater\n",
      "Scraping Carlos Prates...\n",
      "https://www.ufc.com/athlete/carlos-prates\n",
      "Scraping Michel Prazeres...\n",
      "https://www.ufc.com/athlete/michel-prazeres\n",
      "Scraping Kyle Prepolec...\n",
      "https://www.ufc.com/athlete/kyle-prepolec\n",
      "Scraping Dorian Price...\n",
      "https://www.ufc.com/athlete/dorian-price\n",
      "Scraping Chris Price...\n",
      "https://www.ufc.com/athlete/chris-price\n",
      "Scraping Niko Price...\n",
      "https://www.ufc.com/athlete/niko-price\n",
      "Scraping Shane Primm...\n",
      "https://www.ufc.com/athlete/shane-primm\n",
      "Scraping Ji Prochzka...\n",
      "https://www.ufc.com/athlete/jiri-prochazka\n",
      "Scraping Lara Procopio...\n",
      "https://www.ufc.com/athlete/lara-procopio\n",
      "Scraping Joe Proctor...\n",
      "https://www.ufc.com/athlete/joe-proctor\n",
      "Scraping Lucie Pudilova...\n",
      "https://www.ufc.com/athlete/lucie-pudilova\n",
      "Scraping Claudio Puelles...\n",
      "https://www.ufc.com/athlete/claudio-puelles\n",
      "Scraping Juan Puerta...\n",
      "https://www.ufc.com/athlete/juan-puerta\n",
      "Scraping Juan Puig...\n",
      "https://www.ufc.com/athlete/juan-puig\n",
      "Scraping Jens Pulver...\n",
      "https://www.ufc.com/athlete/jens-pulver\n",
      "Scraping CM Punk...\n",
      "https://www.ufc.com/athlete/cm-punk\n",
      "Scraping Joe Pyfer...\n",
      "https://www.ufc.com/athlete/joe-pyfer\n",
      "Scraping Mike Pyle...\n",
      "https://www.ufc.com/athlete/mike-pyle\n",
      "Scraping Billy Quarantillo...\n",
      "https://www.ufc.com/athlete/billy-quarantillo\n",
      "Scraping Nate Quarry...\n",
      "https://www.ufc.com/athlete/nate-quarry\n",
      "Scraping Vinicius Queiroz...\n",
      "https://www.ufc.com/athlete/vinicius-queiroz\n",
      "Scraping Jimmy Quinlan...\n",
      "https://www.ufc.com/athlete/jimmy-quinlan\n",
      "Scraping Josh Quinlan...\n",
      "https://www.ufc.com/athlete/josh-quinlan\n",
      "Scraping Michel Quinones...\n",
      "https://www.ufc.com/athlete/michel-quinones\n",
      "Scraping Landon Quinones...\n",
      "https://www.ufc.com/athlete/landon-quinones\n",
      "Scraping Jose Quinonez...\n",
      "https://www.ufc.com/athlete/jose-quinonez\n",
      "Scraping Cristian Quionez...\n",
      "https://www.ufc.com/athlete/cristian-quinonez\n",
      "Scraping Benji Radach...\n",
      "https://www.ufc.com/athlete/benji-radach\n",
      "Scraping Jordan Radev...\n",
      "https://www.ufc.com/athlete/jordan-radev\n",
      "Scraping Charles Radtke...\n",
      "https://www.ufc.com/athlete/charles-radtke\n",
      "Scraping Loik Radzhabov...\n",
      "https://www.ufc.com/athlete/loik-radzhabov\n",
      "Scraping Josh Raferty...\n",
      "https://www.ufc.com/athlete/josh-raferty\n",
      "Scraping Ricky Rainey...\n",
      "https://www.ufc.com/athlete/ricky-rainey\n",
      "Scraping Shavkat Rakhmonov...\n",
      "https://www.ufc.com/athlete/shavkat-rakhmonov\n",
      "Scraping Aleksandar Raki...\n",
      "https://www.ufc.com/athlete/aleksandar-rakic\n",
      "Scraping Jessica Rakoczy...\n",
      "https://www.ufc.com/athlete/jessica-rakoczy\n",
      "Scraping Zygimantas Ramaska...\n",
      "https://www.ufc.com/athlete/zygimantas-ramaska\n",
      "Scraping Thomas Ramirez...\n",
      "https://www.ufc.com/athlete/thomas-ramirez\n",
      "Scraping Hector Ramirez...\n",
      "https://www.ufc.com/athlete/hector-ramirez\n",
      "Scraping Mitch Ramirez...\n",
      "https://www.ufc.com/athlete/mitch-ramirez\n",
      "Scraping Davi Ramos...\n",
      "https://www.ufc.com/athlete/davi-ramos\n",
      "Scraping Ricardo Ramos...\n",
      "https://www.ufc.com/athlete/ricardo-ramos\n",
      "Scraping Vernon Ramos...\n",
      "https://www.ufc.com/athlete/vernon-ramos\n",
      "Scraping Luis Ramos...\n",
      "https://www.ufc.com/athlete/luis-ramos\n",
      "Scraping Kevin Randleman...\n",
      "https://www.ufc.com/athlete/kevin-randleman\n",
      "Scraping Mitch Raposo...\n",
      "https://www.ufc.com/athlete/mitch-raposo\n",
      "Scraping Bec Rawlings...\n",
      "https://www.ufc.com/athlete/bec-rawlings\n",
      "Scraping Stevie Ray...\n",
      "https://www.ufc.com/athlete/stevie-ray\n",
      "Scraping Gideon Ray...\n",
      "https://www.ufc.com/athlete/gideon-ray\n",
      "Scraping Mateusz Rbecki...\n",
      "https://www.ufc.com/athlete/mateusz-rebecki\n",
      "Scraping Greg Rebello...\n",
      "https://www.ufc.com/athlete/greg-rebello\n",
      "Scraping Paul Redmond...\n",
      "https://www.ufc.com/athlete/paul-redmond\n",
      "Scraping Elise Reed...\n",
      "https://www.ufc.com/athlete/elise-reed\n",
      "Scraping Karl Reed...\n",
      "https://www.ufc.com/athlete/karl-reed\n",
      "Scraping Johnny Rees...\n",
      "https://www.ufc.com/athlete/johnny-rees\n",
      "Scraping Zachary Reese...\n",
      "https://www.ufc.com/athlete/zachary-reese\n",
      "Scraping Steve Regman...\n",
      "https://www.ufc.com/athlete/steve-regman\n",
      "Scraping Chad Reiner...\n",
      "https://www.ufc.com/athlete/chad-reiner\n",
      "Scraping Jason Reinhardt...\n",
      "https://www.ufc.com/athlete/jason-reinhardt\n",
      "Scraping Wilson Reis...\n",
      "https://www.ufc.com/athlete/wilson-reis\n",
      "Scraping Leigh Remedios...\n",
      "https://www.ufc.com/athlete/leigh-remedios\n",
      "Scraping Paulo Renato Jr....\n",
      "https://www.ufc.com/athlete/paulo-renato-jr\n",
      "Scraping Chance Rencountre...\n",
      "https://www.ufc.com/athlete/chance-rencountre\n",
      "Scraping Marion Reneau...\n",
      "https://www.ufc.com/athlete/marion-reneau\n",
      "Scraping Solomon Renfro...\n",
      "https://www.ufc.com/athlete/solomon-renfro\n",
      "Scraping Alex Reyes...\n",
      "https://www.ufc.com/athlete/alex-reyes\n",
      "Scraping Marco Polo Reyes...\n",
      "https://www.ufc.com/athlete/marco-polo-reyes\n",
      "Scraping Jon Delos Reyes...\n",
      "https://www.ufc.com/athlete/jon-delos-reyes\n",
      "Scraping Kyle Reyes...\n",
      "https://www.ufc.com/athlete/kyle-reyes\n",
      "Scraping Dominick Reyes...\n",
      "https://www.ufc.com/athlete/dominick-reyes\n",
      "Scraping Victor Reyna...\n",
      "https://www.ufc.com/athlete/victor-reyna\n",
      "Scraping Johnny Rhodes...\n",
      "https://www.ufc.com/athlete/johnny-rhodes\n",
      "Scraping Mike Rhodes...\n",
      "https://www.ufc.com/athlete/mike-rhodes\n",
      "Scraping Lucrezia Ria...\n",
      "https://www.ufc.com/athlete/lucrezia-ria\n",
      "Scraping Amanda Ribas...\n",
      "https://www.ufc.com/athlete/amanda-ribas\n",
      "Scraping Brendson Ribeiro...\n",
      "https://www.ufc.com/athlete/brendson-ribeiro\n",
      "Scraping Claudio Ribeiro...\n",
      "https://www.ufc.com/athlete/claudio-ribeiro\n",
      "Scraping Esteban Ribovics...\n",
      "https://www.ufc.com/athlete/esteban-ribovics\n",
      "Scraping Alessandro Ricci...\n",
      "https://www.ufc.com/athlete/alessandro-ricci\n",
      "Scraping Mike Ricci...\n",
      "https://www.ufc.com/athlete/mayk-russo-0\n",
      "Scraping Tabatha Ricci...\n",
      "https://www.ufc.com/athlete/tabatha-ricci\n",
      "Scraping Brad Riddell...\n",
      "https://www.ufc.com/athlete/brad-riddell\n",
      "Scraping Matthew Riddle...\n",
      "https://www.ufc.com/athlete/matthew-riddle\n",
      "Scraping Joe Riggs...\n",
      "https://www.ufc.com/athlete/joe-riggs\n",
      "Scraping Aaron Riley...\n",
      "https://www.ufc.com/athlete/aaron-riley\n",
      "Scraping Jordan Rinaldi...\n",
      "https://www.ufc.com/athlete/jordan-rinaldi\n",
      "Scraping Nick Ring...\n",
      "https://www.ufc.com/athlete/nick-ring\n",
      "Scraping Robbie Ring...\n",
      "https://www.ufc.com/athlete/robbie-ring\n",
      "Scraping Mike Rio...\n",
      "https://www.ufc.com/athlete/mike-rio\n",
      "Scraping Diego Rivas...\n",
      "https://www.ufc.com/athlete/diego-rivas\n",
      "Scraping Francisco Rivera...\n",
      "https://www.ufc.com/athlete/francisco-rivera\n",
      "Scraping Dante Rivera...\n",
      "https://www.ufc.com/athlete/dante-rivera\n",
      "Scraping Jimmie Rivera...\n",
      "https://www.ufc.com/athlete/jimmie-rivera\n",
      "Scraping Jorge Rivera...\n",
      "https://www.ufc.com/athlete/jorge-rivera\n",
      "Scraping Jerome Rivera...\n",
      "https://www.ufc.com/athlete/jerome-rivera\n",
      "Scraping Irwin Rivera...\n",
      "https://www.ufc.com/athlete/irwin-rivera\n",
      "Scraping Pedro Rizzo...\n",
      "https://www.ufc.com/athlete/pedro-rizzo\n",
      "Scraping Theo Rlayang...\n",
      "https://www.ufc.com/athlete/theo-rlayang\n",
      "Scraping Kali Robbins...\n",
      "https://www.ufc.com/athlete/kali-robbins\n",
      "Scraping Karl Roberson...\n",
      "https://www.ufc.com/athlete/karl-roberson\n",
      "Scraping Roosevelt Roberts...\n",
      "https://www.ufc.com/athlete/roosevelt-roberts\n",
      "Scraping Daniel Roberts...\n",
      "https://www.ufc.com/athlete/daniel-roberts\n",
      "Scraping Tyrone Roberts...\n",
      "https://www.ufc.com/athlete/dante-rivera-1\n",
      "Scraping Joey Roberts...\n",
      "https://www.ufc.com/athlete/tomas-ramirez-0\n",
      "Scraping Andre Roberts...\n",
      "https://www.ufc.com/athlete/andre-roberts\n",
      "Scraping Danny Roberts...\n",
      "https://www.ufc.com/athlete/danny-roberts\n",
      "Scraping Buddy Roberts...\n",
      "https://www.ufc.com/athlete/buddy-roberts\n",
      "Scraping Keifer Roberts...\n",
      "https://www.ufc.com/athlete/keifer-roberts\n",
      "Scraping Kenny Robertson...\n",
      "https://www.ufc.com/athlete/kenny-robertson\n",
      "Scraping Gillian Robertson...\n",
      "https://www.ufc.com/athlete/gillian-robertson\n",
      "Scraping Alvin Robinson...\n",
      "https://www.ufc.com/athlete/alvin-robinson\n",
      "Scraping Colin Robinson...\n",
      "https://www.ufc.com/athlete/colin-robinson\n",
      "Scraping Mark David Robinson...\n",
      "https://www.ufc.com/athlete/mark-david-robinson\n",
      "Scraping Carlos Eduardo Rocha...\n",
      "https://www.ufc.com/athlete/carlos-eduardo-rocha\n",
      "Scraping Vagner Rocha...\n",
      "https://www.ufc.com/athlete/vagner-rocha\n",
      "Scraping Lucas Rocha...\n",
      "https://www.ufc.com/athlete/lucas-rocha\n",
      "Scraping Keith Rockel...\n",
      "https://www.ufc.com/athlete/keith-rockel\n",
      "Scraping Luke Rockhold...\n",
      "https://www.ufc.com/athlete/ruku-rotsukuhoruto\n",
      "Scraping Gregory Rodrigues...\n",
      "https://www.ufc.com/athlete/gregory-rodrigues\n",
      "Scraping Kleydson Rodrigues...\n",
      "https://www.ufc.com/athlete/kleidison-rodrigues\n",
      "Scraping Ricco Rodriguez...\n",
      "https://www.ufc.com/athlete/ricco-rodriguez\n",
      "Scraping Mike Rodriguez...\n",
      "https://www.ufc.com/athlete/mike-rodriguez\n",
      "Scraping Manuel Rodriguez...\n",
      "https://www.ufc.com/athlete/manuel-rodriguez\n",
      "Scraping Paul Rodriguez...\n",
      "https://www.ufc.com/athlete/paul-rodriguez\n",
      "Scraping Piera Rodriguez...\n",
      "https://www.ufc.com/athlete/piera-rodriguez\n",
      "Scraping Pete Rodriguez...\n",
      "https://www.ufc.com/athlete/pete-rodriguez\n",
      "Scraping Drako Rodriguez...\n",
      "https://www.ufc.com/athlete/drako-rodriguez\n",
      "Scraping Ronaldo Rodriguez...\n",
      "https://www.ufc.com/athlete/luis-rodriguez\n",
      "Scraping Christian Rodriguez...\n",
      "https://www.ufc.com/athlete/christian-rodriguez\n",
      "Scraping Victor Rodriguez...\n",
      "https://www.ufc.com/athlete/victor-rodriguez\n",
      "Scraping Ray Rodriguez...\n",
      "https://www.ufc.com/athlete/ray-rodriguez\n",
      "Scraping Yair Rodriguez...\n",
      "https://www.ufc.com/athlete/yair-rodriguez\n",
      "Scraping Marina Rodriguez...\n",
      "https://www.ufc.com/athlete/marina-rodriguez\n",
      "Scraping Daniel Rodriguez...\n",
      "https://www.ufc.com/athlete/daniel-rodriguez\n",
      "Scraping Nick Roehrick...\n",
      "https://www.ufc.com/athlete/nick-roehrick\n",
      "Scraping Saul Rogers...\n",
      "https://www.ufc.com/athlete/saul-rogers\n",
      "Scraping Max Rohskopf...\n",
      "https://www.ufc.com/athlete/max-rohskopf\n",
      "Scraping Marcelo Rojo...\n",
      "https://www.ufc.com/athlete/marcelo-rojo\n",
      "Scraping Shane Roller...\n",
      "https://www.ufc.com/athlete/shane-roller\n",
      "Scraping Jared Rollins...\n",
      "https://www.ufc.com/athlete/jared-rollins\n",
      "Scraping Alexandr Romanov...\n",
      "https://www.ufc.com/athlete/alexandr-romanov\n",
      "Scraping Ricardo Romero...\n",
      "https://www.ufc.com/athlete/ricardo-romero\n",
      "Scraping Yoel Romero...\n",
      "https://www.ufc.com/athlete/yoeru-romero\n",
      "Scraping Kaleio Romero...\n",
      "https://www.ufc.com/athlete/kaleio-romero\n",
      "Scraping Anthony Romero...\n",
      "https://www.ufc.com/athlete/anthony-romero\n",
      "Scraping Mara Romero Borella...\n",
      "https://www.ufc.com/athlete/mara-romero-borella\n",
      "Scraping Cortavious Romious...\n",
      "https://www.ufc.com/athlete/cortavious-romious\n",
      "Scraping Juancamilo Ronderos...\n",
      "https://www.ufc.com/athlete/juancamilo-ronderos\n",
      "Scraping Rongzhu...\n",
      "https://www.ufc.com/athlete/zhu-rong\n",
      "Scraping Jesse Ronson...\n",
      "https://www.ufc.com/athlete/jesse-ronson\n",
      "Scraping George Roop...\n",
      "https://www.ufc.com/athlete/george-roop\n",
      "Scraping Joao Roque...\n",
      "https://www.ufc.com/athlete/joao-roque\n",
      "Scraping Marcos Rosa...\n",
      "https://www.ufc.com/athlete/marcos-rosa\n",
      "Scraping Charles Rosa...\n",
      "https://www.ufc.com/athlete/charles-rosa\n",
      "Scraping Aaron Rosa...\n",
      "https://www.ufc.com/athlete/aaron-rosa\n",
      "Scraping Karol Rosa...\n",
      "https://www.ufc.com/athlete/karol-rosa\n",
      "Scraping Jacob Rosales...\n",
      "https://www.ufc.com/athlete/jacob-rosales\n",
      "Scraping Raul Rosas Jr....\n",
      "https://www.ufc.com/athlete/raul-rosas-jr\n",
      "Scraping Hilarie Rose...\n",
      "https://www.ufc.com/athlete/hilarie-rose\n",
      "Scraping Jake Rosholt...\n",
      "https://www.ufc.com/athlete/jake-rosholt\n",
      "Scraping Jared Rosholt...\n",
      "https://www.ufc.com/athlete/jared-rosholt\n",
      "Scraping Kevin Rosier...\n",
      "https://www.ufc.com/athlete/kevin-rosier\n",
      "Scraping Shannon Ross...\n",
      "https://www.ufc.com/athlete/shannon-ross\n",
      "Scraping Kristian Rothaermel...\n",
      "https://www.ufc.com/athlete/kristian-rothaermel\n",
      "Scraping Ben Rothwell...\n",
      "https://www.ufc.com/athlete/ben-rothwell\n",
      "Scraping Khalil Rountree Jr....\n",
      "https://www.ufc.com/athlete/khalil-rountree-jr\n",
      "Scraping Ronda Rousey...\n",
      "https://www.ufc.com/athlete/ronta-raushi\n",
      "Scraping Phil Rowe...\n",
      "https://www.ufc.com/athlete/philip-rowe\n",
      "Scraping Cam Rowston...\n",
      "https://www.ufc.com/athlete/cam-rowston\n",
      "Scraping Brandon Royval...\n",
      "https://www.ufc.com/athlete/brandon-royval\n",
      "Scraping Jairzinho Rozenstruik...\n",
      "https://www.ufc.com/athlete/jairzinho-rozenstruik\n",
      "Scraping Mauricio Rua...\n",
      "https://www.ufc.com/athlete/mauricio-rua\n",
      "Scraping Marco Ruas...\n",
      "https://www.ufc.com/athlete/marco-ruas\n",
      "Scraping Rodrigo Ruas...\n",
      "https://www.ufc.com/athlete/rodrigo-ruas\n",
      "Scraping Rodolfo Rubio...\n",
      "https://www.ufc.com/athlete/rodolfo-rubio\n",
      "Scraping Gabe Ruediger...\n",
      "https://www.ufc.com/athlete/gabe-ruediger\n",
      "Scraping Mauricio Ruffy...\n",
      "https://www.ufc.com/athlete/mauricio-ruffy\n",
      "Scraping Eddie Ruiz...\n",
      "https://www.ufc.com/athlete/eddie-ruiz\n",
      "Scraping Montserrat Ruiz...\n",
      "https://www.ufc.com/athlete/montserrat-conejo\n",
      "Scraping Mike Russow...\n",
      "https://www.ufc.com/athlete/mike-russow\n",
      "Scraping Bas Rutten...\n",
      "https://www.ufc.com/athlete/bas-rutten\n",
      "Scraping Nursulton Ruziboev...\n",
      "https://www.ufc.com/athlete/nursultan-ruziboev\n",
      "Scraping Cameron Saaiman...\n",
      "https://www.ufc.com/athlete/cameron-saaiman\n",
      "Scraping Danny Sabatello...\n",
      "https://www.ufc.com/athlete/danny-sabatello\n",
      "Scraping Pat Sabatini...\n",
      "https://www.ufc.com/athlete/pat-sabatini\n",
      "Scraping Amir Sadollah...\n",
      "https://www.ufc.com/athlete/amir-sadollah\n",
      "Scraping Nazim Sadykhov...\n",
      "https://www.ufc.com/athlete/nazim-sadykhov\n",
      "Scraping Frankie Saenz...\n",
      "https://www.ufc.com/athlete/frankie-saenz\n",
      "Scraping Saparbeg Safarov...\n",
      "https://www.ufc.com/athlete/saparbek-safarov\n",
      "Scraping Tarec Saffiedine...\n",
      "https://www.ufc.com/athlete/tarec-saffiedine\n",
      "Scraping Jason Saggo...\n",
      "https://www.ufc.com/athlete/jason-saggo\n",
      "Scraping Wang Sai...\n",
      "https://www.ufc.com/athlete/wang-sai\n",
      "Scraping Benot Saint Denis...\n",
      "https://www.ufc.com/athlete/benoit-saint-denis\n",
      "Scraping Ovince Saint Preux...\n",
      "https://www.ufc.com/athlete/ovince-saint-preux\n",
      "Scraping Lukasz Sajewski...\n",
      "https://www.ufc.com/athlete/lukasz-sajewski\n",
      "Scraping Augusto Sakai...\n",
      "https://www.ufc.com/athlete/augusto-sakai\n",
      "Scraping Alessio Sakara...\n",
      "https://www.ufc.com/athlete/alessio-sakara\n",
      "Scraping Gokhan Saki...\n",
      "https://www.ufc.com/athlete/gokhan-saki\n",
      "Scraping Kazushi Sakuraba...\n",
      "https://www.ufc.com/athlete/kazushi-sakuraba\n",
      "Scraping Hayato Sakurai...\n",
      "https://www.ufc.com/athlete/hayato-sakurai\n",
      "Scraping Justin Salas...\n",
      "https://www.ufc.com/athlete/justin-salas\n",
      "Scraping Ivan Salaverry...\n",
      "https://www.ufc.com/athlete/ivan-salaverry\n",
      "Scraping Roman Salazar...\n",
      "https://www.ufc.com/athlete/roman-salazar\n",
      "Scraping Luis Saldana...\n",
      "https://www.ufc.com/athlete/luis-saldana\n",
      "Scraping Muslim Salikhov...\n",
      "https://www.ufc.com/athlete/muslim-salikhov\n",
      "Scraping Quillan Salkilld...\n",
      "https://www.ufc.com/athlete/quillan-salkilld\n",
      "Scraping Sean Salmon...\n",
      "https://www.ufc.com/athlete/sean-salmon\n",
      "Scraping Boston Salmon...\n",
      "https://www.ufc.com/athlete/boston-salmon\n",
      "Scraping John Salter...\n",
      "https://www.ufc.com/athlete/john-salter\n",
      "Scraping Dylan Salvador...\n",
      "https://www.ufc.com/athlete/dylan-salvador\n",
      "Scraping Vinicius Salvador...\n",
      "https://www.ufc.com/athlete/vinicius-salvador\n",
      "Scraping Josh Samman...\n",
      "https://www.ufc.com/athlete/josh-samman\n",
      "Scraping Josh Sampo...\n",
      "https://www.ufc.com/athlete/josh-sampo\n",
      "Scraping Joby Sanchez...\n",
      "https://www.ufc.com/athlete/joby-sanchez\n",
      "Scraping Roberto Sanchez...\n",
      "https://www.ufc.com/athlete/roberto-sanchez\n",
      "Scraping Julian Sanchez...\n",
      "https://www.ufc.com/athlete/eddi-sanchez-0\n",
      "Scraping Andrew Sanchez...\n",
      "https://www.ufc.com/athlete/andrew-sanchez\n",
      "Scraping Diego Sanchez...\n",
      "https://www.ufc.com/athlete/diego-sanchez\n",
      "Scraping Eddie Sanchez...\n",
      "https://www.ufc.com/athlete/eddie-sanchez\n",
      "Scraping Jerrod Sanders...\n",
      "https://www.ufc.com/athlete/jerrod-sanders\n",
      "Scraping Luke Sanders...\n",
      "https://www.ufc.com/athlete/ruku-santasu\n",
      "Scraping Jesse Sanders...\n",
      "https://www.ufc.com/athlete/jesse-sanders\n",
      "Scraping Cory Sandhagen...\n",
      "https://www.ufc.com/athlete/cory-sandhagen\n",
      "Scraping Hector Sandoval...\n",
      "https://www.ufc.com/athlete/hector-sandoval\n",
      "Scraping Joseph Sandoval...\n",
      "https://www.ufc.com/athlete/joseph-sandoval\n",
      "Scraping Chris Sanford...\n",
      "https://www.ufc.com/athlete/chris-sanford\n",
      "Scraping Roldan Sangcha-an...\n",
      "https://www.ufc.com/athlete/roldan-sangcha\n",
      "Scraping Martin Sano...\n",
      "https://www.ufc.com/athlete/martin-sano\n",
      "Scraping Duda Santana...\n",
      "https://www.ufc.com/athlete/duda-santana\n",
      "Scraping Shaheen Santana...\n",
      "https://www.ufc.com/athlete/shaheen-santana\n",
      "Scraping Sean Santella...\n",
      "https://www.ufc.com/athlete/sean-santella\n",
      "Scraping Will Santiago...\n",
      "https://www.ufc.com/athlete/will-santiago\n",
      "Scraping Mike Santiago...\n",
      "https://www.ufc.com/athlete/mike-santiago\n",
      "Scraping Jorge Santiago...\n",
      "https://www.ufc.com/athlete/jorge-santiago\n",
      "Scraping Richie Santiago...\n",
      "https://www.ufc.com/athlete/richie-santiago\n",
      "Scraping Art Santore...\n",
      "https://www.ufc.com/athlete/art-santore\n",
      "Scraping Taila Santos...\n",
      "https://www.ufc.com/athlete/taila-santos\n",
      "Scraping Paulo Santos...\n",
      "https://www.ufc.com/athlete/paulo-santos\n",
      "Scraping Adriano Santos...\n",
      "https://www.ufc.com/athlete/adriano-martins-0\n",
      "Scraping Bruno Santos...\n",
      "https://www.ufc.com/athlete/bruno-santos\n",
      "Scraping Iliarde Santos...\n",
      "https://www.ufc.com/athlete/iliarde-santos\n",
      "Scraping Leonardo Santos...\n",
      "https://www.ufc.com/athlete/leonardo-santos\n",
      "Scraping Thiago Santos...\n",
      "https://www.ufc.com/athlete/thiago-santos\n",
      "Scraping Djorden Santos...\n",
      "https://www.ufc.com/athlete/djorden-santos\n",
      "Scraping Luana Santos...\n",
      "https://www.ufc.com/athlete/luana-santos\n",
      "Scraping Gabriel Santos...\n",
      "https://www.ufc.com/athlete/gabriel-santos\n",
      "Scraping Daniel Santos...\n",
      "https://www.ufc.com/athlete/daniel-santos\n",
      "Scraping Marilia Santos...\n",
      "https://www.ufc.com/athlete/marilia-santos\n",
      "Scraping Edivan Santos...\n",
      "https://www.ufc.com/athlete/edivan-santos\n",
      "Scraping Yana Santos...\n",
      "https://www.ufc.com/athlete/yana-santos\n",
      "Scraping Mairon Santos...\n",
      "https://www.ufc.com/athlete/mairon-santos-alves\n",
      "Scraping Joilton Lutterbach...\n",
      "https://www.ufc.com/athlete/joilton-lutterbach\n",
      "Scraping Nick Sanzo...\n",
      "https://www.ufc.com/athlete/eddi-sanchez-4\n",
      "Scraping Jeka Saragih...\n",
      "https://www.ufc.com/athlete/jeka-saragih\n",
      "Scraping Diego Saraiva...\n",
      "https://www.ufc.com/athlete/diego-saraiva\n",
      "Scraping Ulka Sasaki...\n",
      "https://www.ufc.com/athlete/ulka-sasaki\n",
      "Scraping Yuki Sasaki...\n",
      "https://www.ufc.com/athlete/yuki-sasaki\n",
      "Scraping Paul Sass...\n",
      "https://www.ufc.com/athlete/paul-sass\n",
      "Scraping Keisuke Sasu...\n",
      "https://www.ufc.com/athlete/keisuke-sasu\n",
      "Scraping Takashi Sato...\n",
      "https://www.ufc.com/athlete/takashi-sato\n",
      "Scraping Takenori Sato...\n",
      "https://www.ufc.com/athlete/takenori-sato\n",
      "Scraping Samy Schiavo...\n",
      "https://www.ufc.com/athlete/samy-schiavo\n",
      "Scraping Pat Schilling...\n",
      "https://www.ufc.com/athlete/pat-schilling\n",
      "Scraping Semmy Schilt...\n",
      "https://www.ufc.com/athlete/semmy-schilt\n",
      "Scraping Matt Schnell...\n",
      "https://www.ufc.com/athlete/matt-schnell\n",
      "Scraping Josh Schockman...\n",
      "https://www.ufc.com/athlete/josh-schockman\n",
      "Scraping Alex Schoenauer...\n",
      "https://www.ufc.com/athlete/alex-schoenauer\n",
      "Scraping Darrill Schoonover...\n",
      "https://www.ufc.com/athlete/darrill-schoonover\n",
      "Scraping Nate Schroeder...\n",
      "https://www.ufc.com/athlete/fabiano-sherner-2\n",
      "Scraping Mark Schultz...\n",
      "https://www.ufc.com/athlete/mark-schultz\n",
      "Scraping Justin Scoggins...\n",
      "https://www.ufc.com/athlete/justin-scoggins\n",
      "Scraping Bradley Scott...\n",
      "https://www.ufc.com/athlete/bradley-scott\n",
      "Scraping Neil Seery...\n",
      "https://www.ufc.com/athlete/neil-seery\n",
      "Scraping Tetsuya Seki...\n",
      "https://www.ufc.com/athlete/tetsuya-seki\n",
      "Scraping Stefan Sekulic...\n",
      "https://www.ufc.com/athlete/stefan-sekulic\n",
      "Scraping Pete Sell...\n",
      "https://www.ufc.com/athlete/pete-sell\n",
      "Scraping Matthew Semelsberger...\n",
      "https://www.ufc.com/athlete/matthew-semelsberger\n",
      "Scraping Andrei Semenov...\n",
      "https://www.ufc.com/athlete/andrei-semenov\n",
      "Scraping Mackens Semerzier...\n",
      "https://www.ufc.com/athlete/mackens-semerzier\n",
      "Scraping YeDam Seo...\n",
      "https://www.ufc.com/athlete/yedam-seo\n",
      "Scraping Ivan Serati...\n",
      "https://www.ufc.com/athlete/ivan-serati\n",
      "Scraping Alex Serdyukov...\n",
      "https://www.ufc.com/athlete/alex-serdyukov\n",
      "Scraping Matt Serra...\n",
      "https://www.ufc.com/athlete/matt-serra\n",
      "Scraping Nick Serra...\n",
      "https://www.ufc.com/athlete/nick-serra\n",
      "Scraping Fredy Serrano...\n",
      "https://www.ufc.com/athlete/fredy-serrano\n",
      "Scraping Adrian Serrano...\n",
      "https://www.ufc.com/athlete/adrian-serrano\n",
      "Scraping Igor Severino...\n",
      "https://www.ufc.com/athlete/igor-severino\n",
      "Scraping Dan Severn...\n",
      "https://www.ufc.com/athlete/dan-severn\n",
      "Scraping Rosi Sexton...\n",
      "https://www.ufc.com/athlete/rosi-sexton\n",
      "Scraping Edmen Shahbazyan...\n",
      "https://www.ufc.com/athlete/edmen-shahbazyan\n",
      "Scraping Leon Shahbazyan...\n",
      "https://www.ufc.com/athlete/leon-shahbazyan\n",
      "Scraping Don Shainis...\n",
      "https://www.ufc.com/athlete/don-shainis\n",
      "Scraping Liliya Shakirova...\n",
      "https://www.ufc.com/athlete/liliya-shakirova\n",
      "Scraping Kamal Shalorus...\n",
      "https://www.ufc.com/athlete/kamal-shalorus\n",
      "Scraping Frank Shamrock...\n",
      "https://www.ufc.com/athlete/frank-shamrock\n",
      "Scraping Ken Shamrock...\n",
      "https://www.ufc.com/athlete/ken-shamrock\n",
      "Scraping Sean Sharaf...\n",
      "https://www.ufc.com/athlete/sean-sharaf\n",
      "Scraping Eric Shelton...\n",
      "https://www.ufc.com/athlete/eric-shelton\n",
      "Scraping Sean Sherk...\n",
      "https://www.ufc.com/athlete/sean-sherk\n",
      "Scraping Chase Sherman...\n",
      "https://www.ufc.com/athlete/chase-sherman\n",
      "Scraping Antonina Shevchenko...\n",
      "https://www.ufc.com/athlete/antonina-shevchenko\n",
      "Scraping Valentina Shevchenko...\n",
      "https://www.ufc.com/athlete/valentina-shevchenko\n",
      "Scraping Jake Shields...\n",
      "https://www.ufc.com/athlete/jake-shields\n",
      "Scraping Henrique Shiguemoto...\n",
      "https://www.ufc.com/athlete/henrique-shiguemoto\n",
      "Scraping Shunichi Shimizu...\n",
      "https://www.ufc.com/athlete/shunichi-shimizu\n",
      "Scraping Wade Shipp...\n",
      "https://www.ufc.com/athlete/wade-shipp\n",
      "Scraping Josh Shockley...\n",
      "https://www.ufc.com/athlete/josh-shockley\n",
      "Scraping Liudvik Sholinian...\n",
      "https://www.ufc.com/athlete/liudvik-sholinian\n",
      "Scraping Jack Shore...\n",
      "https://www.ufc.com/athlete/jack-shore\n",
      "Scraping Ivan Shtyrkov...\n",
      "https://www.ufc.com/athlete/ivan-shtyrkov\n",
      "Scraping Ronal Siahaan...\n",
      "https://www.ufc.com/athlete/ronal-siahaan\n",
      "Scraping Sam Sicilia...\n",
      "https://www.ufc.com/athlete/sam-sicilia\n",
      "Scraping Serhiy Sidey...\n",
      "https://www.ufc.com/athlete/serhiy-sidey\n",
      "Scraping Steven Siler...\n",
      "https://www.ufc.com/athlete/steven-siler\n",
      "Scraping Gabriel Silva...\n",
      "https://www.ufc.com/athlete/gabriel-silva\n",
      "Scraping Anderson Silva...\n",
      "https://www.ufc.com/athlete/anderson-silva\n",
      "Scraping Jay Silva...\n",
      "https://www.ufc.com/athlete/jay-silva\n",
      "Scraping Wagner Silva...\n",
      "https://www.ufc.com/athlete/wagner-silva\n",
      "Scraping Claudio Silva...\n",
      "https://www.ufc.com/athlete/claudio-silva\n",
      "Scraping Assuerio Silva...\n",
      "https://www.ufc.com/athlete/assuerio-silva\n",
      "Scraping Wanderlei Silva...\n",
      "https://www.ufc.com/athlete/wanderlei-silva\n",
      "Scraping Felipe Silva...\n",
      "https://www.ufc.com/athlete/felipe-silva\n",
      "Scraping Joaquim Silva...\n",
      "https://www.ufc.com/athlete/joaquim-silva\n",
      "Scraping Leandro Silva...\n",
      "https://www.ufc.com/athlete/leandro-silva\n",
      "Scraping Antonio Silva...\n",
      "https://www.ufc.com/athlete/antonio-silva\n",
      "Scraping Erick Silva...\n",
      "https://www.ufc.com/athlete/erick-silva\n",
      "Scraping Erik Silva...\n",
      "https://www.ufc.com/athlete/erik-silva\n",
      "Scraping Danny Silva...\n",
      "https://www.ufc.com/athlete/danny-silva\n",
      "Scraping Janaina Silva...\n",
      "https://www.ufc.com/athlete/janaina-silva\n",
      "Scraping Jean Silva...\n",
      "https://www.ufc.com/athlete/jean-silva-lord\n",
      "Scraping Jhonata Silva...\n",
      "https://www.ufc.com/athlete/jhonata-silva\n",
      "Scraping Jansey Silva...\n",
      "https://www.ufc.com/athlete/jansey-silva\n",
      "Scraping Bruno Silva...\n",
      "https://www.ufc.com/athlete/bruno-silva-blindado\n",
      "Scraping Jacob Silva...\n",
      "https://www.ufc.com/athlete/jacob-silva\n",
      "Scraping Maria Silva...\n",
      "https://www.ufc.com/athlete/maria-silva\n",
      "Scraping Karine Silva...\n",
      "https://www.ufc.com/athlete/karine-silva\n",
      "Scraping Natalia Silva...\n",
      "https://www.ufc.com/athlete/natalia-silva\n",
      "Scraping Bruno Silva...\n",
      "https://www.ufc.com/athlete/bruno-silva\n",
      "Scraping Mayra Bueno Silva...\n",
      "https://www.ufc.com/athlete/mayra-bueno-silva\n",
      "Scraping Douglas Silva de Andrade...\n",
      "https://www.ufc.com/athlete/douglas-silva-de-andrade\n",
      "Scraping Elias Silverio...\n",
      "https://www.ufc.com/athlete/elias-silverio\n",
      "Scraping Jamey Simmons...\n",
      "https://www.ufc.com/athlete/jamey-simmons\n",
      "Scraping Ricky Simon...\n",
      "https://www.ufc.com/athlete/ricky-simon\n",
      "Scraping Aaron Simpson...\n",
      "https://www.ufc.com/athlete/aaron-simpson\n",
      "Scraping Everett Sims...\n",
      "https://www.ufc.com/athlete/everett-sims\n",
      "Scraping Tony Sims...\n",
      "https://www.ufc.com/athlete/tony-sims\n",
      "Scraping Wes Sims...\n",
      "https://www.ufc.com/athlete/wes-sims\n",
      "Scraping Lodune Sincaid...\n",
      "https://www.ufc.com/athlete/lodune-sincaid\n",
      "Scraping Rory Singer...\n",
      "https://www.ufc.com/athlete/rory-singer\n",
      "Scraping Arjan Singh Bhullar...\n",
      "https://www.ufc.com/athlete/arjan-singh-bhullar\n",
      "Scraping Elvis Sinosic...\n",
      "https://www.ufc.com/athlete/elvis-sinosic\n",
      "Scraping Mitchell Sipe...\n",
      "https://www.ufc.com/athlete/mitchell-sipe\n",
      "Scraping Gian Siqueira...\n",
      "https://www.ufc.com/athlete/gian-siqueira\n",
      "Scraping Jeremia Siregar...\n",
      "https://www.ufc.com/athlete/jeremia-siregar\n",
      "Scraping Dennis Siver...\n",
      "https://www.ufc.com/athlete/dennis-siver\n",
      "Scraping Chas Skelly...\n",
      "https://www.ufc.com/athlete/chas-skelly\n",
      "Scraping Kimbo Slice...\n",
      "https://www.ufc.com/athlete/kimbo-slice\n",
      "Scraping Joe Slick...\n",
      "https://www.ufc.com/athlete/joe-slick\n",
      "Scraping Devonte Smith...\n",
      "https://www.ufc.com/athlete/devonte-smith\n",
      "Scraping Cole Smith...\n",
      "https://www.ufc.com/athlete/cole-smith\n",
      "Scraping Scott Smith...\n",
      "https://www.ufc.com/athlete/scott-smith\n",
      "Scraping Leslie Smith...\n",
      "https://www.ufc.com/athlete/leslie-smith\n",
      "Scraping Maurice Smith...\n",
      "https://www.ufc.com/athlete/maurice-smith\n",
      "Scraping Patrick Smith...\n",
      "https://www.ufc.com/athlete/patrick-smith\n",
      "Scraping Gilbert Smith...\n",
      "https://www.ufc.com/athlete/gilbert-smith\n",
      "Scraping Colton Smith...\n",
      "https://www.ufc.com/athlete/colton-smith\n",
      "Scraping Trevor Smith...\n",
      "https://www.ufc.com/athlete/toreha-sumisu\n",
      "Scraping Michael Smith...\n",
      "https://www.ufc.com/athlete/michael-smith\n",
      "Scraping Braxton Smith...\n",
      "https://www.ufc.com/athlete/braxton-smith\n",
      "Scraping Nate Smith...\n",
      "https://www.ufc.com/athlete/nate-smith\n",
      "Scraping Anthony Smith...\n",
      "https://www.ufc.com/athlete/anthony-smith\n",
      "Scraping Dmitrii Smoliakov...\n",
      "https://www.ufc.com/athlete/dmitrii-smoliakov\n",
      "Scraping Louis Smolka...\n",
      "https://www.ufc.com/athlete/louis-smolka\n",
      "Scraping Cameron Smotherman...\n",
      "https://www.ufc.com/athlete/cameron-smotherman\n",
      "Scraping Shimon Smotritsky...\n",
      "https://www.ufc.com/athlete/shimon-smotritsky\n",
      "Scraping Richie Smullen...\n",
      "https://www.ufc.com/athlete/richie-smullen\n",
      "Scraping Devin Smyth...\n",
      "https://www.ufc.com/athlete/devin-smyth\n",
      "Scraping Peter Sobotta...\n",
      "https://www.ufc.com/athlete/peter-sobotta\n",
      "Scraping Renato Sobral...\n",
      "https://www.ufc.com/athlete/renato-sobral\n",
      "Scraping Rameau Sokoudjou...\n",
      "https://www.ufc.com/athlete/rameau-sokoudjou\n",
      "Scraping Alexander Soldatkin...\n",
      "https://www.ufc.com/athlete/alexander-soldatkin\n",
      "Scraping Joe Solecki...\n",
      "https://www.ufc.com/athlete/joe-solecki\n",
      "Scraping Jin Soo Son...\n",
      "https://www.ufc.com/athlete/jin-soo-son\n",
      "Scraping Joe Son...\n",
      "https://www.ufc.com/athlete/joe-son\n",
      "Scraping Emrah Sonmez...\n",
      "https://www.ufc.com/athlete/emrah-sonmez\n",
      "Scraping Chael Sonnen...\n",
      "https://www.ufc.com/athlete/chael-sonnen\n",
      "Scraping Benardo Sopaj...\n",
      "https://www.ufc.com/athlete/benardo-sopaj\n",
      "Scraping Emiliano Sordi...\n",
      "https://www.ufc.com/athlete/emiliano-sordi\n",
      "Scraping Punahele Soriano...\n",
      "https://www.ufc.com/athlete/punahele-soriano\n",
      "Scraping Sean Soriano...\n",
      "https://www.ufc.com/athlete/sean-soriano\n",
      "Scraping Dmitry Sosnovskiy...\n",
      "https://www.ufc.com/athlete/dmitry-sosnovskiy\n",
      "Scraping Ben Sosoli...\n",
      "https://www.ufc.com/athlete/ben-sosoli\n",
      "Scraping Krzysztof Soszynski...\n",
      "https://www.ufc.com/athlete/krzysztof-soszynski\n",
      "Scraping George Sotiropoulos...\n",
      "https://www.ufc.com/athlete/george-sotiropoulos\n",
      "Scraping Greg Soto...\n",
      "https://www.ufc.com/athlete/greg-soto\n",
      "Scraping Joe Soto...\n",
      "https://www.ufc.com/athlete/joe-soto\n",
      "Scraping Alex Soto...\n",
      "https://www.ufc.com/athlete/alex-soto\n",
      "Scraping Andre Soukhamthath...\n",
      "https://www.ufc.com/athlete/andre-soukhamthath\n",
      "Scraping Mario Sousa...\n",
      "https://www.ufc.com/athlete/mario-sousa\n",
      "Scraping Bobby Southworth...\n",
      "https://www.ufc.com/athlete/bobby-southworth\n",
      "Scraping Livinha Souza...\n",
      "https://www.ufc.com/athlete/livinha-souza\n",
      "Scraping Kevin Souza...\n",
      "https://www.ufc.com/athlete/kevin-souza\n",
      "Scraping Ronaldo Souza...\n",
      "https://www.ufc.com/athlete/ronaldo-souza\n",
      "Scraping Willian Souza...\n",
      "https://www.ufc.com/athlete/willian-souza\n",
      "Scraping Ketlen Souza...\n",
      "https://www.ufc.com/athlete/ketlen-souza\n",
      "Scraping Bruno Souza...\n",
      "https://www.ufc.com/athlete/bruno-souza\n",
      "Scraping Chris Spang...\n",
      "https://www.ufc.com/athlete/chris-spang\n",
      "Scraping Andreas Spang...\n",
      "https://www.ufc.com/athlete/andreas-spang\n",
      "Scraping Ryan Spann...\n",
      "https://www.ufc.com/athlete/ryan-spann\n",
      "Scraping Tommy Speer...\n",
      "https://www.ufc.com/athlete/tommy-speer\n",
      "Scraping Felicia Spencer...\n",
      "https://www.ufc.com/athlete/felicia-spencer\n",
      "Scraping Sean Spencer...\n",
      "https://www.ufc.com/athlete/sean-spencer\n",
      "Scraping Eric Spicely...\n",
      "https://www.ufc.com/athlete/eric-spicely\n",
      "Scraping Daniel Spitz...\n",
      "https://www.ufc.com/athlete/daniel-spitz\n",
      "Scraping Serghei Spivac...\n",
      "https://www.ufc.com/athlete/serghei-spivac\n",
      "Scraping Daniel Spohn...\n",
      "https://www.ufc.com/athlete/daniel-spohn\n",
      "Scraping Pete Spratt...\n",
      "https://www.ufc.com/athlete/pete-spratt\n",
      "Scraping Austin Springer...\n",
      "https://www.ufc.com/athlete/austin-springer\n",
      "Scraping Georges St-Pierre...\n",
      "https://www.ufc.com/athlete/georges-st-pierre\n",
      "Scraping Andreas Stahl...\n",
      "https://www.ufc.com/athlete/andreas-stahl\n",
      "Scraping Ron Stallings...\n",
      "https://www.ufc.com/athlete/ron-stallings\n",
      "Scraping Cody Stamann...\n",
      "https://www.ufc.com/athlete/cody-stamann\n",
      "Scraping Cristina Stanciu...\n",
      "https://www.ufc.com/athlete/cristina-stanciu\n",
      "Scraping Brian Stann...\n",
      "https://www.ufc.com/athlete/brian-stann\n",
      "Scraping Joshua Stansbury...\n",
      "https://www.ufc.com/athlete/joshua-stansbury\n",
      "Scraping Dion Staring...\n",
      "https://www.ufc.com/athlete/dion-staring\n",
      "Scraping Clifford Starks...\n",
      "https://www.ufc.com/athlete/clifford-starks\n",
      "Scraping Kalib Starnes...\n",
      "https://www.ufc.com/athlete/kalib-starnes\n",
      "Scraping Laureano Staropoli...\n",
      "https://www.ufc.com/athlete/laureano-staropoli\n",
      "Scraping Damian Stasiak...\n",
      "https://www.ufc.com/athlete/damian-stasiak\n",
      "Scraping Dominique Steele...\n",
      "https://www.ufc.com/athlete/tominiku-suteiru\n",
      "Scraping Ricky Steele...\n",
      "https://www.ufc.com/athlete/ricky-steele\n",
      "Scraping Kody Steele...\n",
      "https://www.ufc.com/athlete/kody-steele\n",
      "Scraping Alex Steibling...\n",
      "https://www.ufc.com/athlete/alex-steibling\n",
      "Scraping Steve Steinbeiss...\n",
      "https://www.ufc.com/athlete/steve-steinbeiss\n",
      "Scraping Dmitrei Stepanov...\n",
      "https://www.ufc.com/athlete/dmitrei-stepanov\n",
      "Scraping Jeremy Stephens...\n",
      "https://www.ufc.com/athlete/jeremy-stephens\n",
      "Scraping Aljamain Sterling...\n",
      "https://www.ufc.com/athlete/aljamain-sterling\n",
      "Scraping Joe Stevenson...\n",
      "https://www.ufc.com/athlete/joe-stevenson\n",
      "Scraping Maia Stevenson...\n",
      "https://www.ufc.com/athlete/maia-stevenson\n",
      "Scraping Kyle Stewart...\n",
      "https://www.ufc.com/athlete/kyle-stewart\n",
      "Scraping Darren Stewart...\n",
      "https://www.ufc.com/athlete/darren-stewart\n",
      "Scraping Navajo Stirling...\n",
      "https://www.ufc.com/athlete/navajo-stirling\n",
      "Scraping Dan Stittgen...\n",
      "https://www.ufc.com/athlete/dan-stittgen\n",
      "Scraping Lazar Stojadinovic...\n",
      "https://www.ufc.com/athlete/lazar-stojadinovic\n",
      "Scraping Denis Stojnic...\n",
      "https://www.ufc.com/athlete/denis-stojnic\n",
      "Scraping Julija Stoliarenko...\n",
      "https://www.ufc.com/athlete/julija-stoliarenko\n",
      "Scraping Dustin Stoltzfus...\n",
      "https://www.ufc.com/athlete/dustin-stoltzfus\n",
      "Scraping Niklas Stolze...\n",
      "https://www.ufc.com/athlete/niklas-stolze\n",
      "Scraping Ken Stone...\n",
      "https://www.ufc.com/athlete/ken-stone\n",
      "Scraping Rick Story...\n",
      "https://www.ufc.com/athlete/rick-story\n",
      "Scraping Darko Stosic...\n",
      "https://www.ufc.com/athlete/darko-stosic\n",
      "Scraping Greg Stott...\n",
      "https://www.ufc.com/athlete/greg-stott\n",
      "Scraping Sam Stout...\n",
      "https://www.ufc.com/athlete/sam-stout\n",
      "Scraping Curtis Stout...\n",
      "https://www.ufc.com/athlete/curtis-stout\n",
      "Scraping Jesse Strader...\n",
      "https://www.ufc.com/athlete/jesse-strader\n",
      "Scraping Dave Strasser...\n",
      "https://www.ufc.com/athlete/dave-strasser\n",
      "Scraping Gerald Strebendt...\n",
      "https://www.ufc.com/athlete/gerald-strebendt\n",
      "Scraping Sean Strickland...\n",
      "https://www.ufc.com/athlete/sean-strickland\n",
      "Scraping Mark Striegl...\n",
      "https://www.ufc.com/athlete/mark-striegl\n",
      "Scraping Hans Stringer...\n",
      "https://www.ufc.com/athlete/hans-stringer\n",
      "Scraping Stefan Struve...\n",
      "https://www.ufc.com/athlete/stefan-struve\n",
      "Scraping Josh Stuart...\n",
      "https://www.ufc.com/athlete/josh-stuart\n",
      "Scraping Mike Stumpf...\n",
      "https://www.ufc.com/athlete/mike-stumpf\n",
      "Scraping Tatiana Suarez...\n",
      "https://www.ufc.com/athlete/tatiana-suarez\n",
      "Scraping Vineesh Subrahmanyan...\n",
      "https://www.ufc.com/athlete/vineesh-subrahmanyan\n",
      "Scraping Genki Sudo...\n",
      "https://www.ufc.com/athlete/genki-sudo\n",
      "Scraping Lukasz Sudolski...\n",
      "https://www.ufc.com/athlete/lukasz-sudolski\n",
      "Scraping George Sullivan...\n",
      "https://www.ufc.com/athlete/george-sullivan\n",
      "Scraping Amar Suloev...\n",
      "https://www.ufc.com/athlete/amar-suloev\n",
      "Scraping Justin Sumter...\n",
      "https://www.ufc.com/athlete/justin-sumter\n",
      "Scraping Rama Supandhi...\n",
      "https://www.ufc.com/athlete/rama-supandhi\n",
      "Scraping Joel Sutton...\n",
      "https://www.ufc.com/athlete/genki-sudo-0\n",
      "Scraping Danilo Suzart...\n",
      "https://www.ufc.com/athlete/danilo-suzart\n",
      "Scraping Martin Svensson...\n",
      "https://www.ufc.com/athlete/martin-svensson\n",
      "Scraping Daniel Swain...\n",
      "https://www.ufc.com/athlete/daniel-swain\n",
      "Scraping Cub Swanson...\n",
      "https://www.ufc.com/athlete/cub-swanson\n",
      "Scraping Evan Sweesy...\n",
      "https://www.ufc.com/athlete/evan-sweesy\n",
      "Scraping Mike Swick...\n",
      "https://www.ufc.com/athlete/mike-swick\n",
      "Scraping Floyd Sword...\n",
      "https://www.ufc.com/athlete/floyd-sword\n",
      "Scraping Oumar Sy...\n",
      "https://www.ufc.com/athlete/oumar-sy\n",
      "Scraping Bentley Syler...\n",
      "https://www.ufc.com/athlete/bentley-syler\n",
      "Scraping Kevin Syler...\n",
      "https://www.ufc.com/athlete/kevin-syler\n",
      "Scraping Tim Sylvia...\n",
      "https://www.ufc.com/athlete/tim-sylvia\n",
      "Scraping Kevin Szaflarski...\n",
      "https://www.ufc.com/athlete/kevin-szaflarski\n",
      "Scraping Eugenio Tadeu...\n",
      "https://www.ufc.com/athlete/tim-silviya-0\n",
      "Scraping Justin Tafa...\n",
      "https://www.ufc.com/athlete/justin-tafa\n",
      "Scraping Junior Tafa...\n",
      "https://www.ufc.com/athlete/junior-tafa\n",
      "Scraping Khalid Taha...\n",
      "https://www.ufc.com/athlete/khalid-taha\n",
      "Scraping Tatsuro Taira...\n",
      "https://www.ufc.com/athlete/tatsuro-taira\n",
      "Scraping Mairbek Taisumov...\n",
      "https://www.ufc.com/athlete/mairbek-taisumov\n",
      "Scraping Yoshiki Takahashi...\n",
      "https://www.ufc.com/athlete/yoshiki-takahashi\n",
      "Scraping Daiju Takase...\n",
      "https://www.ufc.com/athlete/daiju-takase\n",
      "Scraping Oleg Taktarov...\n",
      "https://www.ufc.com/athlete/oleg-taktarov\n",
      "Scraping Montrel Talbert...\n",
      "https://www.ufc.com/athlete/montrel-talbert\n",
      "Scraping Payton Talbott...\n",
      "https://www.ufc.com/athlete/payton-talbott\n",
      "Scraping Nordine Taleb...\n",
      "https://www.ufc.com/athlete/nordine-taleb\n",
      "Scraping Murtaza Talha...\n",
      "https://www.ufc.com/athlete/murtaza-talha\n",
      "Scraping Akitoshi Tamura...\n",
      "https://www.ufc.com/athlete/akitoshi-tamura\n",
      "Scraping Issei Tamura...\n",
      "https://www.ufc.com/athlete/issei-tamura\n",
      "Scraping Jason Tan...\n",
      "https://www.ufc.com/athlete/jason-tan\n",
      "Scraping Michinori Tanaka...\n",
      "https://www.ufc.com/athlete/michinori-tanaka\n",
      "Scraping Evan Tanner...\n",
      "https://www.ufc.com/athlete/evan-tanner\n",
      "Scraping Miesha Tate...\n",
      "https://www.ufc.com/athlete/miesha-tate\n",
      "Scraping Thiago Tavares...\n",
      "https://www.ufc.com/athlete/thiago-tavares\n",
      "Scraping Brad Tavares...\n",
      "https://www.ufc.com/athlete/brad-tavares\n",
      "Scraping Ramon Taveras...\n",
      "https://www.ufc.com/athlete/ramon-taveras\n",
      "Scraping Jesse Taylor...\n",
      "https://www.ufc.com/athlete/jesse-taylor\n",
      "Scraping Paul Taylor...\n",
      "https://www.ufc.com/athlete/paul-taylor\n",
      "Scraping Danielle Taylor...\n",
      "https://www.ufc.com/athlete/danielle-taylor\n",
      "Scraping James Te Huna...\n",
      "https://www.ufc.com/athlete/james-te-huna\n",
      "Scraping Shawn Teed...\n",
      "https://www.ufc.com/athlete/shawn-teed\n",
      "Scraping Glover Teixeira...\n",
      "https://www.ufc.com/athlete/glover-teixeira\n",
      "Scraping John Teixeira...\n",
      "https://www.ufc.com/athlete/john-teixeira\n",
      "Scraping Tra Telligman...\n",
      "https://www.ufc.com/athlete/tra-telligman\n",
      "Scraping Ramazan Temirov...\n",
      "https://www.ufc.com/athlete/ramazan-temirov\n",
      "Scraping Taneisha Tennant...\n",
      "https://www.ufc.com/athlete/taneisha-tennant\n",
      "Scraping David Terrell...\n",
      "https://www.ufc.com/athlete/david-terrell\n",
      "Scraping James Terry...\n",
      "https://www.ufc.com/athlete/james-terry\n",
      "Scraping Testy Test...\n",
      "https://www.ufc.com/athlete/testy-test\n",
      "Scraping Daniel Teymur...\n",
      "https://www.ufc.com/athlete/daniel-teymur\n",
      "Scraping David Teymur...\n",
      "https://www.ufc.com/athlete/david-teymur\n",
      "Scraping Motonobu Tezuka...\n",
      "https://www.ufc.com/athlete/montana-de-la-rosa-0\n",
      "Scraping Jason Thacker...\n",
      "https://www.ufc.com/athlete/jason-thacker\n",
      "Scraping Alexia Thainara...\n",
      "https://www.ufc.com/athlete/alexia-thainara\n",
      "Scraping Brandon Thatch...\n",
      "https://www.ufc.com/athlete/brandon-thatch\n",
      "Scraping Elias Theodorou...\n",
      "https://www.ufc.com/athlete/elias-theodorou\n",
      "Scraping Paulo Thiago...\n",
      "https://www.ufc.com/athlete/paulo-thiago\n",
      "Scraping Ryan Thomas...\n",
      "https://www.ufc.com/athlete/ryan-thomas\n",
      "Scraping Din Thomas...\n",
      "https://www.ufc.com/athlete/din-thomas\n",
      "Scraping Timothy Thomas...\n",
      "https://www.ufc.com/athlete/timothy-thomas\n",
      "Scraping Nick Thompson...\n",
      "https://www.ufc.com/athlete/nick-thompson\n",
      "Scraping Oli Thompson...\n",
      "https://www.ufc.com/athlete/oli-thompson\n",
      "Scraping Stephen Thompson...\n",
      "https://www.ufc.com/athlete/stephen-thompson\n",
      "Scraping Josh Thomson...\n",
      "https://www.ufc.com/athlete/josh-thomson\n",
      "Scraping Simeon Thoresen...\n",
      "https://www.ufc.com/athlete/simeon-thoresen\n",
      "Scraping Gleison Tibau...\n",
      "https://www.ufc.com/athlete/gleison-tibau\n",
      "Scraping Nolan Ticman...\n",
      "https://www.ufc.com/athlete/nolan-ticman\n",
      "Scraping Darren Till...\n",
      "https://www.ufc.com/athlete/darren-till\n",
      "Scraping Denis Tiuliulin...\n",
      "https://www.ufc.com/athlete/denis-tiuliulin\n",
      "Scraping Andrew Todhunter...\n",
      "https://www.ufc.com/athlete/andrew-todhunter\n",
      "Scraping Duko Todorovi...\n",
      "https://www.ufc.com/athlete/dusko-todorovic\n",
      "Scraping Tuco Tokkos...\n",
      "https://www.ufc.com/athlete/tuco-tokkos\n",
      "Scraping Puja Tomar...\n",
      "https://www.ufc.com/athlete/puja-tomar\n",
      "Scraping Tyler Toner...\n",
      "https://www.ufc.com/athlete/tyler-toner\n",
      "Scraping James Toney...\n",
      "https://www.ufc.com/athlete/james-toney\n",
      "Scraping Ilia Topuria...\n",
      "https://www.ufc.com/athlete/ilia-topuria\n",
      "Scraping Ronys Torres...\n",
      "https://www.ufc.com/athlete/ronys-torres\n",
      "Scraping Anthony Torres...\n",
      "https://www.ufc.com/athlete/anthony-torres\n",
      "Scraping Miguel Angel Torres...\n",
      "https://www.ufc.com/athlete/miguel-angel-torres\n",
      "Scraping Alex Torres...\n",
      "https://www.ufc.com/athlete/alex-torres\n",
      "Scraping Jose Torres...\n",
      "https://www.ufc.com/athlete/jose-torres\n",
      "Scraping Manuel Torres...\n",
      "https://www.ufc.com/athlete/manuel-torres\n",
      "Scraping Desmond Torres...\n",
      "https://www.ufc.com/athlete/desmond-torres\n",
      "Scraping Salim Touahri...\n",
      "https://www.ufc.com/athlete/salim-touahri\n",
      "Scraping Dequan Townsend...\n",
      "https://www.ufc.com/athlete/dequan-townsend\n",
      "Scraping Slim Trabelsi...\n",
      "https://www.ufc.com/athlete/slim-trabelsi\n",
      "Scraping Tiago Trator...\n",
      "https://www.ufc.com/athlete/tiago-trator\n",
      "Scraping Roberto Traven...\n",
      "https://www.ufc.com/athlete/roberto-traven\n",
      "Scraping Angelo Trevino...\n",
      "https://www.ufc.com/athlete/angelo-trevino\n",
      "Scraping Francisco Trevino...\n",
      "https://www.ufc.com/athlete/francisco-trevino\n",
      "Scraping Frank Trigg...\n",
      "https://www.ufc.com/athlete/frank-trigg\n",
      "Scraping Francisco Trinaldo...\n",
      "https://www.ufc.com/athlete/francisco-trinaldo\n",
      "Scraping Michael Trizano...\n",
      "https://www.ufc.com/athlete/michael-trizano\n",
      "Scraping Antonio Trocoli...\n",
      "https://www.ufc.com/athlete/antonio-trocoli\n",
      "Scraping Tor Troeng...\n",
      "https://www.ufc.com/athlete/tor-troeng\n",
      "Scraping Abel Trujillo...\n",
      "https://www.ufc.com/athlete/abel-trujillo\n",
      "Scraping Arman Tsarukyan...\n",
      "https://www.ufc.com/athlete/arman-tsarukyan\n",
      "Scraping Rei Tsuruya...\n",
      "https://www.ufc.com/athlete/rei-tsuruya\n",
      "Scraping Chris Tuchscherer...\n",
      "https://www.ufc.com/athlete/kris-fishgold-1\n",
      "Scraping Jon Tuck...\n",
      "https://www.ufc.com/athlete/jon-tuck\n",
      "Scraping Gavin Tucker...\n",
      "https://www.ufc.com/athlete/gavin-tucker\n",
      "Scraping Jumabieke Tuerxun...\n",
      "https://www.ufc.com/athlete/khulio-arse-0\n",
      "Scraping Tai Tuivasa...\n",
      "https://www.ufc.com/athlete/tai-tuivasa\n",
      "Scraping Zubaira Tukhugov...\n",
      "https://www.ufc.com/athlete/zubaira-tukhugov\n",
      "Scraping Teila Tuli...\n",
      "https://www.ufc.com/athlete/teila-tuli\n",
      "Scraping Marco Tulio...\n",
      "https://www.ufc.com/athlete/marco-tulio\n",
      "Scraping Nyamjargal Tumendemberel...\n",
      "https://www.ufc.com/athlete/nyamjargal-tumendemberel\n",
      "Scraping Albert Tumenov...\n",
      "https://www.ufc.com/athlete/albert-tumenov\n",
      "Scraping Ricky Turcios...\n",
      "https://www.ufc.com/athlete/ricky-turcios\n",
      "Scraping Anton Turkalj...\n",
      "https://www.ufc.com/athlete/anton-turkalj\n",
      "Scraping Wellington Turman...\n",
      "https://www.ufc.com/athlete/wellington-turman\n",
      "Scraping Courtney Turner...\n",
      "https://www.ufc.com/athlete/ronis-torres-1\n",
      "Scraping Jalin Turner...\n",
      "https://www.ufc.com/athlete/jalin-turner\n",
      "Scraping Austin Tweedy...\n",
      "https://www.ufc.com/athlete/austin-tweedy\n",
      "Scraping Marcin Tybura...\n",
      "https://www.ufc.com/athlete/marcin-tybura\n",
      "Scraping Takeru Uchida...\n",
      "https://www.ufc.com/athlete/takeru-uchida\n",
      "Scraping Tagir Ulanbekov...\n",
      "https://www.ufc.com/athlete/tagir-ulanbekov\n",
      "Scraping Carlos Ulberg...\n",
      "https://www.ufc.com/athlete/carlos-ulberg\n",
      "Scraping Gasan Umalatov...\n",
      "https://www.ufc.com/athlete/gasan-umalatov\n",
      "Scraping Caol Uno...\n",
      "https://www.ufc.com/athlete/caol-uno\n",
      "Scraping Logan Urban...\n",
      "https://www.ufc.com/athlete/logan-urban\n",
      "Scraping Hector Urbina...\n",
      "https://www.ufc.com/athlete/hector-urbina\n",
      "Scraping Elias Urbina...\n",
      "https://www.ufc.com/athlete/elias-urbina\n",
      "Scraping Gilbert Urbina...\n",
      "https://www.ufc.com/athlete/gilbert-urbina\n",
      "Scraping Nick Urso...\n",
      "https://www.ufc.com/athlete/nick-urso\n",
      "Scraping Yasuhiro Urushitani...\n",
      "https://www.ufc.com/athlete/yasuhiro-urushitani\n",
      "Scraping Sho Patrick Usami...\n",
      "https://www.ufc.com/athlete/sho-patrick-usami\n",
      "Scraping Mohammed Usman...\n",
      "https://www.ufc.com/athlete/mohammed-usman\n",
      "Scraping Kamaru Usman...\n",
      "https://www.ufc.com/athlete/kamaru-usman\n",
      "Scraping Darren Uyenoyama...\n",
      "https://www.ufc.com/athlete/darren-uyenoyama\n",
      "Scraping Richie Vaculik...\n",
      "https://www.ufc.com/athlete/richie-vaculik\n",
      "Scraping Richie Vaculik...\n",
      "https://www.ufc.com/athlete/richie-vaculik-0\n",
      "Scraping Artem Vakhitov...\n",
      "https://www.ufc.com/athlete/artem-vakhitov\n",
      "Scraping Genaro Valdez...\n",
      "https://www.ufc.com/athlete/genaro-valdez\n",
      "Scraping Charlie Valencia...\n",
      "https://www.ufc.com/athlete/charlie-valencia\n",
      "Scraping Robert Valentin...\n",
      "https://www.ufc.com/athlete/robert-valentin-frey\n",
      "Scraping Ivan Valenzuela...\n",
      "https://www.ufc.com/athlete/ivan-valenzuela\n",
      "Scraping Timur Valiev...\n",
      "https://www.ufc.com/athlete/timur-valiev\n",
      "Scraping Victor Valimaki...\n",
      "https://www.ufc.com/athlete/victor-valimaki\n",
      "Scraping Kevin Vallejos...\n",
      "https://www.ufc.com/athlete/kevin-vallejos\n",
      "Scraping Isaac Vallie-Flagg...\n",
      "https://www.ufc.com/athlete/isaac-vallie-flagg\n",
      "Scraping Joshua Van...\n",
      "https://www.ufc.com/athlete/joshua-van\n",
      "Scraping Mike Van Arsdale...\n",
      "https://www.ufc.com/athlete/mike-van-arsdale\n",
      "Scraping Matt Van Buren...\n",
      "https://www.ufc.com/athlete/matt-van-buren\n",
      "Scraping Ron Van Clief...\n",
      "https://www.ufc.com/athlete/ron-van-clief\n",
      "Scraping Cameron VanCamp...\n",
      "https://www.ufc.com/athlete/cameron-vancamp\n",
      "Scraping Jared Vanderaa...\n",
      "https://www.ufc.com/athlete/jared-vanderaa\n",
      "Scraping Austin Vanderford...\n",
      "https://www.ufc.com/athlete/austin-vanderford\n",
      "Scraping Lando Vannata...\n",
      "https://www.ufc.com/athlete/lando-vannata\n",
      "Scraping Paige VanZant...\n",
      "https://www.ufc.com/athlete/paige-vanzant\n",
      "Scraping Paul Varelans...\n",
      "https://www.ufc.com/athlete/paul-varelans\n",
      "Scraping Kazula Vargas...\n",
      "https://www.ufc.com/athlete/kazula-vargas\n",
      "Scraping Jamie Varner...\n",
      "https://www.ufc.com/athlete/jamie-varner\n",
      "Scraping Guilherme Vasconcelos...\n",
      "https://www.ufc.com/athlete/guilherme-vasconcelos\n",
      "Scraping Yuri Vaulin...\n",
      "https://www.ufc.com/athlete/dmitriy-stepanov-1\n",
      "Scraping Javier Vazquez...\n",
      "https://www.ufc.com/athlete/javier-vazquez\n",
      "Scraping Manny Vazquez...\n",
      "https://www.ufc.com/athlete/manny-vazquez\n",
      "Scraping Matt Veach...\n",
      "https://www.ufc.com/athlete/matt-veach\n",
      "Scraping Joe Vedepo...\n",
      "https://www.ufc.com/athlete/joe-vedepo\n",
      "Scraping Kelly Velasco...\n",
      "https://www.ufc.com/athlete/kelly-velasco\n",
      "Scraping Greg Velasco...\n",
      "https://www.ufc.com/athlete/greg-velasco\n",
      "Scraping Cain Velasquez...\n",
      "https://www.ufc.com/athlete/cain-velasquez\n",
      "Scraping David Velasquez...\n",
      "https://www.ufc.com/athlete/dzho-vedepo-0\n",
      "Scraping Bojan Velickovic...\n",
      "https://www.ufc.com/athlete/bojan-velickovic\n",
      "Scraping Karlos Vemola...\n",
      "https://www.ufc.com/athlete/kamaru-usman-0\n",
      "Scraping Luigi Vendramini...\n",
      "https://www.ufc.com/athlete/luigi-vendramini\n",
      "Scraping Kerry Vera...\n",
      "https://www.ufc.com/athlete/kerry-vera\n",
      "Scraping Brandon Vera...\n",
      "https://www.ufc.com/athlete/brandon-vera\n",
      "Scraping Carlos Vera...\n",
      "https://www.ufc.com/athlete/carlos-vera\n",
      "Scraping Marlon Vera...\n",
      "https://www.ufc.com/athlete/marlon-vera\n",
      "Scraping Isis Verbeek...\n",
      "https://www.ufc.com/athlete/isis-verbeek\n",
      "Scraping Ernie Verdicia...\n",
      "https://www.ufc.com/athlete/ernie-verdicia\n",
      "Scraping Joe Veres...\n",
      "https://www.ufc.com/athlete/joe-veres\n",
      "Scraping Nikolay Veretennikov...\n",
      "https://www.ufc.com/athlete/nikolay-veretennikov\n",
      "Scraping CJ Vergara...\n",
      "https://www.ufc.com/athlete/cj-vergara\n",
      "Scraping Renato Verissimo...\n",
      "https://www.ufc.com/athlete/renato-verissimo\n",
      "Scraping Marvin Vettori...\n",
      "https://www.ufc.com/athlete/marvin-vettori\n",
      "Scraping Polyana Viana...\n",
      "https://www.ufc.com/athlete/polyana-viana\n",
      "Scraping Hugo Viana...\n",
      "https://www.ufc.com/athlete/hugo-viana\n",
      "Scraping James Vick...\n",
      "https://www.ufc.com/athlete/james-vick\n",
      "Scraping Tamires Vidal...\n",
      "https://www.ufc.com/athlete/tamires-vidal\n",
      "Scraping Rodolfo Vieira...\n",
      "https://www.ufc.com/athlete/rodolfo-vieira\n",
      "Scraping Reginaldo Vieira...\n",
      "https://www.ufc.com/athlete/reginaldo-vieira\n",
      "Scraping Milton Vieira...\n",
      "https://www.ufc.com/athlete/milana-dudieva-0\n",
      "Scraping Ketlen Vieira...\n",
      "https://www.ufc.com/athlete/ketlen-vieira\n",
      "Scraping Steve Vigneault...\n",
      "https://www.ufc.com/athlete/steve-vigneault\n",
      "Scraping Gian Villante...\n",
      "https://www.ufc.com/athlete/shian-uirante\n",
      "Scraping Ike Villanueva...\n",
      "https://www.ufc.com/athlete/isaac-villanueva\n",
      "Scraping Armando Villarreal...\n",
      "https://www.ufc.com/athlete/armando-villarreal\n",
      "Scraping Danillo Villefort...\n",
      "https://www.ufc.com/athlete/danillo-villefort\n",
      "Scraping Yuri Villefort...\n",
      "https://www.ufc.com/athlete/yuri-villefort\n",
      "Scraping Marcos Vinicius...\n",
      "https://www.ufc.com/athlete/marcos-vinicius\n",
      "Scraping Falaniko Vitale...\n",
      "https://www.ufc.com/athlete/falaniko-vitale\n",
      "Scraping Cheyanne Vlismas...\n",
      "https://www.ufc.com/athlete/cheyanne-vlismas\n",
      "Scraping Bobby Voelker...\n",
      "https://www.ufc.com/athlete/bobby-voelker\n",
      "Scraping Mateo Vogel...\n",
      "https://www.ufc.com/athlete/mateo-vogel\n",
      "Scraping Danylo Voievodkin...\n",
      "https://www.ufc.com/athlete/danylo-voievodkin\n",
      "Scraping Alexander Volkanovski...\n",
      "https://www.ufc.com/athlete/alexander-volkanovski\n",
      "Scraping Jacob Volkmann...\n",
      "https://www.ufc.com/athlete/jacob-volkmann\n",
      "Scraping Alexander Volkov...\n",
      "https://www.ufc.com/athlete/alexander-volkov\n",
      "Scraping Jason Von Flue...\n",
      "https://www.ufc.com/athlete/jason-von-flue\n",
      "Scraping Jordan Vucenic...\n",
      "https://www.ufc.com/athlete/jordan-vucenic\n",
      "Scraping Chris Wade...\n",
      "https://www.ufc.com/athlete/chris-wade\n",
      "Scraping Neil Wain...\n",
      "https://www.ufc.com/athlete/neil-wain\n",
      "Scraping TJ Waldburger...\n",
      "https://www.ufc.com/athlete/tj-waldburger\n",
      "Scraping Chase Waldon...\n",
      "https://www.ufc.com/athlete/chase-waldon\n",
      "Scraping Valter Walker...\n",
      "https://www.ufc.com/athlete/valter-walker\n",
      "Scraping Brogan Walker...\n",
      "https://www.ufc.com/athlete/brogan-walker\n",
      "Scraping Donny Walker...\n",
      "https://www.ufc.com/athlete/donny-walker-0\n",
      "Scraping Johnny Walker...\n",
      "https://www.ufc.com/athlete/johnny-walker\n",
      "Scraping Ben Wall...\n",
      "https://www.ufc.com/athlete/ben-wall\n",
      "Scraping Austin Wall...\n",
      "https://www.ufc.com/athlete/austin-wall\n",
      "Scraping Rodney Wallace...\n",
      "https://www.ufc.com/athlete/rodney-wallace\n",
      "Scraping Randall Wallace...\n",
      "https://www.ufc.com/athlete/randall-wallace\n",
      "Scraping Crafton Wallace...\n",
      "https://www.ufc.com/athlete/crafton-wallace\n",
      "Scraping James Wallace...\n",
      "https://www.ufc.com/athlete/james-wallace\n",
      "Scraping Jimmy Wallhead...\n",
      "https://www.ufc.com/athlete/jimmy-wallhead\n",
      "Scraping Cory Walmsley...\n",
      "https://www.ufc.com/athlete/cory-walmsley\n",
      "Scraping Patrick Walsh...\n",
      "https://www.ufc.com/athlete/patrick-walsh\n",
      "Scraping Rich Walsh...\n",
      "https://www.ufc.com/athlete/rich-walsh\n",
      "Scraping Andy Wang...\n",
      "https://www.ufc.com/athlete/andy-wang\n",
      "Scraping Joshua Wang-Kim...\n",
      "https://www.ufc.com/athlete/joshua-wang-kim\n",
      "Scraping Curt Warburton...\n",
      "https://www.ufc.com/athlete/kori-uolsmli\n",
      "Scraping Charlie Ward...\n",
      "https://www.ufc.com/athlete/charlie-ward\n",
      "Scraping Terrion Ware...\n",
      "https://www.ufc.com/athlete/terrion-ware\n",
      "Scraping Ron Waterman...\n",
      "https://www.ufc.com/athlete/ron-waterman\n",
      "Scraping Dominic Waters...\n",
      "https://www.ufc.com/athlete/dominic-waters\n",
      "Scraping Trey Waters...\n",
      "https://www.ufc.com/athlete/trey-waters\n",
      "Scraping Michelle Waterson-Gomez...\n",
      "https://www.ufc.com/athlete/michelle-waterson\n",
      "Scraping Kyle Watson...\n",
      "https://www.ufc.com/athlete/kyle-watson\n",
      "Scraping Tom Watson...\n",
      "https://www.ufc.com/athlete/tom-watson\n",
      "Scraping Walel Watson...\n",
      "https://www.ufc.com/athlete/walel-watson\n",
      "Scraping Brok Weaver...\n",
      "https://www.ufc.com/athlete/brok-weaver\n",
      "Scraping Jonavin Webb...\n",
      "https://www.ufc.com/athlete/jonavin-webb\n",
      "Scraping Royston Wee...\n",
      "https://www.ufc.com/athlete/royston-wee\n",
      "Scraping Darian Weeks...\n",
      "https://www.ufc.com/athlete/darian-weeks\n",
      "Scraping Joshua Weems...\n",
      "https://www.ufc.com/athlete/josh-weems\n",
      "Scraping Chris Weidman...\n",
      "https://www.ufc.com/athlete/chris-weidman\n",
      "Scraping Dakota Weigher...\n",
      "https://www.ufc.com/athlete/dakota-weigher\n",
      "Scraping Zhang Weili...\n",
      "https://www.ufc.com/athlete/weili-zhang\n",
      "Scraping Mark Weir...\n",
      "https://www.ufc.com/athlete/mark-weir\n",
      "Scraping Christian Wellisch...\n",
      "https://www.ufc.com/athlete/christian-wellisch\n",
      "Scraping Jeremiah Wells...\n",
      "https://www.ufc.com/athlete/jeremiah-wells\n",
      "Scraping Orlando Welt...\n",
      "https://www.ufc.com/athlete/orlando-welt\n",
      "Scraping Fabricio Werdum...\n",
      "https://www.ufc.com/athlete/fabricio-werdum\n",
      "Scraping Mike Wessel...\n",
      "https://www.ufc.com/athlete/mike-wessel\n",
      "Scraping Sheldon Westcott...\n",
      "https://www.ufc.com/athlete/sheldon-westcott\n",
      "Scraping Alex White...\n",
      "https://www.ufc.com/athlete/alex-white\n",
      "Scraping Craig White...\n",
      "https://www.ufc.com/athlete/craig-white\n",
      "Scraping Vernon White...\n",
      "https://www.ufc.com/athlete/vernon-white\n",
      "Scraping Patrik White...\n",
      "https://www.ufc.com/athlete/patrik-white\n",
      "Scraping Rob Whiteford...\n",
      "https://www.ufc.com/athlete/rob-whiteford\n",
      "Scraping Mike Whitehead...\n",
      "https://www.ufc.com/athlete/mike-whitehead\n",
      "Scraping Garett Whiteley...\n",
      "https://www.ufc.com/athlete/garett-whiteley\n",
      "Scraping Emily Whitmire...\n",
      "https://www.ufc.com/athlete/emily-whitmire\n",
      "Scraping Robert Whittaker...\n",
      "https://www.ufc.com/athlete/robert-whittaker\n",
      "Scraping Josh Wick...\n",
      "https://www.ufc.com/athlete/josh-wick\n",
      "Scraping Adam Wieczorek...\n",
      "https://www.ufc.com/athlete/adam-wieczorek\n",
      "Scraping Jonathan Wiezorek...\n",
      "https://www.ufc.com/athlete/jonathan-wiezorek\n",
      "Scraping Justin Wilcox...\n",
      "https://www.ufc.com/athlete/justin-wilcox\n",
      "Scraping Aaron Wilkinson...\n",
      "https://www.ufc.com/athlete/aaron-wilkinson\n",
      "Scraping Rob Wilkinson...\n",
      "https://www.ufc.com/athlete/rob-wilkinson\n",
      "Scraping Mike Wilkinson...\n",
      "https://www.ufc.com/athlete/mayk-svik-0\n",
      "Scraping James Wilks...\n",
      "https://www.ufc.com/athlete/james-wilks\n",
      "Scraping Khaos Williams...\n",
      "https://www.ufc.com/athlete/khaos-williams\n",
      "Scraping Cole Williams...\n",
      "https://www.ufc.com/athlete/cole-williams\n",
      "Scraping Pete Williams...\n",
      "https://www.ufc.com/athlete/pete-williams\n",
      "Scraping Patrick Williams...\n",
      "https://www.ufc.com/athlete/patrick-williams\n",
      "Scraping Tim Williams...\n",
      "https://www.ufc.com/athlete/tim-williams\n",
      "Scraping Jordan Williams...\n",
      "https://www.ufc.com/athlete/jordan-williams\n",
      "Scraping Tedd Williams...\n",
      "https://www.ufc.com/athlete/tedd-williams\n",
      "Scraping Karl Williams...\n",
      "https://www.ufc.com/athlete/karl-williams\n",
      "Scraping Justin Willis...\n",
      "https://www.ufc.com/athlete/justin-willis\n",
      "Scraping Jonathan Wilson...\n",
      "https://www.ufc.com/athlete/jonathan-wilson\n",
      "Scraping Chris Wilson...\n",
      "https://www.ufc.com/athlete/chris-wilson\n",
      "Scraping Westin Wilson...\n",
      "https://www.ufc.com/athlete/westin-wilson\n",
      "Scraping Matt Wiman...\n",
      "https://www.ufc.com/athlete/matt-wiman\n",
      "Scraping Eddie Wineland...\n",
      "https://www.ufc.com/athlete/eddie-wineland\n",
      "Scraping Deron Winn...\n",
      "https://www.ufc.com/athlete/deron-winn\n",
      "Scraping Andre Winner...\n",
      "https://www.ufc.com/athlete/andre-winner\n",
      "Scraping Eric Wisely...\n",
      "https://www.ufc.com/athlete/eric-wisely\n",
      "Scraping Keith Wisniewski...\n",
      "https://www.ufc.com/athlete/keith-wisniewski\n",
      "Scraping Jason Witt...\n",
      "https://www.ufc.com/athlete/jason-witt\n",
      "Scraping Travis Wiuff...\n",
      "https://www.ufc.com/athlete/travis-wiuff\n",
      "Scraping Ray Wizard...\n",
      "https://www.ufc.com/athlete/ray-wizard\n",
      "Scraping Karolina Wojcik...\n",
      "https://www.ufc.com/athlete/karolina-wojcik\n",
      "Scraping Danyelle Wolf...\n",
      "https://www.ufc.com/athlete/danyelle-wolf\n",
      "Scraping Brandon Wolff...\n",
      "https://www.ufc.com/athlete/brandon-wolff\n",
      "Scraping Joanne Wood...\n",
      "https://www.ufc.com/athlete/joanne-wood\n",
      "Scraping Nathaniel Wood...\n",
      "https://www.ufc.com/athlete/nathaniel-wood\n",
      "Scraping Val Woodburn...\n",
      "https://www.ufc.com/athlete/val-woodburn\n",
      "Scraping Tyron Woodley...\n",
      "https://www.ufc.com/athlete/tyron-woodley\n",
      "Scraping Sean Woodson...\n",
      "https://www.ufc.com/athlete/sean-woodson\n",
      "Scraping Cal Worsham...\n",
      "https://www.ufc.com/athlete/cal-worsham\n",
      "Scraping Khama Worthy...\n",
      "https://www.ufc.com/athlete/khama-worthy\n",
      "Scraping Justin Wren...\n",
      "https://www.ufc.com/athlete/justin-wren\n",
      "Scraping Jordan Wright...\n",
      "https://www.ufc.com/athlete/jordan-wright\n",
      "Scraping Marcin Wrzosek...\n",
      "https://www.ufc.com/athlete/marcin-wrzosek\n",
      "Scraping Song Yadong...\n",
      "https://www.ufc.com/athlete/yadong-song\n",
      "Scraping Jamie Yager...\n",
      "https://www.ufc.com/athlete/jamie-yager\n",
      "Scraping Eddie Yagin...\n",
      "https://www.ufc.com/athlete/eddie-yagin\n",
      "Scraping Rani Yahya...\n",
      "https://www.ufc.com/athlete/rani-yahya\n",
      "Scraping Mohammad Yahya...\n",
      "https://www.ufc.com/athlete/mohammad-yahya\n",
      "Scraping Alexander Yakovlev...\n",
      "https://www.ufc.com/athlete/alexander-yakovlev\n",
      "Scraping Keichiro Yamamiya...\n",
      "https://www.ufc.com/athlete/keichiro-yamamiya\n",
      "Scraping Norifumi Yamamoto...\n",
      "https://www.ufc.com/athlete/norifumi-yamamoto\n",
      "Scraping Kenichi Yamamoto...\n",
      "https://www.ufc.com/athlete/kenichi-yamamoto\n",
      "Scraping Yan Xiaonan...\n",
      "https://www.ufc.com/athlete/xiaonan-yan\n",
      "Scraping Petr Yan...\n",
      "https://www.ufc.com/athlete/petr-yan\n",
      "Scraping Qihui Yan...\n",
      "https://www.ufc.com/athlete/qihui-yan\n",
      "Scraping Wu Yanan...\n",
      "https://www.ufc.com/athlete/wu-yanan\n",
      "Scraping Adam Yandiev...\n",
      "https://www.ufc.com/athlete/adam-yandiev\n",
      "Scraping Adrian Yanez...\n",
      "https://www.ufc.com/athlete/adrian-yanez\n",
      "Scraping Dongi Yang...\n",
      "https://www.ufc.com/athlete/dongi-yang\n",
      "Scraping Jianping Yang...\n",
      "https://www.ufc.com/athlete/jianping-yang\n",
      "Scraping Masutatsu Yano...\n",
      "https://www.ufc.com/athlete/masutatsu-yano\n",
      "Scraping Hu Yaozong...\n",
      "https://www.ufc.com/athlete/hu-yaozong\n",
      "Scraping Cale Yarbrough...\n",
      "https://www.ufc.com/athlete/cale-yarbrough\n",
      "Scraping Emmanuel Yarbrough...\n",
      "https://www.ufc.com/athlete/emmanuel-yarbrough\n",
      "Scraping Ashley Yoder...\n",
      "https://www.ufc.com/athlete/ashley-yoder\n",
      "Scraping Sang Hoon Yoo...\n",
      "https://www.ufc.com/athlete/sang-hoon-yoo\n",
      "Scraping Jason Young...\n",
      "https://www.ufc.com/athlete/jason-young\n",
      "Scraping Shane Young...\n",
      "https://www.ufc.com/athlete/shane-young\n",
      "Scraping Shanna Young...\n",
      "https://www.ufc.com/athlete/shanna-young\n",
      "Scraping Besam Yousef...\n",
      "https://www.ufc.com/athlete/besam-yousef\n",
      "Scraping Rob Yundt...\n",
      "https://www.ufc.com/athlete/rob-yundt\n",
      "Scraping Sodiq Yusuff...\n",
      "https://www.ufc.com/athlete/sodiq-yusuff\n",
      "Scraping Gilbert Yvel...\n",
      "https://www.ufc.com/athlete/gilbert-yvel\n",
      "Scraping Luke Zachrich...\n",
      "https://www.ufc.com/athlete/luke-zachrich\n",
      "Scraping Anton Zafir...\n",
      "https://www.ufc.com/athlete/anton-zafir\n",
      "Scraping Aiemann Zahabi...\n",
      "https://www.ufc.com/athlete/aiemann-zahabi\n",
      "Scraping Joao Zaiden...\n",
      "https://www.ufc.com/athlete/joao-zaiden\n",
      "Scraping Youssef Zalal...\n",
      "https://www.ufc.com/athlete/youssef-zalal\n",
      "Scraping Zach Zane...\n",
      "https://www.ufc.com/athlete/zach-zane\n",
      "Scraping Roger Zapata...\n",
      "https://www.ufc.com/athlete/roger-zapata\n",
      "Scraping David Zawada...\n",
      "https://www.ufc.com/athlete/david-zawada\n",
      "Scraping Manolo Zecchini...\n",
      "https://www.ufc.com/athlete/manolo-zecchini\n",
      "Scraping Daniel Zellhuber...\n",
      "https://www.ufc.com/athlete/daniel-zellhuber\n",
      "Scraping Rickson Zenidim...\n",
      "https://www.ufc.com/athlete/rickson-zenidim\n",
      "Scraping Yizha...\n",
      "https://www.ufc.com/athlete/yi-zha\n",
      "Scraping Tiequan Zhang...\n",
      "https://www.ufc.com/athlete/tiequan-zhang\n",
      "Scraping Daermisi Zhawupasi...\n",
      "https://www.ufc.com/athlete/daermisi-zhawupasi\n",
      "Scraping Daria Zhelezniakova...\n",
      "https://www.ufc.com/athlete/daria-zheleznyakova\n",
      "Scraping Lu Zhengyong...\n",
      "https://www.ufc.com/athlete/lu-zhengyong\n",
      "Scraping Lv Zhenhong...\n",
      "https://www.ufc.com/athlete/lv-zhenhong\n",
      "Scraping Shang Zhifa...\n",
      "https://www.ufc.com/athlete/shang-zhifa\n",
      "Scraping Yao Zhikui...\n",
      "https://www.ufc.com/athlete/yao-zhikui\n",
      "Scraping Zhalgas Zhumagulov...\n",
      "https://www.ufc.com/athlete/zhalgas-zhumagulov\n",
      "Scraping Fars Ziam...\n",
      "https://www.ufc.com/athlete/fares-ziam\n",
      "Scraping James Zikic...\n",
      "https://www.ufc.com/athlete/james-zikic\n",
      "Scraping Cat Zingano...\n",
      "https://www.ufc.com/athlete/cat-zingano\n",
      "Scraping Igor Zinoviev...\n",
      "https://www.ufc.com/athlete/igor-zinoviev\n",
      "Scraping Allan Zuniga...\n",
      "https://www.ufc.com/athlete/allan-zuniga\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#site request\n",
    "proxyheader = getProxyUserAgentUFC()\n",
    "proxy = proxyheader[0]\n",
    "userAgent = proxyheader[1]\n",
    "\n",
    "url = \"https://www.ufc.com/athletes/all\"\n",
    "\n",
    "querystring = {\"page\":\"0\"}\n",
    "\n",
    "payload = \"\"\n",
    "headers = {\n",
    "    \"cookie\": \"STYXKEY_region=USA.US.en.Default\",\n",
    "    \"User-Agent\": f'{userAgent}'\n",
    "}\n",
    "\n",
    "response = requests.request(\"GET\", url, data=payload, headers=headers, params=querystring, proxies={'http': f\"http://{proxy}\"})\n",
    "\n",
    "\n",
    "#create soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "div = soup.find('div', class_=re.compile('althelete-total'))\n",
    "\n",
    "#get num athletes\n",
    "athleteTotal = div.text.strip().split(' ')[0]\n",
    "print(f\"Athletes found: {athleteTotal}\")\n",
    "\n",
    "#calc number of pages to loop through - 11 fighters shown per\n",
    "numPages = math.ceil(int(athleteTotal)/11)\n",
    "print(numPages)\n",
    "\n",
    "\n",
    "linkParts = []\n",
    "for i in range(numPages):\n",
    "    try:\n",
    "        proxyheader = getProxyUserAgentUFC()\n",
    "        proxy = proxyheader[0]\n",
    "        userAgent = proxyheader[1]\n",
    "        print(i)\n",
    "        #site request\n",
    "        url = \"https://www.ufc.com/athletes/all\"\n",
    "        querystring = {\"page\":f\"{i}\"}\n",
    "\n",
    "        payload = \"\"\n",
    "        headers = {\n",
    "            \"cookie\": \"STYXKEY_region=USA.US.en.Default\",\n",
    "            \"User-Agent\": f'{userAgent}'\n",
    "        }\n",
    "\n",
    "        response = requests.request(\"GET\", url, data=payload, headers=headers, params=querystring, proxies={'http': f\"http://{proxy}\"})\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        urlParts = soup.find_all('a', class_=re.compile(\"e-button--black\"))\n",
    "\n",
    "\n",
    "\n",
    "        for part in urlParts:\n",
    "            href = part['href']\n",
    "            if href:\n",
    "                linkParts.append(href)\n",
    "    except:\n",
    "        print(\"Waiting for new IP... (no func)\")\n",
    "        ipurl = \"https://ipecho.net/plain\"\n",
    "        ipHeader = {\"User-Agent\": \"insomnia/8.4.5\"}\n",
    "        ipr = requests.request(\"GET\", url=ipurl, headers=ipHeader)\n",
    "        soup = BeautifulSoup(ipr.content, 'html.parser')\n",
    "        currentIp = soup.text.strip()\n",
    "        newIP = soup.text.strip()\n",
    "        while(currentIp == newIP):\n",
    "            ipurl = \"https://ipecho.net/plain\"\n",
    "            ipHeader = {\"User-Agent\": \"insomnia/8.4.5\"}\n",
    "            ipr = requests.request(\"GET\", url=ipurl, headers=ipHeader)\n",
    "            soup = BeautifulSoup(ipr.content, 'html.parser')\n",
    "            newIP = soup.text.strip()\n",
    "            time.sleep(15)\n",
    "        i=i-1\n",
    "\n",
    "print(f\"Fighter links found: {len(linkParts)}\")\n",
    "\n",
    "\n",
    "\n",
    "fighterStats = []\n",
    "for part in range(len(linkParts)):\n",
    "    try:\n",
    "        #site request\n",
    "        proxyheader = getProxyUserAgentUFC()\n",
    "        proxy = proxyheader[0]\n",
    "        userAgent = proxyheader[1]\n",
    "        #site request\n",
    "        url = f\"https://www.ufc.com{linkParts[part]}\"\n",
    "        querystring = {\"page\":f\"{i}\"}\n",
    "\n",
    "        payload = \"\"\n",
    "        headers = {\n",
    "            \"cookie\": \"STYXKEY_region=USA.US.en.Default\",\n",
    "            \"User-Agent\": f'{userAgent}'\n",
    "        }\n",
    "\n",
    "        site = requests.request(\"GET\", url, data=payload, headers=headers, params=querystring, proxies={'http': f\"http://{proxy}\"})\n",
    "\n",
    "        #initalize attributes\n",
    "        name = None\n",
    "        nickname = None\n",
    "        wins = None\n",
    "        losses = None\n",
    "        draws = None\n",
    "        sig_str_accuracy = None\n",
    "        sig_str_totals = None\n",
    "        takedown_accuracy = None\n",
    "        takedown_totals = None\n",
    "        sig_str_per_minute = None\n",
    "        takedown_avg_per_fifteen = None\n",
    "        sig_str_defense = None\n",
    "        knockdown_avg = None\n",
    "        sig_str_absorbed_per_min = None\n",
    "        submission_avg_per_fifteen = None\n",
    "        takedown_defense = None\n",
    "        avg_fight_time = None\n",
    "        nation = None\n",
    "        age = None\n",
    "        height = None\n",
    "        reach = None\n",
    "\n",
    "        #soup\n",
    "        soup = BeautifulSoup(site.content, 'html.parser')\n",
    "\n",
    "        #scrape + clean name\n",
    "        try:\n",
    "            name = soup.find('h1', class_=re.compile('hero-profile__name')).text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "\n",
    "        #scrape + clean nickname\n",
    "        try:\n",
    "            nick = soup.find('p', class_=re.compile('hero-profile__nickname'))\n",
    "            nickname = nick.text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        #scrape + clean wins, losses, draws\n",
    "        try:\n",
    "            record = soup.find('p', class_=re.compile('hero-profile__division-body')).text.strip().split(' ')\n",
    "            record = record[0].split('-')\n",
    "            wins = record[0]\n",
    "            losses = record[1]\n",
    "            draws = record[2]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        #scrape + clean sig_str_accuracy + sig_str_totals + takedown_accuracy + takedown_totals\n",
    "        try:\n",
    "            div = soup.find_all('div', class_=re.compile(\"overlap-athlete-content overlap-athlete-content--horizontal\"))\n",
    "            stripped = div[0].text.strip().split('\\n')\n",
    "            clean_stripped = [item for item in stripped if item != '']\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            if(clean_stripped[2].lower() == 'striking accuracy'):\n",
    "                sig_str_accuracy = clean_stripped[1]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            if(clean_stripped[3].lower() == \"sig. strikes landed\" and clean_stripped[5].lower() == \"sig. strikes attempted\"):\n",
    "                sig_str_totals = f\"{clean_stripped[4]} of {clean_stripped[6]}\"\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        #scrape + clean sig_str_per_minute + takedown_avg_per_fifteen + sig_str_defense + knockdown_avg\n",
    "\n",
    "        divs = soup.find_all('div', class_=re.compile('c-stat-compare__group c-stat-compare__group-1'))\n",
    "\n",
    "        for div in divs:\n",
    "            try:\n",
    "                if(div.find('div', class_=re.compile('c-stat-compare__label')).text.strip().lower() == \"sig. str. landed\"):\n",
    "                    sig_str_per_minute = div.find('div', class_=re.compile(\"c-stat-compare__number\")).text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                if(div.find('div', class_=re.compile('c-stat-compare__label')).text.strip().lower() == \"takedown avg\"):\n",
    "                    takedown_avg_per_fifteen = div.find('div', class_=re.compile(\"c-stat-compare__number\")).text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                if(div.find('div', class_=re.compile('c-stat-compare__label')).text.strip().lower() == \"sig. str. defense\"):\n",
    "                    sig_str_defense = str(div.find('div', class_=re.compile(\"c-stat-compare__number\")).text.strip().split(\"\\n\")[0]) +\"%\"\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                if(div.find('div', class_=re.compile('c-stat-compare__label')).text.strip().lower() == \"knockdown avg\"):\n",
    "                    knockdown_avg = div.find('div', class_=re.compile(\"c-stat-compare__number\")).text.strip()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "        # scrape + clean sig_str_absorbed_per_min + submission_avg_per_fifteen + takedown_defense + avg_fight_time\n",
    "        divs = soup.find_all('div', re.compile('c-stat-compare__group c-stat-compare__group-2'))\n",
    "        for div in divs:\n",
    "            try:\n",
    "                if(div.find('div', class_=re.compile('c-stat-compare__label')).text.strip().lower() == \"sig. str. absorbed\"):\n",
    "                    sig_str_absorbed_per_min = div.find('div', class_=re.compile(\"c-stat-compare__number\")).text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                if(div.find('div', class_=re.compile('c-stat-compare__label')).text.strip().lower() == \"submission avg\"):\n",
    "                    submission_avg_per_fifteen = div.find('div', class_=re.compile(\"c-stat-compare__number\")).text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                if(div.find('div', class_=re.compile('c-stat-compare__label')).text.strip().lower() == \"takedown defense\"):\n",
    "                    takedown_defense = str(div.find('div', class_=re.compile(\"c-stat-compare__number\")).text.strip().split('\\n')[0]) +\"%\"\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                if(div.find('div', class_=re.compile('c-stat-compare__label')).text.strip().lower() == \"average fight time\"):\n",
    "                    avg_fight_time = div.find('div', class_=re.compile(\"c-stat-compare__number\")).text.strip()\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "\n",
    "\n",
    "        #scrape + clean nation + age + height + reach\n",
    "        divs = soup.find_all('div', class_=re.compile('c-bio__field'))\n",
    "\n",
    "        for div in divs:\n",
    "            try:\n",
    "                if(div.find('div', class_=re.compile('c-bio__label')).text.strip().lower() == 'place of birth'):\n",
    "                    nation = div.find('div', class_=re.compile('c-bio__text')).text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                if(div.find('div', class_=re.compile('c-bio__label')).text.strip().lower() == 'age'):\n",
    "                    age = div.find('div', class_=re.compile('field field--name-age field--type-integer field--label-hidden field__item')).text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                if(div.find('div', class_=re.compile('c-bio__label')).text.strip().lower() == 'height'):\n",
    "                    height = div.find('div', class_=re.compile('c-bio__text')).text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                if(div.find('div', class_=re.compile('c-bio__label')).text.strip().lower() == 'reach'):\n",
    "                    reach = div.find('div', class_=re.compile('c-bio__text')).text.strip()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "        print(f'Scraping {name}...')\n",
    "        print(url)\n",
    "        fighterStats.append([name, nickname, wins, losses, draws, height, reach, age, nation, sig_str_accuracy, sig_str_totals, takedown_accuracy, takedown_totals, sig_str_per_minute, takedown_avg_per_fifteen, sig_str_defense, knockdown_avg, sig_str_absorbed_per_min, submission_avg_per_fifteen, takedown_defense, avg_fight_time])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "#create csv file\n",
    "\n",
    "head = ['name', 'nickname', 'wins', 'losses', 'draws', 'height', 'reach', 'age', 'nation', 'sig_str_accuracy', 'sig_str_totals', 'takedown_accuracy', 'takedown_totals', 'sig_str_per_minute', 'takedown_avg_per_fifteen', 'sig_str_defense', 'knockdown_avg', 'sig_str_absorbed_per_min', 'submission_avg_per_fifteen', 'takedown_defense', 'avg_fight_time']\n",
    "\n",
    "with open(f'alt_fighter_stats{dateToday}.csv', 'w', encoding='UTF8', newline='') as scrapedFighters:\n",
    "    writer = csv.writer(scrapedFighters)\n",
    "    writer.writerow(head)\n",
    "    writer.writerows(fighterStats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#create csv file\n",
    "\n",
    "head = ['name', 'nickname', 'wins', 'losses', 'draws', 'height', 'reach', 'age', 'nation', 'sig_str_accuracy', 'sig_str_totals', 'takedown_accuracy', 'takedown_totals', 'sig_str_per_minute', 'takedown_avg_per_fifteen', 'sig_str_defense', 'knockdown_avg', 'sig_str_absorbed_per_min', 'submission_avg_per_fifteen', 'takedown_defense', 'avg_fight_time']\n",
    "\n",
    "with open(f'alt_fighter_stats{dateToday}.csv', 'w', encoding='UTF8', newline='') as scrapedFighters:\n",
    "    writer = csv.writer(scrapedFighters)\n",
    "    writer.writerow(head)\n",
    "    writer.writerows(fighterStats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nickname</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>draws</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>reach</th>\n",
       "      <th>stance</th>\n",
       "      <th>dOB</th>\n",
       "      <th>sig_strikes_landed_per_min</th>\n",
       "      <th>sig_striking_accuracy_%</th>\n",
       "      <th>sig_strike_absorbed_per_min</th>\n",
       "      <th>sig_strike_defense(%_of_sig_strikes_not_landed_by_opponent)</th>\n",
       "      <th>takedown_average(average_takedown_landed_per_fifteen_min)</th>\n",
       "      <th>takedown_accuracy_%</th>\n",
       "      <th>takedown_defense(%_of_opponent_takedown_not_landed)</th>\n",
       "      <th>sub_average(average_subs_attempted_per_15_mins)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tom Aaron</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>--</td>\n",
       "      <td>155 lbs.</td>\n",
       "      <td>--</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jul 13, 1978</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Danny Abbadi</td>\n",
       "      <td>The Assassin</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5' 11\"</td>\n",
       "      <td>155 lbs.</td>\n",
       "      <td>--</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Jul 03, 1983</td>\n",
       "      <td>3.29</td>\n",
       "      <td>38%</td>\n",
       "      <td>4.41</td>\n",
       "      <td>57%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0%</td>\n",
       "      <td>77%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nariman Abbasov</td>\n",
       "      <td>Bayraktar</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>155 lbs.</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Feb 01, 1994</td>\n",
       "      <td>3.00</td>\n",
       "      <td>20%</td>\n",
       "      <td>5.67</td>\n",
       "      <td>46%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0%</td>\n",
       "      <td>66%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David Abbott</td>\n",
       "      <td>Tank</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>6' 0\"</td>\n",
       "      <td>265 lbs.</td>\n",
       "      <td>--</td>\n",
       "      <td>Switch</td>\n",
       "      <td>--</td>\n",
       "      <td>1.35</td>\n",
       "      <td>30%</td>\n",
       "      <td>3.55</td>\n",
       "      <td>38%</td>\n",
       "      <td>1.07</td>\n",
       "      <td>33%</td>\n",
       "      <td>66%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hamdy Abdelwahab</td>\n",
       "      <td>The Hammer</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0 (1 NC)</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>264 lbs.</td>\n",
       "      <td>72\"</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>Jan 22, 1993</td>\n",
       "      <td>3.87</td>\n",
       "      <td>52%</td>\n",
       "      <td>3.13</td>\n",
       "      <td>59%</td>\n",
       "      <td>3.00</td>\n",
       "      <td>75%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name      nickname  wins  losses     draws  height    weight  \\\n",
       "0         Tom Aaron           NaN     5       3         0      --  155 lbs.   \n",
       "1      Danny Abbadi  The Assassin     4       6         0  5' 11\"  155 lbs.   \n",
       "2   Nariman Abbasov     Bayraktar    28       4         0   5' 8\"  155 lbs.   \n",
       "3      David Abbott          Tank    10      15         0   6' 0\"  265 lbs.   \n",
       "4  Hamdy Abdelwahab    The Hammer     5       0  0 (1 NC)   6' 2\"  264 lbs.   \n",
       "\n",
       "  reach    stance           dOB  sig_strikes_landed_per_min  \\\n",
       "0    --       NaN  Jul 13, 1978                        0.00   \n",
       "1    --  Orthodox  Jul 03, 1983                        3.29   \n",
       "2   66\"  Orthodox  Feb 01, 1994                        3.00   \n",
       "3    --    Switch            --                        1.35   \n",
       "4   72\"  Southpaw  Jan 22, 1993                        3.87   \n",
       "\n",
       "  sig_striking_accuracy_%  sig_strike_absorbed_per_min  \\\n",
       "0                      0%                         0.00   \n",
       "1                     38%                         4.41   \n",
       "2                     20%                         5.67   \n",
       "3                     30%                         3.55   \n",
       "4                     52%                         3.13   \n",
       "\n",
       "  sig_strike_defense(%_of_sig_strikes_not_landed_by_opponent)  \\\n",
       "0                                                 0%            \n",
       "1                                                57%            \n",
       "2                                                46%            \n",
       "3                                                38%            \n",
       "4                                                59%            \n",
       "\n",
       "   takedown_average(average_takedown_landed_per_fifteen_min)  \\\n",
       "0                                               0.00           \n",
       "1                                               0.00           \n",
       "2                                               0.00           \n",
       "3                                               1.07           \n",
       "4                                               3.00           \n",
       "\n",
       "  takedown_accuracy_% takedown_defense(%_of_opponent_takedown_not_landed)  \\\n",
       "0                  0%                                                 0%    \n",
       "1                  0%                                                77%    \n",
       "2                  0%                                                66%    \n",
       "3                 33%                                                66%    \n",
       "4                 75%                                                 0%    \n",
       "\n",
       "   sub_average(average_subs_attempted_per_15_mins)  \n",
       "0                                              0.0  \n",
       "1                                              0.0  \n",
       "2                                              0.0  \n",
       "3                                              0.0  \n",
       "4                                              0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#dateToday = datetime.datetime.today().date()\n",
    "df = pd.read_csv(f'ufc_fighters_statistics{dateToday}.csv')\n",
    "dfAlt = pd.read_csv(f'alt_fighter_stats{dateToday}.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nickname</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>draws</th>\n",
       "      <th>height</th>\n",
       "      <th>reach</th>\n",
       "      <th>age</th>\n",
       "      <th>nation</th>\n",
       "      <th>sig_str_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>takedown_accuracy</th>\n",
       "      <th>takedown_totals</th>\n",
       "      <th>sig_str_per_minute</th>\n",
       "      <th>takedown_avg_per_fifteen</th>\n",
       "      <th>sig_str_defense</th>\n",
       "      <th>knockdown_avg</th>\n",
       "      <th>sig_str_absorbed_per_min</th>\n",
       "      <th>submission_avg_per_fifteen</th>\n",
       "      <th>takedown_defense</th>\n",
       "      <th>avg_fight_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danny Abbadi</td>\n",
       "      <td>\"The Assassin\"</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Orlando, United States</td>\n",
       "      <td>38%</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78%</td>\n",
       "      <td>08:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nariman Abbassov</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Kazakhstan</td>\n",
       "      <td>20%</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67%</td>\n",
       "      <td>15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tank Abbott</td>\n",
       "      <td>\"Tank\"</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Huntington Beach, United States</td>\n",
       "      <td>39%</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67%</td>\n",
       "      <td>01:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hamdy Abdelwahab</td>\n",
       "      <td>\"The Hammer\"</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>53%</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.87</td>\n",
       "      <td>3.0</td>\n",
       "      <td>59%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mansur Abdul-Malik</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>79.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Pittsburgh, United States</td>\n",
       "      <td>53%</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75%</td>\n",
       "      <td>08:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name        nickname  wins  losses  draws  height  reach  \\\n",
       "0        Danny Abbadi  \"The Assassin\"   2.0     2.0    0.0    71.0    NaN   \n",
       "1    Nariman Abbassov             NaN   0.0     1.0    0.0     NaN    NaN   \n",
       "2         Tank Abbott          \"Tank\"   8.0    10.0    0.0    72.0    NaN   \n",
       "3    Hamdy Abdelwahab    \"The Hammer\"   5.0     0.0    0.0    74.0   72.0   \n",
       "4  Mansur Abdul-Malik             NaN   1.0     0.0    0.0    74.0   79.5   \n",
       "\n",
       "    age                           nation sig_str_accuracy  ...  \\\n",
       "0  39.0           Orlando, United States              38%  ...   \n",
       "1  29.0                       Kazakhstan              20%  ...   \n",
       "2   NaN  Huntington Beach, United States              39%  ...   \n",
       "3  30.0                            Egypt              53%  ...   \n",
       "4  26.0        Pittsburgh, United States              53%  ...   \n",
       "\n",
       "  takedown_accuracy  takedown_totals  sig_str_per_minute  \\\n",
       "0               NaN              NaN                3.29   \n",
       "1               NaN              NaN                3.00   \n",
       "2               NaN              NaN                2.41   \n",
       "3               NaN              NaN                3.87   \n",
       "4               NaN              NaN                5.38   \n",
       "\n",
       "   takedown_avg_per_fifteen  sig_str_defense knockdown_avg  \\\n",
       "0                       0.0              58%           0.0   \n",
       "1                       0.0              46%           0.0   \n",
       "2                       0.0              38%           0.0   \n",
       "3                       3.0              59%           1.0   \n",
       "4                       0.0              54%           0.0   \n",
       "\n",
       "   sig_str_absorbed_per_min  submission_avg_per_fifteen  takedown_defense  \\\n",
       "0                      4.41                         0.0               78%   \n",
       "1                      5.67                         0.0               67%   \n",
       "2                     10.03                         0.0               67%   \n",
       "3                      3.13                         0.0               NaN   \n",
       "4                      5.16                         0.0               75%   \n",
       "\n",
       "  avg_fight_time  \n",
       "0          08:58  \n",
       "1          15:00  \n",
       "2          01:40  \n",
       "3          15:00  \n",
       "4          08:55  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAlt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4238\n",
      "2968\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(len(dfAlt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean nicknames in dfAlt\n",
    "dfAlt['nickname'] = dfAlt['nickname'].str.replace('\"', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving nans characters so dups with nans for nickname cannot match\n",
    "df['nickname'].fillna('!', inplace=True)\n",
    "dfAlt['nickname'].fillna('~', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nickname</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>draws</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>reach</th>\n",
       "      <th>stance</th>\n",
       "      <th>dOB</th>\n",
       "      <th>sig_strikes_landed_per_min</th>\n",
       "      <th>sig_striking_accuracy_%</th>\n",
       "      <th>sig_strike_absorbed_per_min</th>\n",
       "      <th>sig_strike_defense(%_of_sig_strikes_not_landed_by_opponent)</th>\n",
       "      <th>takedown_average(average_takedown_landed_per_fifteen_min)</th>\n",
       "      <th>takedown_accuracy_%</th>\n",
       "      <th>takedown_defense(%_of_opponent_takedown_not_landed)</th>\n",
       "      <th>sub_average(average_subs_attempted_per_15_mins)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tom Aaron</td>\n",
       "      <td>!</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>--</td>\n",
       "      <td>155 lbs.</td>\n",
       "      <td>--</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jul 13, 1978</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Danny Abbadi</td>\n",
       "      <td>The Assassin</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5' 11\"</td>\n",
       "      <td>155 lbs.</td>\n",
       "      <td>--</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Jul 03, 1983</td>\n",
       "      <td>3.29</td>\n",
       "      <td>38%</td>\n",
       "      <td>4.41</td>\n",
       "      <td>57%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0%</td>\n",
       "      <td>77%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nariman Abbasov</td>\n",
       "      <td>Bayraktar</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>155 lbs.</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Feb 01, 1994</td>\n",
       "      <td>3.00</td>\n",
       "      <td>20%</td>\n",
       "      <td>5.67</td>\n",
       "      <td>46%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0%</td>\n",
       "      <td>66%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David Abbott</td>\n",
       "      <td>Tank</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>6' 0\"</td>\n",
       "      <td>265 lbs.</td>\n",
       "      <td>--</td>\n",
       "      <td>Switch</td>\n",
       "      <td>--</td>\n",
       "      <td>1.35</td>\n",
       "      <td>30%</td>\n",
       "      <td>3.55</td>\n",
       "      <td>38%</td>\n",
       "      <td>1.07</td>\n",
       "      <td>33%</td>\n",
       "      <td>66%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hamdy Abdelwahab</td>\n",
       "      <td>The Hammer</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0 (1 NC)</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>264 lbs.</td>\n",
       "      <td>72\"</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>Jan 22, 1993</td>\n",
       "      <td>3.87</td>\n",
       "      <td>52%</td>\n",
       "      <td>3.13</td>\n",
       "      <td>59%</td>\n",
       "      <td>3.00</td>\n",
       "      <td>75%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name      nickname  wins  losses     draws  height    weight  \\\n",
       "0         Tom Aaron             !     5       3         0      --  155 lbs.   \n",
       "1      Danny Abbadi  The Assassin     4       6         0  5' 11\"  155 lbs.   \n",
       "2   Nariman Abbasov     Bayraktar    28       4         0   5' 8\"  155 lbs.   \n",
       "3      David Abbott          Tank    10      15         0   6' 0\"  265 lbs.   \n",
       "4  Hamdy Abdelwahab    The Hammer     5       0  0 (1 NC)   6' 2\"  264 lbs.   \n",
       "\n",
       "  reach    stance           dOB  sig_strikes_landed_per_min  \\\n",
       "0    --       NaN  Jul 13, 1978                        0.00   \n",
       "1    --  Orthodox  Jul 03, 1983                        3.29   \n",
       "2   66\"  Orthodox  Feb 01, 1994                        3.00   \n",
       "3    --    Switch            --                        1.35   \n",
       "4   72\"  Southpaw  Jan 22, 1993                        3.87   \n",
       "\n",
       "  sig_striking_accuracy_%  sig_strike_absorbed_per_min  \\\n",
       "0                      0%                         0.00   \n",
       "1                     38%                         4.41   \n",
       "2                     20%                         5.67   \n",
       "3                     30%                         3.55   \n",
       "4                     52%                         3.13   \n",
       "\n",
       "  sig_strike_defense(%_of_sig_strikes_not_landed_by_opponent)  \\\n",
       "0                                                 0%            \n",
       "1                                                57%            \n",
       "2                                                46%            \n",
       "3                                                38%            \n",
       "4                                                59%            \n",
       "\n",
       "   takedown_average(average_takedown_landed_per_fifteen_min)  \\\n",
       "0                                               0.00           \n",
       "1                                               0.00           \n",
       "2                                               0.00           \n",
       "3                                               1.07           \n",
       "4                                               3.00           \n",
       "\n",
       "  takedown_accuracy_% takedown_defense(%_of_opponent_takedown_not_landed)  \\\n",
       "0                  0%                                                 0%    \n",
       "1                  0%                                                77%    \n",
       "2                  0%                                                66%    \n",
       "3                 33%                                                66%    \n",
       "4                 75%                                                 0%    \n",
       "\n",
       "   sub_average(average_subs_attempted_per_15_mins)  \n",
       "0                                              0.0  \n",
       "1                                              0.0  \n",
       "2                                              0.0  \n",
       "3                                              0.0  \n",
       "4                                              0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n"
     ]
    }
   ],
   "source": [
    "#find special characters in df\n",
    "names = (df['name'].values)\n",
    "nicknames = (df['nickname'].values)\n",
    "\n",
    "chars2rep = []\n",
    "for name in names:\n",
    "    if(isinstance(name, str)):\n",
    "        for char in name:\n",
    "            if char.lower() not in ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "            if char.upper() not in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', \"Q\", 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "for nickname in nicknames:\n",
    "    if(isinstance(nickname, str)):\n",
    "        for char in nickname:\n",
    "            if char.lower() not in ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "            if char.upper() not in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', \"Q\", 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "\n",
    "\n",
    "chars2rep = list(set(chars2rep))\n",
    "for char in chars2rep:\n",
    "    print(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean name, nickname\n",
    "for index, row in df.iterrows():\n",
    "    name = row['name']\n",
    "    nickname = row['nickname']\n",
    "    if(isinstance(name, str)):\n",
    "        cleanName = name.replace('?', '').replace('4', '').replace('9', '').replace('0', '').replace('5', '').replace('7', '').replace('1', '').replace(',', '').replace('3', '').replace('%', '').replace(\"'\", '').replace('-', '').replace('2', '').replace('.', '')\n",
    "        df.loc[index, 'name'] = cleanName\n",
    "    if(isinstance(nickname, str)):\n",
    "        cleanNickname = nickname.replace('?', '').replace('4', '').replace('9', '').replace('0', '').replace('5', '').replace('7', '').replace('1', '').replace(',', '').replace('3', '').replace('%', '').replace(\"'\", '').replace('-', '').replace('2', '').replace('.', '')\n",
    "        df.loc[index, 'nickname'] = cleanNickname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~\n"
     ]
    }
   ],
   "source": [
    "#find special characters in df\n",
    "names = (dfAlt['name'].values)\n",
    "nicknames = (dfAlt['nickname'].values)\n",
    "\n",
    "chars2rep = []\n",
    "for name in names:\n",
    "    if(isinstance(name, str)):\n",
    "        for char in name:\n",
    "            if char.lower() not in ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "            if char.upper() not in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', \"Q\", 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "for nickname in nicknames:\n",
    "    if(isinstance(nickname, str)):\n",
    "        for char in nickname:\n",
    "            if char.lower() not in ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "            if char.upper() not in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', \"Q\", 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "\n",
    "\n",
    "chars2rep = list(set(chars2rep))\n",
    "for char in chars2rep:\n",
    "    print(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean name, nickname\n",
    "for index, row in dfAlt.iterrows():\n",
    "    name = row['name']\n",
    "    nickname = row['nickname']\n",
    "    if(isinstance(name, str)):\n",
    "        cleanName = name.replace('2', '').replace('(', '').replace('3', '').replace('', 'u').replace('', 'c').replace('', 'A').replace('7', '').replace('', 'i').replace('0', '').replace('', 'e').replace('4', '').replace(\"'\", '').replace('%', '').replace('\"', '').replace('', 'a').replace(',', '').replace('', 'c').replace('', 'n').replace(')', '').replace('', 'l').replace('-', '').replace('8', '').replace('', 'e').replace('1', '').replace('', 'e').replace('5', '').replace('', '').replace('', '').replace('', 'r').replace('', 'i').replace('', '').replace('', 'a').replace('', 'n').replace('', 'e').replace('.', '').replace('', '')\n",
    "        dfAlt.loc[index, 'name'] = cleanName\n",
    "    if(isinstance(nickname, str)):\n",
    "        cleanNickname = nickname.replace('2', '').replace('(', '').replace('3', '').replace('', 'u').replace('', 'c').replace('', 'A').replace('7', '').replace('', 'i').replace('0', '').replace('', 'e').replace('4', '').replace(\"'\", '').replace('%', '').replace('\"', '').replace('', 'a').replace(',', '').replace('', 'c').replace('', 'n').replace(')', '').replace('', 'l').replace('-', '').replace('8', '').replace('', 'e').replace('1', '').replace('', 'e').replace('5', '').replace('', '').replace('', '').replace('', 'r').replace('', 'i').replace('', '').replace('', 'a').replace('', 'n').replace('', 'e').replace('.', '').replace('', '')\n",
    "        dfAlt.loc[index, 'nickname'] = cleanNickname\n",
    "\n",
    "for char in chars2rep:\n",
    "    for index, row in dfAlt.iterrows():\n",
    "        name = row['name']\n",
    "        nickname = row['nickname']\n",
    "        if(char != '~'):\n",
    "            if(isinstance(name, str)):\n",
    "                cleanName = name.replace(char, '')\n",
    "                dfAlt.loc[index, 'name'] = cleanName\n",
    "            if(isinstance(nickname, str)):\n",
    "                cleanNickname = nickname.replace(char, '')\n",
    "                dfAlt.loc[index, 'nickname'] = cleanNickname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign nicknames for matching names found within dataframes\n",
    "count = 1\n",
    "for index, row in df.iterrows():\n",
    "    name = row['name']\n",
    "    nickname = row['nickname']\n",
    "    dup_check = df.loc[df['name'] == name]\n",
    "    dup_check2 = dfAlt.loc[dfAlt['name'] == name]\n",
    "    if(len(dup_check == 1) and len(dup_check2) == 1):\n",
    "        try:\n",
    "            altIndex = dfAlt.loc[dfAlt['name'] == name].index[0]\n",
    "            altNickname = dfAlt.loc[altIndex, 'nickname']\n",
    "            if(nickname != altNickname):\n",
    "                if(nickname == '!' and altNickname == '~'):\n",
    "                    df.loc[index, 'nickname'] = str(count)\n",
    "                    dfAlt.loc[altIndex, 'nickname'] = str(count)\n",
    "                    count+=1\n",
    "                elif(nickname != '!'):\n",
    "                    dfAlt.loc[altIndex, 'nickname'] = nickname\n",
    "                elif(altNickname != '~'):\n",
    "                    df.loc[index, 'nickname'] = altNickname\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nickname</th>\n",
       "      <th>wins_x</th>\n",
       "      <th>losses_x</th>\n",
       "      <th>draws_x</th>\n",
       "      <th>height_x</th>\n",
       "      <th>weight</th>\n",
       "      <th>reach_x</th>\n",
       "      <th>stance</th>\n",
       "      <th>dOB</th>\n",
       "      <th>...</th>\n",
       "      <th>takedown_totals</th>\n",
       "      <th>sig_str_per_minute</th>\n",
       "      <th>takedown_avg_per_fifteen</th>\n",
       "      <th>sig_str_defense</th>\n",
       "      <th>knockdown_avg</th>\n",
       "      <th>sig_str_absorbed_per_min</th>\n",
       "      <th>submission_avg_per_fifteen</th>\n",
       "      <th>takedown_defense</th>\n",
       "      <th>avg_fight_time</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tom Aaron</td>\n",
       "      <td>!</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>--</td>\n",
       "      <td>155 lbs.</td>\n",
       "      <td>--</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jul 13, 1978</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Danny Abbadi</td>\n",
       "      <td>The Assassin</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5' 11\"</td>\n",
       "      <td>155 lbs.</td>\n",
       "      <td>--</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Jul 03, 1983</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78%</td>\n",
       "      <td>08:58</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nariman Abbasov</td>\n",
       "      <td>Bayraktar</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>155 lbs.</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Feb 01, 1994</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David Abbott</td>\n",
       "      <td>Tank</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6' 0\"</td>\n",
       "      <td>265 lbs.</td>\n",
       "      <td>--</td>\n",
       "      <td>Switch</td>\n",
       "      <td>--</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hamdy Abdelwahab</td>\n",
       "      <td>The Hammer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 (1 NC)</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>264 lbs.</td>\n",
       "      <td>72\"</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>Jan 22, 1993</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.87</td>\n",
       "      <td>3.0</td>\n",
       "      <td>59%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15:00</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               name      nickname  wins_x  losses_x   draws_x height_x  \\\n",
       "0         Tom Aaron             !     5.0       3.0         0       --   \n",
       "1      Danny Abbadi  The Assassin     4.0       6.0         0   5' 11\"   \n",
       "2   Nariman Abbasov     Bayraktar    28.0       4.0         0    5' 8\"   \n",
       "3      David Abbott          Tank    10.0      15.0         0    6' 0\"   \n",
       "4  Hamdy Abdelwahab    The Hammer     5.0       0.0  0 (1 NC)    6' 2\"   \n",
       "\n",
       "     weight reach_x    stance           dOB  ...  takedown_totals  \\\n",
       "0  155 lbs.      --       NaN  Jul 13, 1978  ...              NaN   \n",
       "1  155 lbs.      --  Orthodox  Jul 03, 1983  ...              NaN   \n",
       "2  155 lbs.     66\"  Orthodox  Feb 01, 1994  ...              NaN   \n",
       "3  265 lbs.      --    Switch            --  ...              NaN   \n",
       "4  264 lbs.     72\"  Southpaw  Jan 22, 1993  ...              NaN   \n",
       "\n",
       "  sig_str_per_minute  takedown_avg_per_fifteen sig_str_defense  knockdown_avg  \\\n",
       "0                NaN                       NaN             NaN            NaN   \n",
       "1               3.29                       0.0             58%            0.0   \n",
       "2                NaN                       NaN             NaN            NaN   \n",
       "3                NaN                       NaN             NaN            NaN   \n",
       "4               3.87                       3.0             59%            1.0   \n",
       "\n",
       "  sig_str_absorbed_per_min submission_avg_per_fifteen  takedown_defense  \\\n",
       "0                      NaN                        NaN               NaN   \n",
       "1                     4.41                        0.0               78%   \n",
       "2                      NaN                        NaN               NaN   \n",
       "3                      NaN                        NaN               NaN   \n",
       "4                     3.13                        0.0               NaN   \n",
       "\n",
       "   avg_fight_time     _merge  \n",
       "0             NaN  left_only  \n",
       "1           08:58       both  \n",
       "2             NaN  left_only  \n",
       "3             NaN  left_only  \n",
       "4           15:00       both  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#outer merge the dfs\n",
    "dfMerged = pd.merge(df, dfAlt, on=['name', 'nickname'], how='outer', indicator=True)\n",
    "dfMerged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nickname</th>\n",
       "      <th>wins_x</th>\n",
       "      <th>losses_x</th>\n",
       "      <th>draws_x</th>\n",
       "      <th>height_x</th>\n",
       "      <th>weight</th>\n",
       "      <th>reach_x</th>\n",
       "      <th>stance</th>\n",
       "      <th>dOB</th>\n",
       "      <th>...</th>\n",
       "      <th>takedown_totals</th>\n",
       "      <th>sig_str_per_minute</th>\n",
       "      <th>takedown_avg_per_fifteen</th>\n",
       "      <th>sig_str_defense</th>\n",
       "      <th>knockdown_avg</th>\n",
       "      <th>sig_str_absorbed_per_min</th>\n",
       "      <th>submission_avg_per_fifteen</th>\n",
       "      <th>takedown_defense</th>\n",
       "      <th>avg_fight_time</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Danny Abbadi</td>\n",
       "      <td>The Assassin</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5' 11\"</td>\n",
       "      <td>155 lbs.</td>\n",
       "      <td>--</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Jul 03, 1983</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>78%</td>\n",
       "      <td>08:58</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hamdy Abdelwahab</td>\n",
       "      <td>The Hammer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 (1 NC)</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>264 lbs.</td>\n",
       "      <td>72\"</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>Jan 22, 1993</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.87</td>\n",
       "      <td>3.00</td>\n",
       "      <td>59%</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15:00</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mansur AbdulMalik</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>185 lbs.</td>\n",
       "      <td>79\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Oct 07, 1997</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>54%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75%</td>\n",
       "      <td>08:55</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shamil Abdurakhimov</td>\n",
       "      <td>Abrek</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>235 lbs.</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Sep 02, 1981</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.41</td>\n",
       "      <td>1.01</td>\n",
       "      <td>55%</td>\n",
       "      <td>0.29</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.14</td>\n",
       "      <td>45%</td>\n",
       "      <td>09:27</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Daichi Abe</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5' 11\"</td>\n",
       "      <td>170 lbs.</td>\n",
       "      <td>71\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Nov 27, 1991</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0.33</td>\n",
       "      <td>57%</td>\n",
       "      <td>0.33</td>\n",
       "      <td>4.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15:00</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name      nickname  wins_x  losses_x   draws_x height_x  \\\n",
       "1         Danny Abbadi  The Assassin     4.0       6.0         0   5' 11\"   \n",
       "4     Hamdy Abdelwahab    The Hammer     5.0       0.0  0 (1 NC)    6' 2\"   \n",
       "5    Mansur AbdulMalik             1     6.0       0.0         0    6' 2\"   \n",
       "6  Shamil Abdurakhimov         Abrek    20.0       8.0         0    6' 3\"   \n",
       "8           Daichi Abe             2     6.0       2.0         0   5' 11\"   \n",
       "\n",
       "     weight reach_x    stance           dOB  ...  takedown_totals  \\\n",
       "1  155 lbs.      --  Orthodox  Jul 03, 1983  ...              NaN   \n",
       "4  264 lbs.     72\"  Southpaw  Jan 22, 1993  ...              NaN   \n",
       "5  185 lbs.     79\"  Orthodox  Oct 07, 1997  ...              NaN   \n",
       "6  235 lbs.     76\"  Orthodox  Sep 02, 1981  ...              NaN   \n",
       "8  170 lbs.     71\"  Orthodox  Nov 27, 1991  ...              NaN   \n",
       "\n",
       "  sig_str_per_minute  takedown_avg_per_fifteen sig_str_defense  knockdown_avg  \\\n",
       "1               3.29                      0.00             58%           0.00   \n",
       "4               3.87                      3.00             59%           1.00   \n",
       "5               5.38                      0.00             54%           0.00   \n",
       "6               2.41                      1.01             55%           0.29   \n",
       "8               3.80                      0.33             57%           0.33   \n",
       "\n",
       "  sig_str_absorbed_per_min submission_avg_per_fifteen  takedown_defense  \\\n",
       "1                     4.41                       0.00               78%   \n",
       "4                     3.13                       0.00               NaN   \n",
       "5                     5.16                       0.00               75%   \n",
       "6                     3.02                       0.14               45%   \n",
       "8                     4.49                       0.00               NaN   \n",
       "\n",
       "   avg_fight_time  _merge  \n",
       "1           08:58    both  \n",
       "4           15:00    both  \n",
       "5           08:55    both  \n",
       "6           09:27    both  \n",
       "8           15:00    both  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#query dfMerged for intersections\n",
    "dfCombined = pd.DataFrame(dfMerged.query('_merge == \"both\"'))\n",
    "dfCombined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set blank values to nan\n",
    "dfCombined.replace('--', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nickname</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>draws</th>\n",
       "      <th>age</th>\n",
       "      <th>nation</th>\n",
       "      <th>knockdown_avg</th>\n",
       "      <th>sig_str_accuracy</th>\n",
       "      <th>takedown_average</th>\n",
       "      <th>takedown_accuracy</th>\n",
       "      <th>subs_attempted_average</th>\n",
       "      <th>height</th>\n",
       "      <th>reach</th>\n",
       "      <th>stance</th>\n",
       "      <th>sig_str_landed_per_min</th>\n",
       "      <th>average_fight_time</th>\n",
       "      <th>sig_str_absorbed_per_min</th>\n",
       "      <th>sig_str_defense</th>\n",
       "      <th>takedown_defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, nickname, wins, losses, draws, age, nation, knockdown_avg, sig_str_accuracy, takedown_average, takedown_accuracy, subs_attempted_average, height, reach, stance, sig_str_landed_per_min, average_fight_time, sig_str_absorbed_per_min, sig_str_defense, takedown_defense]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define column headers\n",
    "column_headers = [\n",
    "    'name', 'nickname', 'wins', 'losses', 'draws', 'age', 'nation', 'knockdown_avg', 'sig_str_accuracy', \n",
    "    'takedown_average', 'takedown_accuracy', 'subs_attempted_average', 'height', 'reach', \n",
    "    'stance', 'sig_str_landed_per_min', 'average_fight_time', 'sig_str_absorbed_per_min', 'sig_str_defense',\n",
    "    'takedown_defense'\n",
    "]\n",
    "\n",
    "#create dataframe using headers\n",
    "dfCareer = pd.DataFrame(columns=column_headers)\n",
    "dfCareer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nickname</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>draws</th>\n",
       "      <th>age</th>\n",
       "      <th>nation</th>\n",
       "      <th>knockdown_avg</th>\n",
       "      <th>sig_str_accuracy</th>\n",
       "      <th>takedown_average</th>\n",
       "      <th>takedown_accuracy</th>\n",
       "      <th>subs_attempted_average</th>\n",
       "      <th>height</th>\n",
       "      <th>reach</th>\n",
       "      <th>stance</th>\n",
       "      <th>sig_str_landed_per_min</th>\n",
       "      <th>average_fight_time</th>\n",
       "      <th>sig_str_absorbed_per_min</th>\n",
       "      <th>sig_str_defense</th>\n",
       "      <th>takedown_defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danny Abbadi</td>\n",
       "      <td>The Assassin</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jul 03, 1983</td>\n",
       "      <td>Orlando, United States</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5' 11\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.29</td>\n",
       "      <td>08:58</td>\n",
       "      <td>4.41</td>\n",
       "      <td>57%</td>\n",
       "      <td>77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hamdy Abdelwahab</td>\n",
       "      <td>The Hammer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 (1 NC)</td>\n",
       "      <td>Jan 22, 1993</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>1.00</td>\n",
       "      <td>52%</td>\n",
       "      <td>3.00</td>\n",
       "      <td>75%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>72\"</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>3.87</td>\n",
       "      <td>15:00</td>\n",
       "      <td>3.13</td>\n",
       "      <td>59%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mansur AbdulMalik</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Oct 07, 1997</td>\n",
       "      <td>Pittsburgh, United States</td>\n",
       "      <td>0.00</td>\n",
       "      <td>53%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>5.38</td>\n",
       "      <td>08:55</td>\n",
       "      <td>5.16</td>\n",
       "      <td>54%</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shamil Abdurakhimov</td>\n",
       "      <td>Abrek</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sep 02, 1981</td>\n",
       "      <td>Dagestan Republic, Russia</td>\n",
       "      <td>0.29</td>\n",
       "      <td>44%</td>\n",
       "      <td>1.01</td>\n",
       "      <td>23%</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>2.41</td>\n",
       "      <td>09:27</td>\n",
       "      <td>3.02</td>\n",
       "      <td>55%</td>\n",
       "      <td>45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daichi Abe</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nov 27, 1991</td>\n",
       "      <td>Japan</td>\n",
       "      <td>0.33</td>\n",
       "      <td>33%</td>\n",
       "      <td>0.33</td>\n",
       "      <td>50%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5' 11\"</td>\n",
       "      <td>71\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.80</td>\n",
       "      <td>15:00</td>\n",
       "      <td>4.49</td>\n",
       "      <td>56%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name      nickname  wins  losses     draws           age  \\\n",
       "0         Danny Abbadi  The Assassin   4.0     6.0         0  Jul 03, 1983   \n",
       "1     Hamdy Abdelwahab    The Hammer   5.0     0.0  0 (1 NC)  Jan 22, 1993   \n",
       "2    Mansur AbdulMalik             1   6.0     0.0         0  Oct 07, 1997   \n",
       "3  Shamil Abdurakhimov         Abrek  20.0     8.0         0  Sep 02, 1981   \n",
       "4           Daichi Abe             2   6.0     2.0         0  Nov 27, 1991   \n",
       "\n",
       "                      nation  knockdown_avg sig_str_accuracy  \\\n",
       "0     Orlando, United States           0.00              38%   \n",
       "1                      Egypt           1.00              52%   \n",
       "2  Pittsburgh, United States           0.00              53%   \n",
       "3  Dagestan Republic, Russia           0.29              44%   \n",
       "4                      Japan           0.33              33%   \n",
       "\n",
       "   takedown_average takedown_accuracy  subs_attempted_average  height reach  \\\n",
       "0              0.00                0%                     0.0  5' 11\"   NaN   \n",
       "1              3.00               75%                     0.0   6' 2\"   72\"   \n",
       "2              0.00                0%                     0.0   6' 2\"   79\"   \n",
       "3              1.01               23%                     0.1   6' 3\"   76\"   \n",
       "4              0.33               50%                     0.0  5' 11\"   71\"   \n",
       "\n",
       "     stance  sig_str_landed_per_min average_fight_time  \\\n",
       "0  Orthodox                    3.29              08:58   \n",
       "1  Southpaw                    3.87              15:00   \n",
       "2  Orthodox                    5.38              08:55   \n",
       "3  Orthodox                    2.41              09:27   \n",
       "4  Orthodox                    3.80              15:00   \n",
       "\n",
       "   sig_str_absorbed_per_min sig_str_defense takedown_defense  \n",
       "0                      4.41             57%              77%  \n",
       "1                      3.13             59%               0%  \n",
       "2                      5.16             54%              75%  \n",
       "3                      3.02             55%              45%  \n",
       "4                      4.49             56%               0%  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#populate df\n",
    "for index, row in dfCombined.iterrows():\n",
    "    #initalize attributes\n",
    "    name = None\n",
    "    nickname = None\n",
    "    wins = None\n",
    "    losses = None\n",
    "    draws = None\n",
    "    age = None\n",
    "    nation = None\n",
    "    knockdown_avg = None\n",
    "    sig_str_accuracy = None\n",
    "    takedown_average = None\n",
    "    takedown_accuracy = None\n",
    "    subs_attempted_average = None\n",
    "    height = None\n",
    "    reach = None\n",
    "    stance = None\n",
    "    sig_str_landed_per_min = None\n",
    "    average_fight_time = None\n",
    "    sig_str_absorbed_per_min = None\n",
    "    sig_str_defense = None\n",
    "    takedown_defense = None\n",
    "\n",
    "    name = row['name']\n",
    "    nickname = row['nickname']\n",
    "\n",
    "    if row['wins_x'] != np.nan:\n",
    "        wins = row['wins_x']\n",
    "    else:\n",
    "        wins = row['wins_y']\n",
    "    \n",
    "    if row['losses_x'] != np.nan:\n",
    "        losses = row['losses_x']\n",
    "    else:\n",
    "        losses = row['losses_y']\n",
    "    \n",
    "    if row['draws_x'] != np.nan:\n",
    "        draws = row['draws_x']\n",
    "    else:\n",
    "        draws = row['draws_y']\n",
    "\n",
    "    if row['dOB'] != np.nan:\n",
    "        age = row['dOB']\n",
    "    else:\n",
    "        age = row['age']\n",
    "    \n",
    "    nation = row['nation']\n",
    "\n",
    "    knockdown_avg = row['knockdown_avg']\n",
    "\n",
    "    if row['sig_striking_accuracy_%'] != np.nan:\n",
    "        sig_str_accuracy = row['sig_striking_accuracy_%']\n",
    "    else:\n",
    "        sig_str_accuracy = row['sig_str_accuracy']\n",
    "\n",
    "    if row['takedown_average(average_takedown_landed_per_fifteen_min)'] != np.nan:\n",
    "        takedown_average = row['takedown_average(average_takedown_landed_per_fifteen_min)']\n",
    "    else:\n",
    "        takedown_average = row['takedown_avg_per_fifteen']\n",
    "\n",
    "    if row['takedown_accuracy_%'] != np.nan:\n",
    "        takedown_accuracy = row['takedown_accuracy_%']\n",
    "    else:\n",
    "        takedown_accuracy = row['takedown_accuracy']\n",
    "    \n",
    "    if row['sub_average(average_subs_attempted_per_15_mins)'] != np.nan:\n",
    "        subs_attempted_average = row['sub_average(average_subs_attempted_per_15_mins)']\n",
    "    else:\n",
    "        subs_attempted_average = row['submission_avg_per_fifteen']\n",
    "\n",
    "    if row['height_x'] != np.nan:\n",
    "        height = row['height_x']\n",
    "    else:\n",
    "        height = row['height_y']\n",
    "    \n",
    "    if row['reach_x'] != np.nan:\n",
    "        reach = row['reach_x']\n",
    "    else:\n",
    "        reach = row['reach_y']\n",
    "\n",
    "    stance = row['stance']\n",
    "\n",
    "    if row['sig_strikes_landed_per_min'] != np.nan:\n",
    "        sig_str_landed_per_min = row['sig_strikes_landed_per_min']\n",
    "    else:\n",
    "        sig_str_landed_per_min = row['sig_str_per_minute']\n",
    "\n",
    "    average_fight_time = row['avg_fight_time']\n",
    "\n",
    "    if row['sig_strike_absorbed_per_min'] != np.nan:\n",
    "        sig_str_absorbed_per_min = row['sig_strike_absorbed_per_min']\n",
    "    else:\n",
    "        sig_str_absorbed_per_min = row['sig_str_absorbed_per_min']\n",
    "\n",
    "    if row['sig_strike_defense(%_of_sig_strikes_not_landed_by_opponent)'] != np.nan:\n",
    "        sig_str_defense = row['sig_strike_defense(%_of_sig_strikes_not_landed_by_opponent)']\n",
    "    else:\n",
    "        sig_str_defense = row['sig_str_defense']\n",
    "\n",
    "    if row['takedown_defense(%_of_opponent_takedown_not_landed)'] != np.nan:\n",
    "        takedown_defense = row['takedown_defense(%_of_opponent_takedown_not_landed)']\n",
    "    else:\n",
    "        takedown_defense = row['takedown_defense']\n",
    "\n",
    "\n",
    "    column_vals = {\n",
    "        'name': name,\n",
    "        'nickname': nickname,\n",
    "        'wins': wins,\n",
    "        'losses': losses,\n",
    "        'draws': draws,\n",
    "        'age': age,\n",
    "        'nation': nation,\n",
    "        'knockdown_avg': knockdown_avg,\n",
    "        'sig_str_accuracy': sig_str_accuracy,\n",
    "        'takedown_average': takedown_average,\n",
    "        'takedown_accuracy': takedown_accuracy,\n",
    "        'subs_attempted_average': subs_attempted_average,\n",
    "        'height': height,\n",
    "        'reach': reach,\n",
    "        'stance': stance,\n",
    "        'sig_str_landed_per_min': sig_str_landed_per_min,\n",
    "        'average_fight_time': average_fight_time,\n",
    "        'sig_str_absorbed_per_min': sig_str_absorbed_per_min,\n",
    "        'sig_str_defense': sig_str_defense,\n",
    "        'takedown_defense': takedown_defense\n",
    "    }\n",
    "    dfCareer.loc[len(dfCareer)] = column_vals\n",
    "\n",
    "dfCareer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nickname</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>draws</th>\n",
       "      <th>age</th>\n",
       "      <th>nation</th>\n",
       "      <th>knockdown_avg</th>\n",
       "      <th>sig_str_accuracy</th>\n",
       "      <th>takedown_average</th>\n",
       "      <th>takedown_accuracy</th>\n",
       "      <th>subs_attempted_average</th>\n",
       "      <th>height</th>\n",
       "      <th>reach</th>\n",
       "      <th>stance</th>\n",
       "      <th>sig_str_landed_per_min</th>\n",
       "      <th>average_fight_time</th>\n",
       "      <th>sig_str_absorbed_per_min</th>\n",
       "      <th>sig_str_defense</th>\n",
       "      <th>takedown_defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danny Abbadi</td>\n",
       "      <td>The Assassin</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jul-03-1983</td>\n",
       "      <td>Orlando, United States</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5' 11\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.29</td>\n",
       "      <td>08:58</td>\n",
       "      <td>4.41</td>\n",
       "      <td>57%</td>\n",
       "      <td>77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hamdy Abdelwahab</td>\n",
       "      <td>The Hammer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 (1 NC)</td>\n",
       "      <td>Jan-22-1993</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>1.00</td>\n",
       "      <td>52%</td>\n",
       "      <td>3.00</td>\n",
       "      <td>75%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>72\"</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>3.87</td>\n",
       "      <td>15:00</td>\n",
       "      <td>3.13</td>\n",
       "      <td>59%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mansur AbdulMalik</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Oct-07-1997</td>\n",
       "      <td>Pittsburgh, United States</td>\n",
       "      <td>0.00</td>\n",
       "      <td>53%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>5.38</td>\n",
       "      <td>08:55</td>\n",
       "      <td>5.16</td>\n",
       "      <td>54%</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shamil Abdurakhimov</td>\n",
       "      <td>Abrek</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sep-02-1981</td>\n",
       "      <td>Dagestan Republic, Russia</td>\n",
       "      <td>0.29</td>\n",
       "      <td>44%</td>\n",
       "      <td>1.01</td>\n",
       "      <td>23%</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>2.41</td>\n",
       "      <td>09:27</td>\n",
       "      <td>3.02</td>\n",
       "      <td>55%</td>\n",
       "      <td>45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daichi Abe</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nov-27-1991</td>\n",
       "      <td>Japan</td>\n",
       "      <td>0.33</td>\n",
       "      <td>33%</td>\n",
       "      <td>0.33</td>\n",
       "      <td>50%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5' 11\"</td>\n",
       "      <td>71\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.80</td>\n",
       "      <td>15:00</td>\n",
       "      <td>4.49</td>\n",
       "      <td>56%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name      nickname  wins  losses     draws          age  \\\n",
       "0         Danny Abbadi  The Assassin   4.0     6.0         0  Jul-03-1983   \n",
       "1     Hamdy Abdelwahab    The Hammer   5.0     0.0  0 (1 NC)  Jan-22-1993   \n",
       "2    Mansur AbdulMalik             1   6.0     0.0         0  Oct-07-1997   \n",
       "3  Shamil Abdurakhimov         Abrek  20.0     8.0         0  Sep-02-1981   \n",
       "4           Daichi Abe             2   6.0     2.0         0  Nov-27-1991   \n",
       "\n",
       "                      nation  knockdown_avg sig_str_accuracy  \\\n",
       "0     Orlando, United States           0.00              38%   \n",
       "1                      Egypt           1.00              52%   \n",
       "2  Pittsburgh, United States           0.00              53%   \n",
       "3  Dagestan Republic, Russia           0.29              44%   \n",
       "4                      Japan           0.33              33%   \n",
       "\n",
       "   takedown_average takedown_accuracy  subs_attempted_average  height reach  \\\n",
       "0              0.00                0%                     0.0  5' 11\"   NaN   \n",
       "1              3.00               75%                     0.0   6' 2\"   72\"   \n",
       "2              0.00                0%                     0.0   6' 2\"   79\"   \n",
       "3              1.01               23%                     0.1   6' 3\"   76\"   \n",
       "4              0.33               50%                     0.0  5' 11\"   71\"   \n",
       "\n",
       "     stance  sig_str_landed_per_min average_fight_time  \\\n",
       "0  Orthodox                    3.29              08:58   \n",
       "1  Southpaw                    3.87              15:00   \n",
       "2  Orthodox                    5.38              08:55   \n",
       "3  Orthodox                    2.41              09:27   \n",
       "4  Orthodox                    3.80              15:00   \n",
       "\n",
       "   sig_str_absorbed_per_min sig_str_defense takedown_defense  \n",
       "0                      4.41             57%              77%  \n",
       "1                      3.13             59%               0%  \n",
       "2                      5.16             54%              75%  \n",
       "3                      3.02             55%              45%  \n",
       "4                      4.49             56%               0%  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reformat age\n",
    "for index, row in dfCareer.iterrows():\n",
    "    age = row['age']\n",
    "    if(isinstance(age, str)):\n",
    "        age = age.replace(',', '')\n",
    "        listAge = age.split(' ')\n",
    "        year = listAge[2]\n",
    "        #if int(year)>30:\n",
    "            #year = f'{year}'\n",
    "        #else:\n",
    "            #year = f'{year}'\n",
    "        listAge.pop()\n",
    "        listAge.append(year)\n",
    "        age = '-'.join(listAge)\n",
    "        dfCareer.at[index, 'age'] = age\n",
    "\n",
    "\n",
    "dfCareer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfCareer.to_csv(f'careerStatsData{dateToday}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fight</th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>event</th>\n",
       "      <th>referee</th>\n",
       "      <th>method_of_victory</th>\n",
       "      <th>date</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>...</th>\n",
       "      <th>redCorner_subs_attempted</th>\n",
       "      <th>blueCorner_subs_attempted</th>\n",
       "      <th>round</th>\n",
       "      <th>time</th>\n",
       "      <th>redCorner_height</th>\n",
       "      <th>blueCorner_height</th>\n",
       "      <th>redCorner_reach</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex Pereira vs Khalil Rountree Jr</td>\n",
       "      <td>Alex Pereira</td>\n",
       "      <td>Khalil Rountree Jr</td>\n",
       "      <td>Alex Pereira</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Marc Goddard</td>\n",
       "      <td>KO/TKO</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4:32</td>\n",
       "      <td>6' 4\"</td>\n",
       "      <td>6' 1\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raquel Pennington vs Julianna Pena</td>\n",
       "      <td>Raquel Pennington</td>\n",
       "      <td>Julianna Pena</td>\n",
       "      <td>Julianna Pena</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Jason Herzog</td>\n",
       "      <td>Decision - Split</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>67\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jose Aldo vs Mario Bautista</td>\n",
       "      <td>Jose Aldo</td>\n",
       "      <td>Mario Bautista</td>\n",
       "      <td>Mario Bautista</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Mike Beltran</td>\n",
       "      <td>Decision - Split</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>70\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roman Dolidze vs Kevin Holland</td>\n",
       "      <td>Roman Dolidze</td>\n",
       "      <td>Kevin Holland</td>\n",
       "      <td>Roman Dolidze</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Jason Herzog</td>\n",
       "      <td>KO/TKO</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5:00</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kayla Harrison vs Ketlen Vieira</td>\n",
       "      <td>Ketlen Vieira</td>\n",
       "      <td>Kayla Harrison</td>\n",
       "      <td>Kayla Harrison</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Marc Goddard</td>\n",
       "      <td>Decision - Unanimous</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>68\"</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                fight          redCorner          blueCorner  \\\n",
       "0  Alex Pereira vs Khalil Rountree Jr       Alex Pereira  Khalil Rountree Jr   \n",
       "1  Raquel Pennington vs Julianna Pena  Raquel Pennington       Julianna Pena   \n",
       "2         Jose Aldo vs Mario Bautista          Jose Aldo      Mario Bautista   \n",
       "3      Roman Dolidze vs Kevin Holland      Roman Dolidze       Kevin Holland   \n",
       "4     Kayla Harrison vs Ketlen Vieira      Ketlen Vieira      Kayla Harrison   \n",
       "\n",
       "           winner                              event       referee  \\\n",
       "0    Alex Pereira  UFC 307: Pereira vs. Rountree Jr.  Marc Goddard   \n",
       "1   Julianna Pena  UFC 307: Pereira vs. Rountree Jr.  Jason Herzog   \n",
       "2  Mario Bautista  UFC 307: Pereira vs. Rountree Jr.  Mike Beltran   \n",
       "3   Roman Dolidze  UFC 307: Pereira vs. Rountree Jr.  Jason Herzog   \n",
       "4  Kayla Harrison  UFC 307: Pereira vs. Rountree Jr.  Marc Goddard   \n",
       "\n",
       "      method_of_victory        date         venue title_fight  ...  \\\n",
       "0                KO/TKO  10.05.2024  Delta Center         yes  ...   \n",
       "1      Decision - Split  10.05.2024  Delta Center         yes  ...   \n",
       "2      Decision - Split  10.05.2024  Delta Center          no  ...   \n",
       "3                KO/TKO  10.05.2024  Delta Center          no  ...   \n",
       "4  Decision - Unanimous  10.05.2024  Delta Center          no  ...   \n",
       "\n",
       "  redCorner_subs_attempted blueCorner_subs_attempted round  time  \\\n",
       "0                        0                         0     4  4:32   \n",
       "1                        0                         1     5  5:00   \n",
       "2                        0                         0     3  5:00   \n",
       "3                        0                         0     1  5:00   \n",
       "4                        0                         0     3  5:00   \n",
       "\n",
       "   redCorner_height  blueCorner_height  redCorner_reach  blueCorner_reach  \\\n",
       "0             6' 4\"              6' 1\"              79\"               76\"   \n",
       "1             5' 7\"              5' 6\"              67\"               69\"   \n",
       "2             5' 7\"              5' 9\"              70\"               69\"   \n",
       "3             6' 2\"              6' 3\"              76\"               81\"   \n",
       "4             5' 8\"              5' 8\"              68\"               66\"   \n",
       "\n",
       "   redCorner_stance blueCorner_stance  \n",
       "0          Orthodox          Southpaw  \n",
       "1          Orthodox          Orthodox  \n",
       "2          Orthodox            Switch  \n",
       "3          Orthodox          Orthodox  \n",
       "4          Orthodox          Southpaw  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#read new df\n",
    "df = pd.read_csv(f'databaseUpdated{dateToday}.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this df nans ar represented as '---' - replacing this with nan\n",
    "df.replace('---', np.nan, inplace=True)\n",
    "df.replace('--', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1306\n"
     ]
    }
   ],
   "source": [
    "#Dropping all rows where red and blue corners are not recorded correctly\n",
    "#Not recorded correctly until 03.21.2010\n",
    "#Since this will affect the accuracy of the model I am removing it for now\n",
    "#Will try and find a credible source to fix this at a later date\n",
    "\n",
    "rows, columns = df.shape\n",
    "\n",
    "event_condition = df['event'] == 'UFC 110: Nogueira vs Velasquez'\n",
    "fight_condition = df['fight'] == 'Cain Velasquez vs Antonio Rodrigo Nogueira'\n",
    "\n",
    "recordedIncorrectly = df.loc[event_condition & fight_condition].index[0]\n",
    "recordedIncorrectly -= rows\n",
    "print(recordedIncorrectly)\n",
    "df = df.iloc[:recordedIncorrectly]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6534\n",
      "fight                             Jason Brilz vs Eric Schafer\n",
      "redCorner                                        Eric Schafer\n",
      "blueCorner                                        Jason Brilz\n",
      "winner                                            Jason Brilz\n",
      "event                                 UFC Live: Vera vs Jones\n",
      "referee                                           Tom Johnson\n",
      "method_of_victory                        Decision - Unanimous\n",
      "date                                               03.21.2010\n",
      "venue                                      The Odeum Colorado\n",
      "title_fight                                                no\n",
      "billing                                      Preliminary Card\n",
      "redCorner_wins                                             11\n",
      "blueCorner_wins                                            17\n",
      "redCorner_losses                                          4.0\n",
      "blueCorner_losses                                         2.0\n",
      "redCorner_draws                                           2.0\n",
      "blueCorner_draws                                          1.0\n",
      "redCorner_age                                            32.0\n",
      "blueCorner_age                                           34.0\n",
      "redCorner_nation                                          NaN\n",
      "blueCorner_nation                               United States\n",
      "redCorner_fan                                             NaN\n",
      "blueCorner_fan                                            NaN\n",
      "redCorner_knockdowns                                        0\n",
      "blueCorner_knockdowns                                       0\n",
      "redCorner_sig_str                                    27 of 81\n",
      "blueCorner_sig_str                                  70 of 145\n",
      "redCorner_sig_str_percentage                              33%\n",
      "blueCorner_sig_str_percentage                             48%\n",
      "redCorner_total_str                                 52 of 107\n",
      "blueCorner_total_str                               130 of 206\n",
      "redCorner_takedowns                                    2 of 3\n",
      "blueCorner_takedowns                                   3 of 6\n",
      "redCorner_takedown_percentage                             66%\n",
      "blueCorner_takedown_percentage                            50%\n",
      "redCorner_subs_attempted                                    1\n",
      "blueCorner_subs_attempted                                   1\n",
      "round                                                       3\n",
      "time                                                     5:00\n",
      "redCorner_height                                        6' 3\"\n",
      "blueCorner_height                                      5' 11\"\n",
      "redCorner_reach                                           76\"\n",
      "blueCorner_reach                                          71\"\n",
      "redCorner_stance                                     Orthodox\n",
      "blueCorner_stance                                    Orthodox\n",
      "Name: 6533, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#output should be Jason Brilz vs Eric Schafer\n",
    "lengthDF = len(df)\n",
    "print(lengthDF)\n",
    "\n",
    "print(df.iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fight</th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>event</th>\n",
       "      <th>referee</th>\n",
       "      <th>method_of_victory</th>\n",
       "      <th>date</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>...</th>\n",
       "      <th>redCorner_subs_attempted</th>\n",
       "      <th>blueCorner_subs_attempted</th>\n",
       "      <th>round</th>\n",
       "      <th>time</th>\n",
       "      <th>redCorner_height</th>\n",
       "      <th>blueCorner_height</th>\n",
       "      <th>redCorner_reach</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex Pereira vs Khalil Rountree Jr</td>\n",
       "      <td>Alex Pereira</td>\n",
       "      <td>Khalil Rountree Jr</td>\n",
       "      <td>0</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Marc Goddard</td>\n",
       "      <td>KO/TKO</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4:32</td>\n",
       "      <td>6' 4\"</td>\n",
       "      <td>6' 1\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raquel Pennington vs Julianna Pena</td>\n",
       "      <td>Raquel Pennington</td>\n",
       "      <td>Julianna Pena</td>\n",
       "      <td>Julianna Pena</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Jason Herzog</td>\n",
       "      <td>Decision - Split</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>67\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jose Aldo vs Mario Bautista</td>\n",
       "      <td>Jose Aldo</td>\n",
       "      <td>Mario Bautista</td>\n",
       "      <td>Mario Bautista</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Mike Beltran</td>\n",
       "      <td>Decision - Split</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>70\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roman Dolidze vs Kevin Holland</td>\n",
       "      <td>Roman Dolidze</td>\n",
       "      <td>Kevin Holland</td>\n",
       "      <td>0</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Jason Herzog</td>\n",
       "      <td>KO/TKO</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5:00</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kayla Harrison vs Ketlen Vieira</td>\n",
       "      <td>Ketlen Vieira</td>\n",
       "      <td>Kayla Harrison</td>\n",
       "      <td>Kayla Harrison</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Marc Goddard</td>\n",
       "      <td>Decision - Unanimous</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>68\"</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                fight          redCorner          blueCorner  \\\n",
       "0  Alex Pereira vs Khalil Rountree Jr       Alex Pereira  Khalil Rountree Jr   \n",
       "1  Raquel Pennington vs Julianna Pena  Raquel Pennington       Julianna Pena   \n",
       "2         Jose Aldo vs Mario Bautista          Jose Aldo      Mario Bautista   \n",
       "3      Roman Dolidze vs Kevin Holland      Roman Dolidze       Kevin Holland   \n",
       "4     Kayla Harrison vs Ketlen Vieira      Ketlen Vieira      Kayla Harrison   \n",
       "\n",
       "           winner                              event       referee  \\\n",
       "0               0  UFC 307: Pereira vs. Rountree Jr.  Marc Goddard   \n",
       "1   Julianna Pena  UFC 307: Pereira vs. Rountree Jr.  Jason Herzog   \n",
       "2  Mario Bautista  UFC 307: Pereira vs. Rountree Jr.  Mike Beltran   \n",
       "3               0  UFC 307: Pereira vs. Rountree Jr.  Jason Herzog   \n",
       "4  Kayla Harrison  UFC 307: Pereira vs. Rountree Jr.  Marc Goddard   \n",
       "\n",
       "      method_of_victory        date         venue title_fight  ...  \\\n",
       "0                KO/TKO  10.05.2024  Delta Center         yes  ...   \n",
       "1      Decision - Split  10.05.2024  Delta Center         yes  ...   \n",
       "2      Decision - Split  10.05.2024  Delta Center          no  ...   \n",
       "3                KO/TKO  10.05.2024  Delta Center          no  ...   \n",
       "4  Decision - Unanimous  10.05.2024  Delta Center          no  ...   \n",
       "\n",
       "  redCorner_subs_attempted blueCorner_subs_attempted round  time  \\\n",
       "0                        0                         0     4  4:32   \n",
       "1                        0                         1     5  5:00   \n",
       "2                        0                         0     3  5:00   \n",
       "3                        0                         0     1  5:00   \n",
       "4                        0                         0     3  5:00   \n",
       "\n",
       "   redCorner_height  blueCorner_height  redCorner_reach  blueCorner_reach  \\\n",
       "0             6' 4\"              6' 1\"              79\"               76\"   \n",
       "1             5' 7\"              5' 6\"              67\"               69\"   \n",
       "2             5' 7\"              5' 9\"              70\"               69\"   \n",
       "3             6' 2\"              6' 3\"              76\"               81\"   \n",
       "4             5' 8\"              5' 8\"              68\"               66\"   \n",
       "\n",
       "   redCorner_stance blueCorner_stance  \n",
       "0          Orthodox          Southpaw  \n",
       "1          Orthodox          Orthodox  \n",
       "2          Orthodox            Switch  \n",
       "3          Orthodox          Orthodox  \n",
       "4          Orthodox          Southpaw  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if redCorner won winner set to 0\n",
    "for index, row in df.iterrows():\n",
    "    if(row['redCorner'] == row['winner']):\n",
    "        df.at[index, 'winner'] = 0\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fight</th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>event</th>\n",
       "      <th>referee</th>\n",
       "      <th>method_of_victory</th>\n",
       "      <th>date</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>...</th>\n",
       "      <th>redCorner_subs_attempted</th>\n",
       "      <th>blueCorner_subs_attempted</th>\n",
       "      <th>round</th>\n",
       "      <th>time</th>\n",
       "      <th>redCorner_height</th>\n",
       "      <th>blueCorner_height</th>\n",
       "      <th>redCorner_reach</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex Pereira vs Khalil Rountree Jr</td>\n",
       "      <td>Alex Pereira</td>\n",
       "      <td>Khalil Rountree Jr</td>\n",
       "      <td>0</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Marc Goddard</td>\n",
       "      <td>KO/TKO</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4:32</td>\n",
       "      <td>6' 4\"</td>\n",
       "      <td>6' 1\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raquel Pennington vs Julianna Pena</td>\n",
       "      <td>Raquel Pennington</td>\n",
       "      <td>Julianna Pena</td>\n",
       "      <td>2</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Jason Herzog</td>\n",
       "      <td>Decision - Split</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>67\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jose Aldo vs Mario Bautista</td>\n",
       "      <td>Jose Aldo</td>\n",
       "      <td>Mario Bautista</td>\n",
       "      <td>2</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Mike Beltran</td>\n",
       "      <td>Decision - Split</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>70\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roman Dolidze vs Kevin Holland</td>\n",
       "      <td>Roman Dolidze</td>\n",
       "      <td>Kevin Holland</td>\n",
       "      <td>0</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Jason Herzog</td>\n",
       "      <td>KO/TKO</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5:00</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kayla Harrison vs Ketlen Vieira</td>\n",
       "      <td>Ketlen Vieira</td>\n",
       "      <td>Kayla Harrison</td>\n",
       "      <td>2</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Marc Goddard</td>\n",
       "      <td>Decision - Unanimous</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>68\"</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                fight          redCorner          blueCorner  \\\n",
       "0  Alex Pereira vs Khalil Rountree Jr       Alex Pereira  Khalil Rountree Jr   \n",
       "1  Raquel Pennington vs Julianna Pena  Raquel Pennington       Julianna Pena   \n",
       "2         Jose Aldo vs Mario Bautista          Jose Aldo      Mario Bautista   \n",
       "3      Roman Dolidze vs Kevin Holland      Roman Dolidze       Kevin Holland   \n",
       "4     Kayla Harrison vs Ketlen Vieira      Ketlen Vieira      Kayla Harrison   \n",
       "\n",
       "  winner                              event       referee  \\\n",
       "0      0  UFC 307: Pereira vs. Rountree Jr.  Marc Goddard   \n",
       "1      2  UFC 307: Pereira vs. Rountree Jr.  Jason Herzog   \n",
       "2      2  UFC 307: Pereira vs. Rountree Jr.  Mike Beltran   \n",
       "3      0  UFC 307: Pereira vs. Rountree Jr.  Jason Herzog   \n",
       "4      2  UFC 307: Pereira vs. Rountree Jr.  Marc Goddard   \n",
       "\n",
       "      method_of_victory        date         venue title_fight  ...  \\\n",
       "0                KO/TKO  10.05.2024  Delta Center         yes  ...   \n",
       "1      Decision - Split  10.05.2024  Delta Center         yes  ...   \n",
       "2      Decision - Split  10.05.2024  Delta Center          no  ...   \n",
       "3                KO/TKO  10.05.2024  Delta Center          no  ...   \n",
       "4  Decision - Unanimous  10.05.2024  Delta Center          no  ...   \n",
       "\n",
       "  redCorner_subs_attempted blueCorner_subs_attempted round  time  \\\n",
       "0                        0                         0     4  4:32   \n",
       "1                        0                         1     5  5:00   \n",
       "2                        0                         0     3  5:00   \n",
       "3                        0                         0     1  5:00   \n",
       "4                        0                         0     3  5:00   \n",
       "\n",
       "   redCorner_height  blueCorner_height  redCorner_reach  blueCorner_reach  \\\n",
       "0             6' 4\"              6' 1\"              79\"               76\"   \n",
       "1             5' 7\"              5' 6\"              67\"               69\"   \n",
       "2             5' 7\"              5' 9\"              70\"               69\"   \n",
       "3             6' 2\"              6' 3\"              76\"               81\"   \n",
       "4             5' 8\"              5' 8\"              68\"               66\"   \n",
       "\n",
       "   redCorner_stance blueCorner_stance  \n",
       "0          Orthodox          Southpaw  \n",
       "1          Orthodox          Orthodox  \n",
       "2          Orthodox            Switch  \n",
       "3          Orthodox          Orthodox  \n",
       "4          Orthodox          Southpaw  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set all winners from fights won by blue corner to 2\n",
    "for index, row in df.iterrows():\n",
    "    if(row['blueCorner'] == row['winner']):\n",
    "        df.at[index, 'winner'] = 2\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, nan, 2]\n"
     ]
    }
   ],
   "source": [
    "#check all winners have been replaced\n",
    "winner_values = df['winner'].tolist()\n",
    "winner_values = list(set(winner_values))\n",
    "print(winner_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all fights with no winner set to 1\n",
    "df['winner'].fillna(1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "#check all winners are now numerical\n",
    "winner_values = df['winner'].tolist()\n",
    "winner_values = list(set(winner_values))\n",
    "print(winner_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fight</th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>event</th>\n",
       "      <th>referee</th>\n",
       "      <th>method_of_victory</th>\n",
       "      <th>date</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>...</th>\n",
       "      <th>redCorner_subs_attempted</th>\n",
       "      <th>blueCorner_subs_attempted</th>\n",
       "      <th>round</th>\n",
       "      <th>time</th>\n",
       "      <th>redCorner_height</th>\n",
       "      <th>blueCorner_height</th>\n",
       "      <th>redCorner_reach</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex Pereira vs Khalil Rountree Jr</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Marc Goddard</td>\n",
       "      <td>KO/TKO</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4:32</td>\n",
       "      <td>6' 4\"</td>\n",
       "      <td>6' 1\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raquel Pennington vs Julianna Pena</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Jason Herzog</td>\n",
       "      <td>Decision - Split</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>67\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jose Aldo vs Mario Bautista</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Mike Beltran</td>\n",
       "      <td>Decision - Split</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>70\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roman Dolidze vs Kevin Holland</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Jason Herzog</td>\n",
       "      <td>KO/TKO</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5:00</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kayla Harrison vs Ketlen Vieira</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Marc Goddard</td>\n",
       "      <td>Decision - Unanimous</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>68\"</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                fight  redCorner  blueCorner  winner  \\\n",
       "0  Alex Pereira vs Khalil Rountree Jr          0           2       0   \n",
       "1  Raquel Pennington vs Julianna Pena          0           2       2   \n",
       "2         Jose Aldo vs Mario Bautista          0           2       2   \n",
       "3      Roman Dolidze vs Kevin Holland          0           2       0   \n",
       "4     Kayla Harrison vs Ketlen Vieira          0           2       2   \n",
       "\n",
       "                               event       referee     method_of_victory  \\\n",
       "0  UFC 307: Pereira vs. Rountree Jr.  Marc Goddard                KO/TKO   \n",
       "1  UFC 307: Pereira vs. Rountree Jr.  Jason Herzog      Decision - Split   \n",
       "2  UFC 307: Pereira vs. Rountree Jr.  Mike Beltran      Decision - Split   \n",
       "3  UFC 307: Pereira vs. Rountree Jr.  Jason Herzog                KO/TKO   \n",
       "4  UFC 307: Pereira vs. Rountree Jr.  Marc Goddard  Decision - Unanimous   \n",
       "\n",
       "         date         venue title_fight  ... redCorner_subs_attempted  \\\n",
       "0  10.05.2024  Delta Center         yes  ...                        0   \n",
       "1  10.05.2024  Delta Center         yes  ...                        0   \n",
       "2  10.05.2024  Delta Center          no  ...                        0   \n",
       "3  10.05.2024  Delta Center          no  ...                        0   \n",
       "4  10.05.2024  Delta Center          no  ...                        0   \n",
       "\n",
       "  blueCorner_subs_attempted round  time  redCorner_height  blueCorner_height  \\\n",
       "0                         0     4  4:32             6' 4\"              6' 1\"   \n",
       "1                         1     5  5:00             5' 7\"              5' 6\"   \n",
       "2                         0     3  5:00             5' 7\"              5' 9\"   \n",
       "3                         0     1  5:00             6' 2\"              6' 3\"   \n",
       "4                         0     3  5:00             5' 8\"              5' 8\"   \n",
       "\n",
       "   redCorner_reach  blueCorner_reach  redCorner_stance blueCorner_stance  \n",
       "0              79\"               76\"          Orthodox          Southpaw  \n",
       "1              67\"               69\"          Orthodox          Orthodox  \n",
       "2              70\"               69\"          Orthodox            Switch  \n",
       "3              76\"               81\"          Orthodox          Orthodox  \n",
       "4              68\"               66\"          Orthodox          Southpaw  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set redCorner values to 0 and blueCorner vals to 2\n",
    "df['redCorner'] = 0\n",
    "df['blueCorner'] = 2\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#check all redCorners were changed correctly\n",
    "redCorner_values = df['redCorner'].tolist()\n",
    "redCorner_values = list(set(redCorner_values))\n",
    "print(redCorner_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "#check all blueCorners were changed correctly\n",
    "blueCorner_values = df['blueCorner'].tolist()\n",
    "blueCorner_values = list(set(blueCorner_values))\n",
    "print(blueCorner_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>referee</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>billing</th>\n",
       "      <th>redCorner_wins</th>\n",
       "      <th>blueCorner_wins</th>\n",
       "      <th>redCorner_losses</th>\n",
       "      <th>...</th>\n",
       "      <th>redCorner_subs_attempted</th>\n",
       "      <th>blueCorner_subs_attempted</th>\n",
       "      <th>round</th>\n",
       "      <th>time</th>\n",
       "      <th>redCorner_height</th>\n",
       "      <th>blueCorner_height</th>\n",
       "      <th>redCorner_reach</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Marc Goddard</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>yes</td>\n",
       "      <td>Main Event</td>\n",
       "      <td>Pereira</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4:32</td>\n",
       "      <td>6' 4\"</td>\n",
       "      <td>6' 1\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Jason Herzog</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>yes</td>\n",
       "      <td>Co-Main Event</td>\n",
       "      <td>Pea</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>67\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Mike Beltran</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>Main Card</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>70\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Jason Herzog</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>Main Card</td>\n",
       "      <td>Dolidze</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5:00</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Marc Goddard</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>Main Card</td>\n",
       "      <td>17</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>68\"</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   redCorner  blueCorner  winner       referee         venue title_fight  \\\n",
       "0          0           2       0  Marc Goddard  Delta Center         yes   \n",
       "1          0           2       2  Jason Herzog  Delta Center         yes   \n",
       "2          0           2       2  Mike Beltran  Delta Center          no   \n",
       "3          0           2       0  Jason Herzog  Delta Center          no   \n",
       "4          0           2       2  Marc Goddard  Delta Center          no   \n",
       "\n",
       "         billing redCorner_wins blueCorner_wins  redCorner_losses  ...  \\\n",
       "0     Main Event        Pereira              11               NaN  ...   \n",
       "1  Co-Main Event           Pea              10               NaN  ...   \n",
       "2      Main Card       Bautista              14               NaN  ...   \n",
       "3      Main Card        Dolidze              13               NaN  ...   \n",
       "4      Main Card             17        Harrison               1.0  ...   \n",
       "\n",
       "   redCorner_subs_attempted  blueCorner_subs_attempted  round  time  \\\n",
       "0                         0                          0      4  4:32   \n",
       "1                         0                          1      5  5:00   \n",
       "2                         0                          0      3  5:00   \n",
       "3                         0                          0      1  5:00   \n",
       "4                         0                          0      3  5:00   \n",
       "\n",
       "   redCorner_height blueCorner_height redCorner_reach blueCorner_reach  \\\n",
       "0             6' 4\"             6' 1\"             79\"              76\"   \n",
       "1             5' 7\"             5' 6\"             67\"              69\"   \n",
       "2             5' 7\"             5' 9\"             70\"              69\"   \n",
       "3             6' 2\"             6' 3\"             76\"              81\"   \n",
       "4             5' 8\"             5' 8\"             68\"              66\"   \n",
       "\n",
       "  redCorner_stance  blueCorner_stance  \n",
       "0         Orthodox           Southpaw  \n",
       "1         Orthodox           Orthodox  \n",
       "2         Orthodox             Switch  \n",
       "3         Orthodox           Orthodox  \n",
       "4         Orthodox           Southpaw  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop column fight, event, method_of_vic, date\n",
    "df.drop('fight', axis=1, inplace=True)\n",
    "df.drop('event', axis=1, inplace=True)\n",
    "df.drop('method_of_victory', axis=1, inplace=True)\n",
    "df.drop('date', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",\n",
      ".\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "#find special characters in referees\n",
    "referees = (df['referee'].values)\n",
    "chars2rep = []\n",
    "for referee in referees:\n",
    "    if(isinstance(referee, str)):\n",
    "        for char in referee:\n",
    "            if char.lower() not in ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "            if char.upper() not in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', \"Q\", 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "chars2rep = list(set(chars2rep))\n",
    "for char in chars2rep:\n",
    "    print(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>referee</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>billing</th>\n",
       "      <th>redCorner_wins</th>\n",
       "      <th>blueCorner_wins</th>\n",
       "      <th>redCorner_losses</th>\n",
       "      <th>...</th>\n",
       "      <th>redCorner_subs_attempted</th>\n",
       "      <th>blueCorner_subs_attempted</th>\n",
       "      <th>round</th>\n",
       "      <th>time</th>\n",
       "      <th>redCorner_height</th>\n",
       "      <th>blueCorner_height</th>\n",
       "      <th>redCorner_reach</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>marcgoddard</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>yes</td>\n",
       "      <td>Main Event</td>\n",
       "      <td>Pereira</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4:32</td>\n",
       "      <td>6' 4\"</td>\n",
       "      <td>6' 1\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>jasonherzog</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>yes</td>\n",
       "      <td>Co-Main Event</td>\n",
       "      <td>Pea</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>67\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>mikebeltran</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>Main Card</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>70\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>jasonherzog</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>Main Card</td>\n",
       "      <td>Dolidze</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5:00</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>marcgoddard</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>Main Card</td>\n",
       "      <td>17</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>68\"</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   redCorner  blueCorner  winner      referee         venue title_fight  \\\n",
       "0          0           2       0  marcgoddard  Delta Center         yes   \n",
       "1          0           2       2  jasonherzog  Delta Center         yes   \n",
       "2          0           2       2  mikebeltran  Delta Center          no   \n",
       "3          0           2       0  jasonherzog  Delta Center          no   \n",
       "4          0           2       2  marcgoddard  Delta Center          no   \n",
       "\n",
       "         billing redCorner_wins blueCorner_wins  redCorner_losses  ...  \\\n",
       "0     Main Event        Pereira              11               NaN  ...   \n",
       "1  Co-Main Event           Pea              10               NaN  ...   \n",
       "2      Main Card       Bautista              14               NaN  ...   \n",
       "3      Main Card        Dolidze              13               NaN  ...   \n",
       "4      Main Card             17        Harrison               1.0  ...   \n",
       "\n",
       "   redCorner_subs_attempted  blueCorner_subs_attempted  round  time  \\\n",
       "0                         0                          0      4  4:32   \n",
       "1                         0                          1      5  5:00   \n",
       "2                         0                          0      3  5:00   \n",
       "3                         0                          0      1  5:00   \n",
       "4                         0                          0      3  5:00   \n",
       "\n",
       "   redCorner_height blueCorner_height redCorner_reach blueCorner_reach  \\\n",
       "0             6' 4\"             6' 1\"             79\"              76\"   \n",
       "1             5' 7\"             5' 6\"             67\"              69\"   \n",
       "2             5' 7\"             5' 9\"             70\"              69\"   \n",
       "3             6' 2\"             6' 3\"             76\"              81\"   \n",
       "4             5' 8\"             5' 8\"             68\"              66\"   \n",
       "\n",
       "  redCorner_stance  blueCorner_stance  \n",
       "0         Orthodox           Southpaw  \n",
       "1         Orthodox           Orthodox  \n",
       "2         Orthodox             Switch  \n",
       "3         Orthodox           Orthodox  \n",
       "4         Orthodox           Southpaw  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean referees\n",
    "for index, row in df.iterrows():\n",
    "    referee = row['referee']\n",
    "    if isinstance(referee, str):\n",
    "        cleaned_referee = referee.replace(',', '').replace('-', '').replace('.', '').replace(' ', '').lower()\n",
    "        df.loc[index, 'referee'] = cleaned_referee\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give referees numerical value\n",
    "referees = df['referee'].tolist()\n",
    "\n",
    "referees = list(set(referees))\n",
    "\n",
    "count = 0 \n",
    "for ref in referees:\n",
    "    df['referee'] = df['referee'].replace(ref, count, regex=True)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205]\n"
     ]
    }
   ],
   "source": [
    "#check all referees were assigned a numerical value\n",
    "referee_values = df['referee'].tolist()\n",
    "referee_values = list(set(referee_values))\n",
    "print(referee_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "&\n",
      "/\n",
      "\n",
      ",\n",
      "3\n",
      "!\n",
      "-\n",
      "\n",
      "1\n",
      ".\n",
      "\n",
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#find special characters in venue\n",
    "venues = (df['venue'].values)\n",
    "chars2rep = []\n",
    "for venue in venues:\n",
    "    if(isinstance(venue, str)):\n",
    "        for char in venue:\n",
    "            if char.lower() not in ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ']:\n",
    "                chars2rep.append(str(char))\n",
    "            if char.upper() not in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', \"Q\", 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ' ']:\n",
    "                chars2rep.append(str(char))\n",
    "chars2rep = list(set(chars2rep))\n",
    "for char in chars2rep:\n",
    "    print(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>referee</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>billing</th>\n",
       "      <th>redCorner_wins</th>\n",
       "      <th>blueCorner_wins</th>\n",
       "      <th>redCorner_losses</th>\n",
       "      <th>...</th>\n",
       "      <th>redCorner_subs_attempted</th>\n",
       "      <th>blueCorner_subs_attempted</th>\n",
       "      <th>round</th>\n",
       "      <th>time</th>\n",
       "      <th>redCorner_height</th>\n",
       "      <th>blueCorner_height</th>\n",
       "      <th>redCorner_reach</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>deltacenter</td>\n",
       "      <td>yes</td>\n",
       "      <td>Main Event</td>\n",
       "      <td>Pereira</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4:32</td>\n",
       "      <td>6' 4\"</td>\n",
       "      <td>6' 1\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>deltacenter</td>\n",
       "      <td>yes</td>\n",
       "      <td>Co-Main Event</td>\n",
       "      <td>Pea</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>67\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>deltacenter</td>\n",
       "      <td>no</td>\n",
       "      <td>Main Card</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>70\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>deltacenter</td>\n",
       "      <td>no</td>\n",
       "      <td>Main Card</td>\n",
       "      <td>Dolidze</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5:00</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>deltacenter</td>\n",
       "      <td>no</td>\n",
       "      <td>Main Card</td>\n",
       "      <td>17</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>68\"</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   redCorner  blueCorner  winner  referee        venue title_fight  \\\n",
       "0          0           2       0      112  deltacenter         yes   \n",
       "1          0           2       2      100  deltacenter         yes   \n",
       "2          0           2       2       11  deltacenter          no   \n",
       "3          0           2       0      100  deltacenter          no   \n",
       "4          0           2       2      112  deltacenter          no   \n",
       "\n",
       "         billing redCorner_wins blueCorner_wins  redCorner_losses  ...  \\\n",
       "0     Main Event        Pereira              11               NaN  ...   \n",
       "1  Co-Main Event           Pea              10               NaN  ...   \n",
       "2      Main Card       Bautista              14               NaN  ...   \n",
       "3      Main Card        Dolidze              13               NaN  ...   \n",
       "4      Main Card             17        Harrison               1.0  ...   \n",
       "\n",
       "   redCorner_subs_attempted  blueCorner_subs_attempted  round  time  \\\n",
       "0                         0                          0      4  4:32   \n",
       "1                         0                          1      5  5:00   \n",
       "2                         0                          0      3  5:00   \n",
       "3                         0                          0      1  5:00   \n",
       "4                         0                          0      3  5:00   \n",
       "\n",
       "   redCorner_height blueCorner_height redCorner_reach blueCorner_reach  \\\n",
       "0             6' 4\"             6' 1\"             79\"              76\"   \n",
       "1             5' 7\"             5' 6\"             67\"              69\"   \n",
       "2             5' 7\"             5' 9\"             70\"              69\"   \n",
       "3             6' 2\"             6' 3\"             76\"              81\"   \n",
       "4             5' 8\"             5' 8\"             68\"              66\"   \n",
       "\n",
       "  redCorner_stance  blueCorner_stance  \n",
       "0         Orthodox           Southpaw  \n",
       "1         Orthodox           Orthodox  \n",
       "2         Orthodox             Switch  \n",
       "3         Orthodox           Orthodox  \n",
       "4         Orthodox           Southpaw  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean venues\n",
    "cleaned_venues = []\n",
    "for index, row in df.iterrows():\n",
    "    venue = row['venue']\n",
    "    cleaned_venue = venue\n",
    "    for char in chars2rep:\n",
    "        cleaned_venue = cleaned_venue.replace(char, '')\n",
    "    cleaned_venue = cleaned_venue.replace(' ', '')\n",
    "    cleaned_venues.append(cleaned_venue.lower())\n",
    "\n",
    "df['venue'] = cleaned_venues\n",
    "        \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mgmgrandgardenarena', 'consolenergycenter', 'fortcampbell', 'jeunessearena', 'patriotcenter', 'savemartcenter', 'goianiaarena', 'usbankarena', 'spectrumcenter', 'cooplive', 'mexicocityarena', 'forthood', 'seminolehardrockhotelcasino', 'foxwoodsresortcasino', 'manchesterarena', 'ufcapex', 'thechelseaatthecosmopolitan', 'boardwalkhall', 'valleyviewcasinocenter', 'bellcentre', 'bradleycenter', 'keyarena', 'nassaucoliseum', 'pncarena', 'estadiojornalistafelippedrummond', 'hondacenter', 'smoothiekingcenter', 'bankatlanticcenter', 'ballarena', 'zagrebarena', 'lunapark', 'monterreyarena', 'toyotacenter', 'sapcenter', 'movistararena', 'philipsarena', 'adirondackbankcenter', 'barclayscenter', 'qudosbankarena', 'rodlaverarena', 'santaanastarcenter', 'canadiantirecentre', 'ssehydroarena', 'krakwarena', 'marinabaysands', 'centurylinkcenter', 'sajikarena', 'thepalaceofauburnhills', 'thetheateratvirginhotels', 'nationwidearena', 'deltacenter', 'tmobilecenter', 'ibirapueragymnasium', 'mangueirinhogymnasium', 'keybankcenter', 'sleeptrainarena', 'scottradecenter', 'cskaarena', 'bankerslifefieldhouse', 'scotiabanksaddledome', 'gilariverarena', 'racarena', 'kaseyacenter', 'wisconsinentertainmentandsportscenter', 'oworldarena', 'theodublin', 'enterprisecenter', 'arenaciudaddemexico', 'goldencenter', 'echoarena', 'gigantinhogymnasium', 'moodycenter', 'goldcoastconventioncentre', 'theprudentialcenter', 'phonesuarena', 'phillipsarena', 'mtscentre', 'arenacdmx', 'monctoneventscentre', 'colisepepsi', 'konigpilsenerarena', 'arenadabaixada', 'talkingstickarena', 'frankerwincenter', 'wembleyarena', 'universiadesportscentre', 'etihadarena', 'izodcenter', 'timesunioncenter', 'dennysanfordpremiercenter', 'duarenayasisland', 'thessearena', 'littlecaesarsarena', 'bbtcenter', 'verizoncenter', 'bonsecourswellnessarena', 'oarena', 'rogersplace', 'pepsicenter', 'aircanadacentre', 'chesapeakeenergyarena', 'sandiegosportsarena', 'parktheatre', 'antelarena', 'americanairlinescenter', 'riodejaneirobrazil', 'ginsionilsonnelson', 'centurylinkarena', 'attcenter', 'talkingstickresortarena', 'adelaideentertainmentcenter', 'neliodiasgymnasium', 'etihadstadium', 'ahoyrotterdam', 'allphonesarena', 'pinnaclebankarena', 'arenaattdplace', 'prudentialcenter', 'scotiabankarena', 'revelatlanticcity', 'ibirapueraarena', 'kingdomarena', 'ericssonglobearena', 'goianaarena', 'theoarena', 'singaporeindoorstadium', 'wellsfargocenter', 'usairwaysarena', 'cotaiarena', 'ppgpaintsarena', 'intrustbankarena', 'telearena', 'royalarena', 'pechangaarena', 'neworleansconventioncenter', 'thepearlatthepalmscasinoresort', 'rogerscentre', 'targetcenter', 'sasktelcentre', 'vectorarena', 'quickenloansarena', 'vivintsmarthomearena', 'chartwayarena', 'josecorreagymnasium', 'staplescenter', 'oraclearena', 'auditrioibirapuera', 'baltimorearena', 'halifaxmetrocentre', 'smmallofasiaarena', 'pertharena', 'thesphere', 'mandalaybayeventscenter', 'sparkarena', 'worldarena', 'madisonsquaregarden', 'barclaycardarena', 'hppavilion', 'amaliearena', 'saitamasuperarena', 'sprintcenter', 'theodeumcolorado', 'footprintcenter', 'bokcenter', 'capitalonearena', 'tancredonevesgymnasium', 'bluecrossarena', 'kfcyumcenter', 'palmscasinoresort', 'mercedesbenzarena', 'ginsiodoibirapuera', 'tmobilearena', 'yubileynysportspalace', 'cadillacarena', 'tdgarden', 'statefarmarena', 'arena', 'crossinsurancecenter', 'accorarena', 'adelaideentertainmentcentre', 'scotiabankcentre', 'ufcfightisland', 'ginsiopaulosarasate', 'ubsarena', 'duarena', 'theforum', 'vystarveteransmemorialarena', 'modacenter', 'capitalfmarena', 'gwinnettcenter', 'thejointatthehardrockhotel', 'amwaycenter', 'arenajaragua', 'miamidadearena', 'tingleycolisuem', 'vivintarena', 'olimpiyskiyarena', 'hsbcarena', 'stbankcenter', 'olympictrainingcenter', 'acerarena', 'concertarenaatferrariworld', 'centrodeformacaoolimpicadonordeste', 'olympicgymnasticsarena', 'ergoarena', 'tedconstantconvocationcenter', 'unitedcenter', 'thepearlatthepalms', 'marvelstadium', 'generalmotorsplace', 'bojanglescoliseum', 'maracanazinhogymnasium', 'ginasiopoliesportivojosecorrea', 'lgarenanationalexhibitioncentre', 'consecofieldhouse', 'rogersarena', 'brisbaneentertainmentcentre', 'bridgestonearena']\n"
     ]
    }
   ],
   "source": [
    "#confirm cleaning worked as intended\n",
    "venue_values = df['venue'].tolist()\n",
    "venue_values = list(set(venue_values))\n",
    "print(venue_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>referee</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>billing</th>\n",
       "      <th>redCorner_wins</th>\n",
       "      <th>blueCorner_wins</th>\n",
       "      <th>redCorner_losses</th>\n",
       "      <th>...</th>\n",
       "      <th>redCorner_subs_attempted</th>\n",
       "      <th>blueCorner_subs_attempted</th>\n",
       "      <th>round</th>\n",
       "      <th>time</th>\n",
       "      <th>redCorner_height</th>\n",
       "      <th>blueCorner_height</th>\n",
       "      <th>redCorner_reach</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>yes</td>\n",
       "      <td>Main Event</td>\n",
       "      <td>Pereira</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4:32</td>\n",
       "      <td>6' 4\"</td>\n",
       "      <td>6' 1\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>yes</td>\n",
       "      <td>Co-Main Event</td>\n",
       "      <td>Pea</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>67\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>no</td>\n",
       "      <td>Main Card</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>70\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>no</td>\n",
       "      <td>Main Card</td>\n",
       "      <td>Dolidze</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5:00</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>no</td>\n",
       "      <td>Main Card</td>\n",
       "      <td>17</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>68\"</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   redCorner  blueCorner  winner  referee  venue title_fight        billing  \\\n",
       "0          0           2       0      112     50         yes     Main Event   \n",
       "1          0           2       2      100     50         yes  Co-Main Event   \n",
       "2          0           2       2       11     50          no      Main Card   \n",
       "3          0           2       0      100     50          no      Main Card   \n",
       "4          0           2       2      112     50          no      Main Card   \n",
       "\n",
       "  redCorner_wins blueCorner_wins  redCorner_losses  ...  \\\n",
       "0        Pereira              11               NaN  ...   \n",
       "1           Pea              10               NaN  ...   \n",
       "2       Bautista              14               NaN  ...   \n",
       "3        Dolidze              13               NaN  ...   \n",
       "4             17        Harrison               1.0  ...   \n",
       "\n",
       "   redCorner_subs_attempted  blueCorner_subs_attempted  round  time  \\\n",
       "0                         0                          0      4  4:32   \n",
       "1                         0                          1      5  5:00   \n",
       "2                         0                          0      3  5:00   \n",
       "3                         0                          0      1  5:00   \n",
       "4                         0                          0      3  5:00   \n",
       "\n",
       "   redCorner_height blueCorner_height redCorner_reach blueCorner_reach  \\\n",
       "0             6' 4\"             6' 1\"             79\"              76\"   \n",
       "1             5' 7\"             5' 6\"             67\"              69\"   \n",
       "2             5' 7\"             5' 9\"             70\"              69\"   \n",
       "3             6' 2\"             6' 3\"             76\"              81\"   \n",
       "4             5' 8\"             5' 8\"             68\"              66\"   \n",
       "\n",
       "  redCorner_stance  blueCorner_stance  \n",
       "0         Orthodox           Southpaw  \n",
       "1         Orthodox           Orthodox  \n",
       "2         Orthodox             Switch  \n",
       "3         Orthodox           Orthodox  \n",
       "4         Orthodox           Southpaw  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#give venues numerical value\n",
    "venues = df['venue']\n",
    "venues1 = []\n",
    "for venue in venues:\n",
    "    venues1.append(venue)\n",
    "\n",
    "venues1 = list(set(venues1))\n",
    "\n",
    "count = 0 \n",
    "for venue in venues1:\n",
    "    df['venue'] = df['venue'].replace(venue, count, regex=True)\n",
    "    count += 1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "#find special characters in billings\n",
    "billings = (df['billing'].values)\n",
    "chars2rep = []\n",
    "for billing in billings:\n",
    "    if(isinstance(billing, str)):\n",
    "        for char in billing:\n",
    "            if char.lower() not in ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "            if char.upper() not in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', \"Q\", 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "chars2rep = list(set(chars2rep))\n",
    "for char in chars2rep:\n",
    "    print(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean billings\n",
    "for index, row in df.iterrows():\n",
    "    df.loc[index, 'billing'] = row['billing'].replace('-', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    df.loc[index, 'billing'] = row['billing'].replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreliminaryCard\n",
      "MainEvent\n",
      "MainCard\n",
      "CoMainEvent\n"
     ]
    }
   ],
   "source": [
    "#check billings\n",
    "colVals = []\n",
    "for index, row in df.iterrows():\n",
    "    colVals.append(row['billing'])\n",
    "\n",
    "colVals = list(set(colVals))\n",
    "for val in colVals:\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give billings numerical value\n",
    "df['billing'] = df['billing'].replace('MainEvent', 0)\n",
    "df['billing'] = df['billing'].replace('CoMainEvent', 1)\n",
    "df['billing'] = df['billing'].replace('MainCard', 2)\n",
    "df['billing'] = df['billing'].replace('PreliminaryCard', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#check billings\n",
    "colVals = []\n",
    "for index, row in df.iterrows():\n",
    "    colVals.append(row['billing'])\n",
    "\n",
    "colVals = list(set(colVals))\n",
    "for val in colVals:\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make title fight binary\n",
    "df['title_fight'] = df['title_fight'].replace('yes', 1)\n",
    "df['title_fight'] = df['title_fight'].replace('no', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>referee</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>billing</th>\n",
       "      <th>redCorner_wins</th>\n",
       "      <th>blueCorner_wins</th>\n",
       "      <th>redCorner_losses</th>\n",
       "      <th>...</th>\n",
       "      <th>redCorner_subs_attempted</th>\n",
       "      <th>blueCorner_subs_attempted</th>\n",
       "      <th>round</th>\n",
       "      <th>time</th>\n",
       "      <th>redCorner_height</th>\n",
       "      <th>blueCorner_height</th>\n",
       "      <th>redCorner_reach</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Pereira</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4:32</td>\n",
       "      <td>6' 4\"</td>\n",
       "      <td>6' 1\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pea</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>67\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>70\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Dolidze</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5:00</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>68\"</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   redCorner  blueCorner  winner  referee  venue  title_fight  billing  \\\n",
       "0          0           2       0      112     50            1        0   \n",
       "1          0           2       2      100     50            1        1   \n",
       "2          0           2       2       11     50            0        2   \n",
       "3          0           2       0      100     50            0        2   \n",
       "4          0           2       2      112     50            0        2   \n",
       "\n",
       "  redCorner_wins blueCorner_wins  redCorner_losses  ...  \\\n",
       "0        Pereira              11               NaN  ...   \n",
       "1           Pea              10               NaN  ...   \n",
       "2       Bautista              14               NaN  ...   \n",
       "3        Dolidze              13               NaN  ...   \n",
       "4             17        Harrison               1.0  ...   \n",
       "\n",
       "   redCorner_subs_attempted  blueCorner_subs_attempted  round  time  \\\n",
       "0                         0                          0      4  4:32   \n",
       "1                         0                          1      5  5:00   \n",
       "2                         0                          0      3  5:00   \n",
       "3                         0                          0      1  5:00   \n",
       "4                         0                          0      3  5:00   \n",
       "\n",
       "   redCorner_height blueCorner_height redCorner_reach blueCorner_reach  \\\n",
       "0             6' 4\"             6' 1\"             79\"              76\"   \n",
       "1             5' 7\"             5' 6\"             67\"              69\"   \n",
       "2             5' 7\"             5' 9\"             70\"              69\"   \n",
       "3             6' 2\"             6' 3\"             76\"              81\"   \n",
       "4             5' 8\"             5' 8\"             68\"              66\"   \n",
       "\n",
       "  redCorner_stance  blueCorner_stance  \n",
       "0         Orthodox           Southpaw  \n",
       "1         Orthodox           Orthodox  \n",
       "2         Orthodox             Switch  \n",
       "3         Orthodox           Orthodox  \n",
       "4         Orthodox           Southpaw  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#find special characters in nations\n",
    "redCorner_nation = df['redCorner_nation'].values\n",
    "blueCorner_nation = df['blueCorner_nation'].values\n",
    "chars2rep = []\n",
    "for nation in redCorner_nation:\n",
    "    if(isinstance(nation, str)):\n",
    "        for char in nation:\n",
    "            if char.lower() not in ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "            if char.upper() not in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', \"Q\", 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "for nation in blueCorner_nation:\n",
    "    if(isinstance(nation, str)):\n",
    "        for char in nation:\n",
    "            if char.lower() not in ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "            if char.upper() not in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', \"Q\", 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "chars2rep = list(set(chars2rep))\n",
    "for char in chars2rep:\n",
    "    print(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean redCorner_nation\n",
    "df['redCorner_nation'] = df['redCorner_nation'].replace('Croatia (Hrvatska)', 'Croatia')\n",
    "df['redCorner_nation'] = df['redCorner_nation'].replace('Virgin Islands (US)', 'Virgin Islands')\n",
    "#clean blueCorner_nation\n",
    "df['blueCorner_nation'] = df['blueCorner_nation'].replace('Croatia (Hrvatska)', 'Croatia')\n",
    "df['blueCorner_nation'] = df['blueCorner_nation'].replace('Virgin Islands (US)', 'Virgin Islands')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    nation = row['redCorner_nation']\n",
    "    if(isinstance(nation, str)):\n",
    "        df.loc[index, 'redCorner_nation'] = row['redCorner_nation'].replace(\" \", \"\").lower()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    nation = row['blueCorner_nation']\n",
    "    if(isinstance(nation, str)):\n",
    "        df.loc[index, 'blueCorner_nation'] = row['blueCorner_nation'].replace(\" \", \"\").lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, 'unitedarabemirates', 'serbia', 'southkorea', 'panama', 'peru', 'tunisia', 'italy', 'azerbaijan', 'assyria', 'norway', 'chile', 'latvia', 'zimbabwe', 'australia', 'germany', 'france', 'austria', 'jordan', 'belarus', 'switzerland', 'moldova', 'czechrepublic', 'ireland', 'iraq', 'ghana', 'spain', 'israel', 'guam', 'kazakhstan', 'afghanistan', 'kyrgyzstan', 'virginislands', 'unitedkingdom', 'singapore', 'ukraine', 'uganda', 'mongolia', 'uruguay', 'finland', 'uzbekistan', 'democraticrepublicofcongo', 'lebanon', 'morocco', 'dominicanrepublic', 'newzealand', 'argentina', 'japan', 'mexico', 'nigeria', 'paraguay', 'elsalvador', 'portugal', 'bahrain', 'lithuania', 'denmark', 'unitedstates', 'iran', 'suriname', 'russia', 'georgia', 'palestine', 'jamaica', 'northernireland', 'myanmar', 'kurdistan', 'bulgaria', 'england', 'venezuela', 'thailand', 'scotland', 'greece', 'romania', 'china', 'canada', 'colombia', 'northmacedonia', 'wales', 'philippines', 'slovakrepublic', 'belgium', 'cyprus', 'ecuador', 'iceland', 'southafrica', 'cameroon', 'cuba', 'hongkong', 'indonesia', 'poland', 'armenia', 'capeverde', 'guyana', 'bahamas', 'bolivia', 'sweden', 'turkey', 'brazil', 'netherlands', 'croatia', 'northernmarianaislands', 'haiti', 'bosniaandherzegovina']\n",
      "103\n",
      "[nan, 'unitedarabemirates', 'serbia', 'vietnam', 'southkorea', 'peru', 'panama', 'tunisia', 'italy', 'azerbaijan', 'assyria', 'norway', 'chile', 'latvia', 'zimbabwe', 'australia', 'germany', 'france', 'austria', 'jordan', 'belarus', 'switzerland', 'moldova', 'czechrepublic', 'ireland', 'india', 'iraq', 'hungary', 'ghana', 'spain', 'israel', 'guam', 'kazakhstan', 'afghanistan', 'syria', 'kyrgyzstan', 'unitedkingdom', 'singapore', 'ukraine', 'uganda', 'mongolia', 'uruguay', 'finland', 'uzbekistan', 'democraticrepublicofcongo', 'lebanon', 'morocco', 'dominicanrepublic', 'newzealand', 'argentina', 'japan', 'mexico', 'nigeria', 'portugal', 'bahrain', 'lithuania', 'denmark', 'unitedstates', 'iran', 'suriname', 'egypt', 'russia', 'nicaragua', 'georgia', 'jamaica', 'northernireland', 'myanmar', 'bulgaria', 'england', 'venezuela', 'greece', 'scotland', 'thailand', 'romania', 'china', 'canada', 'colombia', 'northmacedonia', 'wales', 'philippines', 'slovakrepublic', 'belgium', 'ecuador', 'iceland', 'cyprus', 'southafrica', 'cameroon', 'costarica', 'cuba', 'hongkong', 'indonesia', 'poland', 'armenia', 'capeverde', 'guyana', 'bahamas', 'bolivia', 'sweden', 'taiwan', 'tajikistan', 'turkey', 'brazil', 'netherlands', 'croatia', 'northernmarianaislands', 'haiti', 'bosniaandherzegovina']\n",
      "107\n",
      "['unitedarabemirates', 'serbia', 'southkorea', 'panama', 'peru', 'tunisia', 'italy', 'azerbaijan', 'assyria', 'norway', 'chile', 'latvia', 'zimbabwe', 'australia', 'germany', 'france', 'austria', 'jordan', 'belarus', 'switzerland', 'moldova', 'czechrepublic', 'ireland', 'iraq', 'ghana', 'spain', 'israel', 'guam', 'kazakhstan', 'afghanistan', 'kyrgyzstan', 'unitedkingdom', 'singapore', 'ukraine', 'uganda', 'mongolia', 'uruguay', 'finland', 'uzbekistan', 'democraticrepublicofcongo', 'lebanon', 'morocco', 'dominicanrepublic', 'newzealand', 'argentina', 'japan', 'mexico', 'nigeria', 'portugal', 'bahrain', 'lithuania', 'denmark', 'unitedstates', 'iran', 'suriname', 'russia', 'georgia', 'jamaica', 'northernireland', 'myanmar', 'bulgaria', 'england', 'venezuela', 'greece', 'scotland', 'thailand', 'romania', 'china', 'canada', 'colombia', 'northmacedonia', 'wales', 'philippines', 'slovakrepublic', 'belgium', 'ecuador', 'iceland', 'cyprus', 'southafrica', 'cameroon', 'cuba', 'hongkong', 'indonesia', 'poland', 'armenia', 'capeverde', 'guyana', 'bahamas', 'bolivia', 'sweden', 'turkey', 'brazil', 'netherlands', 'croatia', 'northernmarianaislands', 'haiti', 'bosniaandherzegovina']\n",
      "97\n"
     ]
    }
   ],
   "source": [
    "#generate individual dicts for both - universal dictionary causing problems\n",
    "redCorner_nation_values = df['redCorner_nation'].tolist()\n",
    "redCorner_nation_values = list(set(redCorner_nation_values))\n",
    "blueCorner_nation_values = df['blueCorner_nation'].tolist()\n",
    "blueCorner_nation_values = list(set(blueCorner_nation_values))\n",
    "matched = []\n",
    "notMatched = []\n",
    "for blueNation in blueCorner_nation_values:\n",
    "    for redNation in redCorner_nation_values:\n",
    "        if blueNation == redNation:\n",
    "            matched.append(blueNation)\n",
    "    \n",
    "matched = list(set(matched))\n",
    "print(redCorner_nation_values)\n",
    "print(len(redCorner_nation_values))\n",
    "print(blueCorner_nation_values)\n",
    "print(len(blueCorner_nation_values))\n",
    "print(matched)\n",
    "print(len(matched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "103\n"
     ]
    }
   ],
   "source": [
    "#create list for redNations keeping order with list for blueNations\n",
    "finalizedRed = []\n",
    "i=0\n",
    "for i in range(len(matched)):\n",
    "    finalizedRed.append(matched[i])\n",
    "print(len(finalizedRed))\n",
    "for nation in redCorner_nation_values:\n",
    "    if nation not in matched:\n",
    "        finalizedRed.append(nation)\n",
    "print(len(finalizedRed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unitedarabemirates': 0, 'serbia': 1, 'southkorea': 2, 'panama': 3, 'peru': 4, 'tunisia': 5, 'italy': 6, 'azerbaijan': 7, 'assyria': 8, 'norway': 9, 'chile': 10, 'latvia': 11, 'zimbabwe': 12, 'australia': 13, 'germany': 14, 'france': 15, 'austria': 16, 'jordan': 17, 'belarus': 18, 'switzerland': 19, 'moldova': 20, 'czechrepublic': 21, 'ireland': 22, 'iraq': 23, 'ghana': 24, 'spain': 25, 'israel': 26, 'guam': 27, 'kazakhstan': 28, 'afghanistan': 29, 'kyrgyzstan': 30, 'unitedkingdom': 31, 'singapore': 32, 'ukraine': 33, 'uganda': 34, 'mongolia': 35, 'uruguay': 36, 'finland': 37, 'uzbekistan': 38, 'democraticrepublicofcongo': 39, 'lebanon': 40, 'morocco': 41, 'dominicanrepublic': 42, 'newzealand': 43, 'argentina': 44, 'japan': 45, 'mexico': 46, 'nigeria': 47, 'portugal': 48, 'bahrain': 49, 'lithuania': 50, 'denmark': 51, 'unitedstates': 52, 'iran': 53, 'suriname': 54, 'russia': 55, 'georgia': 56, 'jamaica': 57, 'northernireland': 58, 'myanmar': 59, 'bulgaria': 60, 'england': 61, 'venezuela': 62, 'greece': 63, 'scotland': 64, 'thailand': 65, 'romania': 66, 'china': 67, 'canada': 68, 'colombia': 69, 'northmacedonia': 70, 'wales': 71, 'philippines': 72, 'slovakrepublic': 73, 'belgium': 74, 'ecuador': 75, 'iceland': 76, 'cyprus': 77, 'southafrica': 78, 'cameroon': 79, 'cuba': 80, 'hongkong': 81, 'indonesia': 82, 'poland': 83, 'armenia': 84, 'capeverde': 85, 'guyana': 86, 'bahamas': 87, 'bolivia': 88, 'sweden': 89, 'turkey': 90, 'brazil': 91, 'netherlands': 92, 'croatia': 93, 'northernmarianaislands': 94, 'haiti': 95, 'bosniaandherzegovina': 96, nan: 97, 'virginislands': 98, 'paraguay': 99, 'elsalvador': 100, 'palestine': 101, 'kurdistan': 102}\n"
     ]
    }
   ],
   "source": [
    "#create dict for reddNations keeping order with list for blueNations\n",
    "redNationDict = {}\n",
    "count = 0\n",
    "for nation in finalizedRed:\n",
    "    redNationDict[nation] = count\n",
    "    count+=1\n",
    "print(redNationDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102]\n"
     ]
    }
   ],
   "source": [
    "#give redCorner_nation numerical val\n",
    "for index, row in df.iterrows():\n",
    "    redCorner_nation = row['redCorner_nation']\n",
    "    numericalVal = redNationDict[redCorner_nation]\n",
    "    df.loc[index, 'redCorner_nation'] = numericalVal\n",
    "\n",
    "#confirm redCorner_nations are now numerical\n",
    "print(list(set(df['redCorner_nation'].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "97\n"
     ]
    }
   ],
   "source": [
    "#create list for blueNations keeping order with list for redNations\n",
    "extrasBlue = []\n",
    "for nation in blueCorner_nation_values:\n",
    "    if nation not in matched:\n",
    "        extrasBlue.append(nation)\n",
    "print(len(extrasBlue))\n",
    "print(len(matched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unitedarabemirates': 0, 'serbia': 1, 'southkorea': 2, 'panama': 3, 'peru': 4, 'tunisia': 5, 'italy': 6, 'azerbaijan': 7, 'assyria': 8, 'norway': 9, 'chile': 10, 'latvia': 11, 'zimbabwe': 12, 'australia': 13, 'germany': 14, 'france': 15, 'austria': 16, 'jordan': 17, 'belarus': 18, 'switzerland': 19, 'moldova': 20, 'czechrepublic': 21, 'ireland': 22, 'iraq': 23, 'ghana': 24, 'spain': 25, 'israel': 26, 'guam': 27, 'kazakhstan': 28, 'afghanistan': 29, 'kyrgyzstan': 30, 'unitedkingdom': 31, 'singapore': 32, 'ukraine': 33, 'uganda': 34, 'mongolia': 35, 'uruguay': 36, 'finland': 37, 'uzbekistan': 38, 'democraticrepublicofcongo': 39, 'lebanon': 40, 'morocco': 41, 'dominicanrepublic': 42, 'newzealand': 43, 'argentina': 44, 'japan': 45, 'mexico': 46, 'nigeria': 47, 'portugal': 48, 'bahrain': 49, 'lithuania': 50, 'denmark': 51, 'unitedstates': 52, 'iran': 53, 'suriname': 54, 'russia': 55, 'georgia': 56, 'jamaica': 57, 'northernireland': 58, 'myanmar': 59, 'bulgaria': 60, 'england': 61, 'venezuela': 62, 'greece': 63, 'scotland': 64, 'thailand': 65, 'romania': 66, 'china': 67, 'canada': 68, 'colombia': 69, 'northmacedonia': 70, 'wales': 71, 'philippines': 72, 'slovakrepublic': 73, 'belgium': 74, 'ecuador': 75, 'iceland': 76, 'cyprus': 77, 'southafrica': 78, 'cameroon': 79, 'cuba': 80, 'hongkong': 81, 'indonesia': 82, 'poland': 83, 'armenia': 84, 'capeverde': 85, 'guyana': 86, 'bahamas': 87, 'bolivia': 88, 'sweden': 89, 'turkey': 90, 'brazil': 91, 'netherlands': 92, 'croatia': 93, 'northernmarianaislands': 94, 'haiti': 95, 'bosniaandherzegovina': 96, nan: 97, 'vietnam': 104, 'india': 105, 'hungary': 106, 'syria': 107, 'egypt': 108, 'nicaragua': 109, 'costarica': 110, 'taiwan': 111, 'tajikistan': 112}\n",
      "107\n"
     ]
    }
   ],
   "source": [
    "#create dict for blueNations keeping order with list for redNations\n",
    "blueNationDict = {}\n",
    "count = 0\n",
    "for nation in matched:\n",
    "    blueNationDict[nation] = count\n",
    "    count+=1\n",
    "#initalize count above highest in redValues\n",
    "count =0\n",
    "values_list = list(redNationDict.values())\n",
    "for value in values_list:\n",
    "    if int(value) > count:\n",
    "        count = int(value)\n",
    "count += 1\n",
    "for nation in extrasBlue:\n",
    "    if(nation != np.nan):\n",
    "        blueNationDict[nation] = count\n",
    "        count+=1\n",
    "\n",
    "blueNationDict[np.nan] = redNationDict[np.nan]\n",
    "print(blueNationDict)\n",
    "print(len(blueNationDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 104, 105, 106, 107, 108, 109, 110, 111, 112]\n"
     ]
    }
   ],
   "source": [
    "#give blueCorner_nation numerical val\n",
    "for index, row in df.iterrows():\n",
    "    blueCorner_nation = row['blueCorner_nation']\n",
    "    numericalVal = blueNationDict[blueCorner_nation]\n",
    "    df.loc[index, 'blueCorner_nation'] = numericalVal\n",
    "\n",
    "#confirm blueCorner_nations are now numerical\n",
    "print(list(set(df['blueCorner_nation'].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unitedarabemirates': 0, 'serbia': 1, 'southkorea': 2, 'panama': 3, 'peru': 4, 'tunisia': 5, 'italy': 6, 'azerbaijan': 7, 'assyria': 8, 'norway': 9, 'chile': 10, 'latvia': 11, 'zimbabwe': 12, 'australia': 13, 'germany': 14, 'france': 15, 'austria': 16, 'jordan': 17, 'belarus': 18, 'switzerland': 19, 'moldova': 20, 'czechrepublic': 21, 'ireland': 22, 'iraq': 23, 'ghana': 24, 'spain': 25, 'israel': 26, 'guam': 27, 'kazakhstan': 28, 'afghanistan': 29, 'kyrgyzstan': 30, 'unitedkingdom': 31, 'singapore': 32, 'ukraine': 33, 'uganda': 34, 'mongolia': 35, 'uruguay': 36, 'finland': 37, 'uzbekistan': 38, 'democraticrepublicofcongo': 39, 'lebanon': 40, 'morocco': 41, 'dominicanrepublic': 42, 'newzealand': 43, 'argentina': 44, 'japan': 45, 'mexico': 46, 'nigeria': 47, 'portugal': 48, 'bahrain': 49, 'lithuania': 50, 'denmark': 51, 'unitedstates': 52, 'iran': 53, 'suriname': 54, 'russia': 55, 'georgia': 56, 'jamaica': 57, 'northernireland': 58, 'myanmar': 59, 'bulgaria': 60, 'england': 61, 'venezuela': 62, 'greece': 63, 'scotland': 64, 'thailand': 65, 'romania': 66, 'china': 67, 'canada': 68, 'colombia': 69, 'northmacedonia': 70, 'wales': 71, 'philippines': 72, 'slovakrepublic': 73, 'belgium': 74, 'ecuador': 75, 'iceland': 76, 'cyprus': 77, 'southafrica': 78, 'cameroon': 79, 'cuba': 80, 'hongkong': 81, 'indonesia': 82, 'poland': 83, 'armenia': 84, 'capeverde': 85, 'guyana': 86, 'bahamas': 87, 'bolivia': 88, 'sweden': 89, 'turkey': 90, 'brazil': 91, 'netherlands': 92, 'croatia': 93, 'northernmarianaislands': 94, 'haiti': 95, 'bosniaandherzegovina': 96, nan: 97, 'vietnam': 104, 'india': 105, 'hungary': 106, 'syria': 107, 'egypt': 108, 'nicaragua': 109, 'costarica': 110, 'taiwan': 111, 'tajikistan': 112, 'virginislands': 98, 'paraguay': 99, 'elsalvador': 100, 'palestine': 101, 'kurdistan': 102}\n"
     ]
    }
   ],
   "source": [
    "#build nation dict for test data\n",
    "fullNationDict = blueNationDict\n",
    "for key, value in redNationDict.items():\n",
    "    if key not in blueNationDict:\n",
    "        fullNationDict[key] = value\n",
    "print(fullNationDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping fan votes because there is an issue in the database. Will try and fix at later date\n",
    "df.drop('redCorner_fan', axis=1, inplace=True)\n",
    "df.drop('blueCorner_fan', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>referee</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>billing</th>\n",
       "      <th>redCorner_wins</th>\n",
       "      <th>blueCorner_wins</th>\n",
       "      <th>redCorner_losses</th>\n",
       "      <th>...</th>\n",
       "      <th>redCorner_subs_attempted</th>\n",
       "      <th>blueCorner_subs_attempted</th>\n",
       "      <th>round</th>\n",
       "      <th>time</th>\n",
       "      <th>redCorner_height</th>\n",
       "      <th>blueCorner_height</th>\n",
       "      <th>redCorner_reach</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Pereira</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4:32</td>\n",
       "      <td>6' 4\"</td>\n",
       "      <td>6' 1\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pea</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>67\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>70\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Dolidze</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5:00</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>68\"</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   redCorner  blueCorner  winner  referee  venue  title_fight  billing  \\\n",
       "0          0           2       0      112     50            1        0   \n",
       "1          0           2       2      100     50            1        1   \n",
       "2          0           2       2       11     50            0        2   \n",
       "3          0           2       0      100     50            0        2   \n",
       "4          0           2       2      112     50            0        2   \n",
       "\n",
       "  redCorner_wins blueCorner_wins  redCorner_losses  ...  \\\n",
       "0        Pereira              11               NaN  ...   \n",
       "1           Pea              10               NaN  ...   \n",
       "2       Bautista              14               NaN  ...   \n",
       "3        Dolidze              13               NaN  ...   \n",
       "4             17        Harrison               1.0  ...   \n",
       "\n",
       "   redCorner_subs_attempted  blueCorner_subs_attempted  round  time  \\\n",
       "0                         0                          0      4  4:32   \n",
       "1                         0                          1      5  5:00   \n",
       "2                         0                          0      3  5:00   \n",
       "3                         0                          0      1  5:00   \n",
       "4                         0                          0      3  5:00   \n",
       "\n",
       "   redCorner_height blueCorner_height redCorner_reach  blueCorner_reach  \\\n",
       "0             6' 4\"             6' 1\"             79\"               76\"   \n",
       "1             5' 7\"             5' 6\"             67\"               69\"   \n",
       "2             5' 7\"             5' 9\"             70\"               69\"   \n",
       "3             6' 2\"             6' 3\"             76\"               81\"   \n",
       "4             5' 8\"             5' 8\"             68\"               66\"   \n",
       "\n",
       "   redCorner_stance blueCorner_stance  \n",
       "0          Orthodox          Southpaw  \n",
       "1          Orthodox          Orthodox  \n",
       "2          Orthodox            Switch  \n",
       "3          Orthodox          Orthodox  \n",
       "4          Orthodox          Southpaw  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keeping knockdowns column as is for now. But need to test it while dividing this by total fight time\n",
    "nan_rows_count = df['redCorner_knockdowns'].isna().sum()\n",
    "print(nan_rows_count)\n",
    "nan_rows_count = df['blueCorner_knockdowns'].isna().sum()\n",
    "print(nan_rows_count)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>referee</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>billing</th>\n",
       "      <th>redCorner_wins</th>\n",
       "      <th>blueCorner_wins</th>\n",
       "      <th>redCorner_losses</th>\n",
       "      <th>...</th>\n",
       "      <th>time</th>\n",
       "      <th>redCorner_height</th>\n",
       "      <th>blueCorner_height</th>\n",
       "      <th>redCorner_reach</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "      <th>redCorner_sig_str_landed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_landed_per_minute</th>\n",
       "      <th>fightTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Pereira</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4:32</td>\n",
       "      <td>6' 4\"</td>\n",
       "      <td>6' 1\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pea</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>67\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>70\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Dolidze</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5:00</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>68\"</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   redCorner  blueCorner  winner  referee  venue  title_fight  billing  \\\n",
       "0          0           2       0      112     50            1        0   \n",
       "1          0           2       2      100     50            1        1   \n",
       "2          0           2       2       11     50            0        2   \n",
       "3          0           2       0      100     50            0        2   \n",
       "4          0           2       2      112     50            0        2   \n",
       "\n",
       "  redCorner_wins blueCorner_wins  redCorner_losses  ...  time  \\\n",
       "0        Pereira              11               NaN  ...  4:32   \n",
       "1           Pea              10               NaN  ...  5:00   \n",
       "2       Bautista              14               NaN  ...  5:00   \n",
       "3        Dolidze              13               NaN  ...  5:00   \n",
       "4             17        Harrison               1.0  ...  5:00   \n",
       "\n",
       "   redCorner_height  blueCorner_height  redCorner_reach  blueCorner_reach  \\\n",
       "0             6' 4\"              6' 1\"              79\"               76\"   \n",
       "1             5' 7\"              5' 6\"              67\"               69\"   \n",
       "2             5' 7\"              5' 9\"              70\"               69\"   \n",
       "3             6' 2\"              6' 3\"              76\"               81\"   \n",
       "4             5' 8\"              5' 8\"              68\"               66\"   \n",
       "\n",
       "  redCorner_stance blueCorner_stance  redCorner_sig_str_landed_per_minute  \\\n",
       "0         Orthodox          Southpaw                                  NaN   \n",
       "1         Orthodox          Orthodox                                  NaN   \n",
       "2         Orthodox            Switch                                  NaN   \n",
       "3         Orthodox          Orthodox                                  NaN   \n",
       "4         Orthodox          Southpaw                                  NaN   \n",
       "\n",
       "   blueCorner_sig_str_landed_per_minute fightTime  \n",
       "0                                   NaN       NaN  \n",
       "1                                   NaN       NaN  \n",
       "2                                   NaN       NaN  \n",
       "3                                   NaN       NaN  \n",
       "4                                   NaN       NaN  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding columns redCorner_sig_str_per_minute and blueCorner_sig_str_per_minute\n",
    "df['redCorner_sig_str_landed_per_minute'] = float('nan')\n",
    "df['blueCorner_sig_str_landed_per_minute'] = float('nan')\n",
    "df['fightTime'] = float('nan')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#confirm no rows with nan for round or time\n",
    "nan_rows_count = df['time'].isna().sum()\n",
    "print(nan_rows_count)\n",
    "nan_rows_count = df['round'].isna().sum()\n",
    "print(nan_rows_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>referee</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>billing</th>\n",
       "      <th>redCorner_wins</th>\n",
       "      <th>blueCorner_wins</th>\n",
       "      <th>redCorner_losses</th>\n",
       "      <th>...</th>\n",
       "      <th>time</th>\n",
       "      <th>redCorner_height</th>\n",
       "      <th>blueCorner_height</th>\n",
       "      <th>redCorner_reach</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "      <th>redCorner_sig_str_landed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_landed_per_minute</th>\n",
       "      <th>fightTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Pereira</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4:32</td>\n",
       "      <td>6' 4\"</td>\n",
       "      <td>6' 1\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pea</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>67\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>70\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Dolidze</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5:00</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>68\"</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   redCorner  blueCorner  winner  referee  venue  title_fight  billing  \\\n",
       "0          0           2       0      112     50            1        0   \n",
       "1          0           2       2      100     50            1        1   \n",
       "2          0           2       2       11     50            0        2   \n",
       "3          0           2       0      100     50            0        2   \n",
       "4          0           2       2      112     50            0        2   \n",
       "\n",
       "  redCorner_wins blueCorner_wins  redCorner_losses  ...  time  \\\n",
       "0        Pereira              11               NaN  ...  4:32   \n",
       "1           Pea              10               NaN  ...  5:00   \n",
       "2       Bautista              14               NaN  ...  5:00   \n",
       "3        Dolidze              13               NaN  ...  5:00   \n",
       "4             17        Harrison               1.0  ...  5:00   \n",
       "\n",
       "   redCorner_height  blueCorner_height  redCorner_reach  blueCorner_reach  \\\n",
       "0             6' 4\"              6' 1\"              79\"               76\"   \n",
       "1             5' 7\"              5' 6\"              67\"               69\"   \n",
       "2             5' 7\"              5' 9\"              70\"               69\"   \n",
       "3             6' 2\"              6' 3\"              76\"               81\"   \n",
       "4             5' 8\"              5' 8\"              68\"               66\"   \n",
       "\n",
       "  redCorner_stance blueCorner_stance  redCorner_sig_str_landed_per_minute  \\\n",
       "0         Orthodox          Southpaw                                  NaN   \n",
       "1         Orthodox          Orthodox                                  NaN   \n",
       "2         Orthodox            Switch                                  NaN   \n",
       "3         Orthodox          Orthodox                                  NaN   \n",
       "4         Orthodox          Southpaw                                  NaN   \n",
       "\n",
       "   blueCorner_sig_str_landed_per_minute  fightTime  \n",
       "0                                   NaN  19.533333  \n",
       "1                                   NaN  25.000000  \n",
       "2                                   NaN  15.000000  \n",
       "3                                   NaN   5.000000  \n",
       "4                                   NaN  15.000000  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#format totalTime as float\n",
    "for index, row in df.iterrows():\n",
    "    time = row['time']\n",
    "    round = row['round']\n",
    "    time = time.split(':')\n",
    "    totalTime = (round-1)*5.00\n",
    "    totalTime += float(time[0])\n",
    "    time = float(time[1])\n",
    "    time = time/60\n",
    "    totalTime += time\n",
    "    df.loc[index, 'fightTime'] = totalTime\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>referee</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>billing</th>\n",
       "      <th>redCorner_wins</th>\n",
       "      <th>blueCorner_wins</th>\n",
       "      <th>redCorner_losses</th>\n",
       "      <th>...</th>\n",
       "      <th>time</th>\n",
       "      <th>redCorner_height</th>\n",
       "      <th>blueCorner_height</th>\n",
       "      <th>redCorner_reach</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "      <th>redCorner_sig_str_landed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_landed_per_minute</th>\n",
       "      <th>fightTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Pereira</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4:32</td>\n",
       "      <td>6' 4\"</td>\n",
       "      <td>6' 1\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>6.501706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pea</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>67\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>70\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Dolidze</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5:00</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>68\"</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   redCorner  blueCorner  winner  referee  venue  title_fight  billing  \\\n",
       "0          0           2       0      112     50            1        0   \n",
       "1          0           2       2      100     50            1        1   \n",
       "2          0           2       2       11     50            0        2   \n",
       "3          0           2       0      100     50            0        2   \n",
       "4          0           2       2      112     50            0        2   \n",
       "\n",
       "  redCorner_wins blueCorner_wins  redCorner_losses  ...  time  \\\n",
       "0        Pereira              11               NaN  ...  4:32   \n",
       "1           Pea              10               NaN  ...  5:00   \n",
       "2       Bautista              14               NaN  ...  5:00   \n",
       "3        Dolidze              13               NaN  ...  5:00   \n",
       "4             17        Harrison               1.0  ...  5:00   \n",
       "\n",
       "   redCorner_height  blueCorner_height  redCorner_reach  blueCorner_reach  \\\n",
       "0             6' 4\"              6' 1\"              79\"               76\"   \n",
       "1             5' 7\"              5' 6\"              67\"               69\"   \n",
       "2             5' 7\"              5' 9\"              70\"               69\"   \n",
       "3             6' 2\"              6' 3\"              76\"               81\"   \n",
       "4             5' 8\"              5' 8\"              68\"               66\"   \n",
       "\n",
       "  redCorner_stance blueCorner_stance  redCorner_sig_str_landed_per_minute  \\\n",
       "0         Orthodox          Southpaw                             6.501706   \n",
       "1         Orthodox          Orthodox                             3.680000   \n",
       "2         Orthodox            Switch                             3.400000   \n",
       "3         Orthodox          Orthodox                             3.800000   \n",
       "4         Orthodox          Southpaw                             1.600000   \n",
       "\n",
       "   blueCorner_sig_str_landed_per_minute  fightTime  \n",
       "0                                   NaN  19.533333  \n",
       "1                                   NaN  25.000000  \n",
       "2                                   NaN  15.000000  \n",
       "3                                   NaN   5.000000  \n",
       "4                                   NaN  15.000000  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate value and set redCorner_sig_str_per_minute\n",
    "for index, row in df.iterrows():\n",
    "    totals = row['redCorner_sig_str']\n",
    "    if(isinstance(totals, str)):\n",
    "        totals = totals.split(' ')\n",
    "        landed = float(totals[0])\n",
    "        fightTime = row['fightTime']\n",
    "        sig_str_per_min = landed/fightTime\n",
    "        df.loc[index, 'redCorner_sig_str_landed_per_minute'] = sig_str_per_min\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>referee</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>billing</th>\n",
       "      <th>redCorner_wins</th>\n",
       "      <th>blueCorner_wins</th>\n",
       "      <th>redCorner_losses</th>\n",
       "      <th>...</th>\n",
       "      <th>time</th>\n",
       "      <th>redCorner_height</th>\n",
       "      <th>blueCorner_height</th>\n",
       "      <th>redCorner_reach</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "      <th>redCorner_sig_str_landed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_landed_per_minute</th>\n",
       "      <th>fightTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Pereira</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4:32</td>\n",
       "      <td>6' 4\"</td>\n",
       "      <td>6' 1\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>6.501706</td>\n",
       "      <td>3.122867</td>\n",
       "      <td>19.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pea</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>67\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>70\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Dolidze</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5:00</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>68\"</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   redCorner  blueCorner  winner  referee  venue  title_fight  billing  \\\n",
       "0          0           2       0      112     50            1        0   \n",
       "1          0           2       2      100     50            1        1   \n",
       "2          0           2       2       11     50            0        2   \n",
       "3          0           2       0      100     50            0        2   \n",
       "4          0           2       2      112     50            0        2   \n",
       "\n",
       "  redCorner_wins blueCorner_wins  redCorner_losses  ...  time  \\\n",
       "0        Pereira              11               NaN  ...  4:32   \n",
       "1           Pea              10               NaN  ...  5:00   \n",
       "2       Bautista              14               NaN  ...  5:00   \n",
       "3        Dolidze              13               NaN  ...  5:00   \n",
       "4             17        Harrison               1.0  ...  5:00   \n",
       "\n",
       "   redCorner_height  blueCorner_height  redCorner_reach  blueCorner_reach  \\\n",
       "0             6' 4\"              6' 1\"              79\"               76\"   \n",
       "1             5' 7\"              5' 6\"              67\"               69\"   \n",
       "2             5' 7\"              5' 9\"              70\"               69\"   \n",
       "3             6' 2\"              6' 3\"              76\"               81\"   \n",
       "4             5' 8\"              5' 8\"              68\"               66\"   \n",
       "\n",
       "  redCorner_stance blueCorner_stance  redCorner_sig_str_landed_per_minute  \\\n",
       "0         Orthodox          Southpaw                             6.501706   \n",
       "1         Orthodox          Orthodox                             3.680000   \n",
       "2         Orthodox            Switch                             3.400000   \n",
       "3         Orthodox          Orthodox                             3.800000   \n",
       "4         Orthodox          Southpaw                             1.600000   \n",
       "\n",
       "   blueCorner_sig_str_landed_per_minute  fightTime  \n",
       "0                              3.122867  19.533333  \n",
       "1                              3.680000  25.000000  \n",
       "2                              3.266667  15.000000  \n",
       "3                              3.600000   5.000000  \n",
       "4                              3.666667  15.000000  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate value and set blueCorner_sig_str_per_minute\n",
    "for index, row in df.iterrows():\n",
    "    totals = row['blueCorner_sig_str']\n",
    "    if(isinstance(totals, str)):\n",
    "        totals = totals.split(' ')\n",
    "        landed = float(totals[0])\n",
    "        fightTime = row['fightTime']\n",
    "        sig_str_per_min = landed/fightTime\n",
    "        df.loc[index, 'blueCorner_sig_str_landed_per_minute'] = sig_str_per_min\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix divide by zero errors\n",
    "df['redCorner_sig_str_percentage'].fillna('0%', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#confirm no rows with nan sig_strike_accuracy\n",
    "nan_rows_count = df['redCorner_sig_str_percentage'].isna().sum()\n",
    "print(nan_rows_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6, 0.29, 0.43, 0.57, 0.39, 0.46, 0.33, 0.32, 0.5, 0.45, 0.31, 0.58, 0.69, 0.66, 0.6, 0.59, 0.67, 0.61, 0.37, 0.6, 0.47, 0.46, 0.58, 0.51, 0.47, 0.56, 0.52, 0.18, 0.32, 0.39, 0.5, 0.37, 0.46, 0.47, 0.41, 0.43, 0.48, 0.35, 0.59, 0.48, 0.51, 0.55, 0.73, 0.5, 0.44, 0.66, 0.5, 0.6, 0.32, 0.51, 0.5, 0.42, 0.45, 0.42, 0.45, 0.58, 0.41, 0.53, 0.38, 0.45, 0.35, 0.49, 0.29, 0.36, 0.62, 0.55, 0.43, 0.57, 0.47, 0.51, 0.47, 0.0, 0.65, 0.47, 0.75, 0.69, 0.4, 0.6, 0.57, 0.83, 0.41, 0.44, 0.54, 0.44, 0.55, 0.35, 0.67, 0.52, 0.22, 0.67, 0.44, 0.42, 0.46, 0.55, 0.66, 0.73, 0.71, 0.6, 0.5, 0.7, 0.57, 0.52, 0.36, 0.35, 0.5, 0.34, 0.65, 0.45, 0.22, 0.55, 0.53, 0.44, 0.6, 0.4, 0.16, 0.34, 0.48, 0.56, 0.34, 0.53, 0.35, 0.4, 0.44, 0.39, 0.76, 0.5, 0.44, 0.66, 0.5, 0.66, 0.52, 0.76, 0.54, 0.54, 0.77, 0.48, 0.8, 0.55, 0.5, 1.0, 0.4, 0.62, 0.53, 0.43, 0.66, 0.34, 0.47, 0.75, 0.45, 0.46, 0.35, 0.5, 0.34, 0.66, 0.66, 0.53, 0.3, 0.5, 0.44, 0.68, 0.42, 0.49, 0.52, 0.5, 0.45, 0.5, 0.58, 0.6, 0.33, 0.66, 1.0, 0.58, 0.4, 0.51, 0.6, 0.49, 0.48, 0.38, 0.41, 0.56, 0.56, 0.45, 0.47, 0.48, 0.47, 0.55, 0.5, 0.65, 0.32, 0.58, 0.67, 0.42, 0.32, 0.6, 0.82, 0.64, 0.28, 0.69, 0.0, 0.51, 0.5, 0.49, 0.3, 0.37, 0.54, 0.55, 0.25, 0.51, 0.41, 0.51, 0.56, 0.27, 0.37, 0.46, 0.41, 0.42, 0.51, 0.55, 0.55, 0.6, 0.45, 0.6, 0.37, 0.52, 0.63, 0.62, 0.54, 0.51, 0.53, 0.4, 0.39, 0.51, 0.45, 0.44, 0.41, 0.49, 0.42, 0.36, 0.4, 0.47, 0.49, 0.41, 0.8, 0.67, 0.51, 0.51, 0.61, 0.58, 0.27, 0.16, 0.4, 0.4, 0.49, 0.58, 0.68, 0.5, 0.36, 0.47, 0.58, 0.48, 0.37, 0.49, 0.37, 0.39, 0.35, 0.2, 0.45, 0.33, 0.33, 0.67, 0.37, 0.51, 0.65, 0.48, 0.27, 0.36, 0.41, 0.41, 0.3, 0.37, 0.3, 0.65, 0.62, 0.61, 0.2, 0.55, 0.42, 0.41, 0.31, 0.5, 0.17, 0.46, 0.34, 0.62, 0.36, 0.51, 0.63, 0.33, 0.64, 0.88, 0.44, 0.6, 0.43, 0.6, 0.64, 0.32, 0.64, 0.82, 0.47, 0.46, 0.54, 0.64, 0.43, 0.55, 0.37, 0.48, 0.73, 0.77, 0.54, 0.54, 0.59, 0.36, 0.34, 0.69, 0.28, 0.38, 0.46, 0.43, 0.7, 0.65, 0.55, 0.53, 0.47, 0.44, 0.34, 0.6, 0.35, 0.52, 0.6, 0.44, 0.44, 0.54, 0.0, 0.43, 0.54, 0.51, 0.43, 0.44, 0.51, 0.71, 0.54, 0.6, 0.43, 0.63, 0.35, 0.51, 0.57, 0.24, 0.44, 0.54, 0.54, 0.66, 0.39, 0.51, 0.41, 0.49, 0.65, 0.32, 0.64, 0.22, 0.54, 0.28, 0.38, 0.5, 0.42, 0.46, 0.23, 0.66, 0.59, 0.48, 0.36, 0.67, 0.42, 0.66, 0.55, 0.54, 0.42, 0.41, 0.38, 0.34, 0.58, 0.11, 0.77, 0.52, 0.67, 0.57, 0.41, 0.48, 0.45, 0.4, 0.52, 0.42, 0.3, 0.52, 0.58, 0.52, 0.6, 0.77, 0.59, 0.2, 0.58, 0.47, 0.48, 0.41, 0.58, 0.55, 0.4, 0.46, 0.55, 0.55, 0.47, 0.45, 0.39, 0.4, 0.59, 0.5, 0.76, 0.43, 0.25, 0.55, 0.48, 0.58, 0.32, 0.42, 0.86, 0.8, 1.0, 0.61, 0.64, 0.42, 0.74, 0.4, 0.33, 0.52, 0.47, 0.51, 0.87, 0.36, 0.74, 0.39, 0.44, 0.47, 0.69, 0.66, 0.56, 0.14, 0.49, 0.55, 0.72, 0.59, 0.37, 0.62, 0.43, 0.54, 0.62, 0.52, 0.42, 0.67, 0.42, 0.45, 0.49, 0.48, 0.46, 0.3, 0.63, 0.74, 0.54, 0.82, 0.54, 0.68, 0.72, 0.45, 0.69, 0.46, 0.69, 0.38, 0.51, 0.69, 0.5, 0.73, 0.5, 0.4, 0.62, 0.0, 0.51, 0.33, 0.51, 0.66, 0.44, 0.55, 0.37, 0.0, 0.41, 0.28, 0.56, 0.48, 0.52, 0.82, 0.47, 0.66, 0.32, 0.56, 0.57, 0.68, 0.56, 0.0, 0.38, 0.72, 0.71, 0.44, 0.52, 0.55, 0.41, 0.35, 0.6, 0.35, 0.34, 0.67, 0.58, 0.6, 0.48, 0.36, 0.63, 0.34, 0.41, 0.61, 0.78, 0.55, 0.52, 0.6, 0.49, 0.45, 0.46, 0.25, 0.5, 0.69, 0.25, 0.55, 0.56, 0.59, 0.53, 0.51, 0.53, 0.51, 0.66, 0.15, 0.58, 0.61, 0.46, 0.63, 0.47, 0.61, 0.33, 0.48, 0.5, 0.5, 0.47, 0.26, 0.48, 0.48, 0.75, 0.4, 0.51, 0.56, 0.4, 0.83, 0.51, 0.51, 0.43, 0.34, 0.56, 0.51, 0.49, 0.66, 0.4, 0.5, 0.38, 0.13, 0.63, 0.28, 0.42, 0.63, 0.6, 0.32, 0.4, 0.37, 0.3, 0.0, 0.55, 0.3, 0.38, 0.37, 0.53, 0.44, 0.56, 0.22, 0.51, 0.64, 0.51, 0.43, 0.36, 0.27, 0.6, 0.76, 0.59, 0.43, 0.7, 0.72, 0.37, 0.56, 0.48, 0.36, 0.54, 0.32, 0.33, 0.43, 0.6, 0.55, 0.45, 0.41, 0.37, 0.38, 0.69, 0.6, 0.42, 0.4, 0.61, 0.53, 0.33, 0.27, 0.28, 0.49, 0.38, 0.39, 0.25, 0.68, 0.6, 0.44, 0.56, 0.7, 0.8, 0.78, 0.0, 0.49, 0.54, 0.56, 0.66, 0.52, 0.43, 0.46, 0.35, 0.44, 0.58, 0.6, 0.37, 0.73, 0.6, 0.52, 0.35, 0.55, 0.28, 0.47, 0.6, 0.5, 0.53, 0.44, 0.47, 0.56, 0.31, 0.35, 0.4, 0.36, 0.3, 0.5, 0.69, 0.57, 0.77, 0.76, 0.61, 0.37, 0.59, 0.43, 0.57, 1.0, 0.57, 0.53, 0.72, 0.46, 0.47, 0.49, 0.67, 0.49, 0.62, 0.46, 0.46, 0.5, 0.34, 0.6, 0.6, 0.49, 0.3, 0.53, 0.54, 0.42, 0.45, 0.54, 0.44, 0.48, 0.42, 0.6, 0.58, 0.41, 0.43, 0.42, 0.29, 0.58, 0.5, 0.63, 0.6, 0.44, 0.63, 0.0, 0.41, 0.28, 0.61, 0.45, 0.73, 0.42, 0.38, 0.27, 0.33, 0.43, 0.64, 0.46, 0.37, 0.68, 0.56, 0.33, 0.76, 0.45, 0.53, 0.48, 0.6, 0.7, 0.46, 0.61, 0.66, 0.62, 0.77, 0.39, 0.55, 0.56, 0.37, 0.28, 0.42, 0.42, 0.23, 0.33, 0.44, 0.47, 0.18, 0.33, 0.48, 0.24, 0.11, 0.55, 0.56, 0.63, 0.48, 0.31, 0.34, 0.25, 0.58, 0.59, 0.57, 0.66, 0.56, 0.68, 0.43, 0.49, 0.57, 0.42, 0.44, 0.33, 0.1, 0.34, 0.32, 0.47, 0.31, 0.49, 0.51, 0.23, 0.36, 0.5, 0.41, 0.37, 0.4, 0.53, 0.25, 0.5, 0.57, 0.52, 0.74, 0.6, 0.9, 0.41, 0.48, 0.6, 0.63, 0.28, 0.53, 0.57, 0.64, 0.47, 0.57, 0.47, 0.37, 0.52, 0.8, 0.58, 0.6, 0.75, 0.47, 0.65, 0.72, 0.45, 0.63, 0.49, 0.31, 0.57, 0.5, 0.6, 0.47, 0.69, 0.25, 0.78, 0.44, 0.4, 0.47, 0.54, 0.4, 0.24, 0.39, 0.51, 0.38, 0.55, 0.76, 0.52, 0.24, 0.44, 0.48, 0.31, 0.25, 0.35, 0.37, 0.37, 0.32, 0.24, 0.36, 0.48, 0.5, 0.43, 0.33, 0.41, 0.6, 0.6, 0.57, 0.45, 0.5, 0.5, 0.55, 0.35, 0.25, 0.56, 0.66, 0.62, 0.4, 0.41, 0.0, 0.34, 0.38, 0.64, 0.41, 0.56, 0.43, 0.4, 0.28, 0.65, 1.0, 0.46, 0.44, 0.83, 0.34, 0.37, 0.54, 0.51, 0.66, 0.4, 1.0, 0.44, 0.69, 0.45, 0.48, 0.32, 0.44, 0.45, 0.36, 0.42, 0.7, 0.73, 0.61, 0.52, 0.54, 0.55, 0.59, 0.45, 0.41, 0.45, 0.53, 0.28, 0.0, 0.44, 0.35, 0.38, 0.5, 0.18, 0.35, 0.28, 0.47, 0.4, 0.42, 0.5, 0.43, 0.42, 0.57, 0.5, 0.41, 0.57, 0.63, 0.59, 0.62, 0.48, 0.76, 0.2, 0.59, 0.52, 0.44, 0.52, 0.36, 0.45, 0.29, 0.49, 0.65, 0.43, 0.57, 0.37, 0.25, 0.55, 0.55, 0.43, 0.29, 0.59, 0.68, 0.55, 0.62, 0.53, 0.18, 0.5, 0.16, 0.46, 0.56, 0.41, 0.65, 0.43, 0.4, 0.36, 0.6, 0.2, 0.6, 0.36, 0.52, 1.0, 0.44, 0.67, 0.58, 0.65, 0.61, 0.36, 0.46, 0.58, 0.24, 0.4, 0.46, 0.44, 0.47, 0.42, 0.4, 0.5, 0.33, 0.45, 0.39, 0.48, 0.77, 0.6, 0.45, 0.26, 0.38, 0.4, 0.51, 0.59, 0.47, 0.7, 0.72, 0.49, 0.64, 0.6, 0.65, 0.62, 0.54, 0.33, 0.5, 0.51, 0.61, 0.66, 0.4, 0.42, 0.61, 1.0, 0.48, 0.53, 0.79, 0.5, 0.5, 0.44, 0.61, 0.42, 0.67, 0.41, 0.31, 0.53, 0.65, 0.55, 0.54, 0.55, 0.42, 0.67, 0.29, 0.53, 0.46, 0.0, 0.44, 0.52, 1.0, 0.5, 0.7, 0.45, 0.52, 0.47, 0.27, 0.57, 0.4, 0.65, 0.44, 0.46, 0.3, 0.45, 0.42, 1.0, 0.37, 0.55, 0.62, 0.22, 0.68, 0.61, 0.7, 0.56, 0.61, 0.54, 0.47, 0.44, 0.46, 0.48, 0.66, 0.54, 0.48, 0.39, 0.49, 0.39, 0.26, 0.57, 0.35, 0.38, 0.35, 0.34, 0.61, 0.36, 0.08, 0.42, 0.56, 0.47, 0.3, 0.62, 0.34, 0.48, 0.27, 0.7, 0.59, 1.0, 0.38, 0.38, 0.66, 0.66, 0.58, 0.54, 0.41, 0.4, 0.53, 0.54, 0.43, 0.53, 0.48, 0.4, 0.39, 0.43, 0.59, 0.46, 0.26, 0.4, 0.4, 0.61, 0.5, 0.41, 0.56, 0.55, 0.52, 0.62, 0.51, 0.43, 0.58, 0.52, 0.55, 0.48, 0.65, 0.77, 0.6, 0.52, 0.25, 0.49, 0.48, 0.37, 0.4, 0.51, 0.34, 0.38, 0.47, 0.4, 0.46, 0.45, 0.5, 0.53, 0.51, 0.57, 0.63, 0.66, 0.66, 0.6, 0.54, 0.23, 0.56, 0.56, 0.38, 0.5, 0.61, 0.75, 0.1, 0.62, 0.78, 0.59, 0.44, 0.63, 0.66, 0.47, 0.34, 0.45, 0.25, 0.41, 0.3, 0.52, 0.3, 0.37, 0.28, 0.32, 0.42, 0.67, 0.53, 0.68, 0.55, 0.67, 0.35, 0.5, 0.28, 0.7, 0.6, 0.64, 0.23, 0.57, 0.56, 0.39, 0.5, 0.25, 0.46, 0.86, 0.45, 0.4, 0.6, 0.78, 0.28, 0.37, 0.73, 0.48, 0.61, 0.47, 0.82, 0.37, 0.45, 0.69, 0.52, 0.38, 0.57, 0.64, 0.41, 0.43, 0.36, 0.41, 0.28, 0.51, 0.27, 0.49, 0.62, 0.23, 0.65, 0.36, 0.63, 0.27, 0.5, 0.54, 0.52, 0.64, 0.35, 0.35, 0.48, 0.7, 0.54, 0.56, 0.45, 0.39, 0.52, 0.55, 0.4, 0.64, 0.49, 0.52, 0.57, 0.66, 0.39, 0.65, 0.55, 0.41, 0.75, 0.79, 0.57, 0.92, 0.38, 0.75, 0.57, 0.66, 0.63, 0.4, 0.45, 0.63, 0.41, 0.57, 0.57, 0.54, 0.72, 0.44, 0.7, 0.43, 0.44, 0.65, 0.39, 0.52, 0.64, 0.56, 0.59, 0.32, 0.55, 0.51, 0.67, 0.4, 0.43, 0.36, 0.56, 0.47, 0.47, 0.69, 0.62, 0.45, 0.37, 0.85, 0.58, 0.51, 0.62, 0.3, 0.44, 0.5, 0.56, 0.58, 0.5, 0.8, 0.53, 0.34, 0.0, 0.5, 0.76, 0.65, 0.37, 0.4, 0.43, 0.36, 0.52, 0.37, 0.45, 0.6, 0.48, 0.5, 0.34, 0.41, 0.31, 0.51, 0.36, 0.43, 0.46, 0.52, 0.43, 0.65, 0.51, 0.46, 0.36, 0.4, 0.66, 0.05, 0.44, 0.54, 0.36, 0.43, 0.68, 0.45, 0.67, 0.54, 0.37, 0.44, 0.75, 0.35, 0.0, 0.57, 0.48, 0.66, 0.4, 0.52, 0.33, 0.47, 0.5, 0.46, 0.34, 0.51, 0.4, 0.57, 0.46, 0.62, 0.61, 0.46, 0.52, 0.48, 0.33, 0.48, 0.58, 0.5, 0.57, 0.57, 0.78, 0.3, 0.38, 0.71, 0.46, 0.42, 0.6, 0.53, 0.4, 0.65, 1.0, 0.7, 0.58, 0.36, 0.27, 0.41, 0.4, 0.52, 0.25, 0.61, 0.48, 0.53, 0.46, 0.59, 0.55, 0.43, 0.35, 0.4, 0.3, 0.4, 0.36, 0.5, 0.4, 0.59, 0.49, 0.58, 0.5, 0.59, 0.43, 0.28, 0.35, 0.6, 0.37, 0.5, 0.31, 0.6, 0.56, 0.6, 0.45, 0.55, 0.46, 0.52, 0.56, 0.23, 0.36, 0.43, 0.72, 0.76, 0.5, 0.32, 0.81, 0.47, 0.74, 0.48, 0.51, 0.5, 0.36, 0.6, 0.39, 0.44, 0.73, 0.49, 0.49, 0.57, 0.63, 0.71, 0.42, 0.5, 0.39, 0.56, 0.35, 0.66, 0.38, 0.38, 0.45, 0.34, 0.37, 0.56, 0.25, 0.71, 0.55, 0.37, 0.45, 0.3, 0.51, 0.4, 0.23, 0.33, 0.41, 0.51, 0.6, 0.67, 0.63, 0.61, 0.33, 0.53, 0.62, 0.64, 0.58, 0.47, 0.6, 0.56, 0.62, 0.55, 0.66, 0.53, 0.0, 0.61, 0.37, 0.3, 0.5, 0.57, 0.52, 0.66, 0.38, 0.45, 0.62, 0.77, 0.66, 0.71, 0.51, 0.52, 0.51, 0.55, 0.45, 0.48, 0.52, 0.75, 0.4, 0.48, 0.3, 0.48, 0.66, 0.34, 0.54, 0.62, 0.36, 0.42, 0.43, 0.52, 0.28, 0.48, 0.32, 0.38, 0.66, 0.71, 0.39, 0.84, 0.69, 0.41, 0.42, 0.58, 0.45, 0.57, 0.55, 0.63, 0.42, 0.45, 0.66, 0.69, 0.41, 0.6, 0.57, 0.44, 0.33, 0.55, 0.65, 0.47, 0.36, 0.19, 0.54, 0.52, 0.6, 0.34, 0.6, 0.63, 0.44, 0.7, 0.49, 0.4, 0.34, 0.51, 0.64, 0.58, 0.57, 0.28, 0.38, 0.38, 0.48, 0.61, 0.42, 0.46, 0.58, 0.46, 0.59, 0.48, 0.39, 0.34, 0.52, 0.58, 0.35, 0.57, 0.4, 0.5, 0.55, 0.6, 0.69, 0.71, 0.5, 0.39, 0.33, 0.53, 0.38, 0.44, 0.55, 0.4, 0.7, 0.42, 0.58, 0.32, 1.0, 0.43, 0.51, 0.33, 0.48, 0.45, 0.54, 0.38, 0.66, 0.66, 0.65, 0.67, 0.47, 0.19, 0.41, 0.68, 0.53, 0.49, 0.44, 0.52, 0.37, 0.47, 0.28, 0.49, 0.45, 0.56, 0.66, 0.32, 0.34, 0.44, 0.4, 0.55, 0.37, 0.55, 0.55, 0.66, 0.39, 0.0, 0.55, 0.51, 0.54, 0.53, 0.26, 0.62, 0.65, 0.54, 0.67, 0.47, 0.56, 0.72, 0.35, 0.42, 0.58, 0.31, 0.36, 0.28, 0.41, 0.52, 0.45, 0.52, 0.5, 0.56, 0.63, 0.38, 0.6, 0.88, 0.64, 0.52, 0.28, 0.47, 0.55, 0.48, 0.64, 0.5, 1.0, 0.55, 0.68, 0.52, 0.35, 0.49, 0.5, 0.55, 0.53, 0.66, 0.58, 0.39, 0.92, 0.43, 0.59, 0.54, 0.46, 0.49, 0.0, 0.5, 0.32, 0.48, 0.55, 0.57, 0.35, 0.44, 0.3, 0.52, 0.42, 0.3, 0.4, 0.31, 0.48, 0.34, 0.6, 0.48, 0.45, 0.5, 0.41, 0.51, 0.55, 0.59, 0.5, 0.5, 0.5, 0.32, 0.47, 0.75, 0.44, 0.48, 0.43, 0.44, 0.57, 0.47, 0.81, 0.72, 0.68, 0.56, 0.4, 0.44, 0.48, 0.31, 0.62, 0.51, 0.65, 0.52, 0.48, 0.1, 0.58, 0.66, 0.46, 0.46, 0.36, 0.45, 0.47, 0.59, 0.67, 0.53, 0.55, 0.52, 0.63, 0.82, 0.0, 0.66, 0.58, 0.31, 0.42, 0.57, 0.46, 0.54, 0.44, 0.7, 0.52, 0.47, 0.44, 0.58, 0.46, 0.6, 0.35, 0.46, 0.58, 0.52, 0.37, 0.34, 0.37, 0.57, 0.46, 0.32, 0.2, 0.53, 0.18, 0.56, 0.4, 0.6, 0.44, 0.92, 0.45, 0.57, 0.39, 0.46, 1.0, 0.31, 0.34, 0.43, 0.51, 0.46, 0.58, 0.47, 0.39, 0.77, 0.47, 0.44, 0.47, 0.57, 0.6, 0.48, 0.27, 0.25, 0.4, 0.4, 0.68, 0.57, 0.48, 0.61, 0.45, 0.41, 0.49, 0.6, 0.55, 0.72, 0.62, 0.6, 0.5, 0.44, 0.41, 0.4, 0.35, 0.56, 0.55, 0.54, 0.14, 0.71, 0.5, 0.4, 0.39, 0.41, 0.48, 0.7, 0.24, 0.59, 0.32, 0.41, 0.53, 0.43, 0.6, 0.5, 0.57, 0.36, 0.62, 0.25, 0.64, 0.57, 0.81, 0.7, 0.61, 0.26, 0.45, 0.45, 0.49, 0.34, 0.48, 0.25, 0.49, 0.46, 0.5, 0.4, 0.46, 0.49, 0.44, 0.66, 0.52, 0.67, 0.78, 0.37, 0.72, 0.83, 0.52, 0.42, 0.44, 0.34, 0.41, 0.48, 0.5, 0.5, 0.33, 0.36, 0.4, 0.46, 0.8, 0.42, 0.25, 0.39, 0.41, 0.65, 0.53, 0.39, 0.44, 0.54, 0.52, 0.6, 0.2, 0.59, 0.44, 0.61, 0.13, 0.45, 0.44, 0.54, 0.38, 0.22, 0.31, 0.42, 0.62, 0.55, 0.75, 0.5, 0.62, 0.47, 0.52, 0.64, 0.64, 0.42, 0.46, 0.57, 0.45, 0.47, 0.83, 0.28, 0.69, 0.4, 0.63, 0.5, 0.48, 0.35, 0.5, 0.36, 0.46, 0.0, 0.5, 0.49, 0.4, 0.25, 0.54, 0.5, 0.43, 0.25, 0.51, 0.75, 0.44, 0.5, 0.49, 0.62, 0.52, 0.39, 0.3, 0.35, 0.47, 0.53, 0.68, 0.41, 0.5, 0.52, 0.48, 0.51, 1.0, 0.61, 0.56, 0.6, 0.47, 0.59, 0.54, 0.43, 0.62, 0.41, 0.57, 0.5, 0.37, 0.64, 0.85, 0.44, 0.44, 0.6, 0.54, 0.66, 0.45, 0.91, 0.48, 0.29, 0.5, 0.46, 0.2, 0.57, 0.45, 0.32, 0.45, 0.61, 0.0, 0.25, 0.51, 0.68, 0.42, 0.5, 0.44, 0.37, 0.66, 0.59, 0.35, 0.7, 0.29, 0.37, 0.41, 0.58, 0.47, 0.27, 0.52, 0.75, 0.28, 0.43, 0.32, 0.32, 0.64, 0.32, 0.62, 0.61, 0.35, 0.43, 0.41, 0.47, 0.41, 0.51, 0.48, 0.4, 0.41, 0.31, 0.38, 0.43, 0.3, 0.58, 0.41, 0.56, 0.65, 0.41, 0.57, 0.39, 0.5, 0.4, 0.3, 0.57, 0.7, 0.58, 0.41, 0.54, 0.49, 0.66, 0.86, 0.69, 0.57, 0.3, 0.61, 0.28, 0.71, 0.88, 0.2, 0.41, 0.5, 0.39, 0.72, 0.35, 0.54, 0.64, 0.52, 0.39, 0.4, 0.37, 0.7, 0.5, 0.47, 0.8, 0.41, 0.57, 0.5, 0.33, 0.58, 0.38, 0.42, 0.57, 0.36, 0.66, 0.41, 0.33, 0.58, 0.56, 0.6, 0.57, 0.47, 0.7, 0.64, 0.47, 0.46, 0.64, 1.0, 0.42, 0.7, 0.61, 0.47, 0.54, 0.45, 0.31, 0.35, 1.0, 0.3, 0.28, 0.62, 0.61, 0.83, 0.36, 0.38, 0.75, 0.56, 0.57, 0.58, 0.48, 0.5, 0.41, 0.58, 0.49, 0.6, 0.53, 0.52, 0.42, 0.54, 0.62, 0.52, 0.6, 0.43, 0.52, 0.8, 0.55, 0.4, 0.48, 0.64, 0.51, 0.4, 1.0, 0.52, 0.71, 0.39, 0.43, 0.56, 0.87, 0.5, 0.45, 0.75, 0.51, 0.86, 0.46, 0.53, 0.57, 0.18, 0.32, 0.36, 0.4, 0.39, 0.53, 0.45, 0.5, 0.5, 0.34, 0.36, 0.63, 0.55, 0.64, 0.62, 0.5, 0.62, 0.34, 0.85, 0.44, 0.33, 0.33, 0.55, 0.46, 0.42, 0.52, 0.38, 0.66, 0.58, 0.68, 0.62, 0.85, 0.48, 0.49, 0.35, 0.56, 0.4, 0.69, 0.47, 0.69, 0.47, 0.66, 0.35, 0.46, 0.54, 0.4, 0.26, 0.25, 0.57, 0.25, 0.25, 0.39, 0.25, 0.68, 0.55, 0.57, 0.55, 0.66, 0.36, 0.57, 0.32, 0.66, 0.58, 0.57, 0.62, 0.8, 0.49, 0.44, 0.43, 0.45, 0.5, 0.43, 0.52, 0.74, 0.65, 0.23, 0.67, 0.5, 0.58, 0.53, 0.41, 0.63, 0.8, 0.4, 0.48, 0.42, 0.5, 0.54, 0.0, 0.45, 0.47, 0.5, 0.61, 0.4, 0.5, 0.31, 0.46, 0.46, 0.45, 0.49, 0.27, 0.46, 0.58, 0.45, 0.63, 0.46, 0.54, 0.44, 0.55, 0.51, 0.43, 0.54, 0.81, 0.44, 0.51, 0.57, 0.5, 0.74, 0.43, 0.46, 0.53, 0.39, 0.53, 0.6, 0.46, 0.36, 0.36, 0.4, 0.6, 0.53, 0.51, 0.81, 0.25, 0.5, 0.45, 0.31, 0.51, 0.48, 0.62, 0.45, 0.5, 0.68, 0.31, 0.68, 0.4, 0.64, 0.65, 0.16, 0.51, 0.47, 0.25, 0.44, 0.29, 0.52, 0.32, 0.6, 0.45, 0.46, 0.3, 0.4, 0.44, 0.4, 0.39, 0.4, 0.55, 0.45, 0.52, 0.43, 0.54, 0.47, 0.72, 0.38, 0.51, 0.36, 0.62, 0.61, 0.63, 0.28, 0.4, 0.47, 0.4, 0.25, 0.29, 0.25, 0.45, 0.19, 0.46, 0.38, 0.15, 0.42, 0.43, 0.43, 0.48, 0.48, 0.72, 0.76, 0.76, 0.41, 0.73, 0.48, 0.31, 0.58, 0.48, 0.44, 0.33, 0.42, 0.5, 0.48, 0.36, 0.64, 0.43, 0.44, 0.5, 0.41, 0.5, 0.4, 0.5, 0.26, 0.54, 0.42, 0.5, 0.35, 0.48, 0.44, 0.42, 0.43, 0.5, 0.65, 0.26, 0.51, 0.63, 0.55, 0.32, 0.5, 0.59, 0.7, 0.4, 0.68, 0.55, 0.61, 0.44, 0.5, 0.86, 0.85, 0.8, 0.35, 0.49, 0.41, 0.37, 0.62, 0.61, 0.51, 0.41, 0.29, 0.25, 0.27, 0.45, 0.49, 0.32, 0.38, 0.56, 0.39, 0.51, 0.32, 0.46, 0.65, 0.42, 0.38, 0.44, 0.4, 0.41, 0.39, 0.62, 0.49, 0.57, 0.45, 0.35, 0.56, 0.67, 0.13, 0.44, 0.4, 0.5, 0.25, 0.56, 0.45, 0.33, 0.55, 0.47, 0.55, 0.41, 0.33, 0.36, 0.65, 0.28, 0.72, 0.56, 0.51, 0.69, 0.5, 0.54, 0.75, 0.47, 0.27, 0.5, 0.36, 0.45, 0.29, 0.6, 0.46, 0.5, 0.13, 0.43, 0.35, 0.35, 0.62, 0.45, 0.61, 0.6, 0.57, 0.41, 0.46, 0.27, 0.31, 0.42, 0.25, 0.66, 0.44, 0.5, 0.59, 0.55, 0.34, 0.43, 0.47, 0.75, 0.55, 0.57, 0.47, 0.36, 0.18, 0.31, 0.12, 0.34, 0.55, 0.4, 0.5, 1.0, 0.55, 0.41, 0.37, 0.43, 0.51, 0.6, 0.38, 0.37, 0.33, 0.45, 0.64, 0.32, 0.6, 0.45, 0.42, 0.43, 0.6, 0.85, 0.19, 0.35, 0.35, 0.51, 0.36, 0.53, 0.52, 0.45, 0.58, 0.31, 0.43, 0.37, 0.42, 0.5, 0.46, 0.23, 0.33, 0.42, 0.33, 0.46, 0.47, 0.45, 0.45, 0.54, 0.59, 0.42, 0.37, 0.4, 0.48, 0.68, 0.51, 0.44, 0.33, 0.43, 0.55, 0.55, 0.56, 0.62, 0.42, 0.49, 0.63, 0.36, 0.46, 0.56, 0.46, 0.46, 0.34, 0.5, 0.68, 0.37, 0.53, 0.35, 0.47, 1.0, 0.34, 0.25, 0.26, 0.53, 0.47, 0.44, 0.42, 0.69, 0.83, 0.19, 0.86, 0.42, 0.39, 0.56, 0.67, 0.47, 0.5, 0.49, 0.51, 0.59, 0.4, 0.69, 0.58, 0.47, 0.33, 0.94, 0.3, 0.27, 0.57, 0.47, 0.34, 0.36, 0.26, 0.65, 0.52, 0.52, 0.8, 0.73, 0.51, 0.62, 0.52, 0.43, 0.34, 0.5, 0.23, 0.18, 0.34, 0.4, 0.65, 0.48, 1.0, 0.71, 0.63, 0.2, 0.37, 0.37, 0.07, 0.54, 0.48, 0.4, 0.47, 0.31, 0.25, 0.35, 0.59, 0.36, 0.33, 0.73, 0.6, 0.74, 0.28, 0.44, 0.0, 0.46, 0.42, 0.57, 0.49, 0.56, 0.75, 0.57, 0.0, 0.25, 0.46, 0.52, 0.72, 0.52, 0.38, 0.44, 0.52, 0.49, 0.38, 0.41, 0.37, 0.36, 0.43, 0.37, 0.47, 0.66, 0.33, 0.39, 0.48, 0.39, 0.54, 0.18, 0.46, 0.26, 0.47, 0.46, 0.54, 0.45, 0.5, 0.72, 0.64, 0.55, 0.55, 0.54, 0.5, 0.48, 0.66, 0.34, 0.46, 0.44, 0.54, 0.36, 0.39, 0.33, 0.25, 0.64, 0.45, 0.36, 0.48, 0.47, 0.33, 0.4, 0.59, 0.5, 0.57, 0.6, 0.53, 0.65, 0.34, 0.44, 0.27, 0.66, 0.27, 0.51, 0.46, 0.35, 0.52, 0.41, 0.62, 0.51, 0.42, 0.49, 0.56, 0.54, 0.49, 0.28, 0.87, 0.7, 0.65, 0.41, 0.62, 0.64, 0.39, 0.73, 0.4, 0.46, 0.83, 0.4, 0.41, 0.23, 0.24, 0.5, 0.3, 0.16, 0.51, 0.0, 0.5, 0.59, 0.4, 0.39, 0.4, 0.16, 0.25, 0.48, 0.55, 0.49, 0.58, 0.5, 0.41, 0.62, 0.48, 0.44, 0.54, 0.43, 0.66, 0.53, 0.5, 0.46, 0.5, 0.38, 0.75, 0.59, 0.5, 0.2, 0.3, 0.48, 0.63, 0.35, 0.37, 0.57, 0.2, 0.33, 0.59, 0.4, 0.57, 0.54, 0.58, 0.28, 0.66, 0.64, 0.4, 0.56, 0.42, 0.32, 0.4, 0.44, 0.43, 0.54, 0.45, 0.59, 0.74, 0.66, 0.89, 0.48, 0.35, 0.33, 0.5, 0.39, 0.64, 0.61, 0.56, 0.44, 0.37, 0.0, 0.45, 0.48, 0.37, 0.44, 0.37, 0.51, 0.56, 0.53, 0.42, 0.29, 0.42, 0.6, 0.5, 0.41, 0.28, 0.67, 0.43, 0.28, 0.58, 0.29, 0.44, 0.51, 0.4, 0.49, 0.5, 0.25, 0.6, 0.43, 0.44, 0.38, 0.34, 0.36, 0.75, 0.54, 0.16, 0.52, 0.0, 0.48, 0.87, 0.35, 0.5, 0.34, 0.61, 0.66, 0.64, 0.25, 0.59, 0.78, 0.45, 0.71, 0.42, 0.62, 0.54, 0.46, 0.49, 0.55, 0.31, 0.51, 0.3, 0.18, 0.57, 0.2, 0.2, 0.42, 0.54, 0.47, 0.5, 0.36, 0.37, 0.53, 0.44, 0.53, 0.6, 0.34, 0.55, 0.44, 0.5, 0.19, 0.59, 0.59, 0.5, 0.52, 0.52, 0.47, 0.53, 0.59, 0.46, 0.73, 0.48, 0.64, 0.43, 0.41, 0.32, 0.43, 0.48, 0.5, 0.52, 0.61, 0.4, 0.53, 0.31, 0.32, 0.55, 0.44, 0.17, 0.27, 0.42, 0.21, 0.34, 0.32, 0.55, 0.95, 0.48, 0.6, 0.47, 0.25, 0.39, 0.48, 0.6, 0.36, 0.45, 0.59, 0.55, 0.12, 0.84, 0.45, 0.4, 0.4, 0.5, 0.52, 0.77, 0.41, 0.45, 0.65, 0.6, 0.28, 0.56, 0.44, 0.47, 0.57, 0.53, 0.78, 0.57, 0.35, 0.35, 0.41, 0.45, 0.4, 0.69, 0.28, 0.64, 0.7, 0.51, 0.42, 0.5, 0.8, 0.68, 0.35, 0.39, 0.76, 0.35, 0.4, 0.47, 0.21, 0.28, 0.32, 0.21, 0.63, 0.37, 0.7, 0.18, 0.52, 0.45, 0.61, 0.57, 0.37, 0.45, 0.5, 0.27, 0.5, 0.38, 0.33, 0.55, 0.43, 0.58, 0.58, 0.53, 0.55, 0.71, 0.3, 0.64, 0.68, 0.65, 0.49, 0.48, 0.51, 0.65, 0.7, 0.41, 0.43, 0.41, 0.46, 0.4, 0.5, 0.5, 0.66, 0.34, 0.46, 0.46, 0.55, 0.22, 0.55, 0.31, 0.28, 0.69, 0.43, 0.24, 0.32, 0.44, 0.08, 0.42, 0.37, 0.72, 0.52, 0.71, 0.49, 0.71, 0.6, 0.44, 0.57, 0.6, 0.59, 0.62, 0.52, 0.4, 0.46, 0.56, 0.33, 0.85, 0.53, 0.45, 0.55, 0.58, 0.45, 0.0, 0.83, 0.44, 0.5, 0.62, 0.6, 0.52, 0.35, 0.45, 0.47, 0.47, 0.36, 0.32, 0.51, 0.27, 0.52, 0.34, 0.46, 0.37, 0.48, 0.36, 0.44, 0.41, 0.66, 0.5, 0.34, 0.18, 0.31, 0.46, 0.33, 0.43, 0.42, 0.6, 0.51, 0.46, 0.21, 0.32, 0.56, 0.46, 0.66, 0.25, 0.48, 0.44, 0.64, 0.36, 0.35, 0.25, 0.57, 0.26, 0.47, 0.36, 0.45, 0.67, 0.56, 0.64, 0.47, 0.23, 0.46, 0.46, 0.45, 0.47, 0.45, 0.37, 0.4, 0.64, 0.42, 0.22, 0.59, 0.21, 0.51, 0.39, 0.43, 0.37, 0.34, 0.38, 0.47, 0.4, 0.49, 0.45, 0.58, 0.36, 0.46, 0.36, 0.25, 0.37, 0.45, 0.2, 0.2, 0.38, 0.5, 0.3, 0.39, 0.53, 0.66, 0.4, 0.23, 0.58, 0.4, 0.54, 0.52, 0.16, 0.31, 0.36, 0.0, 0.0, 0.5, 0.36, 0.55, 0.35, 0.37, 0.35, 0.42, 0.53, 0.4, 0.42, 0.44, 0.23, 0.62, 0.32, 0.32, 0.46, 0.2, 0.21, 0.53, 0.37, 0.34, 0.55, 0.31, 0.75, 0.28, 0.47, 0.32, 0.4, 0.3, 0.33, 0.69, 0.47, 0.54, 0.42, 0.32, 0.48, 0.55, 0.46, 0.43, 0.16, 0.83, 0.58, 0.5, 0.25, 0.58, 0.64, 0.14, 1.0, 0.48, 0.42, 0.69, 0.33, 0.58, 0.5, 0.5, 0.29, 0.51, 0.53, 0.42, 0.49, 0.66, 0.46, 0.72, 0.38, 0.52, 0.19, 0.32, 0.47, 0.33, 0.45, 0.5, 0.61, 0.42, 0.44, 0.34, 0.56, 0.44, 0.35, 0.5, 0.28, 0.45, 0.78, 0.54, 0.33, 0.43, 0.48, 0.0, 0.4, 0.4, 0.36, 0.38, 0.64, 0.76, 0.35, 0.56, 0.45, 0.55, 0.36, 0.36, 0.41, 0.68, 0.2, 0.35, 0.55, 0.45, 0.51, 0.29, 0.4, 0.5, 0.18, 0.26, 0.41, 0.52, 0.85, 0.37, 0.35, 0.49, 0.66, 0.43, 0.31, 0.25, 0.45, 0.47, 0.45, 0.66, 0.35, 0.3, 0.77, 0.48, 0.43, 0.74, 0.49, 0.52, 0.37, 0.47, 0.6, 0.55, 0.32, 0.3, 0.48, 0.55, 0.84, 0.5, 0.52, 0.41, 0.7, 0.45, 0.62, 0.54, 0.56, 0.5, 0.42, 0.52, 0.43, 0.45, 0.38, 0.36, 0.26, 0.7, 0.47, 0.32, 0.51, 0.35, 0.73, 0.52, 0.43, 0.35, 0.26, 0.25, 0.32, 0.45, 0.3, 0.29, 0.5, 0.36, 0.45, 0.75, 0.28, 0.52, 0.3, 0.52, 0.27, 0.54, 0.27, 0.58, 0.52, 0.5, 0.42, 0.33, 0.33, 0.28, 0.49, 0.4, 0.3, 0.5, 0.4, 0.45, 0.39, 0.61, 0.29, 0.5, 0.51, 1.0, 0.45, 0.16, 0.4, 0.61, 0.19, 0.5, 0.59, 0.56, 0.39, 0.36, 0.34, 0.28, 0.54, 0.36, 0.47, 0.24, 0.43, 0.25, 0.43, 0.43, 0.54, 0.46, 0.57, 0.37, 0.29, 0.66, 0.65, 0.66, 0.5, 0.4, 0.55, 0.3, 0.54, 0.58, 0.0, 0.58, 0.52, 0.2, 0.34, 0.33, 0.29, 0.52, 0.43, 0.37, 0.48, 1.0, 0.38, 0.27, 0.38, 0.43, 0.28, 0.57, 0.58, 0.44, 0.38, 0.58, 0.47, 0.59, 0.48, 0.41, 0.52, 0.41, 0.64, 0.16, 0.56, 0.53, 0.52, 0.45, 0.55, 0.29, 0.14, 0.4, 0.66, 0.49, 0.46, 0.23, 0.38, 0.3, 0.25, 0.33, 0.11, 0.44, 0.5, 0.3, 0.55, 0.46, 0.58, 0.5, 0.43, 0.41, 0.35, 0.41, 0.45, 0.35, 0.45, 0.53, 0.4, 0.3, 0.47, 0.39, 0.64, 0.58, 0.38, 0.75, 0.6, 0.21, 0.38, 0.41, 0.47, 0.47, 0.64, 0.32, 0.52, 0.79, 0.0, 0.6, 0.51, 0.33, 0.44, 0.46, 0.27, 0.57, 0.34, 0.0, 0.46, 0.66, 0.6, 0.51, 0.4, 0.31, 0.47, 0.53, 0.34, 0.68, 0.61, 0.48, 0.35, 0.33, 0.28, 0.36, 0.0, 0.48, 0.38, 0.48, 0.2, 0.58, 0.55, 0.38, 0.5, 0.5, 0.28, 0.33, 0.28, 0.41, 0.53, 0.53, 0.44, 0.45, 0.56, 0.5, 0.54, 0.31, 0.43, 0.35, 0.07, 0.47, 0.32, 0.39, 0.55, 0.33, 0.45, 0.31, 0.0, 0.8, 0.0, 0.52, 0.54, 0.28, 0.41, 0.37, 0.51, 0.49, 0.5, 0.67, 0.58, 0.29, 0.36, 0.54, 0.35, 0.61, 0.47, 0.43, 0.47, 0.43, 0.45, 0.6, 0.35, 0.36, 0.42, 0.5, 0.46, 0.51, 0.34, 0.71, 0.35, 0.55, 0.34, 0.31, 0.31, 0.36, 0.52, 0.25, 0.53, 0.53, 0.52, 0.44, 0.42, 0.38, 0.66, 0.48, 0.49, 0.42, 0.52, 0.59, 0.58, 0.77, 0.45, 1.0, 0.44, 0.56, 0.43, 0.3, 0.47, 0.56, 0.58, 0.65, 0.66, 0.44, 0.6, 0.5, 0.33, 0.36, 0.53, 0.43, 0.31, 0.42, 0.54, 0.55, 0.36, 0.33, 0.47, 0.5, 0.35, 0.43, 0.0, 0.14, 0.54, 0.59, 0.53, 0.41, 0.53, 0.37, 0.36, 0.47, 0.48, 0.83, 0.25, 0.62, 0.37, 0.48, 0.64, 0.53, 0.4, 0.48, 0.28, 0.47, 0.53, 0.51, 0.32, 0.52, 0.53, 0.42, 0.38, 0.6, 0.4, 0.42, 0.71, 0.47, 0.43, 0.33, 0.79, 0.43, 0.65, 0.41, 0.28, 0.44, 0.46, 0.46, 0.63, 0.6, 0.69, 0.32, 0.34, 0.46, 0.44, 0.38, 0.53, 0.33, 0.33, 0.7, 0.63, 0.51, 0.46, 0.6, 0.41, 0.55, 0.26, 0.54, 0.38, 0.41, 0.62, 0.64, 0.58, 0.65, 0.25, 0.27, 0.67, 0.5, 0.52, 0.42, 0.51, 0.64, 0.49, 0.34, 0.35, 0.87, 0.44, 0.29, 0.5, 0.8, 0.69, 0.52, 0.46, 0.6, 0.66, 0.28, 0.38, 0.32, 0.46, 0.44, 0.45, 0.43, 0.31, 0.42, 0.58, 0.51, 0.85, 0.41, 0.55, 0.35, 0.54, 0.36, 0.48, 0.45, 0.5, 0.42, 0.41, 0.27, 0.7, 0.5, 0.42, 0.43, 0.53, 0.38, 0.25, 0.78, 0.75, 0.61, 0.3, 0.55, 0.65, 0.42, 0.54, 0.37, 0.11, 0.32, 0.5, 0.32, 0.39, 0.24, 0.39, 0.13, 0.5, 0.42, 0.55, 0.38, 0.45, 0.44, 0.35, 0.4, 0.37, 0.45, 0.31, 0.58, 0.38, 0.33, 0.4, 0.37, 0.4, 1.0, 0.4, 0.51, 0.42, 0.34, 0.0, 0.76, 0.46, 0.33, 0.46, 0.43, 0.38, 0.36, 0.51, 0.33, 0.48, 0.37, 0.22, 0.49, 0.32, 0.31, 0.27, 0.27, 0.37, 0.46, 0.5, 0.28, 0.43, 0.4, 0.5, 0.57, 0.3, 0.59, 0.33, 0.23, 0.5, 0.37, 0.2, 0.57, 0.6, 0.41, 0.56, 0.55, 0.51, 0.66, 0.35, 0.36, 0.48, 0.54, 0.42, 0.28, 0.49, 0.41, 0.45, 0.42, 0.52, 0.41, 0.55, 0.55, 0.5, 0.3, 0.62, 0.84, 0.26, 0.47, 0.43, 1.0, 0.64, 0.55, 0.47, 0.51, 0.25, 0.36, 0.28, 0.39, 0.36, 0.45, 0.48, 0.29, 0.35, 0.31, 0.38, 0.37, 0.28, 0.78, 0.65, 0.35, 0.35, 0.54, 0.56, 0.35, 0.31, 0.4, 0.42, 0.3, 0.38, 0.26, 0.2, 0.41, 0.47, 0.5, 0.23, 0.74, 0.51, 0.42, 0.28, 0.34, 0.38, 0.33, 0.33, 0.48, 0.59, 0.35, 0.0, 0.5, 0.41, 0.46, 0.51, 0.43, 0.59, 0.71, 0.48, 0.27, 0.3, 0.35, 0.61, 0.14, 0.21, 0.43, 0.47, 0.25, 0.32, 0.52, 0.66, 0.27, 0.42, 0.32, 0.42, 0.43, 0.56, 0.55, 0.46, 0.5, 0.48, 0.37, 0.37, 0.42, 0.46, 0.45, 0.3, 0.56, 0.35, 0.3, 0.34, 0.39, 0.4, 0.33, 0.42, 0.22, 0.38, 0.33, 0.32, 0.28, 0.94, 0.37, 0.53, 0.57, 0.36, 0.36, 0.41, 0.61, 0.38, 0.44, 0.42, 0.66, 0.42, 0.54, 0.47, 0.22, 0.61, 0.37, 0.55, 0.23, 0.47, 0.58, 0.5, 0.42, 0.5, 0.33, 0.51, 0.47, 0.29, 1.0, 0.38, 0.44, 0.53, 0.42, 0.51, 0.36, 0.56, 0.59, 0.0, 0.19, 0.71, 0.26, 0.46, 0.76, 0.48, 0.29, 0.61, 0.5, 0.38, 0.26, 0.4, 0.5, 0.63, 0.43, 0.53, 0.34, 0.29, 1.0, 0.6, 0.39, 0.39, 0.51, 0.33, 0.41, 0.69, 0.48, 0.38, 0.48, 0.5, 0.33, 0.27, 0.6, 0.44, 0.66, 0.45, 0.23, 0.34, 0.56, 0.44, 0.35, 0.5, 0.67, 0.46, 0.6, 0.06, 0.38, 0.07, 0.42, 0.52, 0.61, 0.35, 0.5, 0.48, 0.41, 0.34, 0.53, 0.5, 0.37, 0.56, 0.5, 0.45, 0.62, 0.25, 0.41, 0.4, 0.43, 0.38, 0.57, 0.61, 0.62, 0.74, 0.41, 0.46, 0.46, 0.55, 0.65, 0.28, 0.57, 0.72, 0.26, 0.77, 0.67, 0.53, 0.53, 0.7, 0.2, 0.68, 0.51, 0.41, 0.63, 0.47, 0.44, 0.32, 0.62, 0.6, 0.61, 0.3, 0.53, 0.72, 0.84, 0.46, 0.57, 0.75, 0.42, 0.27, 0.39, 0.58, 0.38, 0.4, 0.29, 0.21, 0.5, 0.42, 0.16, 0.55, 0.36, 0.43, 0.33, 0.43, 0.41, 0.46, 0.4, 0.61, 0.54, 0.72, 0.55, 0.36, 0.46, 0.33, 0.36, 0.26, 0.35, 0.55, 0.72, 0.45, 0.33, 0.5, 0.41, 0.54, 0.32, 0.65, 0.29, 0.25, 0.35, 0.68, 0.71, 0.45, 0.4, 0.31, 0.45, 0.46, 0.39, 0.41, 0.43, 0.43, 0.5, 0.35, 0.5, 0.39, 0.45, 0.7, 0.65, 0.47, 0.58, 0.85, 0.53, 0.66, 0.43, 0.51, 0.51, 0.34, 0.76, 0.0, 0.56, 0.62, 0.65, 0.45, 0.68, 0.47, 0.29, 0.37, 0.49, 0.68, 0.3, 0.66, 0.63, 0.36, 0.5, 0.47, 0.54, 0.53, 0.66, 0.34, 0.53, 0.7, 0.61, 0.35, 0.29, 0.71, 0.56, 0.5, 0.38, 0.36, 0.52, 0.84, 0.39, 0.49, 0.36, 0.68, 0.42, 0.35, 0.47, 0.41, 0.38, 0.0, 0.42, 0.0, 0.45, 0.79, 0.43, 0.42, 0.75, 0.31, 0.42, 0.14, 0.42, 0.47, 0.55, 0.34, 0.35, 0.33, 0.64, 0.43, 0.41, 0.33, 0.35, 0.48, 0.56, 0.34, 0.64, 0.67, 0.38, 0.57, 0.36, 0.55, 0.47, 0.54, 0.41, 0.56, 0.66, 0.77, 0.3, 0.41, 0.23, 0.57, 0.54, 0.61, 0.66, 0.45, 0.26, 0.76, 0.84, 0.42, 0.34, 0.0, 0.56, 0.27, 0.37, 0.55, 0.51, 0.43, 0.34, 0.5, 0.33, 0.5, 0.42, 0.52, 0.46, 0.45, 0.53, 0.5, 0.21, 0.84, 0.51, 0.38, 0.4, 0.41, 0.52, 0.62, 0.34, 0.63, 0.51, 0.47, 0.33, 0.42, 0.26, 0.51, 0.44, 0.32, 0.66, 0.42, 0.38, 0.41, 0.52, 0.66, 0.39, 0.47, 0.6, 0.51, 0.73, 0.44, 0.51, 0.36, 0.38, 0.44, 0.53, 0.55, 0.52, 0.63, 0.41, 0.59, 0.47, 0.34, 0.34, 0.5, 0.42, 0.61, 0.52, 0.44, 0.36, 0.6, 0.53, 0.55, 0.33, 0.64, 0.57, 0.81, 0.57, 0.67, 0.57, 0.5, 0.66, 0.69, 0.58, 0.58, 0.4, 0.18, 0.48, 0.37, 0.73, 0.56, 0.44, 0.34, 0.35, 0.56, 0.57, 0.46, 0.88, 0.29, 0.52, 0.29, 0.25, 0.37, 0.62, 0.31, 0.25, 0.42, 0.58, 0.75, 0.54, 0.69, 0.69, 0.44, 0.49, 0.4, 0.16, 0.37, 0.59, 0.37, 0.52, 0.28, 0.42, 0.26, 0.38, 0.33, 0.4, 0.42, 0.42, 0.25, 0.34, 0.4, 0.26, 0.49, 0.66, 0.47, 0.56, 0.63, 0.53, 0.18, 0.4, 0.52, 0.54, 0.52, 0.61, 0.54, 0.52, 0.48, 0.38, 0.36, 0.48, 0.6, 0.47, 0.27, 0.54, 0.42, 0.36, 0.34, 0.4, 0.32, 0.49, 0.4, 0.32, 0.56, 0.32, 0.2, 0.3, 0.57, 0.49, 0.39, 0.35, 0.32, 0.55, 0.5, 0.5, 0.42, 0.39, 0.33, 0.46, 0.65, 0.71, 0.7, 0.34, 0.43, 1.0, 0.33, 0.45, 0.41, 0.38, 0.63, 0.51, 0.52, 0.59, 0.46, 0.56, 0.53, 0.44, 0.62, 0.4, 0.57, 0.3, 0.48, 0.51, 0.64, 0.47, 0.37, 0.34, 0.12, 0.5, 0.5, 0.45, 0.63, 0.82, 0.67, 0.37, 0.6, 0.55, 0.12, 0.49, 0.61, 0.59, 0.71, 0.43, 0.0, 0.52, 0.27, 0.59, 0.54, 0.74, 0.56, 0.59, 0.57, 0.44, 0.76, 0.51, 0.44, 0.52, 0.76, 0.34, 0.55, 0.47, 0.47, 0.57, 0.48, 0.4, 0.48, 0.28, 0.31, 0.46, 0.45, 0.46, 0.41, 0.57, 0.27, 0.64, 0.5, 0.46, 0.37, 0.77, 0.5, 0.54, 0.52, 0.75, 0.43, 0.33, 0.36, 0.48, 0.32, 0.49, 0.29, 0.55, 0.35, 0.47, 0.47, 0.2, 0.35, 0.57, 0.6, 0.52, 0.33, 0.57, 0.63, 0.5, 0.42, 0.56, 0.3, 0.64, 0.44, 0.42, 0.75, 0.36, 0.67, 0.2, 0.51, 0.4, 0.48, 0.34, 0.48, 0.32, 0.51, 0.75, 0.51, 0.33, 0.58, 0.32, 0.32, 0.61, 0.36, 0.46, 0.42, 0.0, 0.53, 0.53, 0.35, 0.68, 0.56, 0.51, 0.52, 0.28, 0.53, 0.56, 0.4, 0.43, 1.0, 0.0, 0.45, 0.38, 0.56, 0.5, 0.31, 0.75, 0.41, 0.11, 0.55, 0.62, 0.15, 0.56, 0.38, 0.31, 0.66, 0.46, 0.53, 0.63, 0.47, 0.34, 0.56, 0.71, 0.38, 0.43, 0.3, 0.56, 0.48, 0.46, 0.66, 0.41, 0.39, 0.57, 0.31, 0.68, 0.58, 0.61, 0.64, 0.5, 0.32, 0.65, 0.49, 0.41, 0.5, 0.41, 0.35, 0.33, 0.5, 0.5, 0.47, 0.62, 0.28, 0.6, 0.14, 0.34, 0.37, 0.25, 0.44, 0.4, 0.55, 0.3, 0.54, 0.46, 0.37, 0.47, 0.35, 0.43, 0.34, 0.48, 0.56, 0.56, 0.42, 0.34, 0.48, 0.66, 0.41, 0.59, 0.4, 0.43, 0.39, 0.3, 0.23, 0.5, 0.26, 0.4, 0.5, 0.5, 0.45, 0.0, 0.77, 0.62, 0.6, 0.81, 0.71, 0.6, 0.55, 0.84, 0.48, 0.46, 0.5, 0.42, 0.48, 0.57, 0.38, 0.36, 0.59, 0.52, 0.43, 0.3, 0.88, 0.38, 0.25, 0.33, 0.71, 0.52, 0.49, 0.0, 0.18, 0.33, 0.18, 0.53, 0.29, 0.3, 0.33, 0.34, 0.39, 0.48, 0.39, 0.26, 0.13, 0.0, 0.28, 0.28, 0.48, 0.28, 0.0, 0.32, 0.29, 0.64, 0.41, 0.3, 0.33, 0.31, 0.36, 0.52, 0.3, 0.4, 0.4, 0.58, 0.29, 0.39, 0.37, 0.32, 0.67, 0.37, 0.67, 0.72, 0.61, 0.63, 0.5, 0.49, 0.25, 0.37, 0.32, 0.38, 0.38, 0.0, 0.43, 0.44, 0.25, 0.52, 0.5, 0.36, 0.27, 0.32, 0.34, 0.42, 0.0, 0.81, 0.62, 0.6, 0.59, 0.36, 0.53, 0.45, 0.65, 0.3, 0.43, 0.66, 0.6, 0.56, 0.53, 0.36, 0.47, 0.32, 0.51, 0.44, 0.42, 0.4, 0.41, 0.4, 0.32, 0.38, 0.44, 0.34, 0.24, 0.63, 0.42, 0.41, 0.47, 1.0, 0.52, 0.85, 0.51, 0.38, 0.67, 0.45, 0.66, 0.4, 0.64, 0.68, 0.5, 0.38, 0.58, 0.66, 0.4, 0.55, 0.49, 0.44, 0.46, 0.6, 0.38, 0.32, 0.39, 0.58, 0.48, 0.48, 0.61, 0.45, 0.48, 0.51, 0.67, 0.5, 0.36, 0.36, 0.53, 0.5, 0.5, 0.39, 0.35, 0.46, 0.4, 0.33, 0.59, 0.47, 0.67, 0.43, 0.26, 0.28, 0.35, 0.56, 0.0, 0.56, 0.41, 0.56, 0.57, 0.66, 0.4, 0.29, 0.43, 0.37, 0.5, 0.5, 0.66, 0.44, 0.41, 0.51, 0.55, 0.37, 0.64, 0.5, 0.55, 0.27, 0.48, 0.33, 0.47, 0.47, 0.41, 0.64, 0.57, 0.52, 0.87, 0.5, 0.4, 0.37, 0.19, 0.6, 0.3, 0.24, 0.31, 0.45, 0.31, 0.46, 0.53, 0.12, 0.42, 0.56, 0.42, 0.4, 0.57, 0.29, 0.4, 0.64, 0.58, 0.57, 0.33, 1.0, 0.49, 0.37, 0.33, 0.58, 0.67, 0.44, 0.38, 0.53, 0.31, 0.9, 0.59, 0.62, 0.53, 0.52, 0.34, 0.66, 0.74, 0.43, 0.43, 0.63, 0.37, 0.21, 0.35, 0.43, 0.47, 0.47, 0.39, 0.72, 0.3, 0.41, 0.76, 0.36, 0.41, 0.55, 0.46, 0.4, 0.36, 0.38, 0.51, 0.79, 0.4, 0.4, 0.66, 0.32, 0.46, 0.57, 0.95, 0.63, 0.51, 0.33, 0.42, 0.49, 0.36, 0.5, 0.33, 0.28, 0.66, 0.31, 0.52, 0.5, 0.34, 0.0, 0.37, 0.25, 0.35, 0.6, 0.34, 0.18, 0.49, 0.42, 0.7, 0.66, 0.32, 0.34, 0.86, 0.47, 0.34, 0.51, 0.58, 0.25, 0.0, 0.4, 0.46, 0.33, 0.31, 0.5, 0.38, 0.59, 0.58, 0.39, 0.47, 0.5, 0.47, 0.4, 0.47, 0.35, 0.37, 0.22, 0.25, 0.32, 0.54, 0.41, 0.23, 0.38, 0.36, 0.54, 0.22, 0.4, 0.51, 0.4, 0.57, 0.53, 0.34, 0.47, 0.58, 0.61, 0.4, 0.4, 0.37, 0.47, 0.44, 0.32, 0.61, 0.42, 0.64, 0.5, 0.37, 0.64, 0.48, 0.25, 0.37, 0.44, 0.0, 0.36, 0.87, 0.37, 0.36, 0.52, 0.63, 0.49, 0.27, 0.29, 0.83, 0.39, 0.38, 0.32, 0.35, 0.51, 0.59, 0.66, 0.63, 0.46, 0.66, 0.45, 0.6, 0.44, 0.4, 0.36, 0.7, 0.54, 0.4, 0.54, 0.66, 0.56, 0.61, 0.32, 0.56, 0.21, 0.41, 0.75, 0.37, 0.45, 0.31, 0.1, 0.41, 0.37, 0.24, 0.42, 0.52, 0.34, 0.23, 0.37, 0.39, 0.41, 0.55, 0.58, 0.57, 0.44, 0.38, 0.39, 0.41, 0.35, 0.37, 0.38, 0.46, 0.32, 0.7, 0.55, 0.33, 0.33, 0.23, 0.63, 0.47, 0.54, 1.0, 0.46, 0.37, 0.3, 0.23, 0.62, 0.43, 0.25, 0.23, 0.27, 0.56, 0.29, 0.68, 0.31, 0.54, 0.33, 0.71, 0.34, 0.28, 0.37, 0.71, 0.51, 0.58, 0.44, 0.6, 0.1, 0.53, 0.76, 0.2, 0.58, 0.16, 1.0, 0.26, 0.31, 0.39, 0.54, 0.41, 0.76, 0.38, 0.61, 0.47, 0.55, 0.3, 0.35, 0.49, 0.72, 0.43, 0.61, 0.54, 0.57, 0.3, 0.81, 0.29, 0.54, 0.41, 0.4, 0.5, 0.62, 0.54, 0.62, 0.48, 0.4, 0.64, 0.58, 0.47, 0.32, 0.69, 0.66, 0.66, 0.66, 0.62, 0.57, 0.37, 0.5, 0.37, 0.35, 0.6, 0.52, 0.37, 0.0, 0.39, 0.0, 0.53, 0.21, 0.39, 0.3, 0.26, 0.05, 1.0, 0.43, 0.49, 0.43, 0.36, 0.2, 0.09, 0.4, 0.54, 0.48, 0.32, 0.34, 0.8, 0.0, 0.38, 0.54, 0.32, 0.75, 0.33, 0.39, 0.38, 0.33, 0.56, 0.12, 0.41, 0.35, 0.6, 0.48, 0.35, 0.55, 0.28, 0.46, 0.48, 0.33, 0.51, 0.16, 0.45, 0.27, 0.34, 1.0, 0.34, 0.53, 0.26, 0.4, 0.37, 0.55, 0.4, 0.57, 0.27, 0.36, 0.52, 0.13, 0.5, 0.37, 0.47, 0.35, 0.41, 0.4, 0.36, 0.42, 0.32, 0.5, 0.33, 0.43, 0.15, 0.32, 0.39, 0.34, 0.27, 0.44, 0.34, 0.2, 0.63, 0.34, 0.5, 0.63, 0.45, 0.41, 0.4, 0.35, 0.46, 0.31, 0.54, 0.55, 0.59, 0.88, 0.52, 0.69, 0.53, 0.47, 0.66, 0.37, 0.11, 0.31, 0.45, 0.63, 0.71, 0.24, 0.5, 0.33, 0.19, 0.41, 0.52, 0.63, 0.5, 0.5, 0.63, 0.5, 0.57, 0.28, 0.44, 0.57, 0.38, 0.28, 0.67, 0.46, 0.58, 0.75, 0.7, 0.33, 0.41, 0.29, 0.37, 0.46, 0.28, 0.5, 0.33, 0.33, 0.43, 0.3, 0.66, 0.21, 0.5, 0.45, 0.31, 0.38, 0.43, 0.45, 0.71, 0.34, 0.33, 0.3, 0.47, 0.37, 0.36, 0.46, 0.41, 0.44, 0.56, 0.7, 0.31, 0.76, 0.38, 0.3, 0.2, 0.6, 0.64, 0.63, 0.72, 0.53, 0.41, 0.5, 0.24, 0.4, 0.22, 0.37, 0.37, 0.42, 0.24, 0.43, 0.5, 0.47, 0.5, 0.5, 0.27, 0.66, 0.32, 0.74, 0.36, 0.43, 0.36, 0.35, 0.52, 1.0, 0.6, 0.61, 0.5, 0.38, 0.5, 0.49, 0.53, 0.4, 0.4, 0.25, 0.4, 0.33, 0.51, 0.6, 0.32, 0.46, 0.46, 0.51, 0.0, 0.31, 0.54, 0.52, 0.39, 0.45, 0.61, 0.62, 0.46, 0.28, 0.28, 0.25, 0.46, 0.39, 0.47, 0.51, 0.44, 0.4, 0.56, 0.58, 0.09, 0.38, 0.51, 0.62, 0.57, 0.44, 0.5, 0.39, 0.53, 0.4, 0.68, 0.56, 0.48, 0.54, 0.43, 0.48, 0.35, 0.35, 0.4, 0.69, 0.29, 0.37, 0.42, 0.5, 0.6, 0.28, 0.36, 0.37, 0.44, 0.2, 0.33, 0.0, 0.45, 0.41, 0.0, 0.62, 0.68, 0.55, 0.66, 0.22, 0.21, 0.34, 1.0, 0.48, 0.37, 0.66, 0.0, 0.36, 0.44, 0.6, 0.56, 0.37, 1.0, 0.62, 0.65, 0.4, 0.35, 0.26, 0.66, 0.7, 0.38, 0.6, 0.6, 0.45, 0.31, 0.41, 0.38, 0.56, 0.36, 0.15, 0.33, 0.58, 0.55, 0.58, 0.67, 0.42, 0.45, 0.53, 1.0, 0.55, 0.24, 0.41, 0.44, 0.18, 0.78, 0.6, 0.66, 0.38, 0.32, 0.39, 0.39, 0.68, 0.35, 0.61, 0.49, 0.0, 0.87, 0.31, 0.3, 0.31, 0.46, 0.56, 0.4, 0.64, 0.56, 0.54, 0.46, 0.51, 0.44, 0.32, 0.36, 0.57, 0.48, 0.33, 0.55, 0.45, 0.5, 0.36, 0.43, 0.46, 0.62, 0.31, 0.5, 0.51, 0.66, 0.45, 0.38, 0.35, 0.74, 0.41, 0.4, 0.29, 0.47, 0.17, 0.56, 0.88, 0.39, 0.19, 0.45, 0.4, 0.4, 0.28, 0.47, 0.5, 0.16, 0.21, 0.37, 0.32, 0.47, 0.56, 0.16, 0.57, 0.57, 0.54, 0.9, 0.64, 0.58, 0.48, 0.83, 0.25, 0.11, 0.26, 0.0, 0.53, 0.37, 0.77, 0.33, 0.5, 0.55, 0.73, 0.54, 0.08, 0.29, 0.32, 0.48, 0.66, 0.62, 0.28, 0.52, 0.38, 0.34, 0.53, 0.33, 0.29, 0.44, 0.4, 0.52, 0.44, 0.51, 0.35, 0.45, 0.41, 0.28, 0.39, 0.4, 0.57, 0.43, 0.53, 0.47, 0.5, 0.5, 0.7, 0.49, 0.5, 0.58, 0.1, 0.57, 0.38, 0.69, 0.2, 0.56, 0.32, 0.46, 0.5, 0.52, 0.62, 0.56, 0.2, 0.17, 0.45, 0.54, 0.41, 0.22, 0.3, 0.27, 0.71, 0.37, 0.3, 0.21, 0.68, 0.11, 0.5, 0.56, 0.24, 0.31, 0.64, 0.31, 0.58, 0.23, 0.5, 0.55, 0.57, 0.42, 0.33, 0.38, 0.6, 0.2, 0.47, 0.55, 0.56, 0.57, 0.64, 0.52, 0.63, 0.41, 0.44, 0.47, 0.45, 0.42, 0.31, 0.68, 0.5, 0.14, 0.53, 0.24, 0.31, 0.43, 0.83, 0.73, 0.47, 0.52, 0.56, 0.0, 0.76, 0.26, 0.44, 0.37, 0.3, 0.41, 0.39, 0.52, 0.76, 0.51, 0.33, 0.61, 0.63, 0.38, 0.62, 0.43, 0.26, 0.31, 0.38, 0.36, 0.41, 0.57, 0.56, 0.46, 0.66, 0.53, 0.42, 0.4, 0.32, 0.59, 0.42, 0.85, 0.17, 0.32, 0.27, 0.6, 0.31, 0.57, 0.65, 0.55, 0.38, 0.43, 0.56, 0.51, 0.39, 0.51, 0.7, 0.4, 0.58, 0.62, 0.59, 0.62, 0.47, 0.57, 0.42, 0.35, 0.41, 0.29, 0.42, 0.3, 0.29, 0.0, 0.47, 0.63, 0.68, 0.32, 0.31, 0.16, 0.44, 0.46, 0.29, 0.6, 0.3, 0.61, 0.63, 0.49, 0.51, 0.25, 1.0, 0.59, 0.17, 0.45, 0.65, 0.42, 0.61, 0.54, 0.46, 0.49, 0.19, 0.45, 0.46, 0.38, 0.44, 0.7, 0.38, 0.35, 0.44, 0.4, 0.66, 0.59, 0.89, 0.66, 0.67, 0.37, 0.46, 0.33, 0.33, 0.6, 0.45, 0.44, 0.53, 0.33, 0.33, 0.67, 0.39, 0.5, 0.36, 0.26, 0.0, 0.24, 0.43, 0.25, 0.0, 0.49, 0.68, 0.42, 0.18, 0.6, 0.31, 0.67, 0.66, 0.64, 0.65, 0.5, 0.32, 0.48, 1.0, 1.0, 0.27, 0.36, 0.32, 0.25, 0.33, 0.72, 0.31, 0.37, 0.38, 0.53, 0.38, 0.44, 0.75, 0.37, 0.72, 0.48, 0.55, 0.21, 0.33, 0.66, 0.35, 0.37, 0.33, 0.4, 0.75, 0.32, 0.59, 0.61, 0.52, 0.58, 0.71, 0.64, 0.32, 0.62, 0.35, 0.02, 0.66, 0.61, 0.31, 0.12, 0.37, 0.36, 0.44, 0.34, 0.43, 0.35, 0.25, 0.66, 0.56, 0.5, 0.38, 0.0, 0.48, 0.64, 0.41, 0.62, 0.4, 0.26, 0.56, 0.48, 0.43, 0.45, 0.53, 0.45, 0.12, 0.24, 0.14, 0.6, 0.5, 0.2, 0.23, 0.46, 0.37, 0.0, 0.68, 0.25, 0.34, 0.44, 0.49, 0.38, 0.52, 0.61, 0.4, 0.49, 0.68, 0.52, 0.27, 0.52, 0.69, 0.5, 0.46, 0.33, 0.56, 0.6, 0.17, 0.26, 0.54, 0.0, 0.33, 0.6, 0.53, 0.61, 0.96, 0.93, 1.0, 0.55, 0.51, 0.52, 0.36, 0.51, 0.34, 0.66, 0.55, 0.47, 0.57, 1.0, 0.75, 0.46, 0.35, 0.41, 0.62, 0.34, 0.38, 0.6, 0.45, 0.44, 0.42, 0.51, 0.31, 0.31, 0.25, 0.58, 0.65, 0.47, 0.74, 0.71, 0.64, 0.33, 0.48, 0.42, 0.37, 0.34, 0.34, 0.49, 0.44, 0.61, 0.67, 0.46, 0.5, 0.36, 0.38, 0.41, 0.3, 0.7, 0.56, 0.65, 0.5, 0.47, 0.3, 0.34, 0.61, 0.52, 0.55, 0.92, 0.35, 0.29, 0.92, 0.46, 0.79, 0.75, 0.47, 0.48, 0.5, 0.8, 0.36, 0.39, 0.28, 0.43, 0.25, 0.43, 0.33, 0.65, 0.0, 0.62, 0.38, 0.58, 0.44, 0.42, 0.48, 0.33, 0.45, 0.75, 0.52, 0.59, 0.0, 0.5, 0.36, 0.0, 0.28, 0.54, 0.62, 0.12, 0.53, 0.48, 0.09, 0.26, 0.2, 0.44, 0.67, 0.54, 0.49, 0.41, 0.59, 0.35, 0.48, 0.42, 0.5, 0.28, 0.43, 0.52, 0.55, 0.64, 0.5, 0.27, 0.36, 0.39, 0.3, 0.53, 0.54, 0.58, 0.52, 0.59, 0.34, 0.17, 0.55, 0.45, 0.83, 0.71, 0.72, 0.42, 0.1, 0.58, 0.53, 0.34, 0.5, 0.4, 0.48, 0.57, 0.28, 0.5, 0.76, 0.46, 0.25, 0.34, 0.44, 0.73, 0.26, 0.5, 0.35, 0.44, 0.34, 0.11, 0.41, 0.34, 0.5, 0.66, 0.8, 0.65, 0.38, 0.3, 0.36, 0.16, 0.58, 0.32, 0.52, 0.26, 0.38, 0.48, 0.49, 0.37, 0.35, 0.7, 0.54, 0.71, 0.07, 0.3, 0.38, 0.64, 0.34, 0.26, 0.5, 0.58, 0.44, 0.57, 0.58, 0.56, 0.7, 0.55, 0.32, 0.42, 0.32, 0.38, 0.6, 0.27, 0.52, 0.44, 0.42, 0.34, 0.25, 0.31, 0.5, 0.37, 0.47, 0.45, 0.33, 0.76, 0.28, 0.42, 0.37, 0.58, 0.49, 0.48, 0.0, 0.35, 0.64, 0.38, 0.48, 0.33, 0.44, 0.48, 0.34, 0.37, 0.37, 0.27, 0.37, 0.38, 0.4, 0.08, 0.33, 0.39, 0.54, 0.52, 0.62, 0.42, 0.45, 0.18, 0.53, 0.35, 0.36, 0.34, 0.42, 0.5, 0.36, 0.23, 0.37, 0.54, 0.57, 0.43, 0.43, 0.41, 0.43, 0.59, 0.52, 0.46, 0.27, 0.21, 0.29, 0.57, 0.54, 0.37, 0.36, 0.39, 0.52, 0.53, 0.59, 0.42, 0.7, 0.43, 0.36, 0.47, 0.52, 0.44, 0.33, 0.47, 0.44, 0.34, 0.43, 0.31, 0.88, 0.32, 0.41, 0.47, 0.07, 0.33, 0.0, 0.51, 0.43, 0.41, 0.55, 0.47, 0.3, 0.45, 0.28, 0.5, 0.47, 0.57, 0.87, 0.93, 0.75, 0.22, 0.44, 0.32, 0.26, 0.53, 0.46, 0.3, 0.57, 0.39, 0.4, 0.46, 0.22, 0.25, 0.4, 0.38, 0.31, 0.26, 0.26, 0.31, 0.46, 0.06, 0.26, 0.44, 0.41, 0.4, 0.18, 0.52, 0.57, 0.29, 0.44, 0.32, 0.61, 0.36, 0.32, 0.44, 0.6, 0.32, 0.47, 0.32, 0.38, 0.5, 0.45, 0.24, 0.6, 0.69, 0.51, 0.51, 0.59, 0.56, 0.51, 0.41, 0.22, 0.5, 0.68, 0.53, 0.74, 0.39, 0.42, 0.28, 0.43, 0.42, 0.19, 0.36, 0.52, 0.68, 0.58, 0.23, 0.21, 0.42, 0.57, 0.16, 0.31, 0.39, 0.41, 0.5, 0.65, 0.13, 0.33, 0.11, 0.47, 0.55, 0.26, 0.41, 0.44, 0.0, 0.39, 0.27, 0.31, 1.0, 0.4, 0.32, 0.5, 0.13, 0.44, 0.27, 0.61, 0.36, 0.33, 0.26, 0.42, 0.51, 0.34, 0.42, 0.43, 0.5, 0.42, 0.57, 0.51, 0.65, 0.3, 0.37, 0.47, 0.54, 0.42, 0.28, 0.26, 0.36, 0.27, 0.0, 0.36, 0.56, 0.58, 0.44, 0.21, 0.18, 0.53, 0.42, 0.5, 0.67, 0.5, 0.73, 0.49, 0.31, 0.22, 0.41, 0.33, 0.43, 0.5, 0.5, 0.63, 0.51, 0.25, 0.37, 0.17, 0.25, 0.3, 0.43, 0.36, 0.23, 0.31, 0.63, 0.62, 0.4, 0.72, 0.61, 0.22, 0.28, 0.67, 0.57, 0.31, 0.43, 0.65, 0.5, 0.43, 0.21, 0.12, 0.39, 0.41, 0.22, 0.66, 0.38, 0.57, 0.66, 0.93, 0.36, 0.5, 0.21, 0.39, 0.33, 0.5, 0.59, 0.0, 0.58, 0.53, 0.43, 0.38, 0.35, 0.29, 0.83, 0.48, 0.31, 0.27, 0.3, 0.69, 0.37, 0.28, 0.45, 0.36, 0.39, 0.52, 0.52, 0.2, 0.55, 0.54, 0.41, 0.42, 0.32, 0.61, 0.42, 0.37, 0.5, 0.2, 0.47, 1.0, 0.4, 0.36, 0.33, 0.28, 0.36, 0.26, 0.26, 0.34, 0.66, 0.25, 0.44, 0.33, 0.81, 0.65, 0.38, 0.23, 0.59, 0.45, 0.64, 0.6, 0.6, 0.3, 0.71, 0.54, 0.27, 0.56, 0.35, 0.34, 0.0, 0.68, 0.31, 0.64, 0.32, 0.27, 0.6, 0.26, 0.33, 0.3, 0.42, 0.32, 0.21, 0.69, 0.45, 0.62, 0.74, 0.3, 0.55, 0.56, 0.34, 0.56, 0.55, 0.0, 0.51, 0.53, 0.62, 0.57, 0.56, 0.44, 0.42, 0.19, 0.2, 0.75, 0.69, 0.51, 0.33]\n"
     ]
    }
   ],
   "source": [
    "#reformat redCorner_sig_str_percentage to float\n",
    "for index, row in df.iterrows():\n",
    "    redCorner_sig = row['redCorner_sig_str_percentage']\n",
    "    listsig = redCorner_sig.split('%')\n",
    "    reformatted = float(listsig[0])/100.00\n",
    "    df.loc[index, 'redCorner_sig_str_percentage'] = reformatted\n",
    "\n",
    "print(df['redCorner_sig_str_percentage'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix divide by zero errors\n",
    "df['blueCorner_sig_str_percentage'].fillna('0%', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#confirm no rows with nan sig_strike_accuracy\n",
    "nan_rows_count = df['blueCorner_sig_str_percentage'].isna().sum()\n",
    "print(nan_rows_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31, 0.35, 0.34, 0.64, 0.58, 0.36, 0.41, 0.38, 0.49, 0.7, 0.53, 0.38, 0.41, 0.57, 0.43, 0.57, 0.28, 0.27, 0.56, 0.24, 0.4, 0.27, 0.41, 0.4, 0.35, 0.4, 0.5, 0.56, 0.51, 0.45, 0.54, 0.51, 0.53, 0.6, 0.59, 0.4, 0.59, 0.56, 0.5, 0.43, 0.63, 0.64, 0.42, 0.48, 0.67, 0.33, 0.32, 0.7, 0.6, 0.42, 0.8, 0.46, 0.85, 0.47, 0.38, 0.43, 0.37, 0.33, 0.11, 0.47, 0.31, 0.45, 0.49, 0.65, 1.0, 0.22, 0.42, 0.3, 0.49, 0.4, 0.6, 0.6, 0.73, 0.54, 0.23, 0.45, 0.68, 0.5, 0.34, 0.23, 0.27, 0.52, 0.52, 0.5, 0.16, 0.45, 0.46, 0.2, 0.58, 0.46, 0.4, 0.5, 0.33, 0.37, 0.56, 0.45, 0.61, 0.56, 0.34, 0.46, 0.59, 0.36, 0.41, 0.38, 0.5, 0.56, 0.57, 0.54, 0.25, 0.6, 0.57, 0.57, 0.34, 0.66, 0.54, 0.4, 0.51, 0.37, 0.55, 0.29, 0.38, 0.48, 0.33, 0.44, 0.5, 0.46, 0.48, 1.0, 0.21, 0.66, 0.4, 0.28, 0.49, 0.54, 0.58, 0.55, 0.0, 0.45, 0.61, 0.5, 0.73, 0.64, 0.5, 0.4, 0.33, 0.52, 0.47, 0.47, 0.55, 0.47, 0.52, 0.49, 0.66, 0.48, 0.7, 0.46, 0.52, 0.35, 0.59, 0.23, 0.39, 0.52, 0.5, 0.0, 0.75, 0.52, 0.61, 0.37, 0.46, 0.45, 0.66, 0.82, 0.53, 0.41, 0.36, 0.38, 0.57, 0.56, 0.55, 0.47, 0.4, 0.59, 0.44, 0.45, 0.34, 0.57, 1.0, 0.63, 0.4, 0.47, 0.42, 0.51, 0.6, 0.46, 0.5, 0.5, 0.35, 0.51, 0.75, 0.57, 0.42, 0.32, 0.42, 0.66, 0.65, 0.43, 0.63, 0.37, 0.44, 0.5, 0.33, 0.41, 0.36, 0.42, 0.37, 0.46, 0.52, 0.44, 0.45, 0.66, 0.72, 0.53, 0.61, 0.54, 0.56, 0.36, 0.33, 0.42, 0.32, 0.39, 0.64, 0.36, 0.6, 0.55, 0.58, 0.53, 0.43, 0.47, 0.68, 0.46, 0.46, 0.31, 0.54, 0.5, 0.58, 0.59, 0.33, 0.53, 0.54, 0.71, 0.81, 0.53, 0.35, 0.39, 0.51, 0.51, 0.49, 0.51, 0.37, 0.54, 0.26, 0.56, 0.48, 0.54, 0.54, 0.76, 0.7, 0.47, 0.41, 0.34, 0.06, 0.54, 0.32, 0.5, 0.4, 0.26, 0.43, 0.35, 0.5, 0.52, 0.49, 0.48, 0.32, 0.48, 0.58, 0.38, 0.53, 0.36, 0.29, 0.27, 0.38, 0.51, 0.48, 0.65, 0.42, 0.42, 0.5, 0.4, 0.32, 0.42, 0.44, 0.0, 0.42, 0.36, 0.33, 0.54, 0.36, 0.67, 0.66, 0.54, 0.5, 0.33, 0.56, 0.46, 0.41, 0.58, 0.25, 0.4, 0.57, 0.52, 0.32, 0.5, 0.45, 0.18, 0.47, 0.36, 0.52, 0.32, 0.15, 0.48, 0.43, 0.28, 0.38, 0.36, 0.42, 0.5, 0.58, 0.45, 0.23, 0.64, 0.65, 0.42, 0.5, 0.45, 0.44, 0.49, 0.37, 0.61, 0.38, 0.4, 0.48, 0.45, 0.51, 0.37, 0.48, 0.36, 0.24, 0.39, 0.57, 0.51, 0.45, 0.51, 0.35, 0.44, 0.53, 0.37, 0.34, 0.54, 0.47, 0.59, 0.38, 0.45, 0.29, 1.0, 0.63, 0.37, 0.54, 0.0, 0.35, 0.27, 0.41, 0.52, 0.38, 0.78, 0.67, 0.5, 0.43, 0.62, 0.47, 0.42, 0.29, 0.5, 0.48, 0.42, 0.33, 0.43, 0.41, 0.44, 0.36, 0.54, 0.34, 0.43, 0.69, 0.6, 0.54, 0.34, 0.54, 0.64, 0.64, 0.0, 0.62, 0.58, 0.68, 0.5, 0.74, 0.4, 0.5, 0.6, 0.46, 0.34, 0.4, 0.46, 0.57, 0.4, 0.6, 0.38, 0.5, 0.22, 0.53, 0.57, 0.6, 0.56, 0.5, 0.52, 0.27, 0.75, 1.0, 0.57, 0.63, 0.49, 0.42, 0.38, 0.75, 0.41, 0.38, 0.4, 0.4, 0.58, 0.42, 0.57, 0.68, 0.56, 0.17, 0.41, 0.62, 0.71, 0.42, 0.54, 0.58, 0.55, 0.44, 0.28, 0.59, 0.61, 0.43, 0.38, 0.7, 0.51, 0.46, 0.49, 0.35, 0.25, 0.49, 0.47, 0.46, 0.22, 0.4, 0.66, 0.54, 0.51, 0.75, 0.33, 0.42, 0.62, 0.69, 0.43, 0.53, 0.59, 0.46, 0.71, 0.5, 0.52, 0.27, 0.33, 0.41, 0.3, 0.48, 1.0, 0.54, 0.28, 0.55, 0.63, 0.39, 0.38, 0.22, 0.45, 0.37, 0.42, 0.53, 0.19, 0.48, 0.4, 0.32, 0.4, 0.49, 0.88, 0.46, 0.49, 0.5, 0.47, 0.49, 0.37, 0.44, 0.55, 0.31, 0.46, 0.44, 0.23, 0.32, 0.28, 0.37, 0.59, 0.27, 0.52, 0.65, 0.32, 0.5, 0.33, 0.48, 0.43, 0.44, 0.41, 0.46, 0.33, 0.66, 0.25, 0.4, 0.38, 0.32, 0.38, 0.21, 0.36, 0.42, 0.42, 0.87, 0.57, 0.27, 0.31, 0.36, 0.22, 0.36, 0.22, 0.63, 0.58, 0.61, 0.43, 0.32, 0.72, 0.39, 0.71, 0.38, 0.6, 0.57, 0.45, 0.6, 0.28, 0.41, 0.61, 0.51, 0.4, 0.29, 0.48, 0.53, 0.38, 0.41, 0.53, 0.26, 0.53, 0.2, 0.66, 0.62, 0.16, 0.66, 0.6, 0.18, 0.46, 0.22, 0.0, 0.5, 0.51, 0.39, 0.26, 0.38, 0.31, 0.36, 0.65, 0.62, 0.76, 1.0, 0.63, 0.56, 0.2, 0.45, 0.54, 0.56, 0.53, 0.47, 0.26, 0.31, 0.38, 0.6, 0.53, 0.38, 0.34, 0.5, 0.56, 0.26, 0.34, 0.43, 0.35, 0.62, 0.6, 0.54, 0.25, 0.66, 0.52, 0.36, 0.42, 0.59, 0.33, 0.45, 0.27, 0.24, 0.34, 0.57, 0.5, 0.47, 0.59, 0.63, 0.22, 0.28, 0.65, 0.85, 0.58, 0.62, 0.42, 0.66, 0.56, 0.46, 0.52, 0.43, 0.45, 0.39, 0.66, 0.64, 0.5, 0.5, 0.49, 0.47, 0.4, 0.44, 0.65, 0.0, 0.53, 0.52, 0.53, 0.52, 0.35, 0.34, 0.51, 0.6, 0.49, 0.77, 0.58, 0.56, 0.48, 0.5, 0.5, 0.64, 0.71, 0.44, 0.44, 0.48, 0.5, 0.5, 0.28, 0.42, 0.32, 0.37, 0.49, 0.42, 0.42, 1.0, 0.37, 0.38, 0.38, 0.29, 0.48, 0.14, 0.48, 0.0, 0.37, 0.46, 0.28, 0.38, 0.4, 0.3, 0.43, 0.51, 0.61, 0.71, 0.53, 0.29, 0.55, 0.57, 0.3, 0.62, 0.44, 0.56, 0.38, 0.58, 0.57, 0.47, 0.5, 0.55, 0.35, 0.25, 0.34, 0.34, 0.54, 0.5, 0.5, 0.56, 0.55, 0.72, 0.53, 0.47, 0.46, 0.62, 0.71, 0.62, 0.67, 0.6, 0.58, 0.43, 0.46, 0.68, 0.68, 0.54, 0.51, 0.45, 0.51, 0.4, 0.47, 0.73, 0.25, 0.45, 0.32, 0.2, 0.54, 0.56, 0.42, 0.4, 0.36, 0.34, 0.3, 0.33, 0.45, 0.52, 0.75, 0.57, 0.49, 0.5, 0.4, 0.46, 0.36, 0.37, 0.58, 0.49, 0.39, 0.42, 0.42, 0.46, 0.42, 0.55, 0.44, 0.36, 0.58, 0.48, 0.38, 0.42, 0.44, 0.45, 0.45, 0.32, 0.37, 0.36, 0.35, 0.53, 0.44, 0.41, 0.36, 0.42, 0.57, 0.58, 0.51, 0.36, 0.41, 0.58, 0.75, 0.24, 0.56, 0.66, 0.2, 0.5, 0.48, 0.8, 0.43, 0.0, 0.45, 0.69, 0.4, 0.58, 0.56, 0.47, 0.54, 0.48, 0.49, 0.51, 0.6, 0.75, 0.32, 0.63, 0.41, 0.5, 0.28, 0.61, 0.53, 0.49, 0.5, 0.48, 0.66, 0.6, 0.47, 0.41, 0.46, 0.45, 0.25, 0.59, 0.46, 0.25, 0.47, 0.08, 0.42, 0.42, 0.69, 0.55, 0.54, 0.46, 0.49, 0.56, 0.26, 0.4, 0.6, 0.14, 0.48, 0.42, 0.28, 0.43, 0.67, 0.4, 0.59, 0.63, 0.37, 0.49, 0.58, 0.58, 0.43, 0.57, 0.55, 0.3, 0.34, 0.63, 0.74, 0.41, 0.44, 0.41, 0.36, 1.0, 0.57, 0.64, 0.36, 0.62, 0.8, 0.51, 0.48, 0.46, 0.69, 0.78, 0.54, 0.28, 0.47, 0.46, 0.67, 0.45, 0.36, 0.64, 0.5, 0.54, 0.32, 0.6, 0.36, 0.42, 0.31, 0.53, 0.38, 0.41, 0.23, 0.45, 0.51, 0.51, 0.27, 0.38, 0.36, 0.17, 0.63, 0.48, 0.24, 0.42, 0.58, 0.29, 0.58, 0.51, 0.5, 1.0, 0.47, 0.3, 0.51, 0.72, 0.37, 0.56, 0.8, 0.33, 0.52, 0.46, 0.46, 0.45, 0.41, 0.39, 0.43, 0.49, 0.31, 0.28, 0.6, 0.34, 0.52, 0.58, 0.15, 0.5, 0.29, 0.36, 0.5, 0.53, 0.47, 0.38, 0.57, 0.47, 0.43, 0.5, 0.27, 0.3, 0.47, 0.53, 0.47, 0.45, 0.29, 0.35, 0.45, 0.14, 0.54, 0.61, 0.52, 0.4, 0.5, 0.35, 0.68, 0.42, 0.34, 0.53, 0.92, 0.41, 0.53, 0.4, 0.5, 0.35, 0.42, 0.54, 0.54, 0.65, 0.41, 0.69, 0.73, 0.3, 0.51, 0.4, 0.35, 0.49, 0.59, 0.47, 0.38, 0.36, 0.44, 0.6, 0.47, 0.6, 0.76, 0.43, 0.47, 0.41, 0.5, 0.5, 0.44, 0.63, 0.66, 0.57, 0.59, 0.19, 1.0, 0.53, 0.51, 0.4, 0.46, 0.5, 0.54, 0.28, 0.37, 0.53, 0.47, 0.36, 0.41, 0.47, 0.33, 0.26, 0.71, 0.29, 0.28, 0.53, 0.37, 0.46, 0.0, 0.47, 0.41, 0.6, 0.48, 1.0, 0.54, 0.55, 0.21, 0.37, 0.54, 0.34, 0.32, 0.28, 0.26, 0.48, 0.37, 0.48, 0.0, 0.36, 0.29, 0.54, 0.4, 0.47, 0.73, 0.72, 0.38, 0.48, 0.5, 0.45, 0.66, 0.51, 0.55, 0.73, 0.52, 0.69, 0.36, 0.4, 0.36, 0.74, 0.26, 0.4, 0.38, 0.43, 0.29, 0.46, 0.52, 0.25, 0.39, 0.58, 0.57, 0.64, 0.63, 0.67, 0.56, 0.59, 0.25, 0.38, 0.61, 0.55, 0.48, 0.62, 0.71, 0.5, 0.32, 0.54, 0.52, 0.59, 0.56, 0.4, 0.54, 0.64, 0.6, 0.34, 0.72, 0.62, 0.27, 0.55, 0.57, 0.5, 0.3, 0.8, 0.54, 0.66, 0.35, 0.47, 0.5, 0.57, 0.41, 0.69, 0.6, 0.51, 0.5, 0.43, 0.83, 0.35, 0.43, 0.56, 0.4, 0.5, 0.43, 0.58, 0.11, 0.44, 0.32, 0.38, 0.29, 0.47, 0.54, 0.57, 0.42, 0.62, 0.46, 0.53, 0.6, 0.63, 0.46, 0.53, 0.43, 0.64, 0.66, 0.58, 0.52, 0.65, 0.4, 0.74, 0.59, 0.75, 0.42, 0.53, 0.76, 0.35, 0.46, 0.32, 0.4, 0.2, 0.41, 0.68, 0.4, 0.51, 0.43, 0.33, 0.55, 0.71, 0.28, 0.44, 0.58, 0.53, 0.5, 0.52, 0.29, 0.45, 0.36, 0.6, 0.38, 0.66, 0.61, 0.33, 0.52, 0.49, 0.73, 0.53, 0.18, 0.66, 0.46, 0.45, 0.8, 0.33, 0.33, 0.54, 0.45, 0.56, 0.5, 0.71, 0.45, 0.57, 0.12, 0.0, 0.54, 0.33, 0.91, 0.66, 0.31, 0.22, 0.51, 0.32, 0.53, 0.36, 0.57, 0.46, 0.38, 0.26, 0.1, 0.63, 0.22, 0.4, 0.55, 0.33, 0.3, 0.5, 0.36, 0.51, 0.61, 0.41, 0.55, 0.75, 0.35, 0.56, 0.49, 0.7, 0.48, 0.56, 0.4, 0.0, 1.0, 0.51, 0.49, 0.48, 0.33, 0.33, 0.5, 0.57, 0.76, 0.39, 0.18, 0.5, 0.45, 0.58, 0.48, 0.38, 0.31, 0.57, 0.28, 0.48, 0.41, 0.51, 0.48, 0.47, 0.4, 0.67, 0.45, 0.41, 0.16, 0.38, 0.61, 0.48, 0.61, 0.44, 0.51, 0.57, 0.58, 0.63, 0.37, 0.4, 0.21, 0.34, 0.57, 0.52, 0.39, 0.54, 0.57, 0.6, 0.28, 0.37, 0.6, 0.35, 0.37, 0.67, 0.28, 0.77, 0.39, 0.48, 0.48, 0.0, 0.44, 0.66, 0.48, 0.54, 0.2, 0.5, 0.4, 0.47, 0.6, 0.59, 0.4, 0.53, 0.37, 0.54, 0.4, 0.38, 0.5, 0.63, 0.4, 0.47, 0.51, 0.72, 0.47, 0.58, 0.59, 0.42, 0.5, 0.59, 0.69, 0.48, 0.63, 0.39, 0.69, 0.78, 0.46, 0.7, 0.45, 0.64, 0.52, 1.0, 0.51, 0.0, 0.48, 0.31, 0.55, 0.51, 0.36, 0.48, 0.38, 0.5, 0.47, 0.5, 0.5, 0.43, 0.39, 0.43, 0.66, 0.44, 0.55, 0.39, 0.44, 0.58, 0.35, 0.31, 0.56, 0.62, 0.49, 0.33, 0.77, 0.46, 0.64, 0.37, 0.66, 0.58, 0.59, 0.39, 0.52, 1.0, 0.49, 0.0, 0.47, 0.8, 0.69, 0.5, 0.33, 0.53, 0.53, 0.51, 0.36, 0.49, 0.26, 0.33, 0.45, 0.36, 0.58, 0.48, 0.3, 0.59, 0.38, 0.54, 0.51, 0.34, 0.42, 0.52, 0.61, 0.45, 0.6, 0.43, 0.1, 0.5, 0.55, 0.5, 0.32, 0.3, 0.62, 0.38, 0.61, 0.58, 0.39, 0.52, 0.62, 0.41, 0.37, 0.65, 0.65, 0.23, 0.66, 0.57, 0.48, 0.55, 0.53, 0.53, 0.4, 0.68, 0.67, 0.45, 0.56, 0.39, 0.56, 0.38, 0.49, 0.69, 0.55, 0.44, 0.42, 0.5, 0.52, 0.39, 0.48, 0.37, 0.51, 0.45, 0.62, 0.4, 0.45, 0.58, 0.47, 0.37, 0.16, 0.6, 0.4, 0.2, 0.22, 0.54, 0.32, 0.38, 0.47, 0.53, 0.46, 0.42, 0.27, 0.7, 0.58, 0.66, 0.44, 0.54, 0.4, 0.44, 0.4, 0.58, 0.37, 0.3, 0.41, 1.0, 0.47, 0.32, 0.42, 0.45, 0.45, 0.58, 0.8, 0.7, 0.67, 0.54, 0.68, 0.62, 0.33, 0.23, 0.33, 0.75, 0.58, 0.37, 0.4, 0.52, 0.8, 0.67, 0.39, 0.43, 0.42, 0.37, 0.43, 0.49, 0.56, 0.5, 0.49, 0.25, 0.33, 0.51, 0.51, 0.58, 0.56, 0.27, 0.56, 0.47, 0.23, 0.3, 0.36, 0.69, 0.55, 0.43, 0.4, 0.59, 0.47, 0.62, 0.5, 0.83, 0.44, 0.52, 0.37, 0.12, 0.59, 0.26, 0.36, 0.63, 0.39, 0.4, 0.57, 0.53, 0.35, 0.33, 0.48, 0.4, 0.44, 0.33, 0.16, 0.52, 0.45, 0.58, 0.6, 0.39, 0.33, 0.36, 0.52, 0.3, 0.45, 0.52, 0.0, 0.41, 0.41, 0.49, 0.33, 0.2, 0.52, 0.4, 0.51, 0.59, 0.49, 0.57, 0.59, 0.57, 1.0, 0.57, 0.54, 0.43, 0.11, 0.6, 0.36, 0.51, 0.46, 0.55, 0.36, 0.27, 0.48, 0.27, 0.4, 0.65, 0.46, 0.5, 0.8, 0.41, 0.58, 0.51, 0.41, 0.46, 0.36, 0.32, 0.63, 0.47, 0.19, 0.57, 0.18, 0.43, 0.62, 0.6, 0.58, 0.42, 0.49, 0.62, 0.38, 0.54, 0.42, 0.41, 0.43, 0.54, 0.32, 0.45, 0.44, 0.46, 0.37, 0.31, 0.25, 0.5, 0.29, 0.54, 1.0, 0.34, 0.64, 0.53, 0.42, 0.48, 0.54, 0.59, 0.71, 0.35, 0.4, 0.48, 0.32, 0.54, 0.59, 0.56, 0.52, 0.36, 0.56, 0.27, 0.47, 0.42, 0.4, 0.44, 0.46, 0.28, 0.55, 0.42, 0.4, 0.43, 0.42, 0.47, 0.51, 0.47, 0.52, 0.49, 0.44, 0.73, 0.42, 0.36, 0.45, 0.45, 0.56, 0.58, 0.63, 0.32, 0.55, 0.46, 0.35, 0.12, 0.64, 0.56, 0.53, 0.42, 0.52, 0.8, 0.72, 0.35, 0.46, 0.21, 0.4, 0.23, 0.41, 0.47, 0.45, 0.26, 0.52, 0.44, 0.54, 0.18, 0.47, 0.61, 0.44, 0.81, 0.48, 0.5, 0.44, 0.43, 0.38, 0.37, 0.0, 0.26, 0.34, 0.44, 0.54, 0.41, 0.58, 0.45, 0.51, 0.58, 0.5, 0.8, 0.56, 0.63, 0.55, 0.62, 0.42, 0.41, 0.47, 0.53, 0.72, 0.34, 0.53, 0.42, 0.38, 0.56, 0.66, 0.56, 0.18, 0.35, 0.54, 0.38, 0.54, 0.67, 0.53, 0.59, 0.59, 0.5, 0.66, 0.5, 0.51, 0.5, 0.63, 0.56, 0.38, 0.37, 0.4, 0.53, 0.75, 0.29, 0.45, 0.49, 0.46, 0.47, 0.54, 0.54, 0.8, 0.39, 0.4, 0.35, 0.41, 0.61, 0.54, 0.54, 0.45, 0.61, 0.35, 0.83, 0.63, 0.47, 0.58, 0.54, 0.64, 0.75, 0.35, 0.47, 0.5, 0.0, 0.5, 0.45, 0.47, 0.49, 0.48, 0.6, 0.36, 0.45, 0.33, 0.36, 0.54, 0.47, 0.56, 0.3, 0.3, 0.55, 1.0, 0.43, 0.53, 0.35, 0.29, 0.36, 0.16, 0.23, 0.56, 0.3, 1.0, 0.48, 0.4, 0.42, 0.5, 0.4, 0.38, 0.41, 0.65, 0.59, 0.52, 0.64, 0.25, 0.63, 0.0, 0.76, 0.57, 0.46, 0.65, 0.33, 0.31, 0.28, 0.38, 0.63, 0.42, 0.3, 0.78, 0.75, 0.6, 0.61, 0.61, 0.34, 0.73, 0.65, 0.72, 0.33, 0.54, 0.41, 0.46, 0.4, 0.26, 0.41, 0.64, 0.33, 0.71, 0.54, 0.48, 0.61, 0.66, 0.55, 0.53, 0.53, 1.0, 0.4, 0.64, 0.62, 0.48, 0.28, 0.66, 0.43, 0.7, 0.61, 0.45, 0.3, 0.28, 0.33, 0.38, 0.47, 0.48, 0.44, 0.24, 1.0, 0.57, 0.43, 0.3, 0.36, 0.25, 0.42, 0.22, 0.51, 0.23, 0.37, 0.23, 0.53, 0.47, 0.75, 0.42, 0.52, 0.38, 0.49, 0.58, 0.52, 0.33, 0.52, 0.47, 0.56, 0.43, 0.81, 0.54, 0.39, 0.64, 0.72, 0.72, 0.49, 0.65, 0.35, 0.53, 0.65, 0.47, 1.0, 0.73, 0.46, 0.6, 0.47, 0.37, 0.55, 0.49, 0.53, 0.42, 0.33, 1.0, 0.4, 0.3, 0.45, 0.33, 0.25, 0.55, 0.73, 0.58, 0.56, 0.55, 0.43, 0.0, 0.47, 0.42, 0.4, 0.66, 0.3, 0.5, 0.32, 0.38, 0.57, 0.34, 0.47, 0.5, 0.52, 0.56, 0.5, 0.64, 0.58, 0.41, 0.67, 0.48, 0.53, 0.52, 0.73, 0.57, 0.24, 0.5, 0.43, 0.34, 0.62, 0.46, 0.36, 0.42, 0.48, 0.37, 0.62, 1.0, 0.35, 0.55, 0.46, 0.19, 0.64, 0.32, 0.24, 0.64, 0.59, 0.27, 0.63, 0.3, 0.3, 0.64, 0.49, 0.52, 0.35, 0.51, 1.0, 0.38, 0.65, 0.41, 0.59, 0.35, 0.43, 0.51, 0.35, 0.52, 0.44, 0.42, 0.43, 0.28, 0.51, 0.44, 0.25, 0.39, 0.13, 0.25, 0.3, 0.37, 0.26, 0.31, 0.37, 0.37, 0.44, 0.29, 0.36, 0.63, 0.46, 0.37, 0.61, 0.42, 0.26, 0.2, 0.46, 0.46, 0.54, 0.46, 0.37, 0.48, 0.48, 0.69, 0.56, 0.0, 0.72, 0.4, 0.48, 0.0, 0.53, 0.6, 0.51, 0.46, 0.46, 0.66, 0.4, 0.0, 0.66, 0.46, 0.37, 0.5, 0.11, 0.51, 0.71, 0.27, 0.49, 0.49, 0.83, 0.46, 0.43, 0.42, 0.44, 0.57, 0.47, 0.25, 0.62, 0.2, 0.39, 0.75, 0.77, 0.7, 0.48, 0.52, 0.42, 0.38, 0.43, 0.41, 0.18, 0.49, 0.37, 0.8, 0.65, 0.66, 0.44, 0.6, 1.0, 0.5, 0.52, 0.57, 0.6, 0.63, 0.76, 0.37, 0.52, 0.8, 0.44, 0.65, 0.32, 0.5, 0.33, 0.51, 0.34, 0.23, 0.5, 0.44, 0.33, 0.25, 0.41, 0.4, 0.4, 0.41, 0.48, 0.54, 0.45, 0.58, 0.59, 0.42, 0.5, 0.42, 0.41, 0.46, 0.57, 0.52, 0.68, 0.43, 0.0, 0.3, 0.66, 0.33, 0.3, 0.33, 0.51, 0.41, 0.42, 0.64, 0.0, 0.62, 0.5, 0.65, 0.28, 0.4, 0.48, 0.59, 0.42, 0.46, 0.48, 0.38, 0.45, 0.36, 0.39, 0.55, 0.82, 0.55, 0.5, 0.34, 0.66, 0.4, 0.52, 0.38, 0.52, 0.34, 0.6, 0.45, 0.45, 0.37, 0.42, 0.56, 0.55, 0.33, 0.41, 0.61, 0.51, 0.45, 0.58, 0.4, 0.5, 0.54, 0.68, 0.56, 0.52, 0.4, 0.51, 0.39, 0.47, 0.5, 0.56, 0.5, 0.44, 0.42, 0.53, 0.45, 0.31, 0.47, 0.7, 0.39, 0.44, 0.31, 0.34, 0.24, 0.5, 0.33, 0.43, 0.32, 0.44, 0.5, 0.45, 0.65, 0.28, 0.3, 0.32, 0.49, 0.47, 0.63, 0.5, 0.6, 0.48, 0.56, 0.29, 0.26, 0.39, 0.46, 0.71, 0.48, 0.61, 0.29, 0.52, 0.51, 0.55, 0.56, 0.56, 0.5, 0.77, 0.36, 0.5, 0.71, 0.56, 0.61, 0.51, 0.42, 0.51, 0.41, 0.06, 0.31, 0.29, 0.29, 0.29, 0.72, 0.4, 1.0, 0.46, 0.34, 0.41, 0.63, 0.44, 0.44, 0.5, 0.52, 0.66, 0.81, 0.2, 0.77, 0.54, 0.4, 0.46, 0.5, 0.66, 0.56, 0.5, 0.52, 0.44, 0.51, 0.6, 0.25, 0.46, 0.0, 0.54, 0.5, 0.47, 0.42, 0.47, 0.51, 0.46, 0.66, 0.31, 0.57, 0.52, 0.8, 0.31, 0.53, 0.68, 0.68, 0.42, 0.55, 0.5, 0.52, 0.55, 0.6, 0.77, 0.42, 0.42, 0.48, 0.32, 0.38, 0.45, 0.41, 0.58, 0.43, 0.51, 0.77, 0.35, 0.4, 0.46, 0.44, 0.16, 0.34, 0.56, 0.42, 0.44, 0.3, 0.66, 0.48, 0.41, 0.55, 0.38, 0.58, 0.26, 0.6, 0.46, 0.56, 0.23, 0.17, 0.22, 0.45, 0.43, 0.43, 0.28, 0.2, 0.25, 0.2, 0.59, 0.44, 0.0, 0.48, 0.44, 0.64, 0.47, 0.51, 0.47, 0.48, 0.63, 0.33, 0.4, 0.76, 0.51, 0.49, 0.5, 0.31, 0.47, 0.3, 0.41, 0.35, 0.38, 0.31, 0.66, 0.53, 0.36, 0.51, 0.54, 0.39, 0.23, 0.5, 0.36, 0.33, 0.52, 0.33, 0.35, 0.45, 0.47, 0.42, 0.6, 0.57, 0.58, 0.28, 0.38, 0.56, 0.5, 0.5, 0.45, 0.3, 0.4, 0.41, 0.51, 0.38, 0.52, 0.4, 0.58, 0.37, 0.43, 0.53, 0.36, 0.35, 0.56, 0.37, 0.34, 0.6, 0.57, 0.29, 0.41, 0.23, 0.49, 0.36, 0.18, 0.28, 0.41, 0.47, 0.41, 0.53, 0.44, 0.52, 0.19, 0.33, 0.45, 0.36, 0.55, 0.25, 0.27, 0.39, 0.49, 0.45, 0.72, 0.26, 0.3, 0.41, 0.5, 0.3, 0.54, 0.41, 0.44, 0.5, 0.52, 0.26, 0.42, 0.42, 0.47, 0.71, 0.38, 0.44, 0.54, 0.56, 0.57, 0.61, 0.36, 0.43, 0.5, 0.35, 0.42, 0.35, 0.45, 0.36, 0.31, 0.68, 0.38, 0.19, 0.21, 0.36, 0.42, 0.47, 0.54, 0.3, 0.33, 0.13, 0.38, 0.37, 0.4, 0.44, 0.4, 0.52, 0.0, 0.39, 0.41, 0.29, 0.38, 0.62, 0.31, 0.54, 0.49, 0.53, 0.35, 0.16, 0.0, 0.43, 0.47, 0.27, 0.46, 0.27, 0.75, 0.5, 0.23, 0.66, 0.46, 0.22, 0.65, 0.49, 0.55, 0.51, 0.31, 0.6, 0.55, 0.47, 0.34, 0.42, 0.37, 0.45, 0.3, 0.36, 0.12, 0.37, 0.33, 0.44, 0.35, 0.5, 0.42, 0.32, 0.43, 0.24, 0.32, 0.76, 0.33, 0.3, 0.38, 0.45, 0.53, 0.31, 0.52, 0.31, 0.36, 0.56, 0.53, 0.56, 0.55, 0.43, 0.4, 0.41, 0.53, 0.61, 0.62, 0.33, 0.41, 0.33, 0.23, 0.49, 0.45, 0.3, 0.51, 0.38, 0.46, 0.17, 0.5, 0.2, 0.55, 0.43, 0.33, 0.46, 0.4, 0.55, 0.31, 0.27, 0.4, 0.5, 0.37, 0.25, 0.3, 0.33, 0.33, 0.36, 0.44, 0.42, 0.44, 0.34, 0.45, 0.49, 0.23, 0.59, 0.45, 0.35, 0.42, 0.57, 0.42, 0.53, 0.48, 0.39, 0.3, 0.28, 0.4, 0.47, 0.5, 0.47, 0.54, 0.0, 0.5, 0.15, 0.49, 0.44, 0.42, 0.5, 0.48, 0.43, 0.28, 0.38, 0.43, 0.25, 0.78, 0.0, 0.38, 0.7, 0.53, 0.47, 0.22, 0.4, 0.0, 0.16, 0.39, 0.66, 0.43, 0.23, 0.59, 0.35, 0.53, 0.3, 0.66, 0.46, 0.43, 0.51, 0.43, 0.66, 0.58, 0.26, 0.13, 0.6, 0.31, 0.57, 0.58, 1.0, 0.5, 0.48, 0.47, 0.16, 0.36, 0.29, 0.59, 0.48, 0.39, 0.4, 0.53, 0.49, 0.41, 0.36, 0.42, 0.47, 0.28, 0.3, 0.41, 0.33, 0.4, 0.73, 0.75, 0.49, 0.39, 0.42, 0.65, 0.36, 0.58, 0.7, 0.33, 0.36, 0.37, 0.46, 0.37, 0.54, 0.48, 0.31, 0.48, 0.26, 0.44, 0.53, 0.53, 0.26, 0.41, 0.4, 0.33, 0.32, 0.38, 0.46, 0.15, 0.53, 0.38, 0.38, 0.5, 0.53, 0.33, 0.48, 0.81, 0.3, 0.33, 0.51, 0.43, 0.43, 0.39, 0.33, 0.59, 0.54, 0.43, 0.42, 0.4, 0.31, 0.45, 0.29, 0.4, 0.19, 0.4, 0.65, 0.3, 0.33, 0.55, 0.35, 0.44, 0.35, 0.42, 0.41, 0.8, 1.0, 0.46, 0.45, 0.5, 0.31, 0.61, 0.4, 0.69, 0.42, 1.0, 0.43, 0.48, 0.55, 0.45, 0.57, 0.3, 0.18, 0.42, 0.32, 0.45, 0.43, 0.78, 0.23, 0.76, 0.61, 0.29, 0.3, 0.58, 0.22, 0.32, 0.28, 0.4, 0.29, 0.21, 0.4, 0.46, 0.28, 0.57, 0.44, 0.48, 0.5, 0.36, 0.56, 0.5, 0.33, 0.28, 0.25, 0.81, 0.58, 0.32, 0.23, 0.52, 0.0, 0.47, 0.42, 0.53, 0.38, 0.22, 0.43, 0.57, 0.46, 0.35, 0.32, 0.47, 0.54, 0.72, 0.0, 0.44, 0.53, 0.54, 0.5, 0.33, 0.35, 0.16, 0.51, 0.43, 0.5, 0.78, 0.63, 0.31, 0.51, 0.37, 0.37, 0.43, 0.62, 0.22, 0.61, 0.29, 0.29, 0.33, 0.46, 0.42, 0.2, 0.47, 0.53, 0.57, 0.7, 0.53, 0.58, 0.52, 0.6, 0.43, 0.33, 0.39, 0.71, 0.21, 0.11, 0.36, 0.36, 0.44, 0.52, 0.54, 0.43, 0.45, 0.0, 0.49, 0.0, 0.35, 0.48, 0.36, 0.72, 0.7, 0.41, 0.7, 0.51, 0.33, 0.4, 0.08, 0.56, 0.71, 0.8, 0.49, 0.34, 0.52, 0.3, 0.41, 0.37, 0.66, 0.26, 0.61, 0.45, 0.33, 0.43, 0.25, 0.33, 0.64, 0.4, 0.25, 0.43, 0.33, 0.62, 0.48, 0.39, 0.38, 0.0, 0.29, 0.44, 0.49, 0.69, 0.4, 0.52, 0.83, 0.59, 0.37, 0.31, 1.0, 0.38, 0.56, 0.45, 0.53, 0.42, 0.48, 0.48, 0.2, 0.4, 0.68, 0.38, 0.7, 0.57, 0.29, 0.53, 0.54, 0.55, 0.35, 0.43, 0.48, 0.34, 0.61, 0.58, 0.66, 0.48, 0.41, 0.59, 0.49, 0.51, 0.43, 0.0, 0.4, 0.3, 0.5, 0.5, 0.76, 0.4, 0.36, 0.39, 0.46, 0.39, 0.62, 0.75, 0.54, 0.38, 0.33, 0.51, 0.44, 0.35, 0.9, 0.57, 0.68, 0.3, 0.2, 0.63, 0.63, 0.4, 0.42, 0.27, 0.43, 0.55, 0.39, 0.5, 0.59, 0.27, 0.48, 0.35, 0.33, 0.57, 0.28, 0.44, 0.3, 0.56, 0.46, 0.21, 0.56, 0.5, 0.23, 0.31, 0.52, 0.4, 0.41, 0.47, 0.53, 0.35, 0.6, 0.63, 0.37, 0.57, 0.36, 0.48, 0.26, 0.58, 0.67, 0.49, 0.45, 0.62, 0.45, 0.66, 0.7, 0.51, 0.48, 0.53, 0.56, 0.4, 0.64, 0.74, 0.46, 0.47, 0.5, 0.5, 0.43, 0.42, 0.22, 0.29, 0.47, 0.44, 0.5, 0.61, 0.57, 0.23, 0.44, 0.11, 0.18, 0.45, 0.32, 0.21, 0.26, 0.35, 0.32, 0.13, 0.63, 0.37, 0.23, 0.0, 0.42, 0.39, 0.35, 0.4, 0.83, 0.27, 0.43, 0.36, 0.42, 0.35, 0.31, 0.57, 0.5, 0.31, 0.54, 0.54, 0.74, 0.38, 0.43, 0.37, 0.44, 0.0, 0.76, 0.44, 0.5, 0.39, 0.34, 0.36, 0.48, 0.56, 0.43, 0.44, 0.41, 0.42, 0.38, 0.39, 0.5, 0.46, 0.33, 0.42, 0.59, 0.29, 0.33, 0.38, 0.86, 0.35, 0.3, 0.43, 0.41, 0.3, 0.74, 0.49, 0.37, 0.39, 0.51, 0.22, 0.45, 0.72, 0.65, 0.72, 0.6, 0.56, 0.41, 0.22, 0.37, 0.35, 0.3, 0.62, 0.35, 0.24, 0.69, 0.57, 0.56, 0.4, 0.35, 0.42, 0.67, 0.37, 0.56, 0.4, 0.52, 0.64, 0.16, 0.56, 0.44, 0.46, 0.28, 0.55, 0.38, 0.63, 0.33, 0.3, 0.31, 0.41, 0.77, 0.52, 0.55, 0.42, 0.43, 0.5, 0.75, 0.29, 0.29, 0.62, 0.39, 0.48, 0.43, 0.63, 0.31, 0.24, 0.44, 0.41, 0.46, 0.33, 0.44, 0.45, 0.59, 0.69, 0.41, 0.34, 0.5, 0.66, 0.44, 0.48, 0.92, 0.77, 0.31, 0.4, 0.47, 0.36, 0.43, 0.39, 0.35, 0.13, 0.15, 0.34, 0.35, 0.3, 0.35, 0.35, 0.43, 0.5, 0.37, 0.52, 0.42, 0.37, 0.3, 0.5, 0.31, 0.22, 0.38, 0.47, 0.6, 0.44, 0.39, 0.47, 0.66, 1.0, 0.33, 0.55, 0.53, 0.37, 0.36, 0.24, 0.36, 0.5, 0.66, 0.66, 0.16, 0.38, 0.42, 0.62, 0.46, 0.5, 0.58, 0.36, 0.5, 0.48, 0.3, 0.54, 0.2, 0.33, 0.29, 0.31, 0.28, 0.54, 0.39, 0.29, 0.37, 0.64, 0.43, 0.5, 0.47, 0.34, 0.37, 0.78, 0.48, 0.44, 0.55, 0.29, 0.4, 0.29, 0.26, 0.65, 0.39, 0.72, 0.35, 0.6, 0.53, 0.5, 0.31, 0.37, 0.78, 0.58, 1.0, 0.61, 0.61, 0.7, 0.45, 0.32, 0.41, 0.52, 0.57, 0.48, 0.61, 0.4, 0.57, 0.44, 0.57, 0.43, 0.42, 0.46, 0.6, 0.46, 0.46, 0.58, 0.54, 0.55, 0.62, 0.25, 0.35, 0.42, 0.31, 0.66, 0.28, 0.44, 0.4, 0.42, 0.48, 0.24, 0.2, 0.55, 0.36, 0.44, 0.37, 0.53, 0.27, 0.32, 0.36, 0.43, 0.69, 0.32, 0.32, 0.36, 0.5, 0.36, 0.41, 0.16, 0.54, 0.67, 0.37, 0.45, 0.47, 0.8, 0.66, 0.5, 0.28, 0.23, 0.34, 0.61, 0.47, 0.56, 0.29, 0.37, 0.48, 0.31, 0.45, 0.34, 0.54, 0.18, 0.46, 0.47, 0.57, 0.31, 0.33, 0.39, 0.38, 0.35, 0.45, 0.5, 0.55, 0.56, 0.44, 0.45, 0.44, 0.46, 0.4, 0.48, 0.51, 0.36, 0.64, 0.19, 0.32, 0.34, 0.34, 0.28, 0.58, 0.16, 0.29, 0.5, 0.5, 0.59, 0.26, 0.37, 0.48, 0.39, 0.56, 0.5, 0.25, 0.31, 0.58, 0.27, 0.34, 0.44, 0.3, 0.57, 0.5, 0.41, 0.69, 0.4, 0.6, 0.39, 0.38, 0.44, 0.61, 0.53, 0.42, 0.25, 0.51, 0.4, 0.67, 0.49, 0.39, 0.39, 0.38, 0.44, 0.57, 0.39, 0.32, 0.3, 0.29, 0.42, 0.41, 0.11, 0.35, 0.59, 0.23, 0.35, 0.6, 0.51, 0.29, 0.39, 0.25, 0.58, 0.33, 0.45, 0.1, 0.6, 0.58, 0.26, 0.44, 0.49, 0.58, 0.39, 0.5, 0.35, 0.22, 0.41, 0.62, 0.61, 0.51, 0.49, 0.74, 0.44, 0.62, 0.6, 0.45, 0.58, 0.36, 0.6, 0.34, 0.56, 0.34, 0.46, 0.3, 0.42, 0.73, 0.49, 0.24, 0.44, 0.29, 0.54, 0.37, 0.2, 0.66, 0.43, 0.38, 0.44, 0.3, 0.27, 0.44, 0.42, 0.17, 0.41, 0.25, 0.06, 0.48, 0.38, 0.57, 0.25, 0.43, 0.37, 0.34, 0.28, 0.36, 0.53, 0.53, 0.37, 0.4, 0.43, 0.31, 0.46, 0.44, 0.0, 0.0, 0.31, 0.39, 0.4, 0.63, 0.31, 0.5, 0.51, 0.0, 0.58, 0.65, 0.44, 0.56, 0.5, 0.3, 0.27, 0.51, 0.32, 0.44, 0.46, 0.3, 0.51, 0.48, 0.44, 0.43, 0.83, 0.59, 0.44, 0.37, 0.81, 0.2, 0.57, 0.22, 0.8, 0.33, 0.59, 0.49, 0.48, 0.51, 0.25, 0.52, 0.25, 0.5, 0.23, 0.0, 0.33, 0.42, 0.3, 0.69, 0.61, 0.4, 0.27, 0.4, 0.52, 0.71, 0.37, 0.4, 0.7, 0.16, 0.75, 0.35, 0.33, 0.5, 0.57, 0.31, 0.37, 0.49, 0.63, 0.22, 0.22, 0.43, 0.46, 0.45, 0.33, 0.51, 0.55, 0.45, 0.36, 0.43, 0.37, 0.79, 0.38, 0.48, 0.43, 0.33, 0.6, 0.28, 0.53, 0.58, 0.48, 0.65, 0.43, 0.58, 0.57, 0.39, 0.44, 0.4, 0.53, 0.24, 0.64, 0.33, 0.55, 0.42, 0.43, 0.3, 0.62, 0.25, 0.51, 0.4, 0.39, 0.2, 0.59, 0.87, 0.49, 0.17, 0.41, 0.51, 0.24, 0.26, 0.75, 0.19, 0.61, 0.73, 0.22, 0.55, 0.81, 0.21, 0.36, 0.33, 0.42, 0.31, 0.48, 0.2, 0.36, 0.68, 0.23, 0.55, 0.44, 0.51, 0.53, 0.51, 0.3, 0.51, 0.29, 0.36, 0.4, 0.31, 0.47, 0.25, 0.43, 0.5, 0.42, 0.3, 0.5, 0.53, 0.52, 0.48, 0.36, 0.5, 0.24, 0.5, 0.53, 0.35, 0.29, 0.65, 0.75, 0.26, 0.51, 0.2, 0.65, 0.31, 0.47, 0.27, 0.33, 0.64, 0.25, 0.29, 0.55, 0.28, 0.43, 0.25, 0.46, 0.66, 0.38, 0.61, 0.38, 0.31, 0.5, 0.54, 0.43, 0.38, 0.35, 0.31, 0.5, 0.44, 0.26, 0.37, 0.15, 0.55, 0.47, 0.3, 0.32, 0.48, 0.4, 0.32, 0.34, 0.4, 0.09, 0.66, 0.5, 0.6, 0.47, 0.73, 0.39, 0.62, 0.32, 0.5, 0.6, 0.56, 0.3, 0.61, 0.52, 0.33, 0.33, 0.42, 0.0, 0.26, 0.32, 0.53, 0.44, 0.45, 0.37, 0.44, 0.22, 0.51, 0.46, 0.36, 0.44, 0.45, 0.5, 0.54, 1.0, 0.44, 0.48, 0.53, 0.36, 0.42, 0.4, 0.56, 0.75, 0.34, 0.28, 0.47, 1.0, 0.62, 0.68, 0.36, 0.46, 0.38, 0.5, 0.41, 0.56, 0.47, 0.7, 0.37, 0.5, 0.39, 0.44, 0.35, 0.33, 0.28, 0.0, 0.35, 0.3, 0.43, 0.33, 0.38, 0.37, 0.53, 0.53, 0.6, 0.45, 0.52, 0.46, 0.32, 0.74, 0.49, 0.38, 0.48, 0.24, 0.37, 0.45, 0.5, 0.42, 0.75, 0.65, 0.38, 0.24, 0.19, 1.0, 0.77, 0.56, 0.61, 0.32, 0.42, 0.3, 0.49, 0.58, 0.5, 0.29, 0.34, 0.16, 0.18, 0.29, 0.35, 0.3, 0.61, 0.38, 0.36, 0.36, 0.45, 0.31, 0.43, 0.4, 0.5, 0.34, 0.42, 0.49, 0.55, 0.54, 0.41, 0.48, 0.37, 0.73, 0.7, 0.5, 0.27, 0.41, 0.63, 0.5, 0.53, 0.59, 0.36, 0.42, 0.32, 0.25, 0.57, 0.33, 0.54, 0.48, 0.56, 0.37, 0.44, 0.33, 0.25, 0.55, 0.31, 0.41, 0.52, 0.4, 0.0, 0.4, 0.28, 0.37, 0.31, 0.41, 0.43, 0.38, 0.26, 0.38, 0.38, 0.39, 0.34, 0.69, 0.62, 0.72, 0.24, 0.39, 0.42, 0.65, 0.6, 0.53, 0.45, 0.45, 0.56, 0.31, 0.65, 0.57, 0.27, 0.48, 0.44, 0.47, 0.2, 0.31, 0.42, 0.51, 0.25, 0.24, 0.32, 0.5, 0.47, 0.31, 0.28, 0.0, 0.45, 0.21, 0.43, 0.7, 0.48, 0.41, 0.53, 0.4, 0.46, 0.42, 0.58, 0.4, 0.45, 0.43, 0.36, 0.41, 0.54, 0.38, 0.26, 0.22, 0.45, 0.55, 0.22, 0.24, 0.56, 0.3, 0.32, 0.19, 0.49, 0.36, 0.72, 0.42, 0.52, 0.45, 0.5, 1.0, 0.5, 0.45, 0.45, 0.23, 0.27, 0.36, 0.5, 0.68, 0.46, 0.4, 0.66, 0.25, 0.38, 0.41, 0.42, 0.4, 0.52, 0.81, 0.43, 0.72, 0.4, 0.36, 0.33, 0.28, 0.3, 0.31, 0.64, 0.22, 0.6, 0.27, 0.44, 0.39, 0.62, 0.33, 0.39, 0.58, 0.2, 0.4, 0.22, 0.29, 0.45, 0.37, 0.57, 0.37, 0.2, 0.63, 0.0, 0.27, 0.44, 0.35, 0.32, 0.4, 0.34, 0.52, 0.25, 0.62, 0.33, 0.5, 0.32, 0.32, 0.51, 0.33, 0.19, 0.64, 0.31, 0.3, 0.34, 0.34, 0.26, 0.56, 0.31, 0.47, 0.56, 0.34, 0.16, 0.47, 0.41, 0.48, 0.49, 0.29, 0.44, 0.44, 0.25, 0.46, 0.57, 0.33, 0.61, 0.62, 0.41, 0.44, 0.44, 0.32, 0.58, 0.66, 0.37, 0.71, 0.31, 0.21, 0.53, 0.23, 0.48, 0.16, 0.35, 0.24, 0.28, 0.27, 0.22, 0.49, 0.72, 0.34, 0.61, 0.34, 0.36, 0.47, 0.44, 0.33, 0.38, 0.29, 0.52, 0.47, 0.3, 0.5, 0.29, 0.32, 0.52, 0.53, 0.26, 0.46, 0.33, 0.41, 0.47, 0.36, 0.43, 0.7, 0.36, 0.5, 0.32, 0.53, 0.41, 0.3, 0.41, 0.58, 0.63, 0.4, 0.39, 0.29, 0.22, 0.57, 0.49, 0.35, 0.44, 0.66, 0.38, 0.2, 0.42, 0.51, 0.25, 0.53, 0.4, 0.66, 0.31, 0.48, 0.57, 0.52, 0.63, 0.55, 0.57, 0.5, 0.38, 0.25, 0.37, 0.31, 0.28, 0.56, 0.6, 0.46, 0.35, 0.46, 0.42, 0.49, 0.5, 0.42, 0.55, 0.47, 0.2, 0.4, 0.34, 0.55, 0.33, 0.69, 0.52, 0.42, 0.21, 0.47, 0.56, 0.45, 0.32, 0.3, 0.57, 0.62, 0.4, 0.59, 0.52, 0.42, 0.43, 0.39, 0.52, 0.29, 0.36, 0.43, 0.41, 0.31, 0.55, 0.61, 0.29, 0.5, 0.64, 0.8, 0.22, 0.39, 0.51, 0.43, 0.53, 0.31, 0.35, 0.33, 0.4, 0.25, 0.48, 0.81, 0.65, 0.6, 0.61, 0.46, 0.43, 0.36, 0.35, 0.39, 0.39, 0.18, 0.4, 0.35, 0.35, 0.44, 0.45, 0.35, 0.31, 0.45, 0.6, 0.54, 0.41, 0.0, 0.4, 0.5, 0.5, 0.22, 0.41, 0.21, 0.57, 0.52, 0.5, 1.0, 0.44, 0.34, 0.63, 0.71, 0.41, 0.47, 0.64, 0.51, 0.35, 0.71, 0.25, 0.66, 0.34, 0.33, 0.33, 0.1, 0.75, 0.35, 0.53, 0.41, 0.37, 0.8, 0.5, 0.33, 0.43, 0.36, 0.6, 0.5, 0.38, 0.56, 0.31, 0.41, 0.6, 0.52, 0.52, 0.37, 0.48, 0.33, 0.52, 0.34, 0.24, 0.37, 0.28, 0.64, 0.34, 0.6, 0.4, 0.34, 0.38, 0.43, 0.0, 0.38, 0.58, 0.0, 0.28, 0.46, 0.0, 0.63, 0.48, 0.4, 0.59, 0.33, 0.25, 0.52, 0.59, 0.52, 0.3, 0.45, 0.41, 0.31, 0.24, 0.52, 0.33, 0.47, 0.55, 0.5, 0.45, 0.0, 0.38, 0.44, 0.54, 0.3, 0.42, 0.32, 0.38, 0.83, 0.33, 0.44, 0.57, 0.58, 0.37, 0.46, 0.44, 0.45, 0.4, 0.57, 0.2, 0.54, 0.55, 0.33, 0.4, 0.21, 0.31, 0.35, 0.58, 0.39, 0.26, 0.41, 0.88, 0.34, 0.52, 0.4, 0.37, 0.3, 0.33, 0.57, 0.74, 0.51, 0.39, 0.31, 0.59, 0.72, 0.73, 0.45, 0.31, 0.45, 0.46, 0.5, 0.83, 0.65, 0.5, 0.5, 0.49, 0.48, 0.27, 1.0, 0.21, 0.66, 0.29, 0.47, 0.29, 0.56, 0.52, 0.43, 0.66, 0.43, 0.29, 0.33, 0.33, 0.49, 0.2, 0.43, 0.62, 0.64, 0.37, 0.3, 0.0, 0.16, 0.41, 0.4, 0.25, 0.27, 0.49, 0.0, 0.45, 0.42, 0.53, 0.49, 0.34, 0.34, 0.6, 0.33, 0.45, 0.4, 0.34, 0.39, 0.28, 0.53, 0.39, 0.25, 0.64, 0.29, 0.38, 0.44, 0.32, 0.37, 0.71, 0.32, 0.52, 0.46, 0.43, 0.51, 0.33, 0.55, 0.31, 0.4, 0.37, 0.68, 0.16, 1.0, 0.36, 0.29, 0.5, 0.55, 0.44, 0.0, 0.46, 0.28, 0.38, 0.37, 0.41, 0.59, 0.66, 0.34, 0.55, 0.33, 0.19, 0.43, 0.37, 0.65, 0.36, 0.72, 0.47, 0.22, 0.61, 0.25, 0.5, 0.24, 0.46, 0.26, 0.54, 0.67, 0.3, 0.61, 0.52, 0.75, 0.32, 0.41, 0.82, 0.52, 0.55, 0.44, 0.54, 0.51, 0.47, 0.46, 0.4, 0.56, 0.63, 0.39, 0.46, 0.6, 0.42, 0.66, 0.34, 0.29, 0.49, 0.49, 0.47, 0.79, 0.47, 0.8, 0.66, 0.72, 0.41, 0.55, 0.42, 0.55, 0.37, 0.36, 0.45, 0.69, 0.53, 0.58, 0.58, 0.4, 0.48, 0.5, 0.48, 0.51, 0.64, 0.37, 0.62, 0.42, 0.52, 0.54, 0.37, 0.0, 0.53, 0.5, 0.47, 0.44, 0.62, 0.34, 0.39, 0.31, 0.29, 0.42, 0.33, 0.48, 0.32, 0.66, 0.51, 0.48, 1.0, 0.4, 0.54, 0.46, 0.61, 0.3, 0.57, 0.52, 0.4, 0.57, 0.35, 0.55, 0.08, 0.37, 0.55, 0.34, 0.44, 0.33, 0.24, 0.48, 0.32, 0.54, 0.42, 0.3, 0.51, 0.57, 0.27, 0.49, 0.38, 0.78, 0.2, 0.37, 0.68, 0.67, 0.24, 0.57, 0.5, 0.38, 0.52, 0.57, 0.43, 0.4, 0.23, 0.54, 0.33, 0.51, 0.15, 0.6, 0.55, 0.26, 0.0, 0.56, 0.58, 0.37, 0.52, 0.35, 0.28, 0.56, 0.25, 0.3, 1.0, 0.44, 0.3, 0.62, 0.52, 0.43, 0.39, 0.55, 0.48, 0.36, 0.49, 0.39, 0.33, 0.0, 0.5, 0.36, 0.41, 0.21, 0.8, 0.38, 0.46, 0.4, 0.41, 0.0, 0.26, 0.37, 0.33, 0.36, 0.31, 0.75, 0.49, 0.76, 0.23, 0.57, 0.3, 0.6, 0.38, 0.42, 0.29, 0.56, 0.35, 0.61, 0.56, 0.56, 0.55, 0.6, 0.56, 0.43, 0.45, 0.43, 0.5, 0.28, 0.38, 0.32, 0.19, 0.43, 0.57, 0.48, 0.47, 0.41, 0.37, 0.56, 0.42, 0.08, 0.34, 0.71, 0.52, 0.38, 0.34, 0.34, 0.61, 0.56, 0.42, 0.49, 0.45, 0.34, 0.5, 0.35, 0.43, 0.41, 0.6, 0.5, 0.46, 0.32, 0.27, 0.3, 0.41, 0.52, 0.5, 0.41, 0.72, 0.5, 0.6, 0.41, 0.59, 0.36, 0.61, 0.31, 0.45, 0.41, 0.37, 0.37, 1.0, 0.61, 0.42, 0.68, 0.83, 0.67, 0.73, 0.51, 0.36, 0.35, 0.54, 0.0, 0.28, 0.35, 0.45, 0.43, 0.37, 0.31, 0.27, 0.19, 0.38, 0.12, 0.38, 0.16, 0.45, 0.25, 0.3, 0.43, 0.52, 0.2, 0.52, 0.5, 0.46, 0.73, 0.53, 0.2, 0.32, 0.52, 0.25, 0.31, 0.37, 0.34, 0.0, 0.2, 0.17, 0.5, 0.1, 0.33, 0.38, 0.54, 0.53, 0.34, 0.37, 0.55, 0.2, 0.5, 0.46, 0.26, 0.37, 0.35, 0.53, 0.21, 0.3, 0.3, 0.23, 0.35, 0.4, 0.33, 0.33, 0.52, 0.48, 0.37, 0.34, 0.22, 0.38, 0.4, 0.33, 0.32, 0.61, 0.31, 0.19, 0.28, 0.03, 0.63, 0.18, 0.22, 0.38, 0.43, 0.57, 0.85, 0.5, 0.23, 0.28, 0.47, 0.28, 0.3, 0.55, 0.55, 0.29, 0.33, 0.58, 0.72, 0.34, 0.41, 0.63, 0.46, 0.27, 0.35, 0.28, 0.46, 0.25, 0.32, 0.35, 0.36, 0.5, 0.3, 0.35, 0.38, 0.0, 0.52, 0.65, 0.56, 0.66, 0.5, 0.5, 0.43, 0.57, 0.42, 0.63, 0.42, 0.46, 0.12, 0.4, 0.66, 0.3, 0.29, 0.57, 0.51, 0.46, 0.15, 0.0, 0.38, 0.64, 0.38, 0.37, 0.53, 0.56, 0.52, 0.25, 0.8, 0.67, 0.57, 0.34, 0.38, 0.33, 0.19, 0.26, 0.45, 0.4, 0.68, 0.29, 0.31, 0.36, 0.4, 0.47, 0.61, 0.24, 0.66, 0.35, 0.43, 0.29, 0.46, 0.57, 0.66, 0.27, 0.44, 0.26, 0.4, 0.57, 0.45, 0.34, 0.28, 0.5, 0.47, 0.44, 0.6, 0.5, 0.54, 0.33, 0.53, 0.36, 0.4, 0.44, 0.35, 0.37, 0.24, 0.33, 0.45, 0.3, 0.46, 0.33, 0.85, 0.46, 0.92, 0.52, 0.31, 0.39, 0.33, 0.71, 0.31, 0.47, 0.44, 0.19, 0.37, 0.41, 0.3, 0.09, 0.3, 0.3, 0.18, 0.4, 0.29, 0.5, 0.43, 0.46, 0.6, 0.58, 0.0, 0.5, 0.53, 0.6, 0.65, 0.4, 0.82, 0.41, 0.24, 0.39, 0.75, 0.42, 0.4, 0.22, 0.34, 0.31, 0.48, 0.59, 0.2, 0.4, 0.47, 0.52, 0.47, 0.41, 0.33, 0.25, 0.41, 0.34, 0.56, 0.52, 0.46, 0.39, 0.33, 0.31, 0.17, 0.41, 0.39, 0.46, 0.42, 0.33, 0.34, 0.46, 0.63, 0.68, 0.65, 0.39, 0.45, 0.46, 0.62, 1.0, 0.52, 0.72, 0.32, 0.59, 0.36, 0.36, 0.31, 0.21, 0.26, 0.35, 0.4, 0.4, 0.93, 0.0, 0.6, 0.66, 0.41, 0.33, 0.39, 0.25, 0.12, 0.47, 0.63, 0.8, 0.23, 0.34, 0.5, 0.3, 0.26, 0.48, 0.67, 0.62, 0.64, 0.62, 0.3, 0.26, 0.47, 0.42, 0.58, 0.33, 0.0, 0.36, 0.57, 0.48, 0.51, 0.33, 0.0, 0.41, 0.41, 0.55, 0.56, 0.4, 0.5, 0.38, 0.27, 0.28, 0.4, 0.24, 0.47, 0.22, 0.2, 0.31, 0.71, 0.6, 0.27, 0.46, 0.37, 0.55, 0.3, 0.38, 0.26, 0.4, 0.61, 0.63, 0.66, 0.2, 0.2, 0.52, 0.75, 0.6, 0.44, 0.31, 0.25, 0.42, 0.0, 0.41, 0.33, 0.34, 0.33, 0.44, 0.33, 0.49, 0.52, 0.29, 0.5, 0.28, 0.28, 0.23, 0.41, 0.5, 0.52, 0.7, 0.37, 0.18, 0.0, 0.42, 0.62, 0.74, 0.63, 0.32, 0.73, 0.44, 0.5, 0.35, 0.11, 0.47, 0.29, 0.32, 0.27, 0.34, 0.51, 0.5, 0.24, 0.34, 0.31, 0.56, 0.5, 0.23, 0.41, 0.14, 0.37, 0.49, 0.2, 0.33, 0.54, 0.32, 0.65, 0.13, 0.25, 0.27, 0.48, 0.51, 0.4, 0.39, 0.38, 0.38, 0.41, 0.32, 0.75, 0.25, 0.62, 0.55, 0.29, 0.41, 0.38, 0.6, 0.5, 0.25, 0.51, 0.4, 0.45, 0.33, 0.32, 0.39, 0.43, 0.38, 0.5, 0.42, 0.38, 0.5, 0.45, 0.39, 0.46, 0.53, 0.53, 0.45, 0.0, 0.43, 0.47, 0.24, 0.33, 0.55, 0.52, 0.28, 0.28, 0.27, 0.34, 0.5, 0.33, 0.31, 0.76, 0.49, 0.48, 0.61, 0.4, 0.38, 0.52, 0.51, 0.64, 0.37, 0.26, 0.32, 0.66, 0.27, 0.22, 0.44, 0.22, 0.83, 0.48, 0.58, 0.7, 0.38, 0.36, 0.63, 0.32, 0.6, 0.22, 0.32, 0.12, 0.24, 0.21, 0.54, 0.37, 0.65, 0.45, 0.66, 0.3, 0.38, 0.66, 0.38, 0.75, 0.29, 0.35, 0.28, 0.5, 0.43, 0.25, 0.64, 0.57, 0.5, 0.45, 0.48, 0.38, 0.48, 0.25, 0.27, 0.41, 0.53, 0.45, 0.4, 0.59, 0.57, 0.52, 0.56, 0.21, 0.41, 0.37, 0.0, 0.44, 0.49, 0.52, 0.5, 0.27, 0.4, 0.32, 0.31, 0.59, 0.45, 0.28, 0.55, 0.65, 0.36, 0.42, 0.42, 0.47, 0.42, 0.33, 0.51, 0.28, 0.7, 0.31, 0.33, 0.26, 0.0, 0.43, 0.42, 0.38, 0.39, 0.42, 0.37, 0.4, 0.45, 0.36, 0.25, 0.28, 0.83, 0.53, 0.22, 0.29, 0.3, 0.33, 0.27, 0.3, 0.63, 0.44, 0.32, 0.35, 0.44, 0.34, 0.27, 0.3, 0.34, 0.33, 0.26, 0.48, 0.68, 0.21, 0.4, 0.41, 0.4, 0.42, 0.25, 0.32, 0.6, 0.36, 0.37, 0.61, 0.42, 0.44, 0.73, 0.55, 0.33, 0.27, 0.25, 0.69, 0.39, 0.31, 0.5, 0.53, 0.48, 0.63, 0.47, 0.33, 0.43, 0.25, 0.3, 0.36, 0.25, 0.49, 0.14, 0.33, 0.33, 0.56, 0.33, 0.34, 0.25, 0.32, 0.34, 0.27, 0.23, 0.52, 0.14, 0.24, 0.85, 0.46, 0.55, 0.34, 0.5, 0.72, 0.36, 0.6, 0.6, 0.8, 0.4, 0.23, 0.6, 0.71, 0.62, 0.25, 0.26, 0.28, 0.43, 0.21, 0.43, 0.64, 0.28, 0.33, 0.57, 0.35, 0.21, 0.42, 0.66, 0.52, 0.5, 0.47, 0.56, 0.42, 0.44, 1.0, 0.73, 0.7, 0.23, 0.3, 0.52, 0.37, 0.29, 0.48, 0.32, 0.36, 0.34, 0.36, 0.29, 0.16, 0.38, 0.36, 0.4, 0.0, 0.0, 0.31, 0.66, 0.37, 0.5, 0.45, 0.37, 0.38, 0.59, 0.52, 0.53, 0.77, 0.37, 0.2, 0.23, 0.28, 0.27, 0.48, 0.45, 0.31, 0.33, 0.57, 0.5, 0.52, 0.6, 0.31, 0.35, 0.38, 0.28, 0.4, 0.28, 0.41, 0.22, 0.43, 0.25, 0.38, 0.2, 0.63, 0.45, 0.41, 0.3, 0.34, 0.58, 0.34, 0.25, 0.52, 0.65, 0.67, 0.4, 0.58, 0.33, 0.48, 0.52, 0.55, 0.38, 0.4, 0.58, 0.73, 0.35, 0.56, 0.68, 0.17, 0.65, 0.58, 0.47, 0.58, 0.34, 0.25, 0.66, 0.45, 0.3, 0.36, 0.35, 0.33, 0.26, 0.32, 0.25, 0.47, 0.65, 0.44, 0.16, 0.66, 0.4, 0.55, 0.51, 0.34, 0.0, 0.54, 0.45, 0.58, 0.24, 0.37, 0.38, 0.28, 0.54, 0.0, 0.14, 0.23, 0.0, 0.49, 0.52, 0.61, 0.37, 0.24, 0.25, 0.38, 0.49, 0.0, 0.42, 0.19, 0.23, 0.66, 0.63, 0.4, 0.44, 0.3, 0.8, 0.6, 0.38, 0.57, 0.37, 0.3, 0.41, 0.56, 0.18, 0.63, 0.33, 1.0, 0.45, 0.57, 0.38, 0.43, 0.61, 0.3, 0.55, 0.66, 0.63, 0.51, 0.54, 0.36, 0.83, 0.86, 0.47, 0.39, 0.0, 1.0, 0.51, 0.77, 0.57, 0.51, 0.57, 0.26, 0.33, 0.29, 0.38, 0.5, 0.34, 0.51, 0.38, 0.46, 0.36, 0.46, 0.44, 0.26, 0.4, 0.28, 0.25, 0.35, 0.44, 0.45, 0.34, 0.47, 0.3, 0.65, 0.18, 0.28, 0.48, 0.4, 0.19, 0.66, 0.19, 0.55, 0.22, 0.55, 0.58, 0.38, 0.55, 0.44, 0.22, 0.61, 0.5, 0.41, 0.06, 0.39, 0.2, 0.33, 0.37, 0.32, 0.35, 1.0, 0.43, 0.41, 0.83, 1.0, 0.41, 0.63, 0.44, 0.7, 0.46, 0.29, 0.35, 0.5, 0.16, 0.68, 0.0, 0.45, 0.28, 0.46, 0.31, 0.16, 0.38, 0.6, 0.41, 0.53, 0.54, 0.3, 0.42, 0.56, 0.25, 0.29, 0.47, 0.25, 0.54, 0.25, 0.18, 0.55, 0.53, 0.56, 0.57, 0.44, 0.5, 0.44, 0.2, 0.45, 0.41, 0.42, 0.37, 0.46, 0.66, 0.31, 0.42, 0.41, 0.6, 0.69, 0.32, 0.5, 0.51, 0.33, 0.54, 0.42, 0.28, 0.41, 0.64, 0.34, 0.65, 0.57, 0.39, 0.56, 0.26, 0.5, 0.11, 0.22, 0.22, 0.26, 0.43, 0.7, 0.35, 0.38, 0.0, 0.6, 0.34, 0.28, 0.4, 0.44, 0.33, 0.57, 0.31, 0.41, 0.0, 0.58, 0.14, 0.37, 0.21, 0.4, 0.44, 0.7, 0.5, 0.68, 0.75, 0.38, 0.3, 0.43, 0.33, 0.49, 0.28, 0.37, 0.21, 0.31, 0.3, 0.72, 0.32, 0.46, 0.64, 0.44, 0.35, 0.46, 0.6, 0.56, 0.48, 0.52, 0.26, 0.68, 0.62, 0.56, 0.52, 0.52, 0.5, 0.32, 0.42, 0.46, 0.13, 0.46, 0.32, 0.33, 0.33, 0.7, 0.36, 0.46, 0.57, 0.64, 0.23, 0.19, 0.3, 0.2, 0.76, 0.2, 0.5, 0.24, 0.0, 0.26, 0.4, 0.42, 0.7, 0.66, 0.53, 0.31, 0.33, 0.3, 0.48, 0.5, 0.25, 0.2, 0.52, 0.43, 0.56, 0.29, 0.34, 0.36, 0.27, 0.4, 0.27, 0.57, 0.18, 0.6, 0.4, 0.46, 0.35, 0.34, 0.36, 0.5, 0.75, 0.25, 0.24, 0.85, 0.48, 0.47, 0.53, 0.0, 0.44, 0.17, 0.5, 0.45, 0.45, 0.75, 0.31, 0.2, 0.68, 0.48, 0.47, 0.9, 0.41, 0.44, 0.49, 0.4, 0.36, 0.33, 0.78, 0.42, 0.45, 0.39, 0.31, 0.12, 0.0, 0.36, 0.35, 0.42, 0.42, 0.23, 0.22, 0.58, 0.81, 0.71, 0.5, 0.63, 0.21, 0.46, 0.32, 0.35, 0.12, 0.33, 0.51, 0.43, 0.37, 0.29, 0.55, 0.36, 0.44, 0.44, 0.49, 0.65, 1.0, 0.41, 0.35, 0.54, 0.75, 0.26, 0.58, 0.5, 0.42, 0.36, 0.75, 0.3, 0.31, 0.48, 0.35, 0.61, 0.38, 0.38, 1.0, 0.16, 0.27, 0.24, 0.24, 0.45, 0.44, 0.47, 0.36, 0.52, 0.47, 0.18, 0.43, 0.52, 0.8, 0.46, 0.4, 0.41, 0.38, 0.14, 0.41, 0.43, 0.43, 0.49, 0.71, 0.3, 0.33, 0.49, 0.32, 0.67, 0.45, 0.43, 0.25, 0.54, 0.33, 0.45, 0.54, 0.53, 0.41, 0.62, 0.23, 0.19, 0.37, 0.55, 0.25, 0.35, 0.35, 0.44, 0.69, 0.45, 0.5, 0.37, 0.65, 0.57, 0.4, 0.57, 0.54, 0.44, 0.25, 0.5, 0.35, 0.44, 0.52, 0.4, 0.34, 0.71, 0.45, 0.38, 0.5, 0.44, 0.16, 0.33, 0.39, 0.35, 0.45, 0.54, 0.54, 0.36, 0.35, 0.34, 0.45, 0.34, 0.45, 0.55, 0.41, 0.29, 0.27, 0.47, 0.27, 0.29, 0.37, 0.0, 0.5, 0.48, 0.42, 0.55, 0.23, 0.35, 0.5, 0.75, 0.39, 0.85, 0.4, 0.48, 0.16, 0.78, 0.56, 0.51, 0.52, 0.39, 0.44, 0.42, 0.38, 0.0, 0.22, 0.36, 0.45, 0.4, 0.66, 0.56, 0.32, 0.54, 0.41, 0.45, 0.45, 0.33, 0.0, 0.48, 0.46, 0.31, 0.48, 0.62, 0.5, 0.68, 0.63, 0.38, 0.33, 0.56, 0.43, 0.45, 0.41, 0.47, 0.66, 0.34, 0.35, 0.44, 0.34, 0.5, 0.24, 0.39, 0.48, 0.57, 0.25, 0.34, 0.34, 0.51, 0.72, 0.35, 0.5, 0.6, 0.7, 0.23, 0.33, 0.25, 0.4, 0.15, 0.66, 0.45, 0.27, 0.33, 0.57, 0.47, 0.56, 0.25, 0.0, 0.0, 0.24, 0.26, 0.0, 0.5, 0.45, 0.24, 0.79, 0.52, 1.0, 0.47, 0.7, 0.62, 0.46, 0.26, 0.38, 0.46, 0.34, 0.77, 0.6, 0.58, 0.6, 0.67, 0.65, 0.62, 0.36, 0.32, 0.7, 0.68, 0.22, 0.32, 0.29, 0.3, 0.58, 0.52, 0.58, 0.69, 0.54, 0.39, 0.19, 0.25, 0.58, 0.07, 0.75, 0.5, 0.26, 0.44, 0.34, 0.75, 0.61, 0.44, 0.41, 0.3, 0.28, 0.83, 0.39, 0.41, 0.43, 0.48, 0.52, 0.37, 0.36, 0.44, 0.0, 0.43, 0.6, 0.27, 0.68, 0.51, 0.5, 0.38, 0.42, 0.32, 0.33, 0.39, 0.25, 0.38, 0.22, 0.68, 0.31, 0.24, 0.31, 0.25, 0.51, 0.33, 0.32, 0.36, 0.47, 0.55, 0.13, 0.47, 0.35, 0.37, 0.5, 0.61, 0.18, 0.12, 0.22, 0.37, 0.49, 0.0, 0.36, 0.5, 0.49, 0.38, 0.17, 0.22, 0.54, 0.38, 0.56, 0.0, 0.56, 0.37, 0.36, 0.28, 0.37, 0.16, 0.59, 0.33, 0.38, 0.0, 0.39, 0.66, 0.37, 0.15, 0.28, 0.24, 0.56, 0.33, 0.43, 0.19, 0.32, 0.57, 0.61, 0.32, 0.46, 0.49, 0.34, 0.37, 0.46, 0.33, 0.92, 0.33, 0.52, 0.45, 0.73, 1.0, 0.18, 0.11, 0.79, 0.39, 0.17, 0.37, 0.17, 0.26, 0.37, 0.31, 0.19, 0.29, 0.9, 0.35, 0.19, 0.16, 0.07, 0.2, 0.15, 0.65, 0.13, 0.37, 0.5, 0.36, 0.57, 0.46, 0.45, 0.38, 0.21, 0.65, 0.52, 0.2, 0.39, 0.46, 0.29, 0.41, 0.48, 0.59, 0.24, 0.41, 0.52, 0.53, 0.35, 0.4, 0.46, 0.55, 0.27, 0.45, 0.49, 0.27, 0.62, 0.64, 0.46, 0.42, 0.57, 0.37, 0.41, 0.47, 0.36, 0.32, 0.56, 0.77, 0.25, 0.51, 0.52, 0.19, 0.39, 0.21, 1.0, 0.44, 0.42, 0.21, 0.46, 0.5, 0.0, 0.17, 0.54, 0.14, 0.15, 0.52, 0.17, 0.46, 0.9, 0.6, 0.45, 0.47, 0.33, 0.78, 0.56, 0.66, 0.15, 0.2, 0.6, 0.48, 0.28, 0.38, 0.49, 0.42, 0.5, 0.52, 0.45, 0.38, 0.57, 0.42, 0.34, 0.73, 0.53, 0.24, 0.46, 0.8, 0.66, 0.65, 0.65, 0.15, 0.32, 0.36, 0.4, 0.25, 1.0, 0.34, 0.53, 0.33, 0.24, 0.31, 0.4, 0.31, 0.2, 0.27, 0.07, 0.29, 0.19, 0.37, 0.34, 0.33, 0.33, 0.2, 0.37, 0.37, 0.31, 0.46, 0.44, 1.0, 0.48, 0.46, 0.5, 0.38, 0.33, 0.6, 0.51, 0.41, 0.17, 0.22, 0.37, 0.7, 0.58, 0.46, 0.45, 0.11, 0.44, 0.62, 0.39, 0.29, 0.38, 0.0, 0.56, 0.44, 0.56, 0.58, 0.48, 0.41, 0.53, 0.44, 0.22, 0.0, 0.26, 0.53, 0.4, 0.42, 0.59, 0.64, 0.77, 0.55, 0.36, 0.2, 0.56, 0.48, 0.71, 0.62, 0.46, 0.57, 0.3, 0.29, 0.26, 0.31, 0.54, 0.6, 0.35, 0.53, 0.42, 0.5, 0.46, 0.64, 0.55, 0.3, 0.33, 0.34, 0.65, 0.2, 0.47, 0.52, 0.0, 0.28, 0.44, 0.47, 0.29, 0.57, 0.5, 0.45, 0.3, 0.56, 0.72, 0.27, 0.33, 0.51, 0.45, 0.4, 1.0, 0.33, 0.37, 0.28, 0.0, 0.16, 0.38, 0.23, 0.36, 0.18, 0.36, 0.48, 0.27, 0.72, 0.14, 0.24, 0.0, 0.34, 0.28, 0.25, 0.12, 0.71, 0.4, 0.7, 0.4, 0.52, 0.27, 0.26, 0.35, 0.46, 0.68, 0.64, 0.27, 0.53, 0.5, 0.5, 0.0, 0.26, 0.56, 0.33, 0.4, 0.5, 0.66, 0.45, 0.75, 0.65, 0.47, 0.39, 0.59, 0.42, 0.36, 0.2, 0.63, 0.25, 0.51, 0.11, 0.38, 0.28, 0.38, 0.55, 0.3, 0.36, 0.12, 0.5, 0.56, 0.3, 0.43, 0.46, 0.37, 0.4, 0.54, 0.41, 0.38, 0.33, 0.66, 0.26, 0.72, 0.3, 0.55, 0.23, 0.31, 0.34, 0.48, 0.75, 0.23, 0.16, 0.8, 0.34, 0.5, 0.6, 0.39, 0.46, 0.78, 0.52, 0.46, 0.31, 0.65, 0.5, 0.74, 0.42, 0.19, 0.26, 0.31, 0.55, 0.41, 0.77, 0.43, 0.44, 0.44, 0.15, 0.17, 0.4, 0.44, 0.17, 0.35, 0.4, 0.47, 0.37, 0.18, 0.4, 0.38, 0.14, 0.77, 0.72, 0.72, 0.37, 0.13, 0.6, 0.0, 0.48, 0.53, 0.64, 0.47, 0.1, 0.37, 0.14, 0.3, 0.0, 0.41, 0.33, 0.27, 0.48]\n"
     ]
    }
   ],
   "source": [
    "#reformat blueCorner_sig_str_percentage to float\n",
    "for index, row in df.iterrows():\n",
    "    blueCorner_sig = row['blueCorner_sig_str_percentage']\n",
    "    listsig = blueCorner_sig.split('%')\n",
    "    reformatted = float(listsig[0])/100.00\n",
    "    df.loc[index, 'blueCorner_sig_str_percentage'] = reformatted\n",
    "\n",
    "print(df['blueCorner_sig_str_percentage'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>referee</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>billing</th>\n",
       "      <th>redCorner_wins</th>\n",
       "      <th>blueCorner_wins</th>\n",
       "      <th>redCorner_losses</th>\n",
       "      <th>...</th>\n",
       "      <th>blueCorner_height</th>\n",
       "      <th>redCorner_reach</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "      <th>redCorner_sig_str_landed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_landed_per_minute</th>\n",
       "      <th>fightTime</th>\n",
       "      <th>redCorner_sig_str_absorbed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_absorbed_per_minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Pereira</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6' 1\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>6.501706</td>\n",
       "      <td>3.122867</td>\n",
       "      <td>19.533333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pea</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>67\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>70\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Dolidze</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>68\"</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   redCorner  blueCorner  winner  referee  venue  title_fight  billing  \\\n",
       "0          0           2       0      112     50            1        0   \n",
       "1          0           2       2      100     50            1        1   \n",
       "2          0           2       2       11     50            0        2   \n",
       "3          0           2       0      100     50            0        2   \n",
       "4          0           2       2      112     50            0        2   \n",
       "\n",
       "  redCorner_wins blueCorner_wins  redCorner_losses  ...  blueCorner_height  \\\n",
       "0        Pereira              11               NaN  ...              6' 1\"   \n",
       "1           Pea              10               NaN  ...              5' 6\"   \n",
       "2       Bautista              14               NaN  ...              5' 9\"   \n",
       "3        Dolidze              13               NaN  ...              6' 3\"   \n",
       "4             17        Harrison               1.0  ...              5' 8\"   \n",
       "\n",
       "   redCorner_reach  blueCorner_reach  redCorner_stance  blueCorner_stance  \\\n",
       "0              79\"               76\"          Orthodox           Southpaw   \n",
       "1              67\"               69\"          Orthodox           Orthodox   \n",
       "2              70\"               69\"          Orthodox             Switch   \n",
       "3              76\"               81\"          Orthodox           Orthodox   \n",
       "4              68\"               66\"          Orthodox           Southpaw   \n",
       "\n",
       "  redCorner_sig_str_landed_per_minute blueCorner_sig_str_landed_per_minute  \\\n",
       "0                            6.501706                             3.122867   \n",
       "1                            3.680000                             3.680000   \n",
       "2                            3.400000                             3.266667   \n",
       "3                            3.800000                             3.600000   \n",
       "4                            1.600000                             3.666667   \n",
       "\n",
       "   fightTime  redCorner_sig_str_absorbed_per_minute  \\\n",
       "0  19.533333                                    NaN   \n",
       "1  25.000000                                    NaN   \n",
       "2  15.000000                                    NaN   \n",
       "3   5.000000                                    NaN   \n",
       "4  15.000000                                    NaN   \n",
       "\n",
       "  blueCorner_sig_str_absorbed_per_minute  \n",
       "0                                    NaN  \n",
       "1                                    NaN  \n",
       "2                                    NaN  \n",
       "3                                    NaN  \n",
       "4                                    NaN  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding columns redCorner_sig_str_per_minute and blueCorner_sig_str_per_minute\n",
    "df['redCorner_sig_str_absorbed_per_minute'] = float('nan')\n",
    "df['blueCorner_sig_str_absorbed_per_minute'] = float('nan')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#check for nans\n",
    "nan_count = df['blueCorner_sig_str'].isna().sum()\n",
    "print(nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>referee</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>billing</th>\n",
       "      <th>redCorner_wins</th>\n",
       "      <th>blueCorner_wins</th>\n",
       "      <th>redCorner_losses</th>\n",
       "      <th>...</th>\n",
       "      <th>blueCorner_height</th>\n",
       "      <th>redCorner_reach</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "      <th>redCorner_sig_str_landed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_landed_per_minute</th>\n",
       "      <th>fightTime</th>\n",
       "      <th>redCorner_sig_str_absorbed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_absorbed_per_minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Pereira</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6' 1\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>6.501706</td>\n",
       "      <td>3.122867</td>\n",
       "      <td>19.533333</td>\n",
       "      <td>3.122867</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pea</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>67\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>70\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Dolidze</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>68\"</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   redCorner  blueCorner  winner  referee  venue  title_fight  billing  \\\n",
       "0          0           2       0      112     50            1        0   \n",
       "1          0           2       2      100     50            1        1   \n",
       "2          0           2       2       11     50            0        2   \n",
       "3          0           2       0      100     50            0        2   \n",
       "4          0           2       2      112     50            0        2   \n",
       "\n",
       "  redCorner_wins blueCorner_wins  redCorner_losses  ...  blueCorner_height  \\\n",
       "0        Pereira              11               NaN  ...              6' 1\"   \n",
       "1           Pea              10               NaN  ...              5' 6\"   \n",
       "2       Bautista              14               NaN  ...              5' 9\"   \n",
       "3        Dolidze              13               NaN  ...              6' 3\"   \n",
       "4             17        Harrison               1.0  ...              5' 8\"   \n",
       "\n",
       "   redCorner_reach  blueCorner_reach  redCorner_stance  blueCorner_stance  \\\n",
       "0              79\"               76\"          Orthodox           Southpaw   \n",
       "1              67\"               69\"          Orthodox           Orthodox   \n",
       "2              70\"               69\"          Orthodox             Switch   \n",
       "3              76\"               81\"          Orthodox           Orthodox   \n",
       "4              68\"               66\"          Orthodox           Southpaw   \n",
       "\n",
       "  redCorner_sig_str_landed_per_minute blueCorner_sig_str_landed_per_minute  \\\n",
       "0                            6.501706                             3.122867   \n",
       "1                            3.680000                             3.680000   \n",
       "2                            3.400000                             3.266667   \n",
       "3                            3.800000                             3.600000   \n",
       "4                            1.600000                             3.666667   \n",
       "\n",
       "   fightTime  redCorner_sig_str_absorbed_per_minute  \\\n",
       "0  19.533333                               3.122867   \n",
       "1  25.000000                               3.680000   \n",
       "2  15.000000                               3.266667   \n",
       "3   5.000000                               3.600000   \n",
       "4  15.000000                               3.666667   \n",
       "\n",
       "  blueCorner_sig_str_absorbed_per_minute  \n",
       "0                                    NaN  \n",
       "1                                    NaN  \n",
       "2                                    NaN  \n",
       "3                                    NaN  \n",
       "4                                    NaN  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#May not use this value as it is linearly dependent with sig_strikes_landed_per_min, will see during testing phase\n",
    "#Need to round it to two dec places and test that too\n",
    "for index, row in df.iterrows():\n",
    "    totals = row['blueCorner_sig_str'].split(' ')\n",
    "    landedByOpp = float(totals[0])\n",
    "    fightTime = float(row['fightTime'])\n",
    "    absorbed_per_min = landedByOpp/fightTime\n",
    "    df.loc[index, 'redCorner_sig_str_absorbed_per_minute'] = absorbed_per_min\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#check for nans\n",
    "nan_count = df['redCorner_sig_str'].isna().sum()\n",
    "print(nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>referee</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>billing</th>\n",
       "      <th>redCorner_wins</th>\n",
       "      <th>blueCorner_wins</th>\n",
       "      <th>redCorner_losses</th>\n",
       "      <th>...</th>\n",
       "      <th>blueCorner_height</th>\n",
       "      <th>redCorner_reach</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "      <th>redCorner_sig_str_landed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_landed_per_minute</th>\n",
       "      <th>fightTime</th>\n",
       "      <th>redCorner_sig_str_absorbed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_absorbed_per_minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Pereira</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6' 1\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>6.501706</td>\n",
       "      <td>3.122867</td>\n",
       "      <td>19.533333</td>\n",
       "      <td>3.122867</td>\n",
       "      <td>6.501706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pea</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>67\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>3.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>70\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>3.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Dolidze</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>68\"</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   redCorner  blueCorner  winner  referee  venue  title_fight  billing  \\\n",
       "0          0           2       0      112     50            1        0   \n",
       "1          0           2       2      100     50            1        1   \n",
       "2          0           2       2       11     50            0        2   \n",
       "3          0           2       0      100     50            0        2   \n",
       "4          0           2       2      112     50            0        2   \n",
       "\n",
       "  redCorner_wins blueCorner_wins  redCorner_losses  ...  blueCorner_height  \\\n",
       "0        Pereira              11               NaN  ...              6' 1\"   \n",
       "1           Pea              10               NaN  ...              5' 6\"   \n",
       "2       Bautista              14               NaN  ...              5' 9\"   \n",
       "3        Dolidze              13               NaN  ...              6' 3\"   \n",
       "4             17        Harrison               1.0  ...              5' 8\"   \n",
       "\n",
       "   redCorner_reach  blueCorner_reach  redCorner_stance  blueCorner_stance  \\\n",
       "0              79\"               76\"          Orthodox           Southpaw   \n",
       "1              67\"               69\"          Orthodox           Orthodox   \n",
       "2              70\"               69\"          Orthodox             Switch   \n",
       "3              76\"               81\"          Orthodox           Orthodox   \n",
       "4              68\"               66\"          Orthodox           Southpaw   \n",
       "\n",
       "  redCorner_sig_str_landed_per_minute blueCorner_sig_str_landed_per_minute  \\\n",
       "0                            6.501706                             3.122867   \n",
       "1                            3.680000                             3.680000   \n",
       "2                            3.400000                             3.266667   \n",
       "3                            3.800000                             3.600000   \n",
       "4                            1.600000                             3.666667   \n",
       "\n",
       "   fightTime  redCorner_sig_str_absorbed_per_minute  \\\n",
       "0  19.533333                               3.122867   \n",
       "1  25.000000                               3.680000   \n",
       "2  15.000000                               3.266667   \n",
       "3   5.000000                               3.600000   \n",
       "4  15.000000                               3.666667   \n",
       "\n",
       "  blueCorner_sig_str_absorbed_per_minute  \n",
       "0                               6.501706  \n",
       "1                               3.680000  \n",
       "2                               3.400000  \n",
       "3                               3.800000  \n",
       "4                               1.600000  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#May not use this value as it is linearly dependent with sig_strikes_landed_per_min, will see during testing phase\n",
    "#Need to round it to two dec places and test that too\n",
    "for index, row in df.iterrows():\n",
    "    totals = row['redCorner_sig_str'].split(' ')\n",
    "    landedByOpp = float(totals[0])\n",
    "    fightTime = float(row['fightTime'])\n",
    "    absorbed_per_min = landedByOpp/fightTime\n",
    "    df.loc[index, 'blueCorner_sig_str_absorbed_per_minute'] = absorbed_per_min\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>referee</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>billing</th>\n",
       "      <th>redCorner_wins</th>\n",
       "      <th>blueCorner_wins</th>\n",
       "      <th>redCorner_losses</th>\n",
       "      <th>...</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "      <th>redCorner_sig_str_landed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_landed_per_minute</th>\n",
       "      <th>fightTime</th>\n",
       "      <th>redCorner_sig_str_absorbed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_absorbed_per_minute</th>\n",
       "      <th>redCorner_sig_str_defense</th>\n",
       "      <th>blueCorner_sig_str_defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Pereira</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>6.501706</td>\n",
       "      <td>3.122867</td>\n",
       "      <td>19.533333</td>\n",
       "      <td>3.122867</td>\n",
       "      <td>6.501706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pea</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Dolidze</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   redCorner  blueCorner  winner  referee  venue  title_fight  billing  \\\n",
       "0          0           2       0      112     50            1        0   \n",
       "1          0           2       2      100     50            1        1   \n",
       "2          0           2       2       11     50            0        2   \n",
       "3          0           2       0      100     50            0        2   \n",
       "4          0           2       2      112     50            0        2   \n",
       "\n",
       "  redCorner_wins blueCorner_wins  redCorner_losses  ...  blueCorner_reach  \\\n",
       "0        Pereira              11               NaN  ...               76\"   \n",
       "1           Pea              10               NaN  ...               69\"   \n",
       "2       Bautista              14               NaN  ...               69\"   \n",
       "3        Dolidze              13               NaN  ...               81\"   \n",
       "4             17        Harrison               1.0  ...               66\"   \n",
       "\n",
       "   redCorner_stance  blueCorner_stance  redCorner_sig_str_landed_per_minute  \\\n",
       "0          Orthodox           Southpaw                             6.501706   \n",
       "1          Orthodox           Orthodox                             3.680000   \n",
       "2          Orthodox             Switch                             3.400000   \n",
       "3          Orthodox           Orthodox                             3.800000   \n",
       "4          Orthodox           Southpaw                             1.600000   \n",
       "\n",
       "   blueCorner_sig_str_landed_per_minute  fightTime  \\\n",
       "0                              3.122867  19.533333   \n",
       "1                              3.680000  25.000000   \n",
       "2                              3.266667  15.000000   \n",
       "3                              3.600000   5.000000   \n",
       "4                              3.666667  15.000000   \n",
       "\n",
       "  redCorner_sig_str_absorbed_per_minute  \\\n",
       "0                              3.122867   \n",
       "1                              3.680000   \n",
       "2                              3.266667   \n",
       "3                              3.600000   \n",
       "4                              3.666667   \n",
       "\n",
       "   blueCorner_sig_str_absorbed_per_minute  redCorner_sig_str_defense  \\\n",
       "0                                6.501706                        NaN   \n",
       "1                                3.680000                        NaN   \n",
       "2                                3.400000                        NaN   \n",
       "3                                3.800000                        NaN   \n",
       "4                                1.600000                        NaN   \n",
       "\n",
       "  blueCorner_sig_str_defense  \n",
       "0                        NaN  \n",
       "1                        NaN  \n",
       "2                        NaN  \n",
       "3                        NaN  \n",
       "4                        NaN  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding columns redCorner_sig_str_defense and blueCorner_sig_str_defense\n",
    "df['redCorner_sig_str_defense'] = float('nan')\n",
    "df['blueCorner_sig_str_defense'] = float('nan')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>referee</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>billing</th>\n",
       "      <th>redCorner_wins</th>\n",
       "      <th>blueCorner_wins</th>\n",
       "      <th>redCorner_losses</th>\n",
       "      <th>...</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "      <th>redCorner_sig_str_landed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_landed_per_minute</th>\n",
       "      <th>fightTime</th>\n",
       "      <th>redCorner_sig_str_absorbed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_absorbed_per_minute</th>\n",
       "      <th>redCorner_sig_str_defense</th>\n",
       "      <th>blueCorner_sig_str_defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Pereira</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>6.501706</td>\n",
       "      <td>3.122867</td>\n",
       "      <td>19.533333</td>\n",
       "      <td>3.122867</td>\n",
       "      <td>6.501706</td>\n",
       "      <td>0.680628</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pea</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.654930</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Dolidze</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.414894</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   redCorner  blueCorner  winner  referee  venue  title_fight  billing  \\\n",
       "0          0           2       0      112     50            1        0   \n",
       "1          0           2       2      100     50            1        1   \n",
       "2          0           2       2       11     50            0        2   \n",
       "3          0           2       0      100     50            0        2   \n",
       "4          0           2       2      112     50            0        2   \n",
       "\n",
       "  redCorner_wins blueCorner_wins  redCorner_losses  ...  blueCorner_reach  \\\n",
       "0        Pereira              11               NaN  ...               76\"   \n",
       "1           Pea              10               NaN  ...               69\"   \n",
       "2       Bautista              14               NaN  ...               69\"   \n",
       "3        Dolidze              13               NaN  ...               81\"   \n",
       "4             17        Harrison               1.0  ...               66\"   \n",
       "\n",
       "   redCorner_stance  blueCorner_stance  redCorner_sig_str_landed_per_minute  \\\n",
       "0          Orthodox           Southpaw                             6.501706   \n",
       "1          Orthodox           Orthodox                             3.680000   \n",
       "2          Orthodox             Switch                             3.400000   \n",
       "3          Orthodox           Orthodox                             3.800000   \n",
       "4          Orthodox           Southpaw                             1.600000   \n",
       "\n",
       "   blueCorner_sig_str_landed_per_minute  fightTime  \\\n",
       "0                              3.122867  19.533333   \n",
       "1                              3.680000  25.000000   \n",
       "2                              3.266667  15.000000   \n",
       "3                              3.600000   5.000000   \n",
       "4                              3.666667  15.000000   \n",
       "\n",
       "  redCorner_sig_str_absorbed_per_minute  \\\n",
       "0                              3.122867   \n",
       "1                              3.680000   \n",
       "2                              3.266667   \n",
       "3                              3.600000   \n",
       "4                              3.666667   \n",
       "\n",
       "   blueCorner_sig_str_absorbed_per_minute  redCorner_sig_str_defense  \\\n",
       "0                                6.501706                   0.680628   \n",
       "1                                3.680000                   0.646154   \n",
       "2                                3.400000                   0.654930   \n",
       "3                                3.800000                   0.357143   \n",
       "4                                1.600000                   0.414894   \n",
       "\n",
       "  blueCorner_sig_str_defense  \n",
       "0                        NaN  \n",
       "1                        NaN  \n",
       "2                        NaN  \n",
       "3                        NaN  \n",
       "4                        NaN  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate redCorner sig_str_defense\n",
    "for index, row in df.iterrows():\n",
    "    totals = row['blueCorner_sig_str'].split(' ')\n",
    "    missed = float(totals[2]) - float(totals[0])\n",
    "    try:\n",
    "        sig_str_defense = float(missed/float(totals[2]))\n",
    "    except:\n",
    "        #if no strikes were attempted then defense is 100%\n",
    "        sig_str_defense = 1\n",
    "    df.loc[index, 'redCorner_sig_str_defense'] = sig_str_defense\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>referee</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>billing</th>\n",
       "      <th>redCorner_wins</th>\n",
       "      <th>blueCorner_wins</th>\n",
       "      <th>redCorner_losses</th>\n",
       "      <th>...</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "      <th>redCorner_sig_str_landed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_landed_per_minute</th>\n",
       "      <th>fightTime</th>\n",
       "      <th>redCorner_sig_str_absorbed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_absorbed_per_minute</th>\n",
       "      <th>redCorner_sig_str_defense</th>\n",
       "      <th>blueCorner_sig_str_defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Pereira</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>6.501706</td>\n",
       "      <td>3.122867</td>\n",
       "      <td>19.533333</td>\n",
       "      <td>3.122867</td>\n",
       "      <td>6.501706</td>\n",
       "      <td>0.680628</td>\n",
       "      <td>0.392344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pea</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.709779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.654930</td>\n",
       "      <td>0.564103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Dolidze</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.424242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.414894</td>\n",
       "      <td>0.606557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   redCorner  blueCorner  winner  referee  venue  title_fight  billing  \\\n",
       "0          0           2       0      112     50            1        0   \n",
       "1          0           2       2      100     50            1        1   \n",
       "2          0           2       2       11     50            0        2   \n",
       "3          0           2       0      100     50            0        2   \n",
       "4          0           2       2      112     50            0        2   \n",
       "\n",
       "  redCorner_wins blueCorner_wins  redCorner_losses  ...  blueCorner_reach  \\\n",
       "0        Pereira              11               NaN  ...               76\"   \n",
       "1           Pea              10               NaN  ...               69\"   \n",
       "2       Bautista              14               NaN  ...               69\"   \n",
       "3        Dolidze              13               NaN  ...               81\"   \n",
       "4             17        Harrison               1.0  ...               66\"   \n",
       "\n",
       "   redCorner_stance  blueCorner_stance  redCorner_sig_str_landed_per_minute  \\\n",
       "0          Orthodox           Southpaw                             6.501706   \n",
       "1          Orthodox           Orthodox                             3.680000   \n",
       "2          Orthodox             Switch                             3.400000   \n",
       "3          Orthodox           Orthodox                             3.800000   \n",
       "4          Orthodox           Southpaw                             1.600000   \n",
       "\n",
       "   blueCorner_sig_str_landed_per_minute  fightTime  \\\n",
       "0                              3.122867  19.533333   \n",
       "1                              3.680000  25.000000   \n",
       "2                              3.266667  15.000000   \n",
       "3                              3.600000   5.000000   \n",
       "4                              3.666667  15.000000   \n",
       "\n",
       "  redCorner_sig_str_absorbed_per_minute  \\\n",
       "0                              3.122867   \n",
       "1                              3.680000   \n",
       "2                              3.266667   \n",
       "3                              3.600000   \n",
       "4                              3.666667   \n",
       "\n",
       "   blueCorner_sig_str_absorbed_per_minute  redCorner_sig_str_defense  \\\n",
       "0                                6.501706                   0.680628   \n",
       "1                                3.680000                   0.646154   \n",
       "2                                3.400000                   0.654930   \n",
       "3                                3.800000                   0.357143   \n",
       "4                                1.600000                   0.414894   \n",
       "\n",
       "  blueCorner_sig_str_defense  \n",
       "0                   0.392344  \n",
       "1                   0.709779  \n",
       "2                   0.564103  \n",
       "3                   0.424242  \n",
       "4                   0.606557  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate blueCorner sig_str_defense\n",
    "for index, row in df.iterrows():\n",
    "    totals = row['redCorner_sig_str'].split(' ')\n",
    "    missed = float(totals[2]) - float(totals[0])\n",
    "    try:\n",
    "        sig_str_defense = float(missed/float(totals[2]))\n",
    "    except:\n",
    "        #if no strikes were attempted then defense is 100%\n",
    "        sig_str_defense = 1.0\n",
    "    df.loc[index, 'blueCorner_sig_str_defense'] = sig_str_defense\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix divide by zero errors\n",
    "df['redCorner_takedown_percentage'].fillna('0%', inplace=True)\n",
    "df['blueCorner_takedown_percentage'].fillna('0%', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>referee</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>billing</th>\n",
       "      <th>redCorner_wins</th>\n",
       "      <th>blueCorner_wins</th>\n",
       "      <th>redCorner_losses</th>\n",
       "      <th>...</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "      <th>redCorner_sig_str_landed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_landed_per_minute</th>\n",
       "      <th>fightTime</th>\n",
       "      <th>redCorner_sig_str_absorbed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_absorbed_per_minute</th>\n",
       "      <th>redCorner_sig_str_defense</th>\n",
       "      <th>blueCorner_sig_str_defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Pereira</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>6.501706</td>\n",
       "      <td>3.122867</td>\n",
       "      <td>19.533333</td>\n",
       "      <td>3.122867</td>\n",
       "      <td>6.501706</td>\n",
       "      <td>0.680628</td>\n",
       "      <td>0.392344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pea</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.709779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.654930</td>\n",
       "      <td>0.564103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Dolidze</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.424242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.414894</td>\n",
       "      <td>0.606557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   redCorner  blueCorner  winner  referee  venue  title_fight  billing  \\\n",
       "0          0           2       0      112     50            1        0   \n",
       "1          0           2       2      100     50            1        1   \n",
       "2          0           2       2       11     50            0        2   \n",
       "3          0           2       0      100     50            0        2   \n",
       "4          0           2       2      112     50            0        2   \n",
       "\n",
       "  redCorner_wins blueCorner_wins  redCorner_losses  ...  blueCorner_reach  \\\n",
       "0        Pereira              11               NaN  ...               76\"   \n",
       "1           Pea              10               NaN  ...               69\"   \n",
       "2       Bautista              14               NaN  ...               69\"   \n",
       "3        Dolidze              13               NaN  ...               81\"   \n",
       "4             17        Harrison               1.0  ...               66\"   \n",
       "\n",
       "   redCorner_stance  blueCorner_stance  redCorner_sig_str_landed_per_minute  \\\n",
       "0          Orthodox           Southpaw                             6.501706   \n",
       "1          Orthodox           Orthodox                             3.680000   \n",
       "2          Orthodox             Switch                             3.400000   \n",
       "3          Orthodox           Orthodox                             3.800000   \n",
       "4          Orthodox           Southpaw                             1.600000   \n",
       "\n",
       "   blueCorner_sig_str_landed_per_minute  fightTime  \\\n",
       "0                              3.122867  19.533333   \n",
       "1                              3.680000  25.000000   \n",
       "2                              3.266667  15.000000   \n",
       "3                              3.600000   5.000000   \n",
       "4                              3.666667  15.000000   \n",
       "\n",
       "  redCorner_sig_str_absorbed_per_minute  \\\n",
       "0                              3.122867   \n",
       "1                              3.680000   \n",
       "2                              3.266667   \n",
       "3                              3.600000   \n",
       "4                              3.666667   \n",
       "\n",
       "   blueCorner_sig_str_absorbed_per_minute  redCorner_sig_str_defense  \\\n",
       "0                                6.501706                   0.680628   \n",
       "1                                3.680000                   0.646154   \n",
       "2                                3.400000                   0.654930   \n",
       "3                                3.800000                   0.357143   \n",
       "4                                1.600000                   0.414894   \n",
       "\n",
       "  blueCorner_sig_str_defense  \n",
       "0                   0.392344  \n",
       "1                   0.709779  \n",
       "2                   0.564103  \n",
       "3                   0.424242  \n",
       "4                   0.606557  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#format redCorner_takedown_percentage as float\n",
    "for index, row in df.iterrows():\n",
    "    takedown_percent = row['redCorner_takedown_percentage'].split('%')\n",
    "    takedown_percent = float(takedown_percent[0])\n",
    "    takedown_float = takedown_percent/100\n",
    "    df.at[index, 'redCorner_takedown_percentage'] = takedown_float\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>referee</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>billing</th>\n",
       "      <th>redCorner_wins</th>\n",
       "      <th>blueCorner_wins</th>\n",
       "      <th>redCorner_losses</th>\n",
       "      <th>...</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "      <th>redCorner_sig_str_landed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_landed_per_minute</th>\n",
       "      <th>fightTime</th>\n",
       "      <th>redCorner_sig_str_absorbed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_absorbed_per_minute</th>\n",
       "      <th>redCorner_sig_str_defense</th>\n",
       "      <th>blueCorner_sig_str_defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Pereira</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>6.501706</td>\n",
       "      <td>3.122867</td>\n",
       "      <td>19.533333</td>\n",
       "      <td>3.122867</td>\n",
       "      <td>6.501706</td>\n",
       "      <td>0.680628</td>\n",
       "      <td>0.392344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pea</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.709779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.654930</td>\n",
       "      <td>0.564103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Dolidze</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.424242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.414894</td>\n",
       "      <td>0.606557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   redCorner  blueCorner  winner  referee  venue  title_fight  billing  \\\n",
       "0          0           2       0      112     50            1        0   \n",
       "1          0           2       2      100     50            1        1   \n",
       "2          0           2       2       11     50            0        2   \n",
       "3          0           2       0      100     50            0        2   \n",
       "4          0           2       2      112     50            0        2   \n",
       "\n",
       "  redCorner_wins blueCorner_wins  redCorner_losses  ...  blueCorner_reach  \\\n",
       "0        Pereira              11               NaN  ...               76\"   \n",
       "1           Pea              10               NaN  ...               69\"   \n",
       "2       Bautista              14               NaN  ...               69\"   \n",
       "3        Dolidze              13               NaN  ...               81\"   \n",
       "4             17        Harrison               1.0  ...               66\"   \n",
       "\n",
       "   redCorner_stance  blueCorner_stance  redCorner_sig_str_landed_per_minute  \\\n",
       "0          Orthodox           Southpaw                             6.501706   \n",
       "1          Orthodox           Orthodox                             3.680000   \n",
       "2          Orthodox             Switch                             3.400000   \n",
       "3          Orthodox           Orthodox                             3.800000   \n",
       "4          Orthodox           Southpaw                             1.600000   \n",
       "\n",
       "   blueCorner_sig_str_landed_per_minute  fightTime  \\\n",
       "0                              3.122867  19.533333   \n",
       "1                              3.680000  25.000000   \n",
       "2                              3.266667  15.000000   \n",
       "3                              3.600000   5.000000   \n",
       "4                              3.666667  15.000000   \n",
       "\n",
       "  redCorner_sig_str_absorbed_per_minute  \\\n",
       "0                              3.122867   \n",
       "1                              3.680000   \n",
       "2                              3.266667   \n",
       "3                              3.600000   \n",
       "4                              3.666667   \n",
       "\n",
       "   blueCorner_sig_str_absorbed_per_minute  redCorner_sig_str_defense  \\\n",
       "0                                6.501706                   0.680628   \n",
       "1                                3.680000                   0.646154   \n",
       "2                                3.400000                   0.654930   \n",
       "3                                3.800000                   0.357143   \n",
       "4                                1.600000                   0.414894   \n",
       "\n",
       "  blueCorner_sig_str_defense  \n",
       "0                   0.392344  \n",
       "1                   0.709779  \n",
       "2                   0.564103  \n",
       "3                   0.424242  \n",
       "4                   0.606557  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#format blueCorner_takedown_percentage as float\n",
    "for index, row in df.iterrows():\n",
    "    takedown_percent = row['blueCorner_takedown_percentage'].split('%')\n",
    "    takedown_percent = float(takedown_percent[0])\n",
    "    takedown_float = takedown_percent/100\n",
    "    df.at[index, 'blueCorner_takedown_percentage'] = takedown_float\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>referee</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>billing</th>\n",
       "      <th>redCorner_wins</th>\n",
       "      <th>blueCorner_wins</th>\n",
       "      <th>redCorner_losses</th>\n",
       "      <th>...</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "      <th>redCorner_sig_str_landed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_landed_per_minute</th>\n",
       "      <th>fightTime</th>\n",
       "      <th>redCorner_sig_str_absorbed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_absorbed_per_minute</th>\n",
       "      <th>redCorner_sig_str_defense</th>\n",
       "      <th>blueCorner_sig_str_defense</th>\n",
       "      <th>redCorner_takedown_defense</th>\n",
       "      <th>blueCorner_takedown_defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Pereira</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>6.501706</td>\n",
       "      <td>3.122867</td>\n",
       "      <td>19.533333</td>\n",
       "      <td>3.122867</td>\n",
       "      <td>6.501706</td>\n",
       "      <td>0.680628</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pea</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.709779</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Switch</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.654930</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Dolidze</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.414894</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   redCorner  blueCorner  winner  referee  venue  title_fight  billing  \\\n",
       "0          0           2       0      112     50            1        0   \n",
       "1          0           2       2      100     50            1        1   \n",
       "2          0           2       2       11     50            0        2   \n",
       "3          0           2       0      100     50            0        2   \n",
       "4          0           2       2      112     50            0        2   \n",
       "\n",
       "  redCorner_wins blueCorner_wins  redCorner_losses  ...  blueCorner_stance  \\\n",
       "0        Pereira              11               NaN  ...           Southpaw   \n",
       "1           Pea              10               NaN  ...           Orthodox   \n",
       "2       Bautista              14               NaN  ...             Switch   \n",
       "3        Dolidze              13               NaN  ...           Orthodox   \n",
       "4             17        Harrison               1.0  ...           Southpaw   \n",
       "\n",
       "   redCorner_sig_str_landed_per_minute  blueCorner_sig_str_landed_per_minute  \\\n",
       "0                             6.501706                              3.122867   \n",
       "1                             3.680000                              3.680000   \n",
       "2                             3.400000                              3.266667   \n",
       "3                             3.800000                              3.600000   \n",
       "4                             1.600000                              3.666667   \n",
       "\n",
       "   fightTime  redCorner_sig_str_absorbed_per_minute  \\\n",
       "0  19.533333                               3.122867   \n",
       "1  25.000000                               3.680000   \n",
       "2  15.000000                               3.266667   \n",
       "3   5.000000                               3.600000   \n",
       "4  15.000000                               3.666667   \n",
       "\n",
       "  blueCorner_sig_str_absorbed_per_minute redCorner_sig_str_defense  \\\n",
       "0                               6.501706                  0.680628   \n",
       "1                               3.680000                  0.646154   \n",
       "2                               3.400000                  0.654930   \n",
       "3                               3.800000                  0.357143   \n",
       "4                               1.600000                  0.414894   \n",
       "\n",
       "   blueCorner_sig_str_defense  redCorner_takedown_defense  \\\n",
       "0                    0.392344                         NaN   \n",
       "1                    0.709779                         NaN   \n",
       "2                    0.564103                         NaN   \n",
       "3                    0.424242                         NaN   \n",
       "4                    0.606557                         NaN   \n",
       "\n",
       "  blueCorner_takedown_defense  \n",
       "0                         NaN  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3                         NaN  \n",
       "4                         NaN  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding columns redCorner_takedown_defense and blueCorner_takedown_defense\n",
    "df['redCorner_takedown_defense'] = float('nan')\n",
    "df['blueCorner_takedown_defense'] = float('nan')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>referee</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>billing</th>\n",
       "      <th>redCorner_wins</th>\n",
       "      <th>blueCorner_wins</th>\n",
       "      <th>redCorner_losses</th>\n",
       "      <th>...</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "      <th>redCorner_sig_str_landed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_landed_per_minute</th>\n",
       "      <th>fightTime</th>\n",
       "      <th>redCorner_sig_str_absorbed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_absorbed_per_minute</th>\n",
       "      <th>redCorner_sig_str_defense</th>\n",
       "      <th>blueCorner_sig_str_defense</th>\n",
       "      <th>redCorner_takedown_defense</th>\n",
       "      <th>blueCorner_takedown_defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Pereira</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>6.501706</td>\n",
       "      <td>3.122867</td>\n",
       "      <td>19.533333</td>\n",
       "      <td>3.122867</td>\n",
       "      <td>6.501706</td>\n",
       "      <td>0.680628</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pea</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.709779</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Switch</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.654930</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Dolidze</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.414894</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   redCorner  blueCorner  winner  referee  venue  title_fight  billing  \\\n",
       "0          0           2       0      112     50            1        0   \n",
       "1          0           2       2      100     50            1        1   \n",
       "2          0           2       2       11     50            0        2   \n",
       "3          0           2       0      100     50            0        2   \n",
       "4          0           2       2      112     50            0        2   \n",
       "\n",
       "  redCorner_wins blueCorner_wins  redCorner_losses  ...  blueCorner_stance  \\\n",
       "0        Pereira              11               NaN  ...           Southpaw   \n",
       "1           Pea              10               NaN  ...           Orthodox   \n",
       "2       Bautista              14               NaN  ...             Switch   \n",
       "3        Dolidze              13               NaN  ...           Orthodox   \n",
       "4             17        Harrison               1.0  ...           Southpaw   \n",
       "\n",
       "   redCorner_sig_str_landed_per_minute  blueCorner_sig_str_landed_per_minute  \\\n",
       "0                             6.501706                              3.122867   \n",
       "1                             3.680000                              3.680000   \n",
       "2                             3.400000                              3.266667   \n",
       "3                             3.800000                              3.600000   \n",
       "4                             1.600000                              3.666667   \n",
       "\n",
       "   fightTime  redCorner_sig_str_absorbed_per_minute  \\\n",
       "0  19.533333                               3.122867   \n",
       "1  25.000000                               3.680000   \n",
       "2  15.000000                               3.266667   \n",
       "3   5.000000                               3.600000   \n",
       "4  15.000000                               3.666667   \n",
       "\n",
       "  blueCorner_sig_str_absorbed_per_minute redCorner_sig_str_defense  \\\n",
       "0                               6.501706                  0.680628   \n",
       "1                               3.680000                  0.646154   \n",
       "2                               3.400000                  0.654930   \n",
       "3                               3.800000                  0.357143   \n",
       "4                               1.600000                  0.414894   \n",
       "\n",
       "   blueCorner_sig_str_defense  redCorner_takedown_defense  \\\n",
       "0                    0.392344                    1.000000   \n",
       "1                    0.709779                    0.333333   \n",
       "2                    0.564103                    1.000000   \n",
       "3                    0.424242                    1.000000   \n",
       "4                    0.606557                    0.750000   \n",
       "\n",
       "  blueCorner_takedown_defense  \n",
       "0                         NaN  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3                         NaN  \n",
       "4                         NaN  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#redCorner_takedown_defense\n",
    "#May not use this value as it is linearly dependent with takedown_percentage, will see during testing phase\n",
    "for index, row in df.iterrows():\n",
    "    totals = row['blueCorner_takedowns'].split(' ')\n",
    "    missedByOpp = float(totals[2]) - float(totals[0])\n",
    "    attempted = float(totals[2])\n",
    "    try:\n",
    "        defended = missedByOpp/attempted\n",
    "    except:\n",
    "        #if zero were attempted defense is 100%\n",
    "        defended = 1.0\n",
    "    df.loc[index, 'redCorner_takedown_defense'] = defended\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>referee</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>billing</th>\n",
       "      <th>redCorner_wins</th>\n",
       "      <th>blueCorner_wins</th>\n",
       "      <th>redCorner_losses</th>\n",
       "      <th>...</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "      <th>redCorner_sig_str_landed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_landed_per_minute</th>\n",
       "      <th>fightTime</th>\n",
       "      <th>redCorner_sig_str_absorbed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_absorbed_per_minute</th>\n",
       "      <th>redCorner_sig_str_defense</th>\n",
       "      <th>blueCorner_sig_str_defense</th>\n",
       "      <th>redCorner_takedown_defense</th>\n",
       "      <th>blueCorner_takedown_defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Pereira</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>6.501706</td>\n",
       "      <td>3.122867</td>\n",
       "      <td>19.533333</td>\n",
       "      <td>3.122867</td>\n",
       "      <td>6.501706</td>\n",
       "      <td>0.680628</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pea</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>3.680000</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.709779</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Switch</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.654930</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Dolidze</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.414894</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   redCorner  blueCorner  winner  referee  venue  title_fight  billing  \\\n",
       "0          0           2       0      112     50            1        0   \n",
       "1          0           2       2      100     50            1        1   \n",
       "2          0           2       2       11     50            0        2   \n",
       "3          0           2       0      100     50            0        2   \n",
       "4          0           2       2      112     50            0        2   \n",
       "\n",
       "  redCorner_wins blueCorner_wins  redCorner_losses  ...  blueCorner_stance  \\\n",
       "0        Pereira              11               NaN  ...           Southpaw   \n",
       "1           Pea              10               NaN  ...           Orthodox   \n",
       "2       Bautista              14               NaN  ...             Switch   \n",
       "3        Dolidze              13               NaN  ...           Orthodox   \n",
       "4             17        Harrison               1.0  ...           Southpaw   \n",
       "\n",
       "   redCorner_sig_str_landed_per_minute  blueCorner_sig_str_landed_per_minute  \\\n",
       "0                             6.501706                              3.122867   \n",
       "1                             3.680000                              3.680000   \n",
       "2                             3.400000                              3.266667   \n",
       "3                             3.800000                              3.600000   \n",
       "4                             1.600000                              3.666667   \n",
       "\n",
       "   fightTime  redCorner_sig_str_absorbed_per_minute  \\\n",
       "0  19.533333                               3.122867   \n",
       "1  25.000000                               3.680000   \n",
       "2  15.000000                               3.266667   \n",
       "3   5.000000                               3.600000   \n",
       "4  15.000000                               3.666667   \n",
       "\n",
       "  blueCorner_sig_str_absorbed_per_minute redCorner_sig_str_defense  \\\n",
       "0                               6.501706                  0.680628   \n",
       "1                               3.680000                  0.646154   \n",
       "2                               3.400000                  0.654930   \n",
       "3                               3.800000                  0.357143   \n",
       "4                               1.600000                  0.414894   \n",
       "\n",
       "   blueCorner_sig_str_defense  redCorner_takedown_defense  \\\n",
       "0                    0.392344                    1.000000   \n",
       "1                    0.709779                    0.333333   \n",
       "2                    0.564103                    1.000000   \n",
       "3                    0.424242                    1.000000   \n",
       "4                    0.606557                    0.750000   \n",
       "\n",
       "  blueCorner_takedown_defense  \n",
       "0                         1.0  \n",
       "1                         1.0  \n",
       "2                         1.0  \n",
       "3                         0.0  \n",
       "4                         1.0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#blueCorner_takedown_defense\n",
    "#May not use this value as it is linearly dependent with takedown_percentage, will see during testing phase\n",
    "for index, row in df.iterrows():\n",
    "    totals = row['redCorner_takedowns'].split(' ')\n",
    "    missedByOpp = float(totals[2]) - float(totals[0])\n",
    "    attempted = float(totals[2])\n",
    "    try:\n",
    "        defended = missedByOpp/attempted\n",
    "    except:\n",
    "        #if zero were attempted defense is 100%\n",
    "        defended = 1.0\n",
    "    df.loc[index, 'blueCorner_takedown_defense'] = defended\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 4.0, 3.0, 2.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 4.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 2.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 3.0, 2.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 5.0, 3.0, 5.0, 2.0, 1.0, 0.0, 2.0, 6.0, 6.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 5.0, 1.0, 0.0, 5.0, 0.0, 0.0, 5.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 6.0, 1.0, 0.0, 0.0, 5.0, 0.0, 1.0, 0.0, 2.0, 0.0, 6.0, 1.0, 3.0, 0.0, 1.0, 4.0, 0.0, 3.0, 0.0, 3.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 9.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 5.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 6.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 6.0, 0.0, 2.0, 0.0, 2.0, 1.0, 4.0, 6.0, 1.0, 9.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 7.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 4.0, 0.0, 0.0, 2.0, 7.0, 2.0, 0.0, 1.0, 11.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 5.0, 0.0, 5.0, 2.0, 0.0, 1.0, 2.0, 3.0, 3.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 0.0, 7.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 5.0, 3.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 4.0, 3.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 4.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 5.0, 0.0, 0.0, 1.0, 2.0, 8.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 4.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 4.0, 0.0, 3.0, 2.0, 0.0, 6.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 5.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 3.0, 5.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 5.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 5.0, 1.0, 0.0, 0.0, 0.0, 6.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 6.0, 0.0, 4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 8.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 4.0, 4.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 13.0, 3.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 3.0, 0.0, 7.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 4.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 0.0, 1.0, 2.0, 1.0, 4.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 3.0, 1.0, 1.0, 6.0, 0.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 6.0, 1.0, 1.0, 3.0, 0.0, 3.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 4.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 11.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 4.0, 6.0, 0.0, 0.0, 0.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 4.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 4.0, 1.0, 5.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 5.0, 0.0, 4.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 3.0, 3.0, 7.0, 8.0, 5.0, 0.0, 0.0, 2.0, 0.0, 5.0, 2.0, 4.0, 0.0, 4.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 4.0, 4.0, 0.0, 3.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 6.0, 2.0, 0.0, 0.0, 3.0, 4.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 0.0, 7.0, 1.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 6.0, 0.0, 2.0, 6.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 4.0, 0.0, 2.0, 6.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 8.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 5.0, 0.0, 1.0, 2.0, 5.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 5.0, 6.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 6.0, 3.0, 0.0, 1.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 5.0, 3.0, 0.0, 2.0, 0.0, 2.0, 0.0, 9.0, 3.0, 3.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 8.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 3.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 2.0, 5.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 1.0, 1.0, 6.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 8.0, 1.0, 3.0, 12.0, 0.0, 0.0, 4.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 5.0, 3.0, 3.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 1.0, 1.0, 0.0, 2.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 5.0, 4.0, 3.0, 1.0, 0.0, 9.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 6.0, 0.0, 2.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 1.0, 0.0, 8.0, 2.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 1.0, 11.0, 4.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 0.0, 1.0, 0.0, 1.0, 3.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 6.0, 5.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 0.0, 5.0, 0.0, 1.0, 1.0, 0.0, 0.0, 6.0, 4.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 2.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 1.0, 2.0, 4.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 11.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 5.0, 6.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 6.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 5.0, 7.0, 1.0, 5.0, 4.0, 2.0, 3.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 5.0, 0.0, 4.0, 1.0, 3.0, 5.0, 0.0, 1.0, 0.0, 0.0, 8.0, 5.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 7.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 5.0, 2.0, 5.0, 3.0, 0.0, 0.0, 1.0, 5.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 3.0, 0.0, 3.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 8.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 6.0, 4.0, 3.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 3.0, 4.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 3.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 5.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 4.0, 1.0, 0.0, 1.0, 0.0, 1.0, 9.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 2.0, 0.0, 0.0, 5.0, 0.0, 1.0, 0.0, 4.0, 2.0, 0.0, 0.0, 0.0, 8.0, 3.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 3.0, 4.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 4.0, 2.0, 0.0, 1.0, 0.0, 9.0, 0.0, 5.0, 0.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 0.0, 7.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 3.0, 4.0, 0.0, 0.0, 3.0, 0.0, 2.0, 1.0, 1.0, 1.0, 4.0, 11.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 7.0, 3.0, 0.0, 2.0, 0.0, 0.0, 1.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 4.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 3.0, 6.0, 6.0, 5.0, 4.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 2.0, 4.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 10.0, 0.0, 1.0, 0.0, 1.0, 2.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 7.0, 0.0, 1.0, 4.0, 3.0, 5.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0, 12.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 1.0, 0.0, 2.0, 0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 0.0, 1.0, 1.0, 0.0, 4.0, 0.0, 5.0, 1.0, 7.0, 0.0, 0.0, 0.0, 5.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 7.0, 0.0, 2.0, 0.0, 7.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 5.0, 3.0, 4.0, 5.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 3.0, 4.0, 5.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 4.0, 5.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 2.0, 4.0, 2.0, 1.0, 0.0, 4.0, 1.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 5.0, 1.0, 4.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 3.0, 2.0, 4.0, 1.0, 0.0, 1.0, 1.0, 2.0, 5.0, 1.0, 2.0, 2.0, 1.0, 5.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 8.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 3.0, 5.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 2.0, 14.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 13.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 0.0, 4.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 3.0, 7.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 3.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 0.0, 8.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 4.0, 0.0, 8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 2.0, 3.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 11.0, 3.0, 6.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 3.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 3.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 0.0, 8.0, 1.0, 2.0, 0.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 5.0, 1.0, 0.0, 1.0, 1.0, 4.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 4.0, 0.0, 1.0, 3.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 3.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 6.0, 0.0, 5.0, 1.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 2.0, 4.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 4.0, 4.0, 0.0, 4.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 7.0, 1.0, 0.0, 5.0, 0.0, 2.0, 6.0, 2.0, 0.0, 2.0, 0.0, 2.0, 3.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 4.0, 2.0, 3.0, 1.0, 3.0, 4.0, 1.0, 0.0, 1.0, 0.0, 3.0, 3.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 10.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 5.0, 2.0, 2.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 6.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 0.0, 0.0, 3.0, 0.0, 2.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 4.0, 4.0, 0.0, 0.0, 0.0, 3.0, 3.0, 4.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 4.0, 3.0, 2.0, 0.0, 0.0, 0.0, 4.0, 0.0, 5.0, 4.0, 5.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 3.0, 0.0, 1.0, 6.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 7.0, 0.0, 2.0, 0.0, 7.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 6.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 2.0, 1.0, 0.0, 4.0, 1.0, 2.0, 0.0, 2.0, 6.0, 0.0, 4.0, 0.0, 0.0, 6.0, 7.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 1.0, 3.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 5.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 5.0, 0.0, 0.0, 3.0, 0.0, 5.0, 2.0, 2.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 3.0, 2.0, 0.0, 0.0, 3.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 2.0, 2.0, 0.0, 4.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 5.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 5.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 3.0, 0.0, 7.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 3.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 6.0, 1.0, 0.0, 6.0, 0.0, 1.0, 0.0, 1.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 1.0, 8.0, 3.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 4.0, 0.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 10.0, 0.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 1.0, 6.0, 1.0, 12.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 8.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 6.0, 1.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 7.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 10.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 3.0, 0.0, 1.0, 0.0, 0.0, 9.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 6.0, 2.0, 0.0, 0.0, 0.0, 3.0, 1.0, 7.0, 1.0, 0.0, 0.0, 0.0, 0.0, 8.0, 1.0, 3.0, 0.0, 1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 4.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 7.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 2.0, 0.0, 0.0, 1.0, 4.0, 4.0, 1.0, 2.0, 0.0, 4.0, 0.0, 5.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 2.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 1.0, 1.0, 0.0, 1.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 4.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 0.0, 4.0, 3.0, 2.0, 2.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 7.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 3.0, 0.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 8.0, 5.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 11.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 6.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 4.0, 5.0, 1.0, 2.0, 4.0, 0.0, 0.0, 4.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 4.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 5.0, 1.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 4.0, 0.0, 0.0, 0.0, 1.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 3.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 2.0, 6.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 4.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 3.0, 0.0, 6.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 3.0, 0.0, 6.0, 4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 3.0, 3.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 4.0, 1.0, 0.0, 5.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 4.0, 5.0, 0.0, 0.0, 6.0, 2.0, 5.0, 0.0, 1.0, 4.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 4.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 5.0, 0.0, 6.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 6.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 3.0, 4.0, 7.0, 0.0, 1.0, 0.0, 1.0, 11.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 5.0, 2.0, 0.0, 0.0, 4.0, 4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 2.0, 2.0, 4.0, 0.0, 2.0, 3.0, 2.0, 0.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 4.0, 1.0, 5.0, 2.0, 0.0, 3.0, 0.0, 2.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 7.0, 1.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 7.0, 5.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 5.0, 0.0, 0.0, 1.0, 4.0, 0.0, 2.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 0.0, 1.0, 2.0, 0.0, 0.0, 5.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 6.0, 1.0, 1.0, 5.0, 5.0, 0.0, 4.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 3.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 5.0, 5.0, 7.0, 2.0, 4.0, 1.0, 0.0, 0.0, 2.0, 4.0, 2.0, 3.0, 1.0, 0.0, 2.0, 3.0, 3.0, 1.0, 0.0, 4.0, 3.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 6.0, 3.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 6.0, 0.0, 1.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 0.0, 2.0, 1.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 5.0, 5.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 1.0, 6.0, 2.0, 4.0, 3.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 5.0, 4.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 7.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 4.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 4.0, 0.0, 2.0, 3.0, 0.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 4.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 4.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 0.0, 6.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.0, 2.0, 2.0, 0.0, 0.0, 0.0, 8.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 4.0, 6.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 0.0, 7.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 4.0, 0.0, 2.0, 1.0, 3.0, 1.0, 0.0, 4.0, 1.0, 2.0, 0.0, 0.0, 4.0, 0.0, 0.0, 6.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 3.0, 5.0, 0.0, 0.0, 2.0, 0.0, 3.0, 1.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 4.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 6.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 4.0, 0.0, 1.0, 0.0, 0.0, 6.0, 7.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 3.0, 5.0, 3.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 4.0, 0.0, 2.0, 0.0, 4.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 6.0, 0.0, 0.0, 3.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 4.0, 2.0, 1.0, 1.0, 0.0, 3.0, 1.0, 5.0, 4.0, 9.0, 0.0, 6.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 6.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 14.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 3.0, 6.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 2.0, 0.0, 3.0, 0.0, 0.0, 10.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 4.0, 1.0, 6.0, 0.0, 2.0, 2.0, 0.0, 0.0, 5.0, 0.0, 1.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 5.0, 0.0, 0.0, 0.0, 1.0, 9.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 1.0, 3.0, 3.0, 5.0, 2.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 4.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 0.0, 0.0, 3.0, 4.0, 5.0, 0.0, 0.0, 3.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 5.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 7.0, 1.0, 1.0, 3.0, 4.0, 0.0, 1.0, 5.0, 0.0, 0.0, 0.0, 4.0, 0.0, 2.0, 1.0, 1.0, 2.0, 5.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 7.0, 1.0, 0.0, 1.0, 7.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 3.0, 6.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 3.0, 1.0, 0.0, 1.0, 2.0, 4.0, 3.0, 2.0, 1.0, 6.0, 2.0, 6.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 2.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 3.0, 0.0, 5.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 0.0, 3.0, 4.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 2.0, 0.0, 0.0, 9.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 5.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 4.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 1.0, 5.0, 1.0, 0.0, 0.0, 1.0, 1.0, 5.0, 1.0, 1.0, 2.0, 5.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 1.0, 0.0, 0.0, 3.0, 1.0, 4.0, 4.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 7.0, 0.0, 2.0, 0.0, 0.0, 5.0, 4.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 10.0, 3.0, 3.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 2.0, 3.0, 0.0, 3.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 2.0, 1.0, 4.0, 1.0, 0.0, 5.0, 3.0, 5.0, 0.0, 0.0, 4.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 4.0, 2.0, 2.0, 1.0, 0.0, 3.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 3.0, 4.0, 5.0, 2.0, 0.0, 3.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 1.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 6.0, 0.0, 5.0, 0.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 4.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 0.0, 2.0, 3.0, 4.0, 5.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 4.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 2.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 5.0, 0.0, 1.0, 9.0, 8.0, 0.0, 1.0, 3.0, 0.0, 2.0, 0.0, 3.0, 6.0, 5.0, 0.0, 2.0, 1.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 1.0, 7.0, 3.0, 4.0, 1.0, 3.0, 1.0, 1.0, 5.0, 2.0, 2.0, 0.0, 3.0, 0.0, 2.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 1.0, 4.0, 0.0, 2.0, 1.0, 0.0, 0.0, 7.0, 4.0, 4.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 6.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 3.0, 0.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 4.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 4.0, 0.0, 0.0, 4.0, 0.0, 2.0, 0.0, 1.0, 4.0, 0.0, 8.0, 5.0, 0.0, 1.0, 5.0, 0.0, 0.0, 5.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 12.0, 0.0, 1.0, 3.0, 2.0, 6.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 2.0, 2.0, 5.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 3.0, 1.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 0.0, 4.0, 0.0, 21.0, 2.0, 0.0, 6.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 4.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 4.0, 2.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 4.0, 0.0, 2.0, 4.0, 1.0, 0.0, 0.0, 1.0, 3.0, 4.0, 9.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 2.0, 5.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 4.0, 2.0, 3.0, 2.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 4.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 7.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 8.0, 1.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 2.0, 2.0, 0.0, 7.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 2.0, 4.0, 0.0, 0.0, 3.0, 0.0, 1.0, 3.0, 6.0, 5.0, 3.0, 1.0, 5.0, 3.0, 4.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 6.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 4.0, 4.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 3.0, 6.0, 1.0, 2.0, 6.0, 2.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 4.0, 2.0, 3.0, 4.0, 1.0, 5.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 8.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 5.0, 1.0, 5.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 1.0, 2.0, 2.0, 3.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 0.0, 0.0, 5.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 6.0, 0.0, 3.0, 4.0, 0.0, 2.0, 6.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 5.0, 0.0, 1.0, 1.0, 4.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 3.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 4.0, 0.0, 2.0, 1.0, 2.0, 0.0, 5.0, 2.0, 0.0, 0.0, 1.0, 8.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 4.0, 6.0, 1.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 6.0, 3.0, 0.0, 6.0, 2.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 6.0, 5.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 5.0, 0.0, 1.0, 5.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 5.0, 3.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 4.0, 3.0, 1.0, 1.0, 1.0, 0.0, 2.0, 5.0, 5.0, 1.0, 1.0, 0.0, 5.0, 0.0, 2.0, 0.0, 0.0, 4.0, 1.0, 1.0, 2.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 5.0, 0.0, 0.0, 4.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 5.0, 1.0, 0.0, 0.0, 4.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 5.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 4.0, 1.0, 1.0, 0.0, 2.0, 3.0, 0.0, 4.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 2.0, 3.0, 0.0, 3.0, 4.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 3.0, 0.0, 3.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 4.0, 1.0, 1.0, 4.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 3.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 3.0, 1.0, 5.0, 0.0, 0.0, 1.0, 8.0, 3.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 1.0, 4.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 6.0, 0.0, 3.0, 1.0, 5.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 4.0, 1.0, 9.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 5.0, 1.0, 3.0, 5.0, 0.0, 0.0, 0.0, 0.0, 4.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 5.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 4.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 6.0, 11.0, 0.0, 1.0, 0.0, 1.0, 0.0, 5.0, 0.0, 11.0, 4.0, 0.0, 0.0, 9.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "#reformatting redCorner_takedowns to be purely how many they landed\n",
    "for index, row in df.iterrows():\n",
    "    totals = row['redCorner_takedowns'].split(' ')\n",
    "    landed = float(totals[0])\n",
    "    df.loc[index, 'redCorner_takedowns'] = landed\n",
    "\n",
    "print(df['redCorner_takedowns'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 2.0, 0.0, 0.0, 2.0, 4.0, 3.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 6.0, 8.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 7.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 4.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 0.0, 1.0, 5.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 5.0, 3.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 9.0, 0.0, 0.0, 4.0, 0.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 3.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 4.0, 3.0, 2.0, 0.0, 0.0, 1.0, 0.0, 5.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 5.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 4.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 5.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 8.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 7.0, 2.0, 0.0, 0.0, 2.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 9.0, 4.0, 0.0, 0.0, 2.0, 0.0, 0.0, 9.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 4.0, 1.0, 3.0, 0.0, 0.0, 1.0, 2.0, 4.0, 1.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 6.0, 3.0, 4.0, 0.0, 5.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 7.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 4.0, 0.0, 0.0, 0.0, 3.0, 4.0, 0.0, 1.0, 0.0, 4.0, 1.0, 3.0, 3.0, 2.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 5.0, 4.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 3.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 3.0, 3.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 10.0, 0.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 4.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 2.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 6.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 3.0, 1.0, 1.0, 4.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 5.0, 0.0, 0.0, 0.0, 2.0, 4.0, 11.0, 0.0, 1.0, 0.0, 1.0, 5.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 4.0, 3.0, 11.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 5.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 6.0, 3.0, 0.0, 5.0, 4.0, 2.0, 5.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 5.0, 0.0, 7.0, 0.0, 0.0, 2.0, 3.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 5.0, 2.0, 4.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 7.0, 0.0, 1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 4.0, 1.0, 0.0, 1.0, 7.0, 1.0, 3.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 3.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 4.0, 6.0, 0.0, 0.0, 0.0, 0.0, 1.0, 6.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 4.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 0.0, 1.0, 6.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 3.0, 0.0, 3.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 8.0, 0.0, 0.0, 2.0, 0.0, 7.0, 0.0, 1.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 0.0, 5.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 4.0, 1.0, 0.0, 0.0, 4.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 4.0, 2.0, 2.0, 4.0, 0.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 6.0, 1.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 8.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 7.0, 1.0, 2.0, 4.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 0.0, 1.0, 1.0, 0.0, 1.0, 5.0, 0.0, 0.0, 0.0, 1.0, 3.0, 5.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 5.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 6.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 5.0, 1.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 0.0, 3.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 4.0, 0.0, 1.0, 0.0, 8.0, 5.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 6.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 4.0, 2.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 3.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 2.0, 2.0, 3.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 3.0, 1.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 3.0, 4.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 3.0, 2.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 8.0, 0.0, 4.0, 4.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 6.0, 4.0, 0.0, 0.0, 1.0, 0.0, 1.0, 3.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 3.0, 2.0, 5.0, 4.0, 0.0, 1.0, 7.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 3.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 4.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 1.0, 0.0, 4.0, 7.0, 0.0, 1.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 5.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 5.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 5.0, 0.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 3.0, 1.0, 4.0, 1.0, 0.0, 0.0, 1.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 5.0, 4.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 4.0, 0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 0.0, 2.0, 2.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 5.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 10.0, 0.0, 0.0, 1.0, 1.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 6.0, 1.0, 1.0, 6.0, 0.0, 0.0, 0.0, 1.0, 0.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 2.0, 0.0, 0.0, 2.0, 1.0, 2.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 6.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 4.0, 0.0, 1.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 6.0, 2.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 3.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 5.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 2.0, 6.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 5.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 0.0, 1.0, 3.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 5.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 5.0, 0.0, 1.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 4.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 4.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 5.0, 5.0, 12.0, 0.0, 0.0, 0.0, 8.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 6.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 1.0, 0.0, 2.0, 0.0, 0.0, 6.0, 6.0, 3.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 5.0, 0.0, 3.0, 7.0, 0.0, 0.0, 1.0, 4.0, 2.0, 2.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 6.0, 3.0, 1.0, 0.0, 0.0, 2.0, 3.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 3.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 3.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 0.0, 2.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 0.0, 4.0, 4.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 5.0, 1.0, 0.0, 1.0, 3.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 1.0, 3.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 5.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 3.0, 0.0, 0.0, 0.0, 2.0, 6.0, 2.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 2.0, 11.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 5.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 4.0, 0.0, 4.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 5.0, 2.0, 1.0, 1.0, 3.0, 3.0, 0.0, 0.0, 1.0, 4.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 5.0, 5.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 3.0, 0.0, 3.0, 4.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 3.0, 0.0, 3.0, 1.0, 6.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 8.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 6.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 9.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 5.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 12.0, 0.0, 0.0, 4.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 4.0, 2.0, 7.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 8.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 5.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 8.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 4.0, 1.0, 0.0, 5.0, 0.0, 2.0, 2.0, 4.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 6.0, 12.0, 0.0, 3.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 5.0, 0.0, 4.0, 4.0, 4.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 6.0, 0.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 4.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 5.0, 4.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 5.0, 1.0, 0.0, 1.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 2.0, 5.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 6.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 3.0, 3.0, 0.0, 1.0, 2.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 5.0, 0.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 3.0, 4.0, 1.0, 1.0, 0.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 4.0, 1.0, 0.0, 3.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 9.0, 2.0, 0.0, 1.0, 2.0, 0.0, 4.0, 6.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 5.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 5.0, 0.0, 0.0, 6.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 4.0, 0.0, 0.0, 0.0, 9.0, 0.0, 3.0, 1.0, 0.0, 0.0, 4.0, 0.0, 1.0, 2.0, 6.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 3.0, 5.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 8.0, 0.0, 1.0, 1.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 6.0, 5.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 5.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 4.0, 4.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 4.0, 0.0, 3.0, 0.0, 6.0, 3.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 7.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 6.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 0.0, 3.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 9.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 4.0, 0.0, 1.0, 3.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 5.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 5.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 2.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 9.0, 3.0, 0.0, 3.0, 2.0, 1.0, 1.0, 5.0, 0.0, 1.0, 0.0, 2.0, 0.0, 4.0, 2.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 1.0, 1.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 4.0, 0.0, 2.0, 1.0, 0.0, 0.0, 4.0, 5.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 3.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 5.0, 2.0, 0.0, 2.0, 0.0, 2.0, 10.0, 1.0, 1.0, 0.0, 0.0, 4.0, 0.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 4.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 4.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 2.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 6.0, 1.0, 0.0, 3.0, 4.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 5.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 2.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 3.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 1.0, 0.0, 2.0, 2.0, 0.0, 5.0, 0.0, 7.0, 6.0, 0.0, 2.0, 0.0, 0.0, 0.0, 5.0, 0.0, 1.0, 5.0, 0.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 3.0, 5.0, 0.0, 0.0, 3.0, 0.0, 8.0, 2.0, 6.0, 1.0, 5.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 4.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 3.0, 3.0, 1.0, 3.0, 0.0, 1.0, 0.0, 6.0, 0.0, 2.0, 5.0, 0.0, 1.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 3.0, 2.0, 0.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 2.0, 6.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 4.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 1.0, 1.0, 0.0, 0.0, 4.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 5.0, 5.0, 4.0, 4.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 6.0, 1.0, 3.0, 0.0, 4.0, 0.0, 6.0, 2.0, 0.0, 0.0, 5.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 4.0, 1.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 5.0, 0.0, 0.0, 0.0, 0.0, 5.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 6.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 0.0, 3.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 6.0, 0.0, 6.0, 0.0, 2.0, 0.0, 12.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 5.0, 0.0, 0.0, 2.0, 2.0, 5.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 3.0, 0.0, 4.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 5.0, 2.0, 4.0, 1.0, 5.0, 1.0, 0.0, 2.0, 0.0, 0.0, 7.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 5.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 5.0, 0.0, 10.0, 0.0, 0.0, 2.0, 0.0, 11.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 7.0, 3.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 5.0, 1.0, 0.0, 0.0, 7.0, 0.0, 1.0, 6.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 1.0, 0.0, 6.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 4.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 6.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 5.0, 1.0, 0.0, 0.0, 5.0, 0.0, 0.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 5.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 4.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 4.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 3.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 4.0, 0.0, 0.0, 4.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 5.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 2.0, 0.0, 4.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 4.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 7.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 3.0, 1.0, 0.0, 5.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 5.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 5.0, 0.0, 6.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 5.0, 7.0, 0.0, 1.0, 6.0, 0.0, 1.0, 0.0, 0.0, 3.0, 7.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 3.0, 3.0, 0.0, 1.0, 0.0, 10.0, 0.0, 3.0, 1.0, 1.0, 3.0, 4.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 5.0, 0.0, 1.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 6.0, 1.0, 0.0, 1.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 0.0, 3.0, 3.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 5.0, 0.0, 5.0, 1.0, 6.0, 0.0, 0.0, 0.0, 5.0, 2.0, 2.0, 1.0, 0.0, 0.0, 7.0, 0.0, 4.0, 1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 2.0, 1.0, 4.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 3.0, 0.0, 1.0, 5.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 3.0, 2.0, 5.0, 0.0, 1.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 4.0, 0.0, 0.0, 9.0, 3.0, 2.0, 2.0, 0.0, 2.0, 0.0, 0.0, 5.0, 1.0, 0.0, 7.0, 2.0, 3.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 3.0, 3.0, 2.0, 3.0, 1.0, 3.0, 0.0, 1.0, 5.0, 0.0, 6.0, 3.0, 2.0, 5.0, 0.0, 0.0, 0.0, 5.0, 1.0, 2.0, 3.0, 0.0, 1.0, 3.0, 0.0, 6.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 3.0, 0.0, 3.0, 1.0, 1.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 6.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 4.0, 8.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 4.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 3.0]\n"
     ]
    }
   ],
   "source": [
    "#reformatting blueCorner_takedowns to be purely how many they landed\n",
    "for index, row in df.iterrows():\n",
    "    totals = row['blueCorner_takedowns'].split(' ')\n",
    "    landed = float(totals[0])\n",
    "    df.loc[index, 'blueCorner_takedowns'] = landed\n",
    "\n",
    "print(df['blueCorner_takedowns'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns no longer needed\n",
    "df.drop('redCorner_sig_str', axis=1, inplace=True)\n",
    "df.drop('blueCorner_sig_str', axis=1, inplace=True)\n",
    "df.drop('redCorner_total_str', axis=1, inplace=True)\n",
    "df.drop('blueCorner_total_str', axis=1, inplace=True)\n",
    "df.drop('round', axis=1, inplace=True)\n",
    "df.drop('time', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6534\n",
      "6497\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df.dropna(inplace=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Switch' 'Orthodox' 'Southpaw' 'Open Stance']\n",
      "['Orthodox' 'Southpaw' 'Switch' 'Open Stance']\n"
     ]
    }
   ],
   "source": [
    "unique_stances = df['redCorner_stance'].unique()\n",
    "uniqueStances = df['blueCorner_stance'].unique()\n",
    "\n",
    "print(unique_stances)\n",
    "print(uniqueStances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n",
      "[0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "#format stances\n",
    "\n",
    "df['redCorner_stance'] = df['redCorner_stance'].replace('Orthodox', 0)\n",
    "df['blueCorner_stance'] = df['blueCorner_stance'].replace('Orthodox', 0)\n",
    "\n",
    "df['redCorner_stance'] = df['redCorner_stance'].replace('Southpaw', 1)\n",
    "df['blueCorner_stance'] = df['blueCorner_stance'].replace('Southpaw', 1)\n",
    "\n",
    "df['redCorner_stance'] = df['redCorner_stance'].replace('Open Stance', 2)\n",
    "df['blueCorner_stance'] = df['blueCorner_stance'].replace('Open Stance', 2)\n",
    "\n",
    "df['redCorner_stance'] = df['redCorner_stance'].replace('Switch', 3)\n",
    "df['blueCorner_stance'] = df['blueCorner_stance'].replace('Switch', 3)\n",
    "\n",
    "\n",
    "stances = df['blueCorner_stance'].values.tolist()\n",
    "stancesred = df['redCorner_stance'].values.tolist()\n",
    "print(list(set(stances)))\n",
    "print(list(set(stancesred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format height\n",
    "for index, row in df.iterrows():\n",
    "    height = row['redCorner_height']\n",
    "    height = height.replace(\"'\", '').replace('\"', '')\n",
    "    lHeight = height.split(' ')\n",
    "    finalHeight = int(lHeight[0])*12+int(lHeight[1])\n",
    "    df.loc[index, 'redCorner_height'] = int(finalHeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 83]\n"
     ]
    }
   ],
   "source": [
    "redCornerHeights = df['redCorner_height'].values.tolist()\n",
    "print(list(set(redCornerHeights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format height\n",
    "for index, row in df.iterrows():\n",
    "    height = row['blueCorner_height']\n",
    "    height = height.replace(\"'\", '').replace('\"', '')\n",
    "    lHeight = height.split(' ')\n",
    "    finalHeight = int(lHeight[0])*12+int(lHeight[1])\n",
    "    df.loc[index, 'blueCorner_height'] = int(finalHeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83]\n"
     ]
    }
   ],
   "source": [
    "blueCornerHeights = df['blueCorner_height'].values.tolist()\n",
    "print(list(set(blueCornerHeights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean reaches\n",
    "for index, row in df.iterrows():\n",
    "    reach = row['redCorner_reach']\n",
    "    newreach = reach.replace('\"', '')\n",
    "    df.loc[index, 'redCorner_reach'] = int(newreach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84]\n"
     ]
    }
   ],
   "source": [
    "#confirm reaches are changed\n",
    "redCornerReach = df['redCorner_reach'].values.tolist()\n",
    "print(list(set(redCornerReach)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean reaches\n",
    "for index, row in df.iterrows():\n",
    "    reach = row['blueCorner_reach']\n",
    "    newreach = reach.replace('\"', '')\n",
    "    df.loc[index, 'blueCorner_reach'] = int(newreach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84]\n"
     ]
    }
   ],
   "source": [
    "#confirm reaches are changed\n",
    "redCornerReach = df['redCorner_reach'].values.tolist()\n",
    "print(list(set(redCornerReach)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'traindata{dateToday}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nickname</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>draws</th>\n",
       "      <th>age</th>\n",
       "      <th>nation</th>\n",
       "      <th>knockdown_avg</th>\n",
       "      <th>sig_str_accuracy</th>\n",
       "      <th>takedown_average</th>\n",
       "      <th>takedown_accuracy</th>\n",
       "      <th>subs_attempted_average</th>\n",
       "      <th>height</th>\n",
       "      <th>reach</th>\n",
       "      <th>stance</th>\n",
       "      <th>sig_str_landed_per_min</th>\n",
       "      <th>average_fight_time</th>\n",
       "      <th>sig_str_absorbed_per_min</th>\n",
       "      <th>sig_str_defense</th>\n",
       "      <th>takedown_defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danny Abbadi</td>\n",
       "      <td>The Assassin</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jul-03-1983</td>\n",
       "      <td>Orlando, United States</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5' 11\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.29</td>\n",
       "      <td>08:58</td>\n",
       "      <td>4.41</td>\n",
       "      <td>57%</td>\n",
       "      <td>77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hamdy Abdelwahab</td>\n",
       "      <td>The Hammer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 (1 NC)</td>\n",
       "      <td>Jan-22-1993</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>1.00</td>\n",
       "      <td>52%</td>\n",
       "      <td>3.00</td>\n",
       "      <td>75%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>72\"</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>3.87</td>\n",
       "      <td>15:00</td>\n",
       "      <td>3.13</td>\n",
       "      <td>59%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mansur AbdulMalik</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Oct-07-1997</td>\n",
       "      <td>Pittsburgh, United States</td>\n",
       "      <td>0.00</td>\n",
       "      <td>53%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>5.38</td>\n",
       "      <td>08:55</td>\n",
       "      <td>5.16</td>\n",
       "      <td>54%</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shamil Abdurakhimov</td>\n",
       "      <td>Abrek</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sep-02-1981</td>\n",
       "      <td>Dagestan Republic, Russia</td>\n",
       "      <td>0.29</td>\n",
       "      <td>44%</td>\n",
       "      <td>1.01</td>\n",
       "      <td>23%</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>2.41</td>\n",
       "      <td>09:27</td>\n",
       "      <td>3.02</td>\n",
       "      <td>55%</td>\n",
       "      <td>45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daichi Abe</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nov-27-1991</td>\n",
       "      <td>Japan</td>\n",
       "      <td>0.33</td>\n",
       "      <td>33%</td>\n",
       "      <td>0.33</td>\n",
       "      <td>50%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5' 11\"</td>\n",
       "      <td>71\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.80</td>\n",
       "      <td>15:00</td>\n",
       "      <td>4.49</td>\n",
       "      <td>56%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name      nickname  wins  losses     draws          age  \\\n",
       "0         Danny Abbadi  The Assassin   4.0     6.0         0  Jul-03-1983   \n",
       "1     Hamdy Abdelwahab    The Hammer   5.0     0.0  0 (1 NC)  Jan-22-1993   \n",
       "2    Mansur AbdulMalik             1   6.0     0.0         0  Oct-07-1997   \n",
       "3  Shamil Abdurakhimov         Abrek  20.0     8.0         0  Sep-02-1981   \n",
       "4           Daichi Abe             2   6.0     2.0         0  Nov-27-1991   \n",
       "\n",
       "                      nation  knockdown_avg sig_str_accuracy  \\\n",
       "0     Orlando, United States           0.00              38%   \n",
       "1                      Egypt           1.00              52%   \n",
       "2  Pittsburgh, United States           0.00              53%   \n",
       "3  Dagestan Republic, Russia           0.29              44%   \n",
       "4                      Japan           0.33              33%   \n",
       "\n",
       "   takedown_average takedown_accuracy  subs_attempted_average  height reach  \\\n",
       "0              0.00                0%                     0.0  5' 11\"   NaN   \n",
       "1              3.00               75%                     0.0   6' 2\"   72\"   \n",
       "2              0.00                0%                     0.0   6' 2\"   79\"   \n",
       "3              1.01               23%                     0.1   6' 3\"   76\"   \n",
       "4              0.33               50%                     0.0  5' 11\"   71\"   \n",
       "\n",
       "     stance  sig_str_landed_per_min average_fight_time  \\\n",
       "0  Orthodox                    3.29              08:58   \n",
       "1  Southpaw                    3.87              15:00   \n",
       "2  Orthodox                    5.38              08:55   \n",
       "3  Orthodox                    2.41              09:27   \n",
       "4  Orthodox                    3.80              15:00   \n",
       "\n",
       "   sig_str_absorbed_per_min sig_str_defense takedown_defense  \n",
       "0                      4.41             57%              77%  \n",
       "1                      3.13             59%               0%  \n",
       "2                      5.16             54%              75%  \n",
       "3                      3.02             55%              45%  \n",
       "4                      4.49             56%               0%  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTest = pd.read_csv(f'careerStatsData{dateToday}.csv')\n",
    "dfTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean draws to numerical\n",
    "for index, row in dfTest.iterrows():\n",
    "    draw = row['draws']\n",
    "    listdraw = draw.split(' ')\n",
    "    dfTest.loc[index, 'draws'] = int(listdraw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'str'>, <class 'float'>]\n"
     ]
    }
   ],
   "source": [
    "types = []\n",
    "for index, row in dfTest.iterrows():\n",
    "    types.append(type(row['age']))\n",
    "print(list(set(types)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nickname</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>draws</th>\n",
       "      <th>age</th>\n",
       "      <th>nation</th>\n",
       "      <th>knockdown_avg</th>\n",
       "      <th>sig_str_accuracy</th>\n",
       "      <th>takedown_average</th>\n",
       "      <th>takedown_accuracy</th>\n",
       "      <th>subs_attempted_average</th>\n",
       "      <th>height</th>\n",
       "      <th>reach</th>\n",
       "      <th>stance</th>\n",
       "      <th>sig_str_landed_per_min</th>\n",
       "      <th>average_fight_time</th>\n",
       "      <th>sig_str_absorbed_per_min</th>\n",
       "      <th>sig_str_defense</th>\n",
       "      <th>takedown_defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danny Abbadi</td>\n",
       "      <td>The Assassin</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Orlando, United States</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5' 11\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.29</td>\n",
       "      <td>08:58</td>\n",
       "      <td>4.41</td>\n",
       "      <td>57%</td>\n",
       "      <td>77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hamdy Abdelwahab</td>\n",
       "      <td>The Hammer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>1.00</td>\n",
       "      <td>52%</td>\n",
       "      <td>3.00</td>\n",
       "      <td>75%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>72\"</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>3.87</td>\n",
       "      <td>15:00</td>\n",
       "      <td>3.13</td>\n",
       "      <td>59%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mansur AbdulMalik</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Pittsburgh, United States</td>\n",
       "      <td>0.00</td>\n",
       "      <td>53%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>5.38</td>\n",
       "      <td>08:55</td>\n",
       "      <td>5.16</td>\n",
       "      <td>54%</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shamil Abdurakhimov</td>\n",
       "      <td>Abrek</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Dagestan Republic, Russia</td>\n",
       "      <td>0.29</td>\n",
       "      <td>44%</td>\n",
       "      <td>1.01</td>\n",
       "      <td>23%</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>2.41</td>\n",
       "      <td>09:27</td>\n",
       "      <td>3.02</td>\n",
       "      <td>55%</td>\n",
       "      <td>45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daichi Abe</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Japan</td>\n",
       "      <td>0.33</td>\n",
       "      <td>33%</td>\n",
       "      <td>0.33</td>\n",
       "      <td>50%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5' 11\"</td>\n",
       "      <td>71\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.80</td>\n",
       "      <td>15:00</td>\n",
       "      <td>4.49</td>\n",
       "      <td>56%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name      nickname  wins  losses draws   age  \\\n",
       "0         Danny Abbadi  The Assassin   4.0     6.0     0  41.0   \n",
       "1     Hamdy Abdelwahab    The Hammer   5.0     0.0     0  31.0   \n",
       "2    Mansur AbdulMalik             1   6.0     0.0     0  27.0   \n",
       "3  Shamil Abdurakhimov         Abrek  20.0     8.0     0  43.0   \n",
       "4           Daichi Abe             2   6.0     2.0     0  32.0   \n",
       "\n",
       "                      nation  knockdown_avg sig_str_accuracy  \\\n",
       "0     Orlando, United States           0.00              38%   \n",
       "1                      Egypt           1.00              52%   \n",
       "2  Pittsburgh, United States           0.00              53%   \n",
       "3  Dagestan Republic, Russia           0.29              44%   \n",
       "4                      Japan           0.33              33%   \n",
       "\n",
       "   takedown_average takedown_accuracy  subs_attempted_average  height reach  \\\n",
       "0              0.00                0%                     0.0  5' 11\"   NaN   \n",
       "1              3.00               75%                     0.0   6' 2\"   72\"   \n",
       "2              0.00                0%                     0.0   6' 2\"   79\"   \n",
       "3              1.01               23%                     0.1   6' 3\"   76\"   \n",
       "4              0.33               50%                     0.0  5' 11\"   71\"   \n",
       "\n",
       "     stance  sig_str_landed_per_min average_fight_time  \\\n",
       "0  Orthodox                    3.29              08:58   \n",
       "1  Southpaw                    3.87              15:00   \n",
       "2  Orthodox                    5.38              08:55   \n",
       "3  Orthodox                    2.41              09:27   \n",
       "4  Orthodox                    3.80              15:00   \n",
       "\n",
       "   sig_str_absorbed_per_min sig_str_defense takedown_defense  \n",
       "0                      4.41             57%              77%  \n",
       "1                      3.13             59%               0%  \n",
       "2                      5.16             54%              75%  \n",
       "3                      3.02             55%              45%  \n",
       "4                      4.49             56%               0%  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "#calculate age of fighter\n",
    "def calculate_age(year, month, day):\n",
    "    today = date.today()\n",
    "    return today.year - year - ((today.month, today.day) < (month, day))\n",
    "\n",
    "\n",
    "for index, row in dfTest.iterrows():\n",
    "    born = row['age']\n",
    "    if(isinstance(born, str)):\n",
    "        listBorn = born.split('-')\n",
    "        day = listBorn[1]\n",
    "        month = listBorn[0]\n",
    "        year = listBorn[2]\n",
    "        if month == 'Jan':\n",
    "            month = 1\n",
    "        if month == 'Feb':\n",
    "            month = 2\n",
    "        if month == 'Mar':\n",
    "            month = 3\n",
    "        if month == 'Apr':\n",
    "            month = 4\n",
    "        if month == 'May':\n",
    "            month = 5\n",
    "        if month == 'Jun':\n",
    "            month = 6\n",
    "        if month == 'Jul':\n",
    "            month = 7\n",
    "        if month == 'Aug':\n",
    "            month = 8\n",
    "        if month == 'Sep':\n",
    "            month = 9\n",
    "        if month == 'Oct':\n",
    "            month = 10\n",
    "        if month == 'Nov':\n",
    "            month = 11\n",
    "        if month == 'Dec':\n",
    "            month = 12\n",
    "        age = calculate_age(int(year), int(month), int(day))\n",
    "        dfTest.loc[index, 'age'] = float(age)\n",
    "\n",
    "dfTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nickname</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>draws</th>\n",
       "      <th>age</th>\n",
       "      <th>nation</th>\n",
       "      <th>knockdown_avg</th>\n",
       "      <th>sig_str_accuracy</th>\n",
       "      <th>takedown_average</th>\n",
       "      <th>takedown_accuracy</th>\n",
       "      <th>subs_attempted_average</th>\n",
       "      <th>height</th>\n",
       "      <th>reach</th>\n",
       "      <th>stance</th>\n",
       "      <th>sig_str_landed_per_min</th>\n",
       "      <th>average_fight_time</th>\n",
       "      <th>sig_str_absorbed_per_min</th>\n",
       "      <th>sig_str_defense</th>\n",
       "      <th>takedown_defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danny Abbadi</td>\n",
       "      <td>The Assassin</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5' 11\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.29</td>\n",
       "      <td>08:58</td>\n",
       "      <td>4.41</td>\n",
       "      <td>57%</td>\n",
       "      <td>77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hamdy Abdelwahab</td>\n",
       "      <td>The Hammer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>1.00</td>\n",
       "      <td>52%</td>\n",
       "      <td>3.00</td>\n",
       "      <td>75%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>72\"</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>3.87</td>\n",
       "      <td>15:00</td>\n",
       "      <td>3.13</td>\n",
       "      <td>59%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mansur AbdulMalik</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>0.00</td>\n",
       "      <td>53%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>5.38</td>\n",
       "      <td>08:55</td>\n",
       "      <td>5.16</td>\n",
       "      <td>54%</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shamil Abdurakhimov</td>\n",
       "      <td>Abrek</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Russia</td>\n",
       "      <td>0.29</td>\n",
       "      <td>44%</td>\n",
       "      <td>1.01</td>\n",
       "      <td>23%</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>2.41</td>\n",
       "      <td>09:27</td>\n",
       "      <td>3.02</td>\n",
       "      <td>55%</td>\n",
       "      <td>45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daichi Abe</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Japan</td>\n",
       "      <td>0.33</td>\n",
       "      <td>33%</td>\n",
       "      <td>0.33</td>\n",
       "      <td>50%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5' 11\"</td>\n",
       "      <td>71\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.80</td>\n",
       "      <td>15:00</td>\n",
       "      <td>4.49</td>\n",
       "      <td>56%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name      nickname  wins  losses draws   age         nation  \\\n",
       "0         Danny Abbadi  The Assassin   4.0     6.0     0  41.0  United States   \n",
       "1     Hamdy Abdelwahab    The Hammer   5.0     0.0     0  31.0          Egypt   \n",
       "2    Mansur AbdulMalik             1   6.0     0.0     0  27.0  United States   \n",
       "3  Shamil Abdurakhimov         Abrek  20.0     8.0     0  43.0         Russia   \n",
       "4           Daichi Abe             2   6.0     2.0     0  32.0          Japan   \n",
       "\n",
       "   knockdown_avg sig_str_accuracy  takedown_average takedown_accuracy  \\\n",
       "0           0.00              38%              0.00                0%   \n",
       "1           1.00              52%              3.00               75%   \n",
       "2           0.00              53%              0.00                0%   \n",
       "3           0.29              44%              1.01               23%   \n",
       "4           0.33              33%              0.33               50%   \n",
       "\n",
       "   subs_attempted_average  height reach    stance  sig_str_landed_per_min  \\\n",
       "0                     0.0  5' 11\"   NaN  Orthodox                    3.29   \n",
       "1                     0.0   6' 2\"   72\"  Southpaw                    3.87   \n",
       "2                     0.0   6' 2\"   79\"  Orthodox                    5.38   \n",
       "3                     0.1   6' 3\"   76\"  Orthodox                    2.41   \n",
       "4                     0.0  5' 11\"   71\"  Orthodox                    3.80   \n",
       "\n",
       "  average_fight_time  sig_str_absorbed_per_min sig_str_defense  \\\n",
       "0              08:58                      4.41             57%   \n",
       "1              15:00                      3.13             59%   \n",
       "2              08:55                      5.16             54%   \n",
       "3              09:27                      3.02             55%   \n",
       "4              15:00                      4.49             56%   \n",
       "\n",
       "  takedown_defense  \n",
       "0              77%  \n",
       "1               0%  \n",
       "2              75%  \n",
       "3              45%  \n",
       "4               0%  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reformat nation to just the nation name\n",
    "for index, row in dfTest.iterrows():\n",
    "    nation = row['nation']\n",
    "    if(isinstance(nation, str)):\n",
    "        if ',' in nation:\n",
    "            listn = nation.split(',')\n",
    "            country = listn[len(listn)-1]\n",
    "            countryFinal = country[1:]\n",
    "            dfTest.at[index, 'nation'] = countryFinal\n",
    "\n",
    "\n",
    "dfTest['nation'] = dfTest['nation'].replace(\"Congo - Kinshasa\", \"Congo\", regex=True)\n",
    "dfTest['nation'] = dfTest['nation'].replace(\"Myanmar (Burma)\", \"Myanmar\", regex=True)\n",
    "\n",
    "dfTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nickname</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>draws</th>\n",
       "      <th>age</th>\n",
       "      <th>nation</th>\n",
       "      <th>knockdown_avg</th>\n",
       "      <th>sig_str_accuracy</th>\n",
       "      <th>takedown_average</th>\n",
       "      <th>takedown_accuracy</th>\n",
       "      <th>subs_attempted_average</th>\n",
       "      <th>height</th>\n",
       "      <th>reach</th>\n",
       "      <th>stance</th>\n",
       "      <th>sig_str_landed_per_min</th>\n",
       "      <th>average_fight_time</th>\n",
       "      <th>sig_str_absorbed_per_min</th>\n",
       "      <th>sig_str_defense</th>\n",
       "      <th>takedown_defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danny Abbadi</td>\n",
       "      <td>The Assassin</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>unitedstates</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5' 11\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.29</td>\n",
       "      <td>08:58</td>\n",
       "      <td>4.41</td>\n",
       "      <td>57%</td>\n",
       "      <td>77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hamdy Abdelwahab</td>\n",
       "      <td>The Hammer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>egypt</td>\n",
       "      <td>1.00</td>\n",
       "      <td>52%</td>\n",
       "      <td>3.00</td>\n",
       "      <td>75%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>72\"</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>3.87</td>\n",
       "      <td>15:00</td>\n",
       "      <td>3.13</td>\n",
       "      <td>59%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mansur AbdulMalik</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>unitedstates</td>\n",
       "      <td>0.00</td>\n",
       "      <td>53%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>5.38</td>\n",
       "      <td>08:55</td>\n",
       "      <td>5.16</td>\n",
       "      <td>54%</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shamil Abdurakhimov</td>\n",
       "      <td>Abrek</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>russia</td>\n",
       "      <td>0.29</td>\n",
       "      <td>44%</td>\n",
       "      <td>1.01</td>\n",
       "      <td>23%</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>2.41</td>\n",
       "      <td>09:27</td>\n",
       "      <td>3.02</td>\n",
       "      <td>55%</td>\n",
       "      <td>45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daichi Abe</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>japan</td>\n",
       "      <td>0.33</td>\n",
       "      <td>33%</td>\n",
       "      <td>0.33</td>\n",
       "      <td>50%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5' 11\"</td>\n",
       "      <td>71\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.80</td>\n",
       "      <td>15:00</td>\n",
       "      <td>4.49</td>\n",
       "      <td>56%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name      nickname  wins  losses draws   age        nation  \\\n",
       "0         Danny Abbadi  The Assassin   4.0     6.0     0  41.0  unitedstates   \n",
       "1     Hamdy Abdelwahab    The Hammer   5.0     0.0     0  31.0         egypt   \n",
       "2    Mansur AbdulMalik             1   6.0     0.0     0  27.0  unitedstates   \n",
       "3  Shamil Abdurakhimov         Abrek  20.0     8.0     0  43.0        russia   \n",
       "4           Daichi Abe             2   6.0     2.0     0  32.0         japan   \n",
       "\n",
       "   knockdown_avg sig_str_accuracy  takedown_average takedown_accuracy  \\\n",
       "0           0.00              38%              0.00                0%   \n",
       "1           1.00              52%              3.00               75%   \n",
       "2           0.00              53%              0.00                0%   \n",
       "3           0.29              44%              1.01               23%   \n",
       "4           0.33              33%              0.33               50%   \n",
       "\n",
       "   subs_attempted_average  height reach    stance  sig_str_landed_per_min  \\\n",
       "0                     0.0  5' 11\"   NaN  Orthodox                    3.29   \n",
       "1                     0.0   6' 2\"   72\"  Southpaw                    3.87   \n",
       "2                     0.0   6' 2\"   79\"  Orthodox                    5.38   \n",
       "3                     0.1   6' 3\"   76\"  Orthodox                    2.41   \n",
       "4                     0.0  5' 11\"   71\"  Orthodox                    3.80   \n",
       "\n",
       "  average_fight_time  sig_str_absorbed_per_min sig_str_defense  \\\n",
       "0              08:58                      4.41             57%   \n",
       "1              15:00                      3.13             59%   \n",
       "2              08:55                      5.16             54%   \n",
       "3              09:27                      3.02             55%   \n",
       "4              15:00                      4.49             56%   \n",
       "\n",
       "  takedown_defense  \n",
       "0              77%  \n",
       "1               0%  \n",
       "2              75%  \n",
       "3              45%  \n",
       "4               0%  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean nations\n",
    "for index, row in dfTest.iterrows():\n",
    "    nation = row['nation']\n",
    "    if(isinstance(nation, str)):\n",
    "        dfTest.loc[index, 'nation'] = row['nation'].replace(\" \", \"\").lower()\n",
    "\n",
    "dfTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give nation numerical value\n",
    "for index, row in dfTest.iterrows():\n",
    "    nation = row['nation']\n",
    "    vals = list(set(fullNationDict.values()))\n",
    "    nextVal = max(vals)+1\n",
    "    try:\n",
    "        numericalvalue = fullNationDict[nation]\n",
    "    except:\n",
    "        fullNationDict[nation] = nextVal\n",
    "        numericalvalue = fullNationDict[nation]\n",
    "    dfTest.at[index, 'nation'] = numericalvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'str'>, <class 'float'>]\n"
     ]
    }
   ],
   "source": [
    "types = []\n",
    "for index, row in dfTest.iterrows():\n",
    "    types.append(type(row['height']))\n",
    "print(list(set(types)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nickname</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>draws</th>\n",
       "      <th>age</th>\n",
       "      <th>nation</th>\n",
       "      <th>knockdown_avg</th>\n",
       "      <th>sig_str_accuracy</th>\n",
       "      <th>takedown_average</th>\n",
       "      <th>takedown_accuracy</th>\n",
       "      <th>subs_attempted_average</th>\n",
       "      <th>height</th>\n",
       "      <th>reach</th>\n",
       "      <th>stance</th>\n",
       "      <th>sig_str_landed_per_min</th>\n",
       "      <th>average_fight_time</th>\n",
       "      <th>sig_str_absorbed_per_min</th>\n",
       "      <th>sig_str_defense</th>\n",
       "      <th>takedown_defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danny Abbadi</td>\n",
       "      <td>The Assassin</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5' 11\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.29</td>\n",
       "      <td>08:58</td>\n",
       "      <td>4.41</td>\n",
       "      <td>57%</td>\n",
       "      <td>77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hamdy Abdelwahab</td>\n",
       "      <td>The Hammer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>108</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3.00</td>\n",
       "      <td>75%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>72\"</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>3.87</td>\n",
       "      <td>15:00</td>\n",
       "      <td>3.13</td>\n",
       "      <td>59%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mansur AbdulMalik</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>5.38</td>\n",
       "      <td>08:55</td>\n",
       "      <td>5.16</td>\n",
       "      <td>54%</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shamil Abdurakhimov</td>\n",
       "      <td>Abrek</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.01</td>\n",
       "      <td>23%</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>2.41</td>\n",
       "      <td>09:27</td>\n",
       "      <td>3.02</td>\n",
       "      <td>55%</td>\n",
       "      <td>45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daichi Abe</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>50%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5' 11\"</td>\n",
       "      <td>71\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.80</td>\n",
       "      <td>15:00</td>\n",
       "      <td>4.49</td>\n",
       "      <td>56%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name      nickname  wins  losses draws   age nation  \\\n",
       "0         Danny Abbadi  The Assassin   4.0     6.0     0  41.0     52   \n",
       "1     Hamdy Abdelwahab    The Hammer   5.0     0.0     0  31.0    108   \n",
       "2    Mansur AbdulMalik             1   6.0     0.0     0  27.0     52   \n",
       "3  Shamil Abdurakhimov         Abrek  20.0     8.0     0  43.0     55   \n",
       "4           Daichi Abe             2   6.0     2.0     0  32.0     45   \n",
       "\n",
       "   knockdown_avg sig_str_accuracy  takedown_average takedown_accuracy  \\\n",
       "0           0.00             0.38              0.00                0%   \n",
       "1           1.00             0.52              3.00               75%   \n",
       "2           0.00             0.53              0.00                0%   \n",
       "3           0.29             0.44              1.01               23%   \n",
       "4           0.33             0.33              0.33               50%   \n",
       "\n",
       "   subs_attempted_average  height reach    stance  sig_str_landed_per_min  \\\n",
       "0                     0.0  5' 11\"   NaN  Orthodox                    3.29   \n",
       "1                     0.0   6' 2\"   72\"  Southpaw                    3.87   \n",
       "2                     0.0   6' 2\"   79\"  Orthodox                    5.38   \n",
       "3                     0.1   6' 3\"   76\"  Orthodox                    2.41   \n",
       "4                     0.0  5' 11\"   71\"  Orthodox                    3.80   \n",
       "\n",
       "  average_fight_time  sig_str_absorbed_per_min sig_str_defense  \\\n",
       "0              08:58                      4.41             57%   \n",
       "1              15:00                      3.13             59%   \n",
       "2              08:55                      5.16             54%   \n",
       "3              09:27                      3.02             55%   \n",
       "4              15:00                      4.49             56%   \n",
       "\n",
       "  takedown_defense  \n",
       "0              77%  \n",
       "1               0%  \n",
       "2              75%  \n",
       "3              45%  \n",
       "4               0%  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reformat sig_str_accuracy to float\n",
    "for index, row in dfTest.iterrows():\n",
    "    sig = row['sig_str_accuracy']\n",
    "    sig = sig.replace('%', '')\n",
    "    intsig = int(sig)\n",
    "    floatsig = intsig/100\n",
    "    dfTest.at[index, 'sig_str_accuracy'] = floatsig\n",
    "\n",
    "dfTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nickname</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>draws</th>\n",
       "      <th>age</th>\n",
       "      <th>nation</th>\n",
       "      <th>knockdown_avg</th>\n",
       "      <th>sig_str_accuracy</th>\n",
       "      <th>takedown_average</th>\n",
       "      <th>takedown_accuracy</th>\n",
       "      <th>subs_attempted_average</th>\n",
       "      <th>height</th>\n",
       "      <th>reach</th>\n",
       "      <th>stance</th>\n",
       "      <th>sig_str_landed_per_min</th>\n",
       "      <th>average_fight_time</th>\n",
       "      <th>sig_str_absorbed_per_min</th>\n",
       "      <th>sig_str_defense</th>\n",
       "      <th>takedown_defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danny Abbadi</td>\n",
       "      <td>The Assassin</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5' 11\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.29</td>\n",
       "      <td>08:58</td>\n",
       "      <td>4.41</td>\n",
       "      <td>57%</td>\n",
       "      <td>77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hamdy Abdelwahab</td>\n",
       "      <td>The Hammer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>108</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>72\"</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>3.87</td>\n",
       "      <td>15:00</td>\n",
       "      <td>3.13</td>\n",
       "      <td>59%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mansur AbdulMalik</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>5.38</td>\n",
       "      <td>08:55</td>\n",
       "      <td>5.16</td>\n",
       "      <td>54%</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shamil Abdurakhimov</td>\n",
       "      <td>Abrek</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>2.41</td>\n",
       "      <td>09:27</td>\n",
       "      <td>3.02</td>\n",
       "      <td>55%</td>\n",
       "      <td>45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daichi Abe</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5' 11\"</td>\n",
       "      <td>71\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.80</td>\n",
       "      <td>15:00</td>\n",
       "      <td>4.49</td>\n",
       "      <td>56%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name      nickname  wins  losses draws   age nation  \\\n",
       "0         Danny Abbadi  The Assassin   4.0     6.0     0  41.0     52   \n",
       "1     Hamdy Abdelwahab    The Hammer   5.0     0.0     0  31.0    108   \n",
       "2    Mansur AbdulMalik             1   6.0     0.0     0  27.0     52   \n",
       "3  Shamil Abdurakhimov         Abrek  20.0     8.0     0  43.0     55   \n",
       "4           Daichi Abe             2   6.0     2.0     0  32.0     45   \n",
       "\n",
       "   knockdown_avg sig_str_accuracy  takedown_average takedown_accuracy  \\\n",
       "0           0.00             0.38              0.00               0.0   \n",
       "1           1.00             0.52              3.00              0.75   \n",
       "2           0.00             0.53              0.00               0.0   \n",
       "3           0.29             0.44              1.01              0.23   \n",
       "4           0.33             0.33              0.33               0.5   \n",
       "\n",
       "   subs_attempted_average  height reach    stance  sig_str_landed_per_min  \\\n",
       "0                     0.0  5' 11\"   NaN  Orthodox                    3.29   \n",
       "1                     0.0   6' 2\"   72\"  Southpaw                    3.87   \n",
       "2                     0.0   6' 2\"   79\"  Orthodox                    5.38   \n",
       "3                     0.1   6' 3\"   76\"  Orthodox                    2.41   \n",
       "4                     0.0  5' 11\"   71\"  Orthodox                    3.80   \n",
       "\n",
       "  average_fight_time  sig_str_absorbed_per_min sig_str_defense  \\\n",
       "0              08:58                      4.41             57%   \n",
       "1              15:00                      3.13             59%   \n",
       "2              08:55                      5.16             54%   \n",
       "3              09:27                      3.02             55%   \n",
       "4              15:00                      4.49             56%   \n",
       "\n",
       "  takedown_defense  \n",
       "0              77%  \n",
       "1               0%  \n",
       "2              75%  \n",
       "3              45%  \n",
       "4               0%  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reformat takedown_accuracy to float\n",
    "for index, row in dfTest.iterrows():\n",
    "    tda = row['takedown_accuracy']\n",
    "    tda = tda.replace('%', '')\n",
    "    inttda = int(tda)\n",
    "    floattda = inttda/100\n",
    "    dfTest.at[index, 'takedown_accuracy'] = floattda\n",
    "\n",
    "dfTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nickname</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>draws</th>\n",
       "      <th>age</th>\n",
       "      <th>nation</th>\n",
       "      <th>knockdown_avg</th>\n",
       "      <th>sig_str_accuracy</th>\n",
       "      <th>takedown_average</th>\n",
       "      <th>takedown_accuracy</th>\n",
       "      <th>subs_attempted_average</th>\n",
       "      <th>height</th>\n",
       "      <th>reach</th>\n",
       "      <th>stance</th>\n",
       "      <th>sig_str_landed_per_min</th>\n",
       "      <th>average_fight_time</th>\n",
       "      <th>sig_str_absorbed_per_min</th>\n",
       "      <th>sig_str_defense</th>\n",
       "      <th>takedown_defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danny Abbadi</td>\n",
       "      <td>The Assassin</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.29</td>\n",
       "      <td>08:58</td>\n",
       "      <td>4.41</td>\n",
       "      <td>57%</td>\n",
       "      <td>77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hamdy Abdelwahab</td>\n",
       "      <td>The Hammer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>108</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74</td>\n",
       "      <td>72\"</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>3.87</td>\n",
       "      <td>15:00</td>\n",
       "      <td>3.13</td>\n",
       "      <td>59%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mansur AbdulMalik</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74</td>\n",
       "      <td>79\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>5.38</td>\n",
       "      <td>08:55</td>\n",
       "      <td>5.16</td>\n",
       "      <td>54%</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shamil Abdurakhimov</td>\n",
       "      <td>Abrek</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.1</td>\n",
       "      <td>75</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>2.41</td>\n",
       "      <td>09:27</td>\n",
       "      <td>3.02</td>\n",
       "      <td>55%</td>\n",
       "      <td>45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daichi Abe</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71</td>\n",
       "      <td>71\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.80</td>\n",
       "      <td>15:00</td>\n",
       "      <td>4.49</td>\n",
       "      <td>56%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name      nickname  wins  losses draws   age nation  \\\n",
       "0         Danny Abbadi  The Assassin   4.0     6.0     0  41.0     52   \n",
       "1     Hamdy Abdelwahab    The Hammer   5.0     0.0     0  31.0    108   \n",
       "2    Mansur AbdulMalik             1   6.0     0.0     0  27.0     52   \n",
       "3  Shamil Abdurakhimov         Abrek  20.0     8.0     0  43.0     55   \n",
       "4           Daichi Abe             2   6.0     2.0     0  32.0     45   \n",
       "\n",
       "   knockdown_avg sig_str_accuracy  takedown_average takedown_accuracy  \\\n",
       "0           0.00             0.38              0.00               0.0   \n",
       "1           1.00             0.52              3.00              0.75   \n",
       "2           0.00             0.53              0.00               0.0   \n",
       "3           0.29             0.44              1.01              0.23   \n",
       "4           0.33             0.33              0.33               0.5   \n",
       "\n",
       "   subs_attempted_average height reach    stance  sig_str_landed_per_min  \\\n",
       "0                     0.0     71   NaN  Orthodox                    3.29   \n",
       "1                     0.0     74   72\"  Southpaw                    3.87   \n",
       "2                     0.0     74   79\"  Orthodox                    5.38   \n",
       "3                     0.1     75   76\"  Orthodox                    2.41   \n",
       "4                     0.0     71   71\"  Orthodox                    3.80   \n",
       "\n",
       "  average_fight_time  sig_str_absorbed_per_min sig_str_defense  \\\n",
       "0              08:58                      4.41             57%   \n",
       "1              15:00                      3.13             59%   \n",
       "2              08:55                      5.16             54%   \n",
       "3              09:27                      3.02             55%   \n",
       "4              15:00                      4.49             56%   \n",
       "\n",
       "  takedown_defense  \n",
       "0              77%  \n",
       "1               0%  \n",
       "2              75%  \n",
       "3              45%  \n",
       "4               0%  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reformat height to be displayed in inches\n",
    "for index, row in dfTest.iterrows():\n",
    "    height = row['height']\n",
    "    if(isinstance(height, str)):\n",
    "        height = height.replace('\"', '').replace(\"'\", '')\n",
    "        listheight = height.split(' ')\n",
    "        if len(listheight)>1:\n",
    "            feet = int(listheight[0])\n",
    "            inches = int(listheight[1])\n",
    "            height = feet*12+inches\n",
    "        dfTest.at[index, 'height'] = height\n",
    "        \n",
    "dfTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nickname</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>draws</th>\n",
       "      <th>age</th>\n",
       "      <th>nation</th>\n",
       "      <th>knockdown_avg</th>\n",
       "      <th>sig_str_accuracy</th>\n",
       "      <th>takedown_average</th>\n",
       "      <th>takedown_accuracy</th>\n",
       "      <th>subs_attempted_average</th>\n",
       "      <th>height</th>\n",
       "      <th>reach</th>\n",
       "      <th>stance</th>\n",
       "      <th>sig_str_landed_per_min</th>\n",
       "      <th>average_fight_time</th>\n",
       "      <th>sig_str_absorbed_per_min</th>\n",
       "      <th>sig_str_defense</th>\n",
       "      <th>takedown_defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danny Abbadi</td>\n",
       "      <td>The Assassin</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.29</td>\n",
       "      <td>08:58</td>\n",
       "      <td>4.41</td>\n",
       "      <td>57%</td>\n",
       "      <td>77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hamdy Abdelwahab</td>\n",
       "      <td>The Hammer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>108</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74</td>\n",
       "      <td>72</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>3.87</td>\n",
       "      <td>15:00</td>\n",
       "      <td>3.13</td>\n",
       "      <td>59%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mansur AbdulMalik</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74</td>\n",
       "      <td>79</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>5.38</td>\n",
       "      <td>08:55</td>\n",
       "      <td>5.16</td>\n",
       "      <td>54%</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shamil Abdurakhimov</td>\n",
       "      <td>Abrek</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.1</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>2.41</td>\n",
       "      <td>09:27</td>\n",
       "      <td>3.02</td>\n",
       "      <td>55%</td>\n",
       "      <td>45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daichi Abe</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.80</td>\n",
       "      <td>15:00</td>\n",
       "      <td>4.49</td>\n",
       "      <td>56%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name      nickname  wins  losses draws   age nation  \\\n",
       "0         Danny Abbadi  The Assassin   4.0     6.0     0  41.0     52   \n",
       "1     Hamdy Abdelwahab    The Hammer   5.0     0.0     0  31.0    108   \n",
       "2    Mansur AbdulMalik             1   6.0     0.0     0  27.0     52   \n",
       "3  Shamil Abdurakhimov         Abrek  20.0     8.0     0  43.0     55   \n",
       "4           Daichi Abe             2   6.0     2.0     0  32.0     45   \n",
       "\n",
       "   knockdown_avg sig_str_accuracy  takedown_average takedown_accuracy  \\\n",
       "0           0.00             0.38              0.00               0.0   \n",
       "1           1.00             0.52              3.00              0.75   \n",
       "2           0.00             0.53              0.00               0.0   \n",
       "3           0.29             0.44              1.01              0.23   \n",
       "4           0.33             0.33              0.33               0.5   \n",
       "\n",
       "   subs_attempted_average height reach    stance  sig_str_landed_per_min  \\\n",
       "0                     0.0     71   NaN  Orthodox                    3.29   \n",
       "1                     0.0     74    72  Southpaw                    3.87   \n",
       "2                     0.0     74    79  Orthodox                    5.38   \n",
       "3                     0.1     75    76  Orthodox                    2.41   \n",
       "4                     0.0     71    71  Orthodox                    3.80   \n",
       "\n",
       "  average_fight_time  sig_str_absorbed_per_min sig_str_defense  \\\n",
       "0              08:58                      4.41             57%   \n",
       "1              15:00                      3.13             59%   \n",
       "2              08:55                      5.16             54%   \n",
       "3              09:27                      3.02             55%   \n",
       "4              15:00                      4.49             56%   \n",
       "\n",
       "  takedown_defense  \n",
       "0              77%  \n",
       "1               0%  \n",
       "2              75%  \n",
       "3              45%  \n",
       "4               0%  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reformat reach to be displayed in inches\n",
    "for index, row in dfTest.iterrows():\n",
    "    reach = row['reach']\n",
    "    if(isinstance(reach, str)):\n",
    "        reach = reach.replace('\"', '').replace(\"'\", '')\n",
    "    dfTest.at[index, 'reach'] = reach\n",
    "\n",
    "dfTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, 'Open Stance', 'Sideways', 'Southpaw', 'Switch', 'Orthodox']\n"
     ]
    }
   ],
   "source": [
    "stances = []\n",
    "for index, row in dfTest.iterrows():\n",
    "    stance = row['stance']\n",
    "    stances.append(stance)\n",
    "\n",
    "print(list(set(stances)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nickname</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>draws</th>\n",
       "      <th>age</th>\n",
       "      <th>nation</th>\n",
       "      <th>knockdown_avg</th>\n",
       "      <th>sig_str_accuracy</th>\n",
       "      <th>takedown_average</th>\n",
       "      <th>takedown_accuracy</th>\n",
       "      <th>subs_attempted_average</th>\n",
       "      <th>height</th>\n",
       "      <th>reach</th>\n",
       "      <th>stance</th>\n",
       "      <th>sig_str_landed_per_min</th>\n",
       "      <th>average_fight_time</th>\n",
       "      <th>sig_str_absorbed_per_min</th>\n",
       "      <th>sig_str_defense</th>\n",
       "      <th>takedown_defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danny Abbadi</td>\n",
       "      <td>The Assassin</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.29</td>\n",
       "      <td>08:58</td>\n",
       "      <td>4.41</td>\n",
       "      <td>57%</td>\n",
       "      <td>77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hamdy Abdelwahab</td>\n",
       "      <td>The Hammer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>108</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74</td>\n",
       "      <td>72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.87</td>\n",
       "      <td>15:00</td>\n",
       "      <td>3.13</td>\n",
       "      <td>59%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mansur AbdulMalik</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74</td>\n",
       "      <td>79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.38</td>\n",
       "      <td>08:55</td>\n",
       "      <td>5.16</td>\n",
       "      <td>54%</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shamil Abdurakhimov</td>\n",
       "      <td>Abrek</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.1</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.41</td>\n",
       "      <td>09:27</td>\n",
       "      <td>3.02</td>\n",
       "      <td>55%</td>\n",
       "      <td>45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daichi Abe</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>15:00</td>\n",
       "      <td>4.49</td>\n",
       "      <td>56%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name      nickname  wins  losses draws   age nation  \\\n",
       "0         Danny Abbadi  The Assassin   4.0     6.0     0  41.0     52   \n",
       "1     Hamdy Abdelwahab    The Hammer   5.0     0.0     0  31.0    108   \n",
       "2    Mansur AbdulMalik             1   6.0     0.0     0  27.0     52   \n",
       "3  Shamil Abdurakhimov         Abrek  20.0     8.0     0  43.0     55   \n",
       "4           Daichi Abe             2   6.0     2.0     0  32.0     45   \n",
       "\n",
       "   knockdown_avg sig_str_accuracy  takedown_average takedown_accuracy  \\\n",
       "0           0.00             0.38              0.00               0.0   \n",
       "1           1.00             0.52              3.00              0.75   \n",
       "2           0.00             0.53              0.00               0.0   \n",
       "3           0.29             0.44              1.01              0.23   \n",
       "4           0.33             0.33              0.33               0.5   \n",
       "\n",
       "   subs_attempted_average height reach  stance  sig_str_landed_per_min  \\\n",
       "0                     0.0     71   NaN     0.0                    3.29   \n",
       "1                     0.0     74    72     1.0                    3.87   \n",
       "2                     0.0     74    79     0.0                    5.38   \n",
       "3                     0.1     75    76     0.0                    2.41   \n",
       "4                     0.0     71    71     0.0                    3.80   \n",
       "\n",
       "  average_fight_time  sig_str_absorbed_per_min sig_str_defense  \\\n",
       "0              08:58                      4.41             57%   \n",
       "1              15:00                      3.13             59%   \n",
       "2              08:55                      5.16             54%   \n",
       "3              09:27                      3.02             55%   \n",
       "4              15:00                      4.49             56%   \n",
       "\n",
       "  takedown_defense  \n",
       "0              77%  \n",
       "1               0%  \n",
       "2              75%  \n",
       "3              45%  \n",
       "4               0%  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#format stances\n",
    "dfTest['stance'] = dfTest['stance'].replace('Orthodox', 0)\n",
    "\n",
    "dfTest['stance'] = dfTest['stance'].replace('Southpaw', 1)\n",
    "\n",
    "dfTest['stance'] = dfTest['stance'].replace('Open Stance', 2)\n",
    "\n",
    "dfTest['stance'] = dfTest['stance'].replace('Switch', 3)\n",
    "\n",
    "dfTest['stance'] = dfTest['stance'].replace('Sideways', 4)\n",
    "\n",
    "dfTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nickname</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>draws</th>\n",
       "      <th>age</th>\n",
       "      <th>nation</th>\n",
       "      <th>knockdown_avg</th>\n",
       "      <th>sig_str_accuracy</th>\n",
       "      <th>takedown_average</th>\n",
       "      <th>takedown_accuracy</th>\n",
       "      <th>subs_attempted_average</th>\n",
       "      <th>height</th>\n",
       "      <th>reach</th>\n",
       "      <th>stance</th>\n",
       "      <th>sig_str_landed_per_min</th>\n",
       "      <th>average_fight_time</th>\n",
       "      <th>sig_str_absorbed_per_min</th>\n",
       "      <th>sig_str_defense</th>\n",
       "      <th>takedown_defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danny Abbadi</td>\n",
       "      <td>The Assassin</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.29</td>\n",
       "      <td>8.966667</td>\n",
       "      <td>4.41</td>\n",
       "      <td>57%</td>\n",
       "      <td>77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hamdy Abdelwahab</td>\n",
       "      <td>The Hammer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>108</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74</td>\n",
       "      <td>72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.13</td>\n",
       "      <td>59%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mansur AbdulMalik</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74</td>\n",
       "      <td>79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.38</td>\n",
       "      <td>8.916667</td>\n",
       "      <td>5.16</td>\n",
       "      <td>54%</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shamil Abdurakhimov</td>\n",
       "      <td>Abrek</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.1</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.41</td>\n",
       "      <td>9.45</td>\n",
       "      <td>3.02</td>\n",
       "      <td>55%</td>\n",
       "      <td>45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daichi Abe</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.49</td>\n",
       "      <td>56%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name      nickname  wins  losses draws   age nation  \\\n",
       "0         Danny Abbadi  The Assassin   4.0     6.0     0  41.0     52   \n",
       "1     Hamdy Abdelwahab    The Hammer   5.0     0.0     0  31.0    108   \n",
       "2    Mansur AbdulMalik             1   6.0     0.0     0  27.0     52   \n",
       "3  Shamil Abdurakhimov         Abrek  20.0     8.0     0  43.0     55   \n",
       "4           Daichi Abe             2   6.0     2.0     0  32.0     45   \n",
       "\n",
       "   knockdown_avg sig_str_accuracy  takedown_average takedown_accuracy  \\\n",
       "0           0.00             0.38              0.00               0.0   \n",
       "1           1.00             0.52              3.00              0.75   \n",
       "2           0.00             0.53              0.00               0.0   \n",
       "3           0.29             0.44              1.01              0.23   \n",
       "4           0.33             0.33              0.33               0.5   \n",
       "\n",
       "   subs_attempted_average height reach  stance  sig_str_landed_per_min  \\\n",
       "0                     0.0     71   NaN     0.0                    3.29   \n",
       "1                     0.0     74    72     1.0                    3.87   \n",
       "2                     0.0     74    79     0.0                    5.38   \n",
       "3                     0.1     75    76     0.0                    2.41   \n",
       "4                     0.0     71    71     0.0                    3.80   \n",
       "\n",
       "  average_fight_time  sig_str_absorbed_per_min sig_str_defense  \\\n",
       "0           8.966667                      4.41             57%   \n",
       "1               15.0                      3.13             59%   \n",
       "2           8.916667                      5.16             54%   \n",
       "3               9.45                      3.02             55%   \n",
       "4               15.0                      4.49             56%   \n",
       "\n",
       "  takedown_defense  \n",
       "0              77%  \n",
       "1               0%  \n",
       "2              75%  \n",
       "3              45%  \n",
       "4               0%  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#format average fight time\n",
    "for index, row in dfTest.iterrows():\n",
    "    fightTime = row['average_fight_time']\n",
    "    if(isinstance(fightTime, str)):\n",
    "        timeList = fightTime.split(':')\n",
    "        totalTime = float(timeList[0]) + float(timeList[1])/60\n",
    "        dfTest.at[index, 'average_fight_time'] = totalTime\n",
    "\n",
    "dfTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nickname</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>draws</th>\n",
       "      <th>age</th>\n",
       "      <th>nation</th>\n",
       "      <th>knockdown_avg</th>\n",
       "      <th>sig_str_accuracy</th>\n",
       "      <th>takedown_average</th>\n",
       "      <th>takedown_accuracy</th>\n",
       "      <th>subs_attempted_average</th>\n",
       "      <th>height</th>\n",
       "      <th>reach</th>\n",
       "      <th>stance</th>\n",
       "      <th>sig_str_landed_per_min</th>\n",
       "      <th>average_fight_time</th>\n",
       "      <th>sig_str_absorbed_per_min</th>\n",
       "      <th>sig_str_defense</th>\n",
       "      <th>takedown_defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danny Abbadi</td>\n",
       "      <td>The Assassin</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.29</td>\n",
       "      <td>8.966667</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.57</td>\n",
       "      <td>77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hamdy Abdelwahab</td>\n",
       "      <td>The Hammer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>108</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74</td>\n",
       "      <td>72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mansur AbdulMalik</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74</td>\n",
       "      <td>79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.38</td>\n",
       "      <td>8.916667</td>\n",
       "      <td>5.16</td>\n",
       "      <td>0.54</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shamil Abdurakhimov</td>\n",
       "      <td>Abrek</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.1</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.41</td>\n",
       "      <td>9.45</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.55</td>\n",
       "      <td>45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daichi Abe</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name      nickname  wins  losses draws   age nation  \\\n",
       "0         Danny Abbadi  The Assassin   4.0     6.0     0  41.0     52   \n",
       "1     Hamdy Abdelwahab    The Hammer   5.0     0.0     0  31.0    108   \n",
       "2    Mansur AbdulMalik             1   6.0     0.0     0  27.0     52   \n",
       "3  Shamil Abdurakhimov         Abrek  20.0     8.0     0  43.0     55   \n",
       "4           Daichi Abe             2   6.0     2.0     0  32.0     45   \n",
       "\n",
       "   knockdown_avg sig_str_accuracy  takedown_average takedown_accuracy  \\\n",
       "0           0.00             0.38              0.00               0.0   \n",
       "1           1.00             0.52              3.00              0.75   \n",
       "2           0.00             0.53              0.00               0.0   \n",
       "3           0.29             0.44              1.01              0.23   \n",
       "4           0.33             0.33              0.33               0.5   \n",
       "\n",
       "   subs_attempted_average height reach  stance  sig_str_landed_per_min  \\\n",
       "0                     0.0     71   NaN     0.0                    3.29   \n",
       "1                     0.0     74    72     1.0                    3.87   \n",
       "2                     0.0     74    79     0.0                    5.38   \n",
       "3                     0.1     75    76     0.0                    2.41   \n",
       "4                     0.0     71    71     0.0                    3.80   \n",
       "\n",
       "  average_fight_time  sig_str_absorbed_per_min sig_str_defense  \\\n",
       "0           8.966667                      4.41            0.57   \n",
       "1               15.0                      3.13            0.59   \n",
       "2           8.916667                      5.16            0.54   \n",
       "3               9.45                      3.02            0.55   \n",
       "4               15.0                      4.49            0.56   \n",
       "\n",
       "  takedown_defense  \n",
       "0              77%  \n",
       "1               0%  \n",
       "2              75%  \n",
       "3              45%  \n",
       "4               0%  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reformat sig_str_defense to float\n",
    "for index, row in dfTest.iterrows():\n",
    "    ssd = row['sig_str_defense']\n",
    "    ssd = ssd.replace('%', '')\n",
    "    intssd = int(ssd)\n",
    "    floatssd = intssd/100\n",
    "    dfTest.at[index, 'sig_str_defense'] = floatssd\n",
    "\n",
    "dfTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nickname</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>draws</th>\n",
       "      <th>age</th>\n",
       "      <th>nation</th>\n",
       "      <th>knockdown_avg</th>\n",
       "      <th>sig_str_accuracy</th>\n",
       "      <th>takedown_average</th>\n",
       "      <th>takedown_accuracy</th>\n",
       "      <th>subs_attempted_average</th>\n",
       "      <th>height</th>\n",
       "      <th>reach</th>\n",
       "      <th>stance</th>\n",
       "      <th>sig_str_landed_per_min</th>\n",
       "      <th>average_fight_time</th>\n",
       "      <th>sig_str_absorbed_per_min</th>\n",
       "      <th>sig_str_defense</th>\n",
       "      <th>takedown_defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danny Abbadi</td>\n",
       "      <td>The Assassin</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.29</td>\n",
       "      <td>8.966667</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hamdy Abdelwahab</td>\n",
       "      <td>The Hammer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>108</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74</td>\n",
       "      <td>72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mansur AbdulMalik</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74</td>\n",
       "      <td>79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.38</td>\n",
       "      <td>8.916667</td>\n",
       "      <td>5.16</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shamil Abdurakhimov</td>\n",
       "      <td>Abrek</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.1</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.41</td>\n",
       "      <td>9.45</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daichi Abe</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name      nickname  wins  losses draws   age nation  \\\n",
       "0         Danny Abbadi  The Assassin   4.0     6.0     0  41.0     52   \n",
       "1     Hamdy Abdelwahab    The Hammer   5.0     0.0     0  31.0    108   \n",
       "2    Mansur AbdulMalik             1   6.0     0.0     0  27.0     52   \n",
       "3  Shamil Abdurakhimov         Abrek  20.0     8.0     0  43.0     55   \n",
       "4           Daichi Abe             2   6.0     2.0     0  32.0     45   \n",
       "\n",
       "   knockdown_avg sig_str_accuracy  takedown_average takedown_accuracy  \\\n",
       "0           0.00             0.38              0.00               0.0   \n",
       "1           1.00             0.52              3.00              0.75   \n",
       "2           0.00             0.53              0.00               0.0   \n",
       "3           0.29             0.44              1.01              0.23   \n",
       "4           0.33             0.33              0.33               0.5   \n",
       "\n",
       "   subs_attempted_average height reach  stance  sig_str_landed_per_min  \\\n",
       "0                     0.0     71   NaN     0.0                    3.29   \n",
       "1                     0.0     74    72     1.0                    3.87   \n",
       "2                     0.0     74    79     0.0                    5.38   \n",
       "3                     0.1     75    76     0.0                    2.41   \n",
       "4                     0.0     71    71     0.0                    3.80   \n",
       "\n",
       "  average_fight_time  sig_str_absorbed_per_min sig_str_defense  \\\n",
       "0           8.966667                      4.41            0.57   \n",
       "1               15.0                      3.13            0.59   \n",
       "2           8.916667                      5.16            0.54   \n",
       "3               9.45                      3.02            0.55   \n",
       "4               15.0                      4.49            0.56   \n",
       "\n",
       "  takedown_defense  \n",
       "0             0.77  \n",
       "1              0.0  \n",
       "2             0.75  \n",
       "3             0.45  \n",
       "4              0.0  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reformat sig_str_defense to float\n",
    "for index, row in dfTest.iterrows():\n",
    "    td = row['takedown_defense']\n",
    "    td = td.replace('%', '')\n",
    "    inttd = int(td)\n",
    "    floattd = inttd/100\n",
    "    dfTest.at[index, 'takedown_defense'] = floattd\n",
    "\n",
    "dfTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2755\n",
      "2016\n"
     ]
    }
   ],
   "source": [
    "print(len(dfTest))\n",
    "dfTest.dropna(inplace=True)\n",
    "print(len(dfTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfTest.to_csv(f'careerDataFormatTest{dateToday}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fight</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Winner</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Fight, Prediction, Predicted, Winner, Result]\n",
       "Index: []"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define column headers\n",
    "column_headers = [\n",
    "    'Fight', 'Prediction', 'Predicted', 'Winner', 'Result'\n",
    "]\n",
    "\n",
    "#create dataframe using headers\n",
    "dfTracking = pd.DataFrame(columns=column_headers)\n",
    "dfTracking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fight</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Winner</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex Pereira vs Khalil Rountree Jr</td>\n",
       "      <td>0.559040</td>\n",
       "      <td>Khalil Rountree Jr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raquel Pennington vs Julianna Pena</td>\n",
       "      <td>0.410115</td>\n",
       "      <td>Raquel Pennington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jose Aldo vs Mario Bautista</td>\n",
       "      <td>0.741064</td>\n",
       "      <td>Mario Bautista</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roman Dolidze vs Kevin Holland</td>\n",
       "      <td>0.226893</td>\n",
       "      <td>Roman Dolidze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ketlen Vieira vs Kayla Harrison</td>\n",
       "      <td>0.990812</td>\n",
       "      <td>Kayla Harrison</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Fight  Prediction           Predicted Winner  \\\n",
       "0  Alex Pereira vs Khalil Rountree Jr    0.559040  Khalil Rountree Jr    NaN   \n",
       "1  Raquel Pennington vs Julianna Pena    0.410115   Raquel Pennington    NaN   \n",
       "2         Jose Aldo vs Mario Bautista    0.741064      Mario Bautista    NaN   \n",
       "3      Roman Dolidze vs Kevin Holland    0.226893       Roman Dolidze    NaN   \n",
       "4     Ketlen Vieira vs Kayla Harrison    0.990812      Kayla Harrison    NaN   \n",
       "\n",
       "  Result  \n",
       "0    NaN  \n",
       "1    NaN  \n",
       "2    NaN  \n",
       "3    NaN  \n",
       "4    NaN  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPrevPreds = pd.read_csv(f'predictions{mostRecentDatabase}.csv')\n",
    "dfPrevPreds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fight</th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>event</th>\n",
       "      <th>referee</th>\n",
       "      <th>method_of_victory</th>\n",
       "      <th>date</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>...</th>\n",
       "      <th>redCorner_subs_attempted</th>\n",
       "      <th>blueCorner_subs_attempted</th>\n",
       "      <th>round</th>\n",
       "      <th>time</th>\n",
       "      <th>redCorner_height</th>\n",
       "      <th>blueCorner_height</th>\n",
       "      <th>redCorner_reach</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex Pereira vs Khalil Rountree Jr</td>\n",
       "      <td>Alex Pereira</td>\n",
       "      <td>Khalil Rountree Jr</td>\n",
       "      <td>Alex Pereira</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Marc Goddard</td>\n",
       "      <td>KO/TKO</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4:32</td>\n",
       "      <td>6' 4\"</td>\n",
       "      <td>6' 1\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raquel Pennington vs Julianna Pena</td>\n",
       "      <td>Raquel Pennington</td>\n",
       "      <td>Julianna Pena</td>\n",
       "      <td>Julianna Pena</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Jason Herzog</td>\n",
       "      <td>Decision - Split</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>67\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jose Aldo vs Mario Bautista</td>\n",
       "      <td>Jose Aldo</td>\n",
       "      <td>Mario Bautista</td>\n",
       "      <td>Mario Bautista</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Mike Beltran</td>\n",
       "      <td>Decision - Split</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>70\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roman Dolidze vs Kevin Holland</td>\n",
       "      <td>Roman Dolidze</td>\n",
       "      <td>Kevin Holland</td>\n",
       "      <td>Roman Dolidze</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Jason Herzog</td>\n",
       "      <td>KO/TKO</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5:00</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kayla Harrison vs Ketlen Vieira</td>\n",
       "      <td>Ketlen Vieira</td>\n",
       "      <td>Kayla Harrison</td>\n",
       "      <td>Kayla Harrison</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Marc Goddard</td>\n",
       "      <td>Decision - Unanimous</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>68\"</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                fight          redCorner          blueCorner  \\\n",
       "0  Alex Pereira vs Khalil Rountree Jr       Alex Pereira  Khalil Rountree Jr   \n",
       "1  Raquel Pennington vs Julianna Pena  Raquel Pennington       Julianna Pena   \n",
       "2         Jose Aldo vs Mario Bautista          Jose Aldo      Mario Bautista   \n",
       "3      Roman Dolidze vs Kevin Holland      Roman Dolidze       Kevin Holland   \n",
       "4     Kayla Harrison vs Ketlen Vieira      Ketlen Vieira      Kayla Harrison   \n",
       "\n",
       "           winner                              event       referee  \\\n",
       "0    Alex Pereira  UFC 307: Pereira vs. Rountree Jr.  Marc Goddard   \n",
       "1   Julianna Pena  UFC 307: Pereira vs. Rountree Jr.  Jason Herzog   \n",
       "2  Mario Bautista  UFC 307: Pereira vs. Rountree Jr.  Mike Beltran   \n",
       "3   Roman Dolidze  UFC 307: Pereira vs. Rountree Jr.  Jason Herzog   \n",
       "4  Kayla Harrison  UFC 307: Pereira vs. Rountree Jr.  Marc Goddard   \n",
       "\n",
       "      method_of_victory        date         venue title_fight  ...  \\\n",
       "0                KO/TKO  10.05.2024  Delta Center         yes  ...   \n",
       "1      Decision - Split  10.05.2024  Delta Center         yes  ...   \n",
       "2      Decision - Split  10.05.2024  Delta Center          no  ...   \n",
       "3                KO/TKO  10.05.2024  Delta Center          no  ...   \n",
       "4  Decision - Unanimous  10.05.2024  Delta Center          no  ...   \n",
       "\n",
       "  redCorner_subs_attempted blueCorner_subs_attempted round  time  \\\n",
       "0                        0                         0     4  4:32   \n",
       "1                        0                         1     5  5:00   \n",
       "2                        0                         0     3  5:00   \n",
       "3                        0                         0     1  5:00   \n",
       "4                        0                         0     3  5:00   \n",
       "\n",
       "   redCorner_height  blueCorner_height  redCorner_reach  blueCorner_reach  \\\n",
       "0             6' 4\"              6' 1\"              79\"               76\"   \n",
       "1             5' 7\"              5' 6\"              67\"               69\"   \n",
       "2             5' 7\"              5' 9\"              70\"               69\"   \n",
       "3             6' 2\"              6' 3\"              76\"               81\"   \n",
       "4             5' 8\"              5' 8\"              68\"               66\"   \n",
       "\n",
       "   redCorner_stance blueCorner_stance  \n",
       "0          Orthodox          Southpaw  \n",
       "1          Orthodox          Orthodox  \n",
       "2          Orthodox            Switch  \n",
       "3          Orthodox          Orthodox  \n",
       "4          Orthodox          Southpaw  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "dateToday = datetime.today().date()\n",
    "dfCheck = pd.read_csv(f'databaseUpdated{dateToday}.csv')\n",
    "dfCheck.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#find index of the last fight of the previous event\n",
    "change = dfCheck['event'] != dfCheck['event'].shift(1)\n",
    "\n",
    "# Find the first index where the 'event' is different\n",
    "indexDifferent = dfCheck[change].index[int(numberOfEventsForUpdate)] \n",
    "\n",
    "limitOfCheck = indexDifferent\n",
    "\n",
    "print(limitOfCheck)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fight</th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>event</th>\n",
       "      <th>referee</th>\n",
       "      <th>method_of_victory</th>\n",
       "      <th>date</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>...</th>\n",
       "      <th>redCorner_subs_attempted</th>\n",
       "      <th>blueCorner_subs_attempted</th>\n",
       "      <th>round</th>\n",
       "      <th>time</th>\n",
       "      <th>redCorner_height</th>\n",
       "      <th>blueCorner_height</th>\n",
       "      <th>redCorner_reach</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex Pereira vs Khalil Rountree Jr</td>\n",
       "      <td>Alex Pereira</td>\n",
       "      <td>Khalil Rountree Jr</td>\n",
       "      <td>Alex Pereira</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Marc Goddard</td>\n",
       "      <td>KO/TKO</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4:32</td>\n",
       "      <td>6' 4\"</td>\n",
       "      <td>6' 1\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raquel Pennington vs Julianna Pena</td>\n",
       "      <td>Raquel Pennington</td>\n",
       "      <td>Julianna Pena</td>\n",
       "      <td>Julianna Pena</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Jason Herzog</td>\n",
       "      <td>Decision - Split</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>67\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jose Aldo vs Mario Bautista</td>\n",
       "      <td>Jose Aldo</td>\n",
       "      <td>Mario Bautista</td>\n",
       "      <td>Mario Bautista</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Mike Beltran</td>\n",
       "      <td>Decision - Split</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>70\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roman Dolidze vs Kevin Holland</td>\n",
       "      <td>Roman Dolidze</td>\n",
       "      <td>Kevin Holland</td>\n",
       "      <td>Roman Dolidze</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Jason Herzog</td>\n",
       "      <td>KO/TKO</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5:00</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kayla Harrison vs Ketlen Vieira</td>\n",
       "      <td>Ketlen Vieira</td>\n",
       "      <td>Kayla Harrison</td>\n",
       "      <td>Kayla Harrison</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Marc Goddard</td>\n",
       "      <td>Decision - Unanimous</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>68\"</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                fight          redCorner          blueCorner  \\\n",
       "0  Alex Pereira vs Khalil Rountree Jr       Alex Pereira  Khalil Rountree Jr   \n",
       "1  Raquel Pennington vs Julianna Pena  Raquel Pennington       Julianna Pena   \n",
       "2         Jose Aldo vs Mario Bautista          Jose Aldo      Mario Bautista   \n",
       "3      Roman Dolidze vs Kevin Holland      Roman Dolidze       Kevin Holland   \n",
       "4     Kayla Harrison vs Ketlen Vieira      Ketlen Vieira      Kayla Harrison   \n",
       "\n",
       "           winner                              event       referee  \\\n",
       "0    Alex Pereira  UFC 307: Pereira vs. Rountree Jr.  Marc Goddard   \n",
       "1   Julianna Pena  UFC 307: Pereira vs. Rountree Jr.  Jason Herzog   \n",
       "2  Mario Bautista  UFC 307: Pereira vs. Rountree Jr.  Mike Beltran   \n",
       "3   Roman Dolidze  UFC 307: Pereira vs. Rountree Jr.  Jason Herzog   \n",
       "4  Kayla Harrison  UFC 307: Pereira vs. Rountree Jr.  Marc Goddard   \n",
       "\n",
       "      method_of_victory        date         venue title_fight  ...  \\\n",
       "0                KO/TKO  10.05.2024  Delta Center         yes  ...   \n",
       "1      Decision - Split  10.05.2024  Delta Center         yes  ...   \n",
       "2      Decision - Split  10.05.2024  Delta Center          no  ...   \n",
       "3                KO/TKO  10.05.2024  Delta Center          no  ...   \n",
       "4  Decision - Unanimous  10.05.2024  Delta Center          no  ...   \n",
       "\n",
       "  redCorner_subs_attempted blueCorner_subs_attempted round  time  \\\n",
       "0                        0                         0     4  4:32   \n",
       "1                        0                         1     5  5:00   \n",
       "2                        0                         0     3  5:00   \n",
       "3                        0                         0     1  5:00   \n",
       "4                        0                         0     3  5:00   \n",
       "\n",
       "   redCorner_height  blueCorner_height  redCorner_reach  blueCorner_reach  \\\n",
       "0             6' 4\"              6' 1\"              79\"               76\"   \n",
       "1             5' 7\"              5' 6\"              67\"               69\"   \n",
       "2             5' 7\"              5' 9\"              70\"               69\"   \n",
       "3             6' 2\"              6' 3\"              76\"               81\"   \n",
       "4             5' 8\"              5' 8\"              68\"               66\"   \n",
       "\n",
       "   redCorner_stance blueCorner_stance  \n",
       "0          Orthodox          Southpaw  \n",
       "1          Orthodox          Orthodox  \n",
       "2          Orthodox            Switch  \n",
       "3          Orthodox          Orthodox  \n",
       "4          Orthodox          Southpaw  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMissed = dfCheck.iloc[:limitOfCheck]\n",
    "dfMissed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "change_indices = dfMissed[dfMissed['event'] != dfMissed['event'].shift(1)].index\n",
    "last_change_index = change_indices[-1]\n",
    "print(last_change_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fight</th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>event</th>\n",
       "      <th>referee</th>\n",
       "      <th>method_of_victory</th>\n",
       "      <th>date</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>...</th>\n",
       "      <th>redCorner_subs_attempted</th>\n",
       "      <th>blueCorner_subs_attempted</th>\n",
       "      <th>round</th>\n",
       "      <th>time</th>\n",
       "      <th>redCorner_height</th>\n",
       "      <th>blueCorner_height</th>\n",
       "      <th>redCorner_reach</th>\n",
       "      <th>blueCorner_reach</th>\n",
       "      <th>redCorner_stance</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex Pereira vs Khalil Rountree Jr</td>\n",
       "      <td>Alex Pereira</td>\n",
       "      <td>Khalil Rountree Jr</td>\n",
       "      <td>Alex Pereira</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Marc Goddard</td>\n",
       "      <td>KO/TKO</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4:32</td>\n",
       "      <td>6' 4\"</td>\n",
       "      <td>6' 1\"</td>\n",
       "      <td>79\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raquel Pennington vs Julianna Pena</td>\n",
       "      <td>Raquel Pennington</td>\n",
       "      <td>Julianna Pena</td>\n",
       "      <td>Julianna Pena</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Jason Herzog</td>\n",
       "      <td>Decision - Split</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>67\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jose Aldo vs Mario Bautista</td>\n",
       "      <td>Jose Aldo</td>\n",
       "      <td>Mario Bautista</td>\n",
       "      <td>Mario Bautista</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Mike Beltran</td>\n",
       "      <td>Decision - Split</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>70\"</td>\n",
       "      <td>69\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Switch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roman Dolidze vs Kevin Holland</td>\n",
       "      <td>Roman Dolidze</td>\n",
       "      <td>Kevin Holland</td>\n",
       "      <td>Roman Dolidze</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Jason Herzog</td>\n",
       "      <td>KO/TKO</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5:00</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>6' 3\"</td>\n",
       "      <td>76\"</td>\n",
       "      <td>81\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Orthodox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kayla Harrison vs Ketlen Vieira</td>\n",
       "      <td>Ketlen Vieira</td>\n",
       "      <td>Kayla Harrison</td>\n",
       "      <td>Kayla Harrison</td>\n",
       "      <td>UFC 307: Pereira vs. Rountree Jr.</td>\n",
       "      <td>Marc Goddard</td>\n",
       "      <td>Decision - Unanimous</td>\n",
       "      <td>10.05.2024</td>\n",
       "      <td>Delta Center</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5:00</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>68\"</td>\n",
       "      <td>66\"</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>Southpaw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                fight          redCorner          blueCorner  \\\n",
       "0  Alex Pereira vs Khalil Rountree Jr       Alex Pereira  Khalil Rountree Jr   \n",
       "1  Raquel Pennington vs Julianna Pena  Raquel Pennington       Julianna Pena   \n",
       "2         Jose Aldo vs Mario Bautista          Jose Aldo      Mario Bautista   \n",
       "3      Roman Dolidze vs Kevin Holland      Roman Dolidze       Kevin Holland   \n",
       "4     Kayla Harrison vs Ketlen Vieira      Ketlen Vieira      Kayla Harrison   \n",
       "\n",
       "           winner                              event       referee  \\\n",
       "0    Alex Pereira  UFC 307: Pereira vs. Rountree Jr.  Marc Goddard   \n",
       "1   Julianna Pena  UFC 307: Pereira vs. Rountree Jr.  Jason Herzog   \n",
       "2  Mario Bautista  UFC 307: Pereira vs. Rountree Jr.  Mike Beltran   \n",
       "3   Roman Dolidze  UFC 307: Pereira vs. Rountree Jr.  Jason Herzog   \n",
       "4  Kayla Harrison  UFC 307: Pereira vs. Rountree Jr.  Marc Goddard   \n",
       "\n",
       "      method_of_victory        date         venue title_fight  ...  \\\n",
       "0                KO/TKO  10.05.2024  Delta Center         yes  ...   \n",
       "1      Decision - Split  10.05.2024  Delta Center         yes  ...   \n",
       "2      Decision - Split  10.05.2024  Delta Center          no  ...   \n",
       "3                KO/TKO  10.05.2024  Delta Center          no  ...   \n",
       "4  Decision - Unanimous  10.05.2024  Delta Center          no  ...   \n",
       "\n",
       "  redCorner_subs_attempted blueCorner_subs_attempted round  time  \\\n",
       "0                        0                         0     4  4:32   \n",
       "1                        0                         1     5  5:00   \n",
       "2                        0                         0     3  5:00   \n",
       "3                        0                         0     1  5:00   \n",
       "4                        0                         0     3  5:00   \n",
       "\n",
       "   redCorner_height  blueCorner_height  redCorner_reach  blueCorner_reach  \\\n",
       "0             6' 4\"              6' 1\"              79\"               76\"   \n",
       "1             5' 7\"              5' 6\"              67\"               69\"   \n",
       "2             5' 7\"              5' 9\"              70\"               69\"   \n",
       "3             6' 2\"              6' 3\"              76\"               81\"   \n",
       "4             5' 8\"              5' 8\"              68\"               66\"   \n",
       "\n",
       "   redCorner_stance blueCorner_stance  \n",
       "0          Orthodox          Southpaw  \n",
       "1          Orthodox          Orthodox  \n",
       "2          Orthodox            Switch  \n",
       "3          Orthodox          Orthodox  \n",
       "4          Orthodox          Southpaw  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Limits df to the last predicted event\n",
    "dfCheck = dfMissed.iloc[last_change_index:]\n",
    "print(limitOfCheck)\n",
    "dfCheck.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fight</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Winner</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex Pereira vs Khalil Rountree Jr</td>\n",
       "      <td>0.559040</td>\n",
       "      <td>Khalil Rountree Jr</td>\n",
       "      <td>Alex Pereira</td>\n",
       "      <td>Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raquel Pennington vs Julianna Pena</td>\n",
       "      <td>0.410115</td>\n",
       "      <td>Raquel Pennington</td>\n",
       "      <td>Julianna Pena</td>\n",
       "      <td>Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jose Aldo vs Mario Bautista</td>\n",
       "      <td>0.741064</td>\n",
       "      <td>Mario Bautista</td>\n",
       "      <td>Mario Bautista</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roman Dolidze vs Kevin Holland</td>\n",
       "      <td>0.226893</td>\n",
       "      <td>Roman Dolidze</td>\n",
       "      <td>Roman Dolidze</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ketlen Vieira vs Kayla Harrison</td>\n",
       "      <td>0.990812</td>\n",
       "      <td>Kayla Harrison</td>\n",
       "      <td>Kayla Harrison</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Fight  Prediction           Predicted  \\\n",
       "0  Alex Pereira vs Khalil Rountree Jr    0.559040  Khalil Rountree Jr   \n",
       "1  Raquel Pennington vs Julianna Pena    0.410115   Raquel Pennington   \n",
       "2         Jose Aldo vs Mario Bautista    0.741064      Mario Bautista   \n",
       "3      Roman Dolidze vs Kevin Holland    0.226893       Roman Dolidze   \n",
       "4     Ketlen Vieira vs Kayla Harrison    0.990812      Kayla Harrison   \n",
       "\n",
       "           Winner     Result  \n",
       "0    Alex Pereira  Incorrect  \n",
       "1   Julianna Pena  Incorrect  \n",
       "2  Mario Bautista    Correct  \n",
       "3   Roman Dolidze    Correct  \n",
       "4  Kayla Harrison    Correct  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in dfPrevPreds.iterrows():\n",
    "    winner = None\n",
    "    if(type(row['Result']) != str):\n",
    "        fight = row['Fight']\n",
    "        redAndBlue = fight.split(' vs ')\n",
    "        redCorner = redAndBlue[0]\n",
    "        blueCorner = redAndBlue[1]\n",
    "        prediction = row['Prediction']\n",
    "        #find indexes of fight match\n",
    "        redCornerCheck = dfCheck[:limitOfCheck][dfCheck['redCorner'][:limitOfCheck] == redCorner].index[0]\n",
    "        blueCornerCheck = dfCheck[:limitOfCheck][dfCheck['blueCorner'][:limitOfCheck] == blueCorner].index[0]\n",
    "        if(int(redCornerCheck) == int(blueCornerCheck)):\n",
    "            indexCheck = int(redCornerCheck)\n",
    "            winner = dfCheck.loc[indexCheck, 'winner']\n",
    "            if(winner == redCorner and float(prediction) < 0.5):\n",
    "                dfPrevPreds.loc[index, 'Result'] = 'Correct'\n",
    "                dfPrevPreds.loc[index, 'Winner'] = winner\n",
    "            elif(winner == blueCorner and float(prediction) > 0.5):\n",
    "                dfPrevPreds.loc[index, 'Result'] = 'Correct'\n",
    "                dfPrevPreds.loc[index, 'Winner'] = winner\n",
    "            else:\n",
    "                dfPrevPreds.loc[index, 'Result'] = 'Incorrect'\n",
    "                dfPrevPreds.loc[index, 'Winner'] = winner\n",
    "        if(type(row['Result']) != str):\n",
    "            #upon exception, results get scraped as names will match here\n",
    "            url = 'https://www.espn.com/mma/schedule/_/league/ufc'\n",
    "            headers = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246\"}\n",
    "\n",
    "            #site request\n",
    "            site = requests.get(url, headers=headers)\n",
    "            soup = BeautifulSoup(site.content, 'html.parser')  \n",
    "\n",
    "            #get table\n",
    "            tbodys = soup.find_all('tbody', class_=re.compile('Table__TBODY')) \n",
    "\n",
    "            #get part\n",
    "            table = tbodys[len(tbodys)-1]\n",
    "            links = table.find_all('a', class_=re.compile('AnchorLink'))\n",
    "            lastEvent = links[int(numberOfEventsForUpdate)-1]\n",
    "            part = lastEvent['href']\n",
    "\n",
    "            url = f'https://www.espn.com{part}'\n",
    "            headers = {'User-Agent': \"insomnia/9.1.1\"}\n",
    "\n",
    "            #site request\n",
    "            site = requests.get(url, headers=headers)\n",
    "            soup = BeautifulSoup(site.content, 'html.parser')\n",
    "\n",
    "            right = soup.find_all('div', class_=re.compile('MMACompetitor relative flex flex-uniform pl6 MMACompetitor--desktop'))\n",
    "            left = soup.find_all('div', class_=re.compile('MMACompetitor relative flex flex-uniform pr6 flex-row-reverse MMACompetitor--desktop'))\n",
    "\n",
    "            #find match\n",
    "            for item1, item2 in zip(left, right):\n",
    "                if redCorner in item1.text.strip() and blueCorner in item2.text.strip():\n",
    "                    if(item1.find('svg') is not None):\n",
    "                        winner = redCorner\n",
    "                    if(item2.find('svg') is not None):\n",
    "                        winner = blueCorner\n",
    "            if(winner == redCorner and float(prediction) < 0.5):\n",
    "                dfPrevPreds.loc[index, 'Result'] = 'Correct'\n",
    "                dfPrevPreds.loc[index, 'Winner'] = winner\n",
    "            elif(winner == blueCorner and float(prediction) > 0.5):\n",
    "                dfPrevPreds.loc[index, 'Result'] = 'Correct'\n",
    "                dfPrevPreds.loc[index, 'Winner'] = winner\n",
    "            else:\n",
    "                dfPrevPreds.loc[index, 'Result'] = 'Incorrect'\n",
    "                dfPrevPreds.loc[index, 'Winner'] = winner\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "dfPrevPreds.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape matchups for next event\n",
    "#define url and headers\n",
    "url = 'https://www.espn.com/mma/schedule/_/league/ufc'\n",
    "headers = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#site request\n",
    "site = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(site.content, 'html.parser')\n",
    "print(site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"Table__ScrollerWrapper relative overflow-hidden\"><div class=\"Table__Shadow--left\" style=\"opacity:0\"></div><div class=\"Table__Scroller\"><table class=\"Table\" style=\"border-collapse:collapse;border-spacing:0\"><colgroup class=\"Table__Colgroup\"><col class=\"Table__Column\"/><col class=\"Table__Column\"/><col class=\"Table__Column\"/><col class=\"Table__Column\"/><col class=\"Table__Column\"/></colgroup><thead class=\"Table__THEAD\"><tr class=\"Table__TR Table__even\"><th class=\"Table__TH\" colspan=\"1\" title=\"\"><div class=\"\">Date</div></th><th class=\"Table__TH\" title=\"\"><div class=\"\">TIME</div></th><th class=\"Table__TH\" title=\"\"><div class=\"\">TV</div></th><th class=\"Table__TH\" title=\"\"><div class=\"\">EVENT</div></th><th class=\"Table__TH\" title=\"\"><div class=\"\">location</div></th></tr></thead><tbody class=\"Table__TBODY\"><tr class=\"Table__TR Table__TR--sm Table__even\" data-idx=\"0\"><td class=\"date__col Table__TD\"><span class=\"date__innerCell\">Oct 12</span></td><td class=\"date__col Table__TD\"><a class=\"AnchorLink\" href=\"/mma/fightcenter/_/id/600049121/league/ufc\" tabindex=\"0\">4:00 PM</a></td><td class=\"broadcast__col Table__TD\"><div class=\"network-container\"><a class=\"AnchorLink network-container_link\" href=\"/espnplus\" tabindex=\"0\"><img alt=\"ESPN+\" class=\"Image Logo__Network network-espn+\" data-mptype=\"image\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"/></a></div></td><td class=\"event__col Table__TD\"><a class=\"AnchorLink\" href=\"/mma/fightcenter/_/id/600049121/league/ufc\" tabindex=\"0\">UFC Fight Night: Royval vs. Taira</a></td><td class=\"location__col Table__TD\"><div>UFC APEX, Las Vegas, NV</div></td></tr><tr class=\"Table__TR Table__TR--sm Table__even\" data-idx=\"1\"><td class=\"date__col Table__TD\"><span class=\"date__innerCell\">Oct 15</span></td><td class=\"date__col Table__TD\"><a class=\"AnchorLink\" href=\"/mma/fightcenter/_/id/600047781/league/ufc\" tabindex=\"0\">8:00 PM</a></td><td class=\"broadcast__col Table__TD\"><div class=\"network-container\"><a class=\"AnchorLink network-container_link\" href=\"/espnplus\" tabindex=\"0\"><img alt=\"ESPN+\" class=\"Image Logo__Network network-espn+\" data-mptype=\"image\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"/></a></div></td><td class=\"event__col Table__TD\"><a class=\"AnchorLink\" href=\"/mma/fightcenter/_/id/600047781/league/ufc\" tabindex=\"0\">Dana White's Contender Series: Season 8, Week 10</a></td><td class=\"location__col Table__TD\"><div>UFC APEX, Las Vegas, NV</div></td></tr></tbody></table></div><div class=\"Table__Shadow--right\" style=\"opacity:0\"></div></div>\n"
     ]
    }
   ],
   "source": [
    "#find url of next card\n",
    "divs = soup.find_all('div', class_=re.compile('Table__ScrollerWrapper relative overflow-hidden'))\n",
    "print(divs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mma/fightcenter/_/id/600049121/league/ufc\n"
     ]
    }
   ],
   "source": [
    "#gt url of next card\n",
    "link = divs[0]\n",
    "hrefs = link.find('a')\n",
    "part = hrefs['href']\n",
    "print(part) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.espn.com/mma/fightcenter/_/id/600049121/league/ufc\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#site request for next event\n",
    "url = f'https://www.espn.com{part}'\n",
    "site = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(site.content, 'html.parser')\n",
    "print(url)\n",
    "print(site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<section class=\"Card MMAFightCard\"><header aria-label=\"[object Object]\" class=\"Card__Header Card__Header--no-border\"><div class=\"Card__Header__Title__Wrapper\"><h3 class=\"Card__Header__Title Card__Header__Title--no-theme\">Main Card</h3></div></header><div class=\"Wrapper Card__Content pa0\"><div class=\"Accordion\"><div class=\"mb6\"><div class=\"MMAFightCard__Gamestrip br-5 mh4 relative MMAFightCard__Gamestrip--open\"><h2 class=\"tc h9 fw-normal-med MMAFightCard__GameNote clr-gray-03\">Flyweight - Main Event</h2><div class=\"\"><div class=\"MMAGamestrip flex items-center justify-center MMAFightCard__Gamestrip--pointer\"><div class=\"MMACompetitor relative flex flex-uniform pr6 flex-row-reverse MMACompetitor--desktop\"><div class=\"flex w-100 flex-row-reverse\"><div class=\"relative ph3\"><div class=\"headshot inline-block relative headshot--sm\"><figure class=\"Image aspect-ratio--parent\"><div class=\"RatioFrame aspect-ratio--1x1\"></div><div class=\"Image__Wrapper aspect-ratio--child\"><img alt=\"\" class=\"\" data-mptype=\"image\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"/></div></figure></div></div><div class=\"MMACompetitor__Detail flex flex-column justify-center\"><h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Brandon Royval</span></h2><div class=\"flex items-center n9 nowrap justify-end clr-gray-04\">16-7-0</div></div></div></div><div class=\"Gamestrip__Overview relative items-center clr-gray-04 flex justify-center flex-column n8 MMAGamestrip__Overview\"><div class=\"ScoreCell__Network Gamestrip__Network--mma n9\"><div class=\"ScoreCell__NetworkItem\">ESPN+</div></div></div><div class=\"MMACompetitor relative flex flex-uniform pl6 MMACompetitor--desktop\"><div class=\"flex w-100\"><div class=\"relative ph3\"><div class=\"headshot inline-block relative headshot--sm\"><figure class=\"Image aspect-ratio--parent\"><div class=\"RatioFrame aspect-ratio--1x1\"></div><div class=\"Image__Wrapper aspect-ratio--child\"><img alt=\"\" class=\"\" data-mptype=\"image\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"/></div></figure></div></div><div class=\"MMACompetitor__Detail flex flex-column justify-center\"><h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Tatsuro Taira</span></h2><div class=\"flex items-center n9 nowrap clr-gray-04\">16-0-0</div></div></div></div></div></div><div class=\"lZur\" data-testid=\"gameStripBar\"><div class=\"VZTD nkdHX mLASH VIJfz GqQB yTFnz lZur YXOwE SQFkJ DTlmW GCxLR JrdoJ\"><div class=\"VZTD mLASH ibBTV zkpVE wTBri\"><img alt=\"USA\" class=\"hsDdd lqtkC dfzPr HfYhe mvEmE cYfNW dpDOL\" data-testid=\"prism-image\" draggable=\"false\" src=\"https://a.espncdn.com/i/teamlogos/countries/500/usa.png\"/><span class=\"lqtkC dfzPr HfYhe mvEmE NIhmB AsfGG\">USA</span></div><div class=\"VZTD nkdHX mLASH kfeMl\"><div class=\"nyqUw hfDkF vHUJ wZKny\" id=\"awayOdds\">+240</div><img class=\"cYfNW dpDOL csTyU dfzPr KGLEY mvEmE hsDdd\" data-testid=\"prism-image\" draggable=\"false\" src=\"https://a.espncdn.com/i/espnbet/espn-bet-square-light.svg\"/><div class=\"nyqUw hfDkF vHUJ wZKny\" id=\"homeOdds\">-300</div></div><div class=\"VZTD mLASH ibBTV zkpVE CLwPV\"><img alt=\"Japan\" class=\"hsDdd lqtkC dfzPr HfYhe mvEmE cYfNW dpDOL\" data-testid=\"prism-image\" draggable=\"false\" src=\"https://a.espncdn.com/i/teamlogos/countries/500/jpn.png\"/><span class=\"lqtkC dfzPr HfYhe mvEmE NIhmB AsfGG\">Japan</span></div></div><div class=\"xOPbW kDSxb GqQB LrmZT dIEoT VZTD jIRH mLASH NqeUA PSmaN RqKLX rGwPE\" data-testid=\"gameStripBarCaret\"><svg aria-hidden=\"true\" class=\"NqeUA PSmaN xwYCG kahOz zXGbU UbGlr nfCSQ\" data-icon=\"playerControls-upCarot\" data-testid=\"prism-iconography\" height=\"1em\" role=\"presentation\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M8 20.9c-.2 0-.5-.1-.6-.3-.4-.4-.4-.9 0-1.3l8.6-8.6 8.6 8.6c.4.4.4.9 0 1.3s-.9.4-1.3 0L16 13.3l-7.4 7.4c-.1.1-.4.2-.6.2z\" fill=\"currentColor\"></path></svg></div><div data-testid=\"gameStripContent\"><div class=\"MMAFightCard__MediaButtons flex justify-center items-center mhauto\"></div><div class=\"ResponsiveWrapper\"><div class=\"\"><div class=\"MMAFightCenter__Header\"><div class=\"ButtonGroup MMAFightCenter__Header__ButtonGroup\" role=\"radiogroup\"><button aria-checked=\"true\" class=\"Button Button--filter Button--active MMAFightCenter__Header__Button\" role=\"radio\" tabindex=\"0\">Tale Of The Tape</button><button aria-checked=\"false\" class=\"Button Button--filter MMAFightCenter__Header__Button\" role=\"radio\" tabindex=\"0\">Fight Odds</button></div></div><div class=\"MMAFightCenter__Container\"><div class=\"MMAFightCenter__Fighters flex\"><div class=\"overflow-hidden flex-uniform flex justify-end pr7\"><div class=\"flex flex-column items-center justify-between\"><div class=\"MMAStrikeZone\"><canvas class=\"MMAStrikeZone__canvas\" height=\"388\" style=\"width:64px;height:194px\" width=\"128\"></canvas></div><a class=\"AnchorLink db h9 MMAFightCenter__ProfileLink\" data-player-uid=\"s:3301~a:4239928\" href=\"https://www.espn.com/mma/fighter/_/id/4239928/brandon-royval\" tabindex=\"0\">Full Profile</a></div></div><div class=\"MMAFightCenter__Matchup\"><div class=\"ResponsiveWrapper\" data-wrapping=\"MMAMatchup\"><ul class=\"MMAMatchup list\"><li class=\"flex justify-between items-center\"><div class=\"MMAMatchup__Basis\"><div><div class=\"MMAMatchup__Stat ns8 MMAMatchup__Stat__Text\">5' 9\"</div></div></div><div class=\"ns9 fw-medium ttu nowrap clr-gray-04\">Height</div><div class=\"MMAMatchup__Basis tar\"><div><div class=\"MMAMatchup__Stat ns8 MMAMatchup__Stat__Text\">5' 7\"</div></div></div></li><li class=\"flex justify-between items-center mt5\"><div class=\"MMAMatchup__Basis\"><div><div class=\"MMAMatchup__Stat ns8 MMAMatchup__Stat__Text\">126 lbs</div></div></div><div class=\"ns9 fw-medium ttu nowrap clr-gray-04\">Weight</div><div class=\"MMAMatchup__Basis tar\"><div><div class=\"MMAMatchup__Stat ns8 MMAMatchup__Stat__Text\">126 lbs</div></div></div></li><li class=\"flex justify-between items-center mt5\"><div class=\"MMAMatchup__Basis\"><div><div class=\"MMAMatchup__Stat ns8 MMAMatchup__Stat__Text\">32</div></div></div><div class=\"ns9 fw-medium ttu nowrap clr-gray-04\">Age</div><div class=\"MMAMatchup__Basis tar\"><div><div class=\"MMAMatchup__Stat ns8 MMAMatchup__Stat__Text\">24</div></div></div></li><li class=\"flex justify-between items-center mt5\"><div class=\"MMAMatchup__Basis\"><div><div class=\"MMAMatchup__Stat ns8 MMAMatchup__Stat__Text\">68\"</div></div></div><div class=\"ns9 fw-medium ttu nowrap clr-gray-04\">Reach</div><div class=\"MMAMatchup__Basis tar\"><div><div class=\"MMAMatchup__Stat ns8 MMAMatchup__Stat__Text\">70\"</div></div></div></li><li class=\"flex justify-between items-center mt5\"><div class=\"MMAMatchup__Basis\"><div><div class=\"MMAMatchup__Stat ns8 MMAMatchup__Stat__Text\">Southpaw</div></div></div><div class=\"ns9 fw-medium ttu nowrap clr-gray-04\">Stance</div><div class=\"MMAMatchup__Basis tar\"><div><div class=\"MMAMatchup__Stat ns8 MMAMatchup__Stat__Text\">Orthodox</div></div></div></li><li class=\"flex justify-between items-center mt5\"><div class=\"MMAMatchup__Basis\"><div><div class=\"MMAMatchup__Stat ns8 MMAMatchup__Stat__Text\">4.33</div></div></div><div class=\"ns9 fw-medium ttu nowrap clr-gray-04\">SIG STR LPM</div><div class=\"MMAMatchup__Basis tar\"><div><div class=\"MMAMatchup__Stat ns8 MMAMatchup__Stat__Text\">3.56</div></div></div></li><li class=\"flex justify-between items-center mt5\"><div class=\"MMAMatchup__Basis\"><div><div class=\"MMAMatchup__Stat ns8 MMAMatchup__Stat__Text\">47.65%</div></div></div><div class=\"ns9 fw-medium ttu nowrap clr-gray-04\">SIG STR ACC</div><div class=\"MMAMatchup__Basis tar\"><div><div class=\"MMAMatchup__Stat ns8 MMAMatchup__Stat__Text\">71.00%</div></div></div></li><li class=\"flex justify-between items-center mt5\"><div class=\"MMAMatchup__Basis\"><div><div class=\"MMAMatchup__Stat ns8 MMAMatchup__Stat__Text\">0.47</div></div></div><div class=\"ns9 fw-medium ttu nowrap clr-gray-04\">TD AVG</div><div class=\"MMAMatchup__Basis tar\"><div><div class=\"MMAMatchup__Stat ns8 MMAMatchup__Stat__Text\">2.35</div></div></div></li><li class=\"flex justify-between items-center mt5\"><div class=\"MMAMatchup__Basis\"><div><div class=\"MMAMatchup__Stat ns8 MMAMatchup__Stat__Text\">60.00%</div></div></div><div class=\"ns9 fw-medium ttu nowrap clr-gray-04\">TD ACC</div><div class=\"MMAMatchup__Basis tar\"><div><div class=\"MMAMatchup__Stat ns8 MMAMatchup__Stat__Text\">47.37%</div></div></div></li><li class=\"flex justify-between items-center mt5\"><div class=\"MMAMatchup__Basis\"><div><div class=\"MMAMatchup__Stat ns8 MMAMatchup__Stat__Text\">1.10</div></div></div><div class=\"ns9 fw-medium ttu nowrap clr-gray-04\">SUB AVG</div><div class=\"MMAMatchup__Basis tar\"><div><div class=\"MMAMatchup__Stat ns8 MMAMatchup__Stat__Text\">2.09</div></div></div></li></ul></div></div><div class=\"overflow-hidden flex-uniform flex pl7\"><div class=\"flex flex-column items-center justify-between\"><div class=\"MMAStrikeZone\"><canvas class=\"MMAStrikeZone__canvas\" height=\"388\" style=\"width:64px;height:194px\" width=\"128\"></canvas></div><a class=\"AnchorLink db h9 MMAFightCenter__ProfileLink\" data-player-uid=\"s:3301~a:4917772\" href=\"https://www.espn.com/mma/fighter/_/id/4917772/tatsuro-taira\" tabindex=\"0\">Full Profile</a></div></div></div></div></div></div></div></div></div></div><div class=\"mb6\"><div class=\"MMAFightCard__Gamestrip br-5 mh4 relative\"><h2 class=\"tc h9 fw-normal-med MMAFightCard__GameNote clr-gray-03\">Middleweight</h2><div class=\"\"><div class=\"MMAGamestrip flex items-center justify-center MMAFightCard__Gamestrip--pointer\"><div class=\"MMACompetitor relative flex flex-uniform pr6 flex-row-reverse MMACompetitor--desktop\"><div class=\"flex w-100 flex-row-reverse\"><div class=\"relative ph3\"><div class=\"headshot inline-block relative headshot--sm\"><figure class=\"Image aspect-ratio--parent\"><div class=\"RatioFrame aspect-ratio--1x1\"></div><div class=\"Image__Wrapper aspect-ratio--child\"><img alt=\"\" class=\"\" data-mptype=\"image\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"/></div></figure></div></div><div class=\"MMACompetitor__Detail flex flex-column justify-center\"><h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Brad Tavares</span></h2><div class=\"flex items-center n9 nowrap justify-end clr-gray-04\">20-10-0</div></div></div></div><div class=\"Gamestrip__Overview relative items-center clr-gray-04 flex justify-center flex-column n8 MMAGamestrip__Overview\"><div class=\"ScoreCell__Network Gamestrip__Network--mma n9\"><div class=\"ScoreCell__NetworkItem\">ESPN+</div></div></div><div class=\"MMACompetitor relative flex flex-uniform pl6 MMACompetitor--desktop\"><div class=\"flex w-100\"><div class=\"relative ph3\"><div class=\"headshot inline-block relative headshot--sm\"><figure class=\"Image aspect-ratio--parent\"><div class=\"RatioFrame aspect-ratio--1x1\"></div><div class=\"Image__Wrapper aspect-ratio--child\"><img alt=\"\" class=\"\" data-mptype=\"image\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"/></div></figure></div></div><div class=\"MMACompetitor__Detail flex flex-column justify-center\"><h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">JunYong Park</span></h2><div class=\"flex items-center n9 nowrap clr-gray-04\">17-6-0</div></div></div></div></div></div><div class=\"lZur\" data-testid=\"gameStripBar\"><div class=\"VZTD nkdHX mLASH VIJfz GqQB yTFnz lZur YXOwE SQFkJ DTlmW GCxLR JrdoJ SojoD\"><div class=\"VZTD mLASH ibBTV zkpVE wTBri\"><img alt=\"USA\" class=\"hsDdd lqtkC dfzPr HfYhe mvEmE cYfNW dpDOL\" data-testid=\"prism-image\" draggable=\"false\" src=\"https://a.espncdn.com/i/teamlogos/countries/500/usa.png\"/><span class=\"lqtkC dfzPr HfYhe mvEmE NIhmB AsfGG\">USA</span></div><div class=\"VZTD jIRH mLASH kfeMl frSWj FEKDG zkpVE\"><div class=\"nyqUw hfDkF vHUJ wZKny\" id=\"awayOdds\">+170</div><img class=\"cYfNW dpDOL csTyU dfzPr KGLEY mvEmE hsDdd\" data-testid=\"prism-image\" draggable=\"false\" src=\"https://a.espncdn.com/i/espnbet/espn-bet-square-light.svg\"/><div class=\"nyqUw hfDkF vHUJ wZKny\" id=\"homeOdds\">-200</div></div><div class=\"VZTD mLASH ibBTV zkpVE CLwPV\"><img alt=\"Korea\" class=\"hsDdd lqtkC dfzPr HfYhe mvEmE cYfNW dpDOL\" data-testid=\"prism-image\" draggable=\"false\" src=\"https://a.espncdn.com/i/teamlogos/countries/500/kor.png\"/><span class=\"lqtkC dfzPr HfYhe mvEmE NIhmB AsfGG\">Korea</span></div></div><div class=\"xOPbW kDSxb GqQB LrmZT dIEoT VZTD jIRH mLASH NqeUA PSmaN RqKLX rGwPE\" data-testid=\"gameStripBarCaret\"><svg aria-hidden=\"true\" class=\"NqeUA PSmaN xwYCG kahOz zXGbU UbGlr nfCSQ\" data-icon=\"playerControls-downCarot\" data-testid=\"prism-iconography\" height=\"1em\" role=\"presentation\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M16 21.3l-8.6-8.6c-.4-.4-.4-.9 0-1.3s.9-.4 1.3 0l7.4 7.4 7.4-7.4c.4-.4.9-.4 1.3 0s.4.9 0 1.3L16 21.3z\" fill=\"currentColor\"></path></svg></div></div></div></div><div class=\"mb6\"><div class=\"MMAFightCard__Gamestrip br-5 mh4 relative\"><h2 class=\"tc h9 fw-normal-med MMAFightCard__GameNote clr-gray-03\">Welterweight</h2><div class=\"\"><div class=\"MMAGamestrip flex items-center justify-center MMAFightCard__Gamestrip--pointer\"><div class=\"MMACompetitor relative flex flex-uniform pr6 flex-row-reverse MMACompetitor--desktop\"><div class=\"flex w-100 flex-row-reverse\"><div class=\"relative ph3\"><div class=\"headshot inline-block relative headshot--sm\"><figure class=\"Image aspect-ratio--parent\"><div class=\"RatioFrame aspect-ratio--1x1\"></div><div class=\"Image__Wrapper aspect-ratio--child\"><img alt=\"\" class=\"\" data-mptype=\"image\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"/></div></figure></div></div><div class=\"MMACompetitor__Detail flex flex-column justify-center\"><h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Chidi Njokuani</span></h2><div class=\"flex items-center n9 nowrap justify-end clr-gray-04\">23-10-0</div></div></div></div><div class=\"Gamestrip__Overview relative items-center clr-gray-04 flex justify-center flex-column n8 MMAGamestrip__Overview\"><div class=\"ScoreCell__Network Gamestrip__Network--mma n9\"><div class=\"ScoreCell__NetworkItem\">ESPN+</div></div></div><div class=\"MMACompetitor relative flex flex-uniform pl6 MMACompetitor--desktop\"><div class=\"flex w-100\"><div class=\"relative ph3\"><div class=\"headshot inline-block relative headshot--sm\"><figure class=\"Image aspect-ratio--parent\"><div class=\"RatioFrame aspect-ratio--1x1\"></div><div class=\"Image__Wrapper aspect-ratio--child\"><img alt=\"\" class=\"\" data-mptype=\"image\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"/></div></figure></div></div><div class=\"MMACompetitor__Detail flex flex-column justify-center\"><h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Jared Gooden</span></h2><div class=\"flex items-center n9 nowrap clr-gray-04\">23-9-0</div></div></div></div></div></div><div class=\"lZur\" data-testid=\"gameStripBar\"><div class=\"VZTD nkdHX mLASH VIJfz GqQB yTFnz lZur YXOwE SQFkJ DTlmW GCxLR JrdoJ SojoD\"><div class=\"VZTD mLASH ibBTV zkpVE wTBri\"><img alt=\"USA\" class=\"hsDdd lqtkC dfzPr HfYhe mvEmE cYfNW dpDOL\" data-testid=\"prism-image\" draggable=\"false\" src=\"https://a.espncdn.com/i/teamlogos/countries/500/usa.png\"/><span class=\"lqtkC dfzPr HfYhe mvEmE NIhmB AsfGG\">USA</span></div><div class=\"VZTD jIRH mLASH kfeMl frSWj FEKDG zkpVE\"><div class=\"nyqUw hfDkF vHUJ wZKny\" id=\"awayOdds\">-170</div><img class=\"cYfNW dpDOL csTyU dfzPr KGLEY mvEmE hsDdd\" data-testid=\"prism-image\" draggable=\"false\" src=\"https://a.espncdn.com/i/espnbet/espn-bet-square-light.svg\"/><div class=\"nyqUw hfDkF vHUJ wZKny\" id=\"homeOdds\">+140</div></div><div class=\"VZTD mLASH ibBTV zkpVE CLwPV\"><img alt=\"USA\" class=\"hsDdd lqtkC dfzPr HfYhe mvEmE cYfNW dpDOL\" data-testid=\"prism-image\" draggable=\"false\" src=\"https://a.espncdn.com/i/teamlogos/countries/500/usa.png\"/><span class=\"lqtkC dfzPr HfYhe mvEmE NIhmB AsfGG\">USA</span></div></div><div class=\"xOPbW kDSxb GqQB LrmZT dIEoT VZTD jIRH mLASH NqeUA PSmaN RqKLX rGwPE\" data-testid=\"gameStripBarCaret\"><svg aria-hidden=\"true\" class=\"NqeUA PSmaN xwYCG kahOz zXGbU UbGlr nfCSQ\" data-icon=\"playerControls-downCarot\" data-testid=\"prism-iconography\" height=\"1em\" role=\"presentation\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M16 21.3l-8.6-8.6c-.4-.4-.4-.9 0-1.3s.9-.4 1.3 0l7.4 7.4 7.4-7.4c.4-.4.9-.4 1.3 0s.4.9 0 1.3L16 21.3z\" fill=\"currentColor\"></path></svg></div></div></div></div><div class=\"mb6\"><div class=\"MMAFightCard__Gamestrip br-5 mh4 relative\"><h2 class=\"tc h9 fw-normal-med MMAFightCard__GameNote clr-gray-03\">Lightweight</h2><div class=\"\"><div class=\"MMAGamestrip flex items-center justify-center MMAFightCard__Gamestrip--pointer\"><div class=\"MMACompetitor relative flex flex-uniform pr6 flex-row-reverse MMACompetitor--desktop\"><div class=\"flex w-100 flex-row-reverse\"><div class=\"relative ph3\"><div class=\"headshot inline-block relative headshot--sm\"><figure class=\"Image aspect-ratio--parent\"><div class=\"RatioFrame aspect-ratio--1x1\"></div><div class=\"Image__Wrapper aspect-ratio--child\"><img alt=\"\" class=\"\" data-mptype=\"image\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"/></div></figure></div></div><div class=\"MMACompetitor__Detail flex flex-column justify-center\"><h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Grant Dawson</span></h2><div class=\"flex items-center n9 nowrap justify-end clr-gray-04\">21-2-1</div></div></div></div><div class=\"Gamestrip__Overview relative items-center clr-gray-04 flex justify-center flex-column n8 MMAGamestrip__Overview\"><div class=\"ScoreCell__Network Gamestrip__Network--mma n9\"><div class=\"ScoreCell__NetworkItem\">ESPN+</div></div></div><div class=\"MMACompetitor relative flex flex-uniform pl6 MMACompetitor--desktop\"><div class=\"flex w-100\"><div class=\"relative ph3\"><div class=\"headshot inline-block relative headshot--sm\"><figure class=\"Image aspect-ratio--parent\"><div class=\"RatioFrame aspect-ratio--1x1\"></div><div class=\"Image__Wrapper aspect-ratio--child\"><img alt=\"\" class=\"\" data-mptype=\"image\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"/></div></figure></div></div><div class=\"MMACompetitor__Detail flex flex-column justify-center\"><h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Rafa Garcia</span></h2><div class=\"flex items-center n9 nowrap clr-gray-04\">16-3-0</div></div></div></div></div></div><div class=\"lZur\" data-testid=\"gameStripBar\"><div class=\"VZTD nkdHX mLASH VIJfz GqQB yTFnz lZur YXOwE SQFkJ DTlmW GCxLR JrdoJ SojoD\"><div class=\"VZTD mLASH ibBTV zkpVE wTBri\"><img alt=\"USA\" class=\"hsDdd lqtkC dfzPr HfYhe mvEmE cYfNW dpDOL\" data-testid=\"prism-image\" draggable=\"false\" src=\"https://a.espncdn.com/i/teamlogos/countries/500/usa.png\"/><span class=\"lqtkC dfzPr HfYhe mvEmE NIhmB AsfGG\">USA</span></div><div class=\"VZTD jIRH mLASH kfeMl frSWj FEKDG zkpVE\"><div class=\"nyqUw hfDkF vHUJ wZKny\" id=\"awayOdds\">-450</div><img class=\"cYfNW dpDOL csTyU dfzPr KGLEY mvEmE hsDdd\" data-testid=\"prism-image\" draggable=\"false\" src=\"https://a.espncdn.com/i/espnbet/espn-bet-square-light.svg\"/><div class=\"nyqUw hfDkF vHUJ wZKny\" id=\"homeOdds\">+325</div></div><div class=\"VZTD mLASH ibBTV zkpVE CLwPV\"><img alt=\"Mexico\" class=\"hsDdd lqtkC dfzPr HfYhe mvEmE cYfNW dpDOL\" data-testid=\"prism-image\" draggable=\"false\" src=\"https://a.espncdn.com/i/teamlogos/countries/500/mex.png\"/><span class=\"lqtkC dfzPr HfYhe mvEmE NIhmB AsfGG\">Mexico</span></div></div><div class=\"xOPbW kDSxb GqQB LrmZT dIEoT VZTD jIRH mLASH NqeUA PSmaN RqKLX rGwPE\" data-testid=\"gameStripBarCaret\"><svg aria-hidden=\"true\" class=\"NqeUA PSmaN xwYCG kahOz zXGbU UbGlr nfCSQ\" data-icon=\"playerControls-downCarot\" data-testid=\"prism-iconography\" height=\"1em\" role=\"presentation\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M16 21.3l-8.6-8.6c-.4-.4-.4-.9 0-1.3s.9-.4 1.3 0l7.4 7.4 7.4-7.4c.4-.4.9-.4 1.3 0s.4.9 0 1.3L16 21.3z\" fill=\"currentColor\"></path></svg></div></div></div></div><div class=\"mb6\"><div class=\"MMAFightCard__Gamestrip br-5 mh4 relative\"><h2 class=\"tc h9 fw-normal-med MMAFightCard__GameNote clr-gray-03\">Welterweight</h2><div class=\"\"><div class=\"MMAGamestrip flex items-center justify-center MMAFightCard__Gamestrip--pointer\"><div class=\"MMACompetitor relative flex flex-uniform pr6 flex-row-reverse MMACompetitor--desktop\"><div class=\"flex w-100 flex-row-reverse\"><div class=\"relative ph3\"><div class=\"headshot inline-block relative headshot--sm\"><figure class=\"Image aspect-ratio--parent\"><div class=\"RatioFrame aspect-ratio--1x1\"></div><div class=\"Image__Wrapper aspect-ratio--child\"><img alt=\"\" class=\"\" data-mptype=\"image\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"/></div></figure></div></div><div class=\"MMACompetitor__Detail flex flex-column justify-center\"><h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Daniel Rodriguez</span></h2><div class=\"flex items-center n9 nowrap justify-end clr-gray-04\">17-5-0</div></div></div></div><div class=\"Gamestrip__Overview relative items-center clr-gray-04 flex justify-center flex-column n8 MMAGamestrip__Overview\"><div class=\"ScoreCell__Network Gamestrip__Network--mma n9\"><div class=\"ScoreCell__NetworkItem\">ESPN+</div></div></div><div class=\"MMACompetitor relative flex flex-uniform pl6 MMACompetitor--desktop\"><div class=\"flex w-100\"><div class=\"relative ph3\"><div class=\"headshot inline-block relative headshot--sm\"><figure class=\"Image aspect-ratio--parent\"><div class=\"RatioFrame aspect-ratio--1x1\"></div><div class=\"Image__Wrapper aspect-ratio--child\"><img alt=\"\" class=\"\" data-mptype=\"image\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"/></div></figure></div></div><div class=\"MMACompetitor__Detail flex flex-column justify-center\"><h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Alex Morono</span></h2><div class=\"flex items-center n9 nowrap clr-gray-04\">24-10-0</div></div></div></div></div></div><div class=\"lZur\" data-testid=\"gameStripBar\"><div class=\"VZTD nkdHX mLASH VIJfz GqQB yTFnz lZur YXOwE SQFkJ DTlmW GCxLR JrdoJ SojoD\"><div class=\"VZTD mLASH ibBTV zkpVE wTBri\"><img alt=\"USA\" class=\"hsDdd lqtkC dfzPr HfYhe mvEmE cYfNW dpDOL\" data-testid=\"prism-image\" draggable=\"false\" src=\"https://a.espncdn.com/i/teamlogos/countries/500/usa.png\"/><span class=\"lqtkC dfzPr HfYhe mvEmE NIhmB AsfGG\">USA</span></div><div class=\"VZTD jIRH mLASH kfeMl frSWj FEKDG zkpVE\"><div class=\"nyqUw hfDkF vHUJ wZKny\" id=\"awayOdds\">-220</div><img class=\"cYfNW dpDOL csTyU dfzPr KGLEY mvEmE hsDdd\" data-testid=\"prism-image\" draggable=\"false\" src=\"https://a.espncdn.com/i/espnbet/espn-bet-square-light.svg\"/><div class=\"nyqUw hfDkF vHUJ wZKny\" id=\"homeOdds\">+180</div></div><div class=\"VZTD mLASH ibBTV zkpVE CLwPV\"><img alt=\"USA\" class=\"hsDdd lqtkC dfzPr HfYhe mvEmE cYfNW dpDOL\" data-testid=\"prism-image\" draggable=\"false\" src=\"https://a.espncdn.com/i/teamlogos/countries/500/usa.png\"/><span class=\"lqtkC dfzPr HfYhe mvEmE NIhmB AsfGG\">USA</span></div></div><div class=\"xOPbW kDSxb GqQB LrmZT dIEoT VZTD jIRH mLASH NqeUA PSmaN RqKLX rGwPE\" data-testid=\"gameStripBarCaret\"><svg aria-hidden=\"true\" class=\"NqeUA PSmaN xwYCG kahOz zXGbU UbGlr nfCSQ\" data-icon=\"playerControls-downCarot\" data-testid=\"prism-iconography\" height=\"1em\" role=\"presentation\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M16 21.3l-8.6-8.6c-.4-.4-.4-.9 0-1.3s.9-.4 1.3 0l7.4 7.4 7.4-7.4c.4-.4.9-.4 1.3 0s.4.9 0 1.3L16 21.3z\" fill=\"currentColor\"></path></svg></div></div></div></div></div></div></section>\n"
     ]
    }
   ],
   "source": [
    "#get fight names\n",
    "sections = soup.find_all('section', class_=re.compile(\"Card MMAFightCard\"))\n",
    "print(sections[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Brandon Royval</span></h2>, <h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Tatsuro Taira</span></h2>, <h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Brad Tavares</span></h2>, <h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">JunYong Park</span></h2>, <h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Chidi Njokuani</span></h2>, <h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Jared Gooden</span></h2>, <h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Grant Dawson</span></h2>, <h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Rafa Garcia</span></h2>, <h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Daniel Rodriguez</span></h2>, <h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Alex Morono</span></h2>]\n"
     ]
    }
   ],
   "source": [
    "h2s = sections[0].find_all('h2', class_=re.compile('h4 clr-gray-02'))\n",
    "print(h2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Brandon Royval', 'Tatsuro Taira', 'Brad Tavares', 'JunYong Park', 'Chidi Njokuani', 'Jared Gooden', 'Grant Dawson', 'Rafa Garcia', 'Daniel Rodriguez', 'Alex Morono']\n"
     ]
    }
   ],
   "source": [
    "fightersOnCard = []\n",
    "for h2 in h2s:\n",
    "    fightersOnCard.append(str(h2.text.strip()))\n",
    "print(fightersOnCard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">CJ Vergara</span></h2>, <h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Ramazan Temirov</span></h2>, <h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Jonathan Pearce</span></h2>, <h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Pat Sabatini</span></h2>, <h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Themba Gorimbo</span></h2>, <h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Niko Price</span></h2>, <h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Junior Tafa</span></h2>, <h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Sean Sharaf</span></h2>, <h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Julia Polastri</span></h2>, <h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Cory McKenna</span></h2>, <h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Dan Argueta</span></h2>, <h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Cody Haddon</span></h2>, <h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Clayton Carpenter</span></h2>, <h2 class=\"h4 clr-gray-02\"><span class=\"truncate tc db\">Lucas Rocha</span></h2>]\n"
     ]
    }
   ],
   "source": [
    "h2s = sections[1].find_all('h2', class_=re.compile('h4 clr-gray-02'))\n",
    "print(h2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Brandon Royval', 'Tatsuro Taira', 'Brad Tavares', 'JunYong Park', 'Chidi Njokuani', 'Jared Gooden', 'Grant Dawson', 'Rafa Garcia', 'Daniel Rodriguez', 'Alex Morono', 'CJ Vergara', 'Ramazan Temirov', 'Jonathan Pearce', 'Pat Sabatini', 'Themba Gorimbo', 'Niko Price', 'Junior Tafa', 'Sean Sharaf', 'Julia Polastri', 'Cory McKenna', 'Dan Argueta', 'Cody Haddon', 'Clayton Carpenter', 'Lucas Rocha']\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "for h2 in h2s:\n",
    "    fightersOnCard.append(str(h2.text.strip()))\n",
    "print(fightersOnCard)\n",
    "print(len(fightersOnCard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find special characters in referees\n",
    "chars2rep = []\n",
    "for fighter in fightersOnCard:\n",
    "    if(isinstance(fighter, str)):\n",
    "        for char in fighter:\n",
    "            if char.lower() not in ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "            if char.upper() not in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', \"Q\", 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ' ']:\n",
    "                chars2rep.append(char)\n",
    "chars2rep = list(set(chars2rep))\n",
    "for char in chars2rep:\n",
    "    print(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Brandon Royval', 'Tatsuro Taira', 'Brad Tavares', 'JunYong Park', 'Chidi Njokuani', 'Jared Gooden', 'Grant Dawson', 'Rafa Garcia', 'Daniel Rodriguez', 'Alex Morono', 'CJ Vergara', 'Ramazan Temirov', 'Jonathan Pearce', 'Pat Sabatini', 'Themba Gorimbo', 'Niko Price', 'Junior Tafa', 'Sean Sharaf', 'Julia Polastri', 'Cory McKenna', 'Dan Argueta', 'Cody Haddon', 'Clayton Carpenter', 'Lucas Rocha']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(fightersOnCard)):\n",
    "    fight = fightersOnCard[i]\n",
    "    if '' in fight:\n",
    "        fight = fight.replace('', 'c')\n",
    "    if '' in fight:\n",
    "        fight = fight.replace('', 'E')\n",
    "    if '' in fight:\n",
    "        fight = fight.replace('', 'e')\n",
    "    if '' in fight:\n",
    "        fight = fight.replace('', 'A')\n",
    "    if '' in fight:\n",
    "        fight = fight.replace('', 'L')\n",
    "    if '' in fight:\n",
    "        fight = fight.replace('', 'c')\n",
    "    if '' in fight:\n",
    "        fight = fight.replace('', 'a')\n",
    "    if '' in fight:\n",
    "        fight = fight.replace('', 'a')\n",
    "    if '' in fight:\n",
    "        fight = fight.replace('', 'a')\n",
    "    if '' in fight:\n",
    "        fight = fight.replace('', 'u')\n",
    "    if '' in fight:\n",
    "        fight = fight.replace('', 'e')\n",
    "    if '' in fight:\n",
    "        fight = fight.replace('', 'a')\n",
    "    if '.' in fight:\n",
    "        fight = fight.replace('.', '')\n",
    "    if '' in fight: \n",
    "        fight = fight.replace('', 'e')\n",
    "    if '' in fight:\n",
    "        fight = fight.replace('', 'o')\n",
    "    if \"'\" in fight:\n",
    "        fight = fight.replace(\"'\", '')\n",
    "    if '' in fight:\n",
    "        fight = fight.replace('', 'o')\n",
    "    if '' in fight:\n",
    "        fight = fight.replace('', 'i')\n",
    "    if '' in fight:\n",
    "        fight = fight.replace('', 'r')\n",
    "    if '-' in fight:\n",
    "        fight = fight.replace('-', ' ')\n",
    "    if '' in fight:\n",
    "        fight = fight.replace('', 'a')\n",
    "    if '' in fight:\n",
    "        fight = fight.replace('', 'L')\n",
    "    if '' in fight:\n",
    "        fight = fight.replace('', 't')\n",
    "    if '' in fight:\n",
    "        fight = fight.replace('', 'l')\n",
    "    if '' in fight:\n",
    "        fight = fight.replace('', 'o')\n",
    "    if '' in fight:\n",
    "        fight = fight.replace('', 's')\n",
    "    if '' in fight:\n",
    "        fight = fight.replace('', 'o')\n",
    "    if '' in fight:\n",
    "        fight = fight.replace('', 'c')\n",
    "    if '' in fight:\n",
    "        fight = fight.replace('', 'n')\n",
    "    if '' in fight:\n",
    "        fight = fight.replace('', 'n')\n",
    "    if '' in fight:\n",
    "        fight = fight.replace('', 'z')\n",
    "    \n",
    "    # Update the list with the modified string\n",
    "    fightersOnCard[i] = fight\n",
    "\n",
    "print(fightersOnCard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Brandon Royval vs Tatsuro Taira', 'Brad Tavares vs JunYong Park', 'Chidi Njokuani vs Jared Gooden', 'Grant Dawson vs Rafa Garcia', 'Daniel Rodriguez vs Alex Morono', 'CJ Vergara vs Ramazan Temirov', 'Jonathan Pearce vs Pat Sabatini', 'Themba Gorimbo vs Niko Price', 'Junior Tafa vs Sean Sharaf', 'Julia Polastri vs Cory McKenna', 'Dan Argueta vs Cody Haddon', 'Clayton Carpenter vs Lucas Rocha']\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "fights = []\n",
    "for i in range(int(len(fightersOnCard)/2)):\n",
    "    fight = f'{fightersOnCard[count]} vs {fightersOnCard[count+1]}'\n",
    "    fights.append(fight)\n",
    "    count+=2\n",
    "print(fights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nickname</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>draws</th>\n",
       "      <th>age</th>\n",
       "      <th>nation</th>\n",
       "      <th>knockdown_avg</th>\n",
       "      <th>sig_str_accuracy</th>\n",
       "      <th>takedown_average</th>\n",
       "      <th>takedown_accuracy</th>\n",
       "      <th>subs_attempted_average</th>\n",
       "      <th>height</th>\n",
       "      <th>reach</th>\n",
       "      <th>stance</th>\n",
       "      <th>sig_str_landed_per_min</th>\n",
       "      <th>average_fight_time</th>\n",
       "      <th>sig_str_absorbed_per_min</th>\n",
       "      <th>sig_str_defense</th>\n",
       "      <th>takedown_defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hamdy Abdelwahab</td>\n",
       "      <td>The Hammer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>108</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74</td>\n",
       "      <td>72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.87</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mansur AbdulMalik</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74</td>\n",
       "      <td>79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.38</td>\n",
       "      <td>8.916667</td>\n",
       "      <td>5.16</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shamil Abdurakhimov</td>\n",
       "      <td>Abrek</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.1</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.41</td>\n",
       "      <td>9.450000</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Daichi Abe</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Klidson Abreu</td>\n",
       "      <td>White Bear</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>11.716667</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name    nickname  wins  losses  draws   age  nation  \\\n",
       "0     Hamdy Abdelwahab  The Hammer   5.0     0.0      0  31.0     108   \n",
       "1    Mansur AbdulMalik           1   6.0     0.0      0  27.0      52   \n",
       "2  Shamil Abdurakhimov       Abrek  20.0     8.0      0  43.0      55   \n",
       "3           Daichi Abe           2   6.0     2.0      0  32.0      45   \n",
       "4        Klidson Abreu  White Bear  15.0     4.0      0  31.0      91   \n",
       "\n",
       "   knockdown_avg  sig_str_accuracy  takedown_average  takedown_accuracy  \\\n",
       "0           1.00              0.52              3.00               0.75   \n",
       "1           0.00              0.53              0.00               0.00   \n",
       "2           0.29              0.44              1.01               0.23   \n",
       "3           0.33              0.33              0.33               0.50   \n",
       "4           0.00              0.40              0.64               0.20   \n",
       "\n",
       "   subs_attempted_average  height  reach  stance  sig_str_landed_per_min  \\\n",
       "0                     0.0      74     72     1.0                    3.87   \n",
       "1                     0.0      74     79     0.0                    5.38   \n",
       "2                     0.1      75     76     0.0                    2.41   \n",
       "3                     0.0      71     71     0.0                    3.80   \n",
       "4                     0.0      72     74     0.0                    2.05   \n",
       "\n",
       "   average_fight_time  sig_str_absorbed_per_min  sig_str_defense  \\\n",
       "0           15.000000                      3.13             0.59   \n",
       "1            8.916667                      5.16             0.54   \n",
       "2            9.450000                      3.02             0.55   \n",
       "3           15.000000                      4.49             0.56   \n",
       "4           11.716667                      2.90             0.55   \n",
       "\n",
       "   takedown_defense  \n",
       "0              0.00  \n",
       "1              0.75  \n",
       "2              0.45  \n",
       "3              0.00  \n",
       "4              0.80  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dfCareer = pd.read_csv(f'careerDataFormatTest{dateToday}.csv')\n",
    "dfCareer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 35s - loss: 1.4462 - accuracy: 0.4435\n",
      "Epoch 1: val_accuracy improved from -inf to 0.74462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 6ms/step - loss: 0.6993 - accuracy: 0.6136 - val_loss: 0.5282 - val_accuracy: 0.7446\n",
      "Epoch 2/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.5114 - accuracy: 0.7742\n",
      "Epoch 2: val_accuracy improved from 0.74462 to 0.81692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.8003 - val_loss: 0.4294 - val_accuracy: 0.8169\n",
      "Epoch 3/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3659 - accuracy: 0.8548\n",
      "Epoch 3: val_accuracy improved from 0.81692 to 0.82462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8364 - val_loss: 0.3865 - val_accuracy: 0.8246\n",
      "Epoch 4/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4013 - accuracy: 0.7984\n",
      "Epoch 4: val_accuracy improved from 0.82462 to 0.84462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.8361 - val_loss: 0.3639 - val_accuracy: 0.8446\n",
      "Epoch 5/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3957 - accuracy: 0.8306\n",
      "Epoch 5: val_accuracy improved from 0.84462 to 0.84769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8491 - val_loss: 0.3542 - val_accuracy: 0.8477\n",
      "Epoch 6/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2561 - accuracy: 0.9113\n",
      "Epoch 6: val_accuracy improved from 0.84769 to 0.84923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8484 - val_loss: 0.3427 - val_accuracy: 0.8492\n",
      "Epoch 7/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3299 - accuracy: 0.8548\n",
      "Epoch 7: val_accuracy improved from 0.84923 to 0.85077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8618 - val_loss: 0.3498 - val_accuracy: 0.8508\n",
      "Epoch 8/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3177 - accuracy: 0.8790\n",
      "Epoch 8: val_accuracy did not improve from 0.85077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.8597 - val_loss: 0.3431 - val_accuracy: 0.8508\n",
      "Epoch 9/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2804 - accuracy: 0.8710\n",
      "Epoch 9: val_accuracy improved from 0.85077 to 0.85385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8661 - val_loss: 0.3325 - val_accuracy: 0.8538\n",
      "Epoch 10/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3538 - accuracy: 0.8468\n",
      "Epoch 10: val_accuracy did not improve from 0.85385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8605 - val_loss: 0.3459 - val_accuracy: 0.8469\n",
      "Epoch 11/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3191 - accuracy: 0.8871\n",
      "Epoch 11: val_accuracy did not improve from 0.85385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8634 - val_loss: 0.3370 - val_accuracy: 0.8485\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2983 - accuracy: 0.8952\n",
      "Epoch 12: val_accuracy improved from 0.85385 to 0.85462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8601 - val_loss: 0.3280 - val_accuracy: 0.8546\n",
      "Epoch 13/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2855 - accuracy: 0.9032\n",
      "Epoch 13: val_accuracy did not improve from 0.85462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8753 - val_loss: 0.3415 - val_accuracy: 0.8438\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3562 - accuracy: 0.8548\n",
      "Epoch 14: val_accuracy improved from 0.85462 to 0.86538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3139 - accuracy: 0.8672 - val_loss: 0.3342 - val_accuracy: 0.8654\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3905 - accuracy: 0.8468\n",
      "Epoch 15: val_accuracy did not improve from 0.86538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8668 - val_loss: 0.3273 - val_accuracy: 0.8569\n",
      "Epoch 16/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3639 - accuracy: 0.8387\n",
      "Epoch 16: val_accuracy did not improve from 0.86538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8597 - val_loss: 0.3269 - val_accuracy: 0.8515\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3028 - accuracy: 0.8871\n",
      "Epoch 17: val_accuracy did not improve from 0.86538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8717 - val_loss: 0.3227 - val_accuracy: 0.8585\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3129 - accuracy: 0.8710\n",
      "Epoch 18: val_accuracy improved from 0.86538 to 0.86692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3027 - accuracy: 0.8744 - val_loss: 0.3289 - val_accuracy: 0.8669\n",
      "Epoch 19/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2935 - accuracy: 0.8790\n",
      "Epoch 19: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3060 - accuracy: 0.8722 - val_loss: 0.3228 - val_accuracy: 0.8577\n",
      "Epoch 20/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2559 - accuracy: 0.9113\n",
      "Epoch 20: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2985 - accuracy: 0.8780 - val_loss: 0.3394 - val_accuracy: 0.8615\n",
      "Epoch 21/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2997 - accuracy: 0.8710\n",
      "Epoch 21: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2964 - accuracy: 0.8799 - val_loss: 0.3315 - val_accuracy: 0.8654\n",
      "Epoch 22/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2318 - accuracy: 0.9274\n",
      "Epoch 22: val_accuracy improved from 0.86692 to 0.87077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2896 - accuracy: 0.8842 - val_loss: 0.3178 - val_accuracy: 0.8708\n",
      "Epoch 23/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3326 - accuracy: 0.8468\n",
      "Epoch 23: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2944 - accuracy: 0.8761 - val_loss: 0.3630 - val_accuracy: 0.8477\n",
      "Epoch 24/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2785 - accuracy: 0.8629\n",
      "Epoch 24: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2947 - accuracy: 0.8807 - val_loss: 0.3289 - val_accuracy: 0.8700\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2203 - accuracy: 0.8790\n",
      "Epoch 25: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2885 - accuracy: 0.8780 - val_loss: 0.3102 - val_accuracy: 0.8700\n",
      "Epoch 26/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2172 - accuracy: 0.9032\n",
      "Epoch 26: val_accuracy improved from 0.87077 to 0.87538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2807 - accuracy: 0.8849 - val_loss: 0.3137 - val_accuracy: 0.8754\n",
      "Epoch 27/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2200 - accuracy: 0.9194\n",
      "Epoch 27: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2834 - accuracy: 0.8826 - val_loss: 0.3218 - val_accuracy: 0.8677\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2781 - accuracy: 0.8790\n",
      "Epoch 28: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2874 - accuracy: 0.8797 - val_loss: 0.3537 - val_accuracy: 0.8408\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3085 - accuracy: 0.8710\n",
      "Epoch 29: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2898 - accuracy: 0.8790 - val_loss: 0.3066 - val_accuracy: 0.8708\n",
      "Epoch 30/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1870 - accuracy: 0.9435\n",
      "Epoch 30: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2821 - accuracy: 0.8822 - val_loss: 0.3082 - val_accuracy: 0.8746\n",
      "Epoch 31/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3008 - accuracy: 0.8871\n",
      "Epoch 31: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2754 - accuracy: 0.8859 - val_loss: 0.3040 - val_accuracy: 0.8738\n",
      "Epoch 32/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2933 - accuracy: 0.8871\n",
      "Epoch 32: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2738 - accuracy: 0.8830 - val_loss: 0.3009 - val_accuracy: 0.8738\n",
      "Epoch 33/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2590 - accuracy: 0.8790\n",
      "Epoch 33: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2862 - accuracy: 0.8782 - val_loss: 0.3450 - val_accuracy: 0.8462\n",
      "Epoch 34/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2656 - accuracy: 0.8952\n",
      "Epoch 34: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2832 - accuracy: 0.8826 - val_loss: 0.3121 - val_accuracy: 0.8585\n",
      "Epoch 35/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2550 - accuracy: 0.9194\n",
      "Epoch 35: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2687 - accuracy: 0.8871 - val_loss: 0.3139 - val_accuracy: 0.8723\n",
      "Epoch 36/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2215 - accuracy: 0.9194\n",
      "Epoch 36: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2785 - accuracy: 0.8842 - val_loss: 0.2991 - val_accuracy: 0.8746\n",
      "Epoch 37/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2746 - accuracy: 0.8710\n",
      "Epoch 37: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2707 - accuracy: 0.8894 - val_loss: 0.3014 - val_accuracy: 0.8731\n",
      "Epoch 38/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3025 - accuracy: 0.8952\n",
      "Epoch 38: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2616 - accuracy: 0.8946 - val_loss: 0.2973 - val_accuracy: 0.8708\n",
      "Epoch 39/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2103 - accuracy: 0.9194\n",
      "Epoch 39: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2832 - accuracy: 0.8853 - val_loss: 0.3202 - val_accuracy: 0.8577\n",
      "Epoch 40/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3288 - accuracy: 0.8629\n",
      "Epoch 40: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2671 - accuracy: 0.8911 - val_loss: 0.3357 - val_accuracy: 0.8515\n",
      "Epoch 41/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4032 - accuracy: 0.8145\n",
      "Epoch 41: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2689 - accuracy: 0.8905 - val_loss: 0.3279 - val_accuracy: 0.8562\n",
      "Epoch 42/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2609 - accuracy: 0.8952\n",
      "Epoch 42: val_accuracy improved from 0.87538 to 0.88308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2598 - accuracy: 0.8949 - val_loss: 0.3007 - val_accuracy: 0.8831\n",
      "Epoch 43/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.2535 - accuracy: 0.8978\n",
      "Epoch 43: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2563 - accuracy: 0.8936 - val_loss: 0.3008 - val_accuracy: 0.8808\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2902 - accuracy: 0.8871\n",
      "Epoch 44: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2553 - accuracy: 0.8978 - val_loss: 0.2958 - val_accuracy: 0.8823\n",
      "Epoch 45/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3424 - accuracy: 0.8790\n",
      "Epoch 45: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2701 - accuracy: 0.8880 - val_loss: 0.2982 - val_accuracy: 0.8738\n",
      "Epoch 46/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2828 - accuracy: 0.8790\n",
      "Epoch 46: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.8901 - val_loss: 0.2949 - val_accuracy: 0.8777\n",
      "Epoch 47/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2291 - accuracy: 0.8952\n",
      "Epoch 47: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.8996 - val_loss: 0.3026 - val_accuracy: 0.8677\n",
      "Epoch 48/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2663 - accuracy: 0.8790\n",
      "Epoch 48: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.8888 - val_loss: 0.2973 - val_accuracy: 0.8708\n",
      "Epoch 49/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1907 - accuracy: 0.9355\n",
      "Epoch 49: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2571 - accuracy: 0.8926 - val_loss: 0.3213 - val_accuracy: 0.8662\n",
      "Epoch 50/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2672 - accuracy: 0.9113\n",
      "Epoch 50: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2538 - accuracy: 0.8938 - val_loss: 0.3053 - val_accuracy: 0.8700\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1962 - accuracy: 0.9274\n",
      "Epoch 51: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2484 - accuracy: 0.8980 - val_loss: 0.3228 - val_accuracy: 0.8592\n",
      "Epoch 52/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2693 - accuracy: 0.9032\n",
      "Epoch 52: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2540 - accuracy: 0.8965 - val_loss: 0.2949 - val_accuracy: 0.8808\n",
      "Epoch 53/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3160 - accuracy: 0.8790\n",
      "Epoch 53: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2422 - accuracy: 0.9053 - val_loss: 0.2910 - val_accuracy: 0.8815\n",
      "Epoch 54/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2368 - accuracy: 0.8952\n",
      "Epoch 54: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2419 - accuracy: 0.9032 - val_loss: 0.2956 - val_accuracy: 0.8808\n",
      "Epoch 55/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1854 - accuracy: 0.9274\n",
      "Epoch 55: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.9015 - val_loss: 0.3098 - val_accuracy: 0.8654\n",
      "Epoch 56/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2211 - accuracy: 0.9032\n",
      "Epoch 56: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.9003 - val_loss: 0.3000 - val_accuracy: 0.8808\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1705 - accuracy: 0.9435\n",
      "Epoch 57: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2391 - accuracy: 0.9071 - val_loss: 0.2994 - val_accuracy: 0.8823\n",
      "Epoch 58/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2137 - accuracy: 0.9355\n",
      "Epoch 58: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2475 - accuracy: 0.8997 - val_loss: 0.3211 - val_accuracy: 0.8700\n",
      "Epoch 59/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2425 - accuracy: 0.8790\n",
      "Epoch 59: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.8892 - val_loss: 0.3015 - val_accuracy: 0.8777\n",
      "Epoch 60/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1953 - accuracy: 0.9355\n",
      "Epoch 60: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2370 - accuracy: 0.9036 - val_loss: 0.2972 - val_accuracy: 0.8754\n",
      "Epoch 61/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2357 - accuracy: 0.8952\n",
      "Epoch 61: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2427 - accuracy: 0.9040 - val_loss: 0.2980 - val_accuracy: 0.8800\n",
      "Epoch 62/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2559 - accuracy: 0.9274\n",
      "Epoch 62: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2585 - accuracy: 0.8942 - val_loss: 0.3924 - val_accuracy: 0.8400\n",
      "Epoch 63/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3345 - accuracy: 0.8387\n",
      "Epoch 63: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.9007 - val_loss: 0.2990 - val_accuracy: 0.8815\n",
      "Epoch 64/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2206 - accuracy: 0.9194\n",
      "Epoch 64: val_accuracy improved from 0.88308 to 0.88385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2412 - accuracy: 0.9026 - val_loss: 0.2978 - val_accuracy: 0.8838\n",
      "Epoch 65/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2299 - accuracy: 0.8952\n",
      "Epoch 65: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2547 - accuracy: 0.8999 - val_loss: 0.3256 - val_accuracy: 0.8646\n",
      "Epoch 66/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1912 - accuracy: 0.8871\n",
      "Epoch 66: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2420 - accuracy: 0.9001 - val_loss: 0.3084 - val_accuracy: 0.8677\n",
      "Epoch 67/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2767 - accuracy: 0.8710\n",
      "Epoch 67: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2382 - accuracy: 0.9040 - val_loss: 0.2980 - val_accuracy: 0.8792\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2470 - accuracy: 0.8871\n",
      "Epoch 68: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2350 - accuracy: 0.9034 - val_loss: 0.3109 - val_accuracy: 0.8746\n",
      "Epoch 69/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2557 - accuracy: 0.8790\n",
      "Epoch 69: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2377 - accuracy: 0.9046 - val_loss: 0.3009 - val_accuracy: 0.8808\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2344 - accuracy: 0.8952\n",
      "Epoch 70: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2325 - accuracy: 0.9071 - val_loss: 0.3057 - val_accuracy: 0.8808\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1857 - accuracy: 0.9194\n",
      "Epoch 71: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2328 - accuracy: 0.9057 - val_loss: 0.3049 - val_accuracy: 0.8808\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2290 - accuracy: 0.9113\n",
      "Epoch 72: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2363 - accuracy: 0.9030 - val_loss: 0.3067 - val_accuracy: 0.8731\n",
      "Epoch 73/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2480 - accuracy: 0.9113\n",
      "Epoch 73: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2415 - accuracy: 0.9061 - val_loss: 0.3014 - val_accuracy: 0.8777\n",
      "Epoch 74/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2256 - accuracy: 0.9113\n",
      "Epoch 74: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2299 - accuracy: 0.9074 - val_loss: 0.3017 - val_accuracy: 0.8754\n",
      "Epoch 75/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2369 - accuracy: 0.9113\n",
      "Epoch 75: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2286 - accuracy: 0.9080 - val_loss: 0.3049 - val_accuracy: 0.8800\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2167 - accuracy: 0.8790\n",
      "Epoch 76: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2273 - accuracy: 0.9107 - val_loss: 0.3050 - val_accuracy: 0.8831\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2163 - accuracy: 0.9113\n",
      "Epoch 77: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2280 - accuracy: 0.9098 - val_loss: 0.3145 - val_accuracy: 0.8738\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2196 - accuracy: 0.9194\n",
      "Epoch 78: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2356 - accuracy: 0.9059 - val_loss: 0.3412 - val_accuracy: 0.8646\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2812 - accuracy: 0.8629\n",
      "Epoch 79: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2308 - accuracy: 0.9086 - val_loss: 0.4029 - val_accuracy: 0.8377\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3415 - accuracy: 0.8387\n",
      "Epoch 80: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8974 - val_loss: 0.3053 - val_accuracy: 0.8738\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2666 - accuracy: 0.8790\n",
      "Epoch 81: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2285 - accuracy: 0.9076 - val_loss: 0.3167 - val_accuracy: 0.8762\n",
      "Epoch 82/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1913 - accuracy: 0.9355\n",
      "Epoch 82: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2272 - accuracy: 0.9101 - val_loss: 0.3101 - val_accuracy: 0.8762\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2118 - accuracy: 0.9355\n",
      "Epoch 83: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2213 - accuracy: 0.9124 - val_loss: 0.3025 - val_accuracy: 0.8785\n",
      "Epoch 84/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2306 - accuracy: 0.9032\n",
      "Epoch 84: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2203 - accuracy: 0.9096 - val_loss: 0.3204 - val_accuracy: 0.8731\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2725 - accuracy: 0.8629\n",
      "Epoch 85: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2218 - accuracy: 0.9123 - val_loss: 0.3338 - val_accuracy: 0.8677\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2155 - accuracy: 0.8952\n",
      "Epoch 86: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.9098 - val_loss: 0.3095 - val_accuracy: 0.8823\n",
      "Epoch 87/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1963 - accuracy: 0.9274\n",
      "Epoch 87: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2208 - accuracy: 0.9123 - val_loss: 0.3054 - val_accuracy: 0.8754\n",
      "Epoch 88/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2414 - accuracy: 0.8952\n",
      "Epoch 88: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2216 - accuracy: 0.9098 - val_loss: 0.3080 - val_accuracy: 0.8746\n",
      "Epoch 89/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1720 - accuracy: 0.9355\n",
      "Epoch 89: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2178 - accuracy: 0.9134 - val_loss: 0.3092 - val_accuracy: 0.8738\n",
      "Epoch 90/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1748 - accuracy: 0.9113\n",
      "Epoch 90: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2183 - accuracy: 0.9119 - val_loss: 0.3161 - val_accuracy: 0.8785\n",
      "Epoch 91/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2217 - accuracy: 0.9194\n",
      "Epoch 91: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2150 - accuracy: 0.9150 - val_loss: 0.3156 - val_accuracy: 0.8738\n",
      "Epoch 92/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2022 - accuracy: 0.9194\n",
      "Epoch 92: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.9078 - val_loss: 0.3221 - val_accuracy: 0.8715\n",
      "Epoch 93/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2347 - accuracy: 0.9274\n",
      "Epoch 93: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2162 - accuracy: 0.9144 - val_loss: 0.3169 - val_accuracy: 0.8769\n",
      "Epoch 94/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1653 - accuracy: 0.9435\n",
      "Epoch 94: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2163 - accuracy: 0.9134 - val_loss: 0.3089 - val_accuracy: 0.8746\n",
      "Epoch 95/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1415 - accuracy: 0.9516\n",
      "Epoch 95: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2196 - accuracy: 0.9105 - val_loss: 0.3113 - val_accuracy: 0.8777\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2023 - accuracy: 0.9194\n",
      "Epoch 96: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2179 - accuracy: 0.9148 - val_loss: 0.3226 - val_accuracy: 0.8692\n",
      "Epoch 97/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1572 - accuracy: 0.9435\n",
      "Epoch 97: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2420 - accuracy: 0.8972 - val_loss: 0.3180 - val_accuracy: 0.8715\n",
      "Epoch 98/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1883 - accuracy: 0.9355\n",
      "Epoch 98: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2265 - accuracy: 0.9086 - val_loss: 0.3296 - val_accuracy: 0.8723\n",
      "Epoch 99/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2531 - accuracy: 0.9113\n",
      "Epoch 99: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.9136 - val_loss: 0.3289 - val_accuracy: 0.8700\n",
      "Epoch 100/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2686 - accuracy: 0.9032\n",
      "Epoch 100: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2141 - accuracy: 0.9107 - val_loss: 0.3255 - val_accuracy: 0.8692\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1717 - accuracy: 0.9355\n",
      "Epoch 101: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2152 - accuracy: 0.9130 - val_loss: 0.3119 - val_accuracy: 0.8754\n",
      "Epoch 102/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1459 - accuracy: 0.9516\n",
      "Epoch 102: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2044 - accuracy: 0.9182 - val_loss: 0.3157 - val_accuracy: 0.8723\n",
      "Epoch 103/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1692 - accuracy: 0.9355\n",
      "Epoch 103: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2109 - accuracy: 0.9153 - val_loss: 0.3134 - val_accuracy: 0.8738\n",
      "Epoch 104/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1579 - accuracy: 0.9435\n",
      "Epoch 104: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2090 - accuracy: 0.9144 - val_loss: 0.3144 - val_accuracy: 0.8723\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1496 - accuracy: 0.9435\n",
      "Epoch 105: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2159 - accuracy: 0.9124 - val_loss: 0.3085 - val_accuracy: 0.8677\n",
      "Epoch 106/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2179 - accuracy: 0.9194\n",
      "Epoch 106: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2031 - accuracy: 0.9194 - val_loss: 0.3276 - val_accuracy: 0.8723\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1930 - accuracy: 0.9032\n",
      "Epoch 107: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2166 - accuracy: 0.9150 - val_loss: 0.3149 - val_accuracy: 0.8746\n",
      "Epoch 108/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1433 - accuracy: 0.9355\n",
      "Epoch 108: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2175 - accuracy: 0.9109 - val_loss: 0.3293 - val_accuracy: 0.8715\n",
      "Epoch 109/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2138 - accuracy: 0.9194\n",
      "Epoch 109: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2083 - accuracy: 0.9169 - val_loss: 0.3165 - val_accuracy: 0.8685\n",
      "Epoch 110/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2169 - accuracy: 0.8952\n",
      "Epoch 110: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2076 - accuracy: 0.9188 - val_loss: 0.3667 - val_accuracy: 0.8577\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2572 - accuracy: 0.9032\n",
      "Epoch 111: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2203 - accuracy: 0.9119 - val_loss: 0.3180 - val_accuracy: 0.8777\n",
      "Epoch 112/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1984 - accuracy: 0.9225\n",
      "Epoch 112: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1984 - accuracy: 0.9225 - val_loss: 0.3149 - val_accuracy: 0.8723\n",
      "Epoch 113/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1705 - accuracy: 0.9274\n",
      "Epoch 113: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2041 - accuracy: 0.9186 - val_loss: 0.3204 - val_accuracy: 0.8715\n",
      "Epoch 114/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2037 - accuracy: 0.9194\n",
      "Epoch 114: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2117 - accuracy: 0.9148 - val_loss: 0.3270 - val_accuracy: 0.8669\n",
      "Epoch 115/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2330 - accuracy: 0.9194\n",
      "Epoch 115: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.9248 - val_loss: 0.3181 - val_accuracy: 0.8700\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1908 - accuracy: 0.9194\n",
      "Epoch 116: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2061 - accuracy: 0.9146 - val_loss: 0.3214 - val_accuracy: 0.8708\n",
      "Epoch 117/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1417 - accuracy: 0.9194\n",
      "Epoch 117: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2000 - accuracy: 0.9165 - val_loss: 0.3407 - val_accuracy: 0.8738\n",
      "Epoch 118/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2201 - accuracy: 0.9113\n",
      "Epoch 118: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1992 - accuracy: 0.9215 - val_loss: 0.3407 - val_accuracy: 0.8715\n",
      "Epoch 119/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1654 - accuracy: 0.9274\n",
      "Epoch 119: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.9238 - val_loss: 0.3370 - val_accuracy: 0.8654\n",
      "Epoch 120/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1967 - accuracy: 0.9435\n",
      "Epoch 120: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.9251 - val_loss: 0.3255 - val_accuracy: 0.8700\n",
      "Epoch 121/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1612 - accuracy: 0.9355\n",
      "Epoch 121: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1979 - accuracy: 0.9165 - val_loss: 0.3705 - val_accuracy: 0.8723\n",
      "Epoch 122/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1572 - accuracy: 0.9274\n",
      "Epoch 122: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1956 - accuracy: 0.9194 - val_loss: 0.3367 - val_accuracy: 0.8646\n",
      "Epoch 123/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2417 - accuracy: 0.8790\n",
      "Epoch 123: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2011 - accuracy: 0.9180 - val_loss: 0.3682 - val_accuracy: 0.8615\n",
      "Epoch 124/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1284 - accuracy: 0.9435\n",
      "Epoch 124: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1977 - accuracy: 0.9192 - val_loss: 0.3435 - val_accuracy: 0.8662\n",
      "Epoch 125/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1659 - accuracy: 0.9597\n",
      "Epoch 125: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1968 - accuracy: 0.9221 - val_loss: 0.3349 - val_accuracy: 0.8608\n",
      "Epoch 126/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2250 - accuracy: 0.9274\n",
      "Epoch 126: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1972 - accuracy: 0.9203 - val_loss: 0.3398 - val_accuracy: 0.8685\n",
      "Epoch 127/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2187 - accuracy: 0.8952\n",
      "Epoch 127: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1908 - accuracy: 0.9255 - val_loss: 0.3451 - val_accuracy: 0.8738\n",
      "Epoch 128/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1545 - accuracy: 0.9194\n",
      "Epoch 128: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1981 - accuracy: 0.9180 - val_loss: 0.3310 - val_accuracy: 0.8669\n",
      "Epoch 129/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1967 - accuracy: 0.9032\n",
      "Epoch 129: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2028 - accuracy: 0.9157 - val_loss: 0.3415 - val_accuracy: 0.8623\n",
      "Epoch 130/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1743 - accuracy: 0.9435\n",
      "Epoch 130: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2049 - accuracy: 0.9146 - val_loss: 0.3314 - val_accuracy: 0.8715\n",
      "Epoch 131/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1114 - accuracy: 0.9758\n",
      "Epoch 131: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.9240 - val_loss: 0.3342 - val_accuracy: 0.8692\n",
      "Epoch 132/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2042 - accuracy: 0.9194\n",
      "Epoch 132: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1918 - accuracy: 0.9217 - val_loss: 0.3518 - val_accuracy: 0.8738\n",
      "Epoch 133/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1047 - accuracy: 0.9677\n",
      "Epoch 133: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.9205 - val_loss: 0.3531 - val_accuracy: 0.8692\n",
      "Epoch 134/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1982 - accuracy: 0.9113\n",
      "Epoch 134: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1865 - accuracy: 0.9275 - val_loss: 0.3383 - val_accuracy: 0.8662\n",
      "Epoch 135/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1091 - accuracy: 0.9677\n",
      "Epoch 135: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1885 - accuracy: 0.9261 - val_loss: 0.3808 - val_accuracy: 0.8485\n",
      "Epoch 136/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2514 - accuracy: 0.9113\n",
      "Epoch 136: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1802 - accuracy: 0.9280 - val_loss: 0.3398 - val_accuracy: 0.8685\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2124 - accuracy: 0.9435\n",
      "Epoch 137: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.9273 - val_loss: 0.3897 - val_accuracy: 0.8662\n",
      "Epoch 138/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2964 - accuracy: 0.9032\n",
      "Epoch 138: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.9277 - val_loss: 0.3540 - val_accuracy: 0.8685\n",
      "Epoch 139/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1517 - accuracy: 0.9435\n",
      "Epoch 139: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1887 - accuracy: 0.9236 - val_loss: 0.3517 - val_accuracy: 0.8646\n",
      "Epoch 140/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2418 - accuracy: 0.9032\n",
      "Epoch 140: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1979 - accuracy: 0.9201 - val_loss: 0.3444 - val_accuracy: 0.8677\n",
      "Epoch 141/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1603 - accuracy: 0.9194\n",
      "Epoch 141: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1817 - accuracy: 0.9259 - val_loss: 0.3422 - val_accuracy: 0.8685\n",
      "Epoch 142/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1781 - accuracy: 0.8952\n",
      "Epoch 142: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.9284 - val_loss: 0.3530 - val_accuracy: 0.8615\n",
      "Epoch 143/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2398 - accuracy: 0.8952\n",
      "Epoch 143: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.9290 - val_loss: 0.3692 - val_accuracy: 0.8692\n",
      "Epoch 144/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1994 - accuracy: 0.9435\n",
      "Epoch 144: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.9230 - val_loss: 0.3407 - val_accuracy: 0.8685\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1479 - accuracy: 0.9355\n",
      "Epoch 145: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.9302 - val_loss: 0.3777 - val_accuracy: 0.8623\n",
      "Epoch 146/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1770 - accuracy: 0.9435\n",
      "Epoch 146: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.9303 - val_loss: 0.3399 - val_accuracy: 0.8585\n",
      "Epoch 147/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1532 - accuracy: 0.9355\n",
      "Epoch 147: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1735 - accuracy: 0.9280 - val_loss: 0.3682 - val_accuracy: 0.8692\n",
      "Epoch 148/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1061 - accuracy: 0.9677\n",
      "Epoch 148: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1774 - accuracy: 0.9267 - val_loss: 0.3446 - val_accuracy: 0.8700\n",
      "Epoch 149/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1539 - accuracy: 0.9355\n",
      "Epoch 149: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.9282 - val_loss: 0.3566 - val_accuracy: 0.8738\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1798 - accuracy: 0.9355\n",
      "Epoch 150: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.9315 - val_loss: 0.3573 - val_accuracy: 0.8662\n",
      "Epoch 151/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1670 - accuracy: 0.9355\n",
      "Epoch 151: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1762 - accuracy: 0.9277 - val_loss: 0.3644 - val_accuracy: 0.8715\n",
      "Epoch 152/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1306 - accuracy: 0.9355\n",
      "Epoch 152: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1724 - accuracy: 0.9303 - val_loss: 0.3493 - val_accuracy: 0.8662\n",
      "Epoch 153/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1400 - accuracy: 0.9355\n",
      "Epoch 153: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1648 - accuracy: 0.9348 - val_loss: 0.3562 - val_accuracy: 0.8669\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 22s - loss: 1.7336 - accuracy: 0.4516\n",
      "Epoch 1: val_accuracy improved from -inf to 0.70846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.6951 - accuracy: 0.6105 - val_loss: 0.5683 - val_accuracy: 0.7085\n",
      "Epoch 2/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.5635 - accuracy: 0.7339\n",
      "Epoch 2: val_accuracy improved from 0.70846 to 0.82154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7676 - val_loss: 0.4562 - val_accuracy: 0.8215\n",
      "Epoch 3/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4522 - accuracy: 0.7984\n",
      "Epoch 3: val_accuracy improved from 0.82154 to 0.84308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8232 - val_loss: 0.3731 - val_accuracy: 0.8431\n",
      "Epoch 4/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3806 - accuracy: 0.8548\n",
      "Epoch 4: val_accuracy improved from 0.84308 to 0.84923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8516 - val_loss: 0.3543 - val_accuracy: 0.8492\n",
      "Epoch 5/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3859 - accuracy: 0.8468\n",
      "Epoch 5: val_accuracy improved from 0.84923 to 0.85308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8572 - val_loss: 0.3448 - val_accuracy: 0.8531\n",
      "Epoch 6/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4139 - accuracy: 0.8065\n",
      "Epoch 6: val_accuracy improved from 0.85308 to 0.85615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8543 - val_loss: 0.3361 - val_accuracy: 0.8562\n",
      "Epoch 7/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2915 - accuracy: 0.8629\n",
      "Epoch 7: val_accuracy did not improve from 0.85615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8634 - val_loss: 0.3671 - val_accuracy: 0.8338\n",
      "Epoch 8/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3785 - accuracy: 0.8226\n",
      "Epoch 8: val_accuracy improved from 0.85615 to 0.85846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8715 - val_loss: 0.3387 - val_accuracy: 0.8585\n",
      "Epoch 9/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3741 - accuracy: 0.7984\n",
      "Epoch 9: val_accuracy did not improve from 0.85846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8526 - val_loss: 0.3495 - val_accuracy: 0.8562\n",
      "Epoch 10/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3094 - accuracy: 0.8871\n",
      "Epoch 10: val_accuracy improved from 0.85846 to 0.86769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.8732 - val_loss: 0.3318 - val_accuracy: 0.8677\n",
      "Epoch 11/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3021 - accuracy: 0.8790\n",
      "Epoch 11: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8684 - val_loss: 0.3261 - val_accuracy: 0.8531\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3395 - accuracy: 0.8468\n",
      "Epoch 12: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.8761 - val_loss: 0.3233 - val_accuracy: 0.8631\n",
      "Epoch 13/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2611 - accuracy: 0.9032\n",
      "Epoch 13: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8765 - val_loss: 0.3199 - val_accuracy: 0.8569\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2450 - accuracy: 0.8790\n",
      "Epoch 14: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.8770 - val_loss: 0.3124 - val_accuracy: 0.8646\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2103 - accuracy: 0.9274\n",
      "Epoch 15: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2933 - accuracy: 0.8761 - val_loss: 0.3116 - val_accuracy: 0.8638\n",
      "Epoch 16/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4140 - accuracy: 0.8468\n",
      "Epoch 16: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2913 - accuracy: 0.8805 - val_loss: 0.3201 - val_accuracy: 0.8600\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2465 - accuracy: 0.8952\n",
      "Epoch 17: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2807 - accuracy: 0.8869 - val_loss: 0.3321 - val_accuracy: 0.8554\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2880 - accuracy: 0.8871\n",
      "Epoch 18: val_accuracy improved from 0.86769 to 0.86923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2922 - accuracy: 0.8782 - val_loss: 0.3043 - val_accuracy: 0.8692\n",
      "Epoch 19/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2643 - accuracy: 0.8952\n",
      "Epoch 19: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2832 - accuracy: 0.8845 - val_loss: 0.3267 - val_accuracy: 0.8662\n",
      "Epoch 20/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3031 - accuracy: 0.8871\n",
      "Epoch 20: val_accuracy improved from 0.86923 to 0.87538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2920 - accuracy: 0.8772 - val_loss: 0.3009 - val_accuracy: 0.8754\n",
      "Epoch 21/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3203 - accuracy: 0.8548\n",
      "Epoch 21: val_accuracy improved from 0.87538 to 0.87615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2852 - accuracy: 0.8838 - val_loss: 0.2983 - val_accuracy: 0.8762\n",
      "Epoch 22/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2617 - accuracy: 0.8871\n",
      "Epoch 22: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2725 - accuracy: 0.8890 - val_loss: 0.3016 - val_accuracy: 0.8708\n",
      "Epoch 23/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2359 - accuracy: 0.9032\n",
      "Epoch 23: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2784 - accuracy: 0.8826 - val_loss: 0.2994 - val_accuracy: 0.8715\n",
      "Epoch 24/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3005 - accuracy: 0.9032\n",
      "Epoch 24: val_accuracy improved from 0.87615 to 0.87923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2744 - accuracy: 0.8853 - val_loss: 0.2967 - val_accuracy: 0.8792\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2108 - accuracy: 0.9435\n",
      "Epoch 25: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2899 - accuracy: 0.8776 - val_loss: 0.3189 - val_accuracy: 0.8600\n",
      "Epoch 26/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3041 - accuracy: 0.8710\n",
      "Epoch 26: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2785 - accuracy: 0.8859 - val_loss: 0.2947 - val_accuracy: 0.8731\n",
      "Epoch 27/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2258 - accuracy: 0.9194\n",
      "Epoch 27: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2648 - accuracy: 0.8942 - val_loss: 0.2951 - val_accuracy: 0.8762\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2131 - accuracy: 0.9516\n",
      "Epoch 28: val_accuracy improved from 0.87923 to 0.88000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2641 - accuracy: 0.8926 - val_loss: 0.2951 - val_accuracy: 0.8800\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2558 - accuracy: 0.8871\n",
      "Epoch 29: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2648 - accuracy: 0.8926 - val_loss: 0.2893 - val_accuracy: 0.8754\n",
      "Epoch 30/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2603 - accuracy: 0.8629\n",
      "Epoch 30: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2791 - accuracy: 0.8836 - val_loss: 0.3465 - val_accuracy: 0.8500\n",
      "Epoch 31/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2989 - accuracy: 0.8952\n",
      "Epoch 31: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.8842 - val_loss: 0.2935 - val_accuracy: 0.8746\n",
      "Epoch 32/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1782 - accuracy: 0.9274\n",
      "Epoch 32: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2601 - accuracy: 0.8971 - val_loss: 0.2924 - val_accuracy: 0.8731\n",
      "Epoch 33/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2107 - accuracy: 0.9274\n",
      "Epoch 33: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2581 - accuracy: 0.8967 - val_loss: 0.2942 - val_accuracy: 0.8746\n",
      "Epoch 34/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2174 - accuracy: 0.9194\n",
      "Epoch 34: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2552 - accuracy: 0.8978 - val_loss: 0.3067 - val_accuracy: 0.8754\n",
      "Epoch 35/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2420 - accuracy: 0.9032\n",
      "Epoch 35: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 0.8949 - val_loss: 0.2886 - val_accuracy: 0.8769\n",
      "Epoch 36/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2336 - accuracy: 0.9032\n",
      "Epoch 36: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.9001 - val_loss: 0.2893 - val_accuracy: 0.8785\n",
      "Epoch 37/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2285 - accuracy: 0.9194\n",
      "Epoch 37: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2618 - accuracy: 0.8928 - val_loss: 0.2943 - val_accuracy: 0.8769\n",
      "Epoch 38/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2773 - accuracy: 0.8952\n",
      "Epoch 38: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2591 - accuracy: 0.8894 - val_loss: 0.3091 - val_accuracy: 0.8723\n",
      "Epoch 39/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2849 - accuracy: 0.9113\n",
      "Epoch 39: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2616 - accuracy: 0.8909 - val_loss: 0.2955 - val_accuracy: 0.8762\n",
      "Epoch 40/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2574 - accuracy: 0.9113\n",
      "Epoch 40: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2584 - accuracy: 0.8949 - val_loss: 0.3267 - val_accuracy: 0.8615\n",
      "Epoch 41/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4303 - accuracy: 0.8306\n",
      "Epoch 41: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 0.8959 - val_loss: 0.2920 - val_accuracy: 0.8723\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2549 - accuracy: 0.9274\n",
      "Epoch 42: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2485 - accuracy: 0.9011 - val_loss: 0.3029 - val_accuracy: 0.8792\n",
      "Epoch 43/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3247 - accuracy: 0.8387\n",
      "Epoch 43: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.8972 - val_loss: 0.2907 - val_accuracy: 0.8738\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1973 - accuracy: 0.9113\n",
      "Epoch 44: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.8909 - val_loss: 0.2905 - val_accuracy: 0.8792\n",
      "Epoch 45/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2590 - accuracy: 0.8958\n",
      "Epoch 45: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2587 - accuracy: 0.8957 - val_loss: 0.2988 - val_accuracy: 0.8708\n",
      "Epoch 46/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2295 - accuracy: 0.8790\n",
      "Epoch 46: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2533 - accuracy: 0.8965 - val_loss: 0.2979 - val_accuracy: 0.8731\n",
      "Epoch 47/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2583 - accuracy: 0.8952\n",
      "Epoch 47: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2488 - accuracy: 0.8971 - val_loss: 0.2959 - val_accuracy: 0.8746\n",
      "Epoch 48/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3064 - accuracy: 0.8871\n",
      "Epoch 48: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2432 - accuracy: 0.9015 - val_loss: 0.3035 - val_accuracy: 0.8708\n",
      "Epoch 49/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2521 - accuracy: 0.8939\n",
      "Epoch 49: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.8955 - val_loss: 0.2978 - val_accuracy: 0.8723\n",
      "Epoch 50/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2168 - accuracy: 0.8952\n",
      "Epoch 50: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.8980 - val_loss: 0.3131 - val_accuracy: 0.8715\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2717 - accuracy: 0.8629\n",
      "Epoch 51: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2528 - accuracy: 0.8944 - val_loss: 0.3253 - val_accuracy: 0.8615\n",
      "Epoch 52/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3048 - accuracy: 0.8548\n",
      "Epoch 52: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.9015 - val_loss: 0.2932 - val_accuracy: 0.8762\n",
      "Epoch 53/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2869 - accuracy: 0.8790\n",
      "Epoch 53: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.9003 - val_loss: 0.2981 - val_accuracy: 0.8754\n",
      "Epoch 54/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2737 - accuracy: 0.8790\n",
      "Epoch 54: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8994 - val_loss: 0.3305 - val_accuracy: 0.8638\n",
      "Epoch 55/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3554 - accuracy: 0.8629\n",
      "Epoch 55: val_accuracy improved from 0.88000 to 0.88308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.9007 - val_loss: 0.2931 - val_accuracy: 0.8831\n",
      "Epoch 56/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1638 - accuracy: 0.9435\n",
      "Epoch 56: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.8984 - val_loss: 0.2884 - val_accuracy: 0.8808\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2160 - accuracy: 0.9032\n",
      "Epoch 57: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2417 - accuracy: 0.9003 - val_loss: 0.2948 - val_accuracy: 0.8762\n",
      "Epoch 58/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3182 - accuracy: 0.8710\n",
      "Epoch 58: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2423 - accuracy: 0.8994 - val_loss: 0.2880 - val_accuracy: 0.8738\n",
      "Epoch 59/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3221 - accuracy: 0.8871\n",
      "Epoch 59: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2425 - accuracy: 0.9009 - val_loss: 0.2974 - val_accuracy: 0.8777\n",
      "Epoch 60/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1950 - accuracy: 0.9355\n",
      "Epoch 60: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2311 - accuracy: 0.9099 - val_loss: 0.2973 - val_accuracy: 0.8769\n",
      "Epoch 61/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2349 - accuracy: 0.9113\n",
      "Epoch 61: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.9007 - val_loss: 0.2929 - val_accuracy: 0.8762\n",
      "Epoch 62/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3234 - accuracy: 0.8710\n",
      "Epoch 62: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2365 - accuracy: 0.9003 - val_loss: 0.3018 - val_accuracy: 0.8754\n",
      "Epoch 63/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2025 - accuracy: 0.9355\n",
      "Epoch 63: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2362 - accuracy: 0.9057 - val_loss: 0.3035 - val_accuracy: 0.8731\n",
      "Epoch 64/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2120 - accuracy: 0.9032\n",
      "Epoch 64: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2533 - accuracy: 0.8949 - val_loss: 0.2915 - val_accuracy: 0.8723\n",
      "Epoch 65/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2356 - accuracy: 0.8952\n",
      "Epoch 65: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2270 - accuracy: 0.9061 - val_loss: 0.3021 - val_accuracy: 0.8746\n",
      "Epoch 66/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2375 - accuracy: 0.8952\n",
      "Epoch 66: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2290 - accuracy: 0.9042 - val_loss: 0.2997 - val_accuracy: 0.8792\n",
      "Epoch 67/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1919 - accuracy: 0.9274\n",
      "Epoch 67: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.9011 - val_loss: 0.2927 - val_accuracy: 0.8800\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2618 - accuracy: 0.8871\n",
      "Epoch 68: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.9013 - val_loss: 0.2970 - val_accuracy: 0.8777\n",
      "Epoch 69/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2894 - accuracy: 0.8629\n",
      "Epoch 69: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.9084 - val_loss: 0.3020 - val_accuracy: 0.8762\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1915 - accuracy: 0.8952\n",
      "Epoch 70: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2333 - accuracy: 0.9059 - val_loss: 0.2918 - val_accuracy: 0.8777\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1556 - accuracy: 0.9435\n",
      "Epoch 71: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2264 - accuracy: 0.9103 - val_loss: 0.3045 - val_accuracy: 0.8754\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2331 - accuracy: 0.9194\n",
      "Epoch 72: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2233 - accuracy: 0.9115 - val_loss: 0.3024 - val_accuracy: 0.8785\n",
      "Epoch 73/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2890 - accuracy: 0.8710\n",
      "Epoch 73: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2358 - accuracy: 0.9053 - val_loss: 0.2990 - val_accuracy: 0.8731\n",
      "Epoch 74/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3004 - accuracy: 0.8710\n",
      "Epoch 74: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2303 - accuracy: 0.9057 - val_loss: 0.3313 - val_accuracy: 0.8638\n",
      "Epoch 75/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2517 - accuracy: 0.9113\n",
      "Epoch 75: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2336 - accuracy: 0.9030 - val_loss: 0.3137 - val_accuracy: 0.8638\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2295 - accuracy: 0.9113\n",
      "Epoch 76: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.9057 - val_loss: 0.3064 - val_accuracy: 0.8800\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1788 - accuracy: 0.9435\n",
      "Epoch 77: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2246 - accuracy: 0.9103 - val_loss: 0.3418 - val_accuracy: 0.8500\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2786 - accuracy: 0.8629\n",
      "Epoch 78: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2317 - accuracy: 0.9024 - val_loss: 0.3683 - val_accuracy: 0.8462\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3108 - accuracy: 0.8629\n",
      "Epoch 79: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2269 - accuracy: 0.9101 - val_loss: 0.3423 - val_accuracy: 0.8646\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2857 - accuracy: 0.9194\n",
      "Epoch 80: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2196 - accuracy: 0.9092 - val_loss: 0.3104 - val_accuracy: 0.8723\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3101 - accuracy: 0.8710\n",
      "Epoch 81: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2193 - accuracy: 0.9115 - val_loss: 0.2947 - val_accuracy: 0.8777\n",
      "Epoch 82/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1676 - accuracy: 0.9435\n",
      "Epoch 82: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2249 - accuracy: 0.9044 - val_loss: 0.3005 - val_accuracy: 0.8731\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2264 - accuracy: 0.9274\n",
      "Epoch 83: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.9121 - val_loss: 0.3032 - val_accuracy: 0.8700\n",
      "Epoch 84/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2254 - accuracy: 0.9032\n",
      "Epoch 84: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 0.9071 - val_loss: 0.3009 - val_accuracy: 0.8746\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1936 - accuracy: 0.9274\n",
      "Epoch 85: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2198 - accuracy: 0.9090 - val_loss: 0.3020 - val_accuracy: 0.8785\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3020 - accuracy: 0.8468\n",
      "Epoch 86: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2168 - accuracy: 0.9113 - val_loss: 0.3241 - val_accuracy: 0.8700\n",
      "Epoch 87/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1721 - accuracy: 0.9435\n",
      "Epoch 87: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2152 - accuracy: 0.9130 - val_loss: 0.3345 - val_accuracy: 0.8669\n",
      "Epoch 88/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1894 - accuracy: 0.9032\n",
      "Epoch 88: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2193 - accuracy: 0.9099 - val_loss: 0.3194 - val_accuracy: 0.8746\n",
      "Epoch 89/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1587 - accuracy: 0.9355\n",
      "Epoch 89: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2154 - accuracy: 0.9130 - val_loss: 0.3142 - val_accuracy: 0.8731\n",
      "Epoch 90/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1776 - accuracy: 0.9194\n",
      "Epoch 90: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2138 - accuracy: 0.9130 - val_loss: 0.3168 - val_accuracy: 0.8762\n",
      "Epoch 91/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1921 - accuracy: 0.9113\n",
      "Epoch 91: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 0.9117 - val_loss: 0.3247 - val_accuracy: 0.8685\n",
      "Epoch 92/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2240 - accuracy: 0.9032\n",
      "Epoch 92: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2139 - accuracy: 0.9103 - val_loss: 0.3112 - val_accuracy: 0.8723\n",
      "Epoch 93/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2010 - accuracy: 0.9113\n",
      "Epoch 93: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2159 - accuracy: 0.9121 - val_loss: 0.3221 - val_accuracy: 0.8723\n",
      "Epoch 94/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2428 - accuracy: 0.8871\n",
      "Epoch 94: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2099 - accuracy: 0.9136 - val_loss: 0.3198 - val_accuracy: 0.8731\n",
      "Epoch 95/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1952 - accuracy: 0.9274\n",
      "Epoch 95: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2076 - accuracy: 0.9159 - val_loss: 0.3292 - val_accuracy: 0.8638\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2163 - accuracy: 0.9194\n",
      "Epoch 96: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2353 - accuracy: 0.8986 - val_loss: 0.3103 - val_accuracy: 0.8731\n",
      "Epoch 97/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1989 - accuracy: 0.8790\n",
      "Epoch 97: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2080 - accuracy: 0.9136 - val_loss: 0.3194 - val_accuracy: 0.8677\n",
      "Epoch 98/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2524 - accuracy: 0.8952\n",
      "Epoch 98: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2147 - accuracy: 0.9146 - val_loss: 0.3231 - val_accuracy: 0.8700\n",
      "Epoch 99/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2435 - accuracy: 0.9113\n",
      "Epoch 99: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2162 - accuracy: 0.9069 - val_loss: 0.3260 - val_accuracy: 0.8677\n",
      "Epoch 100/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2059 - accuracy: 0.9113\n",
      "Epoch 100: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2165 - accuracy: 0.9123 - val_loss: 0.3406 - val_accuracy: 0.8669\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1331 - accuracy: 0.9597\n",
      "Epoch 101: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 0.9086 - val_loss: 0.3619 - val_accuracy: 0.8608\n",
      "Epoch 102/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2235 - accuracy: 0.8952\n",
      "Epoch 102: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2238 - accuracy: 0.9071 - val_loss: 0.3213 - val_accuracy: 0.8738\n",
      "Epoch 103/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2305 - accuracy: 0.9194\n",
      "Epoch 103: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2186 - accuracy: 0.9113 - val_loss: 0.3171 - val_accuracy: 0.8769\n",
      "Epoch 104/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1844 - accuracy: 0.9194\n",
      "Epoch 104: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 0.9192 - val_loss: 0.3235 - val_accuracy: 0.8685\n",
      "Epoch 105/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2084 - accuracy: 0.9147\n",
      "Epoch 105: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2066 - accuracy: 0.9165 - val_loss: 0.3231 - val_accuracy: 0.8731\n",
      "Epoch 106/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2421 - accuracy: 0.9113\n",
      "Epoch 106: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2052 - accuracy: 0.9159 - val_loss: 0.3149 - val_accuracy: 0.8746\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1867 - accuracy: 0.9274\n",
      "Epoch 107: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.9003 - val_loss: 0.3831 - val_accuracy: 0.8569\n",
      "Epoch 108/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2499 - accuracy: 0.9032\n",
      "Epoch 108: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.8874 - val_loss: 0.3432 - val_accuracy: 0.8577\n",
      "Epoch 109/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2356 - accuracy: 0.9113\n",
      "Epoch 109: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2195 - accuracy: 0.9103 - val_loss: 0.3338 - val_accuracy: 0.8700\n",
      "Epoch 110/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3155 - accuracy: 0.8790\n",
      "Epoch 110: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2168 - accuracy: 0.9092 - val_loss: 0.3264 - val_accuracy: 0.8700\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2455 - accuracy: 0.9032\n",
      "Epoch 111: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1969 - accuracy: 0.9201 - val_loss: 0.3426 - val_accuracy: 0.8715\n",
      "Epoch 112/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2091 - accuracy: 0.9032\n",
      "Epoch 112: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1997 - accuracy: 0.9167 - val_loss: 0.3230 - val_accuracy: 0.8708\n",
      "Epoch 113/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2006 - accuracy: 0.9185\n",
      "Epoch 113: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1995 - accuracy: 0.9186 - val_loss: 0.3273 - val_accuracy: 0.8669\n",
      "Epoch 114/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1992 - accuracy: 0.9212\n",
      "Epoch 114: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1982 - accuracy: 0.9215 - val_loss: 0.3249 - val_accuracy: 0.8754\n",
      "Epoch 115/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1532 - accuracy: 0.9677\n",
      "Epoch 115: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1956 - accuracy: 0.9196 - val_loss: 0.3642 - val_accuracy: 0.8562\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1512 - accuracy: 0.9435\n",
      "Epoch 116: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1963 - accuracy: 0.9180 - val_loss: 0.3258 - val_accuracy: 0.8654\n",
      "Epoch 117/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1431 - accuracy: 0.9758\n",
      "Epoch 117: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.9194 - val_loss: 0.3571 - val_accuracy: 0.8654\n",
      "Epoch 118/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1763 - accuracy: 0.9274\n",
      "Epoch 118: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2015 - accuracy: 0.9184 - val_loss: 0.3223 - val_accuracy: 0.8708\n",
      "Epoch 119/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1907 - accuracy: 0.9223\n",
      "Epoch 119: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1907 - accuracy: 0.9223 - val_loss: 0.3688 - val_accuracy: 0.8538\n",
      "Epoch 120/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2633 - accuracy: 0.8871\n",
      "Epoch 120: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2000 - accuracy: 0.9184 - val_loss: 0.3376 - val_accuracy: 0.8615\n",
      "Epoch 121/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2268 - accuracy: 0.9113\n",
      "Epoch 121: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1954 - accuracy: 0.9196 - val_loss: 0.3314 - val_accuracy: 0.8723\n",
      "Epoch 122/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1794 - accuracy: 0.9355\n",
      "Epoch 122: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1889 - accuracy: 0.9228 - val_loss: 0.3401 - val_accuracy: 0.8669\n",
      "Epoch 123/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2011 - accuracy: 0.9355\n",
      "Epoch 123: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.9194 - val_loss: 0.3336 - val_accuracy: 0.8700\n",
      "Epoch 124/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1692 - accuracy: 0.9274\n",
      "Epoch 124: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.9223 - val_loss: 0.3439 - val_accuracy: 0.8723\n",
      "Epoch 125/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2469 - accuracy: 0.8790\n",
      "Epoch 125: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1896 - accuracy: 0.9205 - val_loss: 0.3518 - val_accuracy: 0.8708\n",
      "Epoch 126/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3203 - accuracy: 0.8387\n",
      "Epoch 126: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1908 - accuracy: 0.9175 - val_loss: 0.3619 - val_accuracy: 0.8685\n",
      "Epoch 127/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1525 - accuracy: 0.9435\n",
      "Epoch 127: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2048 - accuracy: 0.9173 - val_loss: 0.3597 - val_accuracy: 0.8631\n",
      "Epoch 128/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2718 - accuracy: 0.8790\n",
      "Epoch 128: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1869 - accuracy: 0.9223 - val_loss: 0.3857 - val_accuracy: 0.8669\n",
      "Epoch 129/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1434 - accuracy: 0.9274\n",
      "Epoch 129: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.9251 - val_loss: 0.3382 - val_accuracy: 0.8708\n",
      "Epoch 130/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1514 - accuracy: 0.9516\n",
      "Epoch 130: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.9196 - val_loss: 0.3566 - val_accuracy: 0.8723\n",
      "Epoch 131/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1865 - accuracy: 0.9244\n",
      "Epoch 131: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1848 - accuracy: 0.9248 - val_loss: 0.3632 - val_accuracy: 0.8646\n",
      "Epoch 132/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1955 - accuracy: 0.9194\n",
      "Epoch 132: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1887 - accuracy: 0.9226 - val_loss: 0.3889 - val_accuracy: 0.8562\n",
      "Epoch 133/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2664 - accuracy: 0.8710\n",
      "Epoch 133: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1859 - accuracy: 0.9217 - val_loss: 0.3448 - val_accuracy: 0.8700\n",
      "Epoch 134/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1667 - accuracy: 0.9435\n",
      "Epoch 134: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1739 - accuracy: 0.9307 - val_loss: 0.3536 - val_accuracy: 0.8715\n",
      "Epoch 135/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1703 - accuracy: 0.9435\n",
      "Epoch 135: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1733 - accuracy: 0.9282 - val_loss: 0.3525 - val_accuracy: 0.8738\n",
      "Epoch 136/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1977 - accuracy: 0.9194\n",
      "Epoch 136: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1907 - accuracy: 0.9250 - val_loss: 0.3567 - val_accuracy: 0.8692\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3103 - accuracy: 0.8790\n",
      "Epoch 137: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.9278 - val_loss: 0.3897 - val_accuracy: 0.8669\n",
      "Epoch 138/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1587 - accuracy: 0.9435\n",
      "Epoch 138: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1919 - accuracy: 0.9225 - val_loss: 0.3452 - val_accuracy: 0.8731\n",
      "Epoch 139/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1963 - accuracy: 0.9113\n",
      "Epoch 139: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1953 - accuracy: 0.9186 - val_loss: 0.3542 - val_accuracy: 0.8685\n",
      "Epoch 140/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1499 - accuracy: 0.9516\n",
      "Epoch 140: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1800 - accuracy: 0.9250 - val_loss: 0.3856 - val_accuracy: 0.8654\n",
      "Epoch 141/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2003 - accuracy: 0.9355\n",
      "Epoch 141: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1798 - accuracy: 0.9296 - val_loss: 0.3843 - val_accuracy: 0.8677\n",
      "Epoch 142/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1804 - accuracy: 0.9274\n",
      "Epoch 142: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1785 - accuracy: 0.9259 - val_loss: 0.3744 - val_accuracy: 0.8715\n",
      "Epoch 143/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1946 - accuracy: 0.9113\n",
      "Epoch 143: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1755 - accuracy: 0.9296 - val_loss: 0.3656 - val_accuracy: 0.8654\n",
      "Epoch 144/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1486 - accuracy: 0.9274\n",
      "Epoch 144: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1732 - accuracy: 0.9303 - val_loss: 0.3848 - val_accuracy: 0.8708\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2135 - accuracy: 0.9355\n",
      "Epoch 145: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1733 - accuracy: 0.9286 - val_loss: 0.3715 - val_accuracy: 0.8654\n",
      "Epoch 146/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1433 - accuracy: 0.9516\n",
      "Epoch 146: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.9261 - val_loss: 0.3908 - val_accuracy: 0.8623\n",
      "Epoch 147/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2521 - accuracy: 0.8871\n",
      "Epoch 147: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.9286 - val_loss: 0.3831 - val_accuracy: 0.8746\n",
      "Epoch 148/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1573 - accuracy: 0.9516\n",
      "Epoch 148: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1782 - accuracy: 0.9267 - val_loss: 0.3798 - val_accuracy: 0.8638\n",
      "Epoch 149/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1754 - accuracy: 0.9113\n",
      "Epoch 149: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1714 - accuracy: 0.9286 - val_loss: 0.3737 - val_accuracy: 0.8677\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1965 - accuracy: 0.9032\n",
      "Epoch 150: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 0.9317 - val_loss: 0.4296 - val_accuracy: 0.8554\n",
      "Epoch 151/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1533 - accuracy: 0.9597\n",
      "Epoch 151: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1685 - accuracy: 0.9298 - val_loss: 0.4062 - val_accuracy: 0.8600\n",
      "Epoch 152/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1803 - accuracy: 0.9274\n",
      "Epoch 152: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1698 - accuracy: 0.9278 - val_loss: 0.3925 - val_accuracy: 0.8592\n",
      "Epoch 153/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1603 - accuracy: 0.9355\n",
      "Epoch 153: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.9198 - val_loss: 0.3838 - val_accuracy: 0.8677\n",
      "Epoch 154/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1287 - accuracy: 0.9355\n",
      "Epoch 154: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1640 - accuracy: 0.9307 - val_loss: 0.4088 - val_accuracy: 0.8738\n",
      "Epoch 155/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1111 - accuracy: 0.9597\n",
      "Epoch 155: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1697 - accuracy: 0.9321 - val_loss: 0.4201 - val_accuracy: 0.8638\n",
      "Epoch 156/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1277 - accuracy: 0.9435\n",
      "Epoch 156: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1688 - accuracy: 0.9292 - val_loss: 0.3966 - val_accuracy: 0.8685\n",
      "Epoch 157/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1876 - accuracy: 0.9032\n",
      "Epoch 157: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1663 - accuracy: 0.9332 - val_loss: 0.4329 - val_accuracy: 0.8677\n",
      "Epoch 158/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2064 - accuracy: 0.8952\n",
      "Epoch 158: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1604 - accuracy: 0.9325 - val_loss: 0.3923 - val_accuracy: 0.8615\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 22s - loss: 0.9859 - accuracy: 0.4919\n",
      "Epoch 1: val_accuracy improved from -inf to 0.68077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.6738 - accuracy: 0.6011 - val_loss: 0.5691 - val_accuracy: 0.6808\n",
      "Epoch 2/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.5109 - accuracy: 0.7613\n",
      "Epoch 2: val_accuracy improved from 0.68077 to 0.76769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7631 - val_loss: 0.4713 - val_accuracy: 0.7677\n",
      "Epoch 3/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4570 - accuracy: 0.7661\n",
      "Epoch 3: val_accuracy improved from 0.76769 to 0.81615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8043 - val_loss: 0.4065 - val_accuracy: 0.8162\n",
      "Epoch 4/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4073 - accuracy: 0.7984\n",
      "Epoch 4: val_accuracy improved from 0.81615 to 0.84154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4021 - accuracy: 0.8172 - val_loss: 0.3728 - val_accuracy: 0.8415\n",
      "Epoch 5/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4933 - accuracy: 0.8145\n",
      "Epoch 5: val_accuracy improved from 0.84154 to 0.84385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.8297 - val_loss: 0.3614 - val_accuracy: 0.8438\n",
      "Epoch 6/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2774 - accuracy: 0.8871\n",
      "Epoch 6: val_accuracy improved from 0.84385 to 0.85462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8482 - val_loss: 0.3533 - val_accuracy: 0.8546\n",
      "Epoch 7/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3227 - accuracy: 0.8548\n",
      "Epoch 7: val_accuracy did not improve from 0.85462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3459 - accuracy: 0.8551 - val_loss: 0.3565 - val_accuracy: 0.8477\n",
      "Epoch 8/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3276 - accuracy: 0.8387\n",
      "Epoch 8: val_accuracy did not improve from 0.85462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8545 - val_loss: 0.3968 - val_accuracy: 0.8246\n",
      "Epoch 9/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3320 - accuracy: 0.8306\n",
      "Epoch 9: val_accuracy did not improve from 0.85462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8480 - val_loss: 0.3517 - val_accuracy: 0.8531\n",
      "Epoch 10/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3616 - accuracy: 0.8468\n",
      "Epoch 10: val_accuracy improved from 0.85462 to 0.86000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8593 - val_loss: 0.3434 - val_accuracy: 0.8600\n",
      "Epoch 11/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3194 - accuracy: 0.8790\n",
      "Epoch 11: val_accuracy improved from 0.86000 to 0.86385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8638 - val_loss: 0.3394 - val_accuracy: 0.8638\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3542 - accuracy: 0.8306\n",
      "Epoch 12: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8603 - val_loss: 0.3372 - val_accuracy: 0.8546\n",
      "Epoch 13/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3056 - accuracy: 0.8468\n",
      "Epoch 13: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8603 - val_loss: 0.4126 - val_accuracy: 0.8223\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2956 - accuracy: 0.8548\n",
      "Epoch 14: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8665 - val_loss: 0.3416 - val_accuracy: 0.8431\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3135 - accuracy: 0.8548\n",
      "Epoch 15: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8709 - val_loss: 0.3736 - val_accuracy: 0.8292\n",
      "Epoch 16/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2858 - accuracy: 0.8952\n",
      "Epoch 16: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8688 - val_loss: 0.3384 - val_accuracy: 0.8638\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2666 - accuracy: 0.8790\n",
      "Epoch 17: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8715 - val_loss: 0.3475 - val_accuracy: 0.8623\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2856 - accuracy: 0.8468\n",
      "Epoch 18: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8670 - val_loss: 0.3316 - val_accuracy: 0.8592\n",
      "Epoch 19/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2325 - accuracy: 0.8952\n",
      "Epoch 19: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8668 - val_loss: 0.3442 - val_accuracy: 0.8631\n",
      "Epoch 20/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2795 - accuracy: 0.8710\n",
      "Epoch 20: val_accuracy improved from 0.86385 to 0.86769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8670 - val_loss: 0.3329 - val_accuracy: 0.8677\n",
      "Epoch 21/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3532 - accuracy: 0.8387\n",
      "Epoch 21: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.8732 - val_loss: 0.3329 - val_accuracy: 0.8585\n",
      "Epoch 22/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2298 - accuracy: 0.9274\n",
      "Epoch 22: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2991 - accuracy: 0.8759 - val_loss: 0.3388 - val_accuracy: 0.8654\n",
      "Epoch 23/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4147 - accuracy: 0.8065\n",
      "Epoch 23: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3027 - accuracy: 0.8742 - val_loss: 0.3304 - val_accuracy: 0.8592\n",
      "Epoch 24/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2466 - accuracy: 0.8952\n",
      "Epoch 24: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8718 - val_loss: 0.3729 - val_accuracy: 0.8254\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2037 - accuracy: 0.9274\n",
      "Epoch 25: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3016 - accuracy: 0.8734 - val_loss: 0.3286 - val_accuracy: 0.8662\n",
      "Epoch 26/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2955 - accuracy: 0.8871\n",
      "Epoch 26: val_accuracy improved from 0.86769 to 0.86923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2965 - accuracy: 0.8790 - val_loss: 0.3343 - val_accuracy: 0.8692\n",
      "Epoch 27/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2971 - accuracy: 0.8871\n",
      "Epoch 27: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2877 - accuracy: 0.8834 - val_loss: 0.3432 - val_accuracy: 0.8477\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3970 - accuracy: 0.8145\n",
      "Epoch 28: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2909 - accuracy: 0.8782 - val_loss: 0.3239 - val_accuracy: 0.8646\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3113 - accuracy: 0.8710\n",
      "Epoch 29: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2980 - accuracy: 0.8767 - val_loss: 0.3200 - val_accuracy: 0.8638\n",
      "Epoch 30/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2800 - accuracy: 0.8952\n",
      "Epoch 30: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2890 - accuracy: 0.8794 - val_loss: 0.3212 - val_accuracy: 0.8685\n",
      "Epoch 31/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2457 - accuracy: 0.9032\n",
      "Epoch 31: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2921 - accuracy: 0.8795 - val_loss: 0.3574 - val_accuracy: 0.8431\n",
      "Epoch 32/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3297 - accuracy: 0.8629\n",
      "Epoch 32: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2841 - accuracy: 0.8813 - val_loss: 0.3244 - val_accuracy: 0.8669\n",
      "Epoch 33/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3201 - accuracy: 0.8387\n",
      "Epoch 33: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2944 - accuracy: 0.8757 - val_loss: 0.3360 - val_accuracy: 0.8638\n",
      "Epoch 34/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2762 - accuracy: 0.8629\n",
      "Epoch 34: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2838 - accuracy: 0.8782 - val_loss: 0.3124 - val_accuracy: 0.8669\n",
      "Epoch 35/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2522 - accuracy: 0.9194\n",
      "Epoch 35: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2791 - accuracy: 0.8819 - val_loss: 0.3099 - val_accuracy: 0.8669\n",
      "Epoch 36/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2334 - accuracy: 0.9194\n",
      "Epoch 36: val_accuracy improved from 0.86923 to 0.87000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2730 - accuracy: 0.8871 - val_loss: 0.3143 - val_accuracy: 0.8700\n",
      "Epoch 37/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2274 - accuracy: 0.9032\n",
      "Epoch 37: val_accuracy improved from 0.87000 to 0.87462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2684 - accuracy: 0.8890 - val_loss: 0.3113 - val_accuracy: 0.8746\n",
      "Epoch 38/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3185 - accuracy: 0.8629\n",
      "Epoch 38: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2740 - accuracy: 0.8822 - val_loss: 0.3316 - val_accuracy: 0.8715\n",
      "Epoch 39/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3565 - accuracy: 0.8629\n",
      "Epoch 39: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2694 - accuracy: 0.8896 - val_loss: 0.3113 - val_accuracy: 0.8615\n",
      "Epoch 40/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2226 - accuracy: 0.9032\n",
      "Epoch 40: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2671 - accuracy: 0.8915 - val_loss: 0.3227 - val_accuracy: 0.8746\n",
      "Epoch 41/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3858 - accuracy: 0.8548\n",
      "Epoch 41: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2627 - accuracy: 0.8946 - val_loss: 0.3195 - val_accuracy: 0.8654\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2976 - accuracy: 0.8548\n",
      "Epoch 42: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2629 - accuracy: 0.8932 - val_loss: 0.3122 - val_accuracy: 0.8677\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2586 - accuracy: 0.8965\n",
      "Epoch 43: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2586 - accuracy: 0.8965 - val_loss: 0.3135 - val_accuracy: 0.8700\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2699 - accuracy: 0.9032\n",
      "Epoch 44: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.8988 - val_loss: 0.3329 - val_accuracy: 0.8662\n",
      "Epoch 45/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2614 - accuracy: 0.8871\n",
      "Epoch 45: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2648 - accuracy: 0.8924 - val_loss: 0.3071 - val_accuracy: 0.8654\n",
      "Epoch 46/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2128 - accuracy: 0.9032\n",
      "Epoch 46: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.8940 - val_loss: 0.3192 - val_accuracy: 0.8746\n",
      "Epoch 47/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2914 - accuracy: 0.8710\n",
      "Epoch 47: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2695 - accuracy: 0.8871 - val_loss: 0.3315 - val_accuracy: 0.8700\n",
      "Epoch 48/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2877 - accuracy: 0.8871\n",
      "Epoch 48: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2532 - accuracy: 0.9007 - val_loss: 0.3106 - val_accuracy: 0.8715\n",
      "Epoch 49/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1769 - accuracy: 0.9516\n",
      "Epoch 49: val_accuracy improved from 0.87462 to 0.87769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2616 - accuracy: 0.8926 - val_loss: 0.3042 - val_accuracy: 0.8777\n",
      "Epoch 50/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2593 - accuracy: 0.8710\n",
      "Epoch 50: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2728 - accuracy: 0.8853 - val_loss: 0.3357 - val_accuracy: 0.8677\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3258 - accuracy: 0.8790\n",
      "Epoch 51: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.8990 - val_loss: 0.3061 - val_accuracy: 0.8738\n",
      "Epoch 52/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2295 - accuracy: 0.9113\n",
      "Epoch 52: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2573 - accuracy: 0.8957 - val_loss: 0.3098 - val_accuracy: 0.8769\n",
      "Epoch 53/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1951 - accuracy: 0.9032\n",
      "Epoch 53: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2584 - accuracy: 0.8913 - val_loss: 0.3043 - val_accuracy: 0.8769\n",
      "Epoch 54/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2156 - accuracy: 0.9194\n",
      "Epoch 54: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.9023 - val_loss: 0.3186 - val_accuracy: 0.8700\n",
      "Epoch 55/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3160 - accuracy: 0.8790\n",
      "Epoch 55: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2475 - accuracy: 0.8984 - val_loss: 0.3653 - val_accuracy: 0.8408\n",
      "Epoch 56/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3365 - accuracy: 0.8710\n",
      "Epoch 56: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2562 - accuracy: 0.8946 - val_loss: 0.3303 - val_accuracy: 0.8585\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2149 - accuracy: 0.9274\n",
      "Epoch 57: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2485 - accuracy: 0.8986 - val_loss: 0.3228 - val_accuracy: 0.8669\n",
      "Epoch 58/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2557 - accuracy: 0.8871\n",
      "Epoch 58: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.9013 - val_loss: 0.3160 - val_accuracy: 0.8700\n",
      "Epoch 59/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1997 - accuracy: 0.9435\n",
      "Epoch 59: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.9019 - val_loss: 0.3044 - val_accuracy: 0.8738\n",
      "Epoch 60/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3404 - accuracy: 0.8226\n",
      "Epoch 60: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2426 - accuracy: 0.9036 - val_loss: 0.3240 - val_accuracy: 0.8638\n",
      "Epoch 61/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2818 - accuracy: 0.9194\n",
      "Epoch 61: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2435 - accuracy: 0.9053 - val_loss: 0.3220 - val_accuracy: 0.8700\n",
      "Epoch 62/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2298 - accuracy: 0.9274\n",
      "Epoch 62: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.9030 - val_loss: 0.3204 - val_accuracy: 0.8731\n",
      "Epoch 63/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2488 - accuracy: 0.9113\n",
      "Epoch 63: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2481 - accuracy: 0.8996 - val_loss: 0.3235 - val_accuracy: 0.8746\n",
      "Epoch 64/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2378 - accuracy: 0.9355\n",
      "Epoch 64: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2478 - accuracy: 0.9005 - val_loss: 0.3260 - val_accuracy: 0.8723\n",
      "Epoch 65/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2443 - accuracy: 0.9004\n",
      "Epoch 65: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.9003 - val_loss: 0.3068 - val_accuracy: 0.8708\n",
      "Epoch 66/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1730 - accuracy: 0.9435\n",
      "Epoch 66: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8996 - val_loss: 0.3112 - val_accuracy: 0.8738\n",
      "Epoch 67/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2865 - accuracy: 0.8710\n",
      "Epoch 67: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2365 - accuracy: 0.9055 - val_loss: 0.3115 - val_accuracy: 0.8738\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2198 - accuracy: 0.9274\n",
      "Epoch 68: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.9003 - val_loss: 0.3220 - val_accuracy: 0.8731\n",
      "Epoch 69/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3088 - accuracy: 0.8468\n",
      "Epoch 69: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2415 - accuracy: 0.9005 - val_loss: 0.3363 - val_accuracy: 0.8669\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2682 - accuracy: 0.8790\n",
      "Epoch 70: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2408 - accuracy: 0.9009 - val_loss: 0.3128 - val_accuracy: 0.8723\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2315 - accuracy: 0.8952\n",
      "Epoch 71: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.8990 - val_loss: 0.3166 - val_accuracy: 0.8700\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2148 - accuracy: 0.9274\n",
      "Epoch 72: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2482 - accuracy: 0.8953 - val_loss: 0.3069 - val_accuracy: 0.8746\n",
      "Epoch 73/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1864 - accuracy: 0.9435\n",
      "Epoch 73: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2307 - accuracy: 0.9073 - val_loss: 0.3276 - val_accuracy: 0.8723\n",
      "Epoch 74/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2039 - accuracy: 0.9355\n",
      "Epoch 74: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2407 - accuracy: 0.9015 - val_loss: 0.3081 - val_accuracy: 0.8723\n",
      "Epoch 75/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1921 - accuracy: 0.9355\n",
      "Epoch 75: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 0.9055 - val_loss: 0.3382 - val_accuracy: 0.8685\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2753 - accuracy: 0.8629\n",
      "Epoch 76: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2306 - accuracy: 0.9073 - val_loss: 0.3190 - val_accuracy: 0.8677\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2571 - accuracy: 0.8952\n",
      "Epoch 77: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2287 - accuracy: 0.9078 - val_loss: 0.3119 - val_accuracy: 0.8677\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3245 - accuracy: 0.8387\n",
      "Epoch 78: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2301 - accuracy: 0.9082 - val_loss: 0.3202 - val_accuracy: 0.8708\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2881 - accuracy: 0.8871\n",
      "Epoch 79: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2310 - accuracy: 0.9063 - val_loss: 0.3154 - val_accuracy: 0.8715\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2566 - accuracy: 0.8952\n",
      "Epoch 80: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2286 - accuracy: 0.9094 - val_loss: 0.3144 - val_accuracy: 0.8700\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3009 - accuracy: 0.8952\n",
      "Epoch 81: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2285 - accuracy: 0.9065 - val_loss: 0.3126 - val_accuracy: 0.8731\n",
      "Epoch 82/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1713 - accuracy: 0.9274\n",
      "Epoch 82: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2253 - accuracy: 0.9123 - val_loss: 0.3266 - val_accuracy: 0.8662\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1799 - accuracy: 0.9516\n",
      "Epoch 83: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2358 - accuracy: 0.9049 - val_loss: 0.3414 - val_accuracy: 0.8615\n",
      "Epoch 84/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2319 - accuracy: 0.8952\n",
      "Epoch 84: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.9111 - val_loss: 0.3221 - val_accuracy: 0.8692\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1801 - accuracy: 0.9113\n",
      "Epoch 85: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2231 - accuracy: 0.9096 - val_loss: 0.3188 - val_accuracy: 0.8731\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1806 - accuracy: 0.9355\n",
      "Epoch 86: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.9155 - val_loss: 0.3285 - val_accuracy: 0.8654\n",
      "Epoch 87/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1926 - accuracy: 0.8952\n",
      "Epoch 87: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2269 - accuracy: 0.9069 - val_loss: 0.3161 - val_accuracy: 0.8708\n",
      "Epoch 88/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1663 - accuracy: 0.9355\n",
      "Epoch 88: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2183 - accuracy: 0.9130 - val_loss: 0.3231 - val_accuracy: 0.8715\n",
      "Epoch 89/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1959 - accuracy: 0.9032\n",
      "Epoch 89: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2178 - accuracy: 0.9123 - val_loss: 0.3156 - val_accuracy: 0.8685\n",
      "Epoch 90/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1652 - accuracy: 0.9355\n",
      "Epoch 90: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2253 - accuracy: 0.9111 - val_loss: 0.3165 - val_accuracy: 0.8731\n",
      "Epoch 91/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2165 - accuracy: 0.9138\n",
      "Epoch 91: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2165 - accuracy: 0.9138 - val_loss: 0.3231 - val_accuracy: 0.8708\n",
      "Epoch 92/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1696 - accuracy: 0.9435\n",
      "Epoch 92: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2187 - accuracy: 0.9109 - val_loss: 0.3224 - val_accuracy: 0.8646\n",
      "Epoch 93/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2239 - accuracy: 0.9032\n",
      "Epoch 93: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.9153 - val_loss: 0.3290 - val_accuracy: 0.8692\n",
      "Epoch 94/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1870 - accuracy: 0.9355\n",
      "Epoch 94: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2114 - accuracy: 0.9180 - val_loss: 0.3328 - val_accuracy: 0.8638\n",
      "Epoch 95/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2002 - accuracy: 0.9355\n",
      "Epoch 95: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2088 - accuracy: 0.9198 - val_loss: 0.3200 - val_accuracy: 0.8700\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3101 - accuracy: 0.8952\n",
      "Epoch 96: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2106 - accuracy: 0.9169 - val_loss: 0.3219 - val_accuracy: 0.8692\n",
      "Epoch 97/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2569 - accuracy: 0.9274\n",
      "Epoch 97: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2188 - accuracy: 0.9115 - val_loss: 0.3637 - val_accuracy: 0.8492\n",
      "Epoch 98/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2348 - accuracy: 0.8871\n",
      "Epoch 98: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2167 - accuracy: 0.9128 - val_loss: 0.3469 - val_accuracy: 0.8638\n",
      "Epoch 99/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2674 - accuracy: 0.8952\n",
      "Epoch 99: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.9207 - val_loss: 0.3225 - val_accuracy: 0.8677\n",
      "Epoch 100/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2192 - accuracy: 0.9113\n",
      "Epoch 100: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2114 - accuracy: 0.9159 - val_loss: 0.3208 - val_accuracy: 0.8692\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2346 - accuracy: 0.8952\n",
      "Epoch 101: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.9200 - val_loss: 0.3222 - val_accuracy: 0.8700\n",
      "Epoch 102/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2380 - accuracy: 0.8952\n",
      "Epoch 102: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.9161 - val_loss: 0.3168 - val_accuracy: 0.8646\n",
      "Epoch 103/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2073 - accuracy: 0.9194\n",
      "Epoch 103: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.9119 - val_loss: 0.3259 - val_accuracy: 0.8638\n",
      "Epoch 104/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1683 - accuracy: 0.9355\n",
      "Epoch 104: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2130 - accuracy: 0.9155 - val_loss: 0.3261 - val_accuracy: 0.8700\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1139 - accuracy: 0.9516\n",
      "Epoch 105: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2201 - accuracy: 0.9090 - val_loss: 0.3208 - val_accuracy: 0.8646\n",
      "Epoch 106/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2404 - accuracy: 0.9032\n",
      "Epoch 106: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2059 - accuracy: 0.9190 - val_loss: 0.3226 - val_accuracy: 0.8715\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3109 - accuracy: 0.8629\n",
      "Epoch 107: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1992 - accuracy: 0.9211 - val_loss: 0.3405 - val_accuracy: 0.8700\n",
      "Epoch 108/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1996 - accuracy: 0.9274\n",
      "Epoch 108: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2095 - accuracy: 0.9163 - val_loss: 0.3442 - val_accuracy: 0.8623\n",
      "Epoch 109/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1981 - accuracy: 0.9194\n",
      "Epoch 109: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2179 - accuracy: 0.9126 - val_loss: 0.3340 - val_accuracy: 0.8669\n",
      "Epoch 110/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2148 - accuracy: 0.9194\n",
      "Epoch 110: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2173 - accuracy: 0.9084 - val_loss: 0.3778 - val_accuracy: 0.8546\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2805 - accuracy: 0.8710\n",
      "Epoch 111: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2166 - accuracy: 0.9173 - val_loss: 0.3247 - val_accuracy: 0.8654\n",
      "Epoch 112/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1902 - accuracy: 0.9516\n",
      "Epoch 112: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2052 - accuracy: 0.9184 - val_loss: 0.3394 - val_accuracy: 0.8700\n",
      "Epoch 113/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1813 - accuracy: 0.9355\n",
      "Epoch 113: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9225 - val_loss: 0.3324 - val_accuracy: 0.8708\n",
      "Epoch 114/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1858 - accuracy: 0.9355\n",
      "Epoch 114: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1996 - accuracy: 0.9209 - val_loss: 0.3246 - val_accuracy: 0.8623\n",
      "Epoch 115/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1620 - accuracy: 0.9355\n",
      "Epoch 115: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2108 - accuracy: 0.9153 - val_loss: 0.3358 - val_accuracy: 0.8723\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1995 - accuracy: 0.9194\n",
      "Epoch 116: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2022 - accuracy: 0.9213 - val_loss: 0.3317 - val_accuracy: 0.8677\n",
      "Epoch 117/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1478 - accuracy: 0.9435\n",
      "Epoch 117: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1943 - accuracy: 0.9244 - val_loss: 0.3836 - val_accuracy: 0.8454\n",
      "Epoch 118/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2963 - accuracy: 0.8629\n",
      "Epoch 118: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2186 - accuracy: 0.9103 - val_loss: 0.3302 - val_accuracy: 0.8677\n",
      "Epoch 119/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2038 - accuracy: 0.9274\n",
      "Epoch 119: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1983 - accuracy: 0.9190 - val_loss: 0.3266 - val_accuracy: 0.8692\n",
      "Epoch 120/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1719 - accuracy: 0.9355\n",
      "Epoch 120: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2011 - accuracy: 0.9173 - val_loss: 0.3342 - val_accuracy: 0.8700\n",
      "Epoch 121/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2404 - accuracy: 0.8790\n",
      "Epoch 121: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1900 - accuracy: 0.9248 - val_loss: 0.3353 - val_accuracy: 0.8677\n",
      "Epoch 122/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2573 - accuracy: 0.8871\n",
      "Epoch 122: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1937 - accuracy: 0.9244 - val_loss: 0.3397 - val_accuracy: 0.8677\n",
      "Epoch 123/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1884 - accuracy: 0.9435\n",
      "Epoch 123: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1917 - accuracy: 0.9211 - val_loss: 0.3351 - val_accuracy: 0.8700\n",
      "Epoch 124/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1578 - accuracy: 0.9435\n",
      "Epoch 124: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1911 - accuracy: 0.9232 - val_loss: 0.3528 - val_accuracy: 0.8615\n",
      "Epoch 125/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2793 - accuracy: 0.8952\n",
      "Epoch 125: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1943 - accuracy: 0.9261 - val_loss: 0.3401 - val_accuracy: 0.8638\n",
      "Epoch 126/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1646 - accuracy: 0.9516\n",
      "Epoch 126: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1915 - accuracy: 0.9263 - val_loss: 0.3347 - val_accuracy: 0.8638\n",
      "Epoch 127/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1461 - accuracy: 0.9516\n",
      "Epoch 127: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1891 - accuracy: 0.9253 - val_loss: 0.3646 - val_accuracy: 0.8631\n",
      "Epoch 128/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2092 - accuracy: 0.9355\n",
      "Epoch 128: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1899 - accuracy: 0.9275 - val_loss: 0.3401 - val_accuracy: 0.8638\n",
      "Epoch 129/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1980 - accuracy: 0.9194\n",
      "Epoch 129: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1871 - accuracy: 0.9263 - val_loss: 0.3334 - val_accuracy: 0.8638\n",
      "Epoch 130/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2341 - accuracy: 0.8871\n",
      "Epoch 130: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1831 - accuracy: 0.9259 - val_loss: 0.3534 - val_accuracy: 0.8554\n",
      "Epoch 131/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1849 - accuracy: 0.9435\n",
      "Epoch 131: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1891 - accuracy: 0.9263 - val_loss: 0.3398 - val_accuracy: 0.8608\n",
      "Epoch 132/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1463 - accuracy: 0.9597\n",
      "Epoch 132: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1955 - accuracy: 0.9236 - val_loss: 0.3436 - val_accuracy: 0.8646\n",
      "Epoch 133/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1417 - accuracy: 0.9516\n",
      "Epoch 133: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1899 - accuracy: 0.9223 - val_loss: 0.3494 - val_accuracy: 0.8592\n",
      "Epoch 134/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2335 - accuracy: 0.9032\n",
      "Epoch 134: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.9263 - val_loss: 0.3598 - val_accuracy: 0.8638\n",
      "Epoch 135/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1856 - accuracy: 0.8952\n",
      "Epoch 135: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1840 - accuracy: 0.9263 - val_loss: 0.3646 - val_accuracy: 0.8592\n",
      "Epoch 136/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1261 - accuracy: 0.9516\n",
      "Epoch 136: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.9267 - val_loss: 0.3419 - val_accuracy: 0.8600\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2004 - accuracy: 0.9194\n",
      "Epoch 137: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1874 - accuracy: 0.9248 - val_loss: 0.3511 - val_accuracy: 0.8577\n",
      "Epoch 138/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1344 - accuracy: 0.9597\n",
      "Epoch 138: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1836 - accuracy: 0.9242 - val_loss: 0.3506 - val_accuracy: 0.8615\n",
      "Epoch 139/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2215 - accuracy: 0.8871\n",
      "Epoch 139: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.9284 - val_loss: 0.3467 - val_accuracy: 0.8631\n",
      "Epoch 140/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1326 - accuracy: 0.9435\n",
      "Epoch 140: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1803 - accuracy: 0.9278 - val_loss: 0.3454 - val_accuracy: 0.8638\n",
      "Epoch 141/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1445 - accuracy: 0.9435\n",
      "Epoch 141: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.9307 - val_loss: 0.3491 - val_accuracy: 0.8646\n",
      "Epoch 142/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1593 - accuracy: 0.9516\n",
      "Epoch 142: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1786 - accuracy: 0.9253 - val_loss: 0.3615 - val_accuracy: 0.8638\n",
      "Epoch 143/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2061 - accuracy: 0.9274\n",
      "Epoch 143: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1766 - accuracy: 0.9317 - val_loss: 0.3628 - val_accuracy: 0.8662\n",
      "Epoch 144/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.0927 - accuracy: 0.9677\n",
      "Epoch 144: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1719 - accuracy: 0.9328 - val_loss: 0.3650 - val_accuracy: 0.8608\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2011 - accuracy: 0.9032\n",
      "Epoch 145: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1759 - accuracy: 0.9327 - val_loss: 0.3636 - val_accuracy: 0.8638\n",
      "Epoch 146/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1165 - accuracy: 0.9355\n",
      "Epoch 146: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1806 - accuracy: 0.9271 - val_loss: 0.3607 - val_accuracy: 0.8615\n",
      "Epoch 147/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1395 - accuracy: 0.9597\n",
      "Epoch 147: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1765 - accuracy: 0.9317 - val_loss: 0.3487 - val_accuracy: 0.8577\n",
      "Epoch 148/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2856 - accuracy: 0.8952\n",
      "Epoch 148: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9259 - val_loss: 0.3551 - val_accuracy: 0.8577\n",
      "Epoch 149/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1545 - accuracy: 0.9435\n",
      "Epoch 149: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1770 - accuracy: 0.9292 - val_loss: 0.3561 - val_accuracy: 0.8646\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 22s - loss: 1.6264 - accuracy: 0.4032\n",
      "Epoch 1: val_accuracy improved from -inf to 0.76462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.6804 - accuracy: 0.6479 - val_loss: 0.5359 - val_accuracy: 0.7646\n",
      "Epoch 2/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.5574 - accuracy: 0.6855\n",
      "Epoch 2: val_accuracy improved from 0.76462 to 0.81692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7985 - val_loss: 0.4432 - val_accuracy: 0.8169\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.4144 - accuracy: 0.8216\n",
      "Epoch 3: val_accuracy improved from 0.81692 to 0.82308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.8216 - val_loss: 0.3998 - val_accuracy: 0.8231\n",
      "Epoch 4/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3716 - accuracy: 0.8710\n",
      "Epoch 4: val_accuracy improved from 0.82308 to 0.83615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8453 - val_loss: 0.3750 - val_accuracy: 0.8362\n",
      "Epoch 5/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4665 - accuracy: 0.7984\n",
      "Epoch 5: val_accuracy improved from 0.83615 to 0.85154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8545 - val_loss: 0.3542 - val_accuracy: 0.8515\n",
      "Epoch 6/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2743 - accuracy: 0.9032\n",
      "Epoch 6: val_accuracy improved from 0.85154 to 0.85462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3464 - accuracy: 0.8566 - val_loss: 0.3477 - val_accuracy: 0.8546\n",
      "Epoch 7/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2707 - accuracy: 0.9113\n",
      "Epoch 7: val_accuracy did not improve from 0.85462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3489 - accuracy: 0.8497 - val_loss: 0.3792 - val_accuracy: 0.8323\n",
      "Epoch 8/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2832 - accuracy: 0.8710\n",
      "Epoch 8: val_accuracy did not improve from 0.85462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8599 - val_loss: 0.3397 - val_accuracy: 0.8546\n",
      "Epoch 9/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3023 - accuracy: 0.8952\n",
      "Epoch 9: val_accuracy did not improve from 0.85462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3457 - accuracy: 0.8522 - val_loss: 0.3518 - val_accuracy: 0.8515\n",
      "Epoch 10/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4138 - accuracy: 0.7742\n",
      "Epoch 10: val_accuracy did not improve from 0.85462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8603 - val_loss: 0.3739 - val_accuracy: 0.8415\n",
      "Epoch 11/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3596 - accuracy: 0.8351\n",
      "Epoch 11: val_accuracy did not improve from 0.85462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8370 - val_loss: 0.3550 - val_accuracy: 0.8454\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3612 - accuracy: 0.8145\n",
      "Epoch 12: val_accuracy improved from 0.85462 to 0.86308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3186 - accuracy: 0.8680 - val_loss: 0.3311 - val_accuracy: 0.8631\n",
      "Epoch 13/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3296 - accuracy: 0.8468\n",
      "Epoch 13: val_accuracy improved from 0.86308 to 0.86462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8620 - val_loss: 0.3386 - val_accuracy: 0.8646\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3674 - accuracy: 0.8226\n",
      "Epoch 14: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8659 - val_loss: 0.3596 - val_accuracy: 0.8431\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3190 - accuracy: 0.8306\n",
      "Epoch 15: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8718 - val_loss: 0.3238 - val_accuracy: 0.8646\n",
      "Epoch 16/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2926 - accuracy: 0.8871\n",
      "Epoch 16: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3018 - accuracy: 0.8749 - val_loss: 0.3241 - val_accuracy: 0.8631\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3094 - accuracy: 0.8548\n",
      "Epoch 17: val_accuracy improved from 0.86462 to 0.87000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8744 - val_loss: 0.3237 - val_accuracy: 0.8700\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2450 - accuracy: 0.9113\n",
      "Epoch 18: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8628 - val_loss: 0.3372 - val_accuracy: 0.8515\n",
      "Epoch 19/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2655 - accuracy: 0.8871\n",
      "Epoch 19: val_accuracy improved from 0.87000 to 0.87615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8718 - val_loss: 0.3219 - val_accuracy: 0.8762\n",
      "Epoch 20/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3800 - accuracy: 0.8548\n",
      "Epoch 20: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2941 - accuracy: 0.8782 - val_loss: 0.3210 - val_accuracy: 0.8600\n",
      "Epoch 21/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2747 - accuracy: 0.8790\n",
      "Epoch 21: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2923 - accuracy: 0.8776 - val_loss: 0.3173 - val_accuracy: 0.8623\n",
      "Epoch 22/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2452 - accuracy: 0.8952\n",
      "Epoch 22: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2897 - accuracy: 0.8797 - val_loss: 0.3136 - val_accuracy: 0.8631\n",
      "Epoch 23/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3178 - accuracy: 0.8871\n",
      "Epoch 23: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2945 - accuracy: 0.8765 - val_loss: 0.3103 - val_accuracy: 0.8685\n",
      "Epoch 24/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3114 - accuracy: 0.8871\n",
      "Epoch 24: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2896 - accuracy: 0.8776 - val_loss: 0.3136 - val_accuracy: 0.8708\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2514 - accuracy: 0.8871\n",
      "Epoch 25: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2840 - accuracy: 0.8867 - val_loss: 0.3254 - val_accuracy: 0.8677\n",
      "Epoch 26/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2878 - accuracy: 0.8807\n",
      "Epoch 26: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2863 - accuracy: 0.8826 - val_loss: 0.3053 - val_accuracy: 0.8731\n",
      "Epoch 27/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2899 - accuracy: 0.8786\n",
      "Epoch 27: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2893 - accuracy: 0.8786 - val_loss: 0.3126 - val_accuracy: 0.8731\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2348 - accuracy: 0.9032\n",
      "Epoch 28: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2823 - accuracy: 0.8801 - val_loss: 0.3029 - val_accuracy: 0.8754\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2473 - accuracy: 0.9194\n",
      "Epoch 29: val_accuracy improved from 0.87615 to 0.87769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.8709 - val_loss: 0.3034 - val_accuracy: 0.8777\n",
      "Epoch 30/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2437 - accuracy: 0.9274\n",
      "Epoch 30: val_accuracy improved from 0.87769 to 0.87923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2723 - accuracy: 0.8894 - val_loss: 0.2998 - val_accuracy: 0.8792\n",
      "Epoch 31/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2967 - accuracy: 0.8952\n",
      "Epoch 31: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2802 - accuracy: 0.8822 - val_loss: 0.3046 - val_accuracy: 0.8708\n",
      "Epoch 32/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2789 - accuracy: 0.8790\n",
      "Epoch 32: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2795 - accuracy: 0.8834 - val_loss: 0.3066 - val_accuracy: 0.8785\n",
      "Epoch 33/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2487 - accuracy: 0.8871\n",
      "Epoch 33: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2713 - accuracy: 0.8865 - val_loss: 0.2984 - val_accuracy: 0.8769\n",
      "Epoch 34/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2827 - accuracy: 0.8952\n",
      "Epoch 34: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.8882 - val_loss: 0.3144 - val_accuracy: 0.8792\n",
      "Epoch 35/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2827 - accuracy: 0.8820\n",
      "Epoch 35: val_accuracy improved from 0.87923 to 0.88615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2834 - accuracy: 0.8822 - val_loss: 0.3017 - val_accuracy: 0.8862\n",
      "Epoch 36/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2543 - accuracy: 0.9032\n",
      "Epoch 36: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2760 - accuracy: 0.8845 - val_loss: 0.3585 - val_accuracy: 0.8408\n",
      "Epoch 37/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3056 - accuracy: 0.8468\n",
      "Epoch 37: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2814 - accuracy: 0.8824 - val_loss: 0.2996 - val_accuracy: 0.8777\n",
      "Epoch 38/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1504 - accuracy: 0.9516\n",
      "Epoch 38: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2693 - accuracy: 0.8882 - val_loss: 0.3233 - val_accuracy: 0.8608\n",
      "Epoch 39/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2178 - accuracy: 0.9274\n",
      "Epoch 39: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2829 - accuracy: 0.8826 - val_loss: 0.2925 - val_accuracy: 0.8862\n",
      "Epoch 40/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2395 - accuracy: 0.9113\n",
      "Epoch 40: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2662 - accuracy: 0.8872 - val_loss: 0.3005 - val_accuracy: 0.8785\n",
      "Epoch 41/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2517 - accuracy: 0.8871\n",
      "Epoch 41: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2600 - accuracy: 0.8949 - val_loss: 0.3096 - val_accuracy: 0.8685\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2667 - accuracy: 0.8952\n",
      "Epoch 42: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2956 - accuracy: 0.8745 - val_loss: 0.2984 - val_accuracy: 0.8754\n",
      "Epoch 43/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2723 - accuracy: 0.9032\n",
      "Epoch 43: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.8926 - val_loss: 0.2932 - val_accuracy: 0.8808\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2254 - accuracy: 0.9113\n",
      "Epoch 44: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2666 - accuracy: 0.8890 - val_loss: 0.2931 - val_accuracy: 0.8846\n",
      "Epoch 45/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2869 - accuracy: 0.8790\n",
      "Epoch 45: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2629 - accuracy: 0.8911 - val_loss: 0.2911 - val_accuracy: 0.8800\n",
      "Epoch 46/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2643 - accuracy: 0.8952\n",
      "Epoch 46: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2556 - accuracy: 0.8953 - val_loss: 0.2895 - val_accuracy: 0.8815\n",
      "Epoch 47/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2639 - accuracy: 0.8871\n",
      "Epoch 47: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.8944 - val_loss: 0.2904 - val_accuracy: 0.8854\n",
      "Epoch 48/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2707 - accuracy: 0.8871\n",
      "Epoch 48: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2624 - accuracy: 0.8934 - val_loss: 0.2944 - val_accuracy: 0.8846\n",
      "Epoch 49/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1928 - accuracy: 0.9194\n",
      "Epoch 49: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2561 - accuracy: 0.8919 - val_loss: 0.3014 - val_accuracy: 0.8754\n",
      "Epoch 50/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3056 - accuracy: 0.8710\n",
      "Epoch 50: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.8878 - val_loss: 0.2986 - val_accuracy: 0.8715\n",
      "Epoch 51/1000\n",
      "29/42 [===================>..........] - ETA: 0s - loss: 0.2568 - accuracy: 0.8977\n",
      "Epoch 51: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2553 - accuracy: 0.8980 - val_loss: 0.2964 - val_accuracy: 0.8846\n",
      "Epoch 52/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.2567 - accuracy: 0.8936\n",
      "Epoch 52: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 0.8930 - val_loss: 0.2974 - val_accuracy: 0.8838\n",
      "Epoch 53/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2698 - accuracy: 0.8548\n",
      "Epoch 53: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.8947 - val_loss: 0.2927 - val_accuracy: 0.8754\n",
      "Epoch 54/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3201 - accuracy: 0.8468\n",
      "Epoch 54: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2552 - accuracy: 0.8905 - val_loss: 0.3111 - val_accuracy: 0.8754\n",
      "Epoch 55/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2033 - accuracy: 0.9274\n",
      "Epoch 55: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.8959 - val_loss: 0.2943 - val_accuracy: 0.8785\n",
      "Epoch 56/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2186 - accuracy: 0.9194\n",
      "Epoch 56: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.8953 - val_loss: 0.3023 - val_accuracy: 0.8731\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2335 - accuracy: 0.8790\n",
      "Epoch 57: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2476 - accuracy: 0.8969 - val_loss: 0.3011 - val_accuracy: 0.8823\n",
      "Epoch 58/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2714 - accuracy: 0.8629\n",
      "Epoch 58: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.8940 - val_loss: 0.3143 - val_accuracy: 0.8731\n",
      "Epoch 59/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2382 - accuracy: 0.8952\n",
      "Epoch 59: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.8959 - val_loss: 0.2935 - val_accuracy: 0.8808\n",
      "Epoch 60/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2533 - accuracy: 0.9274\n",
      "Epoch 60: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.9046 - val_loss: 0.2935 - val_accuracy: 0.8838\n",
      "Epoch 61/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2127 - accuracy: 0.9032\n",
      "Epoch 61: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.9026 - val_loss: 0.3302 - val_accuracy: 0.8685\n",
      "Epoch 62/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2520 - accuracy: 0.8871\n",
      "Epoch 62: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.8955 - val_loss: 0.3099 - val_accuracy: 0.8731\n",
      "Epoch 63/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2486 - accuracy: 0.9194\n",
      "Epoch 63: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2634 - accuracy: 0.8921 - val_loss: 0.3315 - val_accuracy: 0.8623\n",
      "Epoch 64/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2517 - accuracy: 0.8710\n",
      "Epoch 64: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.8972 - val_loss: 0.3013 - val_accuracy: 0.8792\n",
      "Epoch 65/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2253 - accuracy: 0.9194\n",
      "Epoch 65: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.8990 - val_loss: 0.3042 - val_accuracy: 0.8738\n",
      "Epoch 66/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2339 - accuracy: 0.9032\n",
      "Epoch 66: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.8965 - val_loss: 0.3002 - val_accuracy: 0.8808\n",
      "Epoch 67/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2776 - accuracy: 0.8548\n",
      "Epoch 67: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2409 - accuracy: 0.8984 - val_loss: 0.2931 - val_accuracy: 0.8838\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2643 - accuracy: 0.8952\n",
      "Epoch 68: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2389 - accuracy: 0.9013 - val_loss: 0.3062 - val_accuracy: 0.8746\n",
      "Epoch 69/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2896 - accuracy: 0.8871\n",
      "Epoch 69: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2397 - accuracy: 0.9024 - val_loss: 0.3030 - val_accuracy: 0.8738\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2116 - accuracy: 0.9274\n",
      "Epoch 70: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2420 - accuracy: 0.9007 - val_loss: 0.3019 - val_accuracy: 0.8792\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2555 - accuracy: 0.9113\n",
      "Epoch 71: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2383 - accuracy: 0.9065 - val_loss: 0.3052 - val_accuracy: 0.8777\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2582 - accuracy: 0.9113\n",
      "Epoch 72: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2383 - accuracy: 0.9034 - val_loss: 0.2998 - val_accuracy: 0.8738\n",
      "Epoch 73/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1837 - accuracy: 0.9274\n",
      "Epoch 73: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2371 - accuracy: 0.9038 - val_loss: 0.3313 - val_accuracy: 0.8615\n",
      "Epoch 74/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2432 - accuracy: 0.9274\n",
      "Epoch 74: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.8959 - val_loss: 0.3053 - val_accuracy: 0.8792\n",
      "Epoch 75/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2487 - accuracy: 0.8629\n",
      "Epoch 75: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2378 - accuracy: 0.9015 - val_loss: 0.3133 - val_accuracy: 0.8731\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3325 - accuracy: 0.8871\n",
      "Epoch 76: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2328 - accuracy: 0.9053 - val_loss: 0.3036 - val_accuracy: 0.8769\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1499 - accuracy: 0.9435\n",
      "Epoch 77: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2351 - accuracy: 0.9080 - val_loss: 0.2955 - val_accuracy: 0.8777\n",
      "Epoch 78/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2326 - accuracy: 0.9053\n",
      "Epoch 78: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2319 - accuracy: 0.9053 - val_loss: 0.2980 - val_accuracy: 0.8800\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2108 - accuracy: 0.9194\n",
      "Epoch 79: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2309 - accuracy: 0.9042 - val_loss: 0.2945 - val_accuracy: 0.8777\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2420 - accuracy: 0.8952\n",
      "Epoch 80: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2262 - accuracy: 0.9073 - val_loss: 0.3076 - val_accuracy: 0.8746\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2088 - accuracy: 0.9274\n",
      "Epoch 81: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2365 - accuracy: 0.9038 - val_loss: 0.2994 - val_accuracy: 0.8692\n",
      "Epoch 82/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2207 - accuracy: 0.9194\n",
      "Epoch 82: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2328 - accuracy: 0.9055 - val_loss: 0.3126 - val_accuracy: 0.8731\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2768 - accuracy: 0.8790\n",
      "Epoch 83: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.9003 - val_loss: 0.3054 - val_accuracy: 0.8723\n",
      "Epoch 84/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2623 - accuracy: 0.9032\n",
      "Epoch 84: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.8984 - val_loss: 0.2969 - val_accuracy: 0.8838\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2584 - accuracy: 0.8952\n",
      "Epoch 85: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.8940 - val_loss: 0.3158 - val_accuracy: 0.8662\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2803 - accuracy: 0.8952\n",
      "Epoch 86: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2413 - accuracy: 0.9007 - val_loss: 0.3190 - val_accuracy: 0.8792\n",
      "Epoch 87/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2524 - accuracy: 0.9032\n",
      "Epoch 87: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2263 - accuracy: 0.9067 - val_loss: 0.3102 - val_accuracy: 0.8700\n",
      "Epoch 88/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1786 - accuracy: 0.9113\n",
      "Epoch 88: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2255 - accuracy: 0.9078 - val_loss: 0.3079 - val_accuracy: 0.8792\n",
      "Epoch 89/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1882 - accuracy: 0.9194\n",
      "Epoch 89: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2285 - accuracy: 0.9086 - val_loss: 0.3143 - val_accuracy: 0.8669\n",
      "Epoch 90/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2397 - accuracy: 0.8952\n",
      "Epoch 90: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2282 - accuracy: 0.9080 - val_loss: 0.3266 - val_accuracy: 0.8700\n",
      "Epoch 91/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2506 - accuracy: 0.8871\n",
      "Epoch 91: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2243 - accuracy: 0.9078 - val_loss: 0.3315 - val_accuracy: 0.8615\n",
      "Epoch 92/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2348 - accuracy: 0.9032\n",
      "Epoch 92: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.9042 - val_loss: 0.3097 - val_accuracy: 0.8762\n",
      "Epoch 93/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2622 - accuracy: 0.8790\n",
      "Epoch 93: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2275 - accuracy: 0.9088 - val_loss: 0.3111 - val_accuracy: 0.8715\n",
      "Epoch 94/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2084 - accuracy: 0.9032\n",
      "Epoch 94: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2252 - accuracy: 0.9082 - val_loss: 0.3041 - val_accuracy: 0.8808\n",
      "Epoch 95/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2070 - accuracy: 0.9032\n",
      "Epoch 95: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2204 - accuracy: 0.9128 - val_loss: 0.3180 - val_accuracy: 0.8708\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2760 - accuracy: 0.8871\n",
      "Epoch 96: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2290 - accuracy: 0.9065 - val_loss: 0.3227 - val_accuracy: 0.8692\n",
      "Epoch 97/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2978 - accuracy: 0.8790\n",
      "Epoch 97: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.9076 - val_loss: 0.3248 - val_accuracy: 0.8762\n",
      "Epoch 98/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2993 - accuracy: 0.8629\n",
      "Epoch 98: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2231 - accuracy: 0.9078 - val_loss: 0.3168 - val_accuracy: 0.8777\n",
      "Epoch 99/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2083 - accuracy: 0.8952\n",
      "Epoch 99: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2154 - accuracy: 0.9111 - val_loss: 0.3086 - val_accuracy: 0.8823\n",
      "Epoch 100/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1931 - accuracy: 0.9032\n",
      "Epoch 100: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.9105 - val_loss: 0.3057 - val_accuracy: 0.8754\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3229 - accuracy: 0.8548\n",
      "Epoch 101: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2262 - accuracy: 0.9063 - val_loss: 0.3100 - val_accuracy: 0.8785\n",
      "Epoch 102/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2287 - accuracy: 0.8952\n",
      "Epoch 102: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2263 - accuracy: 0.9059 - val_loss: 0.3207 - val_accuracy: 0.8669\n",
      "Epoch 103/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1393 - accuracy: 0.9355\n",
      "Epoch 103: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2162 - accuracy: 0.9088 - val_loss: 0.3239 - val_accuracy: 0.8723\n",
      "Epoch 104/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2365 - accuracy: 0.9113\n",
      "Epoch 104: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.9123 - val_loss: 0.3176 - val_accuracy: 0.8700\n",
      "Epoch 105/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2188 - accuracy: 0.9103\n",
      "Epoch 105: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2188 - accuracy: 0.9103 - val_loss: 0.3251 - val_accuracy: 0.8762\n",
      "Epoch 106/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1719 - accuracy: 0.9355\n",
      "Epoch 106: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2355 - accuracy: 0.8996 - val_loss: 0.3051 - val_accuracy: 0.8723\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2999 - accuracy: 0.8468\n",
      "Epoch 107: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2219 - accuracy: 0.9073 - val_loss: 0.3070 - val_accuracy: 0.8777\n",
      "Epoch 108/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1661 - accuracy: 0.9355\n",
      "Epoch 108: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2146 - accuracy: 0.9153 - val_loss: 0.3103 - val_accuracy: 0.8823\n",
      "Epoch 109/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3208 - accuracy: 0.8952\n",
      "Epoch 109: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2117 - accuracy: 0.9150 - val_loss: 0.3053 - val_accuracy: 0.8723\n",
      "Epoch 110/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1981 - accuracy: 0.9032\n",
      "Epoch 110: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2150 - accuracy: 0.9094 - val_loss: 0.3124 - val_accuracy: 0.8738\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1667 - accuracy: 0.9274\n",
      "Epoch 111: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2253 - accuracy: 0.9074 - val_loss: 0.3354 - val_accuracy: 0.8800\n",
      "Epoch 112/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2986 - accuracy: 0.8710\n",
      "Epoch 112: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2179 - accuracy: 0.9063 - val_loss: 0.3195 - val_accuracy: 0.8777\n",
      "Epoch 113/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1769 - accuracy: 0.9355\n",
      "Epoch 113: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2098 - accuracy: 0.9140 - val_loss: 0.3088 - val_accuracy: 0.8692\n",
      "Epoch 114/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1673 - accuracy: 0.9274\n",
      "Epoch 114: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2126 - accuracy: 0.9142 - val_loss: 0.3172 - val_accuracy: 0.8762\n",
      "Epoch 115/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1644 - accuracy: 0.9355\n",
      "Epoch 115: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2145 - accuracy: 0.9098 - val_loss: 0.3104 - val_accuracy: 0.8754\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1874 - accuracy: 0.9274\n",
      "Epoch 116: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2109 - accuracy: 0.9132 - val_loss: 0.3167 - val_accuracy: 0.8762\n",
      "Epoch 117/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1592 - accuracy: 0.9435\n",
      "Epoch 117: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2064 - accuracy: 0.9138 - val_loss: 0.3160 - val_accuracy: 0.8738\n",
      "Epoch 118/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1841 - accuracy: 0.9113\n",
      "Epoch 118: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2050 - accuracy: 0.9186 - val_loss: 0.3142 - val_accuracy: 0.8692\n",
      "Epoch 119/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1513 - accuracy: 0.9194\n",
      "Epoch 119: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2132 - accuracy: 0.9105 - val_loss: 0.3323 - val_accuracy: 0.8654\n",
      "Epoch 120/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1458 - accuracy: 0.9516\n",
      "Epoch 120: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2082 - accuracy: 0.9119 - val_loss: 0.3492 - val_accuracy: 0.8562\n",
      "Epoch 121/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1969 - accuracy: 0.9113\n",
      "Epoch 121: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2106 - accuracy: 0.9144 - val_loss: 0.3181 - val_accuracy: 0.8700\n",
      "Epoch 122/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2707 - accuracy: 0.8871\n",
      "Epoch 122: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2008 - accuracy: 0.9175 - val_loss: 0.3224 - val_accuracy: 0.8723\n",
      "Epoch 123/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2175 - accuracy: 0.9194\n",
      "Epoch 123: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2102 - accuracy: 0.9103 - val_loss: 0.3514 - val_accuracy: 0.8692\n",
      "Epoch 124/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2228 - accuracy: 0.9032\n",
      "Epoch 124: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2069 - accuracy: 0.9178 - val_loss: 0.3318 - val_accuracy: 0.8738\n",
      "Epoch 125/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1954 - accuracy: 0.9032\n",
      "Epoch 125: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2089 - accuracy: 0.9138 - val_loss: 0.3166 - val_accuracy: 0.8662\n",
      "Epoch 126/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2486 - accuracy: 0.8952\n",
      "Epoch 126: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2168 - accuracy: 0.9113 - val_loss: 0.3475 - val_accuracy: 0.8631\n",
      "Epoch 127/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2728 - accuracy: 0.8952\n",
      "Epoch 127: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2112 - accuracy: 0.9142 - val_loss: 0.3251 - val_accuracy: 0.8692\n",
      "Epoch 128/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1212 - accuracy: 0.9516\n",
      "Epoch 128: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 0.9163 - val_loss: 0.3193 - val_accuracy: 0.8777\n",
      "Epoch 129/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1717 - accuracy: 0.9435\n",
      "Epoch 129: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2055 - accuracy: 0.9144 - val_loss: 0.3428 - val_accuracy: 0.8631\n",
      "Epoch 130/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2019 - accuracy: 0.8952\n",
      "Epoch 130: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2005 - accuracy: 0.9175 - val_loss: 0.3217 - val_accuracy: 0.8769\n",
      "Epoch 131/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1181 - accuracy: 0.9758\n",
      "Epoch 131: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2135 - accuracy: 0.9098 - val_loss: 0.3163 - val_accuracy: 0.8785\n",
      "Epoch 132/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2299 - accuracy: 0.9194\n",
      "Epoch 132: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2033 - accuracy: 0.9175 - val_loss: 0.3315 - val_accuracy: 0.8762\n",
      "Epoch 133/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2162 - accuracy: 0.9113\n",
      "Epoch 133: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2011 - accuracy: 0.9155 - val_loss: 0.3235 - val_accuracy: 0.8738\n",
      "Epoch 134/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2025 - accuracy: 0.9143\n",
      "Epoch 134: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1992 - accuracy: 0.9157 - val_loss: 0.3484 - val_accuracy: 0.8638\n",
      "Epoch 135/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3578 - accuracy: 0.8710\n",
      "Epoch 135: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1982 - accuracy: 0.9205 - val_loss: 0.3573 - val_accuracy: 0.8708\n",
      "Epoch 136/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1403 - accuracy: 0.9355\n",
      "Epoch 136: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2093 - accuracy: 0.9136 - val_loss: 0.3690 - val_accuracy: 0.8654\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2638 - accuracy: 0.8629\n",
      "Epoch 137: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2068 - accuracy: 0.9155 - val_loss: 0.3474 - val_accuracy: 0.8700\n",
      "Epoch 138/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2171 - accuracy: 0.9113\n",
      "Epoch 138: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2036 - accuracy: 0.9132 - val_loss: 0.3400 - val_accuracy: 0.8715\n",
      "Epoch 139/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2174 - accuracy: 0.8629\n",
      "Epoch 139: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.9182 - val_loss: 0.3435 - val_accuracy: 0.8631\n",
      "Epoch 140/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2088 - accuracy: 0.9435\n",
      "Epoch 140: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2054 - accuracy: 0.9173 - val_loss: 0.3337 - val_accuracy: 0.8623\n",
      "Epoch 141/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1969 - accuracy: 0.9032\n",
      "Epoch 141: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1933 - accuracy: 0.9234 - val_loss: 0.3378 - val_accuracy: 0.8685\n",
      "Epoch 142/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1974 - accuracy: 0.9184\n",
      "Epoch 142: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1974 - accuracy: 0.9184 - val_loss: 0.3376 - val_accuracy: 0.8731\n",
      "Epoch 143/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2865 - accuracy: 0.8952\n",
      "Epoch 143: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1903 - accuracy: 0.9215 - val_loss: 0.3421 - val_accuracy: 0.8785\n",
      "Epoch 144/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1290 - accuracy: 0.9435\n",
      "Epoch 144: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.9234 - val_loss: 0.3500 - val_accuracy: 0.8762\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1739 - accuracy: 0.9194\n",
      "Epoch 145: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1938 - accuracy: 0.9203 - val_loss: 0.3341 - val_accuracy: 0.8738\n",
      "Epoch 146/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2017 - accuracy: 0.9113\n",
      "Epoch 146: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1896 - accuracy: 0.9236 - val_loss: 0.3404 - val_accuracy: 0.8746\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 22s - loss: 6.9133 - accuracy: 0.3629\n",
      "Epoch 1: val_accuracy improved from -inf to 0.60154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 1.1791 - accuracy: 0.5097 - val_loss: 0.6703 - val_accuracy: 0.6015\n",
      "Epoch 2/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.6370 - accuracy: 0.6643\n",
      "Epoch 2: val_accuracy improved from 0.60154 to 0.65615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.6673 - val_loss: 0.5900 - val_accuracy: 0.6562\n",
      "Epoch 3/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.5812 - accuracy: 0.6774\n",
      "Epoch 3: val_accuracy improved from 0.65615 to 0.81692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7708 - val_loss: 0.4365 - val_accuracy: 0.8169\n",
      "Epoch 4/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4657 - accuracy: 0.7823\n",
      "Epoch 4: val_accuracy improved from 0.81692 to 0.84462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8303 - val_loss: 0.3784 - val_accuracy: 0.8446\n",
      "Epoch 5/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3513 - accuracy: 0.8468\n",
      "Epoch 5: val_accuracy improved from 0.84462 to 0.85308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8466 - val_loss: 0.3557 - val_accuracy: 0.8531\n",
      "Epoch 6/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3339 - accuracy: 0.8629\n",
      "Epoch 6: val_accuracy did not improve from 0.85308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8478 - val_loss: 0.3465 - val_accuracy: 0.8515\n",
      "Epoch 7/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3640 - accuracy: 0.8434\n",
      "Epoch 7: val_accuracy did not improve from 0.85308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8432 - val_loss: 0.3820 - val_accuracy: 0.8238\n",
      "Epoch 8/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4247 - accuracy: 0.7823\n",
      "Epoch 8: val_accuracy improved from 0.85308 to 0.85846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3455 - accuracy: 0.8530 - val_loss: 0.3409 - val_accuracy: 0.8585\n",
      "Epoch 9/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2990 - accuracy: 0.8790\n",
      "Epoch 9: val_accuracy did not improve from 0.85846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8626 - val_loss: 0.3441 - val_accuracy: 0.8585\n",
      "Epoch 10/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2977 - accuracy: 0.9113\n",
      "Epoch 10: val_accuracy improved from 0.85846 to 0.86000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8709 - val_loss: 0.3373 - val_accuracy: 0.8600\n",
      "Epoch 11/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3153 - accuracy: 0.8629\n",
      "Epoch 11: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8703 - val_loss: 0.3341 - val_accuracy: 0.8569\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3650 - accuracy: 0.8710\n",
      "Epoch 12: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8640 - val_loss: 0.3489 - val_accuracy: 0.8523\n",
      "Epoch 13/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2752 - accuracy: 0.8952\n",
      "Epoch 13: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8665 - val_loss: 0.3449 - val_accuracy: 0.8562\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3770 - accuracy: 0.8468\n",
      "Epoch 14: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8680 - val_loss: 0.3587 - val_accuracy: 0.8508\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3610 - accuracy: 0.8226\n",
      "Epoch 15: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8642 - val_loss: 0.3313 - val_accuracy: 0.8600\n",
      "Epoch 16/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2753 - accuracy: 0.8790\n",
      "Epoch 16: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8663 - val_loss: 0.3453 - val_accuracy: 0.8600\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2512 - accuracy: 0.9194\n",
      "Epoch 17: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3169 - accuracy: 0.8653 - val_loss: 0.3368 - val_accuracy: 0.8592\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2510 - accuracy: 0.9113\n",
      "Epoch 18: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3210 - accuracy: 0.8624 - val_loss: 0.3367 - val_accuracy: 0.8531\n",
      "Epoch 19/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3019 - accuracy: 0.8790\n",
      "Epoch 19: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.8622 - val_loss: 0.3292 - val_accuracy: 0.8585\n",
      "Epoch 20/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3531 - accuracy: 0.8468\n",
      "Epoch 20: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8736 - val_loss: 0.3387 - val_accuracy: 0.8592\n",
      "Epoch 21/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2800 - accuracy: 0.8790\n",
      "Epoch 21: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3256 - accuracy: 0.8597 - val_loss: 0.3325 - val_accuracy: 0.8592\n",
      "Epoch 22/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3321 - accuracy: 0.8790\n",
      "Epoch 22: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.8730 - val_loss: 0.3301 - val_accuracy: 0.8585\n",
      "Epoch 23/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2843 - accuracy: 0.9032\n",
      "Epoch 23: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3058 - accuracy: 0.8734 - val_loss: 0.3462 - val_accuracy: 0.8492\n",
      "Epoch 24/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2759 - accuracy: 0.8871\n",
      "Epoch 24: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8651 - val_loss: 0.3560 - val_accuracy: 0.8531\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3589 - accuracy: 0.8468\n",
      "Epoch 25: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8659 - val_loss: 0.3351 - val_accuracy: 0.8592\n",
      "Epoch 26/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.2979 - accuracy: 0.8781\n",
      "Epoch 26: val_accuracy improved from 0.86000 to 0.86154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2988 - accuracy: 0.8784 - val_loss: 0.3284 - val_accuracy: 0.8615\n",
      "Epoch 27/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.3029 - accuracy: 0.8699\n",
      "Epoch 27: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2996 - accuracy: 0.8722 - val_loss: 0.3270 - val_accuracy: 0.8592\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2786 - accuracy: 0.8790\n",
      "Epoch 28: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8699 - val_loss: 0.3247 - val_accuracy: 0.8600\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3633 - accuracy: 0.8306\n",
      "Epoch 29: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3038 - accuracy: 0.8730 - val_loss: 0.3360 - val_accuracy: 0.8546\n",
      "Epoch 30/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2438 - accuracy: 0.9113\n",
      "Epoch 30: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2996 - accuracy: 0.8742 - val_loss: 0.3345 - val_accuracy: 0.8569\n",
      "Epoch 31/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3835 - accuracy: 0.8306\n",
      "Epoch 31: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3016 - accuracy: 0.8730 - val_loss: 0.3724 - val_accuracy: 0.8485\n",
      "Epoch 32/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3678 - accuracy: 0.8306\n",
      "Epoch 32: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3045 - accuracy: 0.8734 - val_loss: 0.3294 - val_accuracy: 0.8615\n",
      "Epoch 33/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3561 - accuracy: 0.8710\n",
      "Epoch 33: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2937 - accuracy: 0.8778 - val_loss: 0.3301 - val_accuracy: 0.8592\n",
      "Epoch 34/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1819 - accuracy: 0.9274\n",
      "Epoch 34: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8722 - val_loss: 0.3282 - val_accuracy: 0.8600\n",
      "Epoch 35/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2498 - accuracy: 0.9194\n",
      "Epoch 35: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2974 - accuracy: 0.8745 - val_loss: 0.3436 - val_accuracy: 0.8608\n",
      "Epoch 36/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3294 - accuracy: 0.8629\n",
      "Epoch 36: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2944 - accuracy: 0.8755 - val_loss: 0.3658 - val_accuracy: 0.8331\n",
      "Epoch 37/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3326 - accuracy: 0.8548\n",
      "Epoch 37: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.8645 - val_loss: 0.3336 - val_accuracy: 0.8585\n",
      "Epoch 38/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3190 - accuracy: 0.8468\n",
      "Epoch 38: val_accuracy improved from 0.86154 to 0.86538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2921 - accuracy: 0.8761 - val_loss: 0.3252 - val_accuracy: 0.8654\n",
      "Epoch 39/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3140 - accuracy: 0.8468\n",
      "Epoch 39: val_accuracy did not improve from 0.86538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2909 - accuracy: 0.8772 - val_loss: 0.3319 - val_accuracy: 0.8600\n",
      "Epoch 40/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2590 - accuracy: 0.8871\n",
      "Epoch 40: val_accuracy did not improve from 0.86538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2890 - accuracy: 0.8811 - val_loss: 0.3314 - val_accuracy: 0.8569\n",
      "Epoch 41/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2425 - accuracy: 0.8871\n",
      "Epoch 41: val_accuracy did not improve from 0.86538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2937 - accuracy: 0.8753 - val_loss: 0.3667 - val_accuracy: 0.8500\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3563 - accuracy: 0.8548\n",
      "Epoch 42: val_accuracy did not improve from 0.86538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2946 - accuracy: 0.8763 - val_loss: 0.3284 - val_accuracy: 0.8615\n",
      "Epoch 43/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2545 - accuracy: 0.8871\n",
      "Epoch 43: val_accuracy did not improve from 0.86538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2856 - accuracy: 0.8799 - val_loss: 0.3292 - val_accuracy: 0.8554\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2862 - accuracy: 0.8952\n",
      "Epoch 44: val_accuracy did not improve from 0.86538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2865 - accuracy: 0.8792 - val_loss: 0.3378 - val_accuracy: 0.8623\n",
      "Epoch 45/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3264 - accuracy: 0.8468\n",
      "Epoch 45: val_accuracy did not improve from 0.86538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2923 - accuracy: 0.8790 - val_loss: 0.3346 - val_accuracy: 0.8623\n",
      "Epoch 46/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2539 - accuracy: 0.9032\n",
      "Epoch 46: val_accuracy did not improve from 0.86538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2844 - accuracy: 0.8790 - val_loss: 0.3295 - val_accuracy: 0.8554\n",
      "Epoch 47/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2577 - accuracy: 0.8952\n",
      "Epoch 47: val_accuracy did not improve from 0.86538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2856 - accuracy: 0.8801 - val_loss: 0.3313 - val_accuracy: 0.8638\n",
      "Epoch 48/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3022 - accuracy: 0.8710\n",
      "Epoch 48: val_accuracy did not improve from 0.86538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2813 - accuracy: 0.8803 - val_loss: 0.3277 - val_accuracy: 0.8577\n",
      "Epoch 49/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2435 - accuracy: 0.9113\n",
      "Epoch 49: val_accuracy improved from 0.86538 to 0.86692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2849 - accuracy: 0.8799 - val_loss: 0.3203 - val_accuracy: 0.8669\n",
      "Epoch 50/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2447 - accuracy: 0.9032\n",
      "Epoch 50: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2753 - accuracy: 0.8853 - val_loss: 0.3165 - val_accuracy: 0.8646\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2906 - accuracy: 0.8871\n",
      "Epoch 51: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2741 - accuracy: 0.8861 - val_loss: 0.3255 - val_accuracy: 0.8654\n",
      "Epoch 52/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3012 - accuracy: 0.8790\n",
      "Epoch 52: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2753 - accuracy: 0.8849 - val_loss: 0.3556 - val_accuracy: 0.8531\n",
      "Epoch 53/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4082 - accuracy: 0.8387\n",
      "Epoch 53: val_accuracy improved from 0.86692 to 0.86923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2829 - accuracy: 0.8819 - val_loss: 0.3151 - val_accuracy: 0.8692\n",
      "Epoch 54/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2673 - accuracy: 0.8790\n",
      "Epoch 54: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2723 - accuracy: 0.8865 - val_loss: 0.3186 - val_accuracy: 0.8623\n",
      "Epoch 55/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2936 - accuracy: 0.8629\n",
      "Epoch 55: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2683 - accuracy: 0.8871 - val_loss: 0.3146 - val_accuracy: 0.8685\n",
      "Epoch 56/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2952 - accuracy: 0.9032\n",
      "Epoch 56: val_accuracy improved from 0.86923 to 0.87231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2687 - accuracy: 0.8871 - val_loss: 0.3085 - val_accuracy: 0.8723\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2188 - accuracy: 0.9032\n",
      "Epoch 57: val_accuracy improved from 0.87231 to 0.87538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2734 - accuracy: 0.8844 - val_loss: 0.3112 - val_accuracy: 0.8754\n",
      "Epoch 58/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1906 - accuracy: 0.9435\n",
      "Epoch 58: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2611 - accuracy: 0.8905 - val_loss: 0.3068 - val_accuracy: 0.8669\n",
      "Epoch 59/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2113 - accuracy: 0.9274\n",
      "Epoch 59: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2654 - accuracy: 0.8896 - val_loss: 0.3075 - val_accuracy: 0.8708\n",
      "Epoch 60/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3109 - accuracy: 0.8790\n",
      "Epoch 60: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2664 - accuracy: 0.8897 - val_loss: 0.3039 - val_accuracy: 0.8754\n",
      "Epoch 61/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2103 - accuracy: 0.9274\n",
      "Epoch 61: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2585 - accuracy: 0.8919 - val_loss: 0.3011 - val_accuracy: 0.8738\n",
      "Epoch 62/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3360 - accuracy: 0.8387\n",
      "Epoch 62: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.8963 - val_loss: 0.3095 - val_accuracy: 0.8731\n",
      "Epoch 63/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2586 - accuracy: 0.8952\n",
      "Epoch 63: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2547 - accuracy: 0.8924 - val_loss: 0.3050 - val_accuracy: 0.8715\n",
      "Epoch 64/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2441 - accuracy: 0.8871\n",
      "Epoch 64: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2607 - accuracy: 0.8946 - val_loss: 0.2989 - val_accuracy: 0.8754\n",
      "Epoch 65/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1846 - accuracy: 0.9194\n",
      "Epoch 65: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2571 - accuracy: 0.8926 - val_loss: 0.3042 - val_accuracy: 0.8723\n",
      "Epoch 66/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2516 - accuracy: 0.8952\n",
      "Epoch 66: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.8928 - val_loss: 0.3143 - val_accuracy: 0.8731\n",
      "Epoch 67/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2492 - accuracy: 0.8986\n",
      "Epoch 67: val_accuracy improved from 0.87538 to 0.87769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.8978 - val_loss: 0.2989 - val_accuracy: 0.8777\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1954 - accuracy: 0.9113\n",
      "Epoch 68: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.8988 - val_loss: 0.3104 - val_accuracy: 0.8662\n",
      "Epoch 69/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3030 - accuracy: 0.8629\n",
      "Epoch 69: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2471 - accuracy: 0.8992 - val_loss: 0.3140 - val_accuracy: 0.8662\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2659 - accuracy: 0.8790\n",
      "Epoch 70: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.8951 - val_loss: 0.3028 - val_accuracy: 0.8708\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2493 - accuracy: 0.8952\n",
      "Epoch 71: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2479 - accuracy: 0.8965 - val_loss: 0.2957 - val_accuracy: 0.8746\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2281 - accuracy: 0.9274\n",
      "Epoch 72: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.8965 - val_loss: 0.3025 - val_accuracy: 0.8762\n",
      "Epoch 73/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2530 - accuracy: 0.8790\n",
      "Epoch 73: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8984 - val_loss: 0.3068 - val_accuracy: 0.8677\n",
      "Epoch 74/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3178 - accuracy: 0.8790\n",
      "Epoch 74: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8969 - val_loss: 0.3056 - val_accuracy: 0.8692\n",
      "Epoch 75/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2282 - accuracy: 0.9113\n",
      "Epoch 75: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2586 - accuracy: 0.8892 - val_loss: 0.3322 - val_accuracy: 0.8608\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2794 - accuracy: 0.9113\n",
      "Epoch 76: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2538 - accuracy: 0.8944 - val_loss: 0.3175 - val_accuracy: 0.8723\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2337 - accuracy: 0.9355\n",
      "Epoch 77: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2411 - accuracy: 0.9019 - val_loss: 0.3092 - val_accuracy: 0.8777\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2212 - accuracy: 0.9113\n",
      "Epoch 78: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 0.9001 - val_loss: 0.3061 - val_accuracy: 0.8677\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1972 - accuracy: 0.8952\n",
      "Epoch 79: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.9021 - val_loss: 0.3098 - val_accuracy: 0.8669\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1260 - accuracy: 0.9758\n",
      "Epoch 80: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.9021 - val_loss: 0.3086 - val_accuracy: 0.8677\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2648 - accuracy: 0.8710\n",
      "Epoch 81: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2375 - accuracy: 0.9021 - val_loss: 0.3027 - val_accuracy: 0.8738\n",
      "Epoch 82/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2228 - accuracy: 0.8952\n",
      "Epoch 82: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2352 - accuracy: 0.9055 - val_loss: 0.3143 - val_accuracy: 0.8715\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2523 - accuracy: 0.8548\n",
      "Epoch 83: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2438 - accuracy: 0.8986 - val_loss: 0.3137 - val_accuracy: 0.8677\n",
      "Epoch 84/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2559 - accuracy: 0.8790\n",
      "Epoch 84: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2402 - accuracy: 0.9032 - val_loss: 0.3241 - val_accuracy: 0.8731\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2070 - accuracy: 0.8952\n",
      "Epoch 85: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2397 - accuracy: 0.8999 - val_loss: 0.3178 - val_accuracy: 0.8708\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2405 - accuracy: 0.9032\n",
      "Epoch 86: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2393 - accuracy: 0.8996 - val_loss: 0.3199 - val_accuracy: 0.8754\n",
      "Epoch 87/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2480 - accuracy: 0.8871\n",
      "Epoch 87: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2334 - accuracy: 0.9015 - val_loss: 0.3122 - val_accuracy: 0.8723\n",
      "Epoch 88/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2134 - accuracy: 0.9194\n",
      "Epoch 88: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2283 - accuracy: 0.9019 - val_loss: 0.3035 - val_accuracy: 0.8708\n",
      "Epoch 89/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2983 - accuracy: 0.8629\n",
      "Epoch 89: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.9055 - val_loss: 0.3163 - val_accuracy: 0.8738\n",
      "Epoch 90/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2158 - accuracy: 0.8871\n",
      "Epoch 90: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2363 - accuracy: 0.9048 - val_loss: 0.3113 - val_accuracy: 0.8623\n",
      "Epoch 91/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1665 - accuracy: 0.9113\n",
      "Epoch 91: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2310 - accuracy: 0.9032 - val_loss: 0.3132 - val_accuracy: 0.8708\n",
      "Epoch 92/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2223 - accuracy: 0.9054\n",
      "Epoch 92: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2236 - accuracy: 0.9044 - val_loss: 0.3109 - val_accuracy: 0.8769\n",
      "Epoch 93/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2409 - accuracy: 0.8975\n",
      "Epoch 93: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.9005 - val_loss: 0.3074 - val_accuracy: 0.8738\n",
      "Epoch 94/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2243 - accuracy: 0.9194\n",
      "Epoch 94: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2238 - accuracy: 0.9069 - val_loss: 0.3071 - val_accuracy: 0.8723\n",
      "Epoch 95/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1825 - accuracy: 0.9274\n",
      "Epoch 95: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2322 - accuracy: 0.8996 - val_loss: 0.3442 - val_accuracy: 0.8585\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2513 - accuracy: 0.8871\n",
      "Epoch 96: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.8974 - val_loss: 0.3227 - val_accuracy: 0.8692\n",
      "Epoch 97/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2410 - accuracy: 0.8871\n",
      "Epoch 97: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2238 - accuracy: 0.9063 - val_loss: 0.3057 - val_accuracy: 0.8669\n",
      "Epoch 98/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2007 - accuracy: 0.9274\n",
      "Epoch 98: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.9092 - val_loss: 0.3053 - val_accuracy: 0.8731\n",
      "Epoch 99/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1843 - accuracy: 0.9355\n",
      "Epoch 99: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2281 - accuracy: 0.9024 - val_loss: 0.3201 - val_accuracy: 0.8746\n",
      "Epoch 100/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1964 - accuracy: 0.9274\n",
      "Epoch 100: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2246 - accuracy: 0.9042 - val_loss: 0.3165 - val_accuracy: 0.8723\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1770 - accuracy: 0.9274\n",
      "Epoch 101: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2158 - accuracy: 0.9084 - val_loss: 0.3143 - val_accuracy: 0.8715\n",
      "Epoch 102/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2145 - accuracy: 0.9274\n",
      "Epoch 102: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 0.9092 - val_loss: 0.3243 - val_accuracy: 0.8677\n",
      "Epoch 103/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1751 - accuracy: 0.9435\n",
      "Epoch 103: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2176 - accuracy: 0.9123 - val_loss: 0.3253 - val_accuracy: 0.8723\n",
      "Epoch 104/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1969 - accuracy: 0.9194\n",
      "Epoch 104: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2169 - accuracy: 0.9096 - val_loss: 0.3273 - val_accuracy: 0.8700\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2522 - accuracy: 0.9113\n",
      "Epoch 105: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2199 - accuracy: 0.9107 - val_loss: 0.3085 - val_accuracy: 0.8692\n",
      "Epoch 106/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2102 - accuracy: 0.9274\n",
      "Epoch 106: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2166 - accuracy: 0.9117 - val_loss: 0.3106 - val_accuracy: 0.8731\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2494 - accuracy: 0.8952\n",
      "Epoch 107: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2288 - accuracy: 0.9023 - val_loss: 0.3626 - val_accuracy: 0.8546\n",
      "Epoch 108/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2319 - accuracy: 0.8952\n",
      "Epoch 108: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2208 - accuracy: 0.9101 - val_loss: 0.3113 - val_accuracy: 0.8700\n",
      "Epoch 109/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2311 - accuracy: 0.8952\n",
      "Epoch 109: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2145 - accuracy: 0.9094 - val_loss: 0.3135 - val_accuracy: 0.8654\n",
      "Epoch 110/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2154 - accuracy: 0.9117\n",
      "Epoch 110: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.9113 - val_loss: 0.3227 - val_accuracy: 0.8692\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2376 - accuracy: 0.9032\n",
      "Epoch 111: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2139 - accuracy: 0.9109 - val_loss: 0.3245 - val_accuracy: 0.8723\n",
      "Epoch 112/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2687 - accuracy: 0.8952\n",
      "Epoch 112: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2196 - accuracy: 0.9076 - val_loss: 0.3402 - val_accuracy: 0.8638\n",
      "Epoch 113/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2146 - accuracy: 0.8871\n",
      "Epoch 113: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2182 - accuracy: 0.9063 - val_loss: 0.3294 - val_accuracy: 0.8685\n",
      "Epoch 114/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3643 - accuracy: 0.8548\n",
      "Epoch 114: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2265 - accuracy: 0.9086 - val_loss: 0.3553 - val_accuracy: 0.8608\n",
      "Epoch 115/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3006 - accuracy: 0.8790\n",
      "Epoch 115: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2220 - accuracy: 0.9074 - val_loss: 0.3160 - val_accuracy: 0.8669\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1558 - accuracy: 0.9516\n",
      "Epoch 116: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2127 - accuracy: 0.9109 - val_loss: 0.3292 - val_accuracy: 0.8723\n",
      "Epoch 117/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2674 - accuracy: 0.8790\n",
      "Epoch 117: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2135 - accuracy: 0.9082 - val_loss: 0.3239 - val_accuracy: 0.8654\n",
      "Epoch 118/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1757 - accuracy: 0.9194\n",
      "Epoch 118: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2115 - accuracy: 0.9115 - val_loss: 0.3272 - val_accuracy: 0.8638\n",
      "Epoch 119/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2344 - accuracy: 0.9194\n",
      "Epoch 119: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2154 - accuracy: 0.9107 - val_loss: 0.3264 - val_accuracy: 0.8592\n",
      "Epoch 120/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1939 - accuracy: 0.9113\n",
      "Epoch 120: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2077 - accuracy: 0.9148 - val_loss: 0.3256 - val_accuracy: 0.8692\n",
      "Epoch 121/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2860 - accuracy: 0.8952\n",
      "Epoch 121: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2070 - accuracy: 0.9142 - val_loss: 0.3394 - val_accuracy: 0.8685\n",
      "Epoch 122/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2496 - accuracy: 0.8710\n",
      "Epoch 122: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2130 - accuracy: 0.9123 - val_loss: 0.3191 - val_accuracy: 0.8654\n",
      "Epoch 123/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2163 - accuracy: 0.9194\n",
      "Epoch 123: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2120 - accuracy: 0.9126 - val_loss: 0.3455 - val_accuracy: 0.8631\n",
      "Epoch 124/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2266 - accuracy: 0.8871\n",
      "Epoch 124: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2158 - accuracy: 0.9107 - val_loss: 0.3216 - val_accuracy: 0.8669\n",
      "Epoch 125/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2466 - accuracy: 0.9113\n",
      "Epoch 125: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2032 - accuracy: 0.9171 - val_loss: 0.3361 - val_accuracy: 0.8646\n",
      "Epoch 126/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1915 - accuracy: 0.9194\n",
      "Epoch 126: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2031 - accuracy: 0.9175 - val_loss: 0.3277 - val_accuracy: 0.8615\n",
      "Epoch 127/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1894 - accuracy: 0.9194\n",
      "Epoch 127: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2099 - accuracy: 0.9151 - val_loss: 0.3344 - val_accuracy: 0.8662\n",
      "Epoch 128/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1765 - accuracy: 0.9274\n",
      "Epoch 128: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2149 - accuracy: 0.9092 - val_loss: 0.3381 - val_accuracy: 0.8677\n",
      "Epoch 129/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2542 - accuracy: 0.9113\n",
      "Epoch 129: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2121 - accuracy: 0.9132 - val_loss: 0.3222 - val_accuracy: 0.8669\n",
      "Epoch 130/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2810 - accuracy: 0.8871\n",
      "Epoch 130: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1974 - accuracy: 0.9186 - val_loss: 0.3386 - val_accuracy: 0.8677\n",
      "Epoch 131/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1093 - accuracy: 0.9677\n",
      "Epoch 131: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1969 - accuracy: 0.9194 - val_loss: 0.3303 - val_accuracy: 0.8692\n",
      "Epoch 132/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2178 - accuracy: 0.9032\n",
      "Epoch 132: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.9171 - val_loss: 0.3290 - val_accuracy: 0.8677\n",
      "Epoch 133/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2620 - accuracy: 0.8790\n",
      "Epoch 133: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1981 - accuracy: 0.9169 - val_loss: 0.3372 - val_accuracy: 0.8677\n",
      "Epoch 134/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2260 - accuracy: 0.8790\n",
      "Epoch 134: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2003 - accuracy: 0.9178 - val_loss: 0.3483 - val_accuracy: 0.8654\n",
      "Epoch 135/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1269 - accuracy: 0.9516\n",
      "Epoch 135: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2016 - accuracy: 0.9138 - val_loss: 0.3313 - val_accuracy: 0.8608\n",
      "Epoch 136/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1208 - accuracy: 0.9597\n",
      "Epoch 136: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1979 - accuracy: 0.9205 - val_loss: 0.3516 - val_accuracy: 0.8677\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2238 - accuracy: 0.9032\n",
      "Epoch 137: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9217 - val_loss: 0.3686 - val_accuracy: 0.8662\n",
      "Epoch 138/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2554 - accuracy: 0.8871\n",
      "Epoch 138: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1963 - accuracy: 0.9219 - val_loss: 0.3519 - val_accuracy: 0.8662\n",
      "Epoch 139/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1986 - accuracy: 0.9113\n",
      "Epoch 139: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1969 - accuracy: 0.9153 - val_loss: 0.3291 - val_accuracy: 0.8685\n",
      "Epoch 140/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2022 - accuracy: 0.9113\n",
      "Epoch 140: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.9225 - val_loss: 0.3403 - val_accuracy: 0.8685\n",
      "Epoch 141/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1361 - accuracy: 0.9435\n",
      "Epoch 141: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1900 - accuracy: 0.9223 - val_loss: 0.3592 - val_accuracy: 0.8715\n",
      "Epoch 142/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2230 - accuracy: 0.9113\n",
      "Epoch 142: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2053 - accuracy: 0.9111 - val_loss: 0.3414 - val_accuracy: 0.8615\n",
      "Epoch 143/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2012 - accuracy: 0.9274\n",
      "Epoch 143: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2012 - accuracy: 0.9171 - val_loss: 0.3484 - val_accuracy: 0.8677\n",
      "Epoch 144/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2103 - accuracy: 0.9113\n",
      "Epoch 144: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1864 - accuracy: 0.9255 - val_loss: 0.3465 - val_accuracy: 0.8646\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1211 - accuracy: 0.9435\n",
      "Epoch 145: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1872 - accuracy: 0.9205 - val_loss: 0.3613 - val_accuracy: 0.8608\n",
      "Epoch 146/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1725 - accuracy: 0.9355\n",
      "Epoch 146: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1964 - accuracy: 0.9194 - val_loss: 0.3589 - val_accuracy: 0.8708\n",
      "Epoch 147/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2612 - accuracy: 0.8952\n",
      "Epoch 147: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1874 - accuracy: 0.9244 - val_loss: 0.3627 - val_accuracy: 0.8592\n",
      "Epoch 148/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2156 - accuracy: 0.9194\n",
      "Epoch 148: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1840 - accuracy: 0.9286 - val_loss: 0.3605 - val_accuracy: 0.8615\n",
      "Epoch 149/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2894 - accuracy: 0.8790\n",
      "Epoch 149: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1850 - accuracy: 0.9257 - val_loss: 0.3612 - val_accuracy: 0.8585\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2603 - accuracy: 0.8871\n",
      "Epoch 150: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1921 - accuracy: 0.9221 - val_loss: 0.3591 - val_accuracy: 0.8662\n",
      "Epoch 151/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1873 - accuracy: 0.9218\n",
      "Epoch 151: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1889 - accuracy: 0.9211 - val_loss: 0.3638 - val_accuracy: 0.8723\n",
      "Epoch 152/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1498 - accuracy: 0.9435\n",
      "Epoch 152: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1936 - accuracy: 0.9173 - val_loss: 0.3882 - val_accuracy: 0.8515\n",
      "Epoch 153/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1773 - accuracy: 0.9194\n",
      "Epoch 153: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1968 - accuracy: 0.9173 - val_loss: 0.3591 - val_accuracy: 0.8669\n",
      "Epoch 154/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1507 - accuracy: 0.9516\n",
      "Epoch 154: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.9244 - val_loss: 0.3618 - val_accuracy: 0.8638\n",
      "Epoch 155/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1339 - accuracy: 0.9435\n",
      "Epoch 155: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.9253 - val_loss: 0.3693 - val_accuracy: 0.8677\n",
      "Epoch 156/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1298 - accuracy: 0.9435\n",
      "Epoch 156: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1843 - accuracy: 0.9230 - val_loss: 0.3741 - val_accuracy: 0.8592\n",
      "Epoch 157/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1789 - accuracy: 0.9274\n",
      "Epoch 157: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.9228 - val_loss: 0.4031 - val_accuracy: 0.8615\n",
      "Epoch 158/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1819 - accuracy: 0.9274\n",
      "Epoch 158: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9228 - val_loss: 0.3629 - val_accuracy: 0.8662\n",
      "Epoch 159/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1358 - accuracy: 0.9516\n",
      "Epoch 159: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.9194 - val_loss: 0.3771 - val_accuracy: 0.8677\n",
      "Epoch 160/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1619 - accuracy: 0.9516\n",
      "Epoch 160: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1778 - accuracy: 0.9250 - val_loss: 0.3777 - val_accuracy: 0.8685\n",
      "Epoch 161/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2158 - accuracy: 0.9113\n",
      "Epoch 161: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1773 - accuracy: 0.9261 - val_loss: 0.3699 - val_accuracy: 0.8646\n",
      "Epoch 162/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1181 - accuracy: 0.9597\n",
      "Epoch 162: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1729 - accuracy: 0.9300 - val_loss: 0.3874 - val_accuracy: 0.8692\n",
      "Epoch 163/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1896 - accuracy: 0.9194\n",
      "Epoch 163: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1734 - accuracy: 0.9303 - val_loss: 0.3788 - val_accuracy: 0.8715\n",
      "Epoch 164/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2179 - accuracy: 0.9194\n",
      "Epoch 164: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1714 - accuracy: 0.9327 - val_loss: 0.3968 - val_accuracy: 0.8600\n",
      "Epoch 165/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2473 - accuracy: 0.9194\n",
      "Epoch 165: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.9273 - val_loss: 0.3838 - val_accuracy: 0.8615\n",
      "Epoch 166/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2052 - accuracy: 0.9274\n",
      "Epoch 166: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1688 - accuracy: 0.9332 - val_loss: 0.3710 - val_accuracy: 0.8700\n",
      "Epoch 167/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1307 - accuracy: 0.9274\n",
      "Epoch 167: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1729 - accuracy: 0.9303 - val_loss: 0.3751 - val_accuracy: 0.8700\n",
      "Epoch 168/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1769 - accuracy: 0.9194\n",
      "Epoch 168: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1794 - accuracy: 0.9246 - val_loss: 0.3739 - val_accuracy: 0.8654\n",
      "Epoch 169/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1654 - accuracy: 0.9274\n",
      "Epoch 169: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1664 - accuracy: 0.9317 - val_loss: 0.3712 - val_accuracy: 0.8631\n",
      "Epoch 170/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1667 - accuracy: 0.9516\n",
      "Epoch 170: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1653 - accuracy: 0.9334 - val_loss: 0.3958 - val_accuracy: 0.8669\n",
      "Epoch 171/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1675 - accuracy: 0.9321\n",
      "Epoch 171: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1657 - accuracy: 0.9332 - val_loss: 0.3800 - val_accuracy: 0.8646\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001E49B5FCD30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 22s - loss: 1.8378 - accuracy: 0.4758\n",
      "Epoch 1: val_accuracy improved from -inf to 0.75462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.7313 - accuracy: 0.6048 - val_loss: 0.5299 - val_accuracy: 0.7546\n",
      "Epoch 2/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.5541 - accuracy: 0.7742\n",
      "Epoch 2: val_accuracy improved from 0.75462 to 0.80769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7758 - val_loss: 0.4580 - val_accuracy: 0.8077\n",
      "Epoch 3/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4361 - accuracy: 0.8306\n",
      "Epoch 3: val_accuracy improved from 0.80769 to 0.83923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8309 - val_loss: 0.3847 - val_accuracy: 0.8392\n",
      "Epoch 4/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3562 - accuracy: 0.8548\n",
      "Epoch 4: val_accuracy improved from 0.83923 to 0.84769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8399 - val_loss: 0.3610 - val_accuracy: 0.8477\n",
      "Epoch 5/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.3587 - accuracy: 0.8555\n",
      "Epoch 5: val_accuracy improved from 0.84769 to 0.85154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3559 - accuracy: 0.8563 - val_loss: 0.3582 - val_accuracy: 0.8515\n",
      "Epoch 6/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3337 - accuracy: 0.8629\n",
      "Epoch 6: val_accuracy improved from 0.85154 to 0.85308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8593 - val_loss: 0.3535 - val_accuracy: 0.8531\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3372 - accuracy: 0.8607\n",
      "Epoch 7: val_accuracy did not improve from 0.85308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8607 - val_loss: 0.3593 - val_accuracy: 0.8431\n",
      "Epoch 8/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4531 - accuracy: 0.7742\n",
      "Epoch 8: val_accuracy did not improve from 0.85308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8638 - val_loss: 0.3463 - val_accuracy: 0.8515\n",
      "Epoch 9/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3343 - accuracy: 0.8306\n",
      "Epoch 9: val_accuracy did not improve from 0.85308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8622 - val_loss: 0.3783 - val_accuracy: 0.8300\n",
      "Epoch 10/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3658 - accuracy: 0.8710\n",
      "Epoch 10: val_accuracy improved from 0.85308 to 0.85923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8582 - val_loss: 0.3341 - val_accuracy: 0.8592\n",
      "Epoch 11/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3041 - accuracy: 0.8548\n",
      "Epoch 11: val_accuracy improved from 0.85923 to 0.86154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.8705 - val_loss: 0.3329 - val_accuracy: 0.8615\n",
      "Epoch 12/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3151 - accuracy: 0.8696\n",
      "Epoch 12: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8693 - val_loss: 0.3412 - val_accuracy: 0.8608\n",
      "Epoch 13/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3517 - accuracy: 0.8226\n",
      "Epoch 13: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.8649 - val_loss: 0.4461 - val_accuracy: 0.7885\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3550 - accuracy: 0.8468\n",
      "Epoch 14: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8624 - val_loss: 0.3466 - val_accuracy: 0.8585\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2966 - accuracy: 0.9113\n",
      "Epoch 15: val_accuracy improved from 0.86154 to 0.86538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.8678 - val_loss: 0.3318 - val_accuracy: 0.8654\n",
      "Epoch 16/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3408 - accuracy: 0.8629\n",
      "Epoch 16: val_accuracy did not improve from 0.86538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3061 - accuracy: 0.8724 - val_loss: 0.3274 - val_accuracy: 0.8554\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2876 - accuracy: 0.8790\n",
      "Epoch 17: val_accuracy did not improve from 0.86538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3025 - accuracy: 0.8715 - val_loss: 0.3271 - val_accuracy: 0.8646\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3198 - accuracy: 0.8629\n",
      "Epoch 18: val_accuracy did not improve from 0.86538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3027 - accuracy: 0.8732 - val_loss: 0.3234 - val_accuracy: 0.8631\n",
      "Epoch 19/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2918 - accuracy: 0.8772\n",
      "Epoch 19: val_accuracy did not improve from 0.86538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2924 - accuracy: 0.8774 - val_loss: 0.3290 - val_accuracy: 0.8654\n",
      "Epoch 20/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3416 - accuracy: 0.8548\n",
      "Epoch 20: val_accuracy did not improve from 0.86538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2913 - accuracy: 0.8797 - val_loss: 0.3543 - val_accuracy: 0.8377\n",
      "Epoch 21/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4174 - accuracy: 0.8145\n",
      "Epoch 21: val_accuracy improved from 0.86538 to 0.86692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2987 - accuracy: 0.8772 - val_loss: 0.3163 - val_accuracy: 0.8669\n",
      "Epoch 22/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2992 - accuracy: 0.8710\n",
      "Epoch 22: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2897 - accuracy: 0.8809 - val_loss: 0.3499 - val_accuracy: 0.8577\n",
      "Epoch 23/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3625 - accuracy: 0.8629\n",
      "Epoch 23: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2924 - accuracy: 0.8770 - val_loss: 0.3333 - val_accuracy: 0.8623\n",
      "Epoch 24/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3201 - accuracy: 0.8387\n",
      "Epoch 24: val_accuracy improved from 0.86692 to 0.87000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2819 - accuracy: 0.8824 - val_loss: 0.3189 - val_accuracy: 0.8700\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2068 - accuracy: 0.8952\n",
      "Epoch 25: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2862 - accuracy: 0.8805 - val_loss: 0.3276 - val_accuracy: 0.8700\n",
      "Epoch 26/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3248 - accuracy: 0.8790\n",
      "Epoch 26: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2972 - accuracy: 0.8753 - val_loss: 0.3321 - val_accuracy: 0.8585\n",
      "Epoch 27/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3411 - accuracy: 0.8468\n",
      "Epoch 27: val_accuracy improved from 0.87000 to 0.87154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2896 - accuracy: 0.8803 - val_loss: 0.3220 - val_accuracy: 0.8715\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1861 - accuracy: 0.9194\n",
      "Epoch 28: val_accuracy did not improve from 0.87154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2864 - accuracy: 0.8792 - val_loss: 0.3134 - val_accuracy: 0.8677\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2841 - accuracy: 0.8629\n",
      "Epoch 29: val_accuracy did not improve from 0.87154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2774 - accuracy: 0.8867 - val_loss: 0.3116 - val_accuracy: 0.8631\n",
      "Epoch 30/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2681 - accuracy: 0.8952\n",
      "Epoch 30: val_accuracy did not improve from 0.87154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2759 - accuracy: 0.8857 - val_loss: 0.3202 - val_accuracy: 0.8623\n",
      "Epoch 31/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2723 - accuracy: 0.8871\n",
      "Epoch 31: val_accuracy did not improve from 0.87154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2756 - accuracy: 0.8863 - val_loss: 0.3107 - val_accuracy: 0.8654\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2749 - accuracy: 0.8842\n",
      "Epoch 32: val_accuracy did not improve from 0.87154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2749 - accuracy: 0.8842 - val_loss: 0.3241 - val_accuracy: 0.8715\n",
      "Epoch 33/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2726 - accuracy: 0.8871\n",
      "Epoch 33: val_accuracy did not improve from 0.87154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2804 - accuracy: 0.8851 - val_loss: 0.3118 - val_accuracy: 0.8669\n",
      "Epoch 34/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1987 - accuracy: 0.9194\n",
      "Epoch 34: val_accuracy did not improve from 0.87154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2756 - accuracy: 0.8861 - val_loss: 0.3165 - val_accuracy: 0.8692\n",
      "Epoch 35/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3118 - accuracy: 0.8790\n",
      "Epoch 35: val_accuracy did not improve from 0.87154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2743 - accuracy: 0.8861 - val_loss: 0.3230 - val_accuracy: 0.8600\n",
      "Epoch 36/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3557 - accuracy: 0.8468\n",
      "Epoch 36: val_accuracy did not improve from 0.87154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2724 - accuracy: 0.8880 - val_loss: 0.3186 - val_accuracy: 0.8662\n",
      "Epoch 37/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2424 - accuracy: 0.9113\n",
      "Epoch 37: val_accuracy did not improve from 0.87154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2702 - accuracy: 0.8869 - val_loss: 0.3083 - val_accuracy: 0.8654\n",
      "Epoch 38/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2511 - accuracy: 0.8871\n",
      "Epoch 38: val_accuracy did not improve from 0.87154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2708 - accuracy: 0.8899 - val_loss: 0.3080 - val_accuracy: 0.8646\n",
      "Epoch 39/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3421 - accuracy: 0.8629\n",
      "Epoch 39: val_accuracy did not improve from 0.87154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.8888 - val_loss: 0.3126 - val_accuracy: 0.8708\n",
      "Epoch 40/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2866 - accuracy: 0.9032\n",
      "Epoch 40: val_accuracy did not improve from 0.87154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2673 - accuracy: 0.8919 - val_loss: 0.3267 - val_accuracy: 0.8692\n",
      "Epoch 41/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1758 - accuracy: 0.9435\n",
      "Epoch 41: val_accuracy improved from 0.87154 to 0.87385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2746 - accuracy: 0.8842 - val_loss: 0.3139 - val_accuracy: 0.8738\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2823 - accuracy: 0.8629\n",
      "Epoch 42: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2662 - accuracy: 0.8897 - val_loss: 0.3106 - val_accuracy: 0.8738\n",
      "Epoch 43/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2643 - accuracy: 0.8889\n",
      "Epoch 43: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2631 - accuracy: 0.8892 - val_loss: 0.3076 - val_accuracy: 0.8723\n",
      "Epoch 44/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2708 - accuracy: 0.8867\n",
      "Epoch 44: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2702 - accuracy: 0.8865 - val_loss: 0.3179 - val_accuracy: 0.8592\n",
      "Epoch 45/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2744 - accuracy: 0.8629\n",
      "Epoch 45: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2698 - accuracy: 0.8880 - val_loss: 0.3053 - val_accuracy: 0.8723\n",
      "Epoch 46/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2424 - accuracy: 0.9113\n",
      "Epoch 46: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2624 - accuracy: 0.8919 - val_loss: 0.3926 - val_accuracy: 0.8331\n",
      "Epoch 47/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3121 - accuracy: 0.8871\n",
      "Epoch 47: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.8922 - val_loss: 0.3077 - val_accuracy: 0.8731\n",
      "Epoch 48/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2777 - accuracy: 0.8807\n",
      "Epoch 48: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2749 - accuracy: 0.8820 - val_loss: 0.3086 - val_accuracy: 0.8662\n",
      "Epoch 49/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3187 - accuracy: 0.8306\n",
      "Epoch 49: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.8909 - val_loss: 0.3777 - val_accuracy: 0.8431\n",
      "Epoch 50/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3758 - accuracy: 0.8548\n",
      "Epoch 50: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2833 - accuracy: 0.8845 - val_loss: 0.3130 - val_accuracy: 0.8685\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2673 - accuracy: 0.9274\n",
      "Epoch 51: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.8944 - val_loss: 0.3376 - val_accuracy: 0.8577\n",
      "Epoch 52/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2936 - accuracy: 0.8548\n",
      "Epoch 52: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2612 - accuracy: 0.8971 - val_loss: 0.3074 - val_accuracy: 0.8654\n",
      "Epoch 53/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2785 - accuracy: 0.8871\n",
      "Epoch 53: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2524 - accuracy: 0.8967 - val_loss: 0.3753 - val_accuracy: 0.8531\n",
      "Epoch 54/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2821 - accuracy: 0.8871\n",
      "Epoch 54: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2551 - accuracy: 0.8969 - val_loss: 0.3157 - val_accuracy: 0.8685\n",
      "Epoch 55/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2779 - accuracy: 0.8871\n",
      "Epoch 55: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.8942 - val_loss: 0.3147 - val_accuracy: 0.8662\n",
      "Epoch 56/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2084 - accuracy: 0.9113\n",
      "Epoch 56: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.8986 - val_loss: 0.3051 - val_accuracy: 0.8700\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2814 - accuracy: 0.9032\n",
      "Epoch 57: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2518 - accuracy: 0.8959 - val_loss: 0.3199 - val_accuracy: 0.8662\n",
      "Epoch 58/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2058 - accuracy: 0.9194\n",
      "Epoch 58: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.8980 - val_loss: 0.3203 - val_accuracy: 0.8708\n",
      "Epoch 59/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2717 - accuracy: 0.8952\n",
      "Epoch 59: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.9013 - val_loss: 0.3102 - val_accuracy: 0.8669\n",
      "Epoch 60/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1744 - accuracy: 0.9113\n",
      "Epoch 60: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8976 - val_loss: 0.3102 - val_accuracy: 0.8715\n",
      "Epoch 61/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1932 - accuracy: 0.9435\n",
      "Epoch 61: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.9007 - val_loss: 0.3104 - val_accuracy: 0.8723\n",
      "Epoch 62/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3297 - accuracy: 0.8629\n",
      "Epoch 62: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.9021 - val_loss: 0.3145 - val_accuracy: 0.8723\n",
      "Epoch 63/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2543 - accuracy: 0.9032\n",
      "Epoch 63: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2437 - accuracy: 0.9028 - val_loss: 0.3203 - val_accuracy: 0.8654\n",
      "Epoch 64/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1529 - accuracy: 0.9274\n",
      "Epoch 64: val_accuracy improved from 0.87385 to 0.87615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2571 - accuracy: 0.8938 - val_loss: 0.3103 - val_accuracy: 0.8762\n",
      "Epoch 65/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2770 - accuracy: 0.8710\n",
      "Epoch 65: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2387 - accuracy: 0.9038 - val_loss: 0.3081 - val_accuracy: 0.8669\n",
      "Epoch 66/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2122 - accuracy: 0.9355\n",
      "Epoch 66: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.9011 - val_loss: 0.3105 - val_accuracy: 0.8669\n",
      "Epoch 67/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2144 - accuracy: 0.8952\n",
      "Epoch 67: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.9017 - val_loss: 0.3190 - val_accuracy: 0.8692\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2774 - accuracy: 0.8952\n",
      "Epoch 68: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2383 - accuracy: 0.9063 - val_loss: 0.3137 - val_accuracy: 0.8692\n",
      "Epoch 69/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2256 - accuracy: 0.9194\n",
      "Epoch 69: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2342 - accuracy: 0.9059 - val_loss: 0.3131 - val_accuracy: 0.8738\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3022 - accuracy: 0.8871\n",
      "Epoch 70: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2377 - accuracy: 0.9021 - val_loss: 0.3160 - val_accuracy: 0.8677\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1984 - accuracy: 0.9435\n",
      "Epoch 71: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2415 - accuracy: 0.9015 - val_loss: 0.3205 - val_accuracy: 0.8669\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2820 - accuracy: 0.8629\n",
      "Epoch 72: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2330 - accuracy: 0.9074 - val_loss: 0.3124 - val_accuracy: 0.8662\n",
      "Epoch 73/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1966 - accuracy: 0.9194\n",
      "Epoch 73: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8999 - val_loss: 0.3165 - val_accuracy: 0.8692\n",
      "Epoch 74/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2197 - accuracy: 0.9194\n",
      "Epoch 74: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2326 - accuracy: 0.9024 - val_loss: 0.3252 - val_accuracy: 0.8662\n",
      "Epoch 75/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2489 - accuracy: 0.9274\n",
      "Epoch 75: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2397 - accuracy: 0.9061 - val_loss: 0.3284 - val_accuracy: 0.8692\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2312 - accuracy: 0.8952\n",
      "Epoch 76: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2340 - accuracy: 0.9065 - val_loss: 0.3229 - val_accuracy: 0.8723\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1987 - accuracy: 0.9194\n",
      "Epoch 77: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2348 - accuracy: 0.9067 - val_loss: 0.3188 - val_accuracy: 0.8731\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2388 - accuracy: 0.9113\n",
      "Epoch 78: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2347 - accuracy: 0.9048 - val_loss: 0.3110 - val_accuracy: 0.8646\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2461 - accuracy: 0.8871\n",
      "Epoch 79: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2368 - accuracy: 0.9034 - val_loss: 0.3238 - val_accuracy: 0.8623\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3155 - accuracy: 0.8548\n",
      "Epoch 80: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.9099 - val_loss: 0.3118 - val_accuracy: 0.8692\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2108 - accuracy: 0.8952\n",
      "Epoch 81: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2301 - accuracy: 0.9053 - val_loss: 0.3138 - val_accuracy: 0.8662\n",
      "Epoch 82/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1709 - accuracy: 0.9274\n",
      "Epoch 82: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2388 - accuracy: 0.9026 - val_loss: 0.3643 - val_accuracy: 0.8492\n",
      "Epoch 83/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2363 - accuracy: 0.9028\n",
      "Epoch 83: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2365 - accuracy: 0.9013 - val_loss: 0.3389 - val_accuracy: 0.8585\n",
      "Epoch 84/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2974 - accuracy: 0.8952\n",
      "Epoch 84: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2289 - accuracy: 0.9053 - val_loss: 0.3277 - val_accuracy: 0.8708\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2667 - accuracy: 0.8871\n",
      "Epoch 85: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2272 - accuracy: 0.9051 - val_loss: 0.3234 - val_accuracy: 0.8685\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2038 - accuracy: 0.8952\n",
      "Epoch 86: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2349 - accuracy: 0.9057 - val_loss: 0.3334 - val_accuracy: 0.8669\n",
      "Epoch 87/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2898 - accuracy: 0.8790\n",
      "Epoch 87: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2252 - accuracy: 0.9109 - val_loss: 0.3405 - val_accuracy: 0.8677\n",
      "Epoch 88/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2926 - accuracy: 0.9113\n",
      "Epoch 88: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2309 - accuracy: 0.9053 - val_loss: 0.3169 - val_accuracy: 0.8685\n",
      "Epoch 89/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2233 - accuracy: 0.9068\n",
      "Epoch 89: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2243 - accuracy: 0.9088 - val_loss: 0.3354 - val_accuracy: 0.8669\n",
      "Epoch 90/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2012 - accuracy: 0.9274\n",
      "Epoch 90: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2253 - accuracy: 0.9042 - val_loss: 0.3212 - val_accuracy: 0.8662\n",
      "Epoch 91/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1743 - accuracy: 0.9355\n",
      "Epoch 91: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2187 - accuracy: 0.9111 - val_loss: 0.3126 - val_accuracy: 0.8677\n",
      "Epoch 92/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1756 - accuracy: 0.9274\n",
      "Epoch 92: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 0.9088 - val_loss: 0.3199 - val_accuracy: 0.8677\n",
      "Epoch 93/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2600 - accuracy: 0.8952\n",
      "Epoch 93: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2273 - accuracy: 0.9099 - val_loss: 0.3339 - val_accuracy: 0.8677\n",
      "Epoch 94/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1428 - accuracy: 0.9435\n",
      "Epoch 94: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2403 - accuracy: 0.8978 - val_loss: 0.3526 - val_accuracy: 0.8608\n",
      "Epoch 95/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2439 - accuracy: 0.9032\n",
      "Epoch 95: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2273 - accuracy: 0.9078 - val_loss: 0.3268 - val_accuracy: 0.8646\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2038 - accuracy: 0.8952\n",
      "Epoch 96: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2144 - accuracy: 0.9150 - val_loss: 0.3210 - val_accuracy: 0.8623\n",
      "Epoch 97/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2219 - accuracy: 0.9274\n",
      "Epoch 97: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2137 - accuracy: 0.9132 - val_loss: 0.3520 - val_accuracy: 0.8608\n",
      "Epoch 98/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2363 - accuracy: 0.8871\n",
      "Epoch 98: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2168 - accuracy: 0.9088 - val_loss: 0.3581 - val_accuracy: 0.8577\n",
      "Epoch 99/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2505 - accuracy: 0.8871\n",
      "Epoch 99: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2229 - accuracy: 0.9063 - val_loss: 0.3311 - val_accuracy: 0.8585\n",
      "Epoch 100/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2853 - accuracy: 0.8710\n",
      "Epoch 100: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.9055 - val_loss: 0.3512 - val_accuracy: 0.8600\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2099 - accuracy: 0.9194\n",
      "Epoch 101: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2158 - accuracy: 0.9113 - val_loss: 0.3262 - val_accuracy: 0.8700\n",
      "Epoch 102/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2123 - accuracy: 0.9113\n",
      "Epoch 102: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2068 - accuracy: 0.9153 - val_loss: 0.3241 - val_accuracy: 0.8646\n",
      "Epoch 103/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2074 - accuracy: 0.9160\n",
      "Epoch 103: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2068 - accuracy: 0.9165 - val_loss: 0.3458 - val_accuracy: 0.8677\n",
      "Epoch 104/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1605 - accuracy: 0.9274\n",
      "Epoch 104: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2053 - accuracy: 0.9151 - val_loss: 0.3237 - val_accuracy: 0.8677\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1844 - accuracy: 0.9355\n",
      "Epoch 105: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2108 - accuracy: 0.9165 - val_loss: 0.3350 - val_accuracy: 0.8746\n",
      "Epoch 106/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2092 - accuracy: 0.9151\n",
      "Epoch 106: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2042 - accuracy: 0.9180 - val_loss: 0.3529 - val_accuracy: 0.8677\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1714 - accuracy: 0.9355\n",
      "Epoch 107: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2030 - accuracy: 0.9188 - val_loss: 0.3429 - val_accuracy: 0.8685\n",
      "Epoch 108/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1768 - accuracy: 0.9274\n",
      "Epoch 108: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2107 - accuracy: 0.9128 - val_loss: 0.3529 - val_accuracy: 0.8623\n",
      "Epoch 109/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2503 - accuracy: 0.9194\n",
      "Epoch 109: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2024 - accuracy: 0.9182 - val_loss: 0.3276 - val_accuracy: 0.8669\n",
      "Epoch 110/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2040 - accuracy: 0.9161\n",
      "Epoch 110: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2042 - accuracy: 0.9159 - val_loss: 0.3434 - val_accuracy: 0.8738\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1064 - accuracy: 0.9677\n",
      "Epoch 111: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2122 - accuracy: 0.9101 - val_loss: 0.3763 - val_accuracy: 0.8600\n",
      "Epoch 112/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2393 - accuracy: 0.8871\n",
      "Epoch 112: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2062 - accuracy: 0.9155 - val_loss: 0.3467 - val_accuracy: 0.8631\n",
      "Epoch 113/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1797 - accuracy: 0.9355\n",
      "Epoch 113: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1979 - accuracy: 0.9200 - val_loss: 0.3534 - val_accuracy: 0.8631\n",
      "Epoch 114/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2164 - accuracy: 0.9113\n",
      "Epoch 114: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2004 - accuracy: 0.9196 - val_loss: 0.3480 - val_accuracy: 0.8623\n",
      "Epoch 115/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1708 - accuracy: 0.9355\n",
      "Epoch 115: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1945 - accuracy: 0.9176 - val_loss: 0.3527 - val_accuracy: 0.8615\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2381 - accuracy: 0.8952\n",
      "Epoch 116: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1980 - accuracy: 0.9209 - val_loss: 0.3294 - val_accuracy: 0.8692\n",
      "Epoch 117/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2200 - accuracy: 0.9194\n",
      "Epoch 117: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1917 - accuracy: 0.9215 - val_loss: 0.3499 - val_accuracy: 0.8623\n",
      "Epoch 118/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1740 - accuracy: 0.9274\n",
      "Epoch 118: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.9238 - val_loss: 0.3559 - val_accuracy: 0.8715\n",
      "Epoch 119/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2289 - accuracy: 0.9194\n",
      "Epoch 119: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2184 - accuracy: 0.9063 - val_loss: 0.4066 - val_accuracy: 0.8438\n",
      "Epoch 120/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3229 - accuracy: 0.8790\n",
      "Epoch 120: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.9076 - val_loss: 0.3430 - val_accuracy: 0.8631\n",
      "Epoch 121/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1653 - accuracy: 0.9194\n",
      "Epoch 121: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2077 - accuracy: 0.9144 - val_loss: 0.3338 - val_accuracy: 0.8692\n",
      "Epoch 122/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3091 - accuracy: 0.8871\n",
      "Epoch 122: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1975 - accuracy: 0.9201 - val_loss: 0.3458 - val_accuracy: 0.8631\n",
      "Epoch 123/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1797 - accuracy: 0.9194\n",
      "Epoch 123: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.9240 - val_loss: 0.3492 - val_accuracy: 0.8677\n",
      "Epoch 124/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2014 - accuracy: 0.9194\n",
      "Epoch 124: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.9257 - val_loss: 0.3531 - val_accuracy: 0.8592\n",
      "Epoch 125/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1399 - accuracy: 0.9516\n",
      "Epoch 125: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1839 - accuracy: 0.9277 - val_loss: 0.3557 - val_accuracy: 0.8654\n",
      "Epoch 126/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1378 - accuracy: 0.9516\n",
      "Epoch 126: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9263 - val_loss: 0.3527 - val_accuracy: 0.8615\n",
      "Epoch 127/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2133 - accuracy: 0.9032\n",
      "Epoch 127: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1894 - accuracy: 0.9215 - val_loss: 0.3715 - val_accuracy: 0.8638\n",
      "Epoch 128/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1607 - accuracy: 0.9194\n",
      "Epoch 128: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.9238 - val_loss: 0.3403 - val_accuracy: 0.8638\n",
      "Epoch 129/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1794 - accuracy: 0.9435\n",
      "Epoch 129: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1969 - accuracy: 0.9178 - val_loss: 0.3456 - val_accuracy: 0.8600\n",
      "Epoch 130/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1973 - accuracy: 0.9435\n",
      "Epoch 130: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.9265 - val_loss: 0.3574 - val_accuracy: 0.8608\n",
      "Epoch 131/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1566 - accuracy: 0.9113\n",
      "Epoch 131: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.9288 - val_loss: 0.3535 - val_accuracy: 0.8608\n",
      "Epoch 132/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2002 - accuracy: 0.9194\n",
      "Epoch 132: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1803 - accuracy: 0.9259 - val_loss: 0.3738 - val_accuracy: 0.8615\n",
      "Epoch 133/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2075 - accuracy: 0.9032\n",
      "Epoch 133: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1788 - accuracy: 0.9284 - val_loss: 0.3710 - val_accuracy: 0.8546\n",
      "Epoch 134/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2011 - accuracy: 0.9194\n",
      "Epoch 134: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2000 - accuracy: 0.9155 - val_loss: 0.3478 - val_accuracy: 0.8638\n",
      "Epoch 135/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2204 - accuracy: 0.9113\n",
      "Epoch 135: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1874 - accuracy: 0.9236 - val_loss: 0.3620 - val_accuracy: 0.8631\n",
      "Epoch 136/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1013 - accuracy: 0.9516\n",
      "Epoch 136: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1772 - accuracy: 0.9303 - val_loss: 0.3632 - val_accuracy: 0.8554\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2087 - accuracy: 0.9113\n",
      "Epoch 137: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1764 - accuracy: 0.9294 - val_loss: 0.3809 - val_accuracy: 0.8577\n",
      "Epoch 138/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1219 - accuracy: 0.9597\n",
      "Epoch 138: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1881 - accuracy: 0.9209 - val_loss: 0.4164 - val_accuracy: 0.8477\n",
      "Epoch 139/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1668 - accuracy: 0.9113\n",
      "Epoch 139: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1816 - accuracy: 0.9259 - val_loss: 0.3622 - val_accuracy: 0.8523\n",
      "Epoch 140/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1641 - accuracy: 0.9516\n",
      "Epoch 140: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.9200 - val_loss: 0.3800 - val_accuracy: 0.8615\n",
      "Epoch 141/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1664 - accuracy: 0.9274\n",
      "Epoch 141: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.9286 - val_loss: 0.3690 - val_accuracy: 0.8538\n",
      "Epoch 142/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1686 - accuracy: 0.9113\n",
      "Epoch 142: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1874 - accuracy: 0.9255 - val_loss: 0.3784 - val_accuracy: 0.8515\n",
      "Epoch 143/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1696 - accuracy: 0.9435\n",
      "Epoch 143: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1855 - accuracy: 0.9248 - val_loss: 0.4014 - val_accuracy: 0.8569\n",
      "Epoch 144/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1965 - accuracy: 0.9274\n",
      "Epoch 144: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1782 - accuracy: 0.9267 - val_loss: 0.3809 - val_accuracy: 0.8585\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1465 - accuracy: 0.9194\n",
      "Epoch 145: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1735 - accuracy: 0.9290 - val_loss: 0.4114 - val_accuracy: 0.8623\n",
      "Epoch 146/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1812 - accuracy: 0.9435\n",
      "Epoch 146: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1797 - accuracy: 0.9265 - val_loss: 0.3884 - val_accuracy: 0.8608\n",
      "Epoch 147/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1777 - accuracy: 0.9290\n",
      "Epoch 147: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1786 - accuracy: 0.9280 - val_loss: 0.3790 - val_accuracy: 0.8600\n",
      "Epoch 148/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1753 - accuracy: 0.9194\n",
      "Epoch 148: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1708 - accuracy: 0.9294 - val_loss: 0.4099 - val_accuracy: 0.8569\n",
      "Epoch 149/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1876 - accuracy: 0.9194\n",
      "Epoch 149: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.9209 - val_loss: 0.3821 - val_accuracy: 0.8585\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1747 - accuracy: 0.9113\n",
      "Epoch 150: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1687 - accuracy: 0.9317 - val_loss: 0.4193 - val_accuracy: 0.8631\n",
      "Epoch 151/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1254 - accuracy: 0.9597\n",
      "Epoch 151: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1644 - accuracy: 0.9388 - val_loss: 0.3787 - val_accuracy: 0.8546\n",
      "Epoch 152/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1923 - accuracy: 0.9274\n",
      "Epoch 152: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1784 - accuracy: 0.9280 - val_loss: 0.4081 - val_accuracy: 0.8615\n",
      "Epoch 153/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1643 - accuracy: 0.9325\n",
      "Epoch 153: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1628 - accuracy: 0.9332 - val_loss: 0.3933 - val_accuracy: 0.8623\n",
      "Epoch 154/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1859 - accuracy: 0.9194\n",
      "Epoch 154: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1720 - accuracy: 0.9294 - val_loss: 0.3889 - val_accuracy: 0.8569\n",
      "Epoch 155/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2273 - accuracy: 0.9032\n",
      "Epoch 155: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1735 - accuracy: 0.9273 - val_loss: 0.3762 - val_accuracy: 0.8638\n",
      "Epoch 156/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1780 - accuracy: 0.9113\n",
      "Epoch 156: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1685 - accuracy: 0.9328 - val_loss: 0.3915 - val_accuracy: 0.8569\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001E49C1B13A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 22s - loss: 4.0838 - accuracy: 0.5403\n",
      "Epoch 1: val_accuracy improved from -inf to 0.61385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 10ms/step - loss: 0.9025 - accuracy: 0.5638 - val_loss: 0.6476 - val_accuracy: 0.6138\n",
      "Epoch 2/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.6532 - accuracy: 0.5565\n",
      "Epoch 2: val_accuracy improved from 0.61385 to 0.74846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.7246 - val_loss: 0.5296 - val_accuracy: 0.7485\n",
      "Epoch 3/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.5857 - accuracy: 0.6290\n",
      "Epoch 3: val_accuracy improved from 0.74846 to 0.82923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7924 - val_loss: 0.4217 - val_accuracy: 0.8292\n",
      "Epoch 4/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4361 - accuracy: 0.7823\n",
      "Epoch 4: val_accuracy improved from 0.82923 to 0.83385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8336 - val_loss: 0.3851 - val_accuracy: 0.8338\n",
      "Epoch 5/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.3773 - accuracy: 0.8430\n",
      "Epoch 5: val_accuracy improved from 0.83385 to 0.84385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3707 - accuracy: 0.8491 - val_loss: 0.3652 - val_accuracy: 0.8438\n",
      "Epoch 6/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3378 - accuracy: 0.8468\n",
      "Epoch 6: val_accuracy did not improve from 0.84385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8522 - val_loss: 0.3591 - val_accuracy: 0.8423\n",
      "Epoch 7/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3181 - accuracy: 0.8548\n",
      "Epoch 7: val_accuracy improved from 0.84385 to 0.85077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3435 - accuracy: 0.8593 - val_loss: 0.3552 - val_accuracy: 0.8508\n",
      "Epoch 8/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4096 - accuracy: 0.8548\n",
      "Epoch 8: val_accuracy did not improve from 0.85077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3406 - accuracy: 0.8630 - val_loss: 0.3487 - val_accuracy: 0.8446\n",
      "Epoch 9/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3535 - accuracy: 0.8548\n",
      "Epoch 9: val_accuracy improved from 0.85077 to 0.85615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8599 - val_loss: 0.3403 - val_accuracy: 0.8562\n",
      "Epoch 10/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.3145 - accuracy: 0.8710\n",
      "Epoch 10: val_accuracy improved from 0.85615 to 0.86000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3249 - accuracy: 0.8676 - val_loss: 0.3370 - val_accuracy: 0.8600\n",
      "Epoch 11/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3475 - accuracy: 0.8952\n",
      "Epoch 11: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8645 - val_loss: 0.3701 - val_accuracy: 0.8362\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3335 - accuracy: 0.8710\n",
      "Epoch 12: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8603 - val_loss: 0.3438 - val_accuracy: 0.8485\n",
      "Epoch 13/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2982 - accuracy: 0.8710\n",
      "Epoch 13: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3335 - accuracy: 0.8586 - val_loss: 0.3572 - val_accuracy: 0.8438\n",
      "Epoch 14/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.3173 - accuracy: 0.8692\n",
      "Epoch 14: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.8690 - val_loss: 0.3405 - val_accuracy: 0.8462\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2932 - accuracy: 0.8548\n",
      "Epoch 15: val_accuracy improved from 0.86000 to 0.86231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8663 - val_loss: 0.3311 - val_accuracy: 0.8623\n",
      "Epoch 16/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3675 - accuracy: 0.8306\n",
      "Epoch 16: val_accuracy did not improve from 0.86231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.8699 - val_loss: 0.3334 - val_accuracy: 0.8577\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4624 - accuracy: 0.8145\n",
      "Epoch 17: val_accuracy did not improve from 0.86231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8736 - val_loss: 0.3336 - val_accuracy: 0.8623\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2790 - accuracy: 0.8790\n",
      "Epoch 18: val_accuracy improved from 0.86231 to 0.86308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8647 - val_loss: 0.3304 - val_accuracy: 0.8631\n",
      "Epoch 19/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.3153 - accuracy: 0.8650\n",
      "Epoch 19: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8665 - val_loss: 0.3652 - val_accuracy: 0.8277\n",
      "Epoch 20/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3216 - accuracy: 0.8548\n",
      "Epoch 20: val_accuracy improved from 0.86308 to 0.86462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8749 - val_loss: 0.3319 - val_accuracy: 0.8646\n",
      "Epoch 21/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3189 - accuracy: 0.8952\n",
      "Epoch 21: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8715 - val_loss: 0.3494 - val_accuracy: 0.8385\n",
      "Epoch 22/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3037 - accuracy: 0.8748\n",
      "Epoch 22: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3044 - accuracy: 0.8732 - val_loss: 0.3325 - val_accuracy: 0.8631\n",
      "Epoch 23/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2152 - accuracy: 0.9032\n",
      "Epoch 23: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3002 - accuracy: 0.8772 - val_loss: 0.3289 - val_accuracy: 0.8646\n",
      "Epoch 24/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3050 - accuracy: 0.8747\n",
      "Epoch 24: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3042 - accuracy: 0.8749 - val_loss: 0.3320 - val_accuracy: 0.8569\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2926 - accuracy: 0.8468\n",
      "Epoch 25: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 0.8693 - val_loss: 0.3358 - val_accuracy: 0.8546\n",
      "Epoch 26/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3174 - accuracy: 0.8548\n",
      "Epoch 26: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.8770 - val_loss: 0.3320 - val_accuracy: 0.8631\n",
      "Epoch 27/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3759 - accuracy: 0.8548\n",
      "Epoch 27: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2971 - accuracy: 0.8759 - val_loss: 0.3367 - val_accuracy: 0.8631\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3334 - accuracy: 0.8226\n",
      "Epoch 28: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2996 - accuracy: 0.8747 - val_loss: 0.3325 - val_accuracy: 0.8569\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3365 - accuracy: 0.8226\n",
      "Epoch 29: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2954 - accuracy: 0.8759 - val_loss: 0.3322 - val_accuracy: 0.8631\n",
      "Epoch 30/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2915 - accuracy: 0.8768\n",
      "Epoch 30: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2918 - accuracy: 0.8772 - val_loss: 0.3453 - val_accuracy: 0.8577\n",
      "Epoch 31/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3357 - accuracy: 0.8468\n",
      "Epoch 31: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2968 - accuracy: 0.8769 - val_loss: 0.3309 - val_accuracy: 0.8646\n",
      "Epoch 32/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2971 - accuracy: 0.8790\n",
      "Epoch 32: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2964 - accuracy: 0.8732 - val_loss: 0.3733 - val_accuracy: 0.8446\n",
      "Epoch 33/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3287 - accuracy: 0.8387\n",
      "Epoch 33: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2963 - accuracy: 0.8792 - val_loss: 0.3429 - val_accuracy: 0.8585\n",
      "Epoch 34/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2604 - accuracy: 0.9274\n",
      "Epoch 34: val_accuracy improved from 0.86462 to 0.86692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2878 - accuracy: 0.8853 - val_loss: 0.3280 - val_accuracy: 0.8669\n",
      "Epoch 35/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2941 - accuracy: 0.8804\n",
      "Epoch 35: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2893 - accuracy: 0.8809 - val_loss: 0.3248 - val_accuracy: 0.8554\n",
      "Epoch 36/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2873 - accuracy: 0.8811\n",
      "Epoch 36: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2880 - accuracy: 0.8807 - val_loss: 0.3233 - val_accuracy: 0.8585\n",
      "Epoch 37/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3223 - accuracy: 0.8548\n",
      "Epoch 37: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2828 - accuracy: 0.8805 - val_loss: 0.3285 - val_accuracy: 0.8646\n",
      "Epoch 38/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2814 - accuracy: 0.8823\n",
      "Epoch 38: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2834 - accuracy: 0.8819 - val_loss: 0.3282 - val_accuracy: 0.8562\n",
      "Epoch 39/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2253 - accuracy: 0.8790\n",
      "Epoch 39: val_accuracy improved from 0.86692 to 0.86923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2831 - accuracy: 0.8811 - val_loss: 0.3217 - val_accuracy: 0.8692\n",
      "Epoch 40/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2811 - accuracy: 0.8857\n",
      "Epoch 40: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2805 - accuracy: 0.8861 - val_loss: 0.3224 - val_accuracy: 0.8592\n",
      "Epoch 41/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3387 - accuracy: 0.8952\n",
      "Epoch 41: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2797 - accuracy: 0.8824 - val_loss: 0.3186 - val_accuracy: 0.8631\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3356 - accuracy: 0.8790\n",
      "Epoch 42: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2906 - accuracy: 0.8736 - val_loss: 0.3267 - val_accuracy: 0.8662\n",
      "Epoch 43/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2408 - accuracy: 0.8871\n",
      "Epoch 43: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2822 - accuracy: 0.8817 - val_loss: 0.3180 - val_accuracy: 0.8654\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2649 - accuracy: 0.8952\n",
      "Epoch 44: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2803 - accuracy: 0.8849 - val_loss: 0.3224 - val_accuracy: 0.8692\n",
      "Epoch 45/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3281 - accuracy: 0.8629\n",
      "Epoch 45: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.8855 - val_loss: 0.3104 - val_accuracy: 0.8669\n",
      "Epoch 46/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2057 - accuracy: 0.9274\n",
      "Epoch 46: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2837 - accuracy: 0.8844 - val_loss: 0.3348 - val_accuracy: 0.8515\n",
      "Epoch 47/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3154 - accuracy: 0.8637\n",
      "Epoch 47: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8634 - val_loss: 0.3068 - val_accuracy: 0.8692\n",
      "Epoch 48/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3505 - accuracy: 0.8468\n",
      "Epoch 48: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2667 - accuracy: 0.8922 - val_loss: 0.3271 - val_accuracy: 0.8638\n",
      "Epoch 49/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2585 - accuracy: 0.9113\n",
      "Epoch 49: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2714 - accuracy: 0.8844 - val_loss: 0.3155 - val_accuracy: 0.8677\n",
      "Epoch 50/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2107 - accuracy: 0.8952\n",
      "Epoch 50: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2716 - accuracy: 0.8909 - val_loss: 0.3201 - val_accuracy: 0.8623\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2767 - accuracy: 0.8871\n",
      "Epoch 51: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2605 - accuracy: 0.8942 - val_loss: 0.3054 - val_accuracy: 0.8638\n",
      "Epoch 52/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2459 - accuracy: 0.9032\n",
      "Epoch 52: val_accuracy improved from 0.86923 to 0.87000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2692 - accuracy: 0.8894 - val_loss: 0.3208 - val_accuracy: 0.8700\n",
      "Epoch 53/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2610 - accuracy: 0.8900\n",
      "Epoch 53: val_accuracy improved from 0.87000 to 0.87385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2599 - accuracy: 0.8915 - val_loss: 0.3038 - val_accuracy: 0.8738\n",
      "Epoch 54/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2066 - accuracy: 0.9032\n",
      "Epoch 54: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2541 - accuracy: 0.8980 - val_loss: 0.3008 - val_accuracy: 0.8708\n",
      "Epoch 55/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3179 - accuracy: 0.8790\n",
      "Epoch 55: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2560 - accuracy: 0.8963 - val_loss: 0.3108 - val_accuracy: 0.8654\n",
      "Epoch 56/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2948 - accuracy: 0.8710\n",
      "Epoch 56: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 0.8946 - val_loss: 0.3153 - val_accuracy: 0.8738\n",
      "Epoch 57/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2453 - accuracy: 0.8997\n",
      "Epoch 57: val_accuracy improved from 0.87385 to 0.87692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2482 - accuracy: 0.8982 - val_loss: 0.2972 - val_accuracy: 0.8769\n",
      "Epoch 58/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2599 - accuracy: 0.8920\n",
      "Epoch 58: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 0.8917 - val_loss: 0.3193 - val_accuracy: 0.8692\n",
      "Epoch 59/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3306 - accuracy: 0.8468\n",
      "Epoch 59: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2550 - accuracy: 0.8949 - val_loss: 0.3171 - val_accuracy: 0.8731\n",
      "Epoch 60/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1996 - accuracy: 0.9355\n",
      "Epoch 60: val_accuracy improved from 0.87692 to 0.87769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.8999 - val_loss: 0.3050 - val_accuracy: 0.8777\n",
      "Epoch 61/1000\n",
      "29/42 [===================>..........] - ETA: 0s - loss: 0.2559 - accuracy: 0.8943\n",
      "Epoch 61: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2529 - accuracy: 0.8951 - val_loss: 0.2968 - val_accuracy: 0.8738\n",
      "Epoch 62/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1888 - accuracy: 0.9435\n",
      "Epoch 62: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.9026 - val_loss: 0.3030 - val_accuracy: 0.8738\n",
      "Epoch 63/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3168 - accuracy: 0.8871\n",
      "Epoch 63: val_accuracy improved from 0.87769 to 0.88000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.9028 - val_loss: 0.3157 - val_accuracy: 0.8800\n",
      "Epoch 64/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1765 - accuracy: 0.9194\n",
      "Epoch 64: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.8974 - val_loss: 0.3313 - val_accuracy: 0.8654\n",
      "Epoch 65/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2572 - accuracy: 0.8979\n",
      "Epoch 65: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2555 - accuracy: 0.8978 - val_loss: 0.3078 - val_accuracy: 0.8631\n",
      "Epoch 66/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2999 - accuracy: 0.8710\n",
      "Epoch 66: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.9005 - val_loss: 0.3027 - val_accuracy: 0.8669\n",
      "Epoch 67/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2495 - accuracy: 0.8629\n",
      "Epoch 67: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2398 - accuracy: 0.9017 - val_loss: 0.2989 - val_accuracy: 0.8723\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1732 - accuracy: 0.9435\n",
      "Epoch 68: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2422 - accuracy: 0.9009 - val_loss: 0.3069 - val_accuracy: 0.8677\n",
      "Epoch 69/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2714 - accuracy: 0.8629\n",
      "Epoch 69: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2432 - accuracy: 0.8999 - val_loss: 0.2993 - val_accuracy: 0.8792\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2912 - accuracy: 0.8952\n",
      "Epoch 70: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2430 - accuracy: 0.9063 - val_loss: 0.3077 - val_accuracy: 0.8631\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1689 - accuracy: 0.9516\n",
      "Epoch 71: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.9023 - val_loss: 0.2953 - val_accuracy: 0.8708\n",
      "Epoch 72/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2401 - accuracy: 0.8997\n",
      "Epoch 72: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2413 - accuracy: 0.8994 - val_loss: 0.3065 - val_accuracy: 0.8715\n",
      "Epoch 73/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1994 - accuracy: 0.9274\n",
      "Epoch 73: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2412 - accuracy: 0.8992 - val_loss: 0.3394 - val_accuracy: 0.8631\n",
      "Epoch 74/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3305 - accuracy: 0.8710\n",
      "Epoch 74: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2419 - accuracy: 0.9032 - val_loss: 0.3037 - val_accuracy: 0.8769\n",
      "Epoch 75/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1714 - accuracy: 0.9355\n",
      "Epoch 75: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2400 - accuracy: 0.9019 - val_loss: 0.3015 - val_accuracy: 0.8738\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1797 - accuracy: 0.9274\n",
      "Epoch 76: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2360 - accuracy: 0.9038 - val_loss: 0.3337 - val_accuracy: 0.8631\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3383 - accuracy: 0.8548\n",
      "Epoch 77: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.9048 - val_loss: 0.3158 - val_accuracy: 0.8715\n",
      "Epoch 78/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2402 - accuracy: 0.9030\n",
      "Epoch 78: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2394 - accuracy: 0.9038 - val_loss: 0.3147 - val_accuracy: 0.8762\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2887 - accuracy: 0.9032\n",
      "Epoch 79: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2302 - accuracy: 0.9063 - val_loss: 0.3159 - val_accuracy: 0.8738\n",
      "Epoch 80/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2354 - accuracy: 0.9067\n",
      "Epoch 80: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2354 - accuracy: 0.9067 - val_loss: 0.2995 - val_accuracy: 0.8746\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1557 - accuracy: 0.9355\n",
      "Epoch 81: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2405 - accuracy: 0.9021 - val_loss: 0.3115 - val_accuracy: 0.8754\n",
      "Epoch 82/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1894 - accuracy: 0.9274\n",
      "Epoch 82: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2318 - accuracy: 0.9078 - val_loss: 0.3058 - val_accuracy: 0.8677\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2200 - accuracy: 0.9032\n",
      "Epoch 83: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2340 - accuracy: 0.9084 - val_loss: 0.3123 - val_accuracy: 0.8715\n",
      "Epoch 84/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3303 - accuracy: 0.8871\n",
      "Epoch 84: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2294 - accuracy: 0.9080 - val_loss: 0.3092 - val_accuracy: 0.8715\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2085 - accuracy: 0.8871\n",
      "Epoch 85: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2326 - accuracy: 0.9063 - val_loss: 0.3070 - val_accuracy: 0.8715\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3140 - accuracy: 0.8710\n",
      "Epoch 86: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2298 - accuracy: 0.9055 - val_loss: 0.3058 - val_accuracy: 0.8723\n",
      "Epoch 87/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1903 - accuracy: 0.8952\n",
      "Epoch 87: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2272 - accuracy: 0.9074 - val_loss: 0.3339 - val_accuracy: 0.8685\n",
      "Epoch 88/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2564 - accuracy: 0.8952\n",
      "Epoch 88: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2299 - accuracy: 0.9088 - val_loss: 0.3139 - val_accuracy: 0.8692\n",
      "Epoch 89/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2360 - accuracy: 0.9032\n",
      "Epoch 89: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2382 - accuracy: 0.9024 - val_loss: 0.3266 - val_accuracy: 0.8669\n",
      "Epoch 90/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2418 - accuracy: 0.9026\n",
      "Epoch 90: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2418 - accuracy: 0.9026 - val_loss: 0.3190 - val_accuracy: 0.8715\n",
      "Epoch 91/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2734 - accuracy: 0.8710\n",
      "Epoch 91: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2315 - accuracy: 0.9042 - val_loss: 0.3548 - val_accuracy: 0.8531\n",
      "Epoch 92/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3146 - accuracy: 0.8710\n",
      "Epoch 92: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 0.9055 - val_loss: 0.3014 - val_accuracy: 0.8731\n",
      "Epoch 93/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2309 - accuracy: 0.9065\n",
      "Epoch 93: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2284 - accuracy: 0.9080 - val_loss: 0.3119 - val_accuracy: 0.8762\n",
      "Epoch 94/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1515 - accuracy: 0.9516\n",
      "Epoch 94: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2272 - accuracy: 0.9103 - val_loss: 0.3043 - val_accuracy: 0.8700\n",
      "Epoch 95/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3109 - accuracy: 0.8790\n",
      "Epoch 95: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2318 - accuracy: 0.9061 - val_loss: 0.3086 - val_accuracy: 0.8700\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1463 - accuracy: 0.9516\n",
      "Epoch 96: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.9080 - val_loss: 0.3232 - val_accuracy: 0.8600\n",
      "Epoch 97/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2201 - accuracy: 0.9109\n",
      "Epoch 97: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2205 - accuracy: 0.9101 - val_loss: 0.3176 - val_accuracy: 0.8715\n",
      "Epoch 98/1000\n",
      "29/42 [===================>..........] - ETA: 0s - loss: 0.2184 - accuracy: 0.9127\n",
      "Epoch 98: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2185 - accuracy: 0.9115 - val_loss: 0.3084 - val_accuracy: 0.8715\n",
      "Epoch 99/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2243 - accuracy: 0.9194\n",
      "Epoch 99: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2179 - accuracy: 0.9126 - val_loss: 0.3121 - val_accuracy: 0.8731\n",
      "Epoch 100/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1736 - accuracy: 0.9194\n",
      "Epoch 100: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2117 - accuracy: 0.9165 - val_loss: 0.3156 - val_accuracy: 0.8700\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1931 - accuracy: 0.9194\n",
      "Epoch 101: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2217 - accuracy: 0.9113 - val_loss: 0.3855 - val_accuracy: 0.8469\n",
      "Epoch 102/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3313 - accuracy: 0.8468\n",
      "Epoch 102: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2284 - accuracy: 0.9057 - val_loss: 0.3130 - val_accuracy: 0.8708\n",
      "Epoch 103/1000\n",
      "30/42 [====================>.........] - ETA: 0s - loss: 0.2169 - accuracy: 0.9177\n",
      "Epoch 103: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2148 - accuracy: 0.9186 - val_loss: 0.3252 - val_accuracy: 0.8715\n",
      "Epoch 104/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1605 - accuracy: 0.9435\n",
      "Epoch 104: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2146 - accuracy: 0.9140 - val_loss: 0.3163 - val_accuracy: 0.8708\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2142 - accuracy: 0.9194\n",
      "Epoch 105: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2126 - accuracy: 0.9151 - val_loss: 0.3264 - val_accuracy: 0.8708\n",
      "Epoch 106/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1829 - accuracy: 0.9194\n",
      "Epoch 106: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2176 - accuracy: 0.9128 - val_loss: 0.3237 - val_accuracy: 0.8754\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1268 - accuracy: 0.9597\n",
      "Epoch 107: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2127 - accuracy: 0.9146 - val_loss: 0.3111 - val_accuracy: 0.8738\n",
      "Epoch 108/1000\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.2209 - accuracy: 0.9131\n",
      "Epoch 108: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2174 - accuracy: 0.9136 - val_loss: 0.3475 - val_accuracy: 0.8692\n",
      "Epoch 109/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1955 - accuracy: 0.9194\n",
      "Epoch 109: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2273 - accuracy: 0.9069 - val_loss: 0.3114 - val_accuracy: 0.8731\n",
      "Epoch 110/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1537 - accuracy: 0.9194\n",
      "Epoch 110: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2155 - accuracy: 0.9107 - val_loss: 0.3172 - val_accuracy: 0.8746\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1954 - accuracy: 0.9435\n",
      "Epoch 111: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2097 - accuracy: 0.9178 - val_loss: 0.3306 - val_accuracy: 0.8708\n",
      "Epoch 112/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2279 - accuracy: 0.9071\n",
      "Epoch 112: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2279 - accuracy: 0.9071 - val_loss: 0.3271 - val_accuracy: 0.8685\n",
      "Epoch 113/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2449 - accuracy: 0.9274\n",
      "Epoch 113: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2159 - accuracy: 0.9119 - val_loss: 0.3160 - val_accuracy: 0.8723\n",
      "Epoch 114/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2027 - accuracy: 0.9194\n",
      "Epoch 114: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2190 - accuracy: 0.9109 - val_loss: 0.3138 - val_accuracy: 0.8677\n",
      "Epoch 115/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2213 - accuracy: 0.9355\n",
      "Epoch 115: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2135 - accuracy: 0.9150 - val_loss: 0.3415 - val_accuracy: 0.8677\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1614 - accuracy: 0.9113\n",
      "Epoch 116: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2207 - accuracy: 0.9103 - val_loss: 0.3223 - val_accuracy: 0.8677\n",
      "Epoch 117/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1445 - accuracy: 0.9435\n",
      "Epoch 117: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2141 - accuracy: 0.9150 - val_loss: 0.3295 - val_accuracy: 0.8700\n",
      "Epoch 118/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2080 - accuracy: 0.9171\n",
      "Epoch 118: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2080 - accuracy: 0.9171 - val_loss: 0.3175 - val_accuracy: 0.8692\n",
      "Epoch 119/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2019 - accuracy: 0.9180\n",
      "Epoch 119: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2036 - accuracy: 0.9167 - val_loss: 0.3159 - val_accuracy: 0.8746\n",
      "Epoch 120/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1440 - accuracy: 0.9435\n",
      "Epoch 120: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2155 - accuracy: 0.9117 - val_loss: 0.3167 - val_accuracy: 0.8677\n",
      "Epoch 121/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2025 - accuracy: 0.9355\n",
      "Epoch 121: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1983 - accuracy: 0.9209 - val_loss: 0.3322 - val_accuracy: 0.8654\n",
      "Epoch 122/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2027 - accuracy: 0.9173\n",
      "Epoch 122: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2027 - accuracy: 0.9173 - val_loss: 0.3341 - val_accuracy: 0.8700\n",
      "Epoch 123/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2532 - accuracy: 0.8952\n",
      "Epoch 123: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2027 - accuracy: 0.9173 - val_loss: 0.3417 - val_accuracy: 0.8715\n",
      "Epoch 124/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2133 - accuracy: 0.9032\n",
      "Epoch 124: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2026 - accuracy: 0.9161 - val_loss: 0.3270 - val_accuracy: 0.8608\n",
      "Epoch 125/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1546 - accuracy: 0.9274\n",
      "Epoch 125: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2162 - accuracy: 0.9107 - val_loss: 0.3240 - val_accuracy: 0.8623\n",
      "Epoch 126/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1844 - accuracy: 0.9194\n",
      "Epoch 126: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2014 - accuracy: 0.9200 - val_loss: 0.3228 - val_accuracy: 0.8638\n",
      "Epoch 127/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1557 - accuracy: 0.9435\n",
      "Epoch 127: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2075 - accuracy: 0.9175 - val_loss: 0.3245 - val_accuracy: 0.8669\n",
      "Epoch 128/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1986 - accuracy: 0.9197\n",
      "Epoch 128: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9200 - val_loss: 0.3449 - val_accuracy: 0.8662\n",
      "Epoch 129/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2479 - accuracy: 0.8925\n",
      "Epoch 129: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2425 - accuracy: 0.8963 - val_loss: 0.3341 - val_accuracy: 0.8692\n",
      "Epoch 130/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1801 - accuracy: 0.9032\n",
      "Epoch 130: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2034 - accuracy: 0.9165 - val_loss: 0.3190 - val_accuracy: 0.8654\n",
      "Epoch 131/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1618 - accuracy: 0.9194\n",
      "Epoch 131: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1923 - accuracy: 0.9226 - val_loss: 0.3299 - val_accuracy: 0.8692\n",
      "Epoch 132/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2159 - accuracy: 0.9032\n",
      "Epoch 132: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2031 - accuracy: 0.9161 - val_loss: 0.3285 - val_accuracy: 0.8700\n",
      "Epoch 133/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2652 - accuracy: 0.9194\n",
      "Epoch 133: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1936 - accuracy: 0.9238 - val_loss: 0.3279 - val_accuracy: 0.8700\n",
      "Epoch 134/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1621 - accuracy: 0.9355\n",
      "Epoch 134: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1990 - accuracy: 0.9186 - val_loss: 0.3314 - val_accuracy: 0.8677\n",
      "Epoch 135/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2030 - accuracy: 0.9184\n",
      "Epoch 135: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2030 - accuracy: 0.9184 - val_loss: 0.3440 - val_accuracy: 0.8669\n",
      "Epoch 136/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2352 - accuracy: 0.8952\n",
      "Epoch 136: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.9225 - val_loss: 0.3374 - val_accuracy: 0.8577\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2441 - accuracy: 0.9032\n",
      "Epoch 137: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1952 - accuracy: 0.9221 - val_loss: 0.3367 - val_accuracy: 0.8646\n",
      "Epoch 138/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2010 - accuracy: 0.8952\n",
      "Epoch 138: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1895 - accuracy: 0.9236 - val_loss: 0.3314 - val_accuracy: 0.8700\n",
      "Epoch 139/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1917 - accuracy: 0.9274\n",
      "Epoch 139: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1972 - accuracy: 0.9194 - val_loss: 0.3378 - val_accuracy: 0.8692\n",
      "Epoch 140/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1989 - accuracy: 0.9194\n",
      "Epoch 140: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.9255 - val_loss: 0.3427 - val_accuracy: 0.8623\n",
      "Epoch 141/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1613 - accuracy: 0.9355\n",
      "Epoch 141: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1900 - accuracy: 0.9232 - val_loss: 0.3342 - val_accuracy: 0.8692\n",
      "Epoch 142/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1560 - accuracy: 0.9355\n",
      "Epoch 142: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.9261 - val_loss: 0.3281 - val_accuracy: 0.8708\n",
      "Epoch 143/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1896 - accuracy: 0.9264\n",
      "Epoch 143: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1909 - accuracy: 0.9257 - val_loss: 0.3680 - val_accuracy: 0.8585\n",
      "Epoch 144/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2135 - accuracy: 0.9032\n",
      "Epoch 144: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9257 - val_loss: 0.3296 - val_accuracy: 0.8669\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1110 - accuracy: 0.9677\n",
      "Epoch 145: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1912 - accuracy: 0.9225 - val_loss: 0.3479 - val_accuracy: 0.8685\n",
      "Epoch 146/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2624 - accuracy: 0.9113\n",
      "Epoch 146: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2014 - accuracy: 0.9150 - val_loss: 0.3465 - val_accuracy: 0.8662\n",
      "Epoch 147/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1897 - accuracy: 0.9274\n",
      "Epoch 147: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1878 - accuracy: 0.9265 - val_loss: 0.3336 - val_accuracy: 0.8692\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1884 - accuracy: 0.9248\n",
      "Epoch 148: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1884 - accuracy: 0.9248 - val_loss: 0.3228 - val_accuracy: 0.8692\n",
      "Epoch 149/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1841 - accuracy: 0.9264\n",
      "Epoch 149: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1836 - accuracy: 0.9261 - val_loss: 0.3382 - val_accuracy: 0.8685\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1538 - accuracy: 0.9516\n",
      "Epoch 150: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1848 - accuracy: 0.9271 - val_loss: 0.3506 - val_accuracy: 0.8654\n",
      "Epoch 151/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1830 - accuracy: 0.9355\n",
      "Epoch 151: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1770 - accuracy: 0.9294 - val_loss: 0.3585 - val_accuracy: 0.8669\n",
      "Epoch 152/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1870 - accuracy: 0.9242\n",
      "Epoch 152: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.9250 - val_loss: 0.3424 - val_accuracy: 0.8569\n",
      "Epoch 153/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2160 - accuracy: 0.9113\n",
      "Epoch 153: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.9290 - val_loss: 0.3559 - val_accuracy: 0.8592\n",
      "Epoch 154/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1799 - accuracy: 0.9194\n",
      "Epoch 154: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1809 - accuracy: 0.9284 - val_loss: 0.3380 - val_accuracy: 0.8577\n",
      "Epoch 155/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1603 - accuracy: 0.9355\n",
      "Epoch 155: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.9284 - val_loss: 0.3547 - val_accuracy: 0.8646\n",
      "Epoch 156/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1999 - accuracy: 0.9274\n",
      "Epoch 156: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.9294 - val_loss: 0.3585 - val_accuracy: 0.8600\n",
      "Epoch 157/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1880 - accuracy: 0.9274\n",
      "Epoch 157: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1802 - accuracy: 0.9251 - val_loss: 0.3525 - val_accuracy: 0.8669\n",
      "Epoch 158/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1714 - accuracy: 0.9303\n",
      "Epoch 158: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1714 - accuracy: 0.9303 - val_loss: 0.3598 - val_accuracy: 0.8631\n",
      "Epoch 159/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1926 - accuracy: 0.9032\n",
      "Epoch 159: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1812 - accuracy: 0.9234 - val_loss: 0.3434 - val_accuracy: 0.8585\n",
      "Epoch 160/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1677 - accuracy: 0.9194\n",
      "Epoch 160: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.9305 - val_loss: 0.3561 - val_accuracy: 0.8508\n",
      "Epoch 161/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1739 - accuracy: 0.9298\n",
      "Epoch 161: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1739 - accuracy: 0.9298 - val_loss: 0.3396 - val_accuracy: 0.8562\n",
      "Epoch 162/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.1675 - accuracy: 0.9295\n",
      "Epoch 162: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1679 - accuracy: 0.9302 - val_loss: 0.3434 - val_accuracy: 0.8654\n",
      "Epoch 163/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1701 - accuracy: 0.9274\n",
      "Epoch 163: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1735 - accuracy: 0.9277 - val_loss: 0.3486 - val_accuracy: 0.8585\n",
      "Epoch 164/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1592 - accuracy: 0.9677\n",
      "Epoch 164: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1739 - accuracy: 0.9315 - val_loss: 0.3441 - val_accuracy: 0.8600\n",
      "Epoch 165/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1630 - accuracy: 0.9274\n",
      "Epoch 165: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.9248 - val_loss: 0.3605 - val_accuracy: 0.8608\n",
      "Epoch 166/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1832 - accuracy: 0.9032\n",
      "Epoch 166: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1729 - accuracy: 0.9259 - val_loss: 0.3502 - val_accuracy: 0.8585\n",
      "Epoch 167/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1773 - accuracy: 0.9284\n",
      "Epoch 167: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1769 - accuracy: 0.9286 - val_loss: 0.3517 - val_accuracy: 0.8600\n",
      "Epoch 168/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1581 - accuracy: 0.9274\n",
      "Epoch 168: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1693 - accuracy: 0.9328 - val_loss: 0.3694 - val_accuracy: 0.8608\n",
      "Epoch 169/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1851 - accuracy: 0.9194\n",
      "Epoch 169: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1699 - accuracy: 0.9317 - val_loss: 0.3685 - val_accuracy: 0.8669\n",
      "Epoch 170/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2018 - accuracy: 0.9194\n",
      "Epoch 170: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1655 - accuracy: 0.9338 - val_loss: 0.3510 - val_accuracy: 0.8631\n",
      "Epoch 171/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1592 - accuracy: 0.9355\n",
      "Epoch 171: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1675 - accuracy: 0.9321 - val_loss: 0.3530 - val_accuracy: 0.8662\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 22s - loss: 1.5116 - accuracy: 0.4194\n",
      "Epoch 1: val_accuracy improved from -inf to 0.74846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.6401 - accuracy: 0.6662 - val_loss: 0.5191 - val_accuracy: 0.7485\n",
      "Epoch 2/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.5128 - accuracy: 0.7500\n",
      "Epoch 2: val_accuracy improved from 0.74846 to 0.76769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7818 - val_loss: 0.4599 - val_accuracy: 0.7677\n",
      "Epoch 3/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.4238 - accuracy: 0.8137\n",
      "Epoch 3: val_accuracy improved from 0.76769 to 0.85154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.8214 - val_loss: 0.3815 - val_accuracy: 0.8515\n",
      "Epoch 4/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3306 - accuracy: 0.9274\n",
      "Epoch 4: val_accuracy did not improve from 0.85154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8501 - val_loss: 0.4011 - val_accuracy: 0.8100\n",
      "Epoch 5/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3489 - accuracy: 0.8629\n",
      "Epoch 5: val_accuracy improved from 0.85154 to 0.85769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8528 - val_loss: 0.3522 - val_accuracy: 0.8577\n",
      "Epoch 6/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.3444 - accuracy: 0.8600\n",
      "Epoch 6: val_accuracy improved from 0.85769 to 0.86000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3449 - accuracy: 0.8595 - val_loss: 0.3430 - val_accuracy: 0.8600\n",
      "Epoch 7/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3356 - accuracy: 0.8637\n",
      "Epoch 7: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8630 - val_loss: 0.3846 - val_accuracy: 0.8369\n",
      "Epoch 8/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4165 - accuracy: 0.7984\n",
      "Epoch 8: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8595 - val_loss: 0.3389 - val_accuracy: 0.8577\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3291 - accuracy: 0.8593\n",
      "Epoch 9: val_accuracy improved from 0.86000 to 0.86615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3291 - accuracy: 0.8593 - val_loss: 0.3335 - val_accuracy: 0.8662\n",
      "Epoch 10/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3449 - accuracy: 0.8468\n",
      "Epoch 10: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8617 - val_loss: 0.3640 - val_accuracy: 0.8485\n",
      "Epoch 11/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2954 - accuracy: 0.8629\n",
      "Epoch 11: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8659 - val_loss: 0.3269 - val_accuracy: 0.8608\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2887 - accuracy: 0.8790\n",
      "Epoch 12: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8682 - val_loss: 0.3274 - val_accuracy: 0.8623\n",
      "Epoch 13/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2496 - accuracy: 0.9113\n",
      "Epoch 13: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8709 - val_loss: 0.3229 - val_accuracy: 0.8600\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3174 - accuracy: 0.8710\n",
      "Epoch 14: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 0.8751 - val_loss: 0.3285 - val_accuracy: 0.8615\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3248 - accuracy: 0.8710\n",
      "Epoch 15: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.8636 - val_loss: 0.3503 - val_accuracy: 0.8546\n",
      "Epoch 16/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3193 - accuracy: 0.8468\n",
      "Epoch 16: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3016 - accuracy: 0.8740 - val_loss: 0.3194 - val_accuracy: 0.8631\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3836 - accuracy: 0.8387\n",
      "Epoch 17: val_accuracy improved from 0.86615 to 0.86846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2982 - accuracy: 0.8751 - val_loss: 0.3166 - val_accuracy: 0.8685\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2855 - accuracy: 0.8710\n",
      "Epoch 18: val_accuracy did not improve from 0.86846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2938 - accuracy: 0.8755 - val_loss: 0.3776 - val_accuracy: 0.8415\n",
      "Epoch 19/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3541 - accuracy: 0.8145\n",
      "Epoch 19: val_accuracy did not improve from 0.86846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3021 - accuracy: 0.8717 - val_loss: 0.3187 - val_accuracy: 0.8654\n",
      "Epoch 20/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2970 - accuracy: 0.8782\n",
      "Epoch 20: val_accuracy improved from 0.86846 to 0.86923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2993 - accuracy: 0.8753 - val_loss: 0.3114 - val_accuracy: 0.8692\n",
      "Epoch 21/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3037 - accuracy: 0.8548\n",
      "Epoch 21: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2906 - accuracy: 0.8782 - val_loss: 0.3327 - val_accuracy: 0.8623\n",
      "Epoch 22/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1967 - accuracy: 0.9113\n",
      "Epoch 22: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2904 - accuracy: 0.8761 - val_loss: 0.3301 - val_accuracy: 0.8562\n",
      "Epoch 23/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2275 - accuracy: 0.8952\n",
      "Epoch 23: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2896 - accuracy: 0.8786 - val_loss: 0.3109 - val_accuracy: 0.8646\n",
      "Epoch 24/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2780 - accuracy: 0.8856\n",
      "Epoch 24: val_accuracy improved from 0.86923 to 0.87692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2816 - accuracy: 0.8836 - val_loss: 0.3054 - val_accuracy: 0.8769\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2971 - accuracy: 0.9032\n",
      "Epoch 25: val_accuracy improved from 0.87692 to 0.87769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2739 - accuracy: 0.8884 - val_loss: 0.3034 - val_accuracy: 0.8777\n",
      "Epoch 26/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1975 - accuracy: 0.9274\n",
      "Epoch 26: val_accuracy improved from 0.87769 to 0.88231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2717 - accuracy: 0.8894 - val_loss: 0.2981 - val_accuracy: 0.8823\n",
      "Epoch 27/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2912 - accuracy: 0.8746\n",
      "Epoch 27: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2940 - accuracy: 0.8736 - val_loss: 0.3033 - val_accuracy: 0.8685\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2798 - accuracy: 0.8820\n",
      "Epoch 28: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2798 - accuracy: 0.8820 - val_loss: 0.3187 - val_accuracy: 0.8654\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2370 - accuracy: 0.9113\n",
      "Epoch 29: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.8855 - val_loss: 0.3120 - val_accuracy: 0.8715\n",
      "Epoch 30/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2792 - accuracy: 0.9113\n",
      "Epoch 30: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2640 - accuracy: 0.8884 - val_loss: 0.2944 - val_accuracy: 0.8731\n",
      "Epoch 31/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2672 - accuracy: 0.8888\n",
      "Epoch 31: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.8878 - val_loss: 0.2983 - val_accuracy: 0.8785\n",
      "Epoch 32/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2531 - accuracy: 0.8710\n",
      "Epoch 32: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2759 - accuracy: 0.8853 - val_loss: 0.3014 - val_accuracy: 0.8746\n",
      "Epoch 33/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2397 - accuracy: 0.8952\n",
      "Epoch 33: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.8880 - val_loss: 0.2979 - val_accuracy: 0.8669\n",
      "Epoch 34/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3287 - accuracy: 0.8629\n",
      "Epoch 34: val_accuracy improved from 0.88231 to 0.88538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2688 - accuracy: 0.8913 - val_loss: 0.2956 - val_accuracy: 0.8854\n",
      "Epoch 35/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2570 - accuracy: 0.8933\n",
      "Epoch 35: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2623 - accuracy: 0.8909 - val_loss: 0.3022 - val_accuracy: 0.8708\n",
      "Epoch 36/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2846 - accuracy: 0.8629\n",
      "Epoch 36: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2552 - accuracy: 0.8965 - val_loss: 0.2961 - val_accuracy: 0.8808\n",
      "Epoch 37/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1959 - accuracy: 0.9435\n",
      "Epoch 37: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2630 - accuracy: 0.8894 - val_loss: 0.2978 - val_accuracy: 0.8723\n",
      "Epoch 38/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2516 - accuracy: 0.9355\n",
      "Epoch 38: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.8922 - val_loss: 0.3220 - val_accuracy: 0.8646\n",
      "Epoch 39/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2644 - accuracy: 0.8710\n",
      "Epoch 39: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2745 - accuracy: 0.8840 - val_loss: 0.3052 - val_accuracy: 0.8700\n",
      "Epoch 40/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2572 - accuracy: 0.8930\n",
      "Epoch 40: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.8917 - val_loss: 0.3057 - val_accuracy: 0.8746\n",
      "Epoch 41/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1431 - accuracy: 0.9435\n",
      "Epoch 41: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.8909 - val_loss: 0.2953 - val_accuracy: 0.8754\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2109 - accuracy: 0.9194\n",
      "Epoch 42: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2555 - accuracy: 0.8944 - val_loss: 0.3031 - val_accuracy: 0.8846\n",
      "Epoch 43/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2937 - accuracy: 0.8710\n",
      "Epoch 43: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2608 - accuracy: 0.8936 - val_loss: 0.2984 - val_accuracy: 0.8769\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2558 - accuracy: 0.8942\n",
      "Epoch 44: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2558 - accuracy: 0.8942 - val_loss: 0.2931 - val_accuracy: 0.8815\n",
      "Epoch 45/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.2467 - accuracy: 0.8972\n",
      "Epoch 45: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.8953 - val_loss: 0.2996 - val_accuracy: 0.8708\n",
      "Epoch 46/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1797 - accuracy: 0.9435\n",
      "Epoch 46: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2546 - accuracy: 0.8969 - val_loss: 0.2938 - val_accuracy: 0.8777\n",
      "Epoch 47/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2437 - accuracy: 0.9113\n",
      "Epoch 47: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.8990 - val_loss: 0.2985 - val_accuracy: 0.8785\n",
      "Epoch 48/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2670 - accuracy: 0.8935\n",
      "Epoch 48: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2608 - accuracy: 0.8955 - val_loss: 0.3028 - val_accuracy: 0.8785\n",
      "Epoch 49/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2523 - accuracy: 0.8958\n",
      "Epoch 49: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.8978 - val_loss: 0.2939 - val_accuracy: 0.8731\n",
      "Epoch 50/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1886 - accuracy: 0.8871\n",
      "Epoch 50: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.8936 - val_loss: 0.2957 - val_accuracy: 0.8746\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1920 - accuracy: 0.9355\n",
      "Epoch 51: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2533 - accuracy: 0.8953 - val_loss: 0.3258 - val_accuracy: 0.8700\n",
      "Epoch 52/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1799 - accuracy: 0.9113\n",
      "Epoch 52: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.8980 - val_loss: 0.3056 - val_accuracy: 0.8746\n",
      "Epoch 53/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3136 - accuracy: 0.8710\n",
      "Epoch 53: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.8980 - val_loss: 0.2934 - val_accuracy: 0.8785\n",
      "Epoch 54/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2716 - accuracy: 0.8790\n",
      "Epoch 54: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.8978 - val_loss: 0.3016 - val_accuracy: 0.8723\n",
      "Epoch 55/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2391 - accuracy: 0.9036\n",
      "Epoch 55: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2391 - accuracy: 0.9042 - val_loss: 0.2952 - val_accuracy: 0.8823\n",
      "Epoch 56/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2804 - accuracy: 0.8468\n",
      "Epoch 56: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2534 - accuracy: 0.8917 - val_loss: 0.2989 - val_accuracy: 0.8731\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2909 - accuracy: 0.8548\n",
      "Epoch 57: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2416 - accuracy: 0.9003 - val_loss: 0.2980 - val_accuracy: 0.8838\n",
      "Epoch 58/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2229 - accuracy: 0.9194\n",
      "Epoch 58: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2381 - accuracy: 0.9048 - val_loss: 0.2994 - val_accuracy: 0.8723\n",
      "Epoch 59/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3114 - accuracy: 0.8468\n",
      "Epoch 59: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2432 - accuracy: 0.8982 - val_loss: 0.2970 - val_accuracy: 0.8831\n",
      "Epoch 60/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1835 - accuracy: 0.9355\n",
      "Epoch 60: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2367 - accuracy: 0.9032 - val_loss: 0.2979 - val_accuracy: 0.8769\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2315 - accuracy: 0.9048\n",
      "Epoch 61: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2315 - accuracy: 0.9048 - val_loss: 0.2999 - val_accuracy: 0.8754\n",
      "Epoch 62/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3113 - accuracy: 0.8387\n",
      "Epoch 62: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2341 - accuracy: 0.9032 - val_loss: 0.2930 - val_accuracy: 0.8777\n",
      "Epoch 63/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1777 - accuracy: 0.9274\n",
      "Epoch 63: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2394 - accuracy: 0.8996 - val_loss: 0.3213 - val_accuracy: 0.8692\n",
      "Epoch 64/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1728 - accuracy: 0.9274\n",
      "Epoch 64: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2369 - accuracy: 0.9051 - val_loss: 0.2996 - val_accuracy: 0.8746\n",
      "Epoch 65/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2228 - accuracy: 0.9032\n",
      "Epoch 65: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2322 - accuracy: 0.9036 - val_loss: 0.3025 - val_accuracy: 0.8792\n",
      "Epoch 66/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1586 - accuracy: 0.9435\n",
      "Epoch 66: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2348 - accuracy: 0.9057 - val_loss: 0.3082 - val_accuracy: 0.8715\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2308 - accuracy: 0.9023\n",
      "Epoch 67: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2308 - accuracy: 0.9023 - val_loss: 0.3102 - val_accuracy: 0.8754\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2141 - accuracy: 0.9194\n",
      "Epoch 68: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2310 - accuracy: 0.9030 - val_loss: 0.2956 - val_accuracy: 0.8769\n",
      "Epoch 69/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2277 - accuracy: 0.8952\n",
      "Epoch 69: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2286 - accuracy: 0.9080 - val_loss: 0.2985 - val_accuracy: 0.8762\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1434 - accuracy: 0.9677\n",
      "Epoch 70: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2338 - accuracy: 0.9030 - val_loss: 0.3013 - val_accuracy: 0.8823\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2718 - accuracy: 0.9194\n",
      "Epoch 71: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2351 - accuracy: 0.9013 - val_loss: 0.3011 - val_accuracy: 0.8792\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2016 - accuracy: 0.9194\n",
      "Epoch 72: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2355 - accuracy: 0.9032 - val_loss: 0.3002 - val_accuracy: 0.8769\n",
      "Epoch 73/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3220 - accuracy: 0.9032\n",
      "Epoch 73: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2329 - accuracy: 0.9071 - val_loss: 0.3083 - val_accuracy: 0.8723\n",
      "Epoch 74/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1920 - accuracy: 0.9355\n",
      "Epoch 74: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2300 - accuracy: 0.9076 - val_loss: 0.3051 - val_accuracy: 0.8746\n",
      "Epoch 75/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2548 - accuracy: 0.9113\n",
      "Epoch 75: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.9078 - val_loss: 0.3122 - val_accuracy: 0.8731\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2369 - accuracy: 0.9113\n",
      "Epoch 76: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2289 - accuracy: 0.9051 - val_loss: 0.3235 - val_accuracy: 0.8708\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2281 - accuracy: 0.9274\n",
      "Epoch 77: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2333 - accuracy: 0.9067 - val_loss: 0.3106 - val_accuracy: 0.8746\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1499 - accuracy: 0.9355\n",
      "Epoch 78: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2347 - accuracy: 0.9009 - val_loss: 0.3069 - val_accuracy: 0.8723\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2189 - accuracy: 0.9274\n",
      "Epoch 79: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2309 - accuracy: 0.9080 - val_loss: 0.3354 - val_accuracy: 0.8631\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2797 - accuracy: 0.8871\n",
      "Epoch 80: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2323 - accuracy: 0.9040 - val_loss: 0.3061 - val_accuracy: 0.8754\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1822 - accuracy: 0.9274\n",
      "Epoch 81: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2209 - accuracy: 0.9107 - val_loss: 0.3124 - val_accuracy: 0.8746\n",
      "Epoch 82/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2942 - accuracy: 0.8790\n",
      "Epoch 82: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2215 - accuracy: 0.9094 - val_loss: 0.3015 - val_accuracy: 0.8754\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2566 - accuracy: 0.8710\n",
      "Epoch 83: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2183 - accuracy: 0.9132 - val_loss: 0.3044 - val_accuracy: 0.8785\n",
      "Epoch 84/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1879 - accuracy: 0.9274\n",
      "Epoch 84: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2248 - accuracy: 0.9069 - val_loss: 0.2993 - val_accuracy: 0.8800\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1854 - accuracy: 0.9113\n",
      "Epoch 85: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.9067 - val_loss: 0.3044 - val_accuracy: 0.8792\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2384 - accuracy: 0.9194\n",
      "Epoch 86: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.9024 - val_loss: 0.3048 - val_accuracy: 0.8708\n",
      "Epoch 87/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2200 - accuracy: 0.9355\n",
      "Epoch 87: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2198 - accuracy: 0.9111 - val_loss: 0.3114 - val_accuracy: 0.8738\n",
      "Epoch 88/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1647 - accuracy: 0.9435\n",
      "Epoch 88: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2302 - accuracy: 0.9063 - val_loss: 0.3117 - val_accuracy: 0.8792\n",
      "Epoch 89/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2020 - accuracy: 0.9113\n",
      "Epoch 89: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2192 - accuracy: 0.9105 - val_loss: 0.3139 - val_accuracy: 0.8708\n",
      "Epoch 90/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2196 - accuracy: 0.9113\n",
      "Epoch 90: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2176 - accuracy: 0.9109 - val_loss: 0.3102 - val_accuracy: 0.8746\n",
      "Epoch 91/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2932 - accuracy: 0.8871\n",
      "Epoch 91: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2183 - accuracy: 0.9113 - val_loss: 0.3155 - val_accuracy: 0.8715\n",
      "Epoch 92/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2084 - accuracy: 0.9274\n",
      "Epoch 92: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2127 - accuracy: 0.9140 - val_loss: 0.3185 - val_accuracy: 0.8708\n",
      "Epoch 93/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2201 - accuracy: 0.9087\n",
      "Epoch 93: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2202 - accuracy: 0.9086 - val_loss: 0.3111 - val_accuracy: 0.8692\n",
      "Epoch 94/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2204 - accuracy: 0.9194\n",
      "Epoch 94: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2238 - accuracy: 0.9074 - val_loss: 0.3192 - val_accuracy: 0.8731\n",
      "Epoch 95/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2347 - accuracy: 0.9194\n",
      "Epoch 95: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2214 - accuracy: 0.9101 - val_loss: 0.3268 - val_accuracy: 0.8685\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2206 - accuracy: 0.9113\n",
      "Epoch 96: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2311 - accuracy: 0.9046 - val_loss: 0.3123 - val_accuracy: 0.8754\n",
      "Epoch 97/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2201 - accuracy: 0.9032\n",
      "Epoch 97: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2168 - accuracy: 0.9092 - val_loss: 0.3250 - val_accuracy: 0.8746\n",
      "Epoch 98/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1888 - accuracy: 0.9113\n",
      "Epoch 98: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.9148 - val_loss: 0.3110 - val_accuracy: 0.8723\n",
      "Epoch 99/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2136 - accuracy: 0.9156\n",
      "Epoch 99: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2140 - accuracy: 0.9148 - val_loss: 0.3086 - val_accuracy: 0.8762\n",
      "Epoch 100/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2034 - accuracy: 0.9355\n",
      "Epoch 100: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2132 - accuracy: 0.9121 - val_loss: 0.3095 - val_accuracy: 0.8708\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1246 - accuracy: 0.9516\n",
      "Epoch 101: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2082 - accuracy: 0.9165 - val_loss: 0.3160 - val_accuracy: 0.8700\n",
      "Epoch 102/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2676 - accuracy: 0.8871\n",
      "Epoch 102: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 0.9099 - val_loss: 0.3231 - val_accuracy: 0.8708\n",
      "Epoch 103/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3002 - accuracy: 0.9032\n",
      "Epoch 103: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2098 - accuracy: 0.9186 - val_loss: 0.3148 - val_accuracy: 0.8738\n",
      "Epoch 104/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2114 - accuracy: 0.9162\n",
      "Epoch 104: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.9167 - val_loss: 0.3415 - val_accuracy: 0.8646\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1495 - accuracy: 0.9435\n",
      "Epoch 105: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2080 - accuracy: 0.9169 - val_loss: 0.3262 - val_accuracy: 0.8777\n",
      "Epoch 106/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2690 - accuracy: 0.8710\n",
      "Epoch 106: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2034 - accuracy: 0.9157 - val_loss: 0.3130 - val_accuracy: 0.8785\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1483 - accuracy: 0.9435\n",
      "Epoch 107: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2141 - accuracy: 0.9123 - val_loss: 0.3210 - val_accuracy: 0.8692\n",
      "Epoch 108/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2791 - accuracy: 0.8871\n",
      "Epoch 108: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2136 - accuracy: 0.9109 - val_loss: 0.3208 - val_accuracy: 0.8746\n",
      "Epoch 109/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2043 - accuracy: 0.9192\n",
      "Epoch 109: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2033 - accuracy: 0.9198 - val_loss: 0.3148 - val_accuracy: 0.8785\n",
      "Epoch 110/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1125 - accuracy: 0.9677\n",
      "Epoch 110: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2128 - accuracy: 0.9123 - val_loss: 0.3352 - val_accuracy: 0.8685\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1903 - accuracy: 0.9113\n",
      "Epoch 111: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2142 - accuracy: 0.9123 - val_loss: 0.3134 - val_accuracy: 0.8754\n",
      "Epoch 112/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1411 - accuracy: 0.9435\n",
      "Epoch 112: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2109 - accuracy: 0.9140 - val_loss: 0.3203 - val_accuracy: 0.8808\n",
      "Epoch 113/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1233 - accuracy: 0.9677\n",
      "Epoch 113: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2124 - accuracy: 0.9140 - val_loss: 0.3231 - val_accuracy: 0.8777\n",
      "Epoch 114/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1931 - accuracy: 0.9194\n",
      "Epoch 114: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1983 - accuracy: 0.9223 - val_loss: 0.3155 - val_accuracy: 0.8792\n",
      "Epoch 115/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2782 - accuracy: 0.8790\n",
      "Epoch 115: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2012 - accuracy: 0.9203 - val_loss: 0.3168 - val_accuracy: 0.8769\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1968 - accuracy: 0.9274\n",
      "Epoch 116: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2056 - accuracy: 0.9180 - val_loss: 0.3195 - val_accuracy: 0.8738\n",
      "Epoch 117/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2515 - accuracy: 0.9113\n",
      "Epoch 117: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2004 - accuracy: 0.9171 - val_loss: 0.3156 - val_accuracy: 0.8785\n",
      "Epoch 118/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1004 - accuracy: 0.9758\n",
      "Epoch 118: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2052 - accuracy: 0.9188 - val_loss: 0.3433 - val_accuracy: 0.8669\n",
      "Epoch 119/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2963 - accuracy: 0.8952\n",
      "Epoch 119: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2058 - accuracy: 0.9194 - val_loss: 0.3454 - val_accuracy: 0.8654\n",
      "Epoch 120/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2138 - accuracy: 0.9095\n",
      "Epoch 120: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2153 - accuracy: 0.9086 - val_loss: 0.3185 - val_accuracy: 0.8769\n",
      "Epoch 121/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2102 - accuracy: 0.9158\n",
      "Epoch 121: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2094 - accuracy: 0.9171 - val_loss: 0.3200 - val_accuracy: 0.8785\n",
      "Epoch 122/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1933 - accuracy: 0.9113\n",
      "Epoch 122: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1983 - accuracy: 0.9186 - val_loss: 0.3229 - val_accuracy: 0.8662\n",
      "Epoch 123/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2111 - accuracy: 0.9144\n",
      "Epoch 123: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2111 - accuracy: 0.9144 - val_loss: 0.3362 - val_accuracy: 0.8700\n",
      "Epoch 124/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2369 - accuracy: 0.9032\n",
      "Epoch 124: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2027 - accuracy: 0.9161 - val_loss: 0.3279 - val_accuracy: 0.8677\n",
      "Epoch 125/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2133 - accuracy: 0.9274\n",
      "Epoch 125: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2042 - accuracy: 0.9178 - val_loss: 0.3191 - val_accuracy: 0.8715\n",
      "Epoch 126/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1802 - accuracy: 0.9194\n",
      "Epoch 126: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1984 - accuracy: 0.9203 - val_loss: 0.3230 - val_accuracy: 0.8769\n",
      "Epoch 127/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1942 - accuracy: 0.9199\n",
      "Epoch 127: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1940 - accuracy: 0.9200 - val_loss: 0.3231 - val_accuracy: 0.8738\n",
      "Epoch 128/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.0904 - accuracy: 0.9839\n",
      "Epoch 128: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1941 - accuracy: 0.9226 - val_loss: 0.3286 - val_accuracy: 0.8731\n",
      "Epoch 129/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1301 - accuracy: 0.9435\n",
      "Epoch 129: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1959 - accuracy: 0.9219 - val_loss: 0.3283 - val_accuracy: 0.8769\n",
      "Epoch 130/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1795 - accuracy: 0.9355\n",
      "Epoch 130: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1983 - accuracy: 0.9192 - val_loss: 0.3276 - val_accuracy: 0.8731\n",
      "Epoch 131/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2061 - accuracy: 0.9157\n",
      "Epoch 131: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2061 - accuracy: 0.9157 - val_loss: 0.3263 - val_accuracy: 0.8792\n",
      "Epoch 132/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2787 - accuracy: 0.8710\n",
      "Epoch 132: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2016 - accuracy: 0.9176 - val_loss: 0.3201 - val_accuracy: 0.8731\n",
      "Epoch 133/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1666 - accuracy: 0.9274\n",
      "Epoch 133: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2082 - accuracy: 0.9190 - val_loss: 0.3316 - val_accuracy: 0.8646\n",
      "Epoch 134/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1883 - accuracy: 0.9274\n",
      "Epoch 134: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1904 - accuracy: 0.9255 - val_loss: 0.3208 - val_accuracy: 0.8754\n",
      "Epoch 135/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1911 - accuracy: 0.9246\n",
      "Epoch 135: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.9244 - val_loss: 0.3361 - val_accuracy: 0.8662\n",
      "Epoch 136/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1836 - accuracy: 0.9355\n",
      "Epoch 136: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1859 - accuracy: 0.9255 - val_loss: 0.3268 - val_accuracy: 0.8762\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1670 - accuracy: 0.9435\n",
      "Epoch 137: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1802 - accuracy: 0.9296 - val_loss: 0.3764 - val_accuracy: 0.8623\n",
      "Epoch 138/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2448 - accuracy: 0.8952\n",
      "Epoch 138: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2026 - accuracy: 0.9161 - val_loss: 0.3309 - val_accuracy: 0.8738\n",
      "Epoch 139/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1953 - accuracy: 0.9213\n",
      "Epoch 139: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1953 - accuracy: 0.9213 - val_loss: 0.3213 - val_accuracy: 0.8769\n",
      "Epoch 140/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2392 - accuracy: 0.8871\n",
      "Epoch 140: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1896 - accuracy: 0.9234 - val_loss: 0.3277 - val_accuracy: 0.8777\n",
      "Epoch 141/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1893 - accuracy: 0.9251\n",
      "Epoch 141: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1893 - accuracy: 0.9251 - val_loss: 0.3367 - val_accuracy: 0.8762\n",
      "Epoch 142/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2114 - accuracy: 0.9032\n",
      "Epoch 142: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.9196 - val_loss: 0.3256 - val_accuracy: 0.8731\n",
      "Epoch 143/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1858 - accuracy: 0.9255\n",
      "Epoch 143: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1858 - accuracy: 0.9255 - val_loss: 0.3390 - val_accuracy: 0.8685\n",
      "Epoch 144/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1425 - accuracy: 0.9355\n",
      "Epoch 144: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1826 - accuracy: 0.9298 - val_loss: 0.3447 - val_accuracy: 0.8692\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3228 - accuracy: 0.8468\n",
      "Epoch 145: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.9225 - val_loss: 0.3532 - val_accuracy: 0.8631\n",
      "Epoch 146/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1566 - accuracy: 0.9435\n",
      "Epoch 146: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1850 - accuracy: 0.9261 - val_loss: 0.3346 - val_accuracy: 0.8723\n",
      "Epoch 147/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1770 - accuracy: 0.9325\n",
      "Epoch 147: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1770 - accuracy: 0.9325 - val_loss: 0.3568 - val_accuracy: 0.8769\n",
      "Epoch 148/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1828 - accuracy: 0.9274\n",
      "Epoch 148: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1857 - accuracy: 0.9263 - val_loss: 0.3463 - val_accuracy: 0.8700\n",
      "Epoch 149/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2147 - accuracy: 0.9032\n",
      "Epoch 149: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1942 - accuracy: 0.9157 - val_loss: 0.3597 - val_accuracy: 0.8669\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2652 - accuracy: 0.9113\n",
      "Epoch 150: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2014 - accuracy: 0.9192 - val_loss: 0.3399 - val_accuracy: 0.8723\n",
      "Epoch 151/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1540 - accuracy: 0.9435\n",
      "Epoch 151: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1920 - accuracy: 0.9217 - val_loss: 0.3383 - val_accuracy: 0.8762\n",
      "Epoch 152/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1153 - accuracy: 0.9597\n",
      "Epoch 152: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1924 - accuracy: 0.9215 - val_loss: 0.3435 - val_accuracy: 0.8685\n",
      "Epoch 153/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2792 - accuracy: 0.8790\n",
      "Epoch 153: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9169 - val_loss: 0.3412 - val_accuracy: 0.8746\n",
      "Epoch 154/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2000 - accuracy: 0.9355\n",
      "Epoch 154: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1833 - accuracy: 0.9275 - val_loss: 0.3412 - val_accuracy: 0.8746\n",
      "Epoch 155/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1089 - accuracy: 0.9677\n",
      "Epoch 155: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1801 - accuracy: 0.9271 - val_loss: 0.3338 - val_accuracy: 0.8746\n",
      "Epoch 156/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1381 - accuracy: 0.9355\n",
      "Epoch 156: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1803 - accuracy: 0.9271 - val_loss: 0.3333 - val_accuracy: 0.8700\n",
      "Epoch 157/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1739 - accuracy: 0.9327\n",
      "Epoch 157: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1759 - accuracy: 0.9319 - val_loss: 0.3469 - val_accuracy: 0.8700\n",
      "Epoch 158/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1039 - accuracy: 0.9758\n",
      "Epoch 158: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.9302 - val_loss: 0.3483 - val_accuracy: 0.8754\n",
      "Epoch 159/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1159 - accuracy: 0.9597\n",
      "Epoch 159: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1738 - accuracy: 0.9296 - val_loss: 0.3332 - val_accuracy: 0.8754\n",
      "Epoch 160/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1204 - accuracy: 0.9758\n",
      "Epoch 160: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1818 - accuracy: 0.9261 - val_loss: 0.3668 - val_accuracy: 0.8708\n",
      "Epoch 161/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1774 - accuracy: 0.9300\n",
      "Epoch 161: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1774 - accuracy: 0.9300 - val_loss: 0.3574 - val_accuracy: 0.8708\n",
      "Epoch 162/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1820 - accuracy: 0.9274\n",
      "Epoch 162: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1728 - accuracy: 0.9303 - val_loss: 0.3638 - val_accuracy: 0.8777\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 23s - loss: 1.7335 - accuracy: 0.3468\n",
      "Epoch 1: val_accuracy improved from -inf to 0.73923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.6485 - accuracy: 0.6546 - val_loss: 0.5177 - val_accuracy: 0.7392\n",
      "Epoch 2/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.4680 - accuracy: 0.8016\n",
      "Epoch 2: val_accuracy improved from 0.73923 to 0.81923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.8024 - val_loss: 0.4408 - val_accuracy: 0.8192\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.4071 - accuracy: 0.8278\n",
      "Epoch 3: val_accuracy did not improve from 0.81923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8278 - val_loss: 0.4339 - val_accuracy: 0.7969\n",
      "Epoch 4/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4846 - accuracy: 0.7581\n",
      "Epoch 4: val_accuracy improved from 0.81923 to 0.82538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8395 - val_loss: 0.3978 - val_accuracy: 0.8254\n",
      "Epoch 5/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4496 - accuracy: 0.8065\n",
      "Epoch 5: val_accuracy improved from 0.82538 to 0.85154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8432 - val_loss: 0.3567 - val_accuracy: 0.8515\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3627 - accuracy: 0.8432\n",
      "Epoch 6: val_accuracy did not improve from 0.85154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8432 - val_loss: 0.3549 - val_accuracy: 0.8431\n",
      "Epoch 7/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3723 - accuracy: 0.8468\n",
      "Epoch 7: val_accuracy improved from 0.85154 to 0.85923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8541 - val_loss: 0.3389 - val_accuracy: 0.8592\n",
      "Epoch 8/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3480 - accuracy: 0.8871\n",
      "Epoch 8: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8690 - val_loss: 0.3385 - val_accuracy: 0.8531\n",
      "Epoch 9/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3071 - accuracy: 0.9032\n",
      "Epoch 9: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8630 - val_loss: 0.3463 - val_accuracy: 0.8531\n",
      "Epoch 10/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.3275 - accuracy: 0.8625\n",
      "Epoch 10: val_accuracy improved from 0.85923 to 0.86154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.8645 - val_loss: 0.3389 - val_accuracy: 0.8615\n",
      "Epoch 11/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3522 - accuracy: 0.8548\n",
      "Epoch 11: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.8582 - val_loss: 0.3308 - val_accuracy: 0.8538\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3332 - accuracy: 0.8468\n",
      "Epoch 12: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8678 - val_loss: 0.3548 - val_accuracy: 0.8508\n",
      "Epoch 13/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.3166 - accuracy: 0.8654\n",
      "Epoch 13: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3178 - accuracy: 0.8651 - val_loss: 0.3757 - val_accuracy: 0.8438\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3713 - accuracy: 0.8306\n",
      "Epoch 14: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8684 - val_loss: 0.3322 - val_accuracy: 0.8569\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3081 - accuracy: 0.8755\n",
      "Epoch 15: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8755 - val_loss: 0.3390 - val_accuracy: 0.8600\n",
      "Epoch 16/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.3316 - accuracy: 0.8575\n",
      "Epoch 16: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8582 - val_loss: 0.3644 - val_accuracy: 0.8431\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3781 - accuracy: 0.8468\n",
      "Epoch 17: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8653 - val_loss: 0.3234 - val_accuracy: 0.8585\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3618 - accuracy: 0.8548\n",
      "Epoch 18: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.8742 - val_loss: 0.3285 - val_accuracy: 0.8554\n",
      "Epoch 19/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3942 - accuracy: 0.8790\n",
      "Epoch 19: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8715 - val_loss: 0.3310 - val_accuracy: 0.8577\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3165 - accuracy: 0.8653\n",
      "Epoch 20: val_accuracy improved from 0.86154 to 0.86308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3165 - accuracy: 0.8653 - val_loss: 0.3336 - val_accuracy: 0.8631\n",
      "Epoch 21/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2764 - accuracy: 0.8629\n",
      "Epoch 21: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3002 - accuracy: 0.8734 - val_loss: 0.3284 - val_accuracy: 0.8600\n",
      "Epoch 22/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1914 - accuracy: 0.9355\n",
      "Epoch 22: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2973 - accuracy: 0.8784 - val_loss: 0.3306 - val_accuracy: 0.8600\n",
      "Epoch 23/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2903 - accuracy: 0.8794\n",
      "Epoch 23: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2917 - accuracy: 0.8792 - val_loss: 0.3248 - val_accuracy: 0.8577\n",
      "Epoch 24/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2516 - accuracy: 0.8790\n",
      "Epoch 24: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2993 - accuracy: 0.8724 - val_loss: 0.3213 - val_accuracy: 0.8608\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2635 - accuracy: 0.8871\n",
      "Epoch 25: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.8724 - val_loss: 0.3263 - val_accuracy: 0.8585\n",
      "Epoch 26/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2734 - accuracy: 0.8629\n",
      "Epoch 26: val_accuracy improved from 0.86308 to 0.86615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2927 - accuracy: 0.8797 - val_loss: 0.3161 - val_accuracy: 0.8662\n",
      "Epoch 27/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2927 - accuracy: 0.8739\n",
      "Epoch 27: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2904 - accuracy: 0.8765 - val_loss: 0.3481 - val_accuracy: 0.8500\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3195 - accuracy: 0.8629\n",
      "Epoch 28: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3011 - accuracy: 0.8730 - val_loss: 0.3201 - val_accuracy: 0.8631\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2842 - accuracy: 0.8952\n",
      "Epoch 29: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2920 - accuracy: 0.8815 - val_loss: 0.3563 - val_accuracy: 0.8423\n",
      "Epoch 30/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3300 - accuracy: 0.8710\n",
      "Epoch 30: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2838 - accuracy: 0.8822 - val_loss: 0.3165 - val_accuracy: 0.8623\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2827 - accuracy: 0.8832\n",
      "Epoch 31: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2827 - accuracy: 0.8832 - val_loss: 0.3345 - val_accuracy: 0.8608\n",
      "Epoch 32/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2964 - accuracy: 0.8871\n",
      "Epoch 32: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2874 - accuracy: 0.8805 - val_loss: 0.3275 - val_accuracy: 0.8523\n",
      "Epoch 33/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2844 - accuracy: 0.8790\n",
      "Epoch 33: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2835 - accuracy: 0.8830 - val_loss: 0.3235 - val_accuracy: 0.8577\n",
      "Epoch 34/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2638 - accuracy: 0.8871\n",
      "Epoch 34: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2879 - accuracy: 0.8809 - val_loss: 0.3162 - val_accuracy: 0.8615\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2837 - accuracy: 0.8867\n",
      "Epoch 35: val_accuracy improved from 0.86615 to 0.86923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2837 - accuracy: 0.8867 - val_loss: 0.3073 - val_accuracy: 0.8692\n",
      "Epoch 36/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2683 - accuracy: 0.8710\n",
      "Epoch 36: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2740 - accuracy: 0.8869 - val_loss: 0.3066 - val_accuracy: 0.8677\n",
      "Epoch 37/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2749 - accuracy: 0.9032\n",
      "Epoch 37: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2746 - accuracy: 0.8865 - val_loss: 0.3089 - val_accuracy: 0.8662\n",
      "Epoch 38/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2857 - accuracy: 0.8790\n",
      "Epoch 38: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.8838 - val_loss: 0.3140 - val_accuracy: 0.8685\n",
      "Epoch 39/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2609 - accuracy: 0.9032\n",
      "Epoch 39: val_accuracy improved from 0.86923 to 0.87077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2736 - accuracy: 0.8874 - val_loss: 0.3088 - val_accuracy: 0.8708\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2664 - accuracy: 0.8907\n",
      "Epoch 40: val_accuracy improved from 0.87077 to 0.87769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2664 - accuracy: 0.8907 - val_loss: 0.3083 - val_accuracy: 0.8777\n",
      "Epoch 41/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3043 - accuracy: 0.8710\n",
      "Epoch 41: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2668 - accuracy: 0.8903 - val_loss: 0.3128 - val_accuracy: 0.8708\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2906 - accuracy: 0.8710\n",
      "Epoch 42: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2646 - accuracy: 0.8915 - val_loss: 0.3165 - val_accuracy: 0.8746\n",
      "Epoch 43/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2720 - accuracy: 0.8629\n",
      "Epoch 43: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.8869 - val_loss: 0.3012 - val_accuracy: 0.8708\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2044 - accuracy: 0.9274\n",
      "Epoch 44: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2657 - accuracy: 0.8897 - val_loss: 0.3234 - val_accuracy: 0.8600\n",
      "Epoch 45/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3050 - accuracy: 0.8468\n",
      "Epoch 45: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2706 - accuracy: 0.8880 - val_loss: 0.3042 - val_accuracy: 0.8700\n",
      "Epoch 46/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2806 - accuracy: 0.8710\n",
      "Epoch 46: val_accuracy improved from 0.87769 to 0.88154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2592 - accuracy: 0.8942 - val_loss: 0.3061 - val_accuracy: 0.8815\n",
      "Epoch 47/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2632 - accuracy: 0.8917\n",
      "Epoch 47: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2632 - accuracy: 0.8917 - val_loss: 0.3156 - val_accuracy: 0.8677\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2682 - accuracy: 0.8871\n",
      "Epoch 48: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2682 - accuracy: 0.8871 - val_loss: 0.3084 - val_accuracy: 0.8638\n",
      "Epoch 49/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2708 - accuracy: 0.8867\n",
      "Epoch 49: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2670 - accuracy: 0.8865 - val_loss: 0.2993 - val_accuracy: 0.8808\n",
      "Epoch 50/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2085 - accuracy: 0.9113\n",
      "Epoch 50: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2552 - accuracy: 0.8961 - val_loss: 0.2981 - val_accuracy: 0.8738\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3599 - accuracy: 0.8306\n",
      "Epoch 51: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.8928 - val_loss: 0.2975 - val_accuracy: 0.8777\n",
      "Epoch 52/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2210 - accuracy: 0.9113\n",
      "Epoch 52: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2623 - accuracy: 0.8909 - val_loss: 0.3219 - val_accuracy: 0.8600\n",
      "Epoch 53/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2685 - accuracy: 0.8871\n",
      "Epoch 53: val_accuracy improved from 0.88154 to 0.88308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2654 - accuracy: 0.8886 - val_loss: 0.2995 - val_accuracy: 0.8831\n",
      "Epoch 54/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1931 - accuracy: 0.9194\n",
      "Epoch 54: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.8949 - val_loss: 0.3072 - val_accuracy: 0.8731\n",
      "Epoch 55/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2364 - accuracy: 0.9274\n",
      "Epoch 55: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.8969 - val_loss: 0.3191 - val_accuracy: 0.8646\n",
      "Epoch 56/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2524 - accuracy: 0.8987\n",
      "Epoch 56: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2533 - accuracy: 0.8980 - val_loss: 0.2979 - val_accuracy: 0.8723\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2272 - accuracy: 0.9194\n",
      "Epoch 57: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2593 - accuracy: 0.8921 - val_loss: 0.2984 - val_accuracy: 0.8723\n",
      "Epoch 58/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2690 - accuracy: 0.8952\n",
      "Epoch 58: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2589 - accuracy: 0.8907 - val_loss: 0.3075 - val_accuracy: 0.8669\n",
      "Epoch 59/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2950 - accuracy: 0.8548\n",
      "Epoch 59: val_accuracy improved from 0.88308 to 0.88385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.8940 - val_loss: 0.3009 - val_accuracy: 0.8838\n",
      "Epoch 60/1000\n",
      "27/42 [==================>...........] - ETA: 0s - loss: 0.2504 - accuracy: 0.8984\n",
      "Epoch 60: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8994 - val_loss: 0.3018 - val_accuracy: 0.8785\n",
      "Epoch 61/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2871 - accuracy: 0.8548\n",
      "Epoch 61: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.9017 - val_loss: 0.3083 - val_accuracy: 0.8754\n",
      "Epoch 62/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2028 - accuracy: 0.8790\n",
      "Epoch 62: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2482 - accuracy: 0.8980 - val_loss: 0.3014 - val_accuracy: 0.8700\n",
      "Epoch 63/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2146 - accuracy: 0.9113\n",
      "Epoch 63: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2429 - accuracy: 0.9003 - val_loss: 0.2988 - val_accuracy: 0.8831\n",
      "Epoch 64/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2208 - accuracy: 0.9032\n",
      "Epoch 64: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2413 - accuracy: 0.9030 - val_loss: 0.2993 - val_accuracy: 0.8800\n",
      "Epoch 65/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1444 - accuracy: 0.9677\n",
      "Epoch 65: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8974 - val_loss: 0.3208 - val_accuracy: 0.8731\n",
      "Epoch 66/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1978 - accuracy: 0.9032\n",
      "Epoch 66: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2403 - accuracy: 0.9011 - val_loss: 0.3075 - val_accuracy: 0.8685\n",
      "Epoch 67/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1745 - accuracy: 0.9113\n",
      "Epoch 67: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2414 - accuracy: 0.9007 - val_loss: 0.3058 - val_accuracy: 0.8808\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2506 - accuracy: 0.8988\n",
      "Epoch 68: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.8988 - val_loss: 0.3369 - val_accuracy: 0.8569\n",
      "Epoch 69/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1653 - accuracy: 0.9194\n",
      "Epoch 69: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.9003 - val_loss: 0.3015 - val_accuracy: 0.8808\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2275 - accuracy: 0.8952\n",
      "Epoch 70: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2405 - accuracy: 0.9024 - val_loss: 0.3087 - val_accuracy: 0.8746\n",
      "Epoch 71/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2408 - accuracy: 0.9013\n",
      "Epoch 71: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2430 - accuracy: 0.8999 - val_loss: 0.3516 - val_accuracy: 0.8569\n",
      "Epoch 72/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2526 - accuracy: 0.8925\n",
      "Epoch 72: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.8921 - val_loss: 0.3059 - val_accuracy: 0.8715\n",
      "Epoch 73/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2563 - accuracy: 0.8958\n",
      "Epoch 73: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.8932 - val_loss: 0.2978 - val_accuracy: 0.8762\n",
      "Epoch 74/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2430 - accuracy: 0.8989\n",
      "Epoch 74: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2423 - accuracy: 0.9001 - val_loss: 0.3185 - val_accuracy: 0.8723\n",
      "Epoch 75/1000\n",
      "28/42 [===================>..........] - ETA: 0s - loss: 0.2379 - accuracy: 0.9012\n",
      "Epoch 75: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2378 - accuracy: 0.9038 - val_loss: 0.3016 - val_accuracy: 0.8777\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1412 - accuracy: 0.9516\n",
      "Epoch 76: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2375 - accuracy: 0.9032 - val_loss: 0.3059 - val_accuracy: 0.8815\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2124 - accuracy: 0.9032\n",
      "Epoch 77: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2351 - accuracy: 0.9030 - val_loss: 0.3143 - val_accuracy: 0.8669\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1668 - accuracy: 0.9355\n",
      "Epoch 78: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2389 - accuracy: 0.8992 - val_loss: 0.3019 - val_accuracy: 0.8723\n",
      "Epoch 79/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2381 - accuracy: 0.9024\n",
      "Epoch 79: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2372 - accuracy: 0.9030 - val_loss: 0.3219 - val_accuracy: 0.8677\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2304 - accuracy: 0.8952\n",
      "Epoch 80: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2335 - accuracy: 0.9063 - val_loss: 0.3053 - val_accuracy: 0.8785\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1778 - accuracy: 0.9435\n",
      "Epoch 81: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2427 - accuracy: 0.8971 - val_loss: 0.3288 - val_accuracy: 0.8585\n",
      "Epoch 82/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2687 - accuracy: 0.9113\n",
      "Epoch 82: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2364 - accuracy: 0.9009 - val_loss: 0.3159 - val_accuracy: 0.8754\n",
      "Epoch 83/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2366 - accuracy: 0.9013\n",
      "Epoch 83: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.9013 - val_loss: 0.3162 - val_accuracy: 0.8685\n",
      "Epoch 84/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2434 - accuracy: 0.8548\n",
      "Epoch 84: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2253 - accuracy: 0.9080 - val_loss: 0.3027 - val_accuracy: 0.8762\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2567 - accuracy: 0.9032\n",
      "Epoch 85: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2263 - accuracy: 0.9082 - val_loss: 0.3035 - val_accuracy: 0.8838\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1649 - accuracy: 0.9435\n",
      "Epoch 86: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2199 - accuracy: 0.9111 - val_loss: 0.3036 - val_accuracy: 0.8808\n",
      "Epoch 87/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1844 - accuracy: 0.9274\n",
      "Epoch 87: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2287 - accuracy: 0.9059 - val_loss: 0.3102 - val_accuracy: 0.8769\n",
      "Epoch 88/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2983 - accuracy: 0.8710\n",
      "Epoch 88: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8974 - val_loss: 0.3219 - val_accuracy: 0.8677\n",
      "Epoch 89/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2024 - accuracy: 0.9032\n",
      "Epoch 89: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2341 - accuracy: 0.9055 - val_loss: 0.3173 - val_accuracy: 0.8677\n",
      "Epoch 90/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2845 - accuracy: 0.8952\n",
      "Epoch 90: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2262 - accuracy: 0.9065 - val_loss: 0.3059 - val_accuracy: 0.8823\n",
      "Epoch 91/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2429 - accuracy: 0.8952\n",
      "Epoch 91: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2295 - accuracy: 0.9048 - val_loss: 0.3196 - val_accuracy: 0.8692\n",
      "Epoch 92/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2276 - accuracy: 0.9032\n",
      "Epoch 92: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2353 - accuracy: 0.9051 - val_loss: 0.3229 - val_accuracy: 0.8669\n",
      "Epoch 93/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1394 - accuracy: 0.9516\n",
      "Epoch 93: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2283 - accuracy: 0.9074 - val_loss: 0.3168 - val_accuracy: 0.8754\n",
      "Epoch 94/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1331 - accuracy: 0.9355\n",
      "Epoch 94: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.9069 - val_loss: 0.3163 - val_accuracy: 0.8715\n",
      "Epoch 95/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2148 - accuracy: 0.8710\n",
      "Epoch 95: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2205 - accuracy: 0.9099 - val_loss: 0.3121 - val_accuracy: 0.8792\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2705 - accuracy: 0.8710\n",
      "Epoch 96: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2202 - accuracy: 0.9065 - val_loss: 0.3109 - val_accuracy: 0.8692\n",
      "Epoch 97/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2087 - accuracy: 0.9113\n",
      "Epoch 97: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2167 - accuracy: 0.9126 - val_loss: 0.3086 - val_accuracy: 0.8792\n",
      "Epoch 98/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2645 - accuracy: 0.8871\n",
      "Epoch 98: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2201 - accuracy: 0.9099 - val_loss: 0.3181 - val_accuracy: 0.8808\n",
      "Epoch 99/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2077 - accuracy: 0.9355\n",
      "Epoch 99: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2297 - accuracy: 0.9044 - val_loss: 0.3189 - val_accuracy: 0.8631\n",
      "Epoch 100/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1957 - accuracy: 0.9032\n",
      "Epoch 100: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2142 - accuracy: 0.9167 - val_loss: 0.3351 - val_accuracy: 0.8631\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1472 - accuracy: 0.9355\n",
      "Epoch 101: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2288 - accuracy: 0.9051 - val_loss: 0.3149 - val_accuracy: 0.8762\n",
      "Epoch 102/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2009 - accuracy: 0.9274\n",
      "Epoch 102: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.9151 - val_loss: 0.3225 - val_accuracy: 0.8692\n",
      "Epoch 103/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2149 - accuracy: 0.9140\n",
      "Epoch 103: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2149 - accuracy: 0.9140 - val_loss: 0.3268 - val_accuracy: 0.8662\n",
      "Epoch 104/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2072 - accuracy: 0.8952\n",
      "Epoch 104: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2283 - accuracy: 0.9086 - val_loss: 0.3245 - val_accuracy: 0.8654\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2315 - accuracy: 0.9355\n",
      "Epoch 105: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2148 - accuracy: 0.9132 - val_loss: 0.3335 - val_accuracy: 0.8677\n",
      "Epoch 106/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1757 - accuracy: 0.9274\n",
      "Epoch 106: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2237 - accuracy: 0.9084 - val_loss: 0.3248 - val_accuracy: 0.8654\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1882 - accuracy: 0.9355\n",
      "Epoch 107: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2185 - accuracy: 0.9115 - val_loss: 0.3130 - val_accuracy: 0.8723\n",
      "Epoch 108/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2698 - accuracy: 0.8952\n",
      "Epoch 108: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2133 - accuracy: 0.9163 - val_loss: 0.3428 - val_accuracy: 0.8623\n",
      "Epoch 109/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2198 - accuracy: 0.8952\n",
      "Epoch 109: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2196 - accuracy: 0.9109 - val_loss: 0.3308 - val_accuracy: 0.8715\n",
      "Epoch 110/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2090 - accuracy: 0.9274\n",
      "Epoch 110: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2084 - accuracy: 0.9142 - val_loss: 0.3153 - val_accuracy: 0.8723\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1759 - accuracy: 0.9274\n",
      "Epoch 111: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.9167 - val_loss: 0.3221 - val_accuracy: 0.8685\n",
      "Epoch 112/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1852 - accuracy: 0.9113\n",
      "Epoch 112: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2133 - accuracy: 0.9140 - val_loss: 0.3317 - val_accuracy: 0.8677\n",
      "Epoch 113/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.2199 - accuracy: 0.9110\n",
      "Epoch 113: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2150 - accuracy: 0.9130 - val_loss: 0.3214 - val_accuracy: 0.8692\n",
      "Epoch 114/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2384 - accuracy: 0.9032\n",
      "Epoch 114: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2095 - accuracy: 0.9155 - val_loss: 0.3215 - val_accuracy: 0.8731\n",
      "Epoch 115/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2028 - accuracy: 0.9194\n",
      "Epoch 115: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2075 - accuracy: 0.9182 - val_loss: 0.3757 - val_accuracy: 0.8438\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3155 - accuracy: 0.8468\n",
      "Epoch 116: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2075 - accuracy: 0.9144 - val_loss: 0.3269 - val_accuracy: 0.8731\n",
      "Epoch 117/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2091 - accuracy: 0.9130\n",
      "Epoch 117: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2091 - accuracy: 0.9130 - val_loss: 0.3284 - val_accuracy: 0.8769\n",
      "Epoch 118/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2288 - accuracy: 0.9274\n",
      "Epoch 118: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2073 - accuracy: 0.9192 - val_loss: 0.3904 - val_accuracy: 0.8585\n",
      "Epoch 119/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3410 - accuracy: 0.8468\n",
      "Epoch 119: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2192 - accuracy: 0.9074 - val_loss: 0.3405 - val_accuracy: 0.8646\n",
      "Epoch 120/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1308 - accuracy: 0.9516\n",
      "Epoch 120: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2037 - accuracy: 0.9192 - val_loss: 0.3554 - val_accuracy: 0.8623\n",
      "Epoch 121/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2103 - accuracy: 0.9130\n",
      "Epoch 121: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.9130 - val_loss: 0.3242 - val_accuracy: 0.8631\n",
      "Epoch 122/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2584 - accuracy: 0.8871\n",
      "Epoch 122: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2125 - accuracy: 0.9115 - val_loss: 0.3210 - val_accuracy: 0.8731\n",
      "Epoch 123/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2434 - accuracy: 0.9113\n",
      "Epoch 123: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2002 - accuracy: 0.9232 - val_loss: 0.3442 - val_accuracy: 0.8654\n",
      "Epoch 124/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3375 - accuracy: 0.8710\n",
      "Epoch 124: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2068 - accuracy: 0.9157 - val_loss: 0.3345 - val_accuracy: 0.8731\n",
      "Epoch 125/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1987 - accuracy: 0.9237\n",
      "Epoch 125: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1997 - accuracy: 0.9228 - val_loss: 0.3297 - val_accuracy: 0.8731\n",
      "Epoch 126/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1534 - accuracy: 0.9435\n",
      "Epoch 126: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1957 - accuracy: 0.9228 - val_loss: 0.3271 - val_accuracy: 0.8746\n",
      "Epoch 127/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1941 - accuracy: 0.9032\n",
      "Epoch 127: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2074 - accuracy: 0.9180 - val_loss: 0.3468 - val_accuracy: 0.8700\n",
      "Epoch 128/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2551 - accuracy: 0.8871\n",
      "Epoch 128: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2122 - accuracy: 0.9146 - val_loss: 0.3234 - val_accuracy: 0.8731\n",
      "Epoch 129/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1981 - accuracy: 0.9213\n",
      "Epoch 129: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.9194 - val_loss: 0.3303 - val_accuracy: 0.8754\n",
      "Epoch 130/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1568 - accuracy: 0.9355\n",
      "Epoch 130: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2005 - accuracy: 0.9175 - val_loss: 0.3317 - val_accuracy: 0.8731\n",
      "Epoch 131/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1895 - accuracy: 0.9355\n",
      "Epoch 131: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2080 - accuracy: 0.9132 - val_loss: 0.3309 - val_accuracy: 0.8715\n",
      "Epoch 132/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1673 - accuracy: 0.9194\n",
      "Epoch 132: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1915 - accuracy: 0.9217 - val_loss: 0.3343 - val_accuracy: 0.8677\n",
      "Epoch 133/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2116 - accuracy: 0.9194\n",
      "Epoch 133: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.9219 - val_loss: 0.3463 - val_accuracy: 0.8669\n",
      "Epoch 134/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1991 - accuracy: 0.9211\n",
      "Epoch 134: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1975 - accuracy: 0.9217 - val_loss: 0.3415 - val_accuracy: 0.8685\n",
      "Epoch 135/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1510 - accuracy: 0.9516\n",
      "Epoch 135: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1927 - accuracy: 0.9242 - val_loss: 0.3491 - val_accuracy: 0.8638\n",
      "Epoch 136/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1935 - accuracy: 0.9201\n",
      "Epoch 136: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1924 - accuracy: 0.9205 - val_loss: 0.3347 - val_accuracy: 0.8669\n",
      "Epoch 137/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1967 - accuracy: 0.9178\n",
      "Epoch 137: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.9178 - val_loss: 0.3392 - val_accuracy: 0.8708\n",
      "Epoch 138/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1532 - accuracy: 0.9435\n",
      "Epoch 138: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1901 - accuracy: 0.9246 - val_loss: 0.3430 - val_accuracy: 0.8762\n",
      "Epoch 139/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2224 - accuracy: 0.9194\n",
      "Epoch 139: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1862 - accuracy: 0.9267 - val_loss: 0.3456 - val_accuracy: 0.8738\n",
      "Epoch 140/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1645 - accuracy: 0.9355\n",
      "Epoch 140: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.9273 - val_loss: 0.3364 - val_accuracy: 0.8723\n",
      "Epoch 141/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1639 - accuracy: 0.9274\n",
      "Epoch 141: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.9265 - val_loss: 0.3515 - val_accuracy: 0.8677\n",
      "Epoch 142/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1861 - accuracy: 0.9264\n",
      "Epoch 142: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.9257 - val_loss: 0.3570 - val_accuracy: 0.8723\n",
      "Epoch 143/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2246 - accuracy: 0.9194\n",
      "Epoch 143: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1912 - accuracy: 0.9251 - val_loss: 0.3402 - val_accuracy: 0.8738\n",
      "Epoch 144/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.0961 - accuracy: 0.9597\n",
      "Epoch 144: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.9273 - val_loss: 0.3420 - val_accuracy: 0.8754\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2083 - accuracy: 0.8710\n",
      "Epoch 145: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.9230 - val_loss: 0.3821 - val_accuracy: 0.8638\n",
      "Epoch 146/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2296 - accuracy: 0.9032\n",
      "Epoch 146: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.9275 - val_loss: 0.3481 - val_accuracy: 0.8615\n",
      "Epoch 147/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1383 - accuracy: 0.9435\n",
      "Epoch 147: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.9255 - val_loss: 0.3456 - val_accuracy: 0.8723\n",
      "Epoch 148/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1851 - accuracy: 0.9194\n",
      "Epoch 148: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.9209 - val_loss: 0.3468 - val_accuracy: 0.8685\n",
      "Epoch 149/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1969 - accuracy: 0.9274\n",
      "Epoch 149: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2005 - accuracy: 0.9173 - val_loss: 0.3455 - val_accuracy: 0.8677\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2010 - accuracy: 0.9113\n",
      "Epoch 150: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.9261 - val_loss: 0.3500 - val_accuracy: 0.8662\n",
      "Epoch 151/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1889 - accuracy: 0.9516\n",
      "Epoch 151: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1877 - accuracy: 0.9226 - val_loss: 0.3540 - val_accuracy: 0.8715\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 22s - loss: 2.8601 - accuracy: 0.4435\n",
      "Epoch 1: val_accuracy improved from -inf to 0.70462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.9273 - accuracy: 0.5911 - val_loss: 0.5709 - val_accuracy: 0.7046\n",
      "Epoch 2/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.5525 - accuracy: 0.7581\n",
      "Epoch 2: val_accuracy improved from 0.70462 to 0.78846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.7552 - val_loss: 0.4457 - val_accuracy: 0.7885\n",
      "Epoch 3/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4458 - accuracy: 0.7661\n",
      "Epoch 3: val_accuracy improved from 0.78846 to 0.84538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8185 - val_loss: 0.3759 - val_accuracy: 0.8454\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3719 - accuracy: 0.8434\n",
      "Epoch 4: val_accuracy did not improve from 0.84538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8434 - val_loss: 0.3634 - val_accuracy: 0.8446\n",
      "Epoch 5/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3769 - accuracy: 0.8871\n",
      "Epoch 5: val_accuracy improved from 0.84538 to 0.85385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3459 - accuracy: 0.8591 - val_loss: 0.3465 - val_accuracy: 0.8538\n",
      "Epoch 6/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3394 - accuracy: 0.8601\n",
      "Epoch 6: val_accuracy did not improve from 0.85385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8591 - val_loss: 0.3623 - val_accuracy: 0.8431\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3338 - accuracy: 0.8651\n",
      "Epoch 7: val_accuracy improved from 0.85385 to 0.85846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3338 - accuracy: 0.8651 - val_loss: 0.3404 - val_accuracy: 0.8585\n",
      "Epoch 8/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2810 - accuracy: 0.8871\n",
      "Epoch 8: val_accuracy did not improve from 0.85846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3253 - accuracy: 0.8674 - val_loss: 0.3317 - val_accuracy: 0.8577\n",
      "Epoch 9/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3768 - accuracy: 0.8548\n",
      "Epoch 9: val_accuracy did not improve from 0.85846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8630 - val_loss: 0.3478 - val_accuracy: 0.8523\n",
      "Epoch 10/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2741 - accuracy: 0.8871\n",
      "Epoch 10: val_accuracy did not improve from 0.85846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.8559 - val_loss: 0.4204 - val_accuracy: 0.8131\n",
      "Epoch 11/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4912 - accuracy: 0.7903\n",
      "Epoch 11: val_accuracy did not improve from 0.85846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8574 - val_loss: 0.3458 - val_accuracy: 0.8485\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3062 - accuracy: 0.8548\n",
      "Epoch 12: val_accuracy did not improve from 0.85846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8682 - val_loss: 0.3412 - val_accuracy: 0.8577\n",
      "Epoch 13/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2961 - accuracy: 0.8952\n",
      "Epoch 13: val_accuracy improved from 0.85846 to 0.86077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3144 - accuracy: 0.8684 - val_loss: 0.3419 - val_accuracy: 0.8608\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3067 - accuracy: 0.8745\n",
      "Epoch 14: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8745 - val_loss: 0.3309 - val_accuracy: 0.8608\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4034 - accuracy: 0.8306\n",
      "Epoch 15: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8636 - val_loss: 0.3310 - val_accuracy: 0.8608\n",
      "Epoch 16/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3027 - accuracy: 0.8710\n",
      "Epoch 16: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8744 - val_loss: 0.3283 - val_accuracy: 0.8608\n",
      "Epoch 17/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3072 - accuracy: 0.8739\n",
      "Epoch 17: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8734 - val_loss: 0.3283 - val_accuracy: 0.8569\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2478 - accuracy: 0.9032\n",
      "Epoch 18: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8684 - val_loss: 0.3261 - val_accuracy: 0.8577\n",
      "Epoch 19/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3430 - accuracy: 0.8387\n",
      "Epoch 19: val_accuracy improved from 0.86077 to 0.86385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3032 - accuracy: 0.8686 - val_loss: 0.3308 - val_accuracy: 0.8638\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2988 - accuracy: 0.8757\n",
      "Epoch 20: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2988 - accuracy: 0.8757 - val_loss: 0.3271 - val_accuracy: 0.8608\n",
      "Epoch 21/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3113 - accuracy: 0.8633\n",
      "Epoch 21: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.8632 - val_loss: 0.3249 - val_accuracy: 0.8562\n",
      "Epoch 22/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2779 - accuracy: 0.8871\n",
      "Epoch 22: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8757 - val_loss: 0.3228 - val_accuracy: 0.8592\n",
      "Epoch 23/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2018 - accuracy: 0.9032\n",
      "Epoch 23: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.8699 - val_loss: 0.3440 - val_accuracy: 0.8638\n",
      "Epoch 24/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3165 - accuracy: 0.8629\n",
      "Epoch 24: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8642 - val_loss: 0.3259 - val_accuracy: 0.8638\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2696 - accuracy: 0.8952\n",
      "Epoch 25: val_accuracy improved from 0.86385 to 0.86538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3018 - accuracy: 0.8730 - val_loss: 0.3250 - val_accuracy: 0.8654\n",
      "Epoch 26/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2531 - accuracy: 0.9113\n",
      "Epoch 26: val_accuracy improved from 0.86538 to 0.86615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8661 - val_loss: 0.3308 - val_accuracy: 0.8662\n",
      "Epoch 27/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2534 - accuracy: 0.8871\n",
      "Epoch 27: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2995 - accuracy: 0.8740 - val_loss: 0.3261 - val_accuracy: 0.8654\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2743 - accuracy: 0.9113\n",
      "Epoch 28: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2922 - accuracy: 0.8765 - val_loss: 0.3324 - val_accuracy: 0.8654\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2986 - accuracy: 0.8871\n",
      "Epoch 29: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2947 - accuracy: 0.8786 - val_loss: 0.4549 - val_accuracy: 0.8085\n",
      "Epoch 30/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2772 - accuracy: 0.8629\n",
      "Epoch 30: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3058 - accuracy: 0.8676 - val_loss: 0.3157 - val_accuracy: 0.8646\n",
      "Epoch 31/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3641 - accuracy: 0.8710\n",
      "Epoch 31: val_accuracy improved from 0.86615 to 0.86769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2910 - accuracy: 0.8828 - val_loss: 0.3142 - val_accuracy: 0.8677\n",
      "Epoch 32/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.3048 - accuracy: 0.8692\n",
      "Epoch 32: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3024 - accuracy: 0.8701 - val_loss: 0.3214 - val_accuracy: 0.8608\n",
      "Epoch 33/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2785 - accuracy: 0.8871\n",
      "Epoch 33: val_accuracy improved from 0.86769 to 0.87077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2797 - accuracy: 0.8836 - val_loss: 0.3136 - val_accuracy: 0.8708\n",
      "Epoch 34/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3174 - accuracy: 0.8710\n",
      "Epoch 34: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2776 - accuracy: 0.8847 - val_loss: 0.3101 - val_accuracy: 0.8692\n",
      "Epoch 35/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2650 - accuracy: 0.8871\n",
      "Epoch 35: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2711 - accuracy: 0.8880 - val_loss: 0.3084 - val_accuracy: 0.8708\n",
      "Epoch 36/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2895 - accuracy: 0.9113\n",
      "Epoch 36: val_accuracy improved from 0.87077 to 0.87385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.8838 - val_loss: 0.3045 - val_accuracy: 0.8738\n",
      "Epoch 37/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2474 - accuracy: 0.9435\n",
      "Epoch 37: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2775 - accuracy: 0.8820 - val_loss: 0.3209 - val_accuracy: 0.8608\n",
      "Epoch 38/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3056 - accuracy: 0.8871\n",
      "Epoch 38: val_accuracy improved from 0.87385 to 0.87615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2764 - accuracy: 0.8863 - val_loss: 0.3159 - val_accuracy: 0.8762\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2719 - accuracy: 0.8857\n",
      "Epoch 39: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2719 - accuracy: 0.8857 - val_loss: 0.3138 - val_accuracy: 0.8662\n",
      "Epoch 40/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2697 - accuracy: 0.8790\n",
      "Epoch 40: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2749 - accuracy: 0.8832 - val_loss: 0.3360 - val_accuracy: 0.8531\n",
      "Epoch 41/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2881 - accuracy: 0.8629\n",
      "Epoch 41: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2960 - accuracy: 0.8792 - val_loss: 0.3208 - val_accuracy: 0.8592\n",
      "Epoch 42/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2639 - accuracy: 0.8908\n",
      "Epoch 42: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2625 - accuracy: 0.8915 - val_loss: 0.3212 - val_accuracy: 0.8754\n",
      "Epoch 43/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2158 - accuracy: 0.8952\n",
      "Epoch 43: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2718 - accuracy: 0.8826 - val_loss: 0.2955 - val_accuracy: 0.8762\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3011 - accuracy: 0.8952\n",
      "Epoch 44: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2596 - accuracy: 0.8942 - val_loss: 0.3199 - val_accuracy: 0.8708\n",
      "Epoch 45/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1941 - accuracy: 0.9032\n",
      "Epoch 45: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2644 - accuracy: 0.8894 - val_loss: 0.3009 - val_accuracy: 0.8723\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2571 - accuracy: 0.8938\n",
      "Epoch 46: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2571 - accuracy: 0.8938 - val_loss: 0.2965 - val_accuracy: 0.8754\n",
      "Epoch 47/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2612 - accuracy: 0.8952\n",
      "Epoch 47: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2591 - accuracy: 0.8959 - val_loss: 0.2992 - val_accuracy: 0.8754\n",
      "Epoch 48/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3195 - accuracy: 0.8629\n",
      "Epoch 48: val_accuracy improved from 0.87615 to 0.88000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.8919 - val_loss: 0.3001 - val_accuracy: 0.8800\n",
      "Epoch 49/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3133 - accuracy: 0.8468\n",
      "Epoch 49: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2643 - accuracy: 0.8905 - val_loss: 0.3277 - val_accuracy: 0.8592\n",
      "Epoch 50/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.2781 - accuracy: 0.8820\n",
      "Epoch 50: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2736 - accuracy: 0.8819 - val_loss: 0.3593 - val_accuracy: 0.8523\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2704 - accuracy: 0.8548\n",
      "Epoch 51: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2814 - accuracy: 0.8851 - val_loss: 0.3049 - val_accuracy: 0.8762\n",
      "Epoch 52/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1954 - accuracy: 0.9355\n",
      "Epoch 52: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2658 - accuracy: 0.8872 - val_loss: 0.3202 - val_accuracy: 0.8654\n",
      "Epoch 53/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2497 - accuracy: 0.9113\n",
      "Epoch 53: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2552 - accuracy: 0.8971 - val_loss: 0.3030 - val_accuracy: 0.8762\n",
      "Epoch 54/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2583 - accuracy: 0.8941\n",
      "Epoch 54: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2559 - accuracy: 0.8959 - val_loss: 0.3144 - val_accuracy: 0.8708\n",
      "Epoch 55/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2370 - accuracy: 0.8952\n",
      "Epoch 55: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.8976 - val_loss: 0.3013 - val_accuracy: 0.8754\n",
      "Epoch 56/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2075 - accuracy: 0.9113\n",
      "Epoch 56: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2526 - accuracy: 0.8959 - val_loss: 0.2989 - val_accuracy: 0.8754\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2759 - accuracy: 0.8710\n",
      "Epoch 57: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.9015 - val_loss: 0.2945 - val_accuracy: 0.8762\n",
      "Epoch 58/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2374 - accuracy: 0.8952\n",
      "Epoch 58: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.8969 - val_loss: 0.3271 - val_accuracy: 0.8608\n",
      "Epoch 59/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2460 - accuracy: 0.8954\n",
      "Epoch 59: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2484 - accuracy: 0.8949 - val_loss: 0.2962 - val_accuracy: 0.8746\n",
      "Epoch 60/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3190 - accuracy: 0.8306\n",
      "Epoch 60: val_accuracy improved from 0.88000 to 0.88077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.8980 - val_loss: 0.2955 - val_accuracy: 0.8808\n",
      "Epoch 61/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2067 - accuracy: 0.8871\n",
      "Epoch 61: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.8992 - val_loss: 0.2964 - val_accuracy: 0.8723\n",
      "Epoch 62/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2468 - accuracy: 0.8984\n",
      "Epoch 62: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.8984 - val_loss: 0.2967 - val_accuracy: 0.8762\n",
      "Epoch 63/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2004 - accuracy: 0.9113\n",
      "Epoch 63: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.8974 - val_loss: 0.3043 - val_accuracy: 0.8769\n",
      "Epoch 64/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2643 - accuracy: 0.8952\n",
      "Epoch 64: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.8959 - val_loss: 0.2970 - val_accuracy: 0.8769\n",
      "Epoch 65/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2556 - accuracy: 0.9032\n",
      "Epoch 65: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2477 - accuracy: 0.8926 - val_loss: 0.3170 - val_accuracy: 0.8692\n",
      "Epoch 66/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1912 - accuracy: 0.9113\n",
      "Epoch 66: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.8938 - val_loss: 0.3032 - val_accuracy: 0.8746\n",
      "Epoch 67/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2310 - accuracy: 0.8952\n",
      "Epoch 67: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.8971 - val_loss: 0.2982 - val_accuracy: 0.8723\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1928 - accuracy: 0.9113\n",
      "Epoch 68: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.8946 - val_loss: 0.3061 - val_accuracy: 0.8777\n",
      "Epoch 69/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2336 - accuracy: 0.9274\n",
      "Epoch 69: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.8994 - val_loss: 0.2956 - val_accuracy: 0.8738\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1667 - accuracy: 0.9194\n",
      "Epoch 70: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.8961 - val_loss: 0.2943 - val_accuracy: 0.8738\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1801 - accuracy: 0.9274\n",
      "Epoch 71: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2526 - accuracy: 0.8963 - val_loss: 0.3467 - val_accuracy: 0.8523\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2698 - accuracy: 0.8871\n",
      "Epoch 72: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2427 - accuracy: 0.8994 - val_loss: 0.3178 - val_accuracy: 0.8623\n",
      "Epoch 73/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2473 - accuracy: 0.8952\n",
      "Epoch 73: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2414 - accuracy: 0.8996 - val_loss: 0.3186 - val_accuracy: 0.8715\n",
      "Epoch 74/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2582 - accuracy: 0.8952\n",
      "Epoch 74: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2352 - accuracy: 0.9061 - val_loss: 0.3510 - val_accuracy: 0.8600\n",
      "Epoch 75/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.2474 - accuracy: 0.8947\n",
      "Epoch 75: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.8955 - val_loss: 0.3048 - val_accuracy: 0.8715\n",
      "Epoch 76/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2400 - accuracy: 0.9020\n",
      "Epoch 76: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2429 - accuracy: 0.8990 - val_loss: 0.3103 - val_accuracy: 0.8731\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2095 - accuracy: 0.9113\n",
      "Epoch 77: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2654 - accuracy: 0.8840 - val_loss: 0.3141 - val_accuracy: 0.8754\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3711 - accuracy: 0.8306\n",
      "Epoch 78: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.8949 - val_loss: 0.3032 - val_accuracy: 0.8762\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2825 - accuracy: 0.9113\n",
      "Epoch 79: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8972 - val_loss: 0.3195 - val_accuracy: 0.8754\n",
      "Epoch 80/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2492 - accuracy: 0.8947\n",
      "Epoch 80: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.8938 - val_loss: 0.3190 - val_accuracy: 0.8692\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2367 - accuracy: 0.8710\n",
      "Epoch 81: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2335 - accuracy: 0.9028 - val_loss: 0.3428 - val_accuracy: 0.8585\n",
      "Epoch 82/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2238 - accuracy: 0.8871\n",
      "Epoch 82: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2338 - accuracy: 0.9065 - val_loss: 0.2991 - val_accuracy: 0.8746\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2598 - accuracy: 0.9113\n",
      "Epoch 83: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2270 - accuracy: 0.9103 - val_loss: 0.3009 - val_accuracy: 0.8677\n",
      "Epoch 84/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1869 - accuracy: 0.9355\n",
      "Epoch 84: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.9024 - val_loss: 0.2996 - val_accuracy: 0.8754\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2355 - accuracy: 0.9194\n",
      "Epoch 85: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2359 - accuracy: 0.9034 - val_loss: 0.3559 - val_accuracy: 0.8600\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2478 - accuracy: 0.9032\n",
      "Epoch 86: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2248 - accuracy: 0.9103 - val_loss: 0.3089 - val_accuracy: 0.8762\n",
      "Epoch 87/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1924 - accuracy: 0.9194\n",
      "Epoch 87: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2334 - accuracy: 0.9042 - val_loss: 0.2963 - val_accuracy: 0.8677\n",
      "Epoch 88/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1376 - accuracy: 0.9597\n",
      "Epoch 88: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2318 - accuracy: 0.9065 - val_loss: 0.3261 - val_accuracy: 0.8723\n",
      "Epoch 89/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3114 - accuracy: 0.8710\n",
      "Epoch 89: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.9088 - val_loss: 0.3021 - val_accuracy: 0.8754\n",
      "Epoch 90/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1901 - accuracy: 0.9113\n",
      "Epoch 90: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.9067 - val_loss: 0.2994 - val_accuracy: 0.8708\n",
      "Epoch 91/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2028 - accuracy: 0.9194\n",
      "Epoch 91: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.9074 - val_loss: 0.3481 - val_accuracy: 0.8592\n",
      "Epoch 92/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2444 - accuracy: 0.8952\n",
      "Epoch 92: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2268 - accuracy: 0.9071 - val_loss: 0.3060 - val_accuracy: 0.8746\n",
      "Epoch 93/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2076 - accuracy: 0.9032\n",
      "Epoch 93: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2256 - accuracy: 0.9073 - val_loss: 0.3090 - val_accuracy: 0.8715\n",
      "Epoch 94/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2778 - accuracy: 0.8629\n",
      "Epoch 94: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.9053 - val_loss: 0.3453 - val_accuracy: 0.8623\n",
      "Epoch 95/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2308 - accuracy: 0.8790\n",
      "Epoch 95: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9121 - val_loss: 0.3314 - val_accuracy: 0.8654\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2195 - accuracy: 0.8871\n",
      "Epoch 96: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.9038 - val_loss: 0.3306 - val_accuracy: 0.8762\n",
      "Epoch 97/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1601 - accuracy: 0.9597\n",
      "Epoch 97: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2183 - accuracy: 0.9130 - val_loss: 0.3137 - val_accuracy: 0.8685\n",
      "Epoch 98/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1934 - accuracy: 0.9194\n",
      "Epoch 98: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2393 - accuracy: 0.8994 - val_loss: 0.3516 - val_accuracy: 0.8646\n",
      "Epoch 99/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2830 - accuracy: 0.8790\n",
      "Epoch 99: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2436 - accuracy: 0.8996 - val_loss: 0.3045 - val_accuracy: 0.8769\n",
      "Epoch 100/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2289 - accuracy: 0.9274\n",
      "Epoch 100: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2192 - accuracy: 0.9128 - val_loss: 0.3142 - val_accuracy: 0.8738\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2585 - accuracy: 0.9113\n",
      "Epoch 101: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2218 - accuracy: 0.9101 - val_loss: 0.3151 - val_accuracy: 0.8723\n",
      "Epoch 102/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1910 - accuracy: 0.9032\n",
      "Epoch 102: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2161 - accuracy: 0.9173 - val_loss: 0.3279 - val_accuracy: 0.8700\n",
      "Epoch 103/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1711 - accuracy: 0.9355\n",
      "Epoch 103: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2377 - accuracy: 0.8996 - val_loss: 0.3484 - val_accuracy: 0.8623\n",
      "Epoch 104/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2073 - accuracy: 0.9194\n",
      "Epoch 104: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2240 - accuracy: 0.9078 - val_loss: 0.3099 - val_accuracy: 0.8692\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2148 - accuracy: 0.9113\n",
      "Epoch 105: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2207 - accuracy: 0.9080 - val_loss: 0.3170 - val_accuracy: 0.8723\n",
      "Epoch 106/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2159 - accuracy: 0.9113\n",
      "Epoch 106: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2126 - accuracy: 0.9161 - val_loss: 0.3117 - val_accuracy: 0.8692\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2510 - accuracy: 0.8952\n",
      "Epoch 107: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.9115 - val_loss: 0.3381 - val_accuracy: 0.8654\n",
      "Epoch 108/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2376 - accuracy: 0.8710\n",
      "Epoch 108: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2128 - accuracy: 0.9138 - val_loss: 0.3196 - val_accuracy: 0.8746\n",
      "Epoch 109/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2114 - accuracy: 0.9150\n",
      "Epoch 109: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2114 - accuracy: 0.9150 - val_loss: 0.3292 - val_accuracy: 0.8738\n",
      "Epoch 110/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1798 - accuracy: 0.8952\n",
      "Epoch 110: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2115 - accuracy: 0.9155 - val_loss: 0.3681 - val_accuracy: 0.8546\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3322 - accuracy: 0.8468\n",
      "Epoch 111: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2167 - accuracy: 0.9101 - val_loss: 0.3478 - val_accuracy: 0.8615\n",
      "Epoch 112/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2672 - accuracy: 0.8952\n",
      "Epoch 112: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 0.9086 - val_loss: 0.3491 - val_accuracy: 0.8600\n",
      "Epoch 113/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1628 - accuracy: 0.9194\n",
      "Epoch 113: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2265 - accuracy: 0.9061 - val_loss: 0.3229 - val_accuracy: 0.8723\n",
      "Epoch 114/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2044 - accuracy: 0.9211\n",
      "Epoch 114: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2043 - accuracy: 0.9209 - val_loss: 0.3273 - val_accuracy: 0.8638\n",
      "Epoch 115/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2820 - accuracy: 0.8952\n",
      "Epoch 115: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2124 - accuracy: 0.9117 - val_loss: 0.3541 - val_accuracy: 0.8638\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1649 - accuracy: 0.9355\n",
      "Epoch 116: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2126 - accuracy: 0.9140 - val_loss: 0.3221 - val_accuracy: 0.8723\n",
      "Epoch 117/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1597 - accuracy: 0.9435\n",
      "Epoch 117: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2067 - accuracy: 0.9176 - val_loss: 0.3258 - val_accuracy: 0.8685\n",
      "Epoch 118/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1956 - accuracy: 0.9194\n",
      "Epoch 118: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2328 - accuracy: 0.9015 - val_loss: 0.3249 - val_accuracy: 0.8708\n",
      "Epoch 119/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2265 - accuracy: 0.9032\n",
      "Epoch 119: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.9088 - val_loss: 0.3200 - val_accuracy: 0.8708\n",
      "Epoch 120/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2038 - accuracy: 0.9113\n",
      "Epoch 120: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2013 - accuracy: 0.9213 - val_loss: 0.3217 - val_accuracy: 0.8623\n",
      "Epoch 121/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2351 - accuracy: 0.9194\n",
      "Epoch 121: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2066 - accuracy: 0.9142 - val_loss: 0.3283 - val_accuracy: 0.8654\n",
      "Epoch 122/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2388 - accuracy: 0.8790\n",
      "Epoch 122: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2006 - accuracy: 0.9198 - val_loss: 0.3332 - val_accuracy: 0.8738\n",
      "Epoch 123/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1469 - accuracy: 0.9355\n",
      "Epoch 123: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2091 - accuracy: 0.9121 - val_loss: 0.3227 - val_accuracy: 0.8708\n",
      "Epoch 124/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2028 - accuracy: 0.9159\n",
      "Epoch 124: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2028 - accuracy: 0.9159 - val_loss: 0.3397 - val_accuracy: 0.8646\n",
      "Epoch 125/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1715 - accuracy: 0.9435\n",
      "Epoch 125: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1990 - accuracy: 0.9207 - val_loss: 0.3374 - val_accuracy: 0.8692\n",
      "Epoch 126/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2483 - accuracy: 0.9032\n",
      "Epoch 126: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 0.9178 - val_loss: 0.3612 - val_accuracy: 0.8662\n",
      "Epoch 127/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2423 - accuracy: 0.9032\n",
      "Epoch 127: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.9130 - val_loss: 0.3401 - val_accuracy: 0.8600\n",
      "Epoch 128/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1318 - accuracy: 0.9597\n",
      "Epoch 128: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2037 - accuracy: 0.9171 - val_loss: 0.3376 - val_accuracy: 0.8692\n",
      "Epoch 129/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2958 - accuracy: 0.8387\n",
      "Epoch 129: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1989 - accuracy: 0.9200 - val_loss: 0.3375 - val_accuracy: 0.8700\n",
      "Epoch 130/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2154 - accuracy: 0.9113\n",
      "Epoch 130: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2005 - accuracy: 0.9176 - val_loss: 0.3474 - val_accuracy: 0.8623\n",
      "Epoch 131/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1520 - accuracy: 0.9194\n",
      "Epoch 131: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9203 - val_loss: 0.3426 - val_accuracy: 0.8600\n",
      "Epoch 132/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1430 - accuracy: 0.9597\n",
      "Epoch 132: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1981 - accuracy: 0.9180 - val_loss: 0.3365 - val_accuracy: 0.8662\n",
      "Epoch 133/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2317 - accuracy: 0.9113\n",
      "Epoch 133: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1928 - accuracy: 0.9225 - val_loss: 0.3424 - val_accuracy: 0.8708\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1957 - accuracy: 0.9186\n",
      "Epoch 134: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1957 - accuracy: 0.9186 - val_loss: 0.3334 - val_accuracy: 0.8669\n",
      "Epoch 135/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1759 - accuracy: 0.9274\n",
      "Epoch 135: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9176 - val_loss: 0.3346 - val_accuracy: 0.8700\n",
      "Epoch 136/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1789 - accuracy: 0.9355\n",
      "Epoch 136: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1954 - accuracy: 0.9215 - val_loss: 0.3586 - val_accuracy: 0.8723\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1932 - accuracy: 0.9032\n",
      "Epoch 137: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1888 - accuracy: 0.9221 - val_loss: 0.3442 - val_accuracy: 0.8685\n",
      "Epoch 138/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1676 - accuracy: 0.9194\n",
      "Epoch 138: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1891 - accuracy: 0.9240 - val_loss: 0.3569 - val_accuracy: 0.8600\n",
      "Epoch 139/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2523 - accuracy: 0.8952\n",
      "Epoch 139: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2048 - accuracy: 0.9159 - val_loss: 0.3610 - val_accuracy: 0.8685\n",
      "Epoch 140/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.0986 - accuracy: 0.9758\n",
      "Epoch 140: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1953 - accuracy: 0.9186 - val_loss: 0.3482 - val_accuracy: 0.8631\n",
      "Epoch 141/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1209 - accuracy: 0.9516\n",
      "Epoch 141: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1936 - accuracy: 0.9236 - val_loss: 0.3693 - val_accuracy: 0.8631\n",
      "Epoch 142/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2962 - accuracy: 0.8710\n",
      "Epoch 142: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1958 - accuracy: 0.9196 - val_loss: 0.3442 - val_accuracy: 0.8685\n",
      "Epoch 143/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2022 - accuracy: 0.9194\n",
      "Epoch 143: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.9273 - val_loss: 0.3581 - val_accuracy: 0.8662\n",
      "Epoch 144/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1513 - accuracy: 0.9274\n",
      "Epoch 144: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1862 - accuracy: 0.9257 - val_loss: 0.3434 - val_accuracy: 0.8631\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1719 - accuracy: 0.9516\n",
      "Epoch 145: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.9288 - val_loss: 0.3610 - val_accuracy: 0.8585\n",
      "Epoch 146/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1857 - accuracy: 0.9032\n",
      "Epoch 146: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9171 - val_loss: 0.3537 - val_accuracy: 0.8700\n",
      "Epoch 147/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1689 - accuracy: 0.9516\n",
      "Epoch 147: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1836 - accuracy: 0.9265 - val_loss: 0.3722 - val_accuracy: 0.8608\n",
      "Epoch 148/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1805 - accuracy: 0.9032\n",
      "Epoch 148: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1907 - accuracy: 0.9209 - val_loss: 0.3459 - val_accuracy: 0.8631\n",
      "Epoch 149/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1174 - accuracy: 0.9597\n",
      "Epoch 149: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9238 - val_loss: 0.3852 - val_accuracy: 0.8623\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1688 - accuracy: 0.9274\n",
      "Epoch 150: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1836 - accuracy: 0.9236 - val_loss: 0.3470 - val_accuracy: 0.8631\n",
      "Epoch 151/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1241 - accuracy: 0.9435\n",
      "Epoch 151: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1843 - accuracy: 0.9278 - val_loss: 0.3508 - val_accuracy: 0.8669\n",
      "Epoch 152/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1600 - accuracy: 0.9355\n",
      "Epoch 152: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1850 - accuracy: 0.9284 - val_loss: 0.3593 - val_accuracy: 0.8677\n",
      "Epoch 153/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2253 - accuracy: 0.9194\n",
      "Epoch 153: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.9290 - val_loss: 0.3868 - val_accuracy: 0.8585\n",
      "Epoch 154/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1603 - accuracy: 0.9194\n",
      "Epoch 154: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2004 - accuracy: 0.9161 - val_loss: 0.3586 - val_accuracy: 0.8600\n",
      "Epoch 155/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1658 - accuracy: 0.9355\n",
      "Epoch 155: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1773 - accuracy: 0.9253 - val_loss: 0.3572 - val_accuracy: 0.8631\n",
      "Epoch 156/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1619 - accuracy: 0.9355\n",
      "Epoch 156: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.9267 - val_loss: 0.3678 - val_accuracy: 0.8638\n",
      "Epoch 157/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1334 - accuracy: 0.9677\n",
      "Epoch 157: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1938 - accuracy: 0.9240 - val_loss: 0.3605 - val_accuracy: 0.8585\n",
      "Epoch 158/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1488 - accuracy: 0.9435\n",
      "Epoch 158: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1762 - accuracy: 0.9275 - val_loss: 0.3715 - val_accuracy: 0.8608\n",
      "Epoch 159/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1358 - accuracy: 0.9516\n",
      "Epoch 159: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1764 - accuracy: 0.9273 - val_loss: 0.3749 - val_accuracy: 0.8554\n",
      "Epoch 160/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2213 - accuracy: 0.9274\n",
      "Epoch 160: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1735 - accuracy: 0.9302 - val_loss: 0.3785 - val_accuracy: 0.8623\n",
      "Epoch 161/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1257 - accuracy: 0.9597\n",
      "Epoch 161: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1833 - accuracy: 0.9240 - val_loss: 0.3647 - val_accuracy: 0.8677\n",
      "Epoch 162/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2622 - accuracy: 0.8790\n",
      "Epoch 162: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1831 - accuracy: 0.9257 - val_loss: 0.3632 - val_accuracy: 0.8685\n",
      "Epoch 163/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1566 - accuracy: 0.9274\n",
      "Epoch 163: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1812 - accuracy: 0.9280 - val_loss: 0.3526 - val_accuracy: 0.8577\n",
      "Epoch 164/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1591 - accuracy: 0.9274\n",
      "Epoch 164: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1708 - accuracy: 0.9323 - val_loss: 0.3797 - val_accuracy: 0.8600\n",
      "Epoch 165/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1462 - accuracy: 0.9435\n",
      "Epoch 165: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1755 - accuracy: 0.9282 - val_loss: 0.3737 - val_accuracy: 0.8631\n",
      "Epoch 166/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1740 - accuracy: 0.9274\n",
      "Epoch 166: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1649 - accuracy: 0.9342 - val_loss: 0.3733 - val_accuracy: 0.8577\n",
      "Epoch 167/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1105 - accuracy: 0.9597\n",
      "Epoch 167: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1674 - accuracy: 0.9303 - val_loss: 0.4085 - val_accuracy: 0.8654\n",
      "Epoch 168/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2851 - accuracy: 0.8548\n",
      "Epoch 168: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9255 - val_loss: 0.3827 - val_accuracy: 0.8669\n",
      "Epoch 169/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2509 - accuracy: 0.8871\n",
      "Epoch 169: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1661 - accuracy: 0.9302 - val_loss: 0.3914 - val_accuracy: 0.8623\n",
      "Epoch 170/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2374 - accuracy: 0.9194\n",
      "Epoch 170: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1620 - accuracy: 0.9361 - val_loss: 0.3902 - val_accuracy: 0.8646\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 23s - loss: 0.7842 - accuracy: 0.6290\n",
      "Epoch 1: val_accuracy improved from -inf to 0.77462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.5929 - accuracy: 0.6852 - val_loss: 0.5008 - val_accuracy: 0.7746\n",
      "Epoch 2/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.5356 - accuracy: 0.7419\n",
      "Epoch 2: val_accuracy improved from 0.77462 to 0.83231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7962 - val_loss: 0.4149 - val_accuracy: 0.8323\n",
      "Epoch 3/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3998 - accuracy: 0.8385\n",
      "Epoch 3: val_accuracy improved from 0.83231 to 0.84615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4023 - accuracy: 0.8363 - val_loss: 0.3781 - val_accuracy: 0.8462\n",
      "Epoch 4/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3500 - accuracy: 0.8871\n",
      "Epoch 4: val_accuracy improved from 0.84615 to 0.85000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8418 - val_loss: 0.3626 - val_accuracy: 0.8500\n",
      "Epoch 5/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.3672 - accuracy: 0.8475\n",
      "Epoch 5: val_accuracy improved from 0.85000 to 0.85615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3622 - accuracy: 0.8491 - val_loss: 0.3476 - val_accuracy: 0.8562\n",
      "Epoch 6/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4108 - accuracy: 0.8145\n",
      "Epoch 6: val_accuracy improved from 0.85615 to 0.85846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3473 - accuracy: 0.8563 - val_loss: 0.3417 - val_accuracy: 0.8585\n",
      "Epoch 7/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.3376 - accuracy: 0.8646\n",
      "Epoch 7: val_accuracy did not improve from 0.85846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3412 - accuracy: 0.8584 - val_loss: 0.3397 - val_accuracy: 0.8531\n",
      "Epoch 8/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3729 - accuracy: 0.8790\n",
      "Epoch 8: val_accuracy did not improve from 0.85846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8640 - val_loss: 0.3335 - val_accuracy: 0.8585\n",
      "Epoch 9/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3249 - accuracy: 0.8790\n",
      "Epoch 9: val_accuracy did not improve from 0.85846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8613 - val_loss: 0.3469 - val_accuracy: 0.8562\n",
      "Epoch 10/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3117 - accuracy: 0.8710\n",
      "Epoch 10: val_accuracy did not improve from 0.85846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8611 - val_loss: 0.3739 - val_accuracy: 0.8277\n",
      "Epoch 11/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3777 - accuracy: 0.8065\n",
      "Epoch 11: val_accuracy did not improve from 0.85846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8595 - val_loss: 0.3482 - val_accuracy: 0.8431\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2915 - accuracy: 0.8710\n",
      "Epoch 12: val_accuracy improved from 0.85846 to 0.86154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8647 - val_loss: 0.3277 - val_accuracy: 0.8615\n",
      "Epoch 13/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2760 - accuracy: 0.8629\n",
      "Epoch 13: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8611 - val_loss: 0.3357 - val_accuracy: 0.8515\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3257 - accuracy: 0.8584\n",
      "Epoch 14: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8584 - val_loss: 0.3398 - val_accuracy: 0.8592\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3305 - accuracy: 0.8387\n",
      "Epoch 15: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8692 - val_loss: 0.3271 - val_accuracy: 0.8600\n",
      "Epoch 16/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4063 - accuracy: 0.8548\n",
      "Epoch 16: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8684 - val_loss: 0.3289 - val_accuracy: 0.8585\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2438 - accuracy: 0.9113\n",
      "Epoch 17: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8599 - val_loss: 0.3251 - val_accuracy: 0.8569\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3406 - accuracy: 0.8387\n",
      "Epoch 18: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8680 - val_loss: 0.3303 - val_accuracy: 0.8546\n",
      "Epoch 19/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3085 - accuracy: 0.8629\n",
      "Epoch 19: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8718 - val_loss: 0.3269 - val_accuracy: 0.8615\n",
      "Epoch 20/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2675 - accuracy: 0.8952\n",
      "Epoch 20: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8722 - val_loss: 0.3279 - val_accuracy: 0.8592\n",
      "Epoch 21/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2628 - accuracy: 0.8871\n",
      "Epoch 21: val_accuracy improved from 0.86154 to 0.86462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3086 - accuracy: 0.8649 - val_loss: 0.3336 - val_accuracy: 0.8646\n",
      "Epoch 22/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2979 - accuracy: 0.8728\n",
      "Epoch 22: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3012 - accuracy: 0.8711 - val_loss: 0.3335 - val_accuracy: 0.8477\n",
      "Epoch 23/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1871 - accuracy: 0.9355\n",
      "Epoch 23: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3054 - accuracy: 0.8701 - val_loss: 0.3251 - val_accuracy: 0.8585\n",
      "Epoch 24/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2886 - accuracy: 0.8952\n",
      "Epoch 24: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2959 - accuracy: 0.8755 - val_loss: 0.3303 - val_accuracy: 0.8546\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2491 - accuracy: 0.8952\n",
      "Epoch 25: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2975 - accuracy: 0.8738 - val_loss: 0.3228 - val_accuracy: 0.8623\n",
      "Epoch 26/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2552 - accuracy: 0.8710\n",
      "Epoch 26: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.8728 - val_loss: 0.3339 - val_accuracy: 0.8454\n",
      "Epoch 27/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2957 - accuracy: 0.8871\n",
      "Epoch 27: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2969 - accuracy: 0.8751 - val_loss: 0.3263 - val_accuracy: 0.8577\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3044 - accuracy: 0.8710\n",
      "Epoch 28: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8678 - val_loss: 0.3365 - val_accuracy: 0.8646\n",
      "Epoch 29/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2952 - accuracy: 0.8781\n",
      "Epoch 29: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2973 - accuracy: 0.8757 - val_loss: 0.3288 - val_accuracy: 0.8623\n",
      "Epoch 30/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2911 - accuracy: 0.8710\n",
      "Epoch 30: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2972 - accuracy: 0.8755 - val_loss: 0.3343 - val_accuracy: 0.8500\n",
      "Epoch 31/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3626 - accuracy: 0.8468\n",
      "Epoch 31: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2957 - accuracy: 0.8757 - val_loss: 0.3236 - val_accuracy: 0.8585\n",
      "Epoch 32/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2086 - accuracy: 0.9355\n",
      "Epoch 32: val_accuracy improved from 0.86462 to 0.86846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2935 - accuracy: 0.8763 - val_loss: 0.3241 - val_accuracy: 0.8685\n",
      "Epoch 33/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2857 - accuracy: 0.8548\n",
      "Epoch 33: val_accuracy improved from 0.86846 to 0.87000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2847 - accuracy: 0.8815 - val_loss: 0.3287 - val_accuracy: 0.8700\n",
      "Epoch 34/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2515 - accuracy: 0.8710\n",
      "Epoch 34: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2829 - accuracy: 0.8842 - val_loss: 0.3214 - val_accuracy: 0.8608\n",
      "Epoch 35/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.3027 - accuracy: 0.8722\n",
      "Epoch 35: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2978 - accuracy: 0.8738 - val_loss: 0.3403 - val_accuracy: 0.8638\n",
      "Epoch 36/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1723 - accuracy: 0.9274\n",
      "Epoch 36: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2951 - accuracy: 0.8744 - val_loss: 0.3385 - val_accuracy: 0.8462\n",
      "Epoch 37/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3574 - accuracy: 0.8387\n",
      "Epoch 37: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2831 - accuracy: 0.8815 - val_loss: 0.3212 - val_accuracy: 0.8608\n",
      "Epoch 38/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2981 - accuracy: 0.8871\n",
      "Epoch 38: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2801 - accuracy: 0.8838 - val_loss: 0.3188 - val_accuracy: 0.8700\n",
      "Epoch 39/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2827 - accuracy: 0.8871\n",
      "Epoch 39: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2777 - accuracy: 0.8845 - val_loss: 0.3269 - val_accuracy: 0.8562\n",
      "Epoch 40/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2193 - accuracy: 0.9274\n",
      "Epoch 40: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2765 - accuracy: 0.8849 - val_loss: 0.3227 - val_accuracy: 0.8577\n",
      "Epoch 41/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2552 - accuracy: 0.8952\n",
      "Epoch 41: val_accuracy improved from 0.87000 to 0.87615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2758 - accuracy: 0.8865 - val_loss: 0.3119 - val_accuracy: 0.8762\n",
      "Epoch 42/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2735 - accuracy: 0.8855\n",
      "Epoch 42: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2732 - accuracy: 0.8855 - val_loss: 0.3286 - val_accuracy: 0.8577\n",
      "Epoch 43/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2239 - accuracy: 0.9032\n",
      "Epoch 43: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2710 - accuracy: 0.8876 - val_loss: 0.3409 - val_accuracy: 0.8638\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2889 - accuracy: 0.8629\n",
      "Epoch 44: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2675 - accuracy: 0.8907 - val_loss: 0.3083 - val_accuracy: 0.8692\n",
      "Epoch 45/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2348 - accuracy: 0.8871\n",
      "Epoch 45: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.8917 - val_loss: 0.3553 - val_accuracy: 0.8415\n",
      "Epoch 46/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2945 - accuracy: 0.8548\n",
      "Epoch 46: val_accuracy improved from 0.87615 to 0.87692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2718 - accuracy: 0.8861 - val_loss: 0.3106 - val_accuracy: 0.8769\n",
      "Epoch 47/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2404 - accuracy: 0.8952\n",
      "Epoch 47: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2619 - accuracy: 0.8928 - val_loss: 0.3144 - val_accuracy: 0.8746\n",
      "Epoch 48/1000\n",
      "29/42 [===================>..........] - ETA: 0s - loss: 0.2848 - accuracy: 0.8813\n",
      "Epoch 48: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8709 - val_loss: 0.3385 - val_accuracy: 0.8462\n",
      "Epoch 49/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2651 - accuracy: 0.8871\n",
      "Epoch 49: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2783 - accuracy: 0.8792 - val_loss: 0.3027 - val_accuracy: 0.8738\n",
      "Epoch 50/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2451 - accuracy: 0.8629\n",
      "Epoch 50: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.8934 - val_loss: 0.3091 - val_accuracy: 0.8708\n",
      "Epoch 51/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.2594 - accuracy: 0.8932\n",
      "Epoch 51: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2560 - accuracy: 0.8963 - val_loss: 0.3093 - val_accuracy: 0.8762\n",
      "Epoch 52/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2883 - accuracy: 0.9113\n",
      "Epoch 52: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2695 - accuracy: 0.8845 - val_loss: 0.3183 - val_accuracy: 0.8638\n",
      "Epoch 53/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3180 - accuracy: 0.8871\n",
      "Epoch 53: val_accuracy improved from 0.87692 to 0.87846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2631 - accuracy: 0.8874 - val_loss: 0.3002 - val_accuracy: 0.8785\n",
      "Epoch 54/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2755 - accuracy: 0.8819\n",
      "Epoch 54: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2729 - accuracy: 0.8840 - val_loss: 0.3047 - val_accuracy: 0.8777\n",
      "Epoch 55/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3097 - accuracy: 0.8629\n",
      "Epoch 55: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.8892 - val_loss: 0.3013 - val_accuracy: 0.8700\n",
      "Epoch 56/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2352 - accuracy: 0.8790\n",
      "Epoch 56: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2593 - accuracy: 0.8901 - val_loss: 0.3007 - val_accuracy: 0.8777\n",
      "Epoch 57/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2512 - accuracy: 0.8981\n",
      "Epoch 57: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.8988 - val_loss: 0.3029 - val_accuracy: 0.8777\n",
      "Epoch 58/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3067 - accuracy: 0.8871\n",
      "Epoch 58: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2641 - accuracy: 0.8944 - val_loss: 0.3428 - val_accuracy: 0.8515\n",
      "Epoch 59/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3909 - accuracy: 0.8629\n",
      "Epoch 59: val_accuracy improved from 0.87846 to 0.88154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2545 - accuracy: 0.8955 - val_loss: 0.3011 - val_accuracy: 0.8815\n",
      "Epoch 60/1000\n",
      "27/42 [==================>...........] - ETA: 0s - loss: 0.2488 - accuracy: 0.8981\n",
      "Epoch 60: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2535 - accuracy: 0.8934 - val_loss: 0.3091 - val_accuracy: 0.8731\n",
      "Epoch 61/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2426 - accuracy: 0.8871\n",
      "Epoch 61: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2538 - accuracy: 0.8976 - val_loss: 0.3060 - val_accuracy: 0.8769\n",
      "Epoch 62/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2529 - accuracy: 0.8952\n",
      "Epoch 62: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2521 - accuracy: 0.8965 - val_loss: 0.3031 - val_accuracy: 0.8700\n",
      "Epoch 63/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2512 - accuracy: 0.8938\n",
      "Epoch 63: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.8942 - val_loss: 0.3123 - val_accuracy: 0.8700\n",
      "Epoch 64/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2318 - accuracy: 0.9113\n",
      "Epoch 64: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.8926 - val_loss: 0.3290 - val_accuracy: 0.8585\n",
      "Epoch 65/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2012 - accuracy: 0.9032\n",
      "Epoch 65: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2625 - accuracy: 0.8886 - val_loss: 0.3073 - val_accuracy: 0.8777\n",
      "Epoch 66/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1540 - accuracy: 0.9355\n",
      "Epoch 66: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2614 - accuracy: 0.8880 - val_loss: 0.3406 - val_accuracy: 0.8600\n",
      "Epoch 67/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2556 - accuracy: 0.8946\n",
      "Epoch 67: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2553 - accuracy: 0.8953 - val_loss: 0.3185 - val_accuracy: 0.8708\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2862 - accuracy: 0.8710\n",
      "Epoch 68: val_accuracy improved from 0.88154 to 0.88538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.8999 - val_loss: 0.3033 - val_accuracy: 0.8854\n",
      "Epoch 69/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2472 - accuracy: 0.8967\n",
      "Epoch 69: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.8971 - val_loss: 0.3036 - val_accuracy: 0.8746\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3115 - accuracy: 0.8952\n",
      "Epoch 70: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.8980 - val_loss: 0.3165 - val_accuracy: 0.8685\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2621 - accuracy: 0.8952\n",
      "Epoch 71: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8996 - val_loss: 0.3137 - val_accuracy: 0.8754\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2913 - accuracy: 0.8548\n",
      "Epoch 72: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2542 - accuracy: 0.8938 - val_loss: 0.3116 - val_accuracy: 0.8715\n",
      "Epoch 73/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2276 - accuracy: 0.9032\n",
      "Epoch 73: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2424 - accuracy: 0.9023 - val_loss: 0.2997 - val_accuracy: 0.8785\n",
      "Epoch 74/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1929 - accuracy: 0.9113\n",
      "Epoch 74: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2413 - accuracy: 0.9036 - val_loss: 0.3023 - val_accuracy: 0.8808\n",
      "Epoch 75/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2634 - accuracy: 0.8710\n",
      "Epoch 75: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.8967 - val_loss: 0.3070 - val_accuracy: 0.8723\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2297 - accuracy: 0.9113\n",
      "Epoch 76: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2394 - accuracy: 0.9021 - val_loss: 0.3073 - val_accuracy: 0.8800\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2788 - accuracy: 0.8548\n",
      "Epoch 77: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2521 - accuracy: 0.8942 - val_loss: 0.3062 - val_accuracy: 0.8738\n",
      "Epoch 78/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2538 - accuracy: 0.8950\n",
      "Epoch 78: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2532 - accuracy: 0.8944 - val_loss: 0.3066 - val_accuracy: 0.8685\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2679 - accuracy: 0.9113\n",
      "Epoch 79: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2354 - accuracy: 0.9040 - val_loss: 0.3005 - val_accuracy: 0.8800\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2250 - accuracy: 0.8952\n",
      "Epoch 80: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2378 - accuracy: 0.9044 - val_loss: 0.3223 - val_accuracy: 0.8677\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2173 - accuracy: 0.9113\n",
      "Epoch 81: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2395 - accuracy: 0.9015 - val_loss: 0.3075 - val_accuracy: 0.8746\n",
      "Epoch 82/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2003 - accuracy: 0.9113\n",
      "Epoch 82: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2321 - accuracy: 0.9065 - val_loss: 0.3101 - val_accuracy: 0.8792\n",
      "Epoch 83/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2400 - accuracy: 0.8990\n",
      "Epoch 83: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8990 - val_loss: 0.3141 - val_accuracy: 0.8700\n",
      "Epoch 84/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2383 - accuracy: 0.9028\n",
      "Epoch 84: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2397 - accuracy: 0.9013 - val_loss: 0.3148 - val_accuracy: 0.8654\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3074 - accuracy: 0.8790\n",
      "Epoch 85: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8972 - val_loss: 0.3167 - val_accuracy: 0.8746\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2675 - accuracy: 0.8871\n",
      "Epoch 86: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2319 - accuracy: 0.9057 - val_loss: 0.3049 - val_accuracy: 0.8754\n",
      "Epoch 87/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2247 - accuracy: 0.9274\n",
      "Epoch 87: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2310 - accuracy: 0.9063 - val_loss: 0.3048 - val_accuracy: 0.8754\n",
      "Epoch 88/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1910 - accuracy: 0.9194\n",
      "Epoch 88: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2332 - accuracy: 0.9055 - val_loss: 0.3051 - val_accuracy: 0.8731\n",
      "Epoch 89/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2899 - accuracy: 0.8790\n",
      "Epoch 89: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2320 - accuracy: 0.9038 - val_loss: 0.3097 - val_accuracy: 0.8762\n",
      "Epoch 90/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1378 - accuracy: 0.9597\n",
      "Epoch 90: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2375 - accuracy: 0.9005 - val_loss: 0.3039 - val_accuracy: 0.8762\n",
      "Epoch 91/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2700 - accuracy: 0.8629\n",
      "Epoch 91: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2284 - accuracy: 0.9061 - val_loss: 0.3261 - val_accuracy: 0.8708\n",
      "Epoch 92/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2154 - accuracy: 0.9032\n",
      "Epoch 92: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2272 - accuracy: 0.9098 - val_loss: 0.3050 - val_accuracy: 0.8731\n",
      "Epoch 93/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2086 - accuracy: 0.9194\n",
      "Epoch 93: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2349 - accuracy: 0.9011 - val_loss: 0.3030 - val_accuracy: 0.8769\n",
      "Epoch 94/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2171 - accuracy: 0.9274\n",
      "Epoch 94: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2321 - accuracy: 0.9049 - val_loss: 0.3592 - val_accuracy: 0.8492\n",
      "Epoch 95/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2319 - accuracy: 0.9074\n",
      "Epoch 95: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2319 - accuracy: 0.9074 - val_loss: 0.3045 - val_accuracy: 0.8777\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2593 - accuracy: 0.8871\n",
      "Epoch 96: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2395 - accuracy: 0.9019 - val_loss: 0.3149 - val_accuracy: 0.8662\n",
      "Epoch 97/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3062 - accuracy: 0.8710\n",
      "Epoch 97: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2347 - accuracy: 0.8994 - val_loss: 0.3136 - val_accuracy: 0.8715\n",
      "Epoch 98/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1847 - accuracy: 0.9194\n",
      "Epoch 98: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2323 - accuracy: 0.9011 - val_loss: 0.3122 - val_accuracy: 0.8746\n",
      "Epoch 99/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1602 - accuracy: 0.9274\n",
      "Epoch 99: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2352 - accuracy: 0.9021 - val_loss: 0.3097 - val_accuracy: 0.8777\n",
      "Epoch 100/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1971 - accuracy: 0.9113\n",
      "Epoch 100: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2287 - accuracy: 0.9044 - val_loss: 0.3023 - val_accuracy: 0.8769\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1652 - accuracy: 0.9516\n",
      "Epoch 101: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.9099 - val_loss: 0.3208 - val_accuracy: 0.8731\n",
      "Epoch 102/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2146 - accuracy: 0.8952\n",
      "Epoch 102: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2299 - accuracy: 0.9023 - val_loss: 0.3126 - val_accuracy: 0.8769\n",
      "Epoch 103/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2282 - accuracy: 0.9194\n",
      "Epoch 103: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2227 - accuracy: 0.9105 - val_loss: 0.3113 - val_accuracy: 0.8746\n",
      "Epoch 104/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1781 - accuracy: 0.9516\n",
      "Epoch 104: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2219 - accuracy: 0.9082 - val_loss: 0.3158 - val_accuracy: 0.8715\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1967 - accuracy: 0.9194\n",
      "Epoch 105: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2186 - accuracy: 0.9115 - val_loss: 0.3300 - val_accuracy: 0.8762\n",
      "Epoch 106/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1725 - accuracy: 0.9516\n",
      "Epoch 106: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2339 - accuracy: 0.9036 - val_loss: 0.3136 - val_accuracy: 0.8746\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2759 - accuracy: 0.8710\n",
      "Epoch 107: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2161 - accuracy: 0.9123 - val_loss: 0.3143 - val_accuracy: 0.8754\n",
      "Epoch 108/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2226 - accuracy: 0.9077\n",
      "Epoch 108: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2228 - accuracy: 0.9078 - val_loss: 0.3205 - val_accuracy: 0.8738\n",
      "Epoch 109/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1840 - accuracy: 0.9194\n",
      "Epoch 109: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2195 - accuracy: 0.9055 - val_loss: 0.3229 - val_accuracy: 0.8731\n",
      "Epoch 110/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2725 - accuracy: 0.9032\n",
      "Epoch 110: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2292 - accuracy: 0.9013 - val_loss: 0.3542 - val_accuracy: 0.8562\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3043 - accuracy: 0.8871\n",
      "Epoch 111: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2324 - accuracy: 0.9030 - val_loss: 0.3151 - val_accuracy: 0.8731\n",
      "Epoch 112/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1325 - accuracy: 0.9839\n",
      "Epoch 112: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2186 - accuracy: 0.9082 - val_loss: 0.3325 - val_accuracy: 0.8677\n",
      "Epoch 113/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1875 - accuracy: 0.9435\n",
      "Epoch 113: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2215 - accuracy: 0.9073 - val_loss: 0.3400 - val_accuracy: 0.8662\n",
      "Epoch 114/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2261 - accuracy: 0.8952\n",
      "Epoch 114: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2230 - accuracy: 0.9073 - val_loss: 0.3102 - val_accuracy: 0.8754\n",
      "Epoch 115/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2121 - accuracy: 0.9132\n",
      "Epoch 115: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2121 - accuracy: 0.9132 - val_loss: 0.3121 - val_accuracy: 0.8754\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1695 - accuracy: 0.9274\n",
      "Epoch 116: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2097 - accuracy: 0.9144 - val_loss: 0.3356 - val_accuracy: 0.8615\n",
      "Epoch 117/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1890 - accuracy: 0.9355\n",
      "Epoch 117: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2168 - accuracy: 0.9098 - val_loss: 0.3109 - val_accuracy: 0.8731\n",
      "Epoch 118/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1682 - accuracy: 0.9435\n",
      "Epoch 118: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2126 - accuracy: 0.9099 - val_loss: 0.3193 - val_accuracy: 0.8662\n",
      "Epoch 119/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2255 - accuracy: 0.8710\n",
      "Epoch 119: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.9069 - val_loss: 0.3252 - val_accuracy: 0.8715\n",
      "Epoch 120/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2498 - accuracy: 0.9032\n",
      "Epoch 120: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2161 - accuracy: 0.9111 - val_loss: 0.3317 - val_accuracy: 0.8738\n",
      "Epoch 121/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2227 - accuracy: 0.8952\n",
      "Epoch 121: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2112 - accuracy: 0.9146 - val_loss: 0.3174 - val_accuracy: 0.8754\n",
      "Epoch 122/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1557 - accuracy: 0.9274\n",
      "Epoch 122: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2053 - accuracy: 0.9167 - val_loss: 0.3198 - val_accuracy: 0.8708\n",
      "Epoch 123/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1999 - accuracy: 0.9194\n",
      "Epoch 123: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.9111 - val_loss: 0.3249 - val_accuracy: 0.8738\n",
      "Epoch 124/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2062 - accuracy: 0.9032\n",
      "Epoch 124: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2091 - accuracy: 0.9115 - val_loss: 0.3290 - val_accuracy: 0.8731\n",
      "Epoch 125/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1306 - accuracy: 0.9516\n",
      "Epoch 125: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2085 - accuracy: 0.9113 - val_loss: 0.3163 - val_accuracy: 0.8708\n",
      "Epoch 126/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1919 - accuracy: 0.9032\n",
      "Epoch 126: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2066 - accuracy: 0.9109 - val_loss: 0.3331 - val_accuracy: 0.8746\n",
      "Epoch 127/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1495 - accuracy: 0.9516\n",
      "Epoch 127: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2074 - accuracy: 0.9111 - val_loss: 0.3214 - val_accuracy: 0.8708\n",
      "Epoch 128/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2259 - accuracy: 0.8871\n",
      "Epoch 128: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2059 - accuracy: 0.9153 - val_loss: 0.3292 - val_accuracy: 0.8692\n",
      "Epoch 129/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2097 - accuracy: 0.9355\n",
      "Epoch 129: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2074 - accuracy: 0.9146 - val_loss: 0.3503 - val_accuracy: 0.8662\n",
      "Epoch 130/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2014 - accuracy: 0.9113\n",
      "Epoch 130: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2028 - accuracy: 0.9159 - val_loss: 0.3641 - val_accuracy: 0.8646\n",
      "Epoch 131/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2852 - accuracy: 0.8710\n",
      "Epoch 131: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2133 - accuracy: 0.9084 - val_loss: 0.3475 - val_accuracy: 0.8592\n",
      "Epoch 132/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1642 - accuracy: 0.9274\n",
      "Epoch 132: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2102 - accuracy: 0.9117 - val_loss: 0.3375 - val_accuracy: 0.8723\n",
      "Epoch 133/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1083 - accuracy: 0.9435\n",
      "Epoch 133: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2023 - accuracy: 0.9136 - val_loss: 0.3245 - val_accuracy: 0.8715\n",
      "Epoch 134/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1705 - accuracy: 0.9355\n",
      "Epoch 134: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2102 - accuracy: 0.9101 - val_loss: 0.3316 - val_accuracy: 0.8708\n",
      "Epoch 135/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1652 - accuracy: 0.9435\n",
      "Epoch 135: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2006 - accuracy: 0.9146 - val_loss: 0.3291 - val_accuracy: 0.8708\n",
      "Epoch 136/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1906 - accuracy: 0.9032\n",
      "Epoch 136: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1963 - accuracy: 0.9184 - val_loss: 0.3352 - val_accuracy: 0.8723\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2154 - accuracy: 0.8871\n",
      "Epoch 137: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2035 - accuracy: 0.9109 - val_loss: 0.3371 - val_accuracy: 0.8646\n",
      "Epoch 138/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2645 - accuracy: 0.8629\n",
      "Epoch 138: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.9109 - val_loss: 0.3589 - val_accuracy: 0.8662\n",
      "Epoch 139/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2400 - accuracy: 0.9113\n",
      "Epoch 139: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2019 - accuracy: 0.9153 - val_loss: 0.3524 - val_accuracy: 0.8669\n",
      "Epoch 140/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2273 - accuracy: 0.8871\n",
      "Epoch 140: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.9155 - val_loss: 0.3762 - val_accuracy: 0.8592\n",
      "Epoch 141/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2105 - accuracy: 0.9032\n",
      "Epoch 141: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2042 - accuracy: 0.9159 - val_loss: 0.3230 - val_accuracy: 0.8692\n",
      "Epoch 142/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1819 - accuracy: 0.9113\n",
      "Epoch 142: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2033 - accuracy: 0.9136 - val_loss: 0.3487 - val_accuracy: 0.8638\n",
      "Epoch 143/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1351 - accuracy: 0.9355\n",
      "Epoch 143: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2177 - accuracy: 0.9061 - val_loss: 0.3546 - val_accuracy: 0.8631\n",
      "Epoch 144/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1420 - accuracy: 0.9435\n",
      "Epoch 144: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1928 - accuracy: 0.9194 - val_loss: 0.3477 - val_accuracy: 0.8646\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1458 - accuracy: 0.9435\n",
      "Epoch 145: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1918 - accuracy: 0.9186 - val_loss: 0.3493 - val_accuracy: 0.8669\n",
      "Epoch 146/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1601 - accuracy: 0.9435\n",
      "Epoch 146: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2033 - accuracy: 0.9144 - val_loss: 0.3467 - val_accuracy: 0.8615\n",
      "Epoch 147/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2714 - accuracy: 0.9194\n",
      "Epoch 147: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2029 - accuracy: 0.9148 - val_loss: 0.3507 - val_accuracy: 0.8646\n",
      "Epoch 148/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2081 - accuracy: 0.9113\n",
      "Epoch 148: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1928 - accuracy: 0.9215 - val_loss: 0.3592 - val_accuracy: 0.8731\n",
      "Epoch 149/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1722 - accuracy: 0.9113\n",
      "Epoch 149: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1932 - accuracy: 0.9155 - val_loss: 0.3459 - val_accuracy: 0.8608\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1692 - accuracy: 0.9194\n",
      "Epoch 150: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1878 - accuracy: 0.9226 - val_loss: 0.3410 - val_accuracy: 0.8785\n",
      "Epoch 151/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1893 - accuracy: 0.9274\n",
      "Epoch 151: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.9196 - val_loss: 0.3528 - val_accuracy: 0.8692\n",
      "Epoch 152/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1964 - accuracy: 0.9032\n",
      "Epoch 152: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1907 - accuracy: 0.9200 - val_loss: 0.3393 - val_accuracy: 0.8677\n",
      "Epoch 153/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2153 - accuracy: 0.9032\n",
      "Epoch 153: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2032 - accuracy: 0.9165 - val_loss: 0.3569 - val_accuracy: 0.8623\n",
      "Epoch 154/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1764 - accuracy: 0.9274\n",
      "Epoch 154: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.9117 - val_loss: 0.3575 - val_accuracy: 0.8715\n",
      "Epoch 155/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1561 - accuracy: 0.9355\n",
      "Epoch 155: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.9190 - val_loss: 0.3515 - val_accuracy: 0.8731\n",
      "Epoch 156/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1226 - accuracy: 0.9677\n",
      "Epoch 156: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2024 - accuracy: 0.9121 - val_loss: 0.3893 - val_accuracy: 0.8446\n",
      "Epoch 157/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1867 - accuracy: 0.9243\n",
      "Epoch 157: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1887 - accuracy: 0.9234 - val_loss: 0.3594 - val_accuracy: 0.8715\n",
      "Epoch 158/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1520 - accuracy: 0.9113\n",
      "Epoch 158: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1780 - accuracy: 0.9250 - val_loss: 0.3770 - val_accuracy: 0.8708\n",
      "Epoch 159/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1821 - accuracy: 0.9194\n",
      "Epoch 159: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1804 - accuracy: 0.9232 - val_loss: 0.3687 - val_accuracy: 0.8592\n",
      "Epoch 160/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1977 - accuracy: 0.8952\n",
      "Epoch 160: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.9207 - val_loss: 0.3642 - val_accuracy: 0.8708\n",
      "Epoch 161/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1578 - accuracy: 0.9274\n",
      "Epoch 161: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1865 - accuracy: 0.9221 - val_loss: 0.3614 - val_accuracy: 0.8600\n",
      "Epoch 162/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1916 - accuracy: 0.9274\n",
      "Epoch 162: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.9246 - val_loss: 0.3557 - val_accuracy: 0.8738\n",
      "Epoch 163/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1591 - accuracy: 0.9194\n",
      "Epoch 163: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1867 - accuracy: 0.9182 - val_loss: 0.3723 - val_accuracy: 0.8592\n",
      "Epoch 164/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1727 - accuracy: 0.9355\n",
      "Epoch 164: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.9236 - val_loss: 0.3479 - val_accuracy: 0.8708\n",
      "Epoch 165/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1820 - accuracy: 0.9113\n",
      "Epoch 165: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1752 - accuracy: 0.9248 - val_loss: 0.3645 - val_accuracy: 0.8600\n",
      "Epoch 166/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1679 - accuracy: 0.9274\n",
      "Epoch 166: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.9205 - val_loss: 0.3679 - val_accuracy: 0.8646\n",
      "Epoch 167/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1427 - accuracy: 0.9516\n",
      "Epoch 167: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1826 - accuracy: 0.9251 - val_loss: 0.3679 - val_accuracy: 0.8638\n",
      "Epoch 168/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2258 - accuracy: 0.9274\n",
      "Epoch 168: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1803 - accuracy: 0.9215 - val_loss: 0.3556 - val_accuracy: 0.8638\n",
      "Epoch 169/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1605 - accuracy: 0.9274\n",
      "Epoch 169: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1835 - accuracy: 0.9203 - val_loss: 0.3840 - val_accuracy: 0.8531\n",
      "Epoch 170/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1926 - accuracy: 0.9032\n",
      "Epoch 170: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.9248 - val_loss: 0.3795 - val_accuracy: 0.8685\n",
      "Epoch 171/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1971 - accuracy: 0.9032\n",
      "Epoch 171: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1828 - accuracy: 0.9184 - val_loss: 0.3929 - val_accuracy: 0.8608\n",
      "Epoch 172/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2393 - accuracy: 0.8871\n",
      "Epoch 172: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1785 - accuracy: 0.9232 - val_loss: 0.3588 - val_accuracy: 0.8638\n",
      "Epoch 173/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1704 - accuracy: 0.9435\n",
      "Epoch 173: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1900 - accuracy: 0.9169 - val_loss: 0.3785 - val_accuracy: 0.8531\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 22s - loss: 0.9670 - accuracy: 0.5403\n",
      "Epoch 1: val_accuracy improved from -inf to 0.74154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.6004 - accuracy: 0.7027 - val_loss: 0.5023 - val_accuracy: 0.7415\n",
      "Epoch 2/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.5144 - accuracy: 0.7258\n",
      "Epoch 2: val_accuracy improved from 0.74154 to 0.83846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.8105 - val_loss: 0.3906 - val_accuracy: 0.8385\n",
      "Epoch 3/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4741 - accuracy: 0.7823\n",
      "Epoch 3: val_accuracy improved from 0.83846 to 0.84615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8405 - val_loss: 0.3626 - val_accuracy: 0.8462\n",
      "Epoch 4/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3684 - accuracy: 0.8226\n",
      "Epoch 4: val_accuracy did not improve from 0.84615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8311 - val_loss: 0.3877 - val_accuracy: 0.8277\n",
      "Epoch 5/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3582 - accuracy: 0.8629\n",
      "Epoch 5: val_accuracy improved from 0.84615 to 0.85462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3456 - accuracy: 0.8566 - val_loss: 0.3401 - val_accuracy: 0.8546\n",
      "Epoch 6/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.3377 - accuracy: 0.8572\n",
      "Epoch 6: val_accuracy improved from 0.85462 to 0.85923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3378 - accuracy: 0.8563 - val_loss: 0.3353 - val_accuracy: 0.8592\n",
      "Epoch 7/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2861 - accuracy: 0.8952\n",
      "Epoch 7: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8626 - val_loss: 0.3352 - val_accuracy: 0.8592\n",
      "Epoch 8/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2880 - accuracy: 0.8629\n",
      "Epoch 8: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8617 - val_loss: 0.3428 - val_accuracy: 0.8592\n",
      "Epoch 9/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2404 - accuracy: 0.9113\n",
      "Epoch 9: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.8513 - val_loss: 0.3414 - val_accuracy: 0.8469\n",
      "Epoch 10/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2536 - accuracy: 0.8790\n",
      "Epoch 10: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.8722 - val_loss: 0.3396 - val_accuracy: 0.8485\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3135 - accuracy: 0.8744\n",
      "Epoch 11: val_accuracy improved from 0.85923 to 0.86077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3135 - accuracy: 0.8744 - val_loss: 0.3271 - val_accuracy: 0.8608\n",
      "Epoch 12/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3211 - accuracy: 0.8641\n",
      "Epoch 12: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3227 - accuracy: 0.8632 - val_loss: 0.3322 - val_accuracy: 0.8608\n",
      "Epoch 13/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3312 - accuracy: 0.8468\n",
      "Epoch 13: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8603 - val_loss: 0.3568 - val_accuracy: 0.8392\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3835 - accuracy: 0.8387\n",
      "Epoch 14: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8690 - val_loss: 0.3504 - val_accuracy: 0.8546\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2976 - accuracy: 0.8629\n",
      "Epoch 15: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.8659 - val_loss: 0.3298 - val_accuracy: 0.8592\n",
      "Epoch 16/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4272 - accuracy: 0.8468\n",
      "Epoch 16: val_accuracy improved from 0.86077 to 0.86231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.8755 - val_loss: 0.3262 - val_accuracy: 0.8623\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3645 - accuracy: 0.8548\n",
      "Epoch 17: val_accuracy did not improve from 0.86231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8703 - val_loss: 0.3436 - val_accuracy: 0.8623\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3132 - accuracy: 0.8548\n",
      "Epoch 18: val_accuracy did not improve from 0.86231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3026 - accuracy: 0.8770 - val_loss: 0.3243 - val_accuracy: 0.8623\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2978 - accuracy: 0.8772\n",
      "Epoch 19: val_accuracy did not improve from 0.86231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2978 - accuracy: 0.8772 - val_loss: 0.3235 - val_accuracy: 0.8600\n",
      "Epoch 20/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3063 - accuracy: 0.8871\n",
      "Epoch 20: val_accuracy did not improve from 0.86231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2936 - accuracy: 0.8797 - val_loss: 0.3307 - val_accuracy: 0.8492\n",
      "Epoch 21/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2411 - accuracy: 0.8871\n",
      "Epoch 21: val_accuracy did not improve from 0.86231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2926 - accuracy: 0.8801 - val_loss: 0.3224 - val_accuracy: 0.8592\n",
      "Epoch 22/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2465 - accuracy: 0.9032\n",
      "Epoch 22: val_accuracy improved from 0.86231 to 0.87000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8705 - val_loss: 0.3205 - val_accuracy: 0.8700\n",
      "Epoch 23/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3688 - accuracy: 0.8629\n",
      "Epoch 23: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2933 - accuracy: 0.8797 - val_loss: 0.3207 - val_accuracy: 0.8577\n",
      "Epoch 24/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3309 - accuracy: 0.8790\n",
      "Epoch 24: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8722 - val_loss: 0.3189 - val_accuracy: 0.8646\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2460 - accuracy: 0.8952\n",
      "Epoch 25: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2892 - accuracy: 0.8824 - val_loss: 0.3197 - val_accuracy: 0.8638\n",
      "Epoch 26/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2640 - accuracy: 0.9032\n",
      "Epoch 26: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2824 - accuracy: 0.8863 - val_loss: 0.3233 - val_accuracy: 0.8646\n",
      "Epoch 27/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1899 - accuracy: 0.9113\n",
      "Epoch 27: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.8734 - val_loss: 0.3400 - val_accuracy: 0.8485\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3380 - accuracy: 0.8468\n",
      "Epoch 28: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2845 - accuracy: 0.8838 - val_loss: 0.3114 - val_accuracy: 0.8638\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2411 - accuracy: 0.9194\n",
      "Epoch 29: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2803 - accuracy: 0.8805 - val_loss: 0.3140 - val_accuracy: 0.8685\n",
      "Epoch 30/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2907 - accuracy: 0.8548\n",
      "Epoch 30: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2862 - accuracy: 0.8813 - val_loss: 0.3173 - val_accuracy: 0.8615\n",
      "Epoch 31/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2518 - accuracy: 0.8871\n",
      "Epoch 31: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2769 - accuracy: 0.8888 - val_loss: 0.3139 - val_accuracy: 0.8646\n",
      "Epoch 32/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3611 - accuracy: 0.8145\n",
      "Epoch 32: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2721 - accuracy: 0.8855 - val_loss: 0.3067 - val_accuracy: 0.8677\n",
      "Epoch 33/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2820 - accuracy: 0.8871\n",
      "Epoch 33: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2772 - accuracy: 0.8874 - val_loss: 0.3046 - val_accuracy: 0.8685\n",
      "Epoch 34/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3145 - accuracy: 0.8468\n",
      "Epoch 34: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.8807 - val_loss: 0.3122 - val_accuracy: 0.8677\n",
      "Epoch 35/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2513 - accuracy: 0.9032\n",
      "Epoch 35: val_accuracy improved from 0.87000 to 0.87385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2738 - accuracy: 0.8834 - val_loss: 0.3026 - val_accuracy: 0.8738\n",
      "Epoch 36/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2836 - accuracy: 0.8790\n",
      "Epoch 36: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2744 - accuracy: 0.8886 - val_loss: 0.3036 - val_accuracy: 0.8654\n",
      "Epoch 37/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2365 - accuracy: 0.9113\n",
      "Epoch 37: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2813 - accuracy: 0.8878 - val_loss: 0.3074 - val_accuracy: 0.8600\n",
      "Epoch 38/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2748 - accuracy: 0.9113\n",
      "Epoch 38: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2705 - accuracy: 0.8871 - val_loss: 0.3672 - val_accuracy: 0.8515\n",
      "Epoch 39/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4058 - accuracy: 0.8548\n",
      "Epoch 39: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2818 - accuracy: 0.8788 - val_loss: 0.3810 - val_accuracy: 0.8415\n",
      "Epoch 40/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3044 - accuracy: 0.8548\n",
      "Epoch 40: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2696 - accuracy: 0.8878 - val_loss: 0.3202 - val_accuracy: 0.8715\n",
      "Epoch 41/1000\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.2724 - accuracy: 0.8871\n",
      "Epoch 41: val_accuracy improved from 0.87385 to 0.87615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2687 - accuracy: 0.8890 - val_loss: 0.3154 - val_accuracy: 0.8762\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2574 - accuracy: 0.8710\n",
      "Epoch 42: val_accuracy improved from 0.87615 to 0.87692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2660 - accuracy: 0.8869 - val_loss: 0.3025 - val_accuracy: 0.8769\n",
      "Epoch 43/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2663 - accuracy: 0.8915\n",
      "Epoch 43: val_accuracy improved from 0.87692 to 0.88000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2652 - accuracy: 0.8919 - val_loss: 0.2962 - val_accuracy: 0.8800\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2685 - accuracy: 0.8952\n",
      "Epoch 44: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2547 - accuracy: 0.8982 - val_loss: 0.3285 - val_accuracy: 0.8700\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2598 - accuracy: 0.8953\n",
      "Epoch 45: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2598 - accuracy: 0.8953 - val_loss: 0.3026 - val_accuracy: 0.8800\n",
      "Epoch 46/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1573 - accuracy: 0.9274\n",
      "Epoch 46: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2594 - accuracy: 0.8949 - val_loss: 0.3025 - val_accuracy: 0.8731\n",
      "Epoch 47/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1941 - accuracy: 0.9355\n",
      "Epoch 47: val_accuracy improved from 0.88000 to 0.88077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2555 - accuracy: 0.8976 - val_loss: 0.3000 - val_accuracy: 0.8808\n",
      "Epoch 48/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2103 - accuracy: 0.9435\n",
      "Epoch 48: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.8946 - val_loss: 0.3098 - val_accuracy: 0.8769\n",
      "Epoch 49/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2109 - accuracy: 0.9194\n",
      "Epoch 49: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2545 - accuracy: 0.8953 - val_loss: 0.3250 - val_accuracy: 0.8592\n",
      "Epoch 50/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1408 - accuracy: 0.9516\n",
      "Epoch 50: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2732 - accuracy: 0.8845 - val_loss: 0.2993 - val_accuracy: 0.8769\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2725 - accuracy: 0.9355\n",
      "Epoch 51: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.9013 - val_loss: 0.3010 - val_accuracy: 0.8785\n",
      "Epoch 52/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1804 - accuracy: 0.9274\n",
      "Epoch 52: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2541 - accuracy: 0.8930 - val_loss: 0.2965 - val_accuracy: 0.8754\n",
      "Epoch 53/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2617 - accuracy: 0.9274\n",
      "Epoch 53: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2435 - accuracy: 0.9015 - val_loss: 0.2972 - val_accuracy: 0.8731\n",
      "Epoch 54/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2678 - accuracy: 0.8710\n",
      "Epoch 54: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.9003 - val_loss: 0.3078 - val_accuracy: 0.8731\n",
      "Epoch 55/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2506 - accuracy: 0.9032\n",
      "Epoch 55: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.9017 - val_loss: 0.2981 - val_accuracy: 0.8762\n",
      "Epoch 56/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2767 - accuracy: 0.8548\n",
      "Epoch 56: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.8951 - val_loss: 0.3730 - val_accuracy: 0.8400\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3968 - accuracy: 0.7903\n",
      "Epoch 57: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2594 - accuracy: 0.8944 - val_loss: 0.2986 - val_accuracy: 0.8715\n",
      "Epoch 58/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2974 - accuracy: 0.8790\n",
      "Epoch 58: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2477 - accuracy: 0.8980 - val_loss: 0.3154 - val_accuracy: 0.8669\n",
      "Epoch 59/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1789 - accuracy: 0.9194\n",
      "Epoch 59: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.8936 - val_loss: 0.3116 - val_accuracy: 0.8777\n",
      "Epoch 60/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2661 - accuracy: 0.8952\n",
      "Epoch 60: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2419 - accuracy: 0.8994 - val_loss: 0.3054 - val_accuracy: 0.8769\n",
      "Epoch 61/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2426 - accuracy: 0.9032\n",
      "Epoch 61: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2429 - accuracy: 0.8996 - val_loss: 0.2987 - val_accuracy: 0.8723\n",
      "Epoch 62/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3592 - accuracy: 0.8468\n",
      "Epoch 62: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2432 - accuracy: 0.8986 - val_loss: 0.3246 - val_accuracy: 0.8685\n",
      "Epoch 63/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2456 - accuracy: 0.9022\n",
      "Epoch 63: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.9024 - val_loss: 0.3096 - val_accuracy: 0.8700\n",
      "Epoch 64/1000\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.2566 - accuracy: 0.8964\n",
      "Epoch 64: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.9007 - val_loss: 0.3071 - val_accuracy: 0.8769\n",
      "Epoch 65/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1933 - accuracy: 0.9194\n",
      "Epoch 65: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.8988 - val_loss: 0.3227 - val_accuracy: 0.8685\n",
      "Epoch 66/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2710 - accuracy: 0.8790\n",
      "Epoch 66: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2395 - accuracy: 0.9007 - val_loss: 0.3092 - val_accuracy: 0.8731\n",
      "Epoch 67/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2468 - accuracy: 0.8790\n",
      "Epoch 67: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2340 - accuracy: 0.9032 - val_loss: 0.3078 - val_accuracy: 0.8777\n",
      "Epoch 68/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2300 - accuracy: 0.9074\n",
      "Epoch 68: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2308 - accuracy: 0.9073 - val_loss: 0.3042 - val_accuracy: 0.8715\n",
      "Epoch 69/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2447 - accuracy: 0.8790\n",
      "Epoch 69: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 0.8978 - val_loss: 0.3136 - val_accuracy: 0.8723\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2006 - accuracy: 0.9194\n",
      "Epoch 70: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2308 - accuracy: 0.9067 - val_loss: 0.3186 - val_accuracy: 0.8777\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2207 - accuracy: 0.9194\n",
      "Epoch 71: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2332 - accuracy: 0.9028 - val_loss: 0.3153 - val_accuracy: 0.8700\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2998 - accuracy: 0.8790\n",
      "Epoch 72: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2340 - accuracy: 0.9034 - val_loss: 0.3083 - val_accuracy: 0.8708\n",
      "Epoch 73/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1629 - accuracy: 0.9355\n",
      "Epoch 73: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8971 - val_loss: 0.3217 - val_accuracy: 0.8785\n",
      "Epoch 74/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3349 - accuracy: 0.8629\n",
      "Epoch 74: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2326 - accuracy: 0.9048 - val_loss: 0.3098 - val_accuracy: 0.8754\n",
      "Epoch 75/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2003 - accuracy: 0.9274\n",
      "Epoch 75: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2290 - accuracy: 0.9086 - val_loss: 0.3111 - val_accuracy: 0.8685\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2456 - accuracy: 0.8952\n",
      "Epoch 76: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2361 - accuracy: 0.8996 - val_loss: 0.3080 - val_accuracy: 0.8646\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2360 - accuracy: 0.9194\n",
      "Epoch 77: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2354 - accuracy: 0.9017 - val_loss: 0.3141 - val_accuracy: 0.8708\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2095 - accuracy: 0.9194\n",
      "Epoch 78: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2262 - accuracy: 0.9113 - val_loss: 0.3346 - val_accuracy: 0.8708\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2435 - accuracy: 0.8790\n",
      "Epoch 79: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2298 - accuracy: 0.9084 - val_loss: 0.3238 - val_accuracy: 0.8569\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2352 - accuracy: 0.8871\n",
      "Epoch 80: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2349 - accuracy: 0.9017 - val_loss: 0.3350 - val_accuracy: 0.8615\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2660 - accuracy: 0.8710\n",
      "Epoch 81: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2256 - accuracy: 0.9069 - val_loss: 0.3173 - val_accuracy: 0.8692\n",
      "Epoch 82/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1993 - accuracy: 0.9194\n",
      "Epoch 82: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2340 - accuracy: 0.9053 - val_loss: 0.3451 - val_accuracy: 0.8485\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2694 - accuracy: 0.8629\n",
      "Epoch 83: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2310 - accuracy: 0.9003 - val_loss: 0.3184 - val_accuracy: 0.8754\n",
      "Epoch 84/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2262 - accuracy: 0.9075\n",
      "Epoch 84: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 0.9078 - val_loss: 0.3176 - val_accuracy: 0.8646\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2165 - accuracy: 0.9032\n",
      "Epoch 85: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.9099 - val_loss: 0.3161 - val_accuracy: 0.8692\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2140 - accuracy: 0.9113\n",
      "Epoch 86: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2426 - accuracy: 0.8965 - val_loss: 0.3187 - val_accuracy: 0.8662\n",
      "Epoch 87/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2317 - accuracy: 0.9032\n",
      "Epoch 87: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2220 - accuracy: 0.9084 - val_loss: 0.3314 - val_accuracy: 0.8654\n",
      "Epoch 88/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1869 - accuracy: 0.9516\n",
      "Epoch 88: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2177 - accuracy: 0.9098 - val_loss: 0.3141 - val_accuracy: 0.8669\n",
      "Epoch 89/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1800 - accuracy: 0.9113\n",
      "Epoch 89: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2147 - accuracy: 0.9123 - val_loss: 0.3398 - val_accuracy: 0.8685\n",
      "Epoch 90/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2193 - accuracy: 0.9059\n",
      "Epoch 90: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2193 - accuracy: 0.9059 - val_loss: 0.3224 - val_accuracy: 0.8662\n",
      "Epoch 91/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2132 - accuracy: 0.9103\n",
      "Epoch 91: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2122 - accuracy: 0.9109 - val_loss: 0.3177 - val_accuracy: 0.8692\n",
      "Epoch 92/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1580 - accuracy: 0.9516\n",
      "Epoch 92: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2133 - accuracy: 0.9126 - val_loss: 0.3242 - val_accuracy: 0.8692\n",
      "Epoch 93/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2448 - accuracy: 0.9032\n",
      "Epoch 93: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2325 - accuracy: 0.9028 - val_loss: 0.3230 - val_accuracy: 0.8662\n",
      "Epoch 94/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1488 - accuracy: 0.9435\n",
      "Epoch 94: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2263 - accuracy: 0.9067 - val_loss: 0.3490 - val_accuracy: 0.8685\n",
      "Epoch 95/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2167 - accuracy: 0.9113\n",
      "Epoch 95: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2174 - accuracy: 0.9092 - val_loss: 0.3272 - val_accuracy: 0.8669\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2069 - accuracy: 0.9355\n",
      "Epoch 96: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2095 - accuracy: 0.9138 - val_loss: 0.3459 - val_accuracy: 0.8715\n",
      "Epoch 97/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1552 - accuracy: 0.9435\n",
      "Epoch 97: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2373 - accuracy: 0.8971 - val_loss: 0.3106 - val_accuracy: 0.8731\n",
      "Epoch 98/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2160 - accuracy: 0.9142\n",
      "Epoch 98: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2160 - accuracy: 0.9142 - val_loss: 0.3361 - val_accuracy: 0.8592\n",
      "Epoch 99/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2030 - accuracy: 0.9113\n",
      "Epoch 99: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2172 - accuracy: 0.9101 - val_loss: 0.3165 - val_accuracy: 0.8692\n",
      "Epoch 100/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2225 - accuracy: 0.9113\n",
      "Epoch 100: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2172 - accuracy: 0.9099 - val_loss: 0.3221 - val_accuracy: 0.8708\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2147 - accuracy: 0.9032\n",
      "Epoch 101: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2240 - accuracy: 0.9038 - val_loss: 0.3413 - val_accuracy: 0.8646\n",
      "Epoch 102/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2133 - accuracy: 0.9123\n",
      "Epoch 102: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2133 - accuracy: 0.9123 - val_loss: 0.3204 - val_accuracy: 0.8708\n",
      "Epoch 103/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2939 - accuracy: 0.8790\n",
      "Epoch 103: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2063 - accuracy: 0.9167 - val_loss: 0.3332 - val_accuracy: 0.8708\n",
      "Epoch 104/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2614 - accuracy: 0.8952\n",
      "Epoch 104: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 0.9150 - val_loss: 0.3496 - val_accuracy: 0.8685\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2173 - accuracy: 0.8952\n",
      "Epoch 105: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.9123 - val_loss: 0.3856 - val_accuracy: 0.8246\n",
      "Epoch 106/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3562 - accuracy: 0.8468\n",
      "Epoch 106: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2207 - accuracy: 0.9073 - val_loss: 0.3222 - val_accuracy: 0.8754\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1950 - accuracy: 0.9355\n",
      "Epoch 107: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2083 - accuracy: 0.9134 - val_loss: 0.3435 - val_accuracy: 0.8669\n",
      "Epoch 108/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1773 - accuracy: 0.9113\n",
      "Epoch 108: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2107 - accuracy: 0.9138 - val_loss: 0.3246 - val_accuracy: 0.8715\n",
      "Epoch 109/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2158 - accuracy: 0.9194\n",
      "Epoch 109: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1981 - accuracy: 0.9188 - val_loss: 0.3426 - val_accuracy: 0.8662\n",
      "Epoch 110/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1967 - accuracy: 0.9176\n",
      "Epoch 110: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1977 - accuracy: 0.9190 - val_loss: 0.3377 - val_accuracy: 0.8677\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2208 - accuracy: 0.8952\n",
      "Epoch 111: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2014 - accuracy: 0.9178 - val_loss: 0.3456 - val_accuracy: 0.8669\n",
      "Epoch 112/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2362 - accuracy: 0.9194\n",
      "Epoch 112: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1953 - accuracy: 0.9201 - val_loss: 0.3437 - val_accuracy: 0.8685\n",
      "Epoch 113/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1984 - accuracy: 0.9355\n",
      "Epoch 113: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2096 - accuracy: 0.9148 - val_loss: 0.3287 - val_accuracy: 0.8708\n",
      "Epoch 114/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1739 - accuracy: 0.9435\n",
      "Epoch 114: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2074 - accuracy: 0.9132 - val_loss: 0.3409 - val_accuracy: 0.8600\n",
      "Epoch 115/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1540 - accuracy: 0.9274\n",
      "Epoch 115: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1965 - accuracy: 0.9163 - val_loss: 0.3423 - val_accuracy: 0.8662\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1646 - accuracy: 0.9274\n",
      "Epoch 116: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2142 - accuracy: 0.9107 - val_loss: 0.3897 - val_accuracy: 0.8608\n",
      "Epoch 117/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2361 - accuracy: 0.8790\n",
      "Epoch 117: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2195 - accuracy: 0.9059 - val_loss: 0.3362 - val_accuracy: 0.8638\n",
      "Epoch 118/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1629 - accuracy: 0.9516\n",
      "Epoch 118: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1952 - accuracy: 0.9196 - val_loss: 0.3301 - val_accuracy: 0.8692\n",
      "Epoch 119/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2116 - accuracy: 0.8871\n",
      "Epoch 119: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1903 - accuracy: 0.9194 - val_loss: 0.3336 - val_accuracy: 0.8738\n",
      "Epoch 120/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1763 - accuracy: 0.9274\n",
      "Epoch 120: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.9180 - val_loss: 0.3514 - val_accuracy: 0.8677\n",
      "Epoch 121/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1933 - accuracy: 0.9435\n",
      "Epoch 121: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1892 - accuracy: 0.9242 - val_loss: 0.3522 - val_accuracy: 0.8669\n",
      "Epoch 122/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1915 - accuracy: 0.9215\n",
      "Epoch 122: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1915 - accuracy: 0.9215 - val_loss: 0.3511 - val_accuracy: 0.8662\n",
      "Epoch 123/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1947 - accuracy: 0.9187\n",
      "Epoch 123: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1936 - accuracy: 0.9190 - val_loss: 0.3482 - val_accuracy: 0.8692\n",
      "Epoch 124/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1696 - accuracy: 0.9274\n",
      "Epoch 124: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1922 - accuracy: 0.9217 - val_loss: 0.3590 - val_accuracy: 0.8577\n",
      "Epoch 125/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2088 - accuracy: 0.9274\n",
      "Epoch 125: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2036 - accuracy: 0.9161 - val_loss: 0.3889 - val_accuracy: 0.8631\n",
      "Epoch 126/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2857 - accuracy: 0.9113\n",
      "Epoch 126: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1935 - accuracy: 0.9201 - val_loss: 0.3584 - val_accuracy: 0.8654\n",
      "Epoch 127/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1460 - accuracy: 0.9274\n",
      "Epoch 127: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1998 - accuracy: 0.9146 - val_loss: 0.3531 - val_accuracy: 0.8692\n",
      "Epoch 128/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1938 - accuracy: 0.9274\n",
      "Epoch 128: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2031 - accuracy: 0.9148 - val_loss: 0.3352 - val_accuracy: 0.8654\n",
      "Epoch 129/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1854 - accuracy: 0.9255\n",
      "Epoch 129: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9255 - val_loss: 0.3531 - val_accuracy: 0.8708\n",
      "Epoch 130/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1801 - accuracy: 0.9355\n",
      "Epoch 130: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.9192 - val_loss: 0.3598 - val_accuracy: 0.8685\n",
      "Epoch 131/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2205 - accuracy: 0.9113\n",
      "Epoch 131: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.9178 - val_loss: 0.3499 - val_accuracy: 0.8585\n",
      "Epoch 132/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2097 - accuracy: 0.9194\n",
      "Epoch 132: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1950 - accuracy: 0.9217 - val_loss: 0.3847 - val_accuracy: 0.8669\n",
      "Epoch 133/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1807 - accuracy: 0.9113\n",
      "Epoch 133: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.9248 - val_loss: 0.3632 - val_accuracy: 0.8700\n",
      "Epoch 134/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1871 - accuracy: 0.9435\n",
      "Epoch 134: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1938 - accuracy: 0.9205 - val_loss: 0.3682 - val_accuracy: 0.8662\n",
      "Epoch 135/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2275 - accuracy: 0.9032\n",
      "Epoch 135: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.9225 - val_loss: 0.3625 - val_accuracy: 0.8654\n",
      "Epoch 136/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1781 - accuracy: 0.9275\n",
      "Epoch 136: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.9275 - val_loss: 0.3467 - val_accuracy: 0.8654\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1761 - accuracy: 0.9435\n",
      "Epoch 137: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1935 - accuracy: 0.9192 - val_loss: 0.3602 - val_accuracy: 0.8638\n",
      "Epoch 138/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1639 - accuracy: 0.9435\n",
      "Epoch 138: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9259 - val_loss: 0.3594 - val_accuracy: 0.8677\n",
      "Epoch 139/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1844 - accuracy: 0.9244\n",
      "Epoch 139: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.9225 - val_loss: 0.3992 - val_accuracy: 0.8592\n",
      "Epoch 140/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1575 - accuracy: 0.9274\n",
      "Epoch 140: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1966 - accuracy: 0.9153 - val_loss: 0.4016 - val_accuracy: 0.8554\n",
      "Epoch 141/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2431 - accuracy: 0.9032\n",
      "Epoch 141: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1922 - accuracy: 0.9203 - val_loss: 0.3785 - val_accuracy: 0.8662\n",
      "Epoch 142/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1877 - accuracy: 0.9205\n",
      "Epoch 142: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1884 - accuracy: 0.9209 - val_loss: 0.3726 - val_accuracy: 0.8615\n",
      "Epoch 143/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2125 - accuracy: 0.9274\n",
      "Epoch 143: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1800 - accuracy: 0.9259 - val_loss: 0.3794 - val_accuracy: 0.8692\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 23s - loss: 0.7212 - accuracy: 0.5081\n",
      "Epoch 1: val_accuracy improved from -inf to 0.68692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.5861 - accuracy: 0.6950 - val_loss: 0.5477 - val_accuracy: 0.6869\n",
      "Epoch 2/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.5195 - accuracy: 0.7500\n",
      "Epoch 2: val_accuracy improved from 0.68692 to 0.81385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.8018 - val_loss: 0.4200 - val_accuracy: 0.8138\n",
      "Epoch 3/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3925 - accuracy: 0.8385\n",
      "Epoch 3: val_accuracy improved from 0.81385 to 0.84385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3939 - accuracy: 0.8388 - val_loss: 0.3720 - val_accuracy: 0.8438\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3624 - accuracy: 0.8520\n",
      "Epoch 4: val_accuracy did not improve from 0.84385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8520 - val_loss: 0.3595 - val_accuracy: 0.8415\n",
      "Epoch 5/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3540 - accuracy: 0.8541\n",
      "Epoch 5: val_accuracy did not improve from 0.84385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8557 - val_loss: 0.3572 - val_accuracy: 0.8423\n",
      "Epoch 6/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.3386 - accuracy: 0.8636\n",
      "Epoch 6: val_accuracy did not improve from 0.84385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.8638 - val_loss: 0.3540 - val_accuracy: 0.8431\n",
      "Epoch 7/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2264 - accuracy: 0.9194\n",
      "Epoch 7: val_accuracy did not improve from 0.84385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.8574 - val_loss: 0.3732 - val_accuracy: 0.8423\n",
      "Epoch 8/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3569 - accuracy: 0.8548\n",
      "Epoch 8: val_accuracy improved from 0.84385 to 0.84692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3385 - accuracy: 0.8561 - val_loss: 0.3582 - val_accuracy: 0.8469\n",
      "Epoch 9/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3406 - accuracy: 0.8468\n",
      "Epoch 9: val_accuracy improved from 0.84692 to 0.85308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8638 - val_loss: 0.3361 - val_accuracy: 0.8531\n",
      "Epoch 10/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3727 - accuracy: 0.8629\n",
      "Epoch 10: val_accuracy did not improve from 0.85308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8578 - val_loss: 0.3515 - val_accuracy: 0.8500\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3244 - accuracy: 0.8647\n",
      "Epoch 11: val_accuracy improved from 0.85308 to 0.85692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3244 - accuracy: 0.8647 - val_loss: 0.3300 - val_accuracy: 0.8569\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2631 - accuracy: 0.8952\n",
      "Epoch 12: val_accuracy improved from 0.85692 to 0.86000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.8722 - val_loss: 0.3287 - val_accuracy: 0.8600\n",
      "Epoch 13/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2985 - accuracy: 0.8871\n",
      "Epoch 13: val_accuracy improved from 0.86000 to 0.86154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8770 - val_loss: 0.3269 - val_accuracy: 0.8615\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2791 - accuracy: 0.8871\n",
      "Epoch 14: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.8715 - val_loss: 0.3290 - val_accuracy: 0.8600\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3112 - accuracy: 0.8697\n",
      "Epoch 15: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.8697 - val_loss: 0.3293 - val_accuracy: 0.8554\n",
      "Epoch 16/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3049 - accuracy: 0.8629\n",
      "Epoch 16: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8736 - val_loss: 0.3303 - val_accuracy: 0.8554\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3518 - accuracy: 0.8710\n",
      "Epoch 17: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8742 - val_loss: 0.3351 - val_accuracy: 0.8538\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2945 - accuracy: 0.8548\n",
      "Epoch 18: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8634 - val_loss: 0.3439 - val_accuracy: 0.8462\n",
      "Epoch 19/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2898 - accuracy: 0.8710\n",
      "Epoch 19: val_accuracy improved from 0.86154 to 0.86385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8640 - val_loss: 0.3378 - val_accuracy: 0.8638\n",
      "Epoch 20/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2780 - accuracy: 0.8790\n",
      "Epoch 20: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8730 - val_loss: 0.3375 - val_accuracy: 0.8638\n",
      "Epoch 21/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3274 - accuracy: 0.8790\n",
      "Epoch 21: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8705 - val_loss: 0.3322 - val_accuracy: 0.8623\n",
      "Epoch 22/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3349 - accuracy: 0.8548\n",
      "Epoch 22: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8613 - val_loss: 0.3361 - val_accuracy: 0.8623\n",
      "Epoch 23/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2191 - accuracy: 0.8952\n",
      "Epoch 23: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.8697 - val_loss: 0.3298 - val_accuracy: 0.8615\n",
      "Epoch 24/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2964 - accuracy: 0.8710\n",
      "Epoch 24: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8663 - val_loss: 0.3344 - val_accuracy: 0.8523\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3246 - accuracy: 0.8387\n",
      "Epoch 25: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8695 - val_loss: 0.3765 - val_accuracy: 0.8415\n",
      "Epoch 26/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3008 - accuracy: 0.8751\n",
      "Epoch 26: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3013 - accuracy: 0.8755 - val_loss: 0.3406 - val_accuracy: 0.8492\n",
      "Epoch 27/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2078 - accuracy: 0.8952\n",
      "Epoch 27: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2991 - accuracy: 0.8740 - val_loss: 0.3315 - val_accuracy: 0.8631\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2506 - accuracy: 0.9113\n",
      "Epoch 28: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2967 - accuracy: 0.8761 - val_loss: 0.3270 - val_accuracy: 0.8615\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2957 - accuracy: 0.8794\n",
      "Epoch 29: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2957 - accuracy: 0.8794 - val_loss: 0.3349 - val_accuracy: 0.8631\n",
      "Epoch 30/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2906 - accuracy: 0.8871\n",
      "Epoch 30: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2976 - accuracy: 0.8770 - val_loss: 0.3280 - val_accuracy: 0.8608\n",
      "Epoch 31/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3216 - accuracy: 0.8710\n",
      "Epoch 31: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8699 - val_loss: 0.3307 - val_accuracy: 0.8600\n",
      "Epoch 32/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2508 - accuracy: 0.9032\n",
      "Epoch 32: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2992 - accuracy: 0.8742 - val_loss: 0.3933 - val_accuracy: 0.8185\n",
      "Epoch 33/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4274 - accuracy: 0.7742\n",
      "Epoch 33: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2962 - accuracy: 0.8726 - val_loss: 0.3407 - val_accuracy: 0.8631\n",
      "Epoch 34/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3464 - accuracy: 0.8548\n",
      "Epoch 34: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2960 - accuracy: 0.8734 - val_loss: 0.3276 - val_accuracy: 0.8623\n",
      "Epoch 35/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2948 - accuracy: 0.8782\n",
      "Epoch 35: val_accuracy improved from 0.86385 to 0.86923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2951 - accuracy: 0.8782 - val_loss: 0.3263 - val_accuracy: 0.8692\n",
      "Epoch 36/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2981 - accuracy: 0.8729\n",
      "Epoch 36: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.8749 - val_loss: 0.3305 - val_accuracy: 0.8585\n",
      "Epoch 37/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2870 - accuracy: 0.8790\n",
      "Epoch 37: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2944 - accuracy: 0.8780 - val_loss: 0.3279 - val_accuracy: 0.8623\n",
      "Epoch 38/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2932 - accuracy: 0.8952\n",
      "Epoch 38: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2990 - accuracy: 0.8763 - val_loss: 0.3305 - val_accuracy: 0.8600\n",
      "Epoch 39/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2367 - accuracy: 0.8952\n",
      "Epoch 39: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2863 - accuracy: 0.8828 - val_loss: 0.3268 - val_accuracy: 0.8669\n",
      "Epoch 40/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2191 - accuracy: 0.9274\n",
      "Epoch 40: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2932 - accuracy: 0.8794 - val_loss: 0.3267 - val_accuracy: 0.8654\n",
      "Epoch 41/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3309 - accuracy: 0.8387\n",
      "Epoch 41: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2933 - accuracy: 0.8784 - val_loss: 0.3289 - val_accuracy: 0.8646\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3060 - accuracy: 0.8387\n",
      "Epoch 42: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2876 - accuracy: 0.8805 - val_loss: 0.3294 - val_accuracy: 0.8638\n",
      "Epoch 43/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2817 - accuracy: 0.9113\n",
      "Epoch 43: val_accuracy improved from 0.86923 to 0.87077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2885 - accuracy: 0.8805 - val_loss: 0.3246 - val_accuracy: 0.8708\n",
      "Epoch 44/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2840 - accuracy: 0.8828\n",
      "Epoch 44: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2839 - accuracy: 0.8822 - val_loss: 0.3276 - val_accuracy: 0.8600\n",
      "Epoch 45/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3875 - accuracy: 0.8306\n",
      "Epoch 45: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2818 - accuracy: 0.8822 - val_loss: 0.3254 - val_accuracy: 0.8700\n",
      "Epoch 46/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1990 - accuracy: 0.9032\n",
      "Epoch 46: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2790 - accuracy: 0.8857 - val_loss: 0.3199 - val_accuracy: 0.8700\n",
      "Epoch 47/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2564 - accuracy: 0.9032\n",
      "Epoch 47: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2788 - accuracy: 0.8855 - val_loss: 0.3707 - val_accuracy: 0.8492\n",
      "Epoch 48/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3342 - accuracy: 0.8226\n",
      "Epoch 48: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2859 - accuracy: 0.8799 - val_loss: 0.3327 - val_accuracy: 0.8608\n",
      "Epoch 49/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2713 - accuracy: 0.8871\n",
      "Epoch 49: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2905 - accuracy: 0.8790 - val_loss: 0.3187 - val_accuracy: 0.8692\n",
      "Epoch 50/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2094 - accuracy: 0.9032\n",
      "Epoch 50: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2839 - accuracy: 0.8867 - val_loss: 0.3177 - val_accuracy: 0.8700\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3145 - accuracy: 0.8710\n",
      "Epoch 51: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2869 - accuracy: 0.8807 - val_loss: 0.3235 - val_accuracy: 0.8692\n",
      "Epoch 52/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2394 - accuracy: 0.8871\n",
      "Epoch 52: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2834 - accuracy: 0.8834 - val_loss: 0.3192 - val_accuracy: 0.8669\n",
      "Epoch 53/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2348 - accuracy: 0.9113\n",
      "Epoch 53: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2742 - accuracy: 0.8863 - val_loss: 0.3286 - val_accuracy: 0.8662\n",
      "Epoch 54/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2840 - accuracy: 0.8710\n",
      "Epoch 54: val_accuracy improved from 0.87077 to 0.87231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2712 - accuracy: 0.8882 - val_loss: 0.3157 - val_accuracy: 0.8723\n",
      "Epoch 55/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2705 - accuracy: 0.8818\n",
      "Epoch 55: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.8813 - val_loss: 0.3244 - val_accuracy: 0.8669\n",
      "Epoch 56/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2069 - accuracy: 0.9274\n",
      "Epoch 56: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2741 - accuracy: 0.8857 - val_loss: 0.3302 - val_accuracy: 0.8662\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2384 - accuracy: 0.9194\n",
      "Epoch 57: val_accuracy improved from 0.87231 to 0.87769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2905 - accuracy: 0.8778 - val_loss: 0.3173 - val_accuracy: 0.8777\n",
      "Epoch 58/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2154 - accuracy: 0.8952\n",
      "Epoch 58: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2739 - accuracy: 0.8853 - val_loss: 0.3151 - val_accuracy: 0.8723\n",
      "Epoch 59/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3210 - accuracy: 0.8629\n",
      "Epoch 59: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2707 - accuracy: 0.8869 - val_loss: 0.3284 - val_accuracy: 0.8623\n",
      "Epoch 60/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2673 - accuracy: 0.8952\n",
      "Epoch 60: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2688 - accuracy: 0.8899 - val_loss: 0.3175 - val_accuracy: 0.8715\n",
      "Epoch 61/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2088 - accuracy: 0.9194\n",
      "Epoch 61: val_accuracy improved from 0.87769 to 0.88000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2584 - accuracy: 0.8972 - val_loss: 0.3101 - val_accuracy: 0.8800\n",
      "Epoch 62/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2603 - accuracy: 0.9032\n",
      "Epoch 62: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2596 - accuracy: 0.8969 - val_loss: 0.3076 - val_accuracy: 0.8777\n",
      "Epoch 63/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2678 - accuracy: 0.8952\n",
      "Epoch 63: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2569 - accuracy: 0.8965 - val_loss: 0.3131 - val_accuracy: 0.8731\n",
      "Epoch 64/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2439 - accuracy: 0.9113\n",
      "Epoch 64: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2671 - accuracy: 0.8886 - val_loss: 0.3309 - val_accuracy: 0.8646\n",
      "Epoch 65/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2626 - accuracy: 0.8468\n",
      "Epoch 65: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2558 - accuracy: 0.8944 - val_loss: 0.3129 - val_accuracy: 0.8738\n",
      "Epoch 66/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2708 - accuracy: 0.8790\n",
      "Epoch 66: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2572 - accuracy: 0.8967 - val_loss: 0.3938 - val_accuracy: 0.8477\n",
      "Epoch 67/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4276 - accuracy: 0.8065\n",
      "Epoch 67: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2688 - accuracy: 0.8849 - val_loss: 0.3146 - val_accuracy: 0.8738\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2922 - accuracy: 0.8790\n",
      "Epoch 68: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.8976 - val_loss: 0.3080 - val_accuracy: 0.8792\n",
      "Epoch 69/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2422 - accuracy: 0.9032\n",
      "Epoch 69: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.8930 - val_loss: 0.3149 - val_accuracy: 0.8738\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3023 - accuracy: 0.8468\n",
      "Epoch 70: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2528 - accuracy: 0.8928 - val_loss: 0.3028 - val_accuracy: 0.8792\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3008 - accuracy: 0.8790\n",
      "Epoch 71: val_accuracy improved from 0.88000 to 0.88385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.8872 - val_loss: 0.3119 - val_accuracy: 0.8838\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2055 - accuracy: 0.9032\n",
      "Epoch 72: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2559 - accuracy: 0.8949 - val_loss: 0.3156 - val_accuracy: 0.8746\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2474 - accuracy: 0.8967\n",
      "Epoch 73: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2474 - accuracy: 0.8967 - val_loss: 0.3106 - val_accuracy: 0.8723\n",
      "Epoch 74/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2639 - accuracy: 0.8952\n",
      "Epoch 74: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.9013 - val_loss: 0.3021 - val_accuracy: 0.8800\n",
      "Epoch 75/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2029 - accuracy: 0.9274\n",
      "Epoch 75: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.8971 - val_loss: 0.3100 - val_accuracy: 0.8738\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2116 - accuracy: 0.9032\n",
      "Epoch 76: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.8982 - val_loss: 0.3132 - val_accuracy: 0.8785\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2212 - accuracy: 0.9113\n",
      "Epoch 77: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2474 - accuracy: 0.8990 - val_loss: 0.3391 - val_accuracy: 0.8677\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3558 - accuracy: 0.8387\n",
      "Epoch 78: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8978 - val_loss: 0.3097 - val_accuracy: 0.8823\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1750 - accuracy: 0.9435\n",
      "Epoch 79: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.9013 - val_loss: 0.3012 - val_accuracy: 0.8746\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2210 - accuracy: 0.9113\n",
      "Epoch 80: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.8965 - val_loss: 0.3187 - val_accuracy: 0.8700\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1943 - accuracy: 0.9274\n",
      "Epoch 81: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2475 - accuracy: 0.8976 - val_loss: 0.3040 - val_accuracy: 0.8762\n",
      "Epoch 82/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3102 - accuracy: 0.8790\n",
      "Epoch 82: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2387 - accuracy: 0.9021 - val_loss: 0.3067 - val_accuracy: 0.8723\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1947 - accuracy: 0.9194\n",
      "Epoch 83: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8990 - val_loss: 0.3083 - val_accuracy: 0.8723\n",
      "Epoch 84/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2096 - accuracy: 0.9355\n",
      "Epoch 84: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2368 - accuracy: 0.9007 - val_loss: 0.3146 - val_accuracy: 0.8777\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3174 - accuracy: 0.8468\n",
      "Epoch 85: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2349 - accuracy: 0.9024 - val_loss: 0.3056 - val_accuracy: 0.8808\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1528 - accuracy: 0.9677\n",
      "Epoch 86: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2360 - accuracy: 0.9053 - val_loss: 0.3134 - val_accuracy: 0.8731\n",
      "Epoch 87/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2688 - accuracy: 0.8710\n",
      "Epoch 87: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2309 - accuracy: 0.9042 - val_loss: 0.3055 - val_accuracy: 0.8800\n",
      "Epoch 88/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2494 - accuracy: 0.8871\n",
      "Epoch 88: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2361 - accuracy: 0.9030 - val_loss: 0.3181 - val_accuracy: 0.8785\n",
      "Epoch 89/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1948 - accuracy: 0.9113\n",
      "Epoch 89: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2351 - accuracy: 0.8982 - val_loss: 0.3175 - val_accuracy: 0.8838\n",
      "Epoch 90/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1750 - accuracy: 0.9435\n",
      "Epoch 90: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2319 - accuracy: 0.9038 - val_loss: 0.3107 - val_accuracy: 0.8662\n",
      "Epoch 91/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1928 - accuracy: 0.9113\n",
      "Epoch 91: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2273 - accuracy: 0.9092 - val_loss: 0.3093 - val_accuracy: 0.8831\n",
      "Epoch 92/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1842 - accuracy: 0.9113\n",
      "Epoch 92: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2335 - accuracy: 0.9032 - val_loss: 0.3350 - val_accuracy: 0.8685\n",
      "Epoch 93/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2150 - accuracy: 0.8952\n",
      "Epoch 93: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2428 - accuracy: 0.8980 - val_loss: 0.3084 - val_accuracy: 0.8731\n",
      "Epoch 94/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2131 - accuracy: 0.9032\n",
      "Epoch 94: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2305 - accuracy: 0.9090 - val_loss: 0.3157 - val_accuracy: 0.8831\n",
      "Epoch 95/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1789 - accuracy: 0.8871\n",
      "Epoch 95: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.9076 - val_loss: 0.3086 - val_accuracy: 0.8785\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1827 - accuracy: 0.9113\n",
      "Epoch 96: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2314 - accuracy: 0.9028 - val_loss: 0.3214 - val_accuracy: 0.8831\n",
      "Epoch 97/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1595 - accuracy: 0.9516\n",
      "Epoch 97: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2248 - accuracy: 0.9067 - val_loss: 0.3061 - val_accuracy: 0.8838\n",
      "Epoch 98/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1701 - accuracy: 0.9516\n",
      "Epoch 98: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.9092 - val_loss: 0.3125 - val_accuracy: 0.8792\n",
      "Epoch 99/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2161 - accuracy: 0.9126\n",
      "Epoch 99: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2211 - accuracy: 0.9090 - val_loss: 0.3260 - val_accuracy: 0.8638\n",
      "Epoch 100/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2309 - accuracy: 0.9044\n",
      "Epoch 100: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2326 - accuracy: 0.9005 - val_loss: 0.3251 - val_accuracy: 0.8677\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2036 - accuracy: 0.9355\n",
      "Epoch 101: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2227 - accuracy: 0.9113 - val_loss: 0.3286 - val_accuracy: 0.8662\n",
      "Epoch 102/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3438 - accuracy: 0.8387\n",
      "Epoch 102: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2258 - accuracy: 0.9071 - val_loss: 0.3223 - val_accuracy: 0.8831\n",
      "Epoch 103/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2133 - accuracy: 0.9435\n",
      "Epoch 103: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.9074 - val_loss: 0.3221 - val_accuracy: 0.8800\n",
      "Epoch 104/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2147 - accuracy: 0.8952\n",
      "Epoch 104: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2163 - accuracy: 0.9099 - val_loss: 0.3242 - val_accuracy: 0.8746\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2629 - accuracy: 0.8790\n",
      "Epoch 105: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2161 - accuracy: 0.9103 - val_loss: 0.3145 - val_accuracy: 0.8738\n",
      "Epoch 106/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3493 - accuracy: 0.8306\n",
      "Epoch 106: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2161 - accuracy: 0.9105 - val_loss: 0.3166 - val_accuracy: 0.8746\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1730 - accuracy: 0.9435\n",
      "Epoch 107: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 0.9117 - val_loss: 0.3332 - val_accuracy: 0.8769\n",
      "Epoch 108/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1620 - accuracy: 0.9274\n",
      "Epoch 108: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.9071 - val_loss: 0.3305 - val_accuracy: 0.8700\n",
      "Epoch 109/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2122 - accuracy: 0.9120\n",
      "Epoch 109: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2145 - accuracy: 0.9128 - val_loss: 0.3183 - val_accuracy: 0.8746\n",
      "Epoch 110/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2695 - accuracy: 0.8710\n",
      "Epoch 110: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.9128 - val_loss: 0.3372 - val_accuracy: 0.8600\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2774 - accuracy: 0.8790\n",
      "Epoch 111: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2230 - accuracy: 0.9076 - val_loss: 0.3485 - val_accuracy: 0.8638\n",
      "Epoch 112/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2339 - accuracy: 0.8790\n",
      "Epoch 112: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2207 - accuracy: 0.9099 - val_loss: 0.3096 - val_accuracy: 0.8754\n",
      "Epoch 113/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2102 - accuracy: 0.9155\n",
      "Epoch 113: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2102 - accuracy: 0.9155 - val_loss: 0.3225 - val_accuracy: 0.8738\n",
      "Epoch 114/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1753 - accuracy: 0.9435\n",
      "Epoch 114: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2192 - accuracy: 0.9090 - val_loss: 0.3450 - val_accuracy: 0.8669\n",
      "Epoch 115/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1584 - accuracy: 0.9435\n",
      "Epoch 115: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2082 - accuracy: 0.9159 - val_loss: 0.3440 - val_accuracy: 0.8685\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2263 - accuracy: 0.9032\n",
      "Epoch 116: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2061 - accuracy: 0.9159 - val_loss: 0.3279 - val_accuracy: 0.8685\n",
      "Epoch 117/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1846 - accuracy: 0.9274\n",
      "Epoch 117: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2062 - accuracy: 0.9184 - val_loss: 0.3525 - val_accuracy: 0.8662\n",
      "Epoch 118/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2256 - accuracy: 0.9032\n",
      "Epoch 118: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2116 - accuracy: 0.9136 - val_loss: 0.3207 - val_accuracy: 0.8746\n",
      "Epoch 119/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1707 - accuracy: 0.9355\n",
      "Epoch 119: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2091 - accuracy: 0.9146 - val_loss: 0.3411 - val_accuracy: 0.8669\n",
      "Epoch 120/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2495 - accuracy: 0.8871\n",
      "Epoch 120: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2068 - accuracy: 0.9161 - val_loss: 0.3437 - val_accuracy: 0.8777\n",
      "Epoch 121/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1279 - accuracy: 0.9516\n",
      "Epoch 121: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2258 - accuracy: 0.9065 - val_loss: 0.3292 - val_accuracy: 0.8738\n",
      "Epoch 122/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2469 - accuracy: 0.8871\n",
      "Epoch 122: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2129 - accuracy: 0.9132 - val_loss: 0.3425 - val_accuracy: 0.8638\n",
      "Epoch 123/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2819 - accuracy: 0.8871\n",
      "Epoch 123: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2188 - accuracy: 0.9092 - val_loss: 0.3333 - val_accuracy: 0.8762\n",
      "Epoch 124/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1865 - accuracy: 0.9194\n",
      "Epoch 124: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2155 - accuracy: 0.9124 - val_loss: 0.3418 - val_accuracy: 0.8754\n",
      "Epoch 125/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1377 - accuracy: 0.9435\n",
      "Epoch 125: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.9184 - val_loss: 0.3413 - val_accuracy: 0.8708\n",
      "Epoch 126/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1979 - accuracy: 0.9159\n",
      "Epoch 126: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1979 - accuracy: 0.9159 - val_loss: 0.3449 - val_accuracy: 0.8715\n",
      "Epoch 127/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1797 - accuracy: 0.9355\n",
      "Epoch 127: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1943 - accuracy: 0.9219 - val_loss: 0.3582 - val_accuracy: 0.8692\n",
      "Epoch 128/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1886 - accuracy: 0.9194\n",
      "Epoch 128: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.9180 - val_loss: 0.3419 - val_accuracy: 0.8677\n",
      "Epoch 129/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1963 - accuracy: 0.9194\n",
      "Epoch 129: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1949 - accuracy: 0.9211 - val_loss: 0.3394 - val_accuracy: 0.8815\n",
      "Epoch 130/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1936 - accuracy: 0.9032\n",
      "Epoch 130: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1917 - accuracy: 0.9223 - val_loss: 0.3464 - val_accuracy: 0.8723\n",
      "Epoch 131/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1670 - accuracy: 0.9435\n",
      "Epoch 131: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2019 - accuracy: 0.9175 - val_loss: 0.3551 - val_accuracy: 0.8762\n",
      "Epoch 132/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1437 - accuracy: 0.9435\n",
      "Epoch 132: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2032 - accuracy: 0.9175 - val_loss: 0.3362 - val_accuracy: 0.8754\n",
      "Epoch 133/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2111 - accuracy: 0.9088\n",
      "Epoch 133: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2122 - accuracy: 0.9084 - val_loss: 0.3359 - val_accuracy: 0.8731\n",
      "Epoch 134/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1632 - accuracy: 0.9274\n",
      "Epoch 134: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.9219 - val_loss: 0.3749 - val_accuracy: 0.8677\n",
      "Epoch 135/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3221 - accuracy: 0.8952\n",
      "Epoch 135: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1942 - accuracy: 0.9188 - val_loss: 0.3332 - val_accuracy: 0.8754\n",
      "Epoch 136/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1811 - accuracy: 0.9435\n",
      "Epoch 136: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.9250 - val_loss: 0.3500 - val_accuracy: 0.8669\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1794 - accuracy: 0.9113\n",
      "Epoch 137: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2126 - accuracy: 0.9123 - val_loss: 0.3473 - val_accuracy: 0.8777\n",
      "Epoch 138/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1227 - accuracy: 0.9597\n",
      "Epoch 138: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2042 - accuracy: 0.9140 - val_loss: 0.3713 - val_accuracy: 0.8692\n",
      "Epoch 139/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1647 - accuracy: 0.9355\n",
      "Epoch 139: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1903 - accuracy: 0.9182 - val_loss: 0.3605 - val_accuracy: 0.8677\n",
      "Epoch 140/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1908 - accuracy: 0.9219\n",
      "Epoch 140: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1900 - accuracy: 0.9219 - val_loss: 0.3597 - val_accuracy: 0.8769\n",
      "Epoch 141/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1608 - accuracy: 0.9274\n",
      "Epoch 141: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1920 - accuracy: 0.9190 - val_loss: 0.3965 - val_accuracy: 0.8669\n",
      "Epoch 142/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1758 - accuracy: 0.9194\n",
      "Epoch 142: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1864 - accuracy: 0.9250 - val_loss: 0.3441 - val_accuracy: 0.8754\n",
      "Epoch 143/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1362 - accuracy: 0.9516\n",
      "Epoch 143: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.9273 - val_loss: 0.3503 - val_accuracy: 0.8700\n",
      "Epoch 144/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1806 - accuracy: 0.9258\n",
      "Epoch 144: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.9259 - val_loss: 0.3552 - val_accuracy: 0.8669\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1172 - accuracy: 0.9516\n",
      "Epoch 145: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1953 - accuracy: 0.9207 - val_loss: 0.3805 - val_accuracy: 0.8638\n",
      "Epoch 146/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1412 - accuracy: 0.9516\n",
      "Epoch 146: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1871 - accuracy: 0.9223 - val_loss: 0.3860 - val_accuracy: 0.8723\n",
      "Epoch 147/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1910 - accuracy: 0.9198\n",
      "Epoch 147: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.9198 - val_loss: 0.3666 - val_accuracy: 0.8685\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1880 - accuracy: 0.9203\n",
      "Epoch 148: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.9203 - val_loss: 0.3676 - val_accuracy: 0.8669\n",
      "Epoch 149/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2675 - accuracy: 0.8790\n",
      "Epoch 149: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.9257 - val_loss: 0.3663 - val_accuracy: 0.8692\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1623 - accuracy: 0.9435\n",
      "Epoch 150: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.9286 - val_loss: 0.3500 - val_accuracy: 0.8715\n",
      "Epoch 151/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1902 - accuracy: 0.9516\n",
      "Epoch 151: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1959 - accuracy: 0.9173 - val_loss: 0.3571 - val_accuracy: 0.8762\n",
      "Epoch 152/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1447 - accuracy: 0.9355\n",
      "Epoch 152: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9244 - val_loss: 0.4165 - val_accuracy: 0.8615\n",
      "Epoch 153/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1914 - accuracy: 0.9194\n",
      "Epoch 153: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.9236 - val_loss: 0.3517 - val_accuracy: 0.8731\n",
      "Epoch 154/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2121 - accuracy: 0.9113\n",
      "Epoch 154: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1739 - accuracy: 0.9284 - val_loss: 0.3712 - val_accuracy: 0.8654\n",
      "Epoch 155/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1045 - accuracy: 0.9597\n",
      "Epoch 155: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1740 - accuracy: 0.9277 - val_loss: 0.3867 - val_accuracy: 0.8662\n",
      "Epoch 156/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2546 - accuracy: 0.8790\n",
      "Epoch 156: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.9290 - val_loss: 0.3592 - val_accuracy: 0.8638\n",
      "Epoch 157/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.0979 - accuracy: 0.9758\n",
      "Epoch 157: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.9219 - val_loss: 0.3487 - val_accuracy: 0.8754\n",
      "Epoch 158/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2500 - accuracy: 0.8710\n",
      "Epoch 158: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1759 - accuracy: 0.9248 - val_loss: 0.3699 - val_accuracy: 0.8731\n",
      "Epoch 159/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1753 - accuracy: 0.9276\n",
      "Epoch 159: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1741 - accuracy: 0.9284 - val_loss: 0.3635 - val_accuracy: 0.8638\n",
      "Epoch 160/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1989 - accuracy: 0.9113\n",
      "Epoch 160: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1808 - accuracy: 0.9232 - val_loss: 0.3779 - val_accuracy: 0.8646\n",
      "Epoch 161/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1828 - accuracy: 0.9274\n",
      "Epoch 161: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1732 - accuracy: 0.9257 - val_loss: 0.4014 - val_accuracy: 0.8592\n",
      "Epoch 162/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1797 - accuracy: 0.9250\n",
      "Epoch 162: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1808 - accuracy: 0.9236 - val_loss: 0.3705 - val_accuracy: 0.8654\n",
      "Epoch 163/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2188 - accuracy: 0.9274\n",
      "Epoch 163: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1692 - accuracy: 0.9296 - val_loss: 0.4050 - val_accuracy: 0.8669\n",
      "Epoch 164/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1419 - accuracy: 0.9435\n",
      "Epoch 164: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1646 - accuracy: 0.9336 - val_loss: 0.3824 - val_accuracy: 0.8700\n",
      "Epoch 165/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1073 - accuracy: 0.9677\n",
      "Epoch 165: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1646 - accuracy: 0.9350 - val_loss: 0.3928 - val_accuracy: 0.8654\n",
      "Epoch 166/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1308 - accuracy: 0.9839\n",
      "Epoch 166: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.9271 - val_loss: 0.3904 - val_accuracy: 0.8654\n",
      "Epoch 167/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1446 - accuracy: 0.9597\n",
      "Epoch 167: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1698 - accuracy: 0.9302 - val_loss: 0.4031 - val_accuracy: 0.8615\n",
      "Epoch 168/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1617 - accuracy: 0.9032\n",
      "Epoch 168: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1729 - accuracy: 0.9296 - val_loss: 0.3920 - val_accuracy: 0.8723\n",
      "Epoch 169/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1804 - accuracy: 0.9194\n",
      "Epoch 169: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.9240 - val_loss: 0.4702 - val_accuracy: 0.8608\n",
      "Epoch 170/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2121 - accuracy: 0.8952\n",
      "Epoch 170: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1692 - accuracy: 0.9286 - val_loss: 0.3988 - val_accuracy: 0.8677\n",
      "Epoch 171/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.0859 - accuracy: 0.9677\n",
      "Epoch 171: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1778 - accuracy: 0.9230 - val_loss: 0.3845 - val_accuracy: 0.8700\n",
      "Epoch 172/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1757 - accuracy: 0.9194\n",
      "Epoch 172: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.9259 - val_loss: 0.3868 - val_accuracy: 0.8731\n",
      "Epoch 173/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1691 - accuracy: 0.9032\n",
      "Epoch 173: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1798 - accuracy: 0.9250 - val_loss: 0.4462 - val_accuracy: 0.8723\n",
      "Epoch 174/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2662 - accuracy: 0.8871\n",
      "Epoch 174: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1747 - accuracy: 0.9302 - val_loss: 0.3937 - val_accuracy: 0.8692\n",
      "Epoch 175/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1492 - accuracy: 0.9355\n",
      "Epoch 175: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1666 - accuracy: 0.9321 - val_loss: 0.3814 - val_accuracy: 0.8677\n",
      "Epoch 176/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1834 - accuracy: 0.9435\n",
      "Epoch 176: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1667 - accuracy: 0.9338 - val_loss: 0.4138 - val_accuracy: 0.8662\n",
      "Epoch 177/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1969 - accuracy: 0.9032\n",
      "Epoch 177: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1667 - accuracy: 0.9303 - val_loss: 0.4148 - val_accuracy: 0.8646\n",
      "Epoch 178/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1914 - accuracy: 0.9032\n",
      "Epoch 178: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1634 - accuracy: 0.9307 - val_loss: 0.4232 - val_accuracy: 0.8638\n",
      "Epoch 179/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1320 - accuracy: 0.9435\n",
      "Epoch 179: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1591 - accuracy: 0.9363 - val_loss: 0.4244 - val_accuracy: 0.8631\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 22s - loss: 4.4933 - accuracy: 0.5887\n",
      "Epoch 1: val_accuracy improved from -inf to 0.59538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.9297 - accuracy: 0.5436 - val_loss: 0.6696 - val_accuracy: 0.5954\n",
      "Epoch 2/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.6717 - accuracy: 0.5161\n",
      "Epoch 2: val_accuracy improved from 0.59538 to 0.64923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6466 - accuracy: 0.6256 - val_loss: 0.6164 - val_accuracy: 0.6492\n",
      "Epoch 3/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.5826 - accuracy: 0.7048\n",
      "Epoch 3: val_accuracy improved from 0.64923 to 0.77000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5804 - accuracy: 0.7069 - val_loss: 0.5186 - val_accuracy: 0.7700\n",
      "Epoch 4/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4863 - accuracy: 0.8468\n",
      "Epoch 4: val_accuracy improved from 0.77000 to 0.83077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.8105 - val_loss: 0.4211 - val_accuracy: 0.8308\n",
      "Epoch 5/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.4045 - accuracy: 0.8365\n",
      "Epoch 5: val_accuracy improved from 0.83077 to 0.83923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4037 - accuracy: 0.8366 - val_loss: 0.3853 - val_accuracy: 0.8392\n",
      "Epoch 6/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3855 - accuracy: 0.8468\n",
      "Epoch 6: val_accuracy did not improve from 0.83923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8401 - val_loss: 0.3797 - val_accuracy: 0.8277\n",
      "Epoch 7/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3612 - accuracy: 0.8472\n",
      "Epoch 7: val_accuracy did not improve from 0.83923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8457 - val_loss: 0.3716 - val_accuracy: 0.8385\n",
      "Epoch 8/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3561 - accuracy: 0.8629\n",
      "Epoch 8: val_accuracy improved from 0.83923 to 0.85462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8622 - val_loss: 0.3431 - val_accuracy: 0.8546\n",
      "Epoch 9/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3215 - accuracy: 0.8790\n",
      "Epoch 9: val_accuracy did not improve from 0.85462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.8618 - val_loss: 0.3477 - val_accuracy: 0.8538\n",
      "Epoch 10/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2785 - accuracy: 0.8629\n",
      "Epoch 10: val_accuracy improved from 0.85462 to 0.86231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3363 - accuracy: 0.8543 - val_loss: 0.3351 - val_accuracy: 0.8623\n",
      "Epoch 11/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2955 - accuracy: 0.8790\n",
      "Epoch 11: val_accuracy did not improve from 0.86231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8668 - val_loss: 0.3320 - val_accuracy: 0.8554\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3185 - accuracy: 0.8732\n",
      "Epoch 12: val_accuracy did not improve from 0.86231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3185 - accuracy: 0.8732 - val_loss: 0.3311 - val_accuracy: 0.8577\n",
      "Epoch 13/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2918 - accuracy: 0.8871\n",
      "Epoch 13: val_accuracy did not improve from 0.86231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.8668 - val_loss: 0.3293 - val_accuracy: 0.8577\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2635 - accuracy: 0.8952\n",
      "Epoch 14: val_accuracy did not improve from 0.86231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8595 - val_loss: 0.3301 - val_accuracy: 0.8592\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3608 - accuracy: 0.8548\n",
      "Epoch 15: val_accuracy did not improve from 0.86231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3166 - accuracy: 0.8668 - val_loss: 0.3249 - val_accuracy: 0.8615\n",
      "Epoch 16/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3141 - accuracy: 0.8716\n",
      "Epoch 16: val_accuracy improved from 0.86231 to 0.86615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3143 - accuracy: 0.8713 - val_loss: 0.3243 - val_accuracy: 0.8662\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4417 - accuracy: 0.8306\n",
      "Epoch 17: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.8720 - val_loss: 0.3284 - val_accuracy: 0.8646\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1845 - accuracy: 0.9274\n",
      "Epoch 18: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3030 - accuracy: 0.8728 - val_loss: 0.3217 - val_accuracy: 0.8608\n",
      "Epoch 19/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2414 - accuracy: 0.8871\n",
      "Epoch 19: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2961 - accuracy: 0.8790 - val_loss: 0.3214 - val_accuracy: 0.8615\n",
      "Epoch 20/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3220 - accuracy: 0.8629\n",
      "Epoch 20: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3021 - accuracy: 0.8715 - val_loss: 0.3679 - val_accuracy: 0.8454\n",
      "Epoch 21/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2980 - accuracy: 0.8790\n",
      "Epoch 21: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3016 - accuracy: 0.8745 - val_loss: 0.3227 - val_accuracy: 0.8654\n",
      "Epoch 22/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2971 - accuracy: 0.8774\n",
      "Epoch 22: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.8776 - val_loss: 0.3178 - val_accuracy: 0.8608\n",
      "Epoch 23/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3130 - accuracy: 0.8387\n",
      "Epoch 23: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2993 - accuracy: 0.8769 - val_loss: 0.3227 - val_accuracy: 0.8631\n",
      "Epoch 24/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2153 - accuracy: 0.9113\n",
      "Epoch 24: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3005 - accuracy: 0.8734 - val_loss: 0.3233 - val_accuracy: 0.8631\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3306 - accuracy: 0.8871\n",
      "Epoch 25: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2904 - accuracy: 0.8786 - val_loss: 0.3161 - val_accuracy: 0.8631\n",
      "Epoch 26/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3154 - accuracy: 0.9032\n",
      "Epoch 26: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2918 - accuracy: 0.8799 - val_loss: 0.3102 - val_accuracy: 0.8638\n",
      "Epoch 27/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2791 - accuracy: 0.9032\n",
      "Epoch 27: val_accuracy improved from 0.86615 to 0.87385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2888 - accuracy: 0.8780 - val_loss: 0.3078 - val_accuracy: 0.8738\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2491 - accuracy: 0.8871\n",
      "Epoch 28: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2795 - accuracy: 0.8817 - val_loss: 0.3080 - val_accuracy: 0.8708\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3285 - accuracy: 0.8790\n",
      "Epoch 29: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2818 - accuracy: 0.8820 - val_loss: 0.3135 - val_accuracy: 0.8715\n",
      "Epoch 30/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1944 - accuracy: 0.9355\n",
      "Epoch 30: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2892 - accuracy: 0.8842 - val_loss: 0.3279 - val_accuracy: 0.8569\n",
      "Epoch 31/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3051 - accuracy: 0.8710\n",
      "Epoch 31: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2779 - accuracy: 0.8849 - val_loss: 0.3149 - val_accuracy: 0.8731\n",
      "Epoch 32/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2873 - accuracy: 0.8710\n",
      "Epoch 32: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2803 - accuracy: 0.8803 - val_loss: 0.3313 - val_accuracy: 0.8577\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2942 - accuracy: 0.8769\n",
      "Epoch 33: val_accuracy improved from 0.87385 to 0.87846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2942 - accuracy: 0.8769 - val_loss: 0.3017 - val_accuracy: 0.8785\n",
      "Epoch 34/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2718 - accuracy: 0.9032\n",
      "Epoch 34: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.8905 - val_loss: 0.3053 - val_accuracy: 0.8715\n",
      "Epoch 35/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3544 - accuracy: 0.8306\n",
      "Epoch 35: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2777 - accuracy: 0.8859 - val_loss: 0.3023 - val_accuracy: 0.8746\n",
      "Epoch 36/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3564 - accuracy: 0.8629\n",
      "Epoch 36: val_accuracy improved from 0.87846 to 0.88385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2800 - accuracy: 0.8834 - val_loss: 0.3008 - val_accuracy: 0.8838\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2972 - accuracy: 0.8751\n",
      "Epoch 37: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2972 - accuracy: 0.8751 - val_loss: 0.2984 - val_accuracy: 0.8723\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2730 - accuracy: 0.8903\n",
      "Epoch 38: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2730 - accuracy: 0.8903 - val_loss: 0.3134 - val_accuracy: 0.8708\n",
      "Epoch 39/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2527 - accuracy: 0.9355\n",
      "Epoch 39: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.8909 - val_loss: 0.3034 - val_accuracy: 0.8708\n",
      "Epoch 40/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2186 - accuracy: 0.9194\n",
      "Epoch 40: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.8911 - val_loss: 0.3007 - val_accuracy: 0.8815\n",
      "Epoch 41/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2140 - accuracy: 0.9113\n",
      "Epoch 41: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2700 - accuracy: 0.8905 - val_loss: 0.2945 - val_accuracy: 0.8808\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1712 - accuracy: 0.9435\n",
      "Epoch 42: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2617 - accuracy: 0.8905 - val_loss: 0.2947 - val_accuracy: 0.8785\n",
      "Epoch 43/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2332 - accuracy: 0.9194\n",
      "Epoch 43: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2675 - accuracy: 0.8901 - val_loss: 0.2947 - val_accuracy: 0.8746\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2208 - accuracy: 0.9355\n",
      "Epoch 44: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2680 - accuracy: 0.8926 - val_loss: 0.2947 - val_accuracy: 0.8762\n",
      "Epoch 45/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1918 - accuracy: 0.9032\n",
      "Epoch 45: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2766 - accuracy: 0.8832 - val_loss: 0.2919 - val_accuracy: 0.8769\n",
      "Epoch 46/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2787 - accuracy: 0.8790\n",
      "Epoch 46: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2611 - accuracy: 0.8936 - val_loss: 0.2961 - val_accuracy: 0.8754\n",
      "Epoch 47/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2354 - accuracy: 0.9113\n",
      "Epoch 47: val_accuracy improved from 0.88385 to 0.88462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.8947 - val_loss: 0.2945 - val_accuracy: 0.8846\n",
      "Epoch 48/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2339 - accuracy: 0.9194\n",
      "Epoch 48: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2643 - accuracy: 0.8928 - val_loss: 0.2935 - val_accuracy: 0.8754\n",
      "Epoch 49/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1775 - accuracy: 0.9355\n",
      "Epoch 49: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.8942 - val_loss: 0.2964 - val_accuracy: 0.8777\n",
      "Epoch 50/1000\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.2704 - accuracy: 0.8838\n",
      "Epoch 50: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2671 - accuracy: 0.8878 - val_loss: 0.2927 - val_accuracy: 0.8785\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2699 - accuracy: 0.8952\n",
      "Epoch 51: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2624 - accuracy: 0.8917 - val_loss: 0.3453 - val_accuracy: 0.8531\n",
      "Epoch 52/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3122 - accuracy: 0.8387\n",
      "Epoch 52: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2613 - accuracy: 0.8926 - val_loss: 0.3065 - val_accuracy: 0.8792\n",
      "Epoch 53/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1639 - accuracy: 0.9274\n",
      "Epoch 53: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.8936 - val_loss: 0.2918 - val_accuracy: 0.8785\n",
      "Epoch 54/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2324 - accuracy: 0.9113\n",
      "Epoch 54: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2653 - accuracy: 0.8896 - val_loss: 0.3570 - val_accuracy: 0.8485\n",
      "Epoch 55/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2243 - accuracy: 0.9113\n",
      "Epoch 55: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2631 - accuracy: 0.8917 - val_loss: 0.2909 - val_accuracy: 0.8800\n",
      "Epoch 56/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1268 - accuracy: 0.9597\n",
      "Epoch 56: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2540 - accuracy: 0.8965 - val_loss: 0.2907 - val_accuracy: 0.8808\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2336 - accuracy: 0.9274\n",
      "Epoch 57: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2556 - accuracy: 0.8947 - val_loss: 0.3023 - val_accuracy: 0.8715\n",
      "Epoch 58/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2802 - accuracy: 0.8952\n",
      "Epoch 58: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2528 - accuracy: 0.8971 - val_loss: 0.2932 - val_accuracy: 0.8777\n",
      "Epoch 59/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2260 - accuracy: 0.9274\n",
      "Epoch 59: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2774 - accuracy: 0.8869 - val_loss: 0.2961 - val_accuracy: 0.8715\n",
      "Epoch 60/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2582 - accuracy: 0.8923\n",
      "Epoch 60: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2582 - accuracy: 0.8917 - val_loss: 0.2999 - val_accuracy: 0.8754\n",
      "Epoch 61/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2534 - accuracy: 0.8871\n",
      "Epoch 61: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.9009 - val_loss: 0.2945 - val_accuracy: 0.8738\n",
      "Epoch 62/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2533 - accuracy: 0.8975\n",
      "Epoch 62: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.8978 - val_loss: 0.2935 - val_accuracy: 0.8769\n",
      "Epoch 63/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2488 - accuracy: 0.9000\n",
      "Epoch 63: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.8994 - val_loss: 0.2946 - val_accuracy: 0.8792\n",
      "Epoch 64/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2286 - accuracy: 0.9274\n",
      "Epoch 64: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.8988 - val_loss: 0.2953 - val_accuracy: 0.8715\n",
      "Epoch 65/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2503 - accuracy: 0.8989\n",
      "Epoch 65: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.8984 - val_loss: 0.3019 - val_accuracy: 0.8685\n",
      "Epoch 66/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2540 - accuracy: 0.8971\n",
      "Epoch 66: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.8982 - val_loss: 0.2972 - val_accuracy: 0.8800\n",
      "Epoch 67/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1959 - accuracy: 0.9113\n",
      "Epoch 67: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.8971 - val_loss: 0.2932 - val_accuracy: 0.8738\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2026 - accuracy: 0.9355\n",
      "Epoch 68: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.9013 - val_loss: 0.2948 - val_accuracy: 0.8762\n",
      "Epoch 69/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2089 - accuracy: 0.9355\n",
      "Epoch 69: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.9030 - val_loss: 0.2984 - val_accuracy: 0.8738\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2429 - accuracy: 0.9113\n",
      "Epoch 70: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2537 - accuracy: 0.8955 - val_loss: 0.2920 - val_accuracy: 0.8792\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2694 - accuracy: 0.8790\n",
      "Epoch 71: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.8986 - val_loss: 0.2925 - val_accuracy: 0.8808\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1439 - accuracy: 0.9435\n",
      "Epoch 72: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.8974 - val_loss: 0.2929 - val_accuracy: 0.8777\n",
      "Epoch 73/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2591 - accuracy: 0.9032\n",
      "Epoch 73: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.9044 - val_loss: 0.2993 - val_accuracy: 0.8746\n",
      "Epoch 74/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1990 - accuracy: 0.9194\n",
      "Epoch 74: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.8996 - val_loss: 0.3064 - val_accuracy: 0.8731\n",
      "Epoch 75/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2712 - accuracy: 0.8871\n",
      "Epoch 75: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.8994 - val_loss: 0.3045 - val_accuracy: 0.8762\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1848 - accuracy: 0.9194\n",
      "Epoch 76: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2437 - accuracy: 0.9013 - val_loss: 0.2988 - val_accuracy: 0.8831\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2969 - accuracy: 0.8629\n",
      "Epoch 77: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.9015 - val_loss: 0.2975 - val_accuracy: 0.8700\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2354 - accuracy: 0.9274\n",
      "Epoch 78: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2433 - accuracy: 0.9015 - val_loss: 0.2992 - val_accuracy: 0.8746\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2986 - accuracy: 0.8629\n",
      "Epoch 79: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.9009 - val_loss: 0.3019 - val_accuracy: 0.8792\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1792 - accuracy: 0.9355\n",
      "Epoch 80: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2400 - accuracy: 0.9026 - val_loss: 0.3156 - val_accuracy: 0.8746\n",
      "Epoch 81/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2497 - accuracy: 0.8978\n",
      "Epoch 81: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.9007 - val_loss: 0.3026 - val_accuracy: 0.8715\n",
      "Epoch 82/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1989 - accuracy: 0.9435\n",
      "Epoch 82: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.8976 - val_loss: 0.3081 - val_accuracy: 0.8746\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1405 - accuracy: 0.9435\n",
      "Epoch 83: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2431 - accuracy: 0.9017 - val_loss: 0.2948 - val_accuracy: 0.8746\n",
      "Epoch 84/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2211 - accuracy: 0.9194\n",
      "Epoch 84: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.9013 - val_loss: 0.3034 - val_accuracy: 0.8723\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2297 - accuracy: 0.8790\n",
      "Epoch 85: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2411 - accuracy: 0.9023 - val_loss: 0.2964 - val_accuracy: 0.8777\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2997 - accuracy: 0.8952\n",
      "Epoch 86: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2406 - accuracy: 0.9023 - val_loss: 0.3376 - val_accuracy: 0.8654\n",
      "Epoch 87/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2814 - accuracy: 0.8710\n",
      "Epoch 87: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.8976 - val_loss: 0.3166 - val_accuracy: 0.8638\n",
      "Epoch 88/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2545 - accuracy: 0.8871\n",
      "Epoch 88: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2417 - accuracy: 0.9019 - val_loss: 0.2990 - val_accuracy: 0.8762\n",
      "Epoch 89/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2136 - accuracy: 0.9194\n",
      "Epoch 89: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2347 - accuracy: 0.9063 - val_loss: 0.3039 - val_accuracy: 0.8762\n",
      "Epoch 90/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2109 - accuracy: 0.9194\n",
      "Epoch 90: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.8963 - val_loss: 0.3124 - val_accuracy: 0.8692\n",
      "Epoch 91/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2625 - accuracy: 0.8925\n",
      "Epoch 91: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2579 - accuracy: 0.8951 - val_loss: 0.3019 - val_accuracy: 0.8746\n",
      "Epoch 92/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2547 - accuracy: 0.8871\n",
      "Epoch 92: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2328 - accuracy: 0.9065 - val_loss: 0.3172 - val_accuracy: 0.8654\n",
      "Epoch 93/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2541 - accuracy: 0.8871\n",
      "Epoch 93: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2351 - accuracy: 0.9051 - val_loss: 0.3228 - val_accuracy: 0.8677\n",
      "Epoch 94/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2351 - accuracy: 0.9073\n",
      "Epoch 94: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2353 - accuracy: 0.9069 - val_loss: 0.3132 - val_accuracy: 0.8715\n",
      "Epoch 95/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2213 - accuracy: 0.9113\n",
      "Epoch 95: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2388 - accuracy: 0.9005 - val_loss: 0.3028 - val_accuracy: 0.8715\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2879 - accuracy: 0.8871\n",
      "Epoch 96: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2385 - accuracy: 0.9024 - val_loss: 0.3134 - val_accuracy: 0.8715\n",
      "Epoch 97/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2060 - accuracy: 0.8952\n",
      "Epoch 97: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2352 - accuracy: 0.9032 - val_loss: 0.3044 - val_accuracy: 0.8708\n",
      "Epoch 98/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2370 - accuracy: 0.8952\n",
      "Epoch 98: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2323 - accuracy: 0.9049 - val_loss: 0.3035 - val_accuracy: 0.8700\n",
      "Epoch 99/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2386 - accuracy: 0.8871\n",
      "Epoch 99: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2300 - accuracy: 0.9101 - val_loss: 0.3089 - val_accuracy: 0.8769\n",
      "Epoch 100/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2184 - accuracy: 0.9435\n",
      "Epoch 100: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2319 - accuracy: 0.9059 - val_loss: 0.3215 - val_accuracy: 0.8731\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2441 - accuracy: 0.8871\n",
      "Epoch 101: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2329 - accuracy: 0.9067 - val_loss: 0.3082 - val_accuracy: 0.8692\n",
      "Epoch 102/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2344 - accuracy: 0.9024\n",
      "Epoch 102: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2326 - accuracy: 0.9036 - val_loss: 0.3097 - val_accuracy: 0.8746\n",
      "Epoch 103/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2346 - accuracy: 0.9032\n",
      "Epoch 103: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2355 - accuracy: 0.9026 - val_loss: 0.3114 - val_accuracy: 0.8700\n",
      "Epoch 104/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1516 - accuracy: 0.9435\n",
      "Epoch 104: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.9021 - val_loss: 0.3261 - val_accuracy: 0.8662\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2627 - accuracy: 0.9194\n",
      "Epoch 105: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2340 - accuracy: 0.9048 - val_loss: 0.3137 - val_accuracy: 0.8715\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2336 - accuracy: 0.9063\n",
      "Epoch 106: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2336 - accuracy: 0.9063 - val_loss: 0.3128 - val_accuracy: 0.8769\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2445 - accuracy: 0.9274\n",
      "Epoch 107: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2320 - accuracy: 0.9032 - val_loss: 0.3237 - val_accuracy: 0.8677\n",
      "Epoch 108/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2505 - accuracy: 0.9032\n",
      "Epoch 108: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2302 - accuracy: 0.9053 - val_loss: 0.3172 - val_accuracy: 0.8685\n",
      "Epoch 109/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2201 - accuracy: 0.9355\n",
      "Epoch 109: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2391 - accuracy: 0.8984 - val_loss: 0.3076 - val_accuracy: 0.8731\n",
      "Epoch 110/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1720 - accuracy: 0.9032\n",
      "Epoch 110: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 0.9026 - val_loss: 0.3107 - val_accuracy: 0.8692\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1922 - accuracy: 0.9194\n",
      "Epoch 111: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2241 - accuracy: 0.9115 - val_loss: 0.3078 - val_accuracy: 0.8769\n",
      "Epoch 112/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2580 - accuracy: 0.9194\n",
      "Epoch 112: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 0.9071 - val_loss: 0.3118 - val_accuracy: 0.8800\n",
      "Epoch 113/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1229 - accuracy: 0.9839\n",
      "Epoch 113: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2205 - accuracy: 0.9121 - val_loss: 0.3127 - val_accuracy: 0.8762\n",
      "Epoch 114/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3034 - accuracy: 0.8871\n",
      "Epoch 114: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2287 - accuracy: 0.9082 - val_loss: 0.3106 - val_accuracy: 0.8723\n",
      "Epoch 115/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2948 - accuracy: 0.8790\n",
      "Epoch 115: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2287 - accuracy: 0.9069 - val_loss: 0.3105 - val_accuracy: 0.8792\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2391 - accuracy: 0.8952\n",
      "Epoch 116: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2207 - accuracy: 0.9092 - val_loss: 0.3239 - val_accuracy: 0.8662\n",
      "Epoch 117/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2203 - accuracy: 0.9274\n",
      "Epoch 117: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2193 - accuracy: 0.9103 - val_loss: 0.3201 - val_accuracy: 0.8646\n",
      "Epoch 118/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2508 - accuracy: 0.9113\n",
      "Epoch 118: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2185 - accuracy: 0.9113 - val_loss: 0.3148 - val_accuracy: 0.8738\n",
      "Epoch 119/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1946 - accuracy: 0.9194\n",
      "Epoch 119: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.9115 - val_loss: 0.3100 - val_accuracy: 0.8669\n",
      "Epoch 120/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1812 - accuracy: 0.9355\n",
      "Epoch 120: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2190 - accuracy: 0.9123 - val_loss: 0.3255 - val_accuracy: 0.8685\n",
      "Epoch 121/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2428 - accuracy: 0.9032\n",
      "Epoch 121: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2249 - accuracy: 0.9080 - val_loss: 0.3233 - val_accuracy: 0.8669\n",
      "Epoch 122/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1557 - accuracy: 0.9516\n",
      "Epoch 122: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.9111 - val_loss: 0.3358 - val_accuracy: 0.8608\n",
      "Epoch 123/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2605 - accuracy: 0.8952\n",
      "Epoch 123: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2272 - accuracy: 0.9038 - val_loss: 0.3502 - val_accuracy: 0.8638\n",
      "Epoch 124/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2191 - accuracy: 0.9105\n",
      "Epoch 124: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2177 - accuracy: 0.9111 - val_loss: 0.3227 - val_accuracy: 0.8715\n",
      "Epoch 125/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1818 - accuracy: 0.9194\n",
      "Epoch 125: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.9186 - val_loss: 0.3198 - val_accuracy: 0.8708\n",
      "Epoch 126/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2169 - accuracy: 0.9113\n",
      "Epoch 126: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2209 - accuracy: 0.9059 - val_loss: 0.3226 - val_accuracy: 0.8638\n",
      "Epoch 127/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2799 - accuracy: 0.8790\n",
      "Epoch 127: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2132 - accuracy: 0.9132 - val_loss: 0.3300 - val_accuracy: 0.8654\n",
      "Epoch 128/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2162 - accuracy: 0.9194\n",
      "Epoch 128: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2093 - accuracy: 0.9163 - val_loss: 0.3247 - val_accuracy: 0.8715\n",
      "Epoch 129/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2010 - accuracy: 0.9355\n",
      "Epoch 129: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2134 - accuracy: 0.9121 - val_loss: 0.3294 - val_accuracy: 0.8723\n",
      "Epoch 130/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2220 - accuracy: 0.9113\n",
      "Epoch 130: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2131 - accuracy: 0.9136 - val_loss: 0.3267 - val_accuracy: 0.8731\n",
      "Epoch 131/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2081 - accuracy: 0.9168\n",
      "Epoch 131: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2098 - accuracy: 0.9155 - val_loss: 0.3299 - val_accuracy: 0.8715\n",
      "Epoch 132/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2875 - accuracy: 0.8952\n",
      "Epoch 132: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2077 - accuracy: 0.9184 - val_loss: 0.3477 - val_accuracy: 0.8685\n",
      "Epoch 133/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2293 - accuracy: 0.9113\n",
      "Epoch 133: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 0.9109 - val_loss: 0.3387 - val_accuracy: 0.8669\n",
      "Epoch 134/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1909 - accuracy: 0.9355\n",
      "Epoch 134: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2175 - accuracy: 0.9107 - val_loss: 0.3383 - val_accuracy: 0.8677\n",
      "Epoch 135/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1490 - accuracy: 0.9274\n",
      "Epoch 135: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2182 - accuracy: 0.9096 - val_loss: 0.3319 - val_accuracy: 0.8592\n",
      "Epoch 136/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1905 - accuracy: 0.9194\n",
      "Epoch 136: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2113 - accuracy: 0.9161 - val_loss: 0.3318 - val_accuracy: 0.8662\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1470 - accuracy: 0.9435\n",
      "Epoch 137: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2036 - accuracy: 0.9173 - val_loss: 0.3288 - val_accuracy: 0.8685\n",
      "Epoch 138/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1942 - accuracy: 0.9355\n",
      "Epoch 138: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2086 - accuracy: 0.9148 - val_loss: 0.3332 - val_accuracy: 0.8738\n",
      "Epoch 139/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1554 - accuracy: 0.9516\n",
      "Epoch 139: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2065 - accuracy: 0.9169 - val_loss: 0.3542 - val_accuracy: 0.8646\n",
      "Epoch 140/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2289 - accuracy: 0.9113\n",
      "Epoch 140: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2097 - accuracy: 0.9134 - val_loss: 0.3328 - val_accuracy: 0.8654\n",
      "Epoch 141/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2248 - accuracy: 0.9113\n",
      "Epoch 141: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2066 - accuracy: 0.9163 - val_loss: 0.3345 - val_accuracy: 0.8715\n",
      "Epoch 142/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3047 - accuracy: 0.8710\n",
      "Epoch 142: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2045 - accuracy: 0.9148 - val_loss: 0.3274 - val_accuracy: 0.8662\n",
      "Epoch 143/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1323 - accuracy: 0.9435\n",
      "Epoch 143: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1983 - accuracy: 0.9188 - val_loss: 0.3383 - val_accuracy: 0.8669\n",
      "Epoch 144/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2181 - accuracy: 0.9076\n",
      "Epoch 144: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.9076 - val_loss: 0.3354 - val_accuracy: 0.8638\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1872 - accuracy: 0.9274\n",
      "Epoch 145: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 0.9167 - val_loss: 0.3272 - val_accuracy: 0.8646\n",
      "Epoch 146/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1978 - accuracy: 0.9184\n",
      "Epoch 146: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.9184 - val_loss: 0.3501 - val_accuracy: 0.8662\n",
      "Epoch 147/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1935 - accuracy: 0.9221\n",
      "Epoch 147: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1953 - accuracy: 0.9205 - val_loss: 0.3457 - val_accuracy: 0.8615\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1981 - accuracy: 0.9211\n",
      "Epoch 148: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1981 - accuracy: 0.9211 - val_loss: 0.3437 - val_accuracy: 0.8615\n",
      "Epoch 149/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1303 - accuracy: 0.9435\n",
      "Epoch 149: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1914 - accuracy: 0.9236 - val_loss: 0.3468 - val_accuracy: 0.8677\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1767 - accuracy: 0.9355\n",
      "Epoch 150: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.9219 - val_loss: 0.3455 - val_accuracy: 0.8623\n",
      "Epoch 151/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1714 - accuracy: 0.9194\n",
      "Epoch 151: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2025 - accuracy: 0.9182 - val_loss: 0.3508 - val_accuracy: 0.8662\n",
      "Epoch 152/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1781 - accuracy: 0.9113\n",
      "Epoch 152: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2008 - accuracy: 0.9190 - val_loss: 0.3569 - val_accuracy: 0.8692\n",
      "Epoch 153/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1265 - accuracy: 0.9516\n",
      "Epoch 153: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1952 - accuracy: 0.9194 - val_loss: 0.3459 - val_accuracy: 0.8654\n",
      "Epoch 154/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1883 - accuracy: 0.9215\n",
      "Epoch 154: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1852 - accuracy: 0.9230 - val_loss: 0.3604 - val_accuracy: 0.8654\n",
      "Epoch 155/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2337 - accuracy: 0.9113\n",
      "Epoch 155: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1899 - accuracy: 0.9244 - val_loss: 0.3619 - val_accuracy: 0.8646\n",
      "Epoch 156/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1703 - accuracy: 0.9355\n",
      "Epoch 156: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1956 - accuracy: 0.9205 - val_loss: 0.3446 - val_accuracy: 0.8677\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 23s - loss: 1.1910 - accuracy: 0.6048\n",
      "Epoch 1: val_accuracy improved from -inf to 0.79231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.6008 - accuracy: 0.6877 - val_loss: 0.4644 - val_accuracy: 0.7923\n",
      "Epoch 2/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.4408 - accuracy: 0.8165\n",
      "Epoch 2: val_accuracy improved from 0.79231 to 0.80615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.8159 - val_loss: 0.4159 - val_accuracy: 0.8062\n",
      "Epoch 3/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3833 - accuracy: 0.8548\n",
      "Epoch 3: val_accuracy improved from 0.80615 to 0.84769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8424 - val_loss: 0.3713 - val_accuracy: 0.8477\n",
      "Epoch 4/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3801 - accuracy: 0.8548\n",
      "Epoch 4: val_accuracy improved from 0.84769 to 0.85308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.8532 - val_loss: 0.3505 - val_accuracy: 0.8531\n",
      "Epoch 5/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2461 - accuracy: 0.9032\n",
      "Epoch 5: val_accuracy improved from 0.85308 to 0.85769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3482 - accuracy: 0.8578 - val_loss: 0.3415 - val_accuracy: 0.8577\n",
      "Epoch 6/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3562 - accuracy: 0.8629\n",
      "Epoch 6: val_accuracy did not improve from 0.85769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3396 - accuracy: 0.8615 - val_loss: 0.3449 - val_accuracy: 0.8485\n",
      "Epoch 7/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2886 - accuracy: 0.8790\n",
      "Epoch 7: val_accuracy did not improve from 0.85769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8499 - val_loss: 0.3411 - val_accuracy: 0.8508\n",
      "Epoch 8/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2991 - accuracy: 0.9274\n",
      "Epoch 8: val_accuracy did not improve from 0.85769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8593 - val_loss: 0.3401 - val_accuracy: 0.8569\n",
      "Epoch 9/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4115 - accuracy: 0.8710\n",
      "Epoch 9: val_accuracy improved from 0.85769 to 0.86154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3213 - accuracy: 0.8657 - val_loss: 0.3366 - val_accuracy: 0.8615\n",
      "Epoch 10/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3314 - accuracy: 0.8468\n",
      "Epoch 10: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8588 - val_loss: 0.3310 - val_accuracy: 0.8546\n",
      "Epoch 11/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3036 - accuracy: 0.8790\n",
      "Epoch 11: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.8695 - val_loss: 0.3259 - val_accuracy: 0.8608\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2395 - accuracy: 0.8952\n",
      "Epoch 12: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8672 - val_loss: 0.3254 - val_accuracy: 0.8608\n",
      "Epoch 13/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.3123 - accuracy: 0.8718\n",
      "Epoch 13: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8730 - val_loss: 0.3681 - val_accuracy: 0.8500\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3582 - accuracy: 0.8548\n",
      "Epoch 14: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3139 - accuracy: 0.8676 - val_loss: 0.3276 - val_accuracy: 0.8600\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3254 - accuracy: 0.8603\n",
      "Epoch 15: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8603 - val_loss: 0.3567 - val_accuracy: 0.8500\n",
      "Epoch 16/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3313 - accuracy: 0.8548\n",
      "Epoch 16: val_accuracy improved from 0.86154 to 0.86385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8647 - val_loss: 0.3220 - val_accuracy: 0.8638\n",
      "Epoch 17/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3080 - accuracy: 0.8733\n",
      "Epoch 17: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8740 - val_loss: 0.3238 - val_accuracy: 0.8623\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3133 - accuracy: 0.8676\n",
      "Epoch 18: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8676 - val_loss: 0.3267 - val_accuracy: 0.8569\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3085 - accuracy: 0.8732\n",
      "Epoch 19: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8732 - val_loss: 0.3353 - val_accuracy: 0.8631\n",
      "Epoch 20/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2593 - accuracy: 0.8952\n",
      "Epoch 20: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8749 - val_loss: 0.3199 - val_accuracy: 0.8600\n",
      "Epoch 21/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2128 - accuracy: 0.9113\n",
      "Epoch 21: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8674 - val_loss: 0.3246 - val_accuracy: 0.8608\n",
      "Epoch 22/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2827 - accuracy: 0.9113\n",
      "Epoch 22: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.8757 - val_loss: 0.3435 - val_accuracy: 0.8623\n",
      "Epoch 23/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3055 - accuracy: 0.8306\n",
      "Epoch 23: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2941 - accuracy: 0.8786 - val_loss: 0.3242 - val_accuracy: 0.8531\n",
      "Epoch 24/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4664 - accuracy: 0.8065\n",
      "Epoch 24: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8705 - val_loss: 0.3182 - val_accuracy: 0.8608\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3099 - accuracy: 0.8871\n",
      "Epoch 25: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.8701 - val_loss: 0.3790 - val_accuracy: 0.8323\n",
      "Epoch 26/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2596 - accuracy: 0.8952\n",
      "Epoch 26: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8593 - val_loss: 0.3276 - val_accuracy: 0.8623\n",
      "Epoch 27/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3569 - accuracy: 0.8548\n",
      "Epoch 27: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2942 - accuracy: 0.8732 - val_loss: 0.3486 - val_accuracy: 0.8592\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3004 - accuracy: 0.8387\n",
      "Epoch 28: val_accuracy improved from 0.86385 to 0.86615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2918 - accuracy: 0.8790 - val_loss: 0.3163 - val_accuracy: 0.8662\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2427 - accuracy: 0.8871\n",
      "Epoch 29: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2851 - accuracy: 0.8817 - val_loss: 0.3266 - val_accuracy: 0.8623\n",
      "Epoch 30/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2367 - accuracy: 0.9113\n",
      "Epoch 30: val_accuracy improved from 0.86615 to 0.86769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2934 - accuracy: 0.8745 - val_loss: 0.3146 - val_accuracy: 0.8677\n",
      "Epoch 31/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3000 - accuracy: 0.8387\n",
      "Epoch 31: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2913 - accuracy: 0.8784 - val_loss: 0.3324 - val_accuracy: 0.8508\n",
      "Epoch 32/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2987 - accuracy: 0.8548\n",
      "Epoch 32: val_accuracy improved from 0.86769 to 0.86923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2920 - accuracy: 0.8786 - val_loss: 0.3175 - val_accuracy: 0.8692\n",
      "Epoch 33/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2798 - accuracy: 0.8849\n",
      "Epoch 33: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2790 - accuracy: 0.8855 - val_loss: 0.3133 - val_accuracy: 0.8654\n",
      "Epoch 34/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2807 - accuracy: 0.8839\n",
      "Epoch 34: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2796 - accuracy: 0.8849 - val_loss: 0.3119 - val_accuracy: 0.8646\n",
      "Epoch 35/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2101 - accuracy: 0.8790\n",
      "Epoch 35: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2878 - accuracy: 0.8763 - val_loss: 0.3106 - val_accuracy: 0.8662\n",
      "Epoch 36/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3175 - accuracy: 0.8790\n",
      "Epoch 36: val_accuracy improved from 0.86923 to 0.87385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2840 - accuracy: 0.8820 - val_loss: 0.3111 - val_accuracy: 0.8738\n",
      "Epoch 37/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2823 - accuracy: 0.8710\n",
      "Epoch 37: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2755 - accuracy: 0.8857 - val_loss: 0.3241 - val_accuracy: 0.8638\n",
      "Epoch 38/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2870 - accuracy: 0.8952\n",
      "Epoch 38: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2876 - accuracy: 0.8759 - val_loss: 0.3060 - val_accuracy: 0.8685\n",
      "Epoch 39/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3148 - accuracy: 0.8710\n",
      "Epoch 39: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2764 - accuracy: 0.8845 - val_loss: 0.3147 - val_accuracy: 0.8646\n",
      "Epoch 40/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2353 - accuracy: 0.8790\n",
      "Epoch 40: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.8863 - val_loss: 0.3055 - val_accuracy: 0.8715\n",
      "Epoch 41/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3189 - accuracy: 0.8629\n",
      "Epoch 41: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.8880 - val_loss: 0.3069 - val_accuracy: 0.8692\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2849 - accuracy: 0.8871\n",
      "Epoch 42: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.8863 - val_loss: 0.3145 - val_accuracy: 0.8723\n",
      "Epoch 43/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3071 - accuracy: 0.8387\n",
      "Epoch 43: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.8884 - val_loss: 0.3060 - val_accuracy: 0.8738\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2449 - accuracy: 0.8952\n",
      "Epoch 44: val_accuracy improved from 0.87385 to 0.87923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2657 - accuracy: 0.8903 - val_loss: 0.3049 - val_accuracy: 0.8792\n",
      "Epoch 45/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1894 - accuracy: 0.9435\n",
      "Epoch 45: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2733 - accuracy: 0.8880 - val_loss: 0.3149 - val_accuracy: 0.8669\n",
      "Epoch 46/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3296 - accuracy: 0.8790\n",
      "Epoch 46: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.8894 - val_loss: 0.3019 - val_accuracy: 0.8708\n",
      "Epoch 47/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2315 - accuracy: 0.9274\n",
      "Epoch 47: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2623 - accuracy: 0.8913 - val_loss: 0.3043 - val_accuracy: 0.8754\n",
      "Epoch 48/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1813 - accuracy: 0.9194\n",
      "Epoch 48: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2689 - accuracy: 0.8844 - val_loss: 0.3051 - val_accuracy: 0.8677\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2721 - accuracy: 0.8845\n",
      "Epoch 49: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2721 - accuracy: 0.8845 - val_loss: 0.3030 - val_accuracy: 0.8738\n",
      "Epoch 50/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2588 - accuracy: 0.8937\n",
      "Epoch 50: val_accuracy improved from 0.87923 to 0.88308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2587 - accuracy: 0.8942 - val_loss: 0.3053 - val_accuracy: 0.8831\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1771 - accuracy: 0.9194\n",
      "Epoch 51: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2632 - accuracy: 0.8907 - val_loss: 0.3069 - val_accuracy: 0.8669\n",
      "Epoch 52/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1809 - accuracy: 0.9194\n",
      "Epoch 52: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2557 - accuracy: 0.8917 - val_loss: 0.2968 - val_accuracy: 0.8731\n",
      "Epoch 53/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2177 - accuracy: 0.9032\n",
      "Epoch 53: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2522 - accuracy: 0.8946 - val_loss: 0.3100 - val_accuracy: 0.8754\n",
      "Epoch 54/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3464 - accuracy: 0.8629\n",
      "Epoch 54: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2738 - accuracy: 0.8845 - val_loss: 0.3554 - val_accuracy: 0.8554\n",
      "Epoch 55/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2974 - accuracy: 0.8629\n",
      "Epoch 55: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.8953 - val_loss: 0.2973 - val_accuracy: 0.8738\n",
      "Epoch 56/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2674 - accuracy: 0.8790\n",
      "Epoch 56: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2579 - accuracy: 0.8913 - val_loss: 0.2959 - val_accuracy: 0.8808\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2530 - accuracy: 0.8953\n",
      "Epoch 57: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2530 - accuracy: 0.8953 - val_loss: 0.3444 - val_accuracy: 0.8654\n",
      "Epoch 58/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2081 - accuracy: 0.9194\n",
      "Epoch 58: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2583 - accuracy: 0.8921 - val_loss: 0.2990 - val_accuracy: 0.8677\n",
      "Epoch 59/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2324 - accuracy: 0.8952\n",
      "Epoch 59: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2485 - accuracy: 0.8999 - val_loss: 0.2981 - val_accuracy: 0.8738\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2602 - accuracy: 0.8896\n",
      "Epoch 60: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2602 - accuracy: 0.8896 - val_loss: 0.2944 - val_accuracy: 0.8715\n",
      "Epoch 61/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2425 - accuracy: 0.9032\n",
      "Epoch 61: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2549 - accuracy: 0.8944 - val_loss: 0.3037 - val_accuracy: 0.8762\n",
      "Epoch 62/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3009 - accuracy: 0.8952\n",
      "Epoch 62: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2488 - accuracy: 0.8978 - val_loss: 0.3062 - val_accuracy: 0.8715\n",
      "Epoch 63/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2082 - accuracy: 0.8871\n",
      "Epoch 63: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2533 - accuracy: 0.8934 - val_loss: 0.3757 - val_accuracy: 0.8362\n",
      "Epoch 64/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2284 - accuracy: 0.9032\n",
      "Epoch 64: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2731 - accuracy: 0.8819 - val_loss: 0.3950 - val_accuracy: 0.8277\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2565 - accuracy: 0.8905\n",
      "Epoch 65: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2565 - accuracy: 0.8905 - val_loss: 0.3159 - val_accuracy: 0.8746\n",
      "Epoch 66/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2432 - accuracy: 0.9009\n",
      "Epoch 66: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.8996 - val_loss: 0.2997 - val_accuracy: 0.8731\n",
      "Epoch 67/1000\n",
      "27/42 [==================>...........] - ETA: 0s - loss: 0.2585 - accuracy: 0.8898\n",
      "Epoch 67: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8984 - val_loss: 0.3159 - val_accuracy: 0.8754\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2701 - accuracy: 0.8790\n",
      "Epoch 68: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2471 - accuracy: 0.8971 - val_loss: 0.2942 - val_accuracy: 0.8746\n",
      "Epoch 69/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2630 - accuracy: 0.8871\n",
      "Epoch 69: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2409 - accuracy: 0.9011 - val_loss: 0.3027 - val_accuracy: 0.8785\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1640 - accuracy: 0.9355\n",
      "Epoch 70: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.9003 - val_loss: 0.3092 - val_accuracy: 0.8731\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1894 - accuracy: 0.9516\n",
      "Epoch 71: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.9038 - val_loss: 0.2994 - val_accuracy: 0.8769\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2521 - accuracy: 0.8790\n",
      "Epoch 72: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2390 - accuracy: 0.9051 - val_loss: 0.3005 - val_accuracy: 0.8754\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2469 - accuracy: 0.8961\n",
      "Epoch 73: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.8961 - val_loss: 0.3043 - val_accuracy: 0.8762\n",
      "Epoch 74/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1811 - accuracy: 0.9516\n",
      "Epoch 74: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2544 - accuracy: 0.8932 - val_loss: 0.3012 - val_accuracy: 0.8792\n",
      "Epoch 75/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1849 - accuracy: 0.9435\n",
      "Epoch 75: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2412 - accuracy: 0.8978 - val_loss: 0.3000 - val_accuracy: 0.8785\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3448 - accuracy: 0.8790\n",
      "Epoch 76: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2563 - accuracy: 0.8940 - val_loss: 0.3197 - val_accuracy: 0.8677\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3718 - accuracy: 0.8226\n",
      "Epoch 77: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2419 - accuracy: 0.9013 - val_loss: 0.3127 - val_accuracy: 0.8731\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2308 - accuracy: 0.9194\n",
      "Epoch 78: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2329 - accuracy: 0.9034 - val_loss: 0.3189 - val_accuracy: 0.8700\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2631 - accuracy: 0.9032\n",
      "Epoch 79: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2385 - accuracy: 0.9028 - val_loss: 0.3332 - val_accuracy: 0.8754\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2520 - accuracy: 0.9113\n",
      "Epoch 80: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2421 - accuracy: 0.8951 - val_loss: 0.3048 - val_accuracy: 0.8754\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2304 - accuracy: 0.9032\n",
      "Epoch 81: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2289 - accuracy: 0.9101 - val_loss: 0.3069 - val_accuracy: 0.8715\n",
      "Epoch 82/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2482 - accuracy: 0.8710\n",
      "Epoch 82: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2375 - accuracy: 0.8992 - val_loss: 0.4042 - val_accuracy: 0.8385\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2684 - accuracy: 0.8952\n",
      "Epoch 83: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8944 - val_loss: 0.3167 - val_accuracy: 0.8631\n",
      "Epoch 84/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3055 - accuracy: 0.8710\n",
      "Epoch 84: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.9030 - val_loss: 0.3015 - val_accuracy: 0.8685\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2299 - accuracy: 0.9194\n",
      "Epoch 85: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8974 - val_loss: 0.3114 - val_accuracy: 0.8692\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2142 - accuracy: 0.9435\n",
      "Epoch 86: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2330 - accuracy: 0.9032 - val_loss: 0.3043 - val_accuracy: 0.8708\n",
      "Epoch 87/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1701 - accuracy: 0.9355\n",
      "Epoch 87: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2354 - accuracy: 0.9011 - val_loss: 0.2994 - val_accuracy: 0.8685\n",
      "Epoch 88/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2089 - accuracy: 0.9032\n",
      "Epoch 88: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2280 - accuracy: 0.9086 - val_loss: 0.3079 - val_accuracy: 0.8723\n",
      "Epoch 89/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2671 - accuracy: 0.8790\n",
      "Epoch 89: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.9061 - val_loss: 0.3230 - val_accuracy: 0.8677\n",
      "Epoch 90/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2218 - accuracy: 0.9113\n",
      "Epoch 90: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2314 - accuracy: 0.9032 - val_loss: 0.3152 - val_accuracy: 0.8608\n",
      "Epoch 91/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2529 - accuracy: 0.8952\n",
      "Epoch 91: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2279 - accuracy: 0.9069 - val_loss: 0.3054 - val_accuracy: 0.8708\n",
      "Epoch 92/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2438 - accuracy: 0.8952\n",
      "Epoch 92: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.9073 - val_loss: 0.3070 - val_accuracy: 0.8708\n",
      "Epoch 93/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2121 - accuracy: 0.9113\n",
      "Epoch 93: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2422 - accuracy: 0.8986 - val_loss: 0.3198 - val_accuracy: 0.8654\n",
      "Epoch 94/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2349 - accuracy: 0.8871\n",
      "Epoch 94: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2264 - accuracy: 0.9071 - val_loss: 0.3086 - val_accuracy: 0.8692\n",
      "Epoch 95/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2804 - accuracy: 0.8468\n",
      "Epoch 95: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 0.9063 - val_loss: 0.3168 - val_accuracy: 0.8646\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1972 - accuracy: 0.9274\n",
      "Epoch 96: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2323 - accuracy: 0.9040 - val_loss: 0.3469 - val_accuracy: 0.8500\n",
      "Epoch 97/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3117 - accuracy: 0.8710\n",
      "Epoch 97: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2488 - accuracy: 0.8949 - val_loss: 0.3101 - val_accuracy: 0.8723\n",
      "Epoch 98/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1318 - accuracy: 0.9758\n",
      "Epoch 98: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2268 - accuracy: 0.9042 - val_loss: 0.3251 - val_accuracy: 0.8700\n",
      "Epoch 99/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2670 - accuracy: 0.8871\n",
      "Epoch 99: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2202 - accuracy: 0.9113 - val_loss: 0.3134 - val_accuracy: 0.8746\n",
      "Epoch 100/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2026 - accuracy: 0.9113\n",
      "Epoch 100: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9071 - val_loss: 0.3139 - val_accuracy: 0.8677\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2444 - accuracy: 0.8952\n",
      "Epoch 101: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2185 - accuracy: 0.9111 - val_loss: 0.3196 - val_accuracy: 0.8692\n",
      "Epoch 102/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1992 - accuracy: 0.8871\n",
      "Epoch 102: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2208 - accuracy: 0.9109 - val_loss: 0.3277 - val_accuracy: 0.8708\n",
      "Epoch 103/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1988 - accuracy: 0.9355\n",
      "Epoch 103: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2182 - accuracy: 0.9124 - val_loss: 0.3235 - val_accuracy: 0.8623\n",
      "Epoch 104/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2685 - accuracy: 0.8952\n",
      "Epoch 104: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2386 - accuracy: 0.9003 - val_loss: 0.3103 - val_accuracy: 0.8677\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1587 - accuracy: 0.9355\n",
      "Epoch 105: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2335 - accuracy: 0.9013 - val_loss: 0.3208 - val_accuracy: 0.8731\n",
      "Epoch 106/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1706 - accuracy: 0.9274\n",
      "Epoch 106: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2368 - accuracy: 0.8999 - val_loss: 0.3176 - val_accuracy: 0.8677\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3192 - accuracy: 0.8952\n",
      "Epoch 107: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2131 - accuracy: 0.9121 - val_loss: 0.3163 - val_accuracy: 0.8631\n",
      "Epoch 108/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2793 - accuracy: 0.8790\n",
      "Epoch 108: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.9105 - val_loss: 0.3240 - val_accuracy: 0.8692\n",
      "Epoch 109/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2109 - accuracy: 0.8952\n",
      "Epoch 109: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2173 - accuracy: 0.9115 - val_loss: 0.3197 - val_accuracy: 0.8646\n",
      "Epoch 110/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2219 - accuracy: 0.9435\n",
      "Epoch 110: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2150 - accuracy: 0.9130 - val_loss: 0.3484 - val_accuracy: 0.8577\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2273 - accuracy: 0.8871\n",
      "Epoch 111: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2149 - accuracy: 0.9113 - val_loss: 0.3242 - val_accuracy: 0.8685\n",
      "Epoch 112/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1895 - accuracy: 0.9032\n",
      "Epoch 112: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2121 - accuracy: 0.9121 - val_loss: 0.3336 - val_accuracy: 0.8654\n",
      "Epoch 113/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2791 - accuracy: 0.9113\n",
      "Epoch 113: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2115 - accuracy: 0.9155 - val_loss: 0.3323 - val_accuracy: 0.8638\n",
      "Epoch 114/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2134 - accuracy: 0.9113\n",
      "Epoch 114: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2124 - accuracy: 0.9142 - val_loss: 0.3345 - val_accuracy: 0.8646\n",
      "Epoch 115/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2480 - accuracy: 0.8629\n",
      "Epoch 115: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2206 - accuracy: 0.9094 - val_loss: 0.3200 - val_accuracy: 0.8646\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2280 - accuracy: 0.9113\n",
      "Epoch 116: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2252 - accuracy: 0.9051 - val_loss: 0.3395 - val_accuracy: 0.8638\n",
      "Epoch 117/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1909 - accuracy: 0.9274\n",
      "Epoch 117: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2155 - accuracy: 0.9107 - val_loss: 0.3269 - val_accuracy: 0.8700\n",
      "Epoch 118/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2049 - accuracy: 0.8871\n",
      "Epoch 118: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2094 - accuracy: 0.9140 - val_loss: 0.3293 - val_accuracy: 0.8662\n",
      "Epoch 119/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2110 - accuracy: 0.9113\n",
      "Epoch 119: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2219 - accuracy: 0.9055 - val_loss: 0.3418 - val_accuracy: 0.8685\n",
      "Epoch 120/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2329 - accuracy: 0.8952\n",
      "Epoch 120: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2078 - accuracy: 0.9140 - val_loss: 0.3325 - val_accuracy: 0.8669\n",
      "Epoch 121/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1822 - accuracy: 0.9194\n",
      "Epoch 121: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 0.9130 - val_loss: 0.3266 - val_accuracy: 0.8615\n",
      "Epoch 122/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1083 - accuracy: 0.9839\n",
      "Epoch 122: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2037 - accuracy: 0.9150 - val_loss: 0.3249 - val_accuracy: 0.8700\n",
      "Epoch 123/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1947 - accuracy: 0.9113\n",
      "Epoch 123: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2050 - accuracy: 0.9155 - val_loss: 0.3400 - val_accuracy: 0.8669\n",
      "Epoch 124/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1787 - accuracy: 0.9355\n",
      "Epoch 124: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2031 - accuracy: 0.9124 - val_loss: 0.3291 - val_accuracy: 0.8623\n",
      "Epoch 125/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2038 - accuracy: 0.8952\n",
      "Epoch 125: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1984 - accuracy: 0.9173 - val_loss: 0.3337 - val_accuracy: 0.8608\n",
      "Epoch 126/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2119 - accuracy: 0.9274\n",
      "Epoch 126: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2044 - accuracy: 0.9167 - val_loss: 0.3474 - val_accuracy: 0.8546\n",
      "Epoch 127/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2102 - accuracy: 0.9113\n",
      "Epoch 127: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2072 - accuracy: 0.9138 - val_loss: 0.3637 - val_accuracy: 0.8577\n",
      "Epoch 128/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1517 - accuracy: 0.9435\n",
      "Epoch 128: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2094 - accuracy: 0.9103 - val_loss: 0.3818 - val_accuracy: 0.8508\n",
      "Epoch 129/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2429 - accuracy: 0.9032\n",
      "Epoch 129: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2121 - accuracy: 0.9111 - val_loss: 0.4009 - val_accuracy: 0.8408\n",
      "Epoch 130/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2653 - accuracy: 0.8871\n",
      "Epoch 130: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2036 - accuracy: 0.9176 - val_loss: 0.3479 - val_accuracy: 0.8600\n",
      "Epoch 131/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2050 - accuracy: 0.8871\n",
      "Epoch 131: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2034 - accuracy: 0.9169 - val_loss: 0.3615 - val_accuracy: 0.8546\n",
      "Epoch 132/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1938 - accuracy: 0.9274\n",
      "Epoch 132: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2082 - accuracy: 0.9121 - val_loss: 0.3632 - val_accuracy: 0.8638\n",
      "Epoch 133/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1895 - accuracy: 0.9194\n",
      "Epoch 133: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2041 - accuracy: 0.9140 - val_loss: 0.3682 - val_accuracy: 0.8585\n",
      "Epoch 134/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1940 - accuracy: 0.9113\n",
      "Epoch 134: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2025 - accuracy: 0.9150 - val_loss: 0.3588 - val_accuracy: 0.8554\n",
      "Epoch 135/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1999 - accuracy: 0.9194\n",
      "Epoch 135: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 0.9151 - val_loss: 0.3372 - val_accuracy: 0.8585\n",
      "Epoch 136/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2243 - accuracy: 0.9194\n",
      "Epoch 136: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1932 - accuracy: 0.9207 - val_loss: 0.3547 - val_accuracy: 0.8638\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1877 - accuracy: 0.9194\n",
      "Epoch 137: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1955 - accuracy: 0.9200 - val_loss: 0.3574 - val_accuracy: 0.8577\n",
      "Epoch 138/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2281 - accuracy: 0.9194\n",
      "Epoch 138: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1977 - accuracy: 0.9192 - val_loss: 0.3505 - val_accuracy: 0.8646\n",
      "Epoch 139/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2404 - accuracy: 0.9032\n",
      "Epoch 139: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1975 - accuracy: 0.9161 - val_loss: 0.3655 - val_accuracy: 0.8546\n",
      "Epoch 140/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2539 - accuracy: 0.9032\n",
      "Epoch 140: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2053 - accuracy: 0.9138 - val_loss: 0.3493 - val_accuracy: 0.8715\n",
      "Epoch 141/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1904 - accuracy: 0.9113\n",
      "Epoch 141: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1937 - accuracy: 0.9205 - val_loss: 0.3529 - val_accuracy: 0.8654\n",
      "Epoch 142/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1723 - accuracy: 0.9274\n",
      "Epoch 142: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2010 - accuracy: 0.9175 - val_loss: 0.3609 - val_accuracy: 0.8662\n",
      "Epoch 143/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1699 - accuracy: 0.9355\n",
      "Epoch 143: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1975 - accuracy: 0.9180 - val_loss: 0.3634 - val_accuracy: 0.8538\n",
      "Epoch 144/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2289 - accuracy: 0.9113\n",
      "Epoch 144: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1968 - accuracy: 0.9173 - val_loss: 0.3594 - val_accuracy: 0.8654\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1505 - accuracy: 0.9194\n",
      "Epoch 145: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.9171 - val_loss: 0.3518 - val_accuracy: 0.8669\n",
      "Epoch 146/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2346 - accuracy: 0.8952\n",
      "Epoch 146: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1903 - accuracy: 0.9213 - val_loss: 0.3795 - val_accuracy: 0.8592\n",
      "Epoch 147/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2006 - accuracy: 0.9194\n",
      "Epoch 147: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1904 - accuracy: 0.9236 - val_loss: 0.3669 - val_accuracy: 0.8654\n",
      "Epoch 148/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1574 - accuracy: 0.9194\n",
      "Epoch 148: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1942 - accuracy: 0.9184 - val_loss: 0.3749 - val_accuracy: 0.8592\n",
      "Epoch 149/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2855 - accuracy: 0.8952\n",
      "Epoch 149: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1918 - accuracy: 0.9201 - val_loss: 0.3590 - val_accuracy: 0.8677\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2304 - accuracy: 0.9113\n",
      "Epoch 150: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1971 - accuracy: 0.9167 - val_loss: 0.3795 - val_accuracy: 0.8577\n",
      "Epoch 151/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2160 - accuracy: 0.8710\n",
      "Epoch 151: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1954 - accuracy: 0.9203 - val_loss: 0.4088 - val_accuracy: 0.8438\n",
      "Epoch 152/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1968 - accuracy: 0.9194\n",
      "Epoch 152: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1935 - accuracy: 0.9194 - val_loss: 0.3783 - val_accuracy: 0.8515\n",
      "Epoch 153/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1341 - accuracy: 0.9435\n",
      "Epoch 153: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.9167 - val_loss: 0.3686 - val_accuracy: 0.8523\n",
      "Epoch 154/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1914 - accuracy: 0.9355\n",
      "Epoch 154: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.9205 - val_loss: 0.4006 - val_accuracy: 0.8600\n",
      "Epoch 155/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1467 - accuracy: 0.9516\n",
      "Epoch 155: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1843 - accuracy: 0.9242 - val_loss: 0.3591 - val_accuracy: 0.8608\n",
      "Epoch 156/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1498 - accuracy: 0.9435\n",
      "Epoch 156: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1836 - accuracy: 0.9255 - val_loss: 0.3653 - val_accuracy: 0.8562\n",
      "Epoch 157/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1550 - accuracy: 0.9194\n",
      "Epoch 157: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.9205 - val_loss: 0.3778 - val_accuracy: 0.8562\n",
      "Epoch 158/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1459 - accuracy: 0.9274\n",
      "Epoch 158: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1861 - accuracy: 0.9250 - val_loss: 0.3604 - val_accuracy: 0.8562\n",
      "Epoch 159/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1273 - accuracy: 0.9435\n",
      "Epoch 159: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.9232 - val_loss: 0.3764 - val_accuracy: 0.8631\n",
      "Epoch 160/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1382 - accuracy: 0.9274\n",
      "Epoch 160: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1957 - accuracy: 0.9200 - val_loss: 0.3944 - val_accuracy: 0.8600\n",
      "Epoch 161/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1958 - accuracy: 0.8871\n",
      "Epoch 161: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1818 - accuracy: 0.9236 - val_loss: 0.3828 - val_accuracy: 0.8654\n",
      "Epoch 162/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1443 - accuracy: 0.9274\n",
      "Epoch 162: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1877 - accuracy: 0.9211 - val_loss: 0.3679 - val_accuracy: 0.8562\n",
      "Epoch 163/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2416 - accuracy: 0.9274\n",
      "Epoch 163: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9176 - val_loss: 0.3938 - val_accuracy: 0.8615\n",
      "Epoch 164/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1815 - accuracy: 0.9194\n",
      "Epoch 164: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1800 - accuracy: 0.9253 - val_loss: 0.3787 - val_accuracy: 0.8600\n",
      "Epoch 165/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2632 - accuracy: 0.8871\n",
      "Epoch 165: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1831 - accuracy: 0.9236 - val_loss: 0.3953 - val_accuracy: 0.8546\n",
      "Epoch 166/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2229 - accuracy: 0.9032\n",
      "Epoch 166: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.9261 - val_loss: 0.4073 - val_accuracy: 0.8600\n",
      "Epoch 167/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1922 - accuracy: 0.9199\n",
      "Epoch 167: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1935 - accuracy: 0.9194 - val_loss: 0.3786 - val_accuracy: 0.8654\n",
      "Epoch 168/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1906 - accuracy: 0.9194\n",
      "Epoch 168: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1851 - accuracy: 0.9228 - val_loss: 0.3752 - val_accuracy: 0.8662\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Epoch 1/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.9137 - accuracy: 0.5556 \n",
      "Epoch 1: val_accuracy improved from -inf to 0.66923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.8877 - accuracy: 0.5621 - val_loss: 0.6192 - val_accuracy: 0.6692\n",
      "Epoch 2/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.6339 - accuracy: 0.7097\n",
      "Epoch 2: val_accuracy improved from 0.66923 to 0.78462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5679 - accuracy: 0.7256 - val_loss: 0.5120 - val_accuracy: 0.7846\n",
      "Epoch 3/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.5371 - accuracy: 0.7581\n",
      "Epoch 3: val_accuracy improved from 0.78462 to 0.82846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.8007 - val_loss: 0.4434 - val_accuracy: 0.8285\n",
      "Epoch 4/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.4254 - accuracy: 0.8336\n",
      "Epoch 4: val_accuracy improved from 0.82846 to 0.83308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.8330 - val_loss: 0.4068 - val_accuracy: 0.8331\n",
      "Epoch 5/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.3924 - accuracy: 0.8387\n",
      "Epoch 5: val_accuracy improved from 0.83308 to 0.84769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3850 - accuracy: 0.8439 - val_loss: 0.3708 - val_accuracy: 0.8477\n",
      "Epoch 6/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3641 - accuracy: 0.8513\n",
      "Epoch 6: val_accuracy improved from 0.84769 to 0.85231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3659 - accuracy: 0.8499 - val_loss: 0.3540 - val_accuracy: 0.8523\n",
      "Epoch 7/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.3508 - accuracy: 0.8527\n",
      "Epoch 7: val_accuracy did not improve from 0.85231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8503 - val_loss: 0.3741 - val_accuracy: 0.8362\n",
      "Epoch 8/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3502 - accuracy: 0.8556\n",
      "Epoch 8: val_accuracy did not improve from 0.85231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3486 - accuracy: 0.8561 - val_loss: 0.3576 - val_accuracy: 0.8392\n",
      "Epoch 9/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3861 - accuracy: 0.8468\n",
      "Epoch 9: val_accuracy improved from 0.85231 to 0.85538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3414 - accuracy: 0.8620 - val_loss: 0.3383 - val_accuracy: 0.8554\n",
      "Epoch 10/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3879 - accuracy: 0.8710\n",
      "Epoch 10: val_accuracy did not improve from 0.85538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8628 - val_loss: 0.3459 - val_accuracy: 0.8469\n",
      "Epoch 11/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3776 - accuracy: 0.8306\n",
      "Epoch 11: val_accuracy improved from 0.85538 to 0.86077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8593 - val_loss: 0.3400 - val_accuracy: 0.8608\n",
      "Epoch 12/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.3251 - accuracy: 0.8603\n",
      "Epoch 12: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8574 - val_loss: 0.4236 - val_accuracy: 0.8177\n",
      "Epoch 13/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.3441 - accuracy: 0.8526\n",
      "Epoch 13: val_accuracy improved from 0.86077 to 0.86231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3407 - accuracy: 0.8543 - val_loss: 0.3381 - val_accuracy: 0.8623\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2518 - accuracy: 0.8710\n",
      "Epoch 14: val_accuracy did not improve from 0.86231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.8630 - val_loss: 0.3363 - val_accuracy: 0.8600\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2659 - accuracy: 0.9032\n",
      "Epoch 15: val_accuracy did not improve from 0.86231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.8682 - val_loss: 0.3334 - val_accuracy: 0.8615\n",
      "Epoch 16/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3135 - accuracy: 0.8688\n",
      "Epoch 16: val_accuracy did not improve from 0.86231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8688 - val_loss: 0.3296 - val_accuracy: 0.8608\n",
      "Epoch 17/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3131 - accuracy: 0.8692\n",
      "Epoch 17: val_accuracy did not improve from 0.86231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8697 - val_loss: 0.3348 - val_accuracy: 0.8492\n",
      "Epoch 18/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.3190 - accuracy: 0.8652\n",
      "Epoch 18: val_accuracy did not improve from 0.86231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8667 - val_loss: 0.3355 - val_accuracy: 0.8485\n",
      "Epoch 19/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4016 - accuracy: 0.8387\n",
      "Epoch 19: val_accuracy did not improve from 0.86231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8703 - val_loss: 0.3538 - val_accuracy: 0.8438\n",
      "Epoch 20/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.3118 - accuracy: 0.8656\n",
      "Epoch 20: val_accuracy did not improve from 0.86231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.8670 - val_loss: 0.3282 - val_accuracy: 0.8608\n",
      "Epoch 21/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3100 - accuracy: 0.8740\n",
      "Epoch 21: val_accuracy improved from 0.86231 to 0.86308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3121 - accuracy: 0.8738 - val_loss: 0.3329 - val_accuracy: 0.8631\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3057 - accuracy: 0.8736\n",
      "Epoch 22: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3057 - accuracy: 0.8736 - val_loss: 0.3408 - val_accuracy: 0.8623\n",
      "Epoch 23/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.3106 - accuracy: 0.8666\n",
      "Epoch 23: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8670 - val_loss: 0.3483 - val_accuracy: 0.8431\n",
      "Epoch 24/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3453 - accuracy: 0.8306\n",
      "Epoch 24: val_accuracy improved from 0.86308 to 0.86615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.8622 - val_loss: 0.3374 - val_accuracy: 0.8662\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3524 - accuracy: 0.8790\n",
      "Epoch 25: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 0.8763 - val_loss: 0.3317 - val_accuracy: 0.8631\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3055 - accuracy: 0.8711\n",
      "Epoch 26: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8711 - val_loss: 0.3744 - val_accuracy: 0.8331\n",
      "Epoch 27/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.3155 - accuracy: 0.8660\n",
      "Epoch 27: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8697 - val_loss: 0.3313 - val_accuracy: 0.8654\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4361 - accuracy: 0.7742\n",
      "Epoch 28: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3012 - accuracy: 0.8724 - val_loss: 0.3279 - val_accuracy: 0.8577\n",
      "Epoch 29/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3055 - accuracy: 0.8708\n",
      "Epoch 29: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3038 - accuracy: 0.8718 - val_loss: 0.3296 - val_accuracy: 0.8538\n",
      "Epoch 30/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2974 - accuracy: 0.8751\n",
      "Epoch 30: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2983 - accuracy: 0.8749 - val_loss: 0.3322 - val_accuracy: 0.8462\n",
      "Epoch 31/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2924 - accuracy: 0.8734\n",
      "Epoch 31: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2961 - accuracy: 0.8722 - val_loss: 0.3354 - val_accuracy: 0.8646\n",
      "Epoch 32/1000\n",
      "29/42 [===================>..........] - ETA: 0s - loss: 0.2955 - accuracy: 0.8788\n",
      "Epoch 32: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2953 - accuracy: 0.8770 - val_loss: 0.3349 - val_accuracy: 0.8654\n",
      "Epoch 33/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2816 - accuracy: 0.8710\n",
      "Epoch 33: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2960 - accuracy: 0.8767 - val_loss: 0.3273 - val_accuracy: 0.8623\n",
      "Epoch 34/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3035 - accuracy: 0.8682\n",
      "Epoch 34: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3017 - accuracy: 0.8695 - val_loss: 0.3307 - val_accuracy: 0.8592\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2947 - accuracy: 0.8761\n",
      "Epoch 35: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2947 - accuracy: 0.8761 - val_loss: 0.3683 - val_accuracy: 0.8362\n",
      "Epoch 36/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.3062 - accuracy: 0.8695\n",
      "Epoch 36: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3054 - accuracy: 0.8693 - val_loss: 0.3283 - val_accuracy: 0.8577\n",
      "Epoch 37/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2767 - accuracy: 0.8871\n",
      "Epoch 37: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2944 - accuracy: 0.8776 - val_loss: 0.3345 - val_accuracy: 0.8477\n",
      "Epoch 38/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2925 - accuracy: 0.8727\n",
      "Epoch 38: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2937 - accuracy: 0.8732 - val_loss: 0.3628 - val_accuracy: 0.8492\n",
      "Epoch 39/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.3034 - accuracy: 0.8705\n",
      "Epoch 39: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2991 - accuracy: 0.8730 - val_loss: 0.3291 - val_accuracy: 0.8623\n",
      "Epoch 40/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2956 - accuracy: 0.8737\n",
      "Epoch 40: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2962 - accuracy: 0.8736 - val_loss: 0.3306 - val_accuracy: 0.8623\n",
      "Epoch 41/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2945 - accuracy: 0.8752\n",
      "Epoch 41: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 0.8720 - val_loss: 0.3806 - val_accuracy: 0.8423\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3346 - accuracy: 0.8548\n",
      "Epoch 42: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3001 - accuracy: 0.8722 - val_loss: 0.3248 - val_accuracy: 0.8631\n",
      "Epoch 43/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2911 - accuracy: 0.8776\n",
      "Epoch 43: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2890 - accuracy: 0.8795 - val_loss: 0.3268 - val_accuracy: 0.8600\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2862 - accuracy: 0.8842\n",
      "Epoch 44: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2862 - accuracy: 0.8842 - val_loss: 0.3294 - val_accuracy: 0.8546\n",
      "Epoch 45/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2875 - accuracy: 0.8803\n",
      "Epoch 45: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2839 - accuracy: 0.8822 - val_loss: 0.3246 - val_accuracy: 0.8585\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2959 - accuracy: 0.8757\n",
      "Epoch 46: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2959 - accuracy: 0.8757 - val_loss: 0.3296 - val_accuracy: 0.8562\n",
      "Epoch 47/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2845 - accuracy: 0.8816\n",
      "Epoch 47: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2841 - accuracy: 0.8809 - val_loss: 0.3431 - val_accuracy: 0.8600\n",
      "Epoch 48/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2865 - accuracy: 0.8871\n",
      "Epoch 48: val_accuracy improved from 0.86615 to 0.86769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2869 - accuracy: 0.8820 - val_loss: 0.3215 - val_accuracy: 0.8677\n",
      "Epoch 49/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2827 - accuracy: 0.8835\n",
      "Epoch 49: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2872 - accuracy: 0.8817 - val_loss: 0.3222 - val_accuracy: 0.8669\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2864 - accuracy: 0.8807\n",
      "Epoch 50: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2864 - accuracy: 0.8807 - val_loss: 0.3368 - val_accuracy: 0.8608\n",
      "Epoch 51/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2819 - accuracy: 0.8778\n",
      "Epoch 51: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2840 - accuracy: 0.8780 - val_loss: 0.3280 - val_accuracy: 0.8623\n",
      "Epoch 52/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2766 - accuracy: 0.8952\n",
      "Epoch 52: val_accuracy improved from 0.86769 to 0.86923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2792 - accuracy: 0.8844 - val_loss: 0.3171 - val_accuracy: 0.8692\n",
      "Epoch 53/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2854 - accuracy: 0.8819\n",
      "Epoch 53: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2855 - accuracy: 0.8813 - val_loss: 0.3233 - val_accuracy: 0.8646\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2825 - accuracy: 0.8822\n",
      "Epoch 54: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2825 - accuracy: 0.8822 - val_loss: 0.3152 - val_accuracy: 0.8685\n",
      "Epoch 55/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2808 - accuracy: 0.8837\n",
      "Epoch 55: val_accuracy improved from 0.86923 to 0.87462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2810 - accuracy: 0.8836 - val_loss: 0.3178 - val_accuracy: 0.8746\n",
      "Epoch 56/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2769 - accuracy: 0.8873\n",
      "Epoch 56: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2762 - accuracy: 0.8867 - val_loss: 0.3232 - val_accuracy: 0.8615\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2273 - accuracy: 0.9113\n",
      "Epoch 57: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2797 - accuracy: 0.8822 - val_loss: 0.3208 - val_accuracy: 0.8708\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2784 - accuracy: 0.8853\n",
      "Epoch 58: val_accuracy improved from 0.87462 to 0.87615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2784 - accuracy: 0.8853 - val_loss: 0.3148 - val_accuracy: 0.8762\n",
      "Epoch 59/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2722 - accuracy: 0.8871\n",
      "Epoch 59: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2743 - accuracy: 0.8853 - val_loss: 0.3194 - val_accuracy: 0.8662\n",
      "Epoch 60/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2718 - accuracy: 0.8887\n",
      "Epoch 60: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2725 - accuracy: 0.8882 - val_loss: 0.3127 - val_accuracy: 0.8723\n",
      "Epoch 61/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2736 - accuracy: 0.8794\n",
      "Epoch 61: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2719 - accuracy: 0.8813 - val_loss: 0.3395 - val_accuracy: 0.8608\n",
      "Epoch 62/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2741 - accuracy: 0.8850\n",
      "Epoch 62: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2734 - accuracy: 0.8855 - val_loss: 0.3292 - val_accuracy: 0.8708\n",
      "Epoch 63/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2717 - accuracy: 0.8790\n",
      "Epoch 63: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2611 - accuracy: 0.8940 - val_loss: 0.3130 - val_accuracy: 0.8646\n",
      "Epoch 64/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2853 - accuracy: 0.8629\n",
      "Epoch 64: val_accuracy improved from 0.87615 to 0.87692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2605 - accuracy: 0.8907 - val_loss: 0.3114 - val_accuracy: 0.8769\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2636 - accuracy: 0.8890\n",
      "Epoch 65: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2636 - accuracy: 0.8890 - val_loss: 0.3225 - val_accuracy: 0.8708\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2727 - accuracy: 0.8845\n",
      "Epoch 66: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2727 - accuracy: 0.8845 - val_loss: 0.3096 - val_accuracy: 0.8708\n",
      "Epoch 67/1000\n",
      "26/42 [=================>............] - ETA: 0s - loss: 0.2506 - accuracy: 0.8970\n",
      "Epoch 67: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2607 - accuracy: 0.8926 - val_loss: 0.3021 - val_accuracy: 0.8700\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2348 - accuracy: 0.9113\n",
      "Epoch 68: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2647 - accuracy: 0.8863 - val_loss: 0.3130 - val_accuracy: 0.8754\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2528 - accuracy: 0.8965\n",
      "Epoch 69: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2528 - accuracy: 0.8965 - val_loss: 0.3329 - val_accuracy: 0.8685\n",
      "Epoch 70/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2550 - accuracy: 0.8930\n",
      "Epoch 70: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2583 - accuracy: 0.8915 - val_loss: 0.3078 - val_accuracy: 0.8738\n",
      "Epoch 71/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2522 - accuracy: 0.8964\n",
      "Epoch 71: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.8967 - val_loss: 0.3438 - val_accuracy: 0.8662\n",
      "Epoch 72/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2739 - accuracy: 0.8841\n",
      "Epoch 72: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2718 - accuracy: 0.8859 - val_loss: 0.3123 - val_accuracy: 0.8692\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2585 - accuracy: 0.8917\n",
      "Epoch 73: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2585 - accuracy: 0.8917 - val_loss: 0.3079 - val_accuracy: 0.8769\n",
      "Epoch 74/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2485 - accuracy: 0.8981\n",
      "Epoch 74: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2518 - accuracy: 0.8961 - val_loss: 0.3268 - val_accuracy: 0.8615\n",
      "Epoch 75/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2734 - accuracy: 0.8828\n",
      "Epoch 75: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2725 - accuracy: 0.8836 - val_loss: 0.3293 - val_accuracy: 0.8685\n",
      "Epoch 76/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2579 - accuracy: 0.8891\n",
      "Epoch 76: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.8905 - val_loss: 0.3033 - val_accuracy: 0.8700\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2701 - accuracy: 0.8952\n",
      "Epoch 77: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2564 - accuracy: 0.8938 - val_loss: 0.2951 - val_accuracy: 0.8723\n",
      "Epoch 78/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2472 - accuracy: 0.8942\n",
      "Epoch 78: val_accuracy improved from 0.87692 to 0.88000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2471 - accuracy: 0.8947 - val_loss: 0.3000 - val_accuracy: 0.8800\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2714 - accuracy: 0.9032\n",
      "Epoch 79: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2423 - accuracy: 0.9005 - val_loss: 0.3032 - val_accuracy: 0.8700\n",
      "Epoch 80/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2498 - accuracy: 0.8964\n",
      "Epoch 80: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.8965 - val_loss: 0.3154 - val_accuracy: 0.8777\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4149 - accuracy: 0.7984\n",
      "Epoch 81: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.9026 - val_loss: 0.3059 - val_accuracy: 0.8738\n",
      "Epoch 82/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2385 - accuracy: 0.8991\n",
      "Epoch 82: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2409 - accuracy: 0.8974 - val_loss: 0.3110 - val_accuracy: 0.8692\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3042 - accuracy: 0.8710\n",
      "Epoch 83: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2425 - accuracy: 0.9005 - val_loss: 0.3112 - val_accuracy: 0.8677\n",
      "Epoch 84/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1639 - accuracy: 0.9435\n",
      "Epoch 84: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2394 - accuracy: 0.8967 - val_loss: 0.3051 - val_accuracy: 0.8715\n",
      "Epoch 85/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2422 - accuracy: 0.8956\n",
      "Epoch 85: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2418 - accuracy: 0.8949 - val_loss: 0.3026 - val_accuracy: 0.8685\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1782 - accuracy: 0.9032\n",
      "Epoch 86: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2359 - accuracy: 0.9001 - val_loss: 0.3261 - val_accuracy: 0.8692\n",
      "Epoch 87/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2393 - accuracy: 0.9030\n",
      "Epoch 87: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2360 - accuracy: 0.9048 - val_loss: 0.2999 - val_accuracy: 0.8792\n",
      "Epoch 88/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1770 - accuracy: 0.9516\n",
      "Epoch 88: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.9023 - val_loss: 0.3062 - val_accuracy: 0.8677\n",
      "Epoch 89/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2344 - accuracy: 0.8952\n",
      "Epoch 89: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2308 - accuracy: 0.9065 - val_loss: 0.3188 - val_accuracy: 0.8746\n",
      "Epoch 90/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2057 - accuracy: 0.9113\n",
      "Epoch 90: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2397 - accuracy: 0.9021 - val_loss: 0.3044 - val_accuracy: 0.8723\n",
      "Epoch 91/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2680 - accuracy: 0.8710\n",
      "Epoch 91: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2476 - accuracy: 0.8940 - val_loss: 0.3019 - val_accuracy: 0.8723\n",
      "Epoch 92/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2289 - accuracy: 0.9077\n",
      "Epoch 92: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2311 - accuracy: 0.9063 - val_loss: 0.3098 - val_accuracy: 0.8746\n",
      "Epoch 93/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1728 - accuracy: 0.9435\n",
      "Epoch 93: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8944 - val_loss: 0.3172 - val_accuracy: 0.8746\n",
      "Epoch 94/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1629 - accuracy: 0.9355\n",
      "Epoch 94: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2308 - accuracy: 0.9042 - val_loss: 0.3102 - val_accuracy: 0.8746\n",
      "Epoch 95/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.2234 - accuracy: 0.9105\n",
      "Epoch 95: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2297 - accuracy: 0.9051 - val_loss: 0.3042 - val_accuracy: 0.8715\n",
      "Epoch 96/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2435 - accuracy: 0.8990\n",
      "Epoch 96: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2367 - accuracy: 0.9030 - val_loss: 0.3066 - val_accuracy: 0.8692\n",
      "Epoch 97/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2396 - accuracy: 0.9017\n",
      "Epoch 97: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.9017 - val_loss: 0.3346 - val_accuracy: 0.8669\n",
      "Epoch 98/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.2262 - accuracy: 0.9050\n",
      "Epoch 98: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.9040 - val_loss: 0.3106 - val_accuracy: 0.8738\n",
      "Epoch 99/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2380 - accuracy: 0.8952\n",
      "Epoch 99: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2202 - accuracy: 0.9057 - val_loss: 0.3022 - val_accuracy: 0.8731\n",
      "Epoch 100/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2213 - accuracy: 0.9069\n",
      "Epoch 100: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2220 - accuracy: 0.9057 - val_loss: 0.3065 - val_accuracy: 0.8731\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1863 - accuracy: 0.9516\n",
      "Epoch 101: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2184 - accuracy: 0.9101 - val_loss: 0.3083 - val_accuracy: 0.8731\n",
      "Epoch 102/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2356 - accuracy: 0.8871\n",
      "Epoch 102: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.9099 - val_loss: 0.3203 - val_accuracy: 0.8685\n",
      "Epoch 103/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2239 - accuracy: 0.9056\n",
      "Epoch 103: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2274 - accuracy: 0.9040 - val_loss: 0.3037 - val_accuracy: 0.8754\n",
      "Epoch 104/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2267 - accuracy: 0.9071\n",
      "Epoch 104: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.9071 - val_loss: 0.3061 - val_accuracy: 0.8685\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1772 - accuracy: 0.9032\n",
      "Epoch 105: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2158 - accuracy: 0.9096 - val_loss: 0.3300 - val_accuracy: 0.8615\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2203 - accuracy: 0.9096\n",
      "Epoch 106: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2203 - accuracy: 0.9096 - val_loss: 0.3134 - val_accuracy: 0.8723\n",
      "Epoch 107/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2175 - accuracy: 0.9081\n",
      "Epoch 107: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2167 - accuracy: 0.9082 - val_loss: 0.3252 - val_accuracy: 0.8777\n",
      "Epoch 108/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2237 - accuracy: 0.9067\n",
      "Epoch 108: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2237 - accuracy: 0.9067 - val_loss: 0.3467 - val_accuracy: 0.8677\n",
      "Epoch 109/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2005 - accuracy: 0.9032\n",
      "Epoch 109: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2132 - accuracy: 0.9117 - val_loss: 0.3093 - val_accuracy: 0.8715\n",
      "Epoch 110/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1644 - accuracy: 0.9435\n",
      "Epoch 110: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2159 - accuracy: 0.9121 - val_loss: 0.3177 - val_accuracy: 0.8685\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1888 - accuracy: 0.9516\n",
      "Epoch 111: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2137 - accuracy: 0.9113 - val_loss: 0.3210 - val_accuracy: 0.8785\n",
      "Epoch 112/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2091 - accuracy: 0.9355\n",
      "Epoch 112: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2147 - accuracy: 0.9074 - val_loss: 0.3693 - val_accuracy: 0.8500\n",
      "Epoch 113/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3333 - accuracy: 0.8387\n",
      "Epoch 113: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2251 - accuracy: 0.9073 - val_loss: 0.3190 - val_accuracy: 0.8723\n",
      "Epoch 114/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1486 - accuracy: 0.9435\n",
      "Epoch 114: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2134 - accuracy: 0.9113 - val_loss: 0.3299 - val_accuracy: 0.8662\n",
      "Epoch 115/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2112 - accuracy: 0.9138\n",
      "Epoch 115: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2112 - accuracy: 0.9138 - val_loss: 0.3277 - val_accuracy: 0.8662\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2538 - accuracy: 0.8871\n",
      "Epoch 116: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2078 - accuracy: 0.9086 - val_loss: 0.3263 - val_accuracy: 0.8700\n",
      "Epoch 117/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2101 - accuracy: 0.9094\n",
      "Epoch 117: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2110 - accuracy: 0.9088 - val_loss: 0.3217 - val_accuracy: 0.8777\n",
      "Epoch 118/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2192 - accuracy: 0.9026\n",
      "Epoch 118: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2179 - accuracy: 0.9034 - val_loss: 0.3154 - val_accuracy: 0.8692\n",
      "Epoch 119/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1545 - accuracy: 0.9194\n",
      "Epoch 119: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2058 - accuracy: 0.9155 - val_loss: 0.3122 - val_accuracy: 0.8746\n",
      "Epoch 120/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2106 - accuracy: 0.9115\n",
      "Epoch 120: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2099 - accuracy: 0.9119 - val_loss: 0.3158 - val_accuracy: 0.8708\n",
      "Epoch 121/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2709 - accuracy: 0.8790\n",
      "Epoch 121: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 0.9124 - val_loss: 0.3235 - val_accuracy: 0.8746\n",
      "Epoch 122/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2059 - accuracy: 0.9121\n",
      "Epoch 122: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2059 - accuracy: 0.9121 - val_loss: 0.3258 - val_accuracy: 0.8685\n",
      "Epoch 123/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2039 - accuracy: 0.9158\n",
      "Epoch 123: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.9155 - val_loss: 0.3228 - val_accuracy: 0.8738\n",
      "Epoch 124/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2064 - accuracy: 0.9139\n",
      "Epoch 124: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2042 - accuracy: 0.9151 - val_loss: 0.3148 - val_accuracy: 0.8769\n",
      "Epoch 125/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2014 - accuracy: 0.9198\n",
      "Epoch 125: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2014 - accuracy: 0.9198 - val_loss: 0.3177 - val_accuracy: 0.8708\n",
      "Epoch 126/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2032 - accuracy: 0.9161\n",
      "Epoch 126: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2032 - accuracy: 0.9161 - val_loss: 0.3200 - val_accuracy: 0.8754\n",
      "Epoch 127/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1971 - accuracy: 0.9208\n",
      "Epoch 127: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9209 - val_loss: 0.3343 - val_accuracy: 0.8631\n",
      "Epoch 128/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2078 - accuracy: 0.9127\n",
      "Epoch 128: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2109 - accuracy: 0.9113 - val_loss: 0.3312 - val_accuracy: 0.8677\n",
      "Epoch 129/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2200 - accuracy: 0.9137\n",
      "Epoch 129: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2189 - accuracy: 0.9128 - val_loss: 0.3286 - val_accuracy: 0.8723\n",
      "Epoch 130/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1971 - accuracy: 0.9181\n",
      "Epoch 130: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1982 - accuracy: 0.9167 - val_loss: 0.3367 - val_accuracy: 0.8723\n",
      "Epoch 131/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1991 - accuracy: 0.9188\n",
      "Epoch 131: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1991 - accuracy: 0.9188 - val_loss: 0.3236 - val_accuracy: 0.8708\n",
      "Epoch 132/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1938 - accuracy: 0.9210\n",
      "Epoch 132: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1919 - accuracy: 0.9217 - val_loss: 0.3277 - val_accuracy: 0.8708\n",
      "Epoch 133/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1944 - accuracy: 0.9206\n",
      "Epoch 133: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9192 - val_loss: 0.3266 - val_accuracy: 0.8700\n",
      "Epoch 134/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1988 - accuracy: 0.9198\n",
      "Epoch 134: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1979 - accuracy: 0.9196 - val_loss: 0.3434 - val_accuracy: 0.8677\n",
      "Epoch 135/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1148 - accuracy: 0.9516\n",
      "Epoch 135: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1951 - accuracy: 0.9161 - val_loss: 0.3301 - val_accuracy: 0.8646\n",
      "Epoch 136/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2136 - accuracy: 0.9274\n",
      "Epoch 136: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.9173 - val_loss: 0.3382 - val_accuracy: 0.8608\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1299 - accuracy: 0.9597\n",
      "Epoch 137: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2059 - accuracy: 0.9105 - val_loss: 0.3418 - val_accuracy: 0.8700\n",
      "Epoch 138/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1277 - accuracy: 0.9516\n",
      "Epoch 138: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1908 - accuracy: 0.9209 - val_loss: 0.3376 - val_accuracy: 0.8654\n",
      "Epoch 139/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1887 - accuracy: 0.9224\n",
      "Epoch 139: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1881 - accuracy: 0.9221 - val_loss: 0.3451 - val_accuracy: 0.8715\n",
      "Epoch 140/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1930 - accuracy: 0.9219\n",
      "Epoch 140: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.9219 - val_loss: 0.3460 - val_accuracy: 0.8654\n",
      "Epoch 141/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1894 - accuracy: 0.9235\n",
      "Epoch 141: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1857 - accuracy: 0.9257 - val_loss: 0.3381 - val_accuracy: 0.8692\n",
      "Epoch 142/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1754 - accuracy: 0.9194\n",
      "Epoch 142: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1857 - accuracy: 0.9251 - val_loss: 0.3514 - val_accuracy: 0.8685\n",
      "Epoch 143/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1817 - accuracy: 0.9310\n",
      "Epoch 143: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1816 - accuracy: 0.9303 - val_loss: 0.3402 - val_accuracy: 0.8654\n",
      "Epoch 144/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1906 - accuracy: 0.9194\n",
      "Epoch 144: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.9267 - val_loss: 0.3389 - val_accuracy: 0.8646\n",
      "Epoch 145/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1900 - accuracy: 0.9262\n",
      "Epoch 145: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1891 - accuracy: 0.9271 - val_loss: 0.3756 - val_accuracy: 0.8600\n",
      "Epoch 146/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1567 - accuracy: 0.9274\n",
      "Epoch 146: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.9244 - val_loss: 0.3516 - val_accuracy: 0.8654\n",
      "Epoch 147/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2545 - accuracy: 0.8710\n",
      "Epoch 147: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1780 - accuracy: 0.9307 - val_loss: 0.3506 - val_accuracy: 0.8623\n",
      "Epoch 148/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1778 - accuracy: 0.9274\n",
      "Epoch 148: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.9275 - val_loss: 0.3561 - val_accuracy: 0.8592\n",
      "Epoch 149/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1862 - accuracy: 0.9194\n",
      "Epoch 149: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1848 - accuracy: 0.9250 - val_loss: 0.3542 - val_accuracy: 0.8685\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1917 - accuracy: 0.9355\n",
      "Epoch 150: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1812 - accuracy: 0.9307 - val_loss: 0.3693 - val_accuracy: 0.8615\n",
      "Epoch 151/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2170 - accuracy: 0.9093\n",
      "Epoch 151: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2169 - accuracy: 0.9090 - val_loss: 0.3463 - val_accuracy: 0.8723\n",
      "Epoch 152/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1714 - accuracy: 0.9274\n",
      "Epoch 152: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.9225 - val_loss: 0.3461 - val_accuracy: 0.8638\n",
      "Epoch 153/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1566 - accuracy: 0.9516\n",
      "Epoch 153: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1818 - accuracy: 0.9263 - val_loss: 0.3519 - val_accuracy: 0.8585\n",
      "Epoch 154/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1469 - accuracy: 0.9355\n",
      "Epoch 154: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1749 - accuracy: 0.9307 - val_loss: 0.3584 - val_accuracy: 0.8646\n",
      "Epoch 155/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1902 - accuracy: 0.9233\n",
      "Epoch 155: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1895 - accuracy: 0.9234 - val_loss: 0.3546 - val_accuracy: 0.8646\n",
      "Epoch 156/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1660 - accuracy: 0.9355\n",
      "Epoch 156: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.9284 - val_loss: 0.3485 - val_accuracy: 0.8654\n",
      "Epoch 157/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2648 - accuracy: 0.8790\n",
      "Epoch 157: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1761 - accuracy: 0.9298 - val_loss: 0.3533 - val_accuracy: 0.8685\n",
      "Epoch 158/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1449 - accuracy: 0.9355\n",
      "Epoch 158: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1744 - accuracy: 0.9271 - val_loss: 0.3932 - val_accuracy: 0.8654\n",
      "Epoch 159/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1727 - accuracy: 0.9337\n",
      "Epoch 159: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1735 - accuracy: 0.9327 - val_loss: 0.3630 - val_accuracy: 0.8654\n",
      "Epoch 160/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2367 - accuracy: 0.8952\n",
      "Epoch 160: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1799 - accuracy: 0.9255 - val_loss: 0.3744 - val_accuracy: 0.8554\n",
      "Epoch 161/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2178 - accuracy: 0.9032\n",
      "Epoch 161: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.9217 - val_loss: 0.3535 - val_accuracy: 0.8677\n",
      "Epoch 162/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1780 - accuracy: 0.9242\n",
      "Epoch 162: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1746 - accuracy: 0.9259 - val_loss: 0.4002 - val_accuracy: 0.8592\n",
      "Epoch 163/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1709 - accuracy: 0.9315\n",
      "Epoch 163: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1709 - accuracy: 0.9315 - val_loss: 0.3635 - val_accuracy: 0.8646\n",
      "Epoch 164/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1708 - accuracy: 0.9316\n",
      "Epoch 164: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1716 - accuracy: 0.9307 - val_loss: 0.3566 - val_accuracy: 0.8592\n",
      "Epoch 165/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1796 - accuracy: 0.9274\n",
      "Epoch 165: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1690 - accuracy: 0.9319 - val_loss: 0.3742 - val_accuracy: 0.8669\n",
      "Epoch 166/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2015 - accuracy: 0.9194\n",
      "Epoch 166: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1749 - accuracy: 0.9290 - val_loss: 0.3635 - val_accuracy: 0.8538\n",
      "Epoch 167/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1466 - accuracy: 0.9435\n",
      "Epoch 167: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.9278 - val_loss: 0.3624 - val_accuracy: 0.8638\n",
      "Epoch 168/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1700 - accuracy: 0.9317\n",
      "Epoch 168: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1693 - accuracy: 0.9327 - val_loss: 0.3665 - val_accuracy: 0.8615\n",
      "Epoch 169/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1114 - accuracy: 0.9516\n",
      "Epoch 169: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1606 - accuracy: 0.9373 - val_loss: 0.3853 - val_accuracy: 0.8662\n",
      "Epoch 170/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.0701 - accuracy: 0.9758\n",
      "Epoch 170: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1687 - accuracy: 0.9325 - val_loss: 0.3831 - val_accuracy: 0.8677\n",
      "Epoch 171/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1652 - accuracy: 0.9355\n",
      "Epoch 171: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1653 - accuracy: 0.9346 - val_loss: 0.3895 - val_accuracy: 0.8600\n",
      "Epoch 172/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1293 - accuracy: 0.9516\n",
      "Epoch 172: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1710 - accuracy: 0.9294 - val_loss: 0.3981 - val_accuracy: 0.8654\n",
      "Epoch 173/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1257 - accuracy: 0.9435\n",
      "Epoch 173: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1675 - accuracy: 0.9311 - val_loss: 0.3829 - val_accuracy: 0.8623\n",
      "Epoch 174/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1508 - accuracy: 0.9274\n",
      "Epoch 174: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1749 - accuracy: 0.9248 - val_loss: 0.3905 - val_accuracy: 0.8577\n",
      "Epoch 175/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1677 - accuracy: 0.9316\n",
      "Epoch 175: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1688 - accuracy: 0.9305 - val_loss: 0.3897 - val_accuracy: 0.8569\n",
      "Epoch 176/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1551 - accuracy: 0.9424\n",
      "Epoch 176: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1564 - accuracy: 0.9417 - val_loss: 0.3969 - val_accuracy: 0.8623\n",
      "Epoch 177/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1629 - accuracy: 0.9328\n",
      "Epoch 177: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1629 - accuracy: 0.9328 - val_loss: 0.3879 - val_accuracy: 0.8608\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.6352 - accuracy: 0.6585 \n",
      "Epoch 1: val_accuracy improved from -inf to 0.77462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.6352 - accuracy: 0.6585 - val_loss: 0.5055 - val_accuracy: 0.7746\n",
      "Epoch 2/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.4673 - accuracy: 0.7936\n",
      "Epoch 2: val_accuracy improved from 0.77462 to 0.82000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7982 - val_loss: 0.4202 - val_accuracy: 0.8200\n",
      "Epoch 3/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.3966 - accuracy: 0.8337\n",
      "Epoch 3: val_accuracy improved from 0.82000 to 0.83538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8368 - val_loss: 0.3746 - val_accuracy: 0.8354\n",
      "Epoch 4/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4616 - accuracy: 0.8790\n",
      "Epoch 4: val_accuracy improved from 0.83538 to 0.84154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.8482 - val_loss: 0.3620 - val_accuracy: 0.8415\n",
      "Epoch 5/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4421 - accuracy: 0.8226\n",
      "Epoch 5: val_accuracy did not improve from 0.84154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8463 - val_loss: 0.3990 - val_accuracy: 0.8200\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3798 - accuracy: 0.8359\n",
      "Epoch 6: val_accuracy did not improve from 0.84154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3798 - accuracy: 0.8359 - val_loss: 0.3673 - val_accuracy: 0.8415\n",
      "Epoch 7/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.3597 - accuracy: 0.8422\n",
      "Epoch 7: val_accuracy improved from 0.84154 to 0.85231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3542 - accuracy: 0.8459 - val_loss: 0.3399 - val_accuracy: 0.8523\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3434 - accuracy: 0.8568\n",
      "Epoch 8: val_accuracy did not improve from 0.85231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8568 - val_loss: 0.3450 - val_accuracy: 0.8500\n",
      "Epoch 9/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3131 - accuracy: 0.8871\n",
      "Epoch 9: val_accuracy improved from 0.85231 to 0.85769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8655 - val_loss: 0.3379 - val_accuracy: 0.8577\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3190 - accuracy: 0.8717\n",
      "Epoch 10: val_accuracy did not improve from 0.85769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8717 - val_loss: 0.3409 - val_accuracy: 0.8492\n",
      "Epoch 11/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.3509 - accuracy: 0.8451\n",
      "Epoch 11: val_accuracy did not improve from 0.85769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3459 - accuracy: 0.8482 - val_loss: 0.3369 - val_accuracy: 0.8523\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3353 - accuracy: 0.8952\n",
      "Epoch 12: val_accuracy did not improve from 0.85769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8730 - val_loss: 0.3320 - val_accuracy: 0.8538\n",
      "Epoch 13/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3144 - accuracy: 0.8735\n",
      "Epoch 13: val_accuracy did not improve from 0.85769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.8740 - val_loss: 0.3626 - val_accuracy: 0.8385\n",
      "Epoch 14/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.3300 - accuracy: 0.8608\n",
      "Epoch 14: val_accuracy did not improve from 0.85769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8618 - val_loss: 0.3310 - val_accuracy: 0.8538\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2636 - accuracy: 0.8952\n",
      "Epoch 15: val_accuracy did not improve from 0.85769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8749 - val_loss: 0.3301 - val_accuracy: 0.8577\n",
      "Epoch 16/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.3358 - accuracy: 0.8544\n",
      "Epoch 16: val_accuracy did not improve from 0.85769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8588 - val_loss: 0.3575 - val_accuracy: 0.8523\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3665 - accuracy: 0.8387\n",
      "Epoch 17: val_accuracy improved from 0.85769 to 0.86462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.8726 - val_loss: 0.3254 - val_accuracy: 0.8646\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3160 - accuracy: 0.8705\n",
      "Epoch 18: val_accuracy improved from 0.86462 to 0.86538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.8705 - val_loss: 0.3256 - val_accuracy: 0.8654\n",
      "Epoch 19/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3259 - accuracy: 0.8387\n",
      "Epoch 19: val_accuracy did not improve from 0.86538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2999 - accuracy: 0.8788 - val_loss: 0.3567 - val_accuracy: 0.8515\n",
      "Epoch 20/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2553 - accuracy: 0.9032\n",
      "Epoch 20: val_accuracy did not improve from 0.86538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8722 - val_loss: 0.3491 - val_accuracy: 0.8577\n",
      "Epoch 21/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3682 - accuracy: 0.8065\n",
      "Epoch 21: val_accuracy improved from 0.86538 to 0.86769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3161 - accuracy: 0.8661 - val_loss: 0.3245 - val_accuracy: 0.8677\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2989 - accuracy: 0.8753\n",
      "Epoch 22: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2989 - accuracy: 0.8753 - val_loss: 0.3310 - val_accuracy: 0.8662\n",
      "Epoch 23/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2958 - accuracy: 0.8804\n",
      "Epoch 23: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2942 - accuracy: 0.8811 - val_loss: 0.3215 - val_accuracy: 0.8669\n",
      "Epoch 24/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2931 - accuracy: 0.8840\n",
      "Epoch 24: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2931 - accuracy: 0.8838 - val_loss: 0.3405 - val_accuracy: 0.8562\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4009 - accuracy: 0.8387\n",
      "Epoch 25: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3041 - accuracy: 0.8755 - val_loss: 0.3279 - val_accuracy: 0.8677\n",
      "Epoch 26/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2888 - accuracy: 0.8828\n",
      "Epoch 26: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2899 - accuracy: 0.8817 - val_loss: 0.3160 - val_accuracy: 0.8623\n",
      "Epoch 27/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2016 - accuracy: 0.9435\n",
      "Epoch 27: val_accuracy improved from 0.86769 to 0.86923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2939 - accuracy: 0.8795 - val_loss: 0.3184 - val_accuracy: 0.8692\n",
      "Epoch 28/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2864 - accuracy: 0.8856\n",
      "Epoch 28: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2868 - accuracy: 0.8855 - val_loss: 0.3316 - val_accuracy: 0.8577\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2846 - accuracy: 0.8820\n",
      "Epoch 29: val_accuracy improved from 0.86923 to 0.87308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2846 - accuracy: 0.8820 - val_loss: 0.3178 - val_accuracy: 0.8731\n",
      "Epoch 30/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2776 - accuracy: 0.8840\n",
      "Epoch 30: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2827 - accuracy: 0.8813 - val_loss: 0.3095 - val_accuracy: 0.8708\n",
      "Epoch 31/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2829 - accuracy: 0.8819\n",
      "Epoch 31: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2811 - accuracy: 0.8826 - val_loss: 0.3115 - val_accuracy: 0.8700\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2757 - accuracy: 0.8907\n",
      "Epoch 32: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2757 - accuracy: 0.8907 - val_loss: 0.3133 - val_accuracy: 0.8700\n",
      "Epoch 33/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2761 - accuracy: 0.8862\n",
      "Epoch 33: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2747 - accuracy: 0.8861 - val_loss: 0.3139 - val_accuracy: 0.8662\n",
      "Epoch 34/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2783 - accuracy: 0.9032\n",
      "Epoch 34: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2845 - accuracy: 0.8830 - val_loss: 0.3071 - val_accuracy: 0.8700\n",
      "Epoch 35/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1595 - accuracy: 0.9597\n",
      "Epoch 35: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2824 - accuracy: 0.8803 - val_loss: 0.3159 - val_accuracy: 0.8638\n",
      "Epoch 36/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2291 - accuracy: 0.9032\n",
      "Epoch 36: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2744 - accuracy: 0.8913 - val_loss: 0.3181 - val_accuracy: 0.8631\n",
      "Epoch 37/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1837 - accuracy: 0.9113\n",
      "Epoch 37: val_accuracy improved from 0.87308 to 0.87846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2653 - accuracy: 0.8892 - val_loss: 0.3024 - val_accuracy: 0.8785\n",
      "Epoch 38/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2849 - accuracy: 0.8952\n",
      "Epoch 38: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2680 - accuracy: 0.8934 - val_loss: 0.3142 - val_accuracy: 0.8669\n",
      "Epoch 39/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2402 - accuracy: 0.8952\n",
      "Epoch 39: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2752 - accuracy: 0.8822 - val_loss: 0.3456 - val_accuracy: 0.8438\n",
      "Epoch 40/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3495 - accuracy: 0.8952\n",
      "Epoch 40: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2685 - accuracy: 0.8903 - val_loss: 0.3143 - val_accuracy: 0.8638\n",
      "Epoch 41/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2622 - accuracy: 0.8928\n",
      "Epoch 41: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2654 - accuracy: 0.8911 - val_loss: 0.2962 - val_accuracy: 0.8785\n",
      "Epoch 42/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2580 - accuracy: 0.8937\n",
      "Epoch 42: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2582 - accuracy: 0.8938 - val_loss: 0.2944 - val_accuracy: 0.8754\n",
      "Epoch 43/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2435 - accuracy: 0.8710\n",
      "Epoch 43: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.8928 - val_loss: 0.3058 - val_accuracy: 0.8769\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3484 - accuracy: 0.8710\n",
      "Epoch 44: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2628 - accuracy: 0.8940 - val_loss: 0.2969 - val_accuracy: 0.8777\n",
      "Epoch 45/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2553 - accuracy: 0.8966\n",
      "Epoch 45: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2541 - accuracy: 0.8976 - val_loss: 0.2981 - val_accuracy: 0.8731\n",
      "Epoch 46/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2648 - accuracy: 0.8952\n",
      "Epoch 46: val_accuracy improved from 0.87846 to 0.88231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2572 - accuracy: 0.8930 - val_loss: 0.2950 - val_accuracy: 0.8823\n",
      "Epoch 47/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2575 - accuracy: 0.8933\n",
      "Epoch 47: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2582 - accuracy: 0.8934 - val_loss: 0.2984 - val_accuracy: 0.8769\n",
      "Epoch 48/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2629 - accuracy: 0.8941\n",
      "Epoch 48: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2607 - accuracy: 0.8947 - val_loss: 0.2915 - val_accuracy: 0.8808\n",
      "Epoch 49/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2097 - accuracy: 0.9355\n",
      "Epoch 49: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2541 - accuracy: 0.8957 - val_loss: 0.2925 - val_accuracy: 0.8808\n",
      "Epoch 50/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1843 - accuracy: 0.9194\n",
      "Epoch 50: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2530 - accuracy: 0.8955 - val_loss: 0.3517 - val_accuracy: 0.8515\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2626 - accuracy: 0.8924\n",
      "Epoch 51: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 0.8924 - val_loss: 0.3033 - val_accuracy: 0.8723\n",
      "Epoch 52/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2469 - accuracy: 0.9032\n",
      "Epoch 52: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2612 - accuracy: 0.8921 - val_loss: 0.2935 - val_accuracy: 0.8754\n",
      "Epoch 53/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1976 - accuracy: 0.9355\n",
      "Epoch 53: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2435 - accuracy: 0.9011 - val_loss: 0.3007 - val_accuracy: 0.8754\n",
      "Epoch 54/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2239 - accuracy: 0.9113\n",
      "Epoch 54: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8992 - val_loss: 0.3142 - val_accuracy: 0.8700\n",
      "Epoch 55/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2502 - accuracy: 0.8790\n",
      "Epoch 55: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.8997 - val_loss: 0.2954 - val_accuracy: 0.8792\n",
      "Epoch 56/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3435 - accuracy: 0.8548\n",
      "Epoch 56: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2430 - accuracy: 0.9019 - val_loss: 0.2967 - val_accuracy: 0.8815\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3764 - accuracy: 0.8387\n",
      "Epoch 57: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2767 - accuracy: 0.8790 - val_loss: 0.3831 - val_accuracy: 0.8254\n",
      "Epoch 58/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3397 - accuracy: 0.8629\n",
      "Epoch 58: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2611 - accuracy: 0.8926 - val_loss: 0.3038 - val_accuracy: 0.8754\n",
      "Epoch 59/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2617 - accuracy: 0.8871\n",
      "Epoch 59: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.8947 - val_loss: 0.3034 - val_accuracy: 0.8762\n",
      "Epoch 60/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.2454 - accuracy: 0.8975\n",
      "Epoch 60: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2491 - accuracy: 0.8972 - val_loss: 0.2940 - val_accuracy: 0.8823\n",
      "Epoch 61/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2518 - accuracy: 0.8968\n",
      "Epoch 61: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.8972 - val_loss: 0.3102 - val_accuracy: 0.8700\n",
      "Epoch 62/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3344 - accuracy: 0.8710\n",
      "Epoch 62: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.8974 - val_loss: 0.3075 - val_accuracy: 0.8700\n",
      "Epoch 63/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2431 - accuracy: 0.8993\n",
      "Epoch 63: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2435 - accuracy: 0.8984 - val_loss: 0.3046 - val_accuracy: 0.8754\n",
      "Epoch 64/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2246 - accuracy: 0.9032\n",
      "Epoch 64: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8953 - val_loss: 0.2969 - val_accuracy: 0.8738\n",
      "Epoch 65/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1760 - accuracy: 0.9355\n",
      "Epoch 65: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.8942 - val_loss: 0.2948 - val_accuracy: 0.8823\n",
      "Epoch 66/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2464 - accuracy: 0.9032\n",
      "Epoch 66: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2401 - accuracy: 0.9024 - val_loss: 0.3061 - val_accuracy: 0.8815\n",
      "Epoch 67/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2157 - accuracy: 0.9032\n",
      "Epoch 67: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2409 - accuracy: 0.9003 - val_loss: 0.3025 - val_accuracy: 0.8800\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1974 - accuracy: 0.9113\n",
      "Epoch 68: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2367 - accuracy: 0.9021 - val_loss: 0.2950 - val_accuracy: 0.8808\n",
      "Epoch 69/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2567 - accuracy: 0.9032\n",
      "Epoch 69: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2356 - accuracy: 0.9028 - val_loss: 0.3163 - val_accuracy: 0.8777\n",
      "Epoch 70/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2354 - accuracy: 0.9037\n",
      "Epoch 70: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2397 - accuracy: 0.9028 - val_loss: 0.2973 - val_accuracy: 0.8777\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2926 - accuracy: 0.8548\n",
      "Epoch 71: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2414 - accuracy: 0.9007 - val_loss: 0.3303 - val_accuracy: 0.8615\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1908 - accuracy: 0.9194\n",
      "Epoch 72: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.8974 - val_loss: 0.3071 - val_accuracy: 0.8815\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2295 - accuracy: 0.9099\n",
      "Epoch 73: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2295 - accuracy: 0.9099 - val_loss: 0.3006 - val_accuracy: 0.8769\n",
      "Epoch 74/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2825 - accuracy: 0.8790\n",
      "Epoch 74: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2316 - accuracy: 0.9038 - val_loss: 0.3002 - val_accuracy: 0.8823\n",
      "Epoch 75/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2110 - accuracy: 0.9194\n",
      "Epoch 75: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2300 - accuracy: 0.9046 - val_loss: 0.3132 - val_accuracy: 0.8731\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2925 - accuracy: 0.8548\n",
      "Epoch 76: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2303 - accuracy: 0.9028 - val_loss: 0.3071 - val_accuracy: 0.8808\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2746 - accuracy: 0.8952\n",
      "Epoch 77: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2249 - accuracy: 0.9103 - val_loss: 0.3070 - val_accuracy: 0.8746\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2248 - accuracy: 0.9194\n",
      "Epoch 78: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2245 - accuracy: 0.9073 - val_loss: 0.2991 - val_accuracy: 0.8777\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2215 - accuracy: 0.9194\n",
      "Epoch 79: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2186 - accuracy: 0.9126 - val_loss: 0.3028 - val_accuracy: 0.8777\n",
      "Epoch 80/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2297 - accuracy: 0.9032\n",
      "Epoch 80: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2288 - accuracy: 0.9038 - val_loss: 0.3220 - val_accuracy: 0.8746\n",
      "Epoch 81/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2359 - accuracy: 0.9048\n",
      "Epoch 81: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2378 - accuracy: 0.9026 - val_loss: 0.3346 - val_accuracy: 0.8631\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2558 - accuracy: 0.8888\n",
      "Epoch 82: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2558 - accuracy: 0.8888 - val_loss: 0.3054 - val_accuracy: 0.8738\n",
      "Epoch 83/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2260 - accuracy: 0.9064\n",
      "Epoch 83: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2255 - accuracy: 0.9067 - val_loss: 0.3074 - val_accuracy: 0.8738\n",
      "Epoch 84/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2244 - accuracy: 0.9117\n",
      "Epoch 84: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2258 - accuracy: 0.9101 - val_loss: 0.3127 - val_accuracy: 0.8738\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1737 - accuracy: 0.9516\n",
      "Epoch 85: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2254 - accuracy: 0.9076 - val_loss: 0.3117 - val_accuracy: 0.8738\n",
      "Epoch 86/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2304 - accuracy: 0.9015\n",
      "Epoch 86: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2287 - accuracy: 0.9024 - val_loss: 0.3285 - val_accuracy: 0.8746\n",
      "Epoch 87/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1711 - accuracy: 0.9355\n",
      "Epoch 87: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2207 - accuracy: 0.9109 - val_loss: 0.2970 - val_accuracy: 0.8723\n",
      "Epoch 88/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2225 - accuracy: 0.9073\n",
      "Epoch 88: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 0.9073 - val_loss: 0.3065 - val_accuracy: 0.8738\n",
      "Epoch 89/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2139 - accuracy: 0.9140\n",
      "Epoch 89: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2139 - accuracy: 0.9140 - val_loss: 0.3195 - val_accuracy: 0.8708\n",
      "Epoch 90/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2505 - accuracy: 0.8968\n",
      "Epoch 90: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.8976 - val_loss: 0.3291 - val_accuracy: 0.8777\n",
      "Epoch 91/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2214 - accuracy: 0.9058\n",
      "Epoch 91: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2264 - accuracy: 0.9044 - val_loss: 0.3100 - val_accuracy: 0.8800\n",
      "Epoch 92/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2198 - accuracy: 0.9083\n",
      "Epoch 92: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2172 - accuracy: 0.9094 - val_loss: 0.3155 - val_accuracy: 0.8777\n",
      "Epoch 93/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1570 - accuracy: 0.9435\n",
      "Epoch 93: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2140 - accuracy: 0.9140 - val_loss: 0.3145 - val_accuracy: 0.8777\n",
      "Epoch 94/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2010 - accuracy: 0.9274\n",
      "Epoch 94: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.9090 - val_loss: 0.3209 - val_accuracy: 0.8700\n",
      "Epoch 95/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2439 - accuracy: 0.8871\n",
      "Epoch 95: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2204 - accuracy: 0.9078 - val_loss: 0.3071 - val_accuracy: 0.8738\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1644 - accuracy: 0.9194\n",
      "Epoch 96: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2112 - accuracy: 0.9151 - val_loss: 0.3236 - val_accuracy: 0.8685\n",
      "Epoch 97/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1933 - accuracy: 0.9194\n",
      "Epoch 97: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2128 - accuracy: 0.9109 - val_loss: 0.3260 - val_accuracy: 0.8762\n",
      "Epoch 98/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1955 - accuracy: 0.9113\n",
      "Epoch 98: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2119 - accuracy: 0.9151 - val_loss: 0.3289 - val_accuracy: 0.8762\n",
      "Epoch 99/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2154 - accuracy: 0.9032\n",
      "Epoch 99: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2189 - accuracy: 0.9098 - val_loss: 0.3122 - val_accuracy: 0.8777\n",
      "Epoch 100/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1634 - accuracy: 0.9355\n",
      "Epoch 100: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2081 - accuracy: 0.9175 - val_loss: 0.3106 - val_accuracy: 0.8746\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2236 - accuracy: 0.8952\n",
      "Epoch 101: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2182 - accuracy: 0.9119 - val_loss: 0.3283 - val_accuracy: 0.8685\n",
      "Epoch 102/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2296 - accuracy: 0.8952\n",
      "Epoch 102: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2148 - accuracy: 0.9121 - val_loss: 0.3328 - val_accuracy: 0.8708\n",
      "Epoch 103/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2596 - accuracy: 0.8952\n",
      "Epoch 103: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.9165 - val_loss: 0.3227 - val_accuracy: 0.8762\n",
      "Epoch 104/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2285 - accuracy: 0.9032\n",
      "Epoch 104: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2111 - accuracy: 0.9123 - val_loss: 0.3169 - val_accuracy: 0.8800\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1805 - accuracy: 0.9355\n",
      "Epoch 105: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2320 - accuracy: 0.8978 - val_loss: 0.3108 - val_accuracy: 0.8754\n",
      "Epoch 106/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2014 - accuracy: 0.9435\n",
      "Epoch 106: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2014 - accuracy: 0.9184 - val_loss: 0.3322 - val_accuracy: 0.8731\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2319 - accuracy: 0.9435\n",
      "Epoch 107: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2012 - accuracy: 0.9203 - val_loss: 0.3136 - val_accuracy: 0.8723\n",
      "Epoch 108/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2273 - accuracy: 0.8871\n",
      "Epoch 108: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2091 - accuracy: 0.9123 - val_loss: 0.3371 - val_accuracy: 0.8746\n",
      "Epoch 109/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1675 - accuracy: 0.9274\n",
      "Epoch 109: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2026 - accuracy: 0.9188 - val_loss: 0.3349 - val_accuracy: 0.8692\n",
      "Epoch 110/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1323 - accuracy: 0.9516\n",
      "Epoch 110: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1982 - accuracy: 0.9228 - val_loss: 0.3312 - val_accuracy: 0.8700\n",
      "Epoch 111/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2106 - accuracy: 0.9163\n",
      "Epoch 111: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2061 - accuracy: 0.9190 - val_loss: 0.3161 - val_accuracy: 0.8762\n",
      "Epoch 112/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1853 - accuracy: 0.9355\n",
      "Epoch 112: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2094 - accuracy: 0.9123 - val_loss: 0.3291 - val_accuracy: 0.8700\n",
      "Epoch 113/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1668 - accuracy: 0.9194\n",
      "Epoch 113: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2280 - accuracy: 0.9049 - val_loss: 0.3767 - val_accuracy: 0.8708\n",
      "Epoch 114/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1915 - accuracy: 0.9194\n",
      "Epoch 114: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2012 - accuracy: 0.9180 - val_loss: 0.3517 - val_accuracy: 0.8708\n",
      "Epoch 115/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1859 - accuracy: 0.9113\n",
      "Epoch 115: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2049 - accuracy: 0.9153 - val_loss: 0.3179 - val_accuracy: 0.8800\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1894 - accuracy: 0.9274\n",
      "Epoch 116: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2045 - accuracy: 0.9209 - val_loss: 0.3462 - val_accuracy: 0.8738\n",
      "Epoch 117/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2346 - accuracy: 0.9113\n",
      "Epoch 117: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2010 - accuracy: 0.9192 - val_loss: 0.3240 - val_accuracy: 0.8708\n",
      "Epoch 118/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2053 - accuracy: 0.9144\n",
      "Epoch 118: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2053 - accuracy: 0.9144 - val_loss: 0.3171 - val_accuracy: 0.8792\n",
      "Epoch 119/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1891 - accuracy: 0.9220\n",
      "Epoch 119: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1935 - accuracy: 0.9207 - val_loss: 0.3312 - val_accuracy: 0.8746\n",
      "Epoch 120/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1942 - accuracy: 0.9032\n",
      "Epoch 120: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1933 - accuracy: 0.9207 - val_loss: 0.3459 - val_accuracy: 0.8662\n",
      "Epoch 121/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1968 - accuracy: 0.9187\n",
      "Epoch 121: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1965 - accuracy: 0.9192 - val_loss: 0.3218 - val_accuracy: 0.8700\n",
      "Epoch 122/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1882 - accuracy: 0.9113\n",
      "Epoch 122: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1962 - accuracy: 0.9209 - val_loss: 0.3237 - val_accuracy: 0.8754\n",
      "Epoch 123/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1922 - accuracy: 0.9234\n",
      "Epoch 123: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1922 - accuracy: 0.9234 - val_loss: 0.3452 - val_accuracy: 0.8677\n",
      "Epoch 124/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2185 - accuracy: 0.9113\n",
      "Epoch 124: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1974 - accuracy: 0.9198 - val_loss: 0.3672 - val_accuracy: 0.8746\n",
      "Epoch 125/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1446 - accuracy: 0.9355\n",
      "Epoch 125: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1920 - accuracy: 0.9226 - val_loss: 0.3213 - val_accuracy: 0.8723\n",
      "Epoch 126/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1845 - accuracy: 0.9274\n",
      "Epoch 126: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1885 - accuracy: 0.9259 - val_loss: 0.3317 - val_accuracy: 0.8731\n",
      "Epoch 127/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1855 - accuracy: 0.9194\n",
      "Epoch 127: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.9248 - val_loss: 0.3321 - val_accuracy: 0.8715\n",
      "Epoch 128/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1984 - accuracy: 0.9194\n",
      "Epoch 128: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9273 - val_loss: 0.3623 - val_accuracy: 0.8715\n",
      "Epoch 129/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2691 - accuracy: 0.9032\n",
      "Epoch 129: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2102 - accuracy: 0.9094 - val_loss: 0.3729 - val_accuracy: 0.8662\n",
      "Epoch 130/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2038 - accuracy: 0.9171\n",
      "Epoch 130: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2038 - accuracy: 0.9171 - val_loss: 0.3649 - val_accuracy: 0.8692\n",
      "Epoch 131/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2600 - accuracy: 0.8790\n",
      "Epoch 131: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.9234 - val_loss: 0.3350 - val_accuracy: 0.8715\n",
      "Epoch 132/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2265 - accuracy: 0.9355\n",
      "Epoch 132: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.9280 - val_loss: 0.3390 - val_accuracy: 0.8769\n",
      "Epoch 133/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1892 - accuracy: 0.9227\n",
      "Epoch 133: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1898 - accuracy: 0.9221 - val_loss: 0.3450 - val_accuracy: 0.8677\n",
      "Epoch 134/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2498 - accuracy: 0.9032\n",
      "Epoch 134: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.9294 - val_loss: 0.3715 - val_accuracy: 0.8638\n",
      "Epoch 135/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1445 - accuracy: 0.9274\n",
      "Epoch 135: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.9228 - val_loss: 0.3346 - val_accuracy: 0.8662\n",
      "Epoch 136/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1903 - accuracy: 0.9032\n",
      "Epoch 136: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1831 - accuracy: 0.9288 - val_loss: 0.3369 - val_accuracy: 0.8708\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2052 - accuracy: 0.9355\n",
      "Epoch 137: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.9303 - val_loss: 0.3369 - val_accuracy: 0.8769\n",
      "Epoch 138/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1776 - accuracy: 0.9032\n",
      "Epoch 138: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1898 - accuracy: 0.9244 - val_loss: 0.3623 - val_accuracy: 0.8592\n",
      "Epoch 139/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1814 - accuracy: 0.9194\n",
      "Epoch 139: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.9251 - val_loss: 0.3774 - val_accuracy: 0.8508\n",
      "Epoch 140/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2617 - accuracy: 0.8871\n",
      "Epoch 140: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.9163 - val_loss: 0.3423 - val_accuracy: 0.8754\n",
      "Epoch 141/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1818 - accuracy: 0.9288\n",
      "Epoch 141: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.9286 - val_loss: 0.3645 - val_accuracy: 0.8769\n",
      "Epoch 142/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1733 - accuracy: 0.9194\n",
      "Epoch 142: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1794 - accuracy: 0.9269 - val_loss: 0.3795 - val_accuracy: 0.8615\n",
      "Epoch 143/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2115 - accuracy: 0.9194\n",
      "Epoch 143: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1761 - accuracy: 0.9298 - val_loss: 0.3599 - val_accuracy: 0.8700\n",
      "Epoch 144/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1782 - accuracy: 0.9278\n",
      "Epoch 144: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1782 - accuracy: 0.9278 - val_loss: 0.3510 - val_accuracy: 0.8731\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1542 - accuracy: 0.9355\n",
      "Epoch 145: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1705 - accuracy: 0.9353 - val_loss: 0.3631 - val_accuracy: 0.8800\n",
      "Epoch 146/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1538 - accuracy: 0.9435\n",
      "Epoch 146: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1700 - accuracy: 0.9340 - val_loss: 0.3390 - val_accuracy: 0.8723\n",
      "Epoch 147/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1465 - accuracy: 0.9355\n",
      "Epoch 147: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.9296 - val_loss: 0.3806 - val_accuracy: 0.8700\n",
      "Epoch 148/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2653 - accuracy: 0.9032\n",
      "Epoch 148: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1775 - accuracy: 0.9296 - val_loss: 0.3673 - val_accuracy: 0.8638\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Epoch 1/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.8254 - accuracy: 0.6131 \n",
      "Epoch 1: val_accuracy improved from -inf to 0.75385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 6ms/step - loss: 0.8062 - accuracy: 0.6198 - val_loss: 0.5292 - val_accuracy: 0.7538\n",
      "Epoch 2/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.5164 - accuracy: 0.8065\n",
      "Epoch 2: val_accuracy improved from 0.75385 to 0.80846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7853 - val_loss: 0.4483 - val_accuracy: 0.8085\n",
      "Epoch 3/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.4323 - accuracy: 0.8185\n",
      "Epoch 3: val_accuracy improved from 0.80846 to 0.82538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.8211 - val_loss: 0.4052 - val_accuracy: 0.8254\n",
      "Epoch 4/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3931 - accuracy: 0.8362\n",
      "Epoch 4: val_accuracy improved from 0.82538 to 0.83923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3912 - accuracy: 0.8378 - val_loss: 0.3797 - val_accuracy: 0.8392\n",
      "Epoch 5/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4306 - accuracy: 0.8387\n",
      "Epoch 5: val_accuracy did not improve from 0.83923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8397 - val_loss: 0.3720 - val_accuracy: 0.8346\n",
      "Epoch 6/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4209 - accuracy: 0.8065\n",
      "Epoch 6: val_accuracy improved from 0.83923 to 0.85462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8478 - val_loss: 0.3465 - val_accuracy: 0.8546\n",
      "Epoch 7/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3043 - accuracy: 0.8871\n",
      "Epoch 7: val_accuracy did not improve from 0.85462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3486 - accuracy: 0.8582 - val_loss: 0.3667 - val_accuracy: 0.8423\n",
      "Epoch 8/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4311 - accuracy: 0.8145\n",
      "Epoch 8: val_accuracy improved from 0.85462 to 0.86000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8668 - val_loss: 0.3427 - val_accuracy: 0.8600\n",
      "Epoch 9/1000\n",
      "28/42 [===================>..........] - ETA: 0s - loss: 0.3291 - accuracy: 0.8684\n",
      "Epoch 9: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8634 - val_loss: 0.3355 - val_accuracy: 0.8538\n",
      "Epoch 10/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.3239 - accuracy: 0.8659\n",
      "Epoch 10: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8668 - val_loss: 0.3368 - val_accuracy: 0.8585\n",
      "Epoch 11/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3794 - accuracy: 0.8065\n",
      "Epoch 11: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8642 - val_loss: 0.3594 - val_accuracy: 0.8492\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3071 - accuracy: 0.8871\n",
      "Epoch 12: val_accuracy improved from 0.86000 to 0.86077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8618 - val_loss: 0.3361 - val_accuracy: 0.8608\n",
      "Epoch 13/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3264 - accuracy: 0.8641\n",
      "Epoch 13: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8638 - val_loss: 0.3383 - val_accuracy: 0.8538\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3238 - accuracy: 0.8790\n",
      "Epoch 14: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8595 - val_loss: 0.3354 - val_accuracy: 0.8608\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2921 - accuracy: 0.8871\n",
      "Epoch 15: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8628 - val_loss: 0.3424 - val_accuracy: 0.8569\n",
      "Epoch 16/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2891 - accuracy: 0.8710\n",
      "Epoch 16: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3164 - accuracy: 0.8720 - val_loss: 0.3285 - val_accuracy: 0.8608\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4644 - accuracy: 0.7742\n",
      "Epoch 17: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8628 - val_loss: 0.3270 - val_accuracy: 0.8592\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3368 - accuracy: 0.8548\n",
      "Epoch 18: val_accuracy improved from 0.86077 to 0.86462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8717 - val_loss: 0.3280 - val_accuracy: 0.8646\n",
      "Epoch 19/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2961 - accuracy: 0.8710\n",
      "Epoch 19: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8740 - val_loss: 0.3339 - val_accuracy: 0.8554\n",
      "Epoch 20/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2259 - accuracy: 0.9194\n",
      "Epoch 20: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.8709 - val_loss: 0.3381 - val_accuracy: 0.8477\n",
      "Epoch 21/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3017 - accuracy: 0.8790\n",
      "Epoch 21: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8720 - val_loss: 0.3409 - val_accuracy: 0.8469\n",
      "Epoch 22/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.3056 - accuracy: 0.8703\n",
      "Epoch 22: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8722 - val_loss: 0.3281 - val_accuracy: 0.8623\n",
      "Epoch 23/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2621 - accuracy: 0.9032\n",
      "Epoch 23: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8717 - val_loss: 0.3281 - val_accuracy: 0.8600\n",
      "Epoch 24/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2920 - accuracy: 0.8952\n",
      "Epoch 24: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8686 - val_loss: 0.3286 - val_accuracy: 0.8554\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3336 - accuracy: 0.8871\n",
      "Epoch 25: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3006 - accuracy: 0.8782 - val_loss: 0.3280 - val_accuracy: 0.8631\n",
      "Epoch 26/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2586 - accuracy: 0.8790\n",
      "Epoch 26: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3006 - accuracy: 0.8755 - val_loss: 0.3313 - val_accuracy: 0.8646\n",
      "Epoch 27/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2745 - accuracy: 0.8710\n",
      "Epoch 27: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3026 - accuracy: 0.8765 - val_loss: 0.3232 - val_accuracy: 0.8554\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3338 - accuracy: 0.8387\n",
      "Epoch 28: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2948 - accuracy: 0.8780 - val_loss: 0.3283 - val_accuracy: 0.8546\n",
      "Epoch 29/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2881 - accuracy: 0.8820\n",
      "Epoch 29: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2901 - accuracy: 0.8805 - val_loss: 0.3188 - val_accuracy: 0.8638\n",
      "Epoch 30/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2918 - accuracy: 0.8710\n",
      "Epoch 30: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2957 - accuracy: 0.8732 - val_loss: 0.3210 - val_accuracy: 0.8623\n",
      "Epoch 31/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2634 - accuracy: 0.8952\n",
      "Epoch 31: val_accuracy improved from 0.86462 to 0.86538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2862 - accuracy: 0.8834 - val_loss: 0.3183 - val_accuracy: 0.8654\n",
      "Epoch 32/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1800 - accuracy: 0.9435\n",
      "Epoch 32: val_accuracy did not improve from 0.86538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2889 - accuracy: 0.8794 - val_loss: 0.3284 - val_accuracy: 0.8600\n",
      "Epoch 33/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2925 - accuracy: 0.8764\n",
      "Epoch 33: val_accuracy did not improve from 0.86538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2905 - accuracy: 0.8786 - val_loss: 0.3183 - val_accuracy: 0.8638\n",
      "Epoch 34/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2841 - accuracy: 0.8813\n",
      "Epoch 34: val_accuracy improved from 0.86538 to 0.86615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2829 - accuracy: 0.8826 - val_loss: 0.3137 - val_accuracy: 0.8662\n",
      "Epoch 35/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2872 - accuracy: 0.8810\n",
      "Epoch 35: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2848 - accuracy: 0.8819 - val_loss: 0.3644 - val_accuracy: 0.8438\n",
      "Epoch 36/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2932 - accuracy: 0.8786\n",
      "Epoch 36: val_accuracy improved from 0.86615 to 0.86692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2907 - accuracy: 0.8795 - val_loss: 0.3114 - val_accuracy: 0.8669\n",
      "Epoch 37/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2750 - accuracy: 0.8710\n",
      "Epoch 37: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2721 - accuracy: 0.8901 - val_loss: 0.3208 - val_accuracy: 0.8646\n",
      "Epoch 38/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2975 - accuracy: 0.8710\n",
      "Epoch 38: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2733 - accuracy: 0.8890 - val_loss: 0.3371 - val_accuracy: 0.8515\n",
      "Epoch 39/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2595 - accuracy: 0.8710\n",
      "Epoch 39: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2812 - accuracy: 0.8871 - val_loss: 0.3133 - val_accuracy: 0.8631\n",
      "Epoch 40/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2756 - accuracy: 0.8845\n",
      "Epoch 40: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2799 - accuracy: 0.8830 - val_loss: 0.3706 - val_accuracy: 0.8338\n",
      "Epoch 41/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3456 - accuracy: 0.8306\n",
      "Epoch 41: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2956 - accuracy: 0.8715 - val_loss: 0.3124 - val_accuracy: 0.8662\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2630 - accuracy: 0.8952\n",
      "Epoch 42: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2760 - accuracy: 0.8871 - val_loss: 0.3203 - val_accuracy: 0.8638\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2687 - accuracy: 0.8892\n",
      "Epoch 43: val_accuracy improved from 0.86692 to 0.87769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2687 - accuracy: 0.8892 - val_loss: 0.3062 - val_accuracy: 0.8777\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2551 - accuracy: 0.8790\n",
      "Epoch 44: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2651 - accuracy: 0.8919 - val_loss: 0.3091 - val_accuracy: 0.8662\n",
      "Epoch 45/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2327 - accuracy: 0.9113\n",
      "Epoch 45: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2816 - accuracy: 0.8782 - val_loss: 0.3268 - val_accuracy: 0.8546\n",
      "Epoch 46/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3671 - accuracy: 0.8548\n",
      "Epoch 46: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2803 - accuracy: 0.8809 - val_loss: 0.3025 - val_accuracy: 0.8685\n",
      "Epoch 47/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2792 - accuracy: 0.8830\n",
      "Epoch 47: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2790 - accuracy: 0.8824 - val_loss: 0.3267 - val_accuracy: 0.8654\n",
      "Epoch 48/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3304 - accuracy: 0.8710\n",
      "Epoch 48: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2730 - accuracy: 0.8871 - val_loss: 0.3018 - val_accuracy: 0.8723\n",
      "Epoch 49/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3215 - accuracy: 0.8871\n",
      "Epoch 49: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2681 - accuracy: 0.8878 - val_loss: 0.3001 - val_accuracy: 0.8731\n",
      "Epoch 50/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2201 - accuracy: 0.9194\n",
      "Epoch 50: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2612 - accuracy: 0.8921 - val_loss: 0.3114 - val_accuracy: 0.8669\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3476 - accuracy: 0.8548\n",
      "Epoch 51: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2651 - accuracy: 0.8917 - val_loss: 0.3513 - val_accuracy: 0.8546\n",
      "Epoch 52/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.5094 - accuracy: 0.7903\n",
      "Epoch 52: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.8886 - val_loss: 0.3027 - val_accuracy: 0.8762\n",
      "Epoch 53/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2645 - accuracy: 0.8871\n",
      "Epoch 53: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2666 - accuracy: 0.8903 - val_loss: 0.3224 - val_accuracy: 0.8685\n",
      "Epoch 54/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3103 - accuracy: 0.8629\n",
      "Epoch 54: val_accuracy improved from 0.87769 to 0.88308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2653 - accuracy: 0.8917 - val_loss: 0.3115 - val_accuracy: 0.8831\n",
      "Epoch 55/1000\n",
      "26/42 [=================>............] - ETA: 0s - loss: 0.2698 - accuracy: 0.8868\n",
      "Epoch 55: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2597 - accuracy: 0.8896 - val_loss: 0.3032 - val_accuracy: 0.8762\n",
      "Epoch 56/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2676 - accuracy: 0.8861\n",
      "Epoch 56: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2689 - accuracy: 0.8863 - val_loss: 0.3016 - val_accuracy: 0.8754\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3323 - accuracy: 0.8952\n",
      "Epoch 57: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2546 - accuracy: 0.8938 - val_loss: 0.3024 - val_accuracy: 0.8738\n",
      "Epoch 58/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2409 - accuracy: 0.8629\n",
      "Epoch 58: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2562 - accuracy: 0.8942 - val_loss: 0.3017 - val_accuracy: 0.8746\n",
      "Epoch 59/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1790 - accuracy: 0.9355\n",
      "Epoch 59: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.8988 - val_loss: 0.2969 - val_accuracy: 0.8746\n",
      "Epoch 60/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2183 - accuracy: 0.9032\n",
      "Epoch 60: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.8984 - val_loss: 0.2959 - val_accuracy: 0.8746\n",
      "Epoch 61/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2350 - accuracy: 0.9032\n",
      "Epoch 61: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 0.8940 - val_loss: 0.3081 - val_accuracy: 0.8754\n",
      "Epoch 62/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2487 - accuracy: 0.9007\n",
      "Epoch 62: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.9007 - val_loss: 0.3049 - val_accuracy: 0.8815\n",
      "Epoch 63/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2493 - accuracy: 0.8952\n",
      "Epoch 63: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.8982 - val_loss: 0.3239 - val_accuracy: 0.8692\n",
      "Epoch 64/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2242 - accuracy: 0.9355\n",
      "Epoch 64: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2559 - accuracy: 0.8965 - val_loss: 0.2995 - val_accuracy: 0.8785\n",
      "Epoch 65/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2039 - accuracy: 0.9194\n",
      "Epoch 65: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.8984 - val_loss: 0.3416 - val_accuracy: 0.8523\n",
      "Epoch 66/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2557 - accuracy: 0.9032\n",
      "Epoch 66: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.8953 - val_loss: 0.3026 - val_accuracy: 0.8792\n",
      "Epoch 67/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2445 - accuracy: 0.9004\n",
      "Epoch 67: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2436 - accuracy: 0.9011 - val_loss: 0.3143 - val_accuracy: 0.8746\n",
      "Epoch 68/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2454 - accuracy: 0.8980\n",
      "Epoch 68: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8986 - val_loss: 0.3042 - val_accuracy: 0.8731\n",
      "Epoch 69/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2674 - accuracy: 0.8832\n",
      "Epoch 69: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2673 - accuracy: 0.8836 - val_loss: 0.3020 - val_accuracy: 0.8823\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3204 - accuracy: 0.8548\n",
      "Epoch 70: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2481 - accuracy: 0.8994 - val_loss: 0.2958 - val_accuracy: 0.8731\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2492 - accuracy: 0.8980\n",
      "Epoch 71: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.8980 - val_loss: 0.2995 - val_accuracy: 0.8831\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1687 - accuracy: 0.9274\n",
      "Epoch 72: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2427 - accuracy: 0.8974 - val_loss: 0.2933 - val_accuracy: 0.8777\n",
      "Epoch 73/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2402 - accuracy: 0.8999\n",
      "Epoch 73: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2402 - accuracy: 0.8996 - val_loss: 0.3166 - val_accuracy: 0.8754\n",
      "Epoch 74/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2867 - accuracy: 0.8871\n",
      "Epoch 74: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2382 - accuracy: 0.9005 - val_loss: 0.3051 - val_accuracy: 0.8723\n",
      "Epoch 75/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1933 - accuracy: 0.9355\n",
      "Epoch 75: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2397 - accuracy: 0.8971 - val_loss: 0.2989 - val_accuracy: 0.8769\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2973 - accuracy: 0.8790\n",
      "Epoch 76: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 0.9028 - val_loss: 0.3034 - val_accuracy: 0.8769\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1530 - accuracy: 0.9435\n",
      "Epoch 77: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.8980 - val_loss: 0.3056 - val_accuracy: 0.8777\n",
      "Epoch 78/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2430 - accuracy: 0.8974\n",
      "Epoch 78: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2430 - accuracy: 0.8974 - val_loss: 0.3027 - val_accuracy: 0.8700\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2310 - accuracy: 0.8548\n",
      "Epoch 79: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.8980 - val_loss: 0.3078 - val_accuracy: 0.8754\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2778 - accuracy: 0.8952\n",
      "Epoch 80: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2306 - accuracy: 0.9059 - val_loss: 0.3242 - val_accuracy: 0.8662\n",
      "Epoch 81/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2596 - accuracy: 0.8875\n",
      "Epoch 81: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2582 - accuracy: 0.8888 - val_loss: 0.3033 - val_accuracy: 0.8800\n",
      "Epoch 82/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2448 - accuracy: 0.8710\n",
      "Epoch 82: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2321 - accuracy: 0.9048 - val_loss: 0.3003 - val_accuracy: 0.8777\n",
      "Epoch 83/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2340 - accuracy: 0.9010\n",
      "Epoch 83: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2323 - accuracy: 0.9015 - val_loss: 0.3015 - val_accuracy: 0.8762\n",
      "Epoch 84/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2176 - accuracy: 0.9032\n",
      "Epoch 84: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2262 - accuracy: 0.9074 - val_loss: 0.3036 - val_accuracy: 0.8777\n",
      "Epoch 85/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2257 - accuracy: 0.9057\n",
      "Epoch 85: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2257 - accuracy: 0.9057 - val_loss: 0.3083 - val_accuracy: 0.8754\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1645 - accuracy: 0.9435\n",
      "Epoch 86: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.9082 - val_loss: 0.3169 - val_accuracy: 0.8769\n",
      "Epoch 87/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3112 - accuracy: 0.8710\n",
      "Epoch 87: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2274 - accuracy: 0.9051 - val_loss: 0.3215 - val_accuracy: 0.8800\n",
      "Epoch 88/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3248 - accuracy: 0.8629\n",
      "Epoch 88: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2417 - accuracy: 0.8986 - val_loss: 0.3054 - val_accuracy: 0.8792\n",
      "Epoch 89/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1636 - accuracy: 0.9355\n",
      "Epoch 89: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2620 - accuracy: 0.8849 - val_loss: 0.2970 - val_accuracy: 0.8769\n",
      "Epoch 90/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2111 - accuracy: 0.9194\n",
      "Epoch 90: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2307 - accuracy: 0.9082 - val_loss: 0.3178 - val_accuracy: 0.8731\n",
      "Epoch 91/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1668 - accuracy: 0.9516\n",
      "Epoch 91: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2252 - accuracy: 0.9088 - val_loss: 0.3521 - val_accuracy: 0.8615\n",
      "Epoch 92/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2831 - accuracy: 0.8548\n",
      "Epoch 92: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2270 - accuracy: 0.9051 - val_loss: 0.3007 - val_accuracy: 0.8762\n",
      "Epoch 93/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1629 - accuracy: 0.9274\n",
      "Epoch 93: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.9071 - val_loss: 0.3005 - val_accuracy: 0.8754\n",
      "Epoch 94/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2293 - accuracy: 0.9082\n",
      "Epoch 94: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2294 - accuracy: 0.9073 - val_loss: 0.3189 - val_accuracy: 0.8685\n",
      "Epoch 95/1000\n",
      "27/42 [==================>...........] - ETA: 0s - loss: 0.2460 - accuracy: 0.8961\n",
      "Epoch 95: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2398 - accuracy: 0.8992 - val_loss: 0.3091 - val_accuracy: 0.8669\n",
      "Epoch 96/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2256 - accuracy: 0.9088\n",
      "Epoch 96: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2256 - accuracy: 0.9092 - val_loss: 0.2988 - val_accuracy: 0.8769\n",
      "Epoch 97/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2356 - accuracy: 0.9113\n",
      "Epoch 97: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 0.9078 - val_loss: 0.3017 - val_accuracy: 0.8754\n",
      "Epoch 98/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1408 - accuracy: 0.9435\n",
      "Epoch 98: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2307 - accuracy: 0.9065 - val_loss: 0.3569 - val_accuracy: 0.8662\n",
      "Epoch 99/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2299 - accuracy: 0.9061\n",
      "Epoch 99: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.9078 - val_loss: 0.3208 - val_accuracy: 0.8800\n",
      "Epoch 100/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1781 - accuracy: 0.9274\n",
      "Epoch 100: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 0.9124 - val_loss: 0.3240 - val_accuracy: 0.8715\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2786 - accuracy: 0.8790\n",
      "Epoch 101: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2184 - accuracy: 0.9113 - val_loss: 0.3208 - val_accuracy: 0.8708\n",
      "Epoch 102/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2216 - accuracy: 0.9096\n",
      "Epoch 102: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2218 - accuracy: 0.9092 - val_loss: 0.3076 - val_accuracy: 0.8746\n",
      "Epoch 103/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1529 - accuracy: 0.9194\n",
      "Epoch 103: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2343 - accuracy: 0.9013 - val_loss: 0.3193 - val_accuracy: 0.8792\n",
      "Epoch 104/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2298 - accuracy: 0.9113\n",
      "Epoch 104: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2194 - accuracy: 0.9107 - val_loss: 0.3117 - val_accuracy: 0.8738\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2112 - accuracy: 0.8952\n",
      "Epoch 105: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2228 - accuracy: 0.9061 - val_loss: 0.3217 - val_accuracy: 0.8769\n",
      "Epoch 106/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2651 - accuracy: 0.8710\n",
      "Epoch 106: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2205 - accuracy: 0.9067 - val_loss: 0.3216 - val_accuracy: 0.8777\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2237 - accuracy: 0.9113\n",
      "Epoch 107: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2276 - accuracy: 0.9057 - val_loss: 0.3775 - val_accuracy: 0.8508\n",
      "Epoch 108/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2216 - accuracy: 0.9085\n",
      "Epoch 108: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2189 - accuracy: 0.9101 - val_loss: 0.3319 - val_accuracy: 0.8685\n",
      "Epoch 109/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2240 - accuracy: 0.9087\n",
      "Epoch 109: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2228 - accuracy: 0.9090 - val_loss: 0.3265 - val_accuracy: 0.8723\n",
      "Epoch 110/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2143 - accuracy: 0.8952\n",
      "Epoch 110: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2069 - accuracy: 0.9159 - val_loss: 0.3186 - val_accuracy: 0.8777\n",
      "Epoch 111/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2128 - accuracy: 0.9121\n",
      "Epoch 111: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2128 - accuracy: 0.9121 - val_loss: 0.3171 - val_accuracy: 0.8769\n",
      "Epoch 112/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2706 - accuracy: 0.8710\n",
      "Epoch 112: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2253 - accuracy: 0.9048 - val_loss: 0.3230 - val_accuracy: 0.8731\n",
      "Epoch 113/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1520 - accuracy: 0.9435\n",
      "Epoch 113: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2116 - accuracy: 0.9146 - val_loss: 0.3180 - val_accuracy: 0.8762\n",
      "Epoch 114/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2265 - accuracy: 0.9038\n",
      "Epoch 114: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2270 - accuracy: 0.9036 - val_loss: 0.3258 - val_accuracy: 0.8700\n",
      "Epoch 115/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2058 - accuracy: 0.9166\n",
      "Epoch 115: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2080 - accuracy: 0.9151 - val_loss: 0.3162 - val_accuracy: 0.8769\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1896 - accuracy: 0.9194\n",
      "Epoch 116: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2143 - accuracy: 0.9117 - val_loss: 0.3277 - val_accuracy: 0.8662\n",
      "Epoch 117/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2090 - accuracy: 0.9136\n",
      "Epoch 117: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2090 - accuracy: 0.9136 - val_loss: 0.3179 - val_accuracy: 0.8731\n",
      "Epoch 118/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2038 - accuracy: 0.9188\n",
      "Epoch 118: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2039 - accuracy: 0.9188 - val_loss: 0.3222 - val_accuracy: 0.8769\n",
      "Epoch 119/1000\n",
      "27/42 [==================>...........] - ETA: 0s - loss: 0.1960 - accuracy: 0.9214\n",
      "Epoch 119: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2007 - accuracy: 0.9167 - val_loss: 0.3235 - val_accuracy: 0.8708\n",
      "Epoch 120/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2235 - accuracy: 0.9194\n",
      "Epoch 120: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2171 - accuracy: 0.9128 - val_loss: 0.3152 - val_accuracy: 0.8738\n",
      "Epoch 121/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1691 - accuracy: 0.9597\n",
      "Epoch 121: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2089 - accuracy: 0.9138 - val_loss: 0.3329 - val_accuracy: 0.8669\n",
      "Epoch 122/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2280 - accuracy: 0.8871\n",
      "Epoch 122: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2034 - accuracy: 0.9186 - val_loss: 0.3323 - val_accuracy: 0.8685\n",
      "Epoch 123/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1772 - accuracy: 0.9274\n",
      "Epoch 123: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2073 - accuracy: 0.9144 - val_loss: 0.3320 - val_accuracy: 0.8708\n",
      "Epoch 124/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2045 - accuracy: 0.9131\n",
      "Epoch 124: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2049 - accuracy: 0.9128 - val_loss: 0.3250 - val_accuracy: 0.8700\n",
      "Epoch 125/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1454 - accuracy: 0.9435\n",
      "Epoch 125: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2022 - accuracy: 0.9192 - val_loss: 0.3271 - val_accuracy: 0.8723\n",
      "Epoch 126/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1628 - accuracy: 0.9516\n",
      "Epoch 126: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2061 - accuracy: 0.9151 - val_loss: 0.3313 - val_accuracy: 0.8769\n",
      "Epoch 127/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2049 - accuracy: 0.9146\n",
      "Epoch 127: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2040 - accuracy: 0.9153 - val_loss: 0.3176 - val_accuracy: 0.8669\n",
      "Epoch 128/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2074 - accuracy: 0.9122\n",
      "Epoch 128: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2089 - accuracy: 0.9132 - val_loss: 0.3165 - val_accuracy: 0.8708\n",
      "Epoch 129/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1992 - accuracy: 0.9210\n",
      "Epoch 129: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2000 - accuracy: 0.9205 - val_loss: 0.3520 - val_accuracy: 0.8669\n",
      "Epoch 130/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2132 - accuracy: 0.9078\n",
      "Epoch 130: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2125 - accuracy: 0.9088 - val_loss: 0.3352 - val_accuracy: 0.8754\n",
      "Epoch 131/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1978 - accuracy: 0.9355\n",
      "Epoch 131: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1963 - accuracy: 0.9221 - val_loss: 0.3391 - val_accuracy: 0.8662\n",
      "Epoch 132/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1187 - accuracy: 0.9516\n",
      "Epoch 132: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2153 - accuracy: 0.9090 - val_loss: 0.3569 - val_accuracy: 0.8538\n",
      "Epoch 133/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2912 - accuracy: 0.8710\n",
      "Epoch 133: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2229 - accuracy: 0.9057 - val_loss: 0.3200 - val_accuracy: 0.8662\n",
      "Epoch 134/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2659 - accuracy: 0.8629\n",
      "Epoch 134: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2016 - accuracy: 0.9148 - val_loss: 0.3381 - val_accuracy: 0.8738\n",
      "Epoch 135/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1641 - accuracy: 0.9435\n",
      "Epoch 135: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1943 - accuracy: 0.9205 - val_loss: 0.3551 - val_accuracy: 0.8662\n",
      "Epoch 136/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2227 - accuracy: 0.8871\n",
      "Epoch 136: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1946 - accuracy: 0.9217 - val_loss: 0.3429 - val_accuracy: 0.8731\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1585 - accuracy: 0.9355\n",
      "Epoch 137: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.9240 - val_loss: 0.3423 - val_accuracy: 0.8754\n",
      "Epoch 138/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1625 - accuracy: 0.9274\n",
      "Epoch 138: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1976 - accuracy: 0.9190 - val_loss: 0.3427 - val_accuracy: 0.8708\n",
      "Epoch 139/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1918 - accuracy: 0.9234\n",
      "Epoch 139: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1918 - accuracy: 0.9234 - val_loss: 0.3401 - val_accuracy: 0.8723\n",
      "Epoch 140/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1866 - accuracy: 0.9113\n",
      "Epoch 140: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1932 - accuracy: 0.9207 - val_loss: 0.3368 - val_accuracy: 0.8654\n",
      "Epoch 141/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1454 - accuracy: 0.9516\n",
      "Epoch 141: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1913 - accuracy: 0.9217 - val_loss: 0.3732 - val_accuracy: 0.8654\n",
      "Epoch 142/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1783 - accuracy: 0.9355\n",
      "Epoch 142: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1953 - accuracy: 0.9198 - val_loss: 0.3770 - val_accuracy: 0.8692\n",
      "Epoch 143/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1880 - accuracy: 0.9248\n",
      "Epoch 143: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.9248 - val_loss: 0.3513 - val_accuracy: 0.8654\n",
      "Epoch 144/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1929 - accuracy: 0.9236\n",
      "Epoch 144: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1909 - accuracy: 0.9244 - val_loss: 0.3639 - val_accuracy: 0.8677\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3866 - accuracy: 0.8468\n",
      "Epoch 145: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1960 - accuracy: 0.9213 - val_loss: 0.3272 - val_accuracy: 0.8708\n",
      "Epoch 146/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2098 - accuracy: 0.9355\n",
      "Epoch 146: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1851 - accuracy: 0.9292 - val_loss: 0.3619 - val_accuracy: 0.8708\n",
      "Epoch 147/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2072 - accuracy: 0.9274\n",
      "Epoch 147: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1923 - accuracy: 0.9219 - val_loss: 0.3522 - val_accuracy: 0.8700\n",
      "Epoch 148/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1951 - accuracy: 0.9209\n",
      "Epoch 148: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1964 - accuracy: 0.9203 - val_loss: 0.3803 - val_accuracy: 0.8654\n",
      "Epoch 149/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2485 - accuracy: 0.8629\n",
      "Epoch 149: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.9219 - val_loss: 0.3386 - val_accuracy: 0.8685\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2166 - accuracy: 0.8871\n",
      "Epoch 150: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1898 - accuracy: 0.9207 - val_loss: 0.3617 - val_accuracy: 0.8654\n",
      "Epoch 151/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1494 - accuracy: 0.9274\n",
      "Epoch 151: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.9242 - val_loss: 0.3556 - val_accuracy: 0.8715\n",
      "Epoch 152/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1745 - accuracy: 0.9113\n",
      "Epoch 152: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.9253 - val_loss: 0.3649 - val_accuracy: 0.8623\n",
      "Epoch 153/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1261 - accuracy: 0.9597\n",
      "Epoch 153: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1841 - accuracy: 0.9255 - val_loss: 0.3799 - val_accuracy: 0.8692\n",
      "Epoch 154/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1905 - accuracy: 0.9235\n",
      "Epoch 154: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1892 - accuracy: 0.9242 - val_loss: 0.3707 - val_accuracy: 0.8677\n",
      "Epoch 155/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1152 - accuracy: 0.9677\n",
      "Epoch 155: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.9284 - val_loss: 0.3479 - val_accuracy: 0.8692\n",
      "Epoch 156/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1497 - accuracy: 0.9435\n",
      "Epoch 156: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.9307 - val_loss: 0.3904 - val_accuracy: 0.8677\n",
      "Epoch 157/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1477 - accuracy: 0.9274\n",
      "Epoch 157: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.9288 - val_loss: 0.3707 - val_accuracy: 0.8746\n",
      "Epoch 158/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1751 - accuracy: 0.9293\n",
      "Epoch 158: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1768 - accuracy: 0.9292 - val_loss: 0.3760 - val_accuracy: 0.8685\n",
      "Epoch 159/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1769 - accuracy: 0.9308\n",
      "Epoch 159: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1769 - accuracy: 0.9311 - val_loss: 0.3881 - val_accuracy: 0.8623\n",
      "Epoch 160/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1771 - accuracy: 0.9274\n",
      "Epoch 160: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.9277 - val_loss: 0.3645 - val_accuracy: 0.8708\n",
      "Epoch 161/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1728 - accuracy: 0.9298\n",
      "Epoch 161: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1765 - accuracy: 0.9280 - val_loss: 0.3631 - val_accuracy: 0.8731\n",
      "Epoch 162/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1756 - accuracy: 0.9306\n",
      "Epoch 162: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1766 - accuracy: 0.9298 - val_loss: 0.3909 - val_accuracy: 0.8615\n",
      "Epoch 163/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1888 - accuracy: 0.9253\n",
      "Epoch 163: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1848 - accuracy: 0.9265 - val_loss: 0.3729 - val_accuracy: 0.8715\n",
      "Epoch 164/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1944 - accuracy: 0.9435\n",
      "Epoch 164: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1768 - accuracy: 0.9300 - val_loss: 0.3838 - val_accuracy: 0.8669\n",
      "Epoch 165/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1981 - accuracy: 0.9194\n",
      "Epoch 165: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.9240 - val_loss: 0.3971 - val_accuracy: 0.8685\n",
      "Epoch 166/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1806 - accuracy: 0.9296\n",
      "Epoch 166: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1784 - accuracy: 0.9307 - val_loss: 0.3896 - val_accuracy: 0.8692\n",
      "Epoch 167/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.0947 - accuracy: 0.9758\n",
      "Epoch 167: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1696 - accuracy: 0.9319 - val_loss: 0.3854 - val_accuracy: 0.8677\n",
      "Epoch 168/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1695 - accuracy: 0.9321\n",
      "Epoch 168: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1717 - accuracy: 0.9321 - val_loss: 0.3931 - val_accuracy: 0.8592\n",
      "Epoch 169/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1762 - accuracy: 0.9304\n",
      "Epoch 169: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.9298 - val_loss: 0.4007 - val_accuracy: 0.8692\n",
      "Epoch 170/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1718 - accuracy: 0.9274\n",
      "Epoch 170: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1796 - accuracy: 0.9277 - val_loss: 0.3766 - val_accuracy: 0.8646\n",
      "Epoch 171/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2297 - accuracy: 0.8952\n",
      "Epoch 171: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1714 - accuracy: 0.9325 - val_loss: 0.3928 - val_accuracy: 0.8708\n",
      "Epoch 172/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1873 - accuracy: 0.9113\n",
      "Epoch 172: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1794 - accuracy: 0.9288 - val_loss: 0.3976 - val_accuracy: 0.8662\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.6789 - accuracy: 0.6198 \n",
      "Epoch 1: val_accuracy improved from -inf to 0.69769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 6ms/step - loss: 0.6789 - accuracy: 0.6198 - val_loss: 0.5330 - val_accuracy: 0.6977\n",
      "Epoch 2/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.4877 - accuracy: 0.7881\n",
      "Epoch 2: val_accuracy improved from 0.69769 to 0.80385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7953 - val_loss: 0.4325 - val_accuracy: 0.8038\n",
      "Epoch 3/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.4208 - accuracy: 0.8129\n",
      "Epoch 3: val_accuracy improved from 0.80385 to 0.83077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.8139 - val_loss: 0.3885 - val_accuracy: 0.8308\n",
      "Epoch 4/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.3736 - accuracy: 0.8455\n",
      "Epoch 4: val_accuracy improved from 0.83077 to 0.85385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3736 - accuracy: 0.8472 - val_loss: 0.3603 - val_accuracy: 0.8538\n",
      "Epoch 5/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.3588 - accuracy: 0.8501\n",
      "Epoch 5: val_accuracy did not improve from 0.85385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8524 - val_loss: 0.3502 - val_accuracy: 0.8538\n",
      "Epoch 6/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3471 - accuracy: 0.8560\n",
      "Epoch 6: val_accuracy did not improve from 0.85385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8543 - val_loss: 0.3939 - val_accuracy: 0.8238\n",
      "Epoch 7/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.3365 - accuracy: 0.8614\n",
      "Epoch 7: val_accuracy improved from 0.85385 to 0.85923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3405 - accuracy: 0.8584 - val_loss: 0.3398 - val_accuracy: 0.8592\n",
      "Epoch 8/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.3468 - accuracy: 0.8580\n",
      "Epoch 8: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3477 - accuracy: 0.8563 - val_loss: 0.4107 - val_accuracy: 0.8231\n",
      "Epoch 9/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.3450 - accuracy: 0.8497\n",
      "Epoch 9: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3452 - accuracy: 0.8499 - val_loss: 0.3440 - val_accuracy: 0.8554\n",
      "Epoch 10/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3232 - accuracy: 0.8468\n",
      "Epoch 10: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8513 - val_loss: 0.3366 - val_accuracy: 0.8546\n",
      "Epoch 11/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4312 - accuracy: 0.8468\n",
      "Epoch 11: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3200 - accuracy: 0.8686 - val_loss: 0.3376 - val_accuracy: 0.8538\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3665 - accuracy: 0.8790\n",
      "Epoch 12: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8593 - val_loss: 0.3305 - val_accuracy: 0.8569\n",
      "Epoch 13/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2973 - accuracy: 0.8952\n",
      "Epoch 13: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8563 - val_loss: 0.3352 - val_accuracy: 0.8577\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3201 - accuracy: 0.8629\n",
      "Epoch 14: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8582 - val_loss: 0.3473 - val_accuracy: 0.8415\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3305 - accuracy: 0.8618\n",
      "Epoch 15: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8618 - val_loss: 0.3875 - val_accuracy: 0.8338\n",
      "Epoch 16/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3594 - accuracy: 0.8306\n",
      "Epoch 16: val_accuracy improved from 0.85923 to 0.86077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8649 - val_loss: 0.3260 - val_accuracy: 0.8608\n",
      "Epoch 17/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.3161 - accuracy: 0.8638\n",
      "Epoch 17: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3192 - accuracy: 0.8640 - val_loss: 0.3263 - val_accuracy: 0.8546\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2670 - accuracy: 0.9032\n",
      "Epoch 18: val_accuracy improved from 0.86077 to 0.86385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.8736 - val_loss: 0.3284 - val_accuracy: 0.8638\n",
      "Epoch 19/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.3028 - accuracy: 0.8729\n",
      "Epoch 19: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.8722 - val_loss: 0.3507 - val_accuracy: 0.8585\n",
      "Epoch 20/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3133 - accuracy: 0.8649\n",
      "Epoch 20: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.8663 - val_loss: 0.3682 - val_accuracy: 0.8292\n",
      "Epoch 21/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3505 - accuracy: 0.8548\n",
      "Epoch 21: val_accuracy improved from 0.86385 to 0.86769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2936 - accuracy: 0.8769 - val_loss: 0.3230 - val_accuracy: 0.8677\n",
      "Epoch 22/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2051 - accuracy: 0.9355\n",
      "Epoch 22: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2919 - accuracy: 0.8782 - val_loss: 0.3178 - val_accuracy: 0.8662\n",
      "Epoch 23/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2937 - accuracy: 0.8780\n",
      "Epoch 23: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2915 - accuracy: 0.8797 - val_loss: 0.3351 - val_accuracy: 0.8623\n",
      "Epoch 24/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2871 - accuracy: 0.8807\n",
      "Epoch 24: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2869 - accuracy: 0.8803 - val_loss: 0.3197 - val_accuracy: 0.8646\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2904 - accuracy: 0.8871\n",
      "Epoch 25: val_accuracy improved from 0.86769 to 0.86846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2876 - accuracy: 0.8786 - val_loss: 0.3151 - val_accuracy: 0.8685\n",
      "Epoch 26/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2989 - accuracy: 0.8765\n",
      "Epoch 26: val_accuracy improved from 0.86846 to 0.87077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3000 - accuracy: 0.8761 - val_loss: 0.3354 - val_accuracy: 0.8708\n",
      "Epoch 27/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3415 - accuracy: 0.8306\n",
      "Epoch 27: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2861 - accuracy: 0.8822 - val_loss: 0.3385 - val_accuracy: 0.8615\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3297 - accuracy: 0.8468\n",
      "Epoch 28: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2862 - accuracy: 0.8770 - val_loss: 0.3485 - val_accuracy: 0.8454\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2740 - accuracy: 0.9032\n",
      "Epoch 29: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2995 - accuracy: 0.8732 - val_loss: 0.3242 - val_accuracy: 0.8623\n",
      "Epoch 30/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2826 - accuracy: 0.8788\n",
      "Epoch 30: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2852 - accuracy: 0.8782 - val_loss: 0.3375 - val_accuracy: 0.8669\n",
      "Epoch 31/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3588 - accuracy: 0.8306\n",
      "Epoch 31: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2906 - accuracy: 0.8736 - val_loss: 0.3401 - val_accuracy: 0.8654\n",
      "Epoch 32/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3005 - accuracy: 0.9032\n",
      "Epoch 32: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2839 - accuracy: 0.8797 - val_loss: 0.3110 - val_accuracy: 0.8662\n",
      "Epoch 33/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2294 - accuracy: 0.8952\n",
      "Epoch 33: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2787 - accuracy: 0.8851 - val_loss: 0.3326 - val_accuracy: 0.8531\n",
      "Epoch 34/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.3053 - accuracy: 0.8723\n",
      "Epoch 34: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8720 - val_loss: 0.3287 - val_accuracy: 0.8677\n",
      "Epoch 35/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2389 - accuracy: 0.9435\n",
      "Epoch 35: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2864 - accuracy: 0.8795 - val_loss: 0.3142 - val_accuracy: 0.8700\n",
      "Epoch 36/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2498 - accuracy: 0.8952\n",
      "Epoch 36: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2785 - accuracy: 0.8851 - val_loss: 0.3185 - val_accuracy: 0.8638\n",
      "Epoch 37/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3530 - accuracy: 0.8548\n",
      "Epoch 37: val_accuracy improved from 0.87077 to 0.87231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2857 - accuracy: 0.8795 - val_loss: 0.3145 - val_accuracy: 0.8723\n",
      "Epoch 38/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2821 - accuracy: 0.8822\n",
      "Epoch 38: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2811 - accuracy: 0.8826 - val_loss: 0.3166 - val_accuracy: 0.8615\n",
      "Epoch 39/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1967 - accuracy: 0.9355\n",
      "Epoch 39: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2860 - accuracy: 0.8788 - val_loss: 0.3154 - val_accuracy: 0.8638\n",
      "Epoch 40/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2614 - accuracy: 0.9113\n",
      "Epoch 40: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2747 - accuracy: 0.8853 - val_loss: 0.3288 - val_accuracy: 0.8646\n",
      "Epoch 41/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2336 - accuracy: 0.9113\n",
      "Epoch 41: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2755 - accuracy: 0.8872 - val_loss: 0.3085 - val_accuracy: 0.8708\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1933 - accuracy: 0.9274\n",
      "Epoch 42: val_accuracy improved from 0.87231 to 0.87308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2711 - accuracy: 0.8878 - val_loss: 0.3082 - val_accuracy: 0.8731\n",
      "Epoch 43/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2658 - accuracy: 0.8908\n",
      "Epoch 43: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.8899 - val_loss: 0.3126 - val_accuracy: 0.8638\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1743 - accuracy: 0.9516\n",
      "Epoch 44: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2842 - accuracy: 0.8820 - val_loss: 0.3130 - val_accuracy: 0.8662\n",
      "Epoch 45/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2859 - accuracy: 0.9113\n",
      "Epoch 45: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2683 - accuracy: 0.8897 - val_loss: 0.3117 - val_accuracy: 0.8685\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2699 - accuracy: 0.8880\n",
      "Epoch 46: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.8880 - val_loss: 0.3301 - val_accuracy: 0.8562\n",
      "Epoch 47/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2818 - accuracy: 0.8824\n",
      "Epoch 47: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2817 - accuracy: 0.8826 - val_loss: 0.3121 - val_accuracy: 0.8669\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2726 - accuracy: 0.8867\n",
      "Epoch 48: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.8867 - val_loss: 0.3162 - val_accuracy: 0.8715\n",
      "Epoch 49/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3285 - accuracy: 0.8468\n",
      "Epoch 49: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 0.8911 - val_loss: 0.3322 - val_accuracy: 0.8538\n",
      "Epoch 50/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2265 - accuracy: 0.9194\n",
      "Epoch 50: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2829 - accuracy: 0.8817 - val_loss: 0.3222 - val_accuracy: 0.8615\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2675 - accuracy: 0.8952\n",
      "Epoch 51: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.8876 - val_loss: 0.3070 - val_accuracy: 0.8731\n",
      "Epoch 52/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2599 - accuracy: 0.8899\n",
      "Epoch 52: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2584 - accuracy: 0.8911 - val_loss: 0.3243 - val_accuracy: 0.8638\n",
      "Epoch 53/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2636 - accuracy: 0.8913\n",
      "Epoch 53: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2648 - accuracy: 0.8903 - val_loss: 0.3521 - val_accuracy: 0.8492\n",
      "Epoch 54/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2597 - accuracy: 0.9113\n",
      "Epoch 54: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2629 - accuracy: 0.8922 - val_loss: 0.3392 - val_accuracy: 0.8646\n",
      "Epoch 55/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2226 - accuracy: 0.9274\n",
      "Epoch 55: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2706 - accuracy: 0.8863 - val_loss: 0.3142 - val_accuracy: 0.8677\n",
      "Epoch 56/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3717 - accuracy: 0.8468\n",
      "Epoch 56: val_accuracy improved from 0.87308 to 0.87385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2651 - accuracy: 0.8924 - val_loss: 0.3106 - val_accuracy: 0.8738\n",
      "Epoch 57/1000\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.2571 - accuracy: 0.8952\n",
      "Epoch 57: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2602 - accuracy: 0.8953 - val_loss: 0.3028 - val_accuracy: 0.8654\n",
      "Epoch 58/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2660 - accuracy: 0.8891\n",
      "Epoch 58: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2657 - accuracy: 0.8892 - val_loss: 0.3182 - val_accuracy: 0.8738\n",
      "Epoch 59/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2750 - accuracy: 0.8797\n",
      "Epoch 59: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.8817 - val_loss: 0.3075 - val_accuracy: 0.8715\n",
      "Epoch 60/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2722 - accuracy: 0.8790\n",
      "Epoch 60: val_accuracy improved from 0.87385 to 0.87692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.8896 - val_loss: 0.3159 - val_accuracy: 0.8769\n",
      "Epoch 61/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2153 - accuracy: 0.9113\n",
      "Epoch 61: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2603 - accuracy: 0.8928 - val_loss: 0.3199 - val_accuracy: 0.8700\n",
      "Epoch 62/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2755 - accuracy: 0.8871\n",
      "Epoch 62: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.8963 - val_loss: 0.3192 - val_accuracy: 0.8700\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2526 - accuracy: 0.8974\n",
      "Epoch 63: val_accuracy improved from 0.87692 to 0.87769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2526 - accuracy: 0.8974 - val_loss: 0.3015 - val_accuracy: 0.8777\n",
      "Epoch 64/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2187 - accuracy: 0.9032\n",
      "Epoch 64: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.8880 - val_loss: 0.3835 - val_accuracy: 0.8438\n",
      "Epoch 65/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3756 - accuracy: 0.8145\n",
      "Epoch 65: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2683 - accuracy: 0.8863 - val_loss: 0.3090 - val_accuracy: 0.8715\n",
      "Epoch 66/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2570 - accuracy: 0.8952\n",
      "Epoch 66: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.8951 - val_loss: 0.3116 - val_accuracy: 0.8723\n",
      "Epoch 67/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2441 - accuracy: 0.9194\n",
      "Epoch 67: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2522 - accuracy: 0.8971 - val_loss: 0.3097 - val_accuracy: 0.8731\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2564 - accuracy: 0.9274\n",
      "Epoch 68: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2575 - accuracy: 0.8961 - val_loss: 0.3117 - val_accuracy: 0.8738\n",
      "Epoch 69/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2784 - accuracy: 0.8871\n",
      "Epoch 69: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2484 - accuracy: 0.8996 - val_loss: 0.3103 - val_accuracy: 0.8738\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2148 - accuracy: 0.9274\n",
      "Epoch 70: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.8984 - val_loss: 0.3270 - val_accuracy: 0.8585\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2010 - accuracy: 0.9355\n",
      "Epoch 71: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.9009 - val_loss: 0.3212 - val_accuracy: 0.8685\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2899 - accuracy: 0.8710\n",
      "Epoch 72: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2545 - accuracy: 0.8928 - val_loss: 0.3414 - val_accuracy: 0.8662\n",
      "Epoch 73/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2322 - accuracy: 0.9032\n",
      "Epoch 73: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.8990 - val_loss: 0.3137 - val_accuracy: 0.8685\n",
      "Epoch 74/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1892 - accuracy: 0.9113\n",
      "Epoch 74: val_accuracy improved from 0.87769 to 0.87846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.9013 - val_loss: 0.3048 - val_accuracy: 0.8785\n",
      "Epoch 75/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2891 - accuracy: 0.8548\n",
      "Epoch 75: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2676 - accuracy: 0.8874 - val_loss: 0.3110 - val_accuracy: 0.8723\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2985 - accuracy: 0.8790\n",
      "Epoch 76: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2424 - accuracy: 0.9036 - val_loss: 0.3059 - val_accuracy: 0.8785\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2133 - accuracy: 0.9194\n",
      "Epoch 77: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2424 - accuracy: 0.9038 - val_loss: 0.3071 - val_accuracy: 0.8754\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2343 - accuracy: 0.9032\n",
      "Epoch 78: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.8971 - val_loss: 0.3331 - val_accuracy: 0.8600\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2757 - accuracy: 0.8952\n",
      "Epoch 79: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.9036 - val_loss: 0.3314 - val_accuracy: 0.8608\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2555 - accuracy: 0.8952\n",
      "Epoch 80: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.8959 - val_loss: 0.3333 - val_accuracy: 0.8592\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3465 - accuracy: 0.8790\n",
      "Epoch 81: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.8930 - val_loss: 0.3104 - val_accuracy: 0.8769\n",
      "Epoch 82/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2082 - accuracy: 0.9194\n",
      "Epoch 82: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.8969 - val_loss: 0.3240 - val_accuracy: 0.8631\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2729 - accuracy: 0.8790\n",
      "Epoch 83: val_accuracy improved from 0.87846 to 0.88154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.8957 - val_loss: 0.3112 - val_accuracy: 0.8815\n",
      "Epoch 84/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2434 - accuracy: 0.8975\n",
      "Epoch 84: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2425 - accuracy: 0.8986 - val_loss: 0.3188 - val_accuracy: 0.8715\n",
      "Epoch 85/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2492 - accuracy: 0.8973\n",
      "Epoch 85: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.8969 - val_loss: 0.3154 - val_accuracy: 0.8700\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2243 - accuracy: 0.8952\n",
      "Epoch 86: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.8957 - val_loss: 0.3229 - val_accuracy: 0.8715\n",
      "Epoch 87/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2402 - accuracy: 0.9113\n",
      "Epoch 87: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2557 - accuracy: 0.8947 - val_loss: 0.3078 - val_accuracy: 0.8769\n",
      "Epoch 88/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2361 - accuracy: 0.9032\n",
      "Epoch 88: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2429 - accuracy: 0.8982 - val_loss: 0.3298 - val_accuracy: 0.8631\n",
      "Epoch 89/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2663 - accuracy: 0.8871\n",
      "Epoch 89: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8992 - val_loss: 0.3081 - val_accuracy: 0.8715\n",
      "Epoch 90/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2151 - accuracy: 0.9113\n",
      "Epoch 90: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2361 - accuracy: 0.9057 - val_loss: 0.3093 - val_accuracy: 0.8769\n",
      "Epoch 91/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1913 - accuracy: 0.9355\n",
      "Epoch 91: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 0.9080 - val_loss: 0.3140 - val_accuracy: 0.8754\n",
      "Epoch 92/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1979 - accuracy: 0.9274\n",
      "Epoch 92: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.8999 - val_loss: 0.3205 - val_accuracy: 0.8754\n",
      "Epoch 93/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2386 - accuracy: 0.9024\n",
      "Epoch 93: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 0.9021 - val_loss: 0.3239 - val_accuracy: 0.8731\n",
      "Epoch 94/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2555 - accuracy: 0.8871\n",
      "Epoch 94: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2408 - accuracy: 0.8988 - val_loss: 0.3193 - val_accuracy: 0.8762\n",
      "Epoch 95/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1484 - accuracy: 0.9435\n",
      "Epoch 95: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2383 - accuracy: 0.9021 - val_loss: 0.3242 - val_accuracy: 0.8685\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2434 - accuracy: 0.8952\n",
      "Epoch 96: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.9048 - val_loss: 0.3272 - val_accuracy: 0.8646\n",
      "Epoch 97/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2380 - accuracy: 0.9113\n",
      "Epoch 97: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2359 - accuracy: 0.9040 - val_loss: 0.3120 - val_accuracy: 0.8762\n",
      "Epoch 98/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2688 - accuracy: 0.8952\n",
      "Epoch 98: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 0.9107 - val_loss: 0.3112 - val_accuracy: 0.8708\n",
      "Epoch 99/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2978 - accuracy: 0.8710\n",
      "Epoch 99: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2420 - accuracy: 0.8997 - val_loss: 0.3197 - val_accuracy: 0.8646\n",
      "Epoch 100/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2000 - accuracy: 0.9355\n",
      "Epoch 100: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2328 - accuracy: 0.9082 - val_loss: 0.3178 - val_accuracy: 0.8715\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1907 - accuracy: 0.9194\n",
      "Epoch 101: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2355 - accuracy: 0.9038 - val_loss: 0.3347 - val_accuracy: 0.8638\n",
      "Epoch 102/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2411 - accuracy: 0.8952\n",
      "Epoch 102: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2347 - accuracy: 0.9040 - val_loss: 0.3097 - val_accuracy: 0.8723\n",
      "Epoch 103/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1925 - accuracy: 0.9355\n",
      "Epoch 103: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2301 - accuracy: 0.9071 - val_loss: 0.3443 - val_accuracy: 0.8631\n",
      "Epoch 104/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1393 - accuracy: 0.9355\n",
      "Epoch 104: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2272 - accuracy: 0.9092 - val_loss: 0.3137 - val_accuracy: 0.8754\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2439 - accuracy: 0.8871\n",
      "Epoch 105: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2381 - accuracy: 0.9019 - val_loss: 0.3245 - val_accuracy: 0.8738\n",
      "Epoch 106/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1540 - accuracy: 0.9274\n",
      "Epoch 106: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2261 - accuracy: 0.9063 - val_loss: 0.3234 - val_accuracy: 0.8700\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2644 - accuracy: 0.9032\n",
      "Epoch 107: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2229 - accuracy: 0.9099 - val_loss: 0.3095 - val_accuracy: 0.8800\n",
      "Epoch 108/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3053 - accuracy: 0.9032\n",
      "Epoch 108: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2238 - accuracy: 0.9096 - val_loss: 0.3569 - val_accuracy: 0.8608\n",
      "Epoch 109/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3009 - accuracy: 0.8629\n",
      "Epoch 109: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2315 - accuracy: 0.9069 - val_loss: 0.3234 - val_accuracy: 0.8685\n",
      "Epoch 110/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2237 - accuracy: 0.9092\n",
      "Epoch 110: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.9086 - val_loss: 0.3362 - val_accuracy: 0.8692\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1809 - accuracy: 0.9355\n",
      "Epoch 111: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.9098 - val_loss: 0.3249 - val_accuracy: 0.8715\n",
      "Epoch 112/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1508 - accuracy: 0.9435\n",
      "Epoch 112: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2283 - accuracy: 0.9082 - val_loss: 0.3227 - val_accuracy: 0.8692\n",
      "Epoch 113/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1940 - accuracy: 0.9355\n",
      "Epoch 113: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2188 - accuracy: 0.9167 - val_loss: 0.3599 - val_accuracy: 0.8654\n",
      "Epoch 114/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2636 - accuracy: 0.9355\n",
      "Epoch 114: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2475 - accuracy: 0.8969 - val_loss: 0.3510 - val_accuracy: 0.8662\n",
      "Epoch 115/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2392 - accuracy: 0.9113\n",
      "Epoch 115: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2282 - accuracy: 0.9107 - val_loss: 0.3357 - val_accuracy: 0.8615\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2004 - accuracy: 0.9113\n",
      "Epoch 116: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2203 - accuracy: 0.9128 - val_loss: 0.3322 - val_accuracy: 0.8731\n",
      "Epoch 117/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1648 - accuracy: 0.9113\n",
      "Epoch 117: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2284 - accuracy: 0.9065 - val_loss: 0.3477 - val_accuracy: 0.8669\n",
      "Epoch 118/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1644 - accuracy: 0.9194\n",
      "Epoch 118: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 0.9117 - val_loss: 0.3317 - val_accuracy: 0.8669\n",
      "Epoch 119/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1456 - accuracy: 0.9516\n",
      "Epoch 119: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2203 - accuracy: 0.9111 - val_loss: 0.3206 - val_accuracy: 0.8677\n",
      "Epoch 120/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2148 - accuracy: 0.9180\n",
      "Epoch 120: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2190 - accuracy: 0.9146 - val_loss: 0.3139 - val_accuracy: 0.8692\n",
      "Epoch 121/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2196 - accuracy: 0.9111\n",
      "Epoch 121: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.9103 - val_loss: 0.3166 - val_accuracy: 0.8738\n",
      "Epoch 122/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2174 - accuracy: 0.9119\n",
      "Epoch 122: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2196 - accuracy: 0.9111 - val_loss: 0.3386 - val_accuracy: 0.8700\n",
      "Epoch 123/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2656 - accuracy: 0.8710\n",
      "Epoch 123: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2245 - accuracy: 0.9076 - val_loss: 0.3321 - val_accuracy: 0.8692\n",
      "Epoch 124/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2593 - accuracy: 0.8629\n",
      "Epoch 124: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.9107 - val_loss: 0.3634 - val_accuracy: 0.8577\n",
      "Epoch 125/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1970 - accuracy: 0.9355\n",
      "Epoch 125: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2173 - accuracy: 0.9113 - val_loss: 0.3297 - val_accuracy: 0.8662\n",
      "Epoch 126/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1758 - accuracy: 0.9355\n",
      "Epoch 126: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.9109 - val_loss: 0.3307 - val_accuracy: 0.8662\n",
      "Epoch 127/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1618 - accuracy: 0.9274\n",
      "Epoch 127: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2195 - accuracy: 0.9119 - val_loss: 0.3392 - val_accuracy: 0.8692\n",
      "Epoch 128/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2866 - accuracy: 0.8710\n",
      "Epoch 128: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2109 - accuracy: 0.9165 - val_loss: 0.3332 - val_accuracy: 0.8692\n",
      "Epoch 129/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2200 - accuracy: 0.9032\n",
      "Epoch 129: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 0.9167 - val_loss: 0.3155 - val_accuracy: 0.8777\n",
      "Epoch 130/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2234 - accuracy: 0.9113\n",
      "Epoch 130: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2115 - accuracy: 0.9157 - val_loss: 0.3318 - val_accuracy: 0.8700\n",
      "Epoch 131/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1887 - accuracy: 0.9355\n",
      "Epoch 131: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2108 - accuracy: 0.9151 - val_loss: 0.3365 - val_accuracy: 0.8669\n",
      "Epoch 132/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2066 - accuracy: 0.9355\n",
      "Epoch 132: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2049 - accuracy: 0.9205 - val_loss: 0.3311 - val_accuracy: 0.8731\n",
      "Epoch 133/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1229 - accuracy: 0.9597\n",
      "Epoch 133: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2107 - accuracy: 0.9138 - val_loss: 0.3395 - val_accuracy: 0.8669\n",
      "Epoch 134/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2205 - accuracy: 0.9194\n",
      "Epoch 134: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2072 - accuracy: 0.9132 - val_loss: 0.3376 - val_accuracy: 0.8708\n",
      "Epoch 135/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2253 - accuracy: 0.9032\n",
      "Epoch 135: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2025 - accuracy: 0.9188 - val_loss: 0.3321 - val_accuracy: 0.8708\n",
      "Epoch 136/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2319 - accuracy: 0.9032\n",
      "Epoch 136: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2053 - accuracy: 0.9175 - val_loss: 0.3298 - val_accuracy: 0.8738\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1664 - accuracy: 0.9355\n",
      "Epoch 137: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.9194 - val_loss: 0.3459 - val_accuracy: 0.8608\n",
      "Epoch 138/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2525 - accuracy: 0.9194\n",
      "Epoch 138: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2022 - accuracy: 0.9228 - val_loss: 0.3626 - val_accuracy: 0.8592\n",
      "Epoch 139/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2212 - accuracy: 0.9113\n",
      "Epoch 139: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2074 - accuracy: 0.9130 - val_loss: 0.3601 - val_accuracy: 0.8631\n",
      "Epoch 140/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2679 - accuracy: 0.9032\n",
      "Epoch 140: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.9221 - val_loss: 0.3458 - val_accuracy: 0.8646\n",
      "Epoch 141/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2663 - accuracy: 0.8871\n",
      "Epoch 141: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.9225 - val_loss: 0.3490 - val_accuracy: 0.8615\n",
      "Epoch 142/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2396 - accuracy: 0.9194\n",
      "Epoch 142: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2088 - accuracy: 0.9178 - val_loss: 0.3321 - val_accuracy: 0.8623\n",
      "Epoch 143/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2052 - accuracy: 0.9211\n",
      "Epoch 143: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2052 - accuracy: 0.9211 - val_loss: 0.3390 - val_accuracy: 0.8662\n",
      "Epoch 144/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1623 - accuracy: 0.9597\n",
      "Epoch 144: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1977 - accuracy: 0.9244 - val_loss: 0.3485 - val_accuracy: 0.8692\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1242 - accuracy: 0.9516\n",
      "Epoch 145: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1960 - accuracy: 0.9225 - val_loss: 0.3509 - val_accuracy: 0.8662\n",
      "Epoch 146/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1883 - accuracy: 0.8952\n",
      "Epoch 146: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2080 - accuracy: 0.9157 - val_loss: 0.3494 - val_accuracy: 0.8646\n",
      "Epoch 147/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2217 - accuracy: 0.9194\n",
      "Epoch 147: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2284 - accuracy: 0.9051 - val_loss: 0.3393 - val_accuracy: 0.8646\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1976 - accuracy: 0.9238\n",
      "Epoch 148: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1976 - accuracy: 0.9238 - val_loss: 0.3518 - val_accuracy: 0.8685\n",
      "Epoch 149/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1427 - accuracy: 0.9516\n",
      "Epoch 149: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2023 - accuracy: 0.9180 - val_loss: 0.3368 - val_accuracy: 0.8692\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1902 - accuracy: 0.9355\n",
      "Epoch 150: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1993 - accuracy: 0.9190 - val_loss: 0.3505 - val_accuracy: 0.8692\n",
      "Epoch 151/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2129 - accuracy: 0.9435\n",
      "Epoch 151: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2037 - accuracy: 0.9150 - val_loss: 0.3468 - val_accuracy: 0.8654\n",
      "Epoch 152/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2424 - accuracy: 0.8952\n",
      "Epoch 152: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.9215 - val_loss: 0.3597 - val_accuracy: 0.8638\n",
      "Epoch 153/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1583 - accuracy: 0.9355\n",
      "Epoch 153: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.9240 - val_loss: 0.3754 - val_accuracy: 0.8585\n",
      "Epoch 154/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2318 - accuracy: 0.9113\n",
      "Epoch 154: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1962 - accuracy: 0.9217 - val_loss: 0.3536 - val_accuracy: 0.8638\n",
      "Epoch 155/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1363 - accuracy: 0.9597\n",
      "Epoch 155: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1934 - accuracy: 0.9244 - val_loss: 0.3577 - val_accuracy: 0.8638\n",
      "Epoch 156/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1841 - accuracy: 0.9516\n",
      "Epoch 156: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2063 - accuracy: 0.9186 - val_loss: 0.3788 - val_accuracy: 0.8600\n",
      "Epoch 157/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2673 - accuracy: 0.8790\n",
      "Epoch 157: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2011 - accuracy: 0.9176 - val_loss: 0.3642 - val_accuracy: 0.8685\n",
      "Epoch 158/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1234 - accuracy: 0.9677\n",
      "Epoch 158: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1872 - accuracy: 0.9265 - val_loss: 0.3734 - val_accuracy: 0.8600\n",
      "Epoch 159/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1497 - accuracy: 0.9355\n",
      "Epoch 159: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9278 - val_loss: 0.3560 - val_accuracy: 0.8631\n",
      "Epoch 160/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2018 - accuracy: 0.9113\n",
      "Epoch 160: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.9230 - val_loss: 0.3611 - val_accuracy: 0.8623\n",
      "Epoch 161/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1955 - accuracy: 0.9355\n",
      "Epoch 161: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2034 - accuracy: 0.9182 - val_loss: 0.3676 - val_accuracy: 0.8638\n",
      "Epoch 162/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1788 - accuracy: 0.9435\n",
      "Epoch 162: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1891 - accuracy: 0.9271 - val_loss: 0.4080 - val_accuracy: 0.8569\n",
      "Epoch 163/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2108 - accuracy: 0.9109\n",
      "Epoch 163: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2108 - accuracy: 0.9109 - val_loss: 0.3574 - val_accuracy: 0.8600\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 23s - loss: 4.2379 - accuracy: 0.4113\n",
      "Epoch 1: val_accuracy improved from -inf to 0.72077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.8832 - accuracy: 0.5923 - val_loss: 0.6193 - val_accuracy: 0.7208\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.5661 - accuracy: 0.7273\n",
      "Epoch 2: val_accuracy improved from 0.72077 to 0.78615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5661 - accuracy: 0.7273 - val_loss: 0.5158 - val_accuracy: 0.7862\n",
      "Epoch 3/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.4559 - accuracy: 0.8185\n",
      "Epoch 3: val_accuracy improved from 0.78615 to 0.83385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.8157 - val_loss: 0.4063 - val_accuracy: 0.8338\n",
      "Epoch 4/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.3912 - accuracy: 0.8348\n",
      "Epoch 4: val_accuracy improved from 0.83385 to 0.84462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3884 - accuracy: 0.8374 - val_loss: 0.3690 - val_accuracy: 0.8446\n",
      "Epoch 5/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.3667 - accuracy: 0.8487\n",
      "Epoch 5: val_accuracy improved from 0.84462 to 0.84538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3646 - accuracy: 0.8499 - val_loss: 0.3582 - val_accuracy: 0.8454\n",
      "Epoch 6/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4003 - accuracy: 0.8226\n",
      "Epoch 6: val_accuracy did not improve from 0.84538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8453 - val_loss: 0.3937 - val_accuracy: 0.8277\n",
      "Epoch 7/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4226 - accuracy: 0.8226\n",
      "Epoch 7: val_accuracy improved from 0.84538 to 0.85769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3513 - accuracy: 0.8480 - val_loss: 0.3408 - val_accuracy: 0.8577\n",
      "Epoch 8/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2919 - accuracy: 0.8790\n",
      "Epoch 8: val_accuracy did not improve from 0.85769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8634 - val_loss: 0.3598 - val_accuracy: 0.8454\n",
      "Epoch 9/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3317 - accuracy: 0.8611\n",
      "Epoch 9: val_accuracy did not improve from 0.85769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8626 - val_loss: 0.3476 - val_accuracy: 0.8469\n",
      "Epoch 10/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3348 - accuracy: 0.8952\n",
      "Epoch 10: val_accuracy did not improve from 0.85769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8665 - val_loss: 0.3483 - val_accuracy: 0.8462\n",
      "Epoch 11/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2326 - accuracy: 0.9032\n",
      "Epoch 11: val_accuracy did not improve from 0.85769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3469 - accuracy: 0.8499 - val_loss: 0.3909 - val_accuracy: 0.8200\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3959 - accuracy: 0.8468\n",
      "Epoch 12: val_accuracy improved from 0.85769 to 0.86000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8601 - val_loss: 0.3378 - val_accuracy: 0.8600\n",
      "Epoch 13/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3382 - accuracy: 0.8145\n",
      "Epoch 13: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.8707 - val_loss: 0.3293 - val_accuracy: 0.8585\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2978 - accuracy: 0.8710\n",
      "Epoch 14: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8722 - val_loss: 0.3292 - val_accuracy: 0.8600\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3123 - accuracy: 0.8952\n",
      "Epoch 15: val_accuracy improved from 0.86000 to 0.86077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3185 - accuracy: 0.8688 - val_loss: 0.3296 - val_accuracy: 0.8608\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3132 - accuracy: 0.8742\n",
      "Epoch 16: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8742 - val_loss: 0.3282 - val_accuracy: 0.8577\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2602 - accuracy: 0.8952\n",
      "Epoch 17: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8636 - val_loss: 0.3303 - val_accuracy: 0.8562\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2652 - accuracy: 0.8710\n",
      "Epoch 18: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8738 - val_loss: 0.3705 - val_accuracy: 0.8315\n",
      "Epoch 19/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2837 - accuracy: 0.8790\n",
      "Epoch 19: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3170 - accuracy: 0.8655 - val_loss: 0.3271 - val_accuracy: 0.8592\n",
      "Epoch 20/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2932 - accuracy: 0.9032\n",
      "Epoch 20: val_accuracy improved from 0.86077 to 0.86462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8643 - val_loss: 0.3310 - val_accuracy: 0.8646\n",
      "Epoch 21/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3166 - accuracy: 0.8641\n",
      "Epoch 21: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.8642 - val_loss: 0.3401 - val_accuracy: 0.8446\n",
      "Epoch 22/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4348 - accuracy: 0.8226\n",
      "Epoch 22: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8705 - val_loss: 0.3259 - val_accuracy: 0.8562\n",
      "Epoch 23/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2781 - accuracy: 0.9113\n",
      "Epoch 23: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.8718 - val_loss: 0.3426 - val_accuracy: 0.8454\n",
      "Epoch 24/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3832 - accuracy: 0.8226\n",
      "Epoch 24: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8678 - val_loss: 0.3271 - val_accuracy: 0.8585\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3070 - accuracy: 0.8710\n",
      "Epoch 25: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8753 - val_loss: 0.3472 - val_accuracy: 0.8446\n",
      "Epoch 26/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2965 - accuracy: 0.8790\n",
      "Epoch 26: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8701 - val_loss: 0.3319 - val_accuracy: 0.8531\n",
      "Epoch 27/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2789 - accuracy: 0.9032\n",
      "Epoch 27: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.8734 - val_loss: 0.3303 - val_accuracy: 0.8492\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2830 - accuracy: 0.9032\n",
      "Epoch 28: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2998 - accuracy: 0.8718 - val_loss: 0.3266 - val_accuracy: 0.8577\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2837 - accuracy: 0.9032\n",
      "Epoch 29: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8795 - val_loss: 0.3297 - val_accuracy: 0.8554\n",
      "Epoch 30/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2238 - accuracy: 0.9355\n",
      "Epoch 30: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3028 - accuracy: 0.8753 - val_loss: 0.3497 - val_accuracy: 0.8600\n",
      "Epoch 31/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3026 - accuracy: 0.8629\n",
      "Epoch 31: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8751 - val_loss: 0.3419 - val_accuracy: 0.8646\n",
      "Epoch 32/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2489 - accuracy: 0.8952\n",
      "Epoch 32: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8724 - val_loss: 0.3412 - val_accuracy: 0.8646\n",
      "Epoch 33/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3428 - accuracy: 0.8629\n",
      "Epoch 33: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8711 - val_loss: 0.3537 - val_accuracy: 0.8362\n",
      "Epoch 34/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2658 - accuracy: 0.8629\n",
      "Epoch 34: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3010 - accuracy: 0.8772 - val_loss: 0.3552 - val_accuracy: 0.8369\n",
      "Epoch 35/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3327 - accuracy: 0.8710\n",
      "Epoch 35: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8703 - val_loss: 0.3262 - val_accuracy: 0.8585\n",
      "Epoch 36/1000\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.2923 - accuracy: 0.8783\n",
      "Epoch 36: val_accuracy improved from 0.86462 to 0.86538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2979 - accuracy: 0.8778 - val_loss: 0.3329 - val_accuracy: 0.8654\n",
      "Epoch 37/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.3004 - accuracy: 0.8733\n",
      "Epoch 37: val_accuracy did not improve from 0.86538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.8744 - val_loss: 0.3269 - val_accuracy: 0.8615\n",
      "Epoch 38/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2410 - accuracy: 0.8871\n",
      "Epoch 38: val_accuracy improved from 0.86538 to 0.86615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2995 - accuracy: 0.8738 - val_loss: 0.3282 - val_accuracy: 0.8662\n",
      "Epoch 39/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3033 - accuracy: 0.8734\n",
      "Epoch 39: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3021 - accuracy: 0.8730 - val_loss: 0.3282 - val_accuracy: 0.8654\n",
      "Epoch 40/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2598 - accuracy: 0.9113\n",
      "Epoch 40: val_accuracy improved from 0.86615 to 0.86769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2985 - accuracy: 0.8778 - val_loss: 0.3284 - val_accuracy: 0.8677\n",
      "Epoch 41/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3232 - accuracy: 0.8710\n",
      "Epoch 41: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2922 - accuracy: 0.8805 - val_loss: 0.3358 - val_accuracy: 0.8646\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2111 - accuracy: 0.9194\n",
      "Epoch 42: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2925 - accuracy: 0.8824 - val_loss: 0.3436 - val_accuracy: 0.8400\n",
      "Epoch 43/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2772 - accuracy: 0.8629\n",
      "Epoch 43: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.8659 - val_loss: 0.3386 - val_accuracy: 0.8662\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2799 - accuracy: 0.9113\n",
      "Epoch 44: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2943 - accuracy: 0.8742 - val_loss: 0.3347 - val_accuracy: 0.8638\n",
      "Epoch 45/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2602 - accuracy: 0.9113\n",
      "Epoch 45: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2989 - accuracy: 0.8765 - val_loss: 0.3251 - val_accuracy: 0.8615\n",
      "Epoch 46/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2837 - accuracy: 0.8952\n",
      "Epoch 46: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3013 - accuracy: 0.8695 - val_loss: 0.3298 - val_accuracy: 0.8623\n",
      "Epoch 47/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2358 - accuracy: 0.8952\n",
      "Epoch 47: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2895 - accuracy: 0.8809 - val_loss: 0.3252 - val_accuracy: 0.8631\n",
      "Epoch 48/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2701 - accuracy: 0.8871\n",
      "Epoch 48: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2926 - accuracy: 0.8788 - val_loss: 0.3257 - val_accuracy: 0.8608\n",
      "Epoch 49/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2328 - accuracy: 0.9032\n",
      "Epoch 49: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2948 - accuracy: 0.8765 - val_loss: 0.3281 - val_accuracy: 0.8508\n",
      "Epoch 50/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2648 - accuracy: 0.8710\n",
      "Epoch 50: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2904 - accuracy: 0.8749 - val_loss: 0.3330 - val_accuracy: 0.8462\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3758 - accuracy: 0.8468\n",
      "Epoch 51: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2892 - accuracy: 0.8782 - val_loss: 0.3313 - val_accuracy: 0.8569\n",
      "Epoch 52/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3444 - accuracy: 0.8710\n",
      "Epoch 52: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2920 - accuracy: 0.8761 - val_loss: 0.3269 - val_accuracy: 0.8608\n",
      "Epoch 53/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3087 - accuracy: 0.8629\n",
      "Epoch 53: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2901 - accuracy: 0.8790 - val_loss: 0.3292 - val_accuracy: 0.8538\n",
      "Epoch 54/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2269 - accuracy: 0.9355\n",
      "Epoch 54: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2917 - accuracy: 0.8805 - val_loss: 0.3793 - val_accuracy: 0.8477\n",
      "Epoch 55/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3255 - accuracy: 0.8468\n",
      "Epoch 55: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2936 - accuracy: 0.8761 - val_loss: 0.3342 - val_accuracy: 0.8423\n",
      "Epoch 56/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3346 - accuracy: 0.8306\n",
      "Epoch 56: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.8720 - val_loss: 0.3333 - val_accuracy: 0.8631\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3158 - accuracy: 0.8629\n",
      "Epoch 57: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2856 - accuracy: 0.8795 - val_loss: 0.3248 - val_accuracy: 0.8631\n",
      "Epoch 58/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2981 - accuracy: 0.8710\n",
      "Epoch 58: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2865 - accuracy: 0.8820 - val_loss: 0.3290 - val_accuracy: 0.8600\n",
      "Epoch 59/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2474 - accuracy: 0.9032\n",
      "Epoch 59: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2915 - accuracy: 0.8776 - val_loss: 0.3256 - val_accuracy: 0.8623\n",
      "Epoch 60/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2520 - accuracy: 0.9113\n",
      "Epoch 60: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2881 - accuracy: 0.8797 - val_loss: 0.3434 - val_accuracy: 0.8592\n",
      "Epoch 61/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2728 - accuracy: 0.8871\n",
      "Epoch 61: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2865 - accuracy: 0.8790 - val_loss: 0.3338 - val_accuracy: 0.8638\n",
      "Epoch 62/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2800 - accuracy: 0.8871\n",
      "Epoch 62: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2912 - accuracy: 0.8788 - val_loss: 0.3317 - val_accuracy: 0.8508\n",
      "Epoch 63/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2601 - accuracy: 0.8952\n",
      "Epoch 63: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2906 - accuracy: 0.8765 - val_loss: 0.3390 - val_accuracy: 0.8631\n",
      "Epoch 64/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2852 - accuracy: 0.8629\n",
      "Epoch 64: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2862 - accuracy: 0.8776 - val_loss: 0.3252 - val_accuracy: 0.8623\n",
      "Epoch 65/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2685 - accuracy: 0.8790\n",
      "Epoch 65: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2855 - accuracy: 0.8797 - val_loss: 0.3353 - val_accuracy: 0.8492\n",
      "Epoch 66/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2397 - accuracy: 0.9113\n",
      "Epoch 66: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2829 - accuracy: 0.8832 - val_loss: 0.3292 - val_accuracy: 0.8531\n",
      "Epoch 67/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2328 - accuracy: 0.8952\n",
      "Epoch 67: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2863 - accuracy: 0.8778 - val_loss: 0.3370 - val_accuracy: 0.8631\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3078 - accuracy: 0.8548\n",
      "Epoch 68: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2859 - accuracy: 0.8803 - val_loss: 0.3274 - val_accuracy: 0.8654\n",
      "Epoch 69/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1982 - accuracy: 0.9113\n",
      "Epoch 69: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2819 - accuracy: 0.8801 - val_loss: 0.3328 - val_accuracy: 0.8662\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2218 - accuracy: 0.9113\n",
      "Epoch 70: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2817 - accuracy: 0.8803 - val_loss: 0.3361 - val_accuracy: 0.8669\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3765 - accuracy: 0.8548\n",
      "Epoch 71: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2786 - accuracy: 0.8840 - val_loss: 0.3294 - val_accuracy: 0.8523\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2101 - accuracy: 0.9113\n",
      "Epoch 72: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2875 - accuracy: 0.8774 - val_loss: 0.3286 - val_accuracy: 0.8523\n",
      "Epoch 73/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2347 - accuracy: 0.9032\n",
      "Epoch 73: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2821 - accuracy: 0.8826 - val_loss: 0.3318 - val_accuracy: 0.8531\n",
      "Epoch 74/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2928 - accuracy: 0.8952\n",
      "Epoch 74: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2955 - accuracy: 0.8753 - val_loss: 0.3259 - val_accuracy: 0.8554\n",
      "Epoch 75/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2181 - accuracy: 0.8952\n",
      "Epoch 75: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2806 - accuracy: 0.8820 - val_loss: 0.3509 - val_accuracy: 0.8462\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1943 - accuracy: 0.9194\n",
      "Epoch 76: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2851 - accuracy: 0.8767 - val_loss: 0.3323 - val_accuracy: 0.8554\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2560 - accuracy: 0.8952\n",
      "Epoch 77: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2782 - accuracy: 0.8845 - val_loss: 0.3303 - val_accuracy: 0.8569\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2528 - accuracy: 0.8871\n",
      "Epoch 78: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2802 - accuracy: 0.8836 - val_loss: 0.3455 - val_accuracy: 0.8438\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2812 - accuracy: 0.8790\n",
      "Epoch 79: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2862 - accuracy: 0.8761 - val_loss: 0.3462 - val_accuracy: 0.8577\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3656 - accuracy: 0.8548\n",
      "Epoch 80: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2753 - accuracy: 0.8847 - val_loss: 0.3488 - val_accuracy: 0.8615\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3025 - accuracy: 0.8790\n",
      "Epoch 81: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2760 - accuracy: 0.8809 - val_loss: 0.3450 - val_accuracy: 0.8577\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2819 - accuracy: 0.8803\n",
      "Epoch 82: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2819 - accuracy: 0.8803 - val_loss: 0.3472 - val_accuracy: 0.8338\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3063 - accuracy: 0.8629\n",
      "Epoch 83: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2824 - accuracy: 0.8809 - val_loss: 0.3328 - val_accuracy: 0.8477\n",
      "Epoch 84/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2508 - accuracy: 0.8952\n",
      "Epoch 84: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2800 - accuracy: 0.8828 - val_loss: 0.3264 - val_accuracy: 0.8577\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2684 - accuracy: 0.8790\n",
      "Epoch 85: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2706 - accuracy: 0.8844 - val_loss: 0.3543 - val_accuracy: 0.8600\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2419 - accuracy: 0.9032\n",
      "Epoch 86: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2781 - accuracy: 0.8815 - val_loss: 0.3520 - val_accuracy: 0.8615\n",
      "Epoch 87/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3617 - accuracy: 0.8306\n",
      "Epoch 87: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2734 - accuracy: 0.8849 - val_loss: 0.3274 - val_accuracy: 0.8546\n",
      "Epoch 88/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2853 - accuracy: 0.8790\n",
      "Epoch 88: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2688 - accuracy: 0.8878 - val_loss: 0.3340 - val_accuracy: 0.8515\n",
      "Epoch 89/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1694 - accuracy: 0.9194\n",
      "Epoch 89: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2963 - accuracy: 0.8786 - val_loss: 0.3350 - val_accuracy: 0.8654\n",
      "Epoch 90/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2055 - accuracy: 0.9194\n",
      "Epoch 90: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2839 - accuracy: 0.8824 - val_loss: 0.3270 - val_accuracy: 0.8569\n",
      "Epoch 91/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2256 - accuracy: 0.9032\n",
      "Epoch 91: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2825 - accuracy: 0.8799 - val_loss: 0.3404 - val_accuracy: 0.8423\n",
      "Epoch 92/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2807 - accuracy: 0.8790\n",
      "Epoch 92: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2789 - accuracy: 0.8801 - val_loss: 0.3231 - val_accuracy: 0.8662\n",
      "Epoch 93/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3086 - accuracy: 0.8952\n",
      "Epoch 93: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2820 - accuracy: 0.8834 - val_loss: 0.3737 - val_accuracy: 0.8469\n",
      "Epoch 94/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3420 - accuracy: 0.8548\n",
      "Epoch 94: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2798 - accuracy: 0.8792 - val_loss: 0.3236 - val_accuracy: 0.8623\n",
      "Epoch 95/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2373 - accuracy: 0.8710\n",
      "Epoch 95: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2721 - accuracy: 0.8849 - val_loss: 0.3256 - val_accuracy: 0.8569\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3494 - accuracy: 0.8387\n",
      "Epoch 96: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.8867 - val_loss: 0.3373 - val_accuracy: 0.8500\n",
      "Epoch 97/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2495 - accuracy: 0.9194\n",
      "Epoch 97: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2712 - accuracy: 0.8859 - val_loss: 0.3610 - val_accuracy: 0.8362\n",
      "Epoch 98/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3301 - accuracy: 0.8548\n",
      "Epoch 98: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.8836 - val_loss: 0.3343 - val_accuracy: 0.8646\n",
      "Epoch 99/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2156 - accuracy: 0.9113\n",
      "Epoch 99: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2710 - accuracy: 0.8890 - val_loss: 0.3301 - val_accuracy: 0.8508\n",
      "Epoch 100/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2737 - accuracy: 0.8822\n",
      "Epoch 100: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2681 - accuracy: 0.8872 - val_loss: 0.3261 - val_accuracy: 0.8585\n",
      "Epoch 101/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2764 - accuracy: 0.8864\n",
      "Epoch 101: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2753 - accuracy: 0.8869 - val_loss: 0.3256 - val_accuracy: 0.8615\n",
      "Epoch 102/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2563 - accuracy: 0.8938\n",
      "Epoch 102: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2581 - accuracy: 0.8938 - val_loss: 0.3311 - val_accuracy: 0.8669\n",
      "Epoch 103/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2259 - accuracy: 0.9032\n",
      "Epoch 103: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.8894 - val_loss: 0.3294 - val_accuracy: 0.8592\n",
      "Epoch 104/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2260 - accuracy: 0.8790\n",
      "Epoch 104: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2664 - accuracy: 0.8869 - val_loss: 0.3492 - val_accuracy: 0.8508\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2121 - accuracy: 0.8952\n",
      "Epoch 105: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2650 - accuracy: 0.8872 - val_loss: 0.3261 - val_accuracy: 0.8585\n",
      "Epoch 106/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2638 - accuracy: 0.8790\n",
      "Epoch 106: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.8953 - val_loss: 0.3377 - val_accuracy: 0.8592\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2128 - accuracy: 0.9113\n",
      "Epoch 107: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2549 - accuracy: 0.8915 - val_loss: 0.3280 - val_accuracy: 0.8638\n",
      "Epoch 108/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2181 - accuracy: 0.9113\n",
      "Epoch 108: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.8946 - val_loss: 0.3426 - val_accuracy: 0.8538\n",
      "Epoch 109/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2274 - accuracy: 0.9113\n",
      "Epoch 109: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2680 - accuracy: 0.8892 - val_loss: 0.3282 - val_accuracy: 0.8592\n",
      "Epoch 110/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2350 - accuracy: 0.9194\n",
      "Epoch 110: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2573 - accuracy: 0.8892 - val_loss: 0.3266 - val_accuracy: 0.8569\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2314 - accuracy: 0.9032\n",
      "Epoch 111: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.8965 - val_loss: 0.3336 - val_accuracy: 0.8677\n",
      "Epoch 112/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2819 - accuracy: 0.8629\n",
      "Epoch 112: val_accuracy improved from 0.86769 to 0.86846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8940 - val_loss: 0.3282 - val_accuracy: 0.8685\n",
      "Epoch 113/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2542 - accuracy: 0.8952\n",
      "Epoch 113: val_accuracy did not improve from 0.86846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.8959 - val_loss: 0.3167 - val_accuracy: 0.8623\n",
      "Epoch 114/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2463 - accuracy: 0.8790\n",
      "Epoch 114: val_accuracy did not improve from 0.86846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2532 - accuracy: 0.8922 - val_loss: 0.3284 - val_accuracy: 0.8685\n",
      "Epoch 115/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2616 - accuracy: 0.9194\n",
      "Epoch 115: val_accuracy did not improve from 0.86846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.9001 - val_loss: 0.3212 - val_accuracy: 0.8646\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3120 - accuracy: 0.8629\n",
      "Epoch 116: val_accuracy did not improve from 0.86846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.8953 - val_loss: 0.3265 - val_accuracy: 0.8615\n",
      "Epoch 117/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2882 - accuracy: 0.8387\n",
      "Epoch 117: val_accuracy did not improve from 0.86846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8951 - val_loss: 0.3395 - val_accuracy: 0.8631\n",
      "Epoch 118/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2515 - accuracy: 0.8966\n",
      "Epoch 118: val_accuracy did not improve from 0.86846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2516 - accuracy: 0.8971 - val_loss: 0.3167 - val_accuracy: 0.8623\n",
      "Epoch 119/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2420 - accuracy: 0.9000\n",
      "Epoch 119: val_accuracy did not improve from 0.86846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2411 - accuracy: 0.8996 - val_loss: 0.3492 - val_accuracy: 0.8577\n",
      "Epoch 120/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2025 - accuracy: 0.9113\n",
      "Epoch 120: val_accuracy improved from 0.86846 to 0.87077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2364 - accuracy: 0.9015 - val_loss: 0.3235 - val_accuracy: 0.8708\n",
      "Epoch 121/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2482 - accuracy: 0.9032\n",
      "Epoch 121: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2368 - accuracy: 0.9036 - val_loss: 0.3246 - val_accuracy: 0.8662\n",
      "Epoch 122/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3502 - accuracy: 0.8548\n",
      "Epoch 122: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2431 - accuracy: 0.8986 - val_loss: 0.3201 - val_accuracy: 0.8662\n",
      "Epoch 123/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2613 - accuracy: 0.9032\n",
      "Epoch 123: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2385 - accuracy: 0.9005 - val_loss: 0.3501 - val_accuracy: 0.8577\n",
      "Epoch 124/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2110 - accuracy: 0.9194\n",
      "Epoch 124: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.9001 - val_loss: 0.3166 - val_accuracy: 0.8577\n",
      "Epoch 125/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2247 - accuracy: 0.8871\n",
      "Epoch 125: val_accuracy improved from 0.87077 to 0.87308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2347 - accuracy: 0.9024 - val_loss: 0.3226 - val_accuracy: 0.8731\n",
      "Epoch 126/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1958 - accuracy: 0.9032\n",
      "Epoch 126: val_accuracy improved from 0.87308 to 0.87538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2314 - accuracy: 0.9057 - val_loss: 0.3339 - val_accuracy: 0.8754\n",
      "Epoch 127/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2033 - accuracy: 0.9194\n",
      "Epoch 127: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2356 - accuracy: 0.9028 - val_loss: 0.3216 - val_accuracy: 0.8577\n",
      "Epoch 128/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2298 - accuracy: 0.9052\n",
      "Epoch 128: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2310 - accuracy: 0.9044 - val_loss: 0.3145 - val_accuracy: 0.8677\n",
      "Epoch 129/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3069 - accuracy: 0.8952\n",
      "Epoch 129: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2297 - accuracy: 0.9055 - val_loss: 0.3198 - val_accuracy: 0.8638\n",
      "Epoch 130/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2188 - accuracy: 0.9032\n",
      "Epoch 130: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2321 - accuracy: 0.9015 - val_loss: 0.3325 - val_accuracy: 0.8723\n",
      "Epoch 131/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2062 - accuracy: 0.9113\n",
      "Epoch 131: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2474 - accuracy: 0.8934 - val_loss: 0.3144 - val_accuracy: 0.8654\n",
      "Epoch 132/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2836 - accuracy: 0.8790\n",
      "Epoch 132: val_accuracy improved from 0.87538 to 0.87692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.9007 - val_loss: 0.3198 - val_accuracy: 0.8769\n",
      "Epoch 133/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2336 - accuracy: 0.9032\n",
      "Epoch 133: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2409 - accuracy: 0.8990 - val_loss: 0.3219 - val_accuracy: 0.8685\n",
      "Epoch 134/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1966 - accuracy: 0.9194\n",
      "Epoch 134: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2361 - accuracy: 0.9015 - val_loss: 0.3285 - val_accuracy: 0.8623\n",
      "Epoch 135/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1653 - accuracy: 0.9355\n",
      "Epoch 135: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2289 - accuracy: 0.9057 - val_loss: 0.3273 - val_accuracy: 0.8631\n",
      "Epoch 136/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1987 - accuracy: 0.9274\n",
      "Epoch 136: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2256 - accuracy: 0.9057 - val_loss: 0.3155 - val_accuracy: 0.8685\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2379 - accuracy: 0.9113\n",
      "Epoch 137: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2269 - accuracy: 0.9073 - val_loss: 0.3245 - val_accuracy: 0.8646\n",
      "Epoch 138/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1942 - accuracy: 0.9194\n",
      "Epoch 138: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2195 - accuracy: 0.9107 - val_loss: 0.3201 - val_accuracy: 0.8662\n",
      "Epoch 139/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2190 - accuracy: 0.9085\n",
      "Epoch 139: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2159 - accuracy: 0.9084 - val_loss: 0.3361 - val_accuracy: 0.8562\n",
      "Epoch 140/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2142 - accuracy: 0.9128\n",
      "Epoch 140: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2171 - accuracy: 0.9107 - val_loss: 0.3219 - val_accuracy: 0.8669\n",
      "Epoch 141/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1341 - accuracy: 0.9597\n",
      "Epoch 141: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.9105 - val_loss: 0.3191 - val_accuracy: 0.8677\n",
      "Epoch 142/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1655 - accuracy: 0.9355\n",
      "Epoch 142: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.9069 - val_loss: 0.3374 - val_accuracy: 0.8685\n",
      "Epoch 143/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2203 - accuracy: 0.9113\n",
      "Epoch 143: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2249 - accuracy: 0.9090 - val_loss: 0.3560 - val_accuracy: 0.8669\n",
      "Epoch 144/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2298 - accuracy: 0.8952\n",
      "Epoch 144: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2254 - accuracy: 0.9044 - val_loss: 0.3498 - val_accuracy: 0.8646\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2529 - accuracy: 0.8871\n",
      "Epoch 145: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2175 - accuracy: 0.9092 - val_loss: 0.3433 - val_accuracy: 0.8646\n",
      "Epoch 146/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2401 - accuracy: 0.8871\n",
      "Epoch 146: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2193 - accuracy: 0.9092 - val_loss: 0.3275 - val_accuracy: 0.8638\n",
      "Epoch 147/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2173 - accuracy: 0.9086\n",
      "Epoch 147: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2173 - accuracy: 0.9086 - val_loss: 0.3341 - val_accuracy: 0.8654\n",
      "Epoch 148/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2154 - accuracy: 0.8790\n",
      "Epoch 148: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2237 - accuracy: 0.9057 - val_loss: 0.3397 - val_accuracy: 0.8762\n",
      "Epoch 149/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2017 - accuracy: 0.9113\n",
      "Epoch 149: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.9082 - val_loss: 0.3391 - val_accuracy: 0.8662\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1568 - accuracy: 0.9355\n",
      "Epoch 150: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2113 - accuracy: 0.9121 - val_loss: 0.3255 - val_accuracy: 0.8646\n",
      "Epoch 151/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2313 - accuracy: 0.8952\n",
      "Epoch 151: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.9121 - val_loss: 0.3398 - val_accuracy: 0.8646\n",
      "Epoch 152/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2125 - accuracy: 0.9128\n",
      "Epoch 152: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2125 - accuracy: 0.9128 - val_loss: 0.3342 - val_accuracy: 0.8600\n",
      "Epoch 153/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2077 - accuracy: 0.9355\n",
      "Epoch 153: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 0.9113 - val_loss: 0.3627 - val_accuracy: 0.8608\n",
      "Epoch 154/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2681 - accuracy: 0.9032\n",
      "Epoch 154: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2107 - accuracy: 0.9119 - val_loss: 0.3360 - val_accuracy: 0.8646\n",
      "Epoch 155/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1597 - accuracy: 0.9435\n",
      "Epoch 155: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2111 - accuracy: 0.9140 - val_loss: 0.3366 - val_accuracy: 0.8646\n",
      "Epoch 156/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1459 - accuracy: 0.9516\n",
      "Epoch 156: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2106 - accuracy: 0.9136 - val_loss: 0.3366 - val_accuracy: 0.8631\n",
      "Epoch 157/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2202 - accuracy: 0.9274\n",
      "Epoch 157: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2081 - accuracy: 0.9140 - val_loss: 0.3503 - val_accuracy: 0.8692\n",
      "Epoch 158/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1523 - accuracy: 0.9435\n",
      "Epoch 158: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2054 - accuracy: 0.9146 - val_loss: 0.3333 - val_accuracy: 0.8646\n",
      "Epoch 159/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2217 - accuracy: 0.8871\n",
      "Epoch 159: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2067 - accuracy: 0.9121 - val_loss: 0.3444 - val_accuracy: 0.8669\n",
      "Epoch 160/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1811 - accuracy: 0.9355\n",
      "Epoch 160: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2045 - accuracy: 0.9178 - val_loss: 0.3274 - val_accuracy: 0.8592\n",
      "Epoch 161/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1615 - accuracy: 0.9597\n",
      "Epoch 161: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 0.9163 - val_loss: 0.3389 - val_accuracy: 0.8569\n",
      "Epoch 162/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2047 - accuracy: 0.9140\n",
      "Epoch 162: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.9151 - val_loss: 0.3365 - val_accuracy: 0.8608\n",
      "Epoch 163/1000\n",
      "29/42 [===================>..........] - ETA: 0s - loss: 0.2003 - accuracy: 0.9188\n",
      "Epoch 163: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2070 - accuracy: 0.9142 - val_loss: 0.3437 - val_accuracy: 0.8615\n",
      "Epoch 164/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2419 - accuracy: 0.8871\n",
      "Epoch 164: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2116 - accuracy: 0.9130 - val_loss: 0.3437 - val_accuracy: 0.8677\n",
      "Epoch 165/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2215 - accuracy: 0.9032\n",
      "Epoch 165: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2179 - accuracy: 0.9078 - val_loss: 0.3483 - val_accuracy: 0.8677\n",
      "Epoch 166/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1892 - accuracy: 0.9274\n",
      "Epoch 166: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1979 - accuracy: 0.9169 - val_loss: 0.3443 - val_accuracy: 0.8623\n",
      "Epoch 167/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1650 - accuracy: 0.9274\n",
      "Epoch 167: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1998 - accuracy: 0.9167 - val_loss: 0.3524 - val_accuracy: 0.8646\n",
      "Epoch 168/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1559 - accuracy: 0.9274\n",
      "Epoch 168: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2107 - accuracy: 0.9084 - val_loss: 0.3285 - val_accuracy: 0.8585\n",
      "Epoch 169/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1669 - accuracy: 0.9435\n",
      "Epoch 169: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.9061 - val_loss: 0.3478 - val_accuracy: 0.8708\n",
      "Epoch 170/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1919 - accuracy: 0.9274\n",
      "Epoch 170: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2016 - accuracy: 0.9167 - val_loss: 0.3424 - val_accuracy: 0.8600\n",
      "Epoch 171/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1708 - accuracy: 0.9274\n",
      "Epoch 171: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1949 - accuracy: 0.9182 - val_loss: 0.3523 - val_accuracy: 0.8677\n",
      "Epoch 172/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2001 - accuracy: 0.9113\n",
      "Epoch 172: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1949 - accuracy: 0.9186 - val_loss: 0.3401 - val_accuracy: 0.8638\n",
      "Epoch 173/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1830 - accuracy: 0.9274\n",
      "Epoch 173: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2017 - accuracy: 0.9171 - val_loss: 0.3399 - val_accuracy: 0.8700\n",
      "Epoch 174/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1998 - accuracy: 0.9032\n",
      "Epoch 174: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2155 - accuracy: 0.9074 - val_loss: 0.3725 - val_accuracy: 0.8515\n",
      "Epoch 175/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1873 - accuracy: 0.9355\n",
      "Epoch 175: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2022 - accuracy: 0.9151 - val_loss: 0.3788 - val_accuracy: 0.8638\n",
      "Epoch 176/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2764 - accuracy: 0.8710\n",
      "Epoch 176: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1956 - accuracy: 0.9207 - val_loss: 0.3596 - val_accuracy: 0.8623\n",
      "Epoch 177/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1608 - accuracy: 0.9274\n",
      "Epoch 177: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2051 - accuracy: 0.9142 - val_loss: 0.3680 - val_accuracy: 0.8738\n",
      "Epoch 178/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2631 - accuracy: 0.8952\n",
      "Epoch 178: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1949 - accuracy: 0.9203 - val_loss: 0.3438 - val_accuracy: 0.8592\n",
      "Epoch 179/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1955 - accuracy: 0.9157\n",
      "Epoch 179: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.9161 - val_loss: 0.3552 - val_accuracy: 0.8685\n",
      "Epoch 180/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1666 - accuracy: 0.9355\n",
      "Epoch 180: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1940 - accuracy: 0.9198 - val_loss: 0.3563 - val_accuracy: 0.8669\n",
      "Epoch 181/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1862 - accuracy: 0.9032\n",
      "Epoch 181: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2059 - accuracy: 0.9146 - val_loss: 0.3453 - val_accuracy: 0.8692\n",
      "Epoch 182/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1777 - accuracy: 0.9355\n",
      "Epoch 182: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1865 - accuracy: 0.9226 - val_loss: 0.3574 - val_accuracy: 0.8600\n",
      "Epoch 183/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1518 - accuracy: 0.9355\n",
      "Epoch 183: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1894 - accuracy: 0.9234 - val_loss: 0.3568 - val_accuracy: 0.8592\n",
      "Epoch 184/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1666 - accuracy: 0.9355\n",
      "Epoch 184: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2011 - accuracy: 0.9163 - val_loss: 0.3545 - val_accuracy: 0.8523\n",
      "Epoch 185/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1792 - accuracy: 0.9274\n",
      "Epoch 185: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1935 - accuracy: 0.9203 - val_loss: 0.3522 - val_accuracy: 0.8615\n",
      "Epoch 186/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1231 - accuracy: 0.9597\n",
      "Epoch 186: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1884 - accuracy: 0.9200 - val_loss: 0.3516 - val_accuracy: 0.8631\n",
      "Epoch 187/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2043 - accuracy: 0.9194\n",
      "Epoch 187: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.9215 - val_loss: 0.3700 - val_accuracy: 0.8646\n",
      "Epoch 188/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1991 - accuracy: 0.8952\n",
      "Epoch 188: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1994 - accuracy: 0.9136 - val_loss: 0.3644 - val_accuracy: 0.8608\n",
      "Epoch 189/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1881 - accuracy: 0.9194\n",
      "Epoch 189: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1909 - accuracy: 0.9176 - val_loss: 0.3617 - val_accuracy: 0.8546\n",
      "Epoch 190/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2093 - accuracy: 0.9113\n",
      "Epoch 190: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2003 - accuracy: 0.9182 - val_loss: 0.3786 - val_accuracy: 0.8554\n",
      "Epoch 191/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2045 - accuracy: 0.9142\n",
      "Epoch 191: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2048 - accuracy: 0.9140 - val_loss: 0.3557 - val_accuracy: 0.8577\n",
      "Epoch 192/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1555 - accuracy: 0.9516\n",
      "Epoch 192: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1990 - accuracy: 0.9171 - val_loss: 0.3854 - val_accuracy: 0.8592\n",
      "Epoch 193/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1425 - accuracy: 0.9597\n",
      "Epoch 193: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1885 - accuracy: 0.9203 - val_loss: 0.3710 - val_accuracy: 0.8646\n",
      "Epoch 194/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2173 - accuracy: 0.9355\n",
      "Epoch 194: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1961 - accuracy: 0.9161 - val_loss: 0.3862 - val_accuracy: 0.8631\n",
      "Epoch 195/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1344 - accuracy: 0.9677\n",
      "Epoch 195: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.9209 - val_loss: 0.3802 - val_accuracy: 0.8600\n",
      "Epoch 196/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1416 - accuracy: 0.9516\n",
      "Epoch 196: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1916 - accuracy: 0.9192 - val_loss: 0.3717 - val_accuracy: 0.8592\n",
      "Epoch 197/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2414 - accuracy: 0.8952\n",
      "Epoch 197: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1871 - accuracy: 0.9225 - val_loss: 0.3849 - val_accuracy: 0.8623\n",
      "Epoch 198/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2061 - accuracy: 0.9274\n",
      "Epoch 198: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.9240 - val_loss: 0.3633 - val_accuracy: 0.8608\n",
      "Epoch 199/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1405 - accuracy: 0.9597\n",
      "Epoch 199: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.9259 - val_loss: 0.3863 - val_accuracy: 0.8662\n",
      "Epoch 200/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1805 - accuracy: 0.9274\n",
      "Epoch 200: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9221 - val_loss: 0.3699 - val_accuracy: 0.8615\n",
      "Epoch 201/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1326 - accuracy: 0.9435\n",
      "Epoch 201: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.9190 - val_loss: 0.3847 - val_accuracy: 0.8631\n",
      "Epoch 202/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2056 - accuracy: 0.9032\n",
      "Epoch 202: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.9250 - val_loss: 0.3873 - val_accuracy: 0.8608\n",
      "Epoch 203/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1619 - accuracy: 0.9435\n",
      "Epoch 203: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2002 - accuracy: 0.9115 - val_loss: 0.4154 - val_accuracy: 0.8608\n",
      "Epoch 204/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2810 - accuracy: 0.8871\n",
      "Epoch 204: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2003 - accuracy: 0.9159 - val_loss: 0.3836 - val_accuracy: 0.8546\n",
      "Epoch 205/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2314 - accuracy: 0.8952\n",
      "Epoch 205: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.9211 - val_loss: 0.3947 - val_accuracy: 0.8592\n",
      "Epoch 206/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3039 - accuracy: 0.9032\n",
      "Epoch 206: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.9223 - val_loss: 0.4121 - val_accuracy: 0.8646\n",
      "Epoch 207/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.0842 - accuracy: 0.9758\n",
      "Epoch 207: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.9215 - val_loss: 0.3830 - val_accuracy: 0.8631\n",
      "Epoch 208/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1620 - accuracy: 0.9032\n",
      "Epoch 208: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1717 - accuracy: 0.9278 - val_loss: 0.3823 - val_accuracy: 0.8638\n",
      "Epoch 209/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1533 - accuracy: 0.9355\n",
      "Epoch 209: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.9263 - val_loss: 0.3917 - val_accuracy: 0.8585\n",
      "Epoch 210/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1926 - accuracy: 0.9113\n",
      "Epoch 210: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1823 - accuracy: 0.9261 - val_loss: 0.3851 - val_accuracy: 0.8638\n",
      "Epoch 211/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2481 - accuracy: 0.9113\n",
      "Epoch 211: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1855 - accuracy: 0.9228 - val_loss: 0.4004 - val_accuracy: 0.8600\n",
      "Epoch 212/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1123 - accuracy: 0.9677\n",
      "Epoch 212: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.9246 - val_loss: 0.4170 - val_accuracy: 0.8638\n",
      "Epoch 213/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1946 - accuracy: 0.9032\n",
      "Epoch 213: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.9240 - val_loss: 0.4157 - val_accuracy: 0.8592\n",
      "Epoch 214/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2730 - accuracy: 0.8790\n",
      "Epoch 214: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1762 - accuracy: 0.9286 - val_loss: 0.4044 - val_accuracy: 0.8592\n",
      "Epoch 215/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1759 - accuracy: 0.9250\n",
      "Epoch 215: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1759 - accuracy: 0.9250 - val_loss: 0.4170 - val_accuracy: 0.8592\n",
      "Epoch 216/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2368 - accuracy: 0.9113\n",
      "Epoch 216: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1716 - accuracy: 0.9271 - val_loss: 0.4136 - val_accuracy: 0.8662\n",
      "Epoch 217/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1558 - accuracy: 0.9435\n",
      "Epoch 217: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1778 - accuracy: 0.9251 - val_loss: 0.4098 - val_accuracy: 0.8608\n",
      "Epoch 218/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2073 - accuracy: 0.9113\n",
      "Epoch 218: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1716 - accuracy: 0.9269 - val_loss: 0.4149 - val_accuracy: 0.8615\n",
      "Epoch 219/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1653 - accuracy: 0.9113\n",
      "Epoch 219: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1710 - accuracy: 0.9280 - val_loss: 0.4322 - val_accuracy: 0.8608\n",
      "Epoch 220/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1305 - accuracy: 0.9274\n",
      "Epoch 220: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1647 - accuracy: 0.9305 - val_loss: 0.4169 - val_accuracy: 0.8608\n",
      "Epoch 221/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2083 - accuracy: 0.9274\n",
      "Epoch 221: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1639 - accuracy: 0.9296 - val_loss: 0.4058 - val_accuracy: 0.8577\n",
      "Epoch 222/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1671 - accuracy: 0.9355\n",
      "Epoch 222: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1738 - accuracy: 0.9259 - val_loss: 0.4529 - val_accuracy: 0.8577\n",
      "Epoch 223/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1759 - accuracy: 0.9194\n",
      "Epoch 223: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1769 - accuracy: 0.9232 - val_loss: 0.4013 - val_accuracy: 0.8600\n",
      "Epoch 224/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2108 - accuracy: 0.9194\n",
      "Epoch 224: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1700 - accuracy: 0.9317 - val_loss: 0.4039 - val_accuracy: 0.8562\n",
      "Epoch 225/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1504 - accuracy: 0.9194\n",
      "Epoch 225: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1757 - accuracy: 0.9253 - val_loss: 0.4167 - val_accuracy: 0.8608\n",
      "Epoch 226/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2276 - accuracy: 0.9032\n",
      "Epoch 226: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1709 - accuracy: 0.9342 - val_loss: 0.4150 - val_accuracy: 0.8546\n",
      "Epoch 227/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2289 - accuracy: 0.8952\n",
      "Epoch 227: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1699 - accuracy: 0.9271 - val_loss: 0.4339 - val_accuracy: 0.8554\n",
      "Epoch 228/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2006 - accuracy: 0.9113\n",
      "Epoch 228: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1733 - accuracy: 0.9282 - val_loss: 0.4033 - val_accuracy: 0.8562\n",
      "Epoch 229/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1671 - accuracy: 0.9113\n",
      "Epoch 229: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1652 - accuracy: 0.9309 - val_loss: 0.4403 - val_accuracy: 0.8631\n",
      "Epoch 230/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1497 - accuracy: 0.9274\n",
      "Epoch 230: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1669 - accuracy: 0.9294 - val_loss: 0.4236 - val_accuracy: 0.8631\n",
      "Epoch 231/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1121 - accuracy: 0.9435\n",
      "Epoch 231: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1714 - accuracy: 0.9280 - val_loss: 0.4118 - val_accuracy: 0.8577\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 22s - loss: 6.5008 - accuracy: 0.4919\n",
      "Epoch 1: val_accuracy improved from -inf to 0.63769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 1.2611 - accuracy: 0.5419 - val_loss: 0.6473 - val_accuracy: 0.6377\n",
      "Epoch 2/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.6685 - accuracy: 0.5726\n",
      "Epoch 2: val_accuracy improved from 0.63769 to 0.71769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6108 - accuracy: 0.6735 - val_loss: 0.5626 - val_accuracy: 0.7177\n",
      "Epoch 3/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.5763 - accuracy: 0.7177\n",
      "Epoch 3: val_accuracy improved from 0.71769 to 0.78538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.7462 - val_loss: 0.4963 - val_accuracy: 0.7854\n",
      "Epoch 4/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4515 - accuracy: 0.8629\n",
      "Epoch 4: val_accuracy improved from 0.78538 to 0.80462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.8032 - val_loss: 0.4365 - val_accuracy: 0.8046\n",
      "Epoch 5/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4759 - accuracy: 0.7661\n",
      "Epoch 5: val_accuracy improved from 0.80462 to 0.83769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.8182 - val_loss: 0.3956 - val_accuracy: 0.8377\n",
      "Epoch 6/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3749 - accuracy: 0.8790\n",
      "Epoch 6: val_accuracy improved from 0.83769 to 0.85231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8366 - val_loss: 0.3675 - val_accuracy: 0.8523\n",
      "Epoch 7/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3660 - accuracy: 0.8535\n",
      "Epoch 7: val_accuracy did not improve from 0.85231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8536 - val_loss: 0.3755 - val_accuracy: 0.8323\n",
      "Epoch 8/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3886 - accuracy: 0.8065\n",
      "Epoch 8: val_accuracy improved from 0.85231 to 0.85923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3529 - accuracy: 0.8532 - val_loss: 0.3467 - val_accuracy: 0.8592\n",
      "Epoch 9/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3262 - accuracy: 0.8629\n",
      "Epoch 9: val_accuracy improved from 0.85923 to 0.86462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3449 - accuracy: 0.8617 - val_loss: 0.3396 - val_accuracy: 0.8646\n",
      "Epoch 10/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3442 - accuracy: 0.8871\n",
      "Epoch 10: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3437 - accuracy: 0.8559 - val_loss: 0.3370 - val_accuracy: 0.8615\n",
      "Epoch 11/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2787 - accuracy: 0.8790\n",
      "Epoch 11: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8640 - val_loss: 0.3345 - val_accuracy: 0.8638\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3321 - accuracy: 0.8468\n",
      "Epoch 12: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8647 - val_loss: 0.3468 - val_accuracy: 0.8446\n",
      "Epoch 13/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3391 - accuracy: 0.8226\n",
      "Epoch 13: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8661 - val_loss: 0.3328 - val_accuracy: 0.8623\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3054 - accuracy: 0.8629\n",
      "Epoch 14: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8605 - val_loss: 0.3395 - val_accuracy: 0.8600\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2981 - accuracy: 0.8468\n",
      "Epoch 15: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8561 - val_loss: 0.3322 - val_accuracy: 0.8623\n",
      "Epoch 16/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3675 - accuracy: 0.8548\n",
      "Epoch 16: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3173 - accuracy: 0.8693 - val_loss: 0.3930 - val_accuracy: 0.8208\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3407 - accuracy: 0.8548\n",
      "Epoch 17: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3187 - accuracy: 0.8668 - val_loss: 0.3343 - val_accuracy: 0.8615\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2556 - accuracy: 0.9355\n",
      "Epoch 18: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8718 - val_loss: 0.3332 - val_accuracy: 0.8577\n",
      "Epoch 19/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3068 - accuracy: 0.8790\n",
      "Epoch 19: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3193 - accuracy: 0.8645 - val_loss: 0.3313 - val_accuracy: 0.8538\n",
      "Epoch 20/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3209 - accuracy: 0.8548\n",
      "Epoch 20: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8690 - val_loss: 0.3336 - val_accuracy: 0.8554\n",
      "Epoch 21/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2211 - accuracy: 0.9113\n",
      "Epoch 21: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8703 - val_loss: 0.3318 - val_accuracy: 0.8592\n",
      "Epoch 22/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3563 - accuracy: 0.8387\n",
      "Epoch 22: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8715 - val_loss: 0.3390 - val_accuracy: 0.8492\n",
      "Epoch 23/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1925 - accuracy: 0.9194\n",
      "Epoch 23: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3185 - accuracy: 0.8659 - val_loss: 0.3300 - val_accuracy: 0.8585\n",
      "Epoch 24/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.3204 - accuracy: 0.8631\n",
      "Epoch 24: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3167 - accuracy: 0.8643 - val_loss: 0.3433 - val_accuracy: 0.8608\n",
      "Epoch 25/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.3010 - accuracy: 0.8728\n",
      "Epoch 25: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8717 - val_loss: 0.3305 - val_accuracy: 0.8562\n",
      "Epoch 26/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.3022 - accuracy: 0.8717\n",
      "Epoch 26: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.8622 - val_loss: 0.3631 - val_accuracy: 0.8369\n",
      "Epoch 27/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3521 - accuracy: 0.8710\n",
      "Epoch 27: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3166 - accuracy: 0.8647 - val_loss: 0.3334 - val_accuracy: 0.8577\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2420 - accuracy: 0.9032\n",
      "Epoch 28: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.8701 - val_loss: 0.3306 - val_accuracy: 0.8608\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2734 - accuracy: 0.8790\n",
      "Epoch 29: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3047 - accuracy: 0.8717 - val_loss: 0.3448 - val_accuracy: 0.8438\n",
      "Epoch 30/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3552 - accuracy: 0.8710\n",
      "Epoch 30: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8697 - val_loss: 0.3399 - val_accuracy: 0.8431\n",
      "Epoch 31/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4098 - accuracy: 0.8226\n",
      "Epoch 31: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3058 - accuracy: 0.8713 - val_loss: 0.3642 - val_accuracy: 0.8523\n",
      "Epoch 32/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3385 - accuracy: 0.8710\n",
      "Epoch 32: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2967 - accuracy: 0.8770 - val_loss: 0.3341 - val_accuracy: 0.8631\n",
      "Epoch 33/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2810 - accuracy: 0.8952\n",
      "Epoch 33: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3030 - accuracy: 0.8740 - val_loss: 0.3390 - val_accuracy: 0.8600\n",
      "Epoch 34/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3519 - accuracy: 0.8710\n",
      "Epoch 34: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.8738 - val_loss: 0.3292 - val_accuracy: 0.8562\n",
      "Epoch 35/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2908 - accuracy: 0.8790\n",
      "Epoch 35: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2921 - accuracy: 0.8784 - val_loss: 0.3333 - val_accuracy: 0.8623\n",
      "Epoch 36/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2350 - accuracy: 0.9355\n",
      "Epoch 36: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3007 - accuracy: 0.8726 - val_loss: 0.3294 - val_accuracy: 0.8615\n",
      "Epoch 37/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2728 - accuracy: 0.8952\n",
      "Epoch 37: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2898 - accuracy: 0.8780 - val_loss: 0.3362 - val_accuracy: 0.8477\n",
      "Epoch 38/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2933 - accuracy: 0.8710\n",
      "Epoch 38: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2971 - accuracy: 0.8740 - val_loss: 0.3345 - val_accuracy: 0.8615\n",
      "Epoch 39/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3424 - accuracy: 0.8710\n",
      "Epoch 39: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2938 - accuracy: 0.8742 - val_loss: 0.3288 - val_accuracy: 0.8592\n",
      "Epoch 40/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3042 - accuracy: 0.8952\n",
      "Epoch 40: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2917 - accuracy: 0.8813 - val_loss: 0.3326 - val_accuracy: 0.8623\n",
      "Epoch 41/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2485 - accuracy: 0.8952\n",
      "Epoch 41: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2854 - accuracy: 0.8801 - val_loss: 0.3302 - val_accuracy: 0.8515\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3107 - accuracy: 0.8790\n",
      "Epoch 42: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2928 - accuracy: 0.8759 - val_loss: 0.3339 - val_accuracy: 0.8623\n",
      "Epoch 43/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2901 - accuracy: 0.8548\n",
      "Epoch 43: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2820 - accuracy: 0.8809 - val_loss: 0.3273 - val_accuracy: 0.8608\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2940 - accuracy: 0.8952\n",
      "Epoch 44: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2880 - accuracy: 0.8799 - val_loss: 0.3269 - val_accuracy: 0.8638\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2851 - accuracy: 0.8809\n",
      "Epoch 45: val_accuracy improved from 0.86462 to 0.86538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2851 - accuracy: 0.8809 - val_loss: 0.3480 - val_accuracy: 0.8654\n",
      "Epoch 46/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4350 - accuracy: 0.8145\n",
      "Epoch 46: val_accuracy did not improve from 0.86538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2870 - accuracy: 0.8778 - val_loss: 0.3316 - val_accuracy: 0.8654\n",
      "Epoch 47/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2477 - accuracy: 0.9113\n",
      "Epoch 47: val_accuracy did not improve from 0.86538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2896 - accuracy: 0.8819 - val_loss: 0.3406 - val_accuracy: 0.8638\n",
      "Epoch 48/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2314 - accuracy: 0.9194\n",
      "Epoch 48: val_accuracy improved from 0.86538 to 0.87538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.8788 - val_loss: 0.3247 - val_accuracy: 0.8754\n",
      "Epoch 49/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2438 - accuracy: 0.8871\n",
      "Epoch 49: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2884 - accuracy: 0.8767 - val_loss: 0.3176 - val_accuracy: 0.8692\n",
      "Epoch 50/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2432 - accuracy: 0.9032\n",
      "Epoch 50: val_accuracy improved from 0.87538 to 0.87615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2767 - accuracy: 0.8863 - val_loss: 0.3180 - val_accuracy: 0.8762\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1718 - accuracy: 0.9113\n",
      "Epoch 51: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2808 - accuracy: 0.8832 - val_loss: 0.3292 - val_accuracy: 0.8715\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2709 - accuracy: 0.8890\n",
      "Epoch 52: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.8890 - val_loss: 0.3212 - val_accuracy: 0.8754\n",
      "Epoch 53/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1824 - accuracy: 0.9032\n",
      "Epoch 53: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2746 - accuracy: 0.8855 - val_loss: 0.3286 - val_accuracy: 0.8562\n",
      "Epoch 54/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2464 - accuracy: 0.9194\n",
      "Epoch 54: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2727 - accuracy: 0.8874 - val_loss: 0.3258 - val_accuracy: 0.8692\n",
      "Epoch 55/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2213 - accuracy: 0.9194\n",
      "Epoch 55: val_accuracy improved from 0.87615 to 0.87769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2668 - accuracy: 0.8938 - val_loss: 0.3103 - val_accuracy: 0.8777\n",
      "Epoch 56/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3168 - accuracy: 0.9032\n",
      "Epoch 56: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.8946 - val_loss: 0.3147 - val_accuracy: 0.8685\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2860 - accuracy: 0.8790\n",
      "Epoch 57: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2631 - accuracy: 0.8913 - val_loss: 0.3082 - val_accuracy: 0.8615\n",
      "Epoch 58/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2222 - accuracy: 0.9274\n",
      "Epoch 58: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.8884 - val_loss: 0.3510 - val_accuracy: 0.8638\n",
      "Epoch 59/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2636 - accuracy: 0.9113\n",
      "Epoch 59: val_accuracy improved from 0.87769 to 0.88000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2594 - accuracy: 0.8942 - val_loss: 0.3096 - val_accuracy: 0.8800\n",
      "Epoch 60/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2074 - accuracy: 0.9194\n",
      "Epoch 60: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2603 - accuracy: 0.8949 - val_loss: 0.3140 - val_accuracy: 0.8662\n",
      "Epoch 61/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2736 - accuracy: 0.8629\n",
      "Epoch 61: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2589 - accuracy: 0.8947 - val_loss: 0.3129 - val_accuracy: 0.8677\n",
      "Epoch 62/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2831 - accuracy: 0.8790\n",
      "Epoch 62: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2561 - accuracy: 0.8963 - val_loss: 0.3100 - val_accuracy: 0.8762\n",
      "Epoch 63/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2334 - accuracy: 0.9113\n",
      "Epoch 63: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2529 - accuracy: 0.8959 - val_loss: 0.3013 - val_accuracy: 0.8777\n",
      "Epoch 64/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2482 - accuracy: 0.8871\n",
      "Epoch 64: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.8938 - val_loss: 0.3165 - val_accuracy: 0.8623\n",
      "Epoch 65/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1925 - accuracy: 0.8952\n",
      "Epoch 65: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.8961 - val_loss: 0.3215 - val_accuracy: 0.8785\n",
      "Epoch 66/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2131 - accuracy: 0.9274\n",
      "Epoch 66: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.8947 - val_loss: 0.3165 - val_accuracy: 0.8662\n",
      "Epoch 67/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2417 - accuracy: 0.8790\n",
      "Epoch 67: val_accuracy improved from 0.88000 to 0.88077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.8946 - val_loss: 0.3053 - val_accuracy: 0.8808\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2339 - accuracy: 0.9032\n",
      "Epoch 68: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.8955 - val_loss: 0.3193 - val_accuracy: 0.8746\n",
      "Epoch 69/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2760 - accuracy: 0.8871\n",
      "Epoch 69: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2557 - accuracy: 0.8982 - val_loss: 0.3005 - val_accuracy: 0.8754\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2597 - accuracy: 0.9032\n",
      "Epoch 70: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.8974 - val_loss: 0.3095 - val_accuracy: 0.8708\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2905 - accuracy: 0.8790\n",
      "Epoch 71: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2480 - accuracy: 0.8961 - val_loss: 0.3359 - val_accuracy: 0.8669\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1738 - accuracy: 0.9274\n",
      "Epoch 72: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2584 - accuracy: 0.8905 - val_loss: 0.3287 - val_accuracy: 0.8592\n",
      "Epoch 73/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3834 - accuracy: 0.8468\n",
      "Epoch 73: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2559 - accuracy: 0.8944 - val_loss: 0.3566 - val_accuracy: 0.8508\n",
      "Epoch 74/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2999 - accuracy: 0.8548\n",
      "Epoch 74: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2517 - accuracy: 0.8992 - val_loss: 0.3046 - val_accuracy: 0.8800\n",
      "Epoch 75/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2323 - accuracy: 0.8952\n",
      "Epoch 75: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2423 - accuracy: 0.9026 - val_loss: 0.3085 - val_accuracy: 0.8669\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1735 - accuracy: 0.9355\n",
      "Epoch 76: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2400 - accuracy: 0.9026 - val_loss: 0.3062 - val_accuracy: 0.8754\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2131 - accuracy: 0.9032\n",
      "Epoch 77: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2399 - accuracy: 0.9019 - val_loss: 0.3088 - val_accuracy: 0.8769\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2263 - accuracy: 0.8952\n",
      "Epoch 78: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2416 - accuracy: 0.9038 - val_loss: 0.3059 - val_accuracy: 0.8708\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2028 - accuracy: 0.9113\n",
      "Epoch 79: val_accuracy improved from 0.88077 to 0.88308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2388 - accuracy: 0.9057 - val_loss: 0.3108 - val_accuracy: 0.8831\n",
      "Epoch 80/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2440 - accuracy: 0.8990\n",
      "Epoch 80: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.8990 - val_loss: 0.3039 - val_accuracy: 0.8731\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2573 - accuracy: 0.8952\n",
      "Epoch 81: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.8942 - val_loss: 0.3092 - val_accuracy: 0.8700\n",
      "Epoch 82/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2004 - accuracy: 0.9274\n",
      "Epoch 82: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2427 - accuracy: 0.9007 - val_loss: 0.3139 - val_accuracy: 0.8785\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2187 - accuracy: 0.9194\n",
      "Epoch 83: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.8980 - val_loss: 0.3313 - val_accuracy: 0.8669\n",
      "Epoch 84/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3186 - accuracy: 0.8710\n",
      "Epoch 84: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.8880 - val_loss: 0.3376 - val_accuracy: 0.8738\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2618 - accuracy: 0.8790\n",
      "Epoch 85: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.9001 - val_loss: 0.3070 - val_accuracy: 0.8700\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1889 - accuracy: 0.8952\n",
      "Epoch 86: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2326 - accuracy: 0.9049 - val_loss: 0.3074 - val_accuracy: 0.8808\n",
      "Epoch 87/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2487 - accuracy: 0.9194\n",
      "Epoch 87: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2319 - accuracy: 0.9067 - val_loss: 0.3370 - val_accuracy: 0.8592\n",
      "Epoch 88/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2892 - accuracy: 0.8871\n",
      "Epoch 88: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2407 - accuracy: 0.9003 - val_loss: 0.3074 - val_accuracy: 0.8777\n",
      "Epoch 89/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2181 - accuracy: 0.9194\n",
      "Epoch 89: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2333 - accuracy: 0.9096 - val_loss: 0.3158 - val_accuracy: 0.8662\n",
      "Epoch 90/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2423 - accuracy: 0.8790\n",
      "Epoch 90: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2414 - accuracy: 0.9028 - val_loss: 0.3321 - val_accuracy: 0.8715\n",
      "Epoch 91/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2860 - accuracy: 0.9113\n",
      "Epoch 91: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2367 - accuracy: 0.9028 - val_loss: 0.3117 - val_accuracy: 0.8715\n",
      "Epoch 92/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2933 - accuracy: 0.8629\n",
      "Epoch 92: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.8996 - val_loss: 0.3235 - val_accuracy: 0.8754\n",
      "Epoch 93/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2386 - accuracy: 0.9032\n",
      "Epoch 93: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2363 - accuracy: 0.9013 - val_loss: 0.3076 - val_accuracy: 0.8723\n",
      "Epoch 94/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2328 - accuracy: 0.9058\n",
      "Epoch 94: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2317 - accuracy: 0.9067 - val_loss: 0.3063 - val_accuracy: 0.8754\n",
      "Epoch 95/1000\n",
      "26/42 [=================>............] - ETA: 0s - loss: 0.2315 - accuracy: 0.9069\n",
      "Epoch 95: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2358 - accuracy: 0.9042 - val_loss: 0.3360 - val_accuracy: 0.8692\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2362 - accuracy: 0.9113\n",
      "Epoch 96: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2360 - accuracy: 0.9069 - val_loss: 0.3110 - val_accuracy: 0.8777\n",
      "Epoch 97/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1795 - accuracy: 0.9516\n",
      "Epoch 97: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2292 - accuracy: 0.9105 - val_loss: 0.3115 - val_accuracy: 0.8777\n",
      "Epoch 98/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1902 - accuracy: 0.9274\n",
      "Epoch 98: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2356 - accuracy: 0.9013 - val_loss: 0.3261 - val_accuracy: 0.8685\n",
      "Epoch 99/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2469 - accuracy: 0.9032\n",
      "Epoch 99: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2327 - accuracy: 0.9065 - val_loss: 0.3145 - val_accuracy: 0.8700\n",
      "Epoch 100/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2194 - accuracy: 0.8871\n",
      "Epoch 100: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2295 - accuracy: 0.9073 - val_loss: 0.3153 - val_accuracy: 0.8677\n",
      "Epoch 101/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2252 - accuracy: 0.9103\n",
      "Epoch 101: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2252 - accuracy: 0.9103 - val_loss: 0.3413 - val_accuracy: 0.8577\n",
      "Epoch 102/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2287 - accuracy: 0.9071\n",
      "Epoch 102: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2287 - accuracy: 0.9071 - val_loss: 0.3143 - val_accuracy: 0.8731\n",
      "Epoch 103/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2242 - accuracy: 0.9117\n",
      "Epoch 103: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2247 - accuracy: 0.9111 - val_loss: 0.3104 - val_accuracy: 0.8731\n",
      "Epoch 104/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2251 - accuracy: 0.9113\n",
      "Epoch 104: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2239 - accuracy: 0.9126 - val_loss: 0.3119 - val_accuracy: 0.8777\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1713 - accuracy: 0.9274\n",
      "Epoch 105: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.9074 - val_loss: 0.3229 - val_accuracy: 0.8685\n",
      "Epoch 106/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2216 - accuracy: 0.9194\n",
      "Epoch 106: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2227 - accuracy: 0.9123 - val_loss: 0.3172 - val_accuracy: 0.8746\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2349 - accuracy: 0.8952\n",
      "Epoch 107: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2190 - accuracy: 0.9103 - val_loss: 0.3216 - val_accuracy: 0.8785\n",
      "Epoch 108/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2103 - accuracy: 0.9194\n",
      "Epoch 108: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2302 - accuracy: 0.9061 - val_loss: 0.3315 - val_accuracy: 0.8662\n",
      "Epoch 109/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2046 - accuracy: 0.9194\n",
      "Epoch 109: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2214 - accuracy: 0.9074 - val_loss: 0.3134 - val_accuracy: 0.8731\n",
      "Epoch 110/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1923 - accuracy: 0.9274\n",
      "Epoch 110: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2311 - accuracy: 0.9063 - val_loss: 0.3325 - val_accuracy: 0.8785\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2079 - accuracy: 0.9194\n",
      "Epoch 111: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2214 - accuracy: 0.9105 - val_loss: 0.3333 - val_accuracy: 0.8723\n",
      "Epoch 112/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2321 - accuracy: 0.8790\n",
      "Epoch 112: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2145 - accuracy: 0.9151 - val_loss: 0.3174 - val_accuracy: 0.8746\n",
      "Epoch 113/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1955 - accuracy: 0.9435\n",
      "Epoch 113: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 0.9130 - val_loss: 0.3210 - val_accuracy: 0.8715\n",
      "Epoch 114/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2982 - accuracy: 0.8629\n",
      "Epoch 114: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.9099 - val_loss: 0.3263 - val_accuracy: 0.8746\n",
      "Epoch 115/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1920 - accuracy: 0.9113\n",
      "Epoch 115: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.9063 - val_loss: 0.3202 - val_accuracy: 0.8685\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1947 - accuracy: 0.9194\n",
      "Epoch 116: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2093 - accuracy: 0.9155 - val_loss: 0.3356 - val_accuracy: 0.8731\n",
      "Epoch 117/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2280 - accuracy: 0.9194\n",
      "Epoch 117: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2240 - accuracy: 0.9078 - val_loss: 0.3278 - val_accuracy: 0.8692\n",
      "Epoch 118/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1909 - accuracy: 0.9194\n",
      "Epoch 118: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.9088 - val_loss: 0.3192 - val_accuracy: 0.8715\n",
      "Epoch 119/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2268 - accuracy: 0.8952\n",
      "Epoch 119: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2091 - accuracy: 0.9165 - val_loss: 0.3228 - val_accuracy: 0.8762\n",
      "Epoch 120/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2565 - accuracy: 0.9113\n",
      "Epoch 120: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2110 - accuracy: 0.9161 - val_loss: 0.3353 - val_accuracy: 0.8646\n",
      "Epoch 121/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1877 - accuracy: 0.9113\n",
      "Epoch 121: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2085 - accuracy: 0.9146 - val_loss: 0.3433 - val_accuracy: 0.8662\n",
      "Epoch 122/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1854 - accuracy: 0.9435\n",
      "Epoch 122: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.9117 - val_loss: 0.3257 - val_accuracy: 0.8769\n",
      "Epoch 123/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1826 - accuracy: 0.9113\n",
      "Epoch 123: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2076 - accuracy: 0.9144 - val_loss: 0.3267 - val_accuracy: 0.8746\n",
      "Epoch 124/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1932 - accuracy: 0.9597\n",
      "Epoch 124: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2075 - accuracy: 0.9146 - val_loss: 0.3364 - val_accuracy: 0.8708\n",
      "Epoch 125/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1871 - accuracy: 0.9274\n",
      "Epoch 125: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2092 - accuracy: 0.9157 - val_loss: 0.3417 - val_accuracy: 0.8723\n",
      "Epoch 126/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2309 - accuracy: 0.8871\n",
      "Epoch 126: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2082 - accuracy: 0.9175 - val_loss: 0.3439 - val_accuracy: 0.8708\n",
      "Epoch 127/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1965 - accuracy: 0.9355\n",
      "Epoch 127: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.9182 - val_loss: 0.3320 - val_accuracy: 0.8723\n",
      "Epoch 128/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2087 - accuracy: 0.9153\n",
      "Epoch 128: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.9153 - val_loss: 0.3351 - val_accuracy: 0.8708\n",
      "Epoch 129/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2047 - accuracy: 0.9355\n",
      "Epoch 129: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.9184 - val_loss: 0.3280 - val_accuracy: 0.8762\n",
      "Epoch 130/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1807 - accuracy: 0.9274\n",
      "Epoch 130: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2093 - accuracy: 0.9155 - val_loss: 0.3346 - val_accuracy: 0.8746\n",
      "Epoch 131/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2347 - accuracy: 0.9113\n",
      "Epoch 131: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.9076 - val_loss: 0.3442 - val_accuracy: 0.8654\n",
      "Epoch 132/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2270 - accuracy: 0.9194\n",
      "Epoch 132: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2124 - accuracy: 0.9124 - val_loss: 0.3379 - val_accuracy: 0.8731\n",
      "Epoch 133/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1692 - accuracy: 0.9435\n",
      "Epoch 133: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.9188 - val_loss: 0.3410 - val_accuracy: 0.8585\n",
      "Epoch 134/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2395 - accuracy: 0.9032\n",
      "Epoch 134: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2245 - accuracy: 0.9078 - val_loss: 0.3332 - val_accuracy: 0.8715\n",
      "Epoch 135/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2365 - accuracy: 0.8952\n",
      "Epoch 135: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2136 - accuracy: 0.9107 - val_loss: 0.3312 - val_accuracy: 0.8731\n",
      "Epoch 136/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2802 - accuracy: 0.8871\n",
      "Epoch 136: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1997 - accuracy: 0.9217 - val_loss: 0.3281 - val_accuracy: 0.8708\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1331 - accuracy: 0.9597\n",
      "Epoch 137: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2070 - accuracy: 0.9140 - val_loss: 0.3484 - val_accuracy: 0.8662\n",
      "Epoch 138/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1995 - accuracy: 0.9032\n",
      "Epoch 138: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2033 - accuracy: 0.9169 - val_loss: 0.3578 - val_accuracy: 0.8692\n",
      "Epoch 139/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1919 - accuracy: 0.8952\n",
      "Epoch 139: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 0.9186 - val_loss: 0.3391 - val_accuracy: 0.8731\n",
      "Epoch 140/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1266 - accuracy: 0.9516\n",
      "Epoch 140: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2032 - accuracy: 0.9142 - val_loss: 0.3477 - val_accuracy: 0.8700\n",
      "Epoch 141/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1436 - accuracy: 0.9677\n",
      "Epoch 141: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1998 - accuracy: 0.9230 - val_loss: 0.3407 - val_accuracy: 0.8738\n",
      "Epoch 142/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1982 - accuracy: 0.9032\n",
      "Epoch 142: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1963 - accuracy: 0.9223 - val_loss: 0.3392 - val_accuracy: 0.8715\n",
      "Epoch 143/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1631 - accuracy: 0.9435\n",
      "Epoch 143: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2151 - accuracy: 0.9080 - val_loss: 0.3540 - val_accuracy: 0.8662\n",
      "Epoch 144/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2226 - accuracy: 0.9435\n",
      "Epoch 144: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2024 - accuracy: 0.9205 - val_loss: 0.3610 - val_accuracy: 0.8677\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2091 - accuracy: 0.9113\n",
      "Epoch 145: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1917 - accuracy: 0.9198 - val_loss: 0.3432 - val_accuracy: 0.8669\n",
      "Epoch 146/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1566 - accuracy: 0.9274\n",
      "Epoch 146: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2020 - accuracy: 0.9157 - val_loss: 0.3577 - val_accuracy: 0.8700\n",
      "Epoch 147/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2093 - accuracy: 0.9121\n",
      "Epoch 147: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2093 - accuracy: 0.9121 - val_loss: 0.3453 - val_accuracy: 0.8677\n",
      "Epoch 148/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1795 - accuracy: 0.9032\n",
      "Epoch 148: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1965 - accuracy: 0.9190 - val_loss: 0.3455 - val_accuracy: 0.8715\n",
      "Epoch 149/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1482 - accuracy: 0.9597\n",
      "Epoch 149: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1957 - accuracy: 0.9194 - val_loss: 0.3583 - val_accuracy: 0.8723\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1467 - accuracy: 0.9355\n",
      "Epoch 150: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1871 - accuracy: 0.9265 - val_loss: 0.3514 - val_accuracy: 0.8792\n",
      "Epoch 151/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2203 - accuracy: 0.9032\n",
      "Epoch 151: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.9234 - val_loss: 0.3466 - val_accuracy: 0.8746\n",
      "Epoch 152/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1898 - accuracy: 0.9355\n",
      "Epoch 152: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1981 - accuracy: 0.9173 - val_loss: 0.3505 - val_accuracy: 0.8738\n",
      "Epoch 153/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1915 - accuracy: 0.9274\n",
      "Epoch 153: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.9209 - val_loss: 0.3589 - val_accuracy: 0.8715\n",
      "Epoch 154/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2244 - accuracy: 0.9274\n",
      "Epoch 154: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.9221 - val_loss: 0.3452 - val_accuracy: 0.8738\n",
      "Epoch 155/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1921 - accuracy: 0.9032\n",
      "Epoch 155: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1873 - accuracy: 0.9213 - val_loss: 0.3546 - val_accuracy: 0.8754\n",
      "Epoch 156/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2545 - accuracy: 0.8790\n",
      "Epoch 156: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9232 - val_loss: 0.3600 - val_accuracy: 0.8715\n",
      "Epoch 157/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1770 - accuracy: 0.9274\n",
      "Epoch 157: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1818 - accuracy: 0.9271 - val_loss: 0.3544 - val_accuracy: 0.8738\n",
      "Epoch 158/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2627 - accuracy: 0.9032\n",
      "Epoch 158: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9226 - val_loss: 0.4070 - val_accuracy: 0.8569\n",
      "Epoch 159/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2392 - accuracy: 0.8952\n",
      "Epoch 159: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.9238 - val_loss: 0.3714 - val_accuracy: 0.8731\n",
      "Epoch 160/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1778 - accuracy: 0.9355\n",
      "Epoch 160: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1904 - accuracy: 0.9221 - val_loss: 0.3676 - val_accuracy: 0.8754\n",
      "Epoch 161/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2005 - accuracy: 0.9113\n",
      "Epoch 161: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1942 - accuracy: 0.9217 - val_loss: 0.4144 - val_accuracy: 0.8615\n",
      "Epoch 162/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3414 - accuracy: 0.8871\n",
      "Epoch 162: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1946 - accuracy: 0.9225 - val_loss: 0.3768 - val_accuracy: 0.8708\n",
      "Epoch 163/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1414 - accuracy: 0.9435\n",
      "Epoch 163: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1861 - accuracy: 0.9236 - val_loss: 0.3600 - val_accuracy: 0.8685\n",
      "Epoch 164/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1403 - accuracy: 0.9435\n",
      "Epoch 164: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.9240 - val_loss: 0.3710 - val_accuracy: 0.8731\n",
      "Epoch 165/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1884 - accuracy: 0.9113\n",
      "Epoch 165: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.9305 - val_loss: 0.3663 - val_accuracy: 0.8677\n",
      "Epoch 166/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1377 - accuracy: 0.9516\n",
      "Epoch 166: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1764 - accuracy: 0.9298 - val_loss: 0.3608 - val_accuracy: 0.8754\n",
      "Epoch 167/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1093 - accuracy: 0.9597\n",
      "Epoch 167: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1783 - accuracy: 0.9267 - val_loss: 0.3758 - val_accuracy: 0.8631\n",
      "Epoch 168/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2260 - accuracy: 0.9113\n",
      "Epoch 168: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1812 - accuracy: 0.9292 - val_loss: 0.3735 - val_accuracy: 0.8692\n",
      "Epoch 169/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1501 - accuracy: 0.9516\n",
      "Epoch 169: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1913 - accuracy: 0.9232 - val_loss: 0.3648 - val_accuracy: 0.8731\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 22s - loss: 0.8380 - accuracy: 0.4919\n",
      "Epoch 1: val_accuracy improved from -inf to 0.74308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.6583 - accuracy: 0.6107 - val_loss: 0.5515 - val_accuracy: 0.7431\n",
      "Epoch 2/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.5689 - accuracy: 0.7500\n",
      "Epoch 2: val_accuracy improved from 0.74308 to 0.83462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7758 - val_loss: 0.4466 - val_accuracy: 0.8346\n",
      "Epoch 3/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4219 - accuracy: 0.8145\n",
      "Epoch 3: val_accuracy improved from 0.83462 to 0.85077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8135 - val_loss: 0.3845 - val_accuracy: 0.8508\n",
      "Epoch 4/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.3838 - accuracy: 0.8400\n",
      "Epoch 4: val_accuracy did not improve from 0.85077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.8418 - val_loss: 0.3605 - val_accuracy: 0.8485\n",
      "Epoch 5/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3284 - accuracy: 0.8790\n",
      "Epoch 5: val_accuracy did not improve from 0.85077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3549 - accuracy: 0.8559 - val_loss: 0.3652 - val_accuracy: 0.8438\n",
      "Epoch 6/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2898 - accuracy: 0.8871\n",
      "Epoch 6: val_accuracy did not improve from 0.85077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8549 - val_loss: 0.3880 - val_accuracy: 0.8277\n",
      "Epoch 7/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3082 - accuracy: 0.8710\n",
      "Epoch 7: val_accuracy did not improve from 0.85077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3469 - accuracy: 0.8540 - val_loss: 0.3498 - val_accuracy: 0.8485\n",
      "Epoch 8/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3553 - accuracy: 0.8468\n",
      "Epoch 8: val_accuracy did not improve from 0.85077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8611 - val_loss: 0.3612 - val_accuracy: 0.8423\n",
      "Epoch 9/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3726 - accuracy: 0.7984\n",
      "Epoch 9: val_accuracy improved from 0.85077 to 0.85769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8663 - val_loss: 0.3387 - val_accuracy: 0.8577\n",
      "Epoch 10/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.3260 - accuracy: 0.8616\n",
      "Epoch 10: val_accuracy did not improve from 0.85769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8638 - val_loss: 0.3350 - val_accuracy: 0.8577\n",
      "Epoch 11/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2556 - accuracy: 0.9274\n",
      "Epoch 11: val_accuracy did not improve from 0.85769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3186 - accuracy: 0.8686 - val_loss: 0.3371 - val_accuracy: 0.8531\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3178 - accuracy: 0.8790\n",
      "Epoch 12: val_accuracy did not improve from 0.85769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8659 - val_loss: 0.3525 - val_accuracy: 0.8454\n",
      "Epoch 13/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2988 - accuracy: 0.8790\n",
      "Epoch 13: val_accuracy did not improve from 0.85769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8701 - val_loss: 0.3319 - val_accuracy: 0.8546\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3332 - accuracy: 0.8306\n",
      "Epoch 14: val_accuracy improved from 0.85769 to 0.86077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.8688 - val_loss: 0.3441 - val_accuracy: 0.8608\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2904 - accuracy: 0.8790\n",
      "Epoch 15: val_accuracy improved from 0.86077 to 0.86308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 0.8718 - val_loss: 0.3293 - val_accuracy: 0.8631\n",
      "Epoch 16/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3120 - accuracy: 0.8678\n",
      "Epoch 16: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8678 - val_loss: 0.3381 - val_accuracy: 0.8477\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2942 - accuracy: 0.8468\n",
      "Epoch 17: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8593 - val_loss: 0.3326 - val_accuracy: 0.8631\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4102 - accuracy: 0.8468\n",
      "Epoch 18: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3024 - accuracy: 0.8769 - val_loss: 0.3305 - val_accuracy: 0.8623\n",
      "Epoch 19/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2382 - accuracy: 0.9032\n",
      "Epoch 19: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.8717 - val_loss: 0.3267 - val_accuracy: 0.8569\n",
      "Epoch 20/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2718 - accuracy: 0.8790\n",
      "Epoch 20: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8720 - val_loss: 0.3270 - val_accuracy: 0.8577\n",
      "Epoch 21/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3276 - accuracy: 0.8710\n",
      "Epoch 21: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3005 - accuracy: 0.8724 - val_loss: 0.3344 - val_accuracy: 0.8600\n",
      "Epoch 22/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2127 - accuracy: 0.9516\n",
      "Epoch 22: val_accuracy improved from 0.86308 to 0.86385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3046 - accuracy: 0.8749 - val_loss: 0.3293 - val_accuracy: 0.8638\n",
      "Epoch 23/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3693 - accuracy: 0.8226\n",
      "Epoch 23: val_accuracy improved from 0.86385 to 0.86462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.8697 - val_loss: 0.3226 - val_accuracy: 0.8646\n",
      "Epoch 24/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2312 - accuracy: 0.9113\n",
      "Epoch 24: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2984 - accuracy: 0.8753 - val_loss: 0.3756 - val_accuracy: 0.8438\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3724 - accuracy: 0.8145\n",
      "Epoch 25: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3016 - accuracy: 0.8734 - val_loss: 0.3226 - val_accuracy: 0.8615\n",
      "Epoch 26/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2032 - accuracy: 0.9274\n",
      "Epoch 26: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8709 - val_loss: 0.3228 - val_accuracy: 0.8608\n",
      "Epoch 27/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2950 - accuracy: 0.8790\n",
      "Epoch 27: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.8711 - val_loss: 0.3232 - val_accuracy: 0.8638\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2883 - accuracy: 0.8871\n",
      "Epoch 28: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2933 - accuracy: 0.8776 - val_loss: 0.3619 - val_accuracy: 0.8523\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2829 - accuracy: 0.8710\n",
      "Epoch 29: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8663 - val_loss: 0.3566 - val_accuracy: 0.8600\n",
      "Epoch 30/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2684 - accuracy: 0.8710\n",
      "Epoch 30: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2985 - accuracy: 0.8742 - val_loss: 0.3205 - val_accuracy: 0.8638\n",
      "Epoch 31/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2767 - accuracy: 0.8629\n",
      "Epoch 31: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2861 - accuracy: 0.8840 - val_loss: 0.3155 - val_accuracy: 0.8646\n",
      "Epoch 32/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2615 - accuracy: 0.8790\n",
      "Epoch 32: val_accuracy improved from 0.86462 to 0.86846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2913 - accuracy: 0.8730 - val_loss: 0.3177 - val_accuracy: 0.8685\n",
      "Epoch 33/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2201 - accuracy: 0.9113\n",
      "Epoch 33: val_accuracy improved from 0.86846 to 0.86923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2829 - accuracy: 0.8826 - val_loss: 0.3119 - val_accuracy: 0.8692\n",
      "Epoch 34/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2976 - accuracy: 0.8548\n",
      "Epoch 34: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2833 - accuracy: 0.8826 - val_loss: 0.3189 - val_accuracy: 0.8685\n",
      "Epoch 35/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2176 - accuracy: 0.9194\n",
      "Epoch 35: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2781 - accuracy: 0.8847 - val_loss: 0.3227 - val_accuracy: 0.8685\n",
      "Epoch 36/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2931 - accuracy: 0.8710\n",
      "Epoch 36: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2876 - accuracy: 0.8801 - val_loss: 0.3143 - val_accuracy: 0.8685\n",
      "Epoch 37/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3099 - accuracy: 0.8790\n",
      "Epoch 37: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2783 - accuracy: 0.8872 - val_loss: 0.3166 - val_accuracy: 0.8677\n",
      "Epoch 38/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3349 - accuracy: 0.8468\n",
      "Epoch 38: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2780 - accuracy: 0.8853 - val_loss: 0.3168 - val_accuracy: 0.8646\n",
      "Epoch 39/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1609 - accuracy: 0.9435\n",
      "Epoch 39: val_accuracy improved from 0.86923 to 0.87077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2766 - accuracy: 0.8815 - val_loss: 0.3099 - val_accuracy: 0.8708\n",
      "Epoch 40/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2836 - accuracy: 0.8710\n",
      "Epoch 40: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2720 - accuracy: 0.8880 - val_loss: 0.3100 - val_accuracy: 0.8700\n",
      "Epoch 41/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2384 - accuracy: 0.8790\n",
      "Epoch 41: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2727 - accuracy: 0.8882 - val_loss: 0.3161 - val_accuracy: 0.8677\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3463 - accuracy: 0.8790\n",
      "Epoch 42: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.8894 - val_loss: 0.3202 - val_accuracy: 0.8677\n",
      "Epoch 43/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2723 - accuracy: 0.8629\n",
      "Epoch 43: val_accuracy improved from 0.87077 to 0.87538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.8855 - val_loss: 0.3034 - val_accuracy: 0.8754\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2094 - accuracy: 0.9355\n",
      "Epoch 44: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2665 - accuracy: 0.8921 - val_loss: 0.3095 - val_accuracy: 0.8646\n",
      "Epoch 45/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2528 - accuracy: 0.9113\n",
      "Epoch 45: val_accuracy improved from 0.87538 to 0.88077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2650 - accuracy: 0.8905 - val_loss: 0.3045 - val_accuracy: 0.8808\n",
      "Epoch 46/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2129 - accuracy: 0.9032\n",
      "Epoch 46: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2753 - accuracy: 0.8855 - val_loss: 0.3295 - val_accuracy: 0.8669\n",
      "Epoch 47/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3021 - accuracy: 0.8952\n",
      "Epoch 47: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2607 - accuracy: 0.8951 - val_loss: 0.3005 - val_accuracy: 0.8785\n",
      "Epoch 48/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2047 - accuracy: 0.9032\n",
      "Epoch 48: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2603 - accuracy: 0.8949 - val_loss: 0.3154 - val_accuracy: 0.8738\n",
      "Epoch 49/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2070 - accuracy: 0.9274\n",
      "Epoch 49: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.8934 - val_loss: 0.3159 - val_accuracy: 0.8746\n",
      "Epoch 50/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2794 - accuracy: 0.8871\n",
      "Epoch 50: val_accuracy improved from 0.88077 to 0.88462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2614 - accuracy: 0.8894 - val_loss: 0.2980 - val_accuracy: 0.8846\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2881 - accuracy: 0.8629\n",
      "Epoch 51: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2638 - accuracy: 0.8897 - val_loss: 0.3161 - val_accuracy: 0.8692\n",
      "Epoch 52/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2476 - accuracy: 0.8710\n",
      "Epoch 52: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2612 - accuracy: 0.8905 - val_loss: 0.3002 - val_accuracy: 0.8800\n",
      "Epoch 53/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1900 - accuracy: 0.9032\n",
      "Epoch 53: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2628 - accuracy: 0.8890 - val_loss: 0.3127 - val_accuracy: 0.8692\n",
      "Epoch 54/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3689 - accuracy: 0.8548\n",
      "Epoch 54: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2718 - accuracy: 0.8867 - val_loss: 0.3016 - val_accuracy: 0.8731\n",
      "Epoch 55/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2109 - accuracy: 0.9113\n",
      "Epoch 55: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2587 - accuracy: 0.8951 - val_loss: 0.2998 - val_accuracy: 0.8815\n",
      "Epoch 56/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2527 - accuracy: 0.8710\n",
      "Epoch 56: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.8988 - val_loss: 0.3117 - val_accuracy: 0.8685\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3491 - accuracy: 0.8548\n",
      "Epoch 57: val_accuracy improved from 0.88462 to 0.88846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.9007 - val_loss: 0.2981 - val_accuracy: 0.8885\n",
      "Epoch 58/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1961 - accuracy: 0.9355\n",
      "Epoch 58: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.8984 - val_loss: 0.2975 - val_accuracy: 0.8762\n",
      "Epoch 59/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2914 - accuracy: 0.8629\n",
      "Epoch 59: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2434 - accuracy: 0.9011 - val_loss: 0.2976 - val_accuracy: 0.8862\n",
      "Epoch 60/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2546 - accuracy: 0.8952\n",
      "Epoch 60: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.8999 - val_loss: 0.2962 - val_accuracy: 0.8808\n",
      "Epoch 61/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2946 - accuracy: 0.8629\n",
      "Epoch 61: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.8940 - val_loss: 0.3203 - val_accuracy: 0.8592\n",
      "Epoch 62/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2899 - accuracy: 0.8790\n",
      "Epoch 62: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.8982 - val_loss: 0.3009 - val_accuracy: 0.8762\n",
      "Epoch 63/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2195 - accuracy: 0.9113\n",
      "Epoch 63: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8984 - val_loss: 0.3054 - val_accuracy: 0.8815\n",
      "Epoch 64/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3170 - accuracy: 0.8629\n",
      "Epoch 64: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8967 - val_loss: 0.3092 - val_accuracy: 0.8792\n",
      "Epoch 65/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1542 - accuracy: 0.9274\n",
      "Epoch 65: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2411 - accuracy: 0.9015 - val_loss: 0.2976 - val_accuracy: 0.8708\n",
      "Epoch 66/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2404 - accuracy: 0.8871\n",
      "Epoch 66: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2373 - accuracy: 0.9030 - val_loss: 0.3071 - val_accuracy: 0.8792\n",
      "Epoch 67/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2188 - accuracy: 0.9032\n",
      "Epoch 67: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2425 - accuracy: 0.9001 - val_loss: 0.2975 - val_accuracy: 0.8800\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2900 - accuracy: 0.8952\n",
      "Epoch 68: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2424 - accuracy: 0.9013 - val_loss: 0.3044 - val_accuracy: 0.8846\n",
      "Epoch 69/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2823 - accuracy: 0.8952\n",
      "Epoch 69: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2388 - accuracy: 0.9032 - val_loss: 0.2969 - val_accuracy: 0.8738\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1369 - accuracy: 0.9677\n",
      "Epoch 70: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2394 - accuracy: 0.9007 - val_loss: 0.3090 - val_accuracy: 0.8754\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3527 - accuracy: 0.8226\n",
      "Epoch 71: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.8969 - val_loss: 0.3094 - val_accuracy: 0.8769\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2132 - accuracy: 0.9032\n",
      "Epoch 72: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2565 - accuracy: 0.8942 - val_loss: 0.2990 - val_accuracy: 0.8769\n",
      "Epoch 73/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2345 - accuracy: 0.9032\n",
      "Epoch 73: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2358 - accuracy: 0.9065 - val_loss: 0.2996 - val_accuracy: 0.8808\n",
      "Epoch 74/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2432 - accuracy: 0.9113\n",
      "Epoch 74: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2349 - accuracy: 0.9059 - val_loss: 0.3094 - val_accuracy: 0.8800\n",
      "Epoch 75/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1877 - accuracy: 0.9113\n",
      "Epoch 75: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2316 - accuracy: 0.9076 - val_loss: 0.3061 - val_accuracy: 0.8769\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2357 - accuracy: 0.9032\n",
      "Epoch 76: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2391 - accuracy: 0.9055 - val_loss: 0.3061 - val_accuracy: 0.8808\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2626 - accuracy: 0.8952\n",
      "Epoch 77: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.9084 - val_loss: 0.3062 - val_accuracy: 0.8831\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1170 - accuracy: 0.9839\n",
      "Epoch 78: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2356 - accuracy: 0.9065 - val_loss: 0.3139 - val_accuracy: 0.8677\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2109 - accuracy: 0.9032\n",
      "Epoch 79: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8965 - val_loss: 0.3037 - val_accuracy: 0.8746\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2268 - accuracy: 0.9113\n",
      "Epoch 80: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2265 - accuracy: 0.9088 - val_loss: 0.3058 - val_accuracy: 0.8777\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1864 - accuracy: 0.9516\n",
      "Epoch 81: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2281 - accuracy: 0.9069 - val_loss: 0.3000 - val_accuracy: 0.8738\n",
      "Epoch 82/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2158 - accuracy: 0.9194\n",
      "Epoch 82: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2402 - accuracy: 0.9011 - val_loss: 0.3050 - val_accuracy: 0.8746\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1919 - accuracy: 0.9355\n",
      "Epoch 83: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2282 - accuracy: 0.9059 - val_loss: 0.3012 - val_accuracy: 0.8808\n",
      "Epoch 84/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2580 - accuracy: 0.8952\n",
      "Epoch 84: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2269 - accuracy: 0.9107 - val_loss: 0.3107 - val_accuracy: 0.8669\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3247 - accuracy: 0.8548\n",
      "Epoch 85: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2249 - accuracy: 0.9057 - val_loss: 0.3587 - val_accuracy: 0.8662\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1925 - accuracy: 0.9355\n",
      "Epoch 86: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2276 - accuracy: 0.9111 - val_loss: 0.2997 - val_accuracy: 0.8815\n",
      "Epoch 87/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2255 - accuracy: 0.9079\n",
      "Epoch 87: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2266 - accuracy: 0.9080 - val_loss: 0.3110 - val_accuracy: 0.8723\n",
      "Epoch 88/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2194 - accuracy: 0.9032\n",
      "Epoch 88: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2261 - accuracy: 0.9092 - val_loss: 0.3355 - val_accuracy: 0.8623\n",
      "Epoch 89/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2507 - accuracy: 0.8871\n",
      "Epoch 89: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.9078 - val_loss: 0.3385 - val_accuracy: 0.8677\n",
      "Epoch 90/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2815 - accuracy: 0.8952\n",
      "Epoch 90: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2428 - accuracy: 0.9003 - val_loss: 0.3370 - val_accuracy: 0.8592\n",
      "Epoch 91/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2718 - accuracy: 0.9032\n",
      "Epoch 91: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2270 - accuracy: 0.9038 - val_loss: 0.3307 - val_accuracy: 0.8692\n",
      "Epoch 92/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2592 - accuracy: 0.9113\n",
      "Epoch 92: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2356 - accuracy: 0.9038 - val_loss: 0.3142 - val_accuracy: 0.8769\n",
      "Epoch 93/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2277 - accuracy: 0.9032\n",
      "Epoch 93: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 0.9034 - val_loss: 0.3110 - val_accuracy: 0.8754\n",
      "Epoch 94/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2581 - accuracy: 0.8952\n",
      "Epoch 94: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2214 - accuracy: 0.9094 - val_loss: 0.3255 - val_accuracy: 0.8792\n",
      "Epoch 95/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2098 - accuracy: 0.8871\n",
      "Epoch 95: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2222 - accuracy: 0.9107 - val_loss: 0.3008 - val_accuracy: 0.8792\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1573 - accuracy: 0.9355\n",
      "Epoch 96: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2201 - accuracy: 0.9153 - val_loss: 0.3238 - val_accuracy: 0.8769\n",
      "Epoch 97/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1088 - accuracy: 0.9758\n",
      "Epoch 97: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.9115 - val_loss: 0.3278 - val_accuracy: 0.8731\n",
      "Epoch 98/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2800 - accuracy: 0.8790\n",
      "Epoch 98: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2171 - accuracy: 0.9144 - val_loss: 0.3102 - val_accuracy: 0.8777\n",
      "Epoch 99/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2198 - accuracy: 0.9123\n",
      "Epoch 99: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2195 - accuracy: 0.9128 - val_loss: 0.3052 - val_accuracy: 0.8792\n",
      "Epoch 100/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2443 - accuracy: 0.9113\n",
      "Epoch 100: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2189 - accuracy: 0.9128 - val_loss: 0.3097 - val_accuracy: 0.8754\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1942 - accuracy: 0.9194\n",
      "Epoch 101: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2196 - accuracy: 0.9088 - val_loss: 0.3109 - val_accuracy: 0.8792\n",
      "Epoch 102/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2434 - accuracy: 0.9355\n",
      "Epoch 102: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2237 - accuracy: 0.9096 - val_loss: 0.3092 - val_accuracy: 0.8823\n",
      "Epoch 103/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2351 - accuracy: 0.8952\n",
      "Epoch 103: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.9171 - val_loss: 0.3178 - val_accuracy: 0.8762\n",
      "Epoch 104/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2202 - accuracy: 0.8952\n",
      "Epoch 104: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2139 - accuracy: 0.9150 - val_loss: 0.3253 - val_accuracy: 0.8738\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1610 - accuracy: 0.9274\n",
      "Epoch 105: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2109 - accuracy: 0.9144 - val_loss: 0.3179 - val_accuracy: 0.8731\n",
      "Epoch 106/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1934 - accuracy: 0.9355\n",
      "Epoch 106: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2175 - accuracy: 0.9082 - val_loss: 0.3107 - val_accuracy: 0.8769\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1661 - accuracy: 0.9355\n",
      "Epoch 107: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.9159 - val_loss: 0.3214 - val_accuracy: 0.8838\n",
      "Epoch 108/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2810 - accuracy: 0.9032\n",
      "Epoch 108: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2094 - accuracy: 0.9186 - val_loss: 0.3236 - val_accuracy: 0.8731\n",
      "Epoch 109/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1946 - accuracy: 0.9113\n",
      "Epoch 109: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2069 - accuracy: 0.9161 - val_loss: 0.3203 - val_accuracy: 0.8785\n",
      "Epoch 110/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3091 - accuracy: 0.8468\n",
      "Epoch 110: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2206 - accuracy: 0.9086 - val_loss: 0.3883 - val_accuracy: 0.8646\n",
      "Epoch 111/1000\n",
      "30/42 [====================>.........] - ETA: 0s - loss: 0.2339 - accuracy: 0.9075\n",
      "Epoch 111: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2304 - accuracy: 0.9073 - val_loss: 0.3172 - val_accuracy: 0.8654\n",
      "Epoch 112/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2114 - accuracy: 0.9274\n",
      "Epoch 112: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2070 - accuracy: 0.9163 - val_loss: 0.3187 - val_accuracy: 0.8792\n",
      "Epoch 113/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2162 - accuracy: 0.9113\n",
      "Epoch 113: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2159 - accuracy: 0.9101 - val_loss: 0.3254 - val_accuracy: 0.8785\n",
      "Epoch 114/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1450 - accuracy: 0.9597\n",
      "Epoch 114: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 0.9111 - val_loss: 0.3279 - val_accuracy: 0.8762\n",
      "Epoch 115/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3175 - accuracy: 0.8548\n",
      "Epoch 115: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.9017 - val_loss: 0.3535 - val_accuracy: 0.8654\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3143 - accuracy: 0.8387\n",
      "Epoch 116: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.9076 - val_loss: 0.3245 - val_accuracy: 0.8777\n",
      "Epoch 117/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1944 - accuracy: 0.9274\n",
      "Epoch 117: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2151 - accuracy: 0.9103 - val_loss: 0.3187 - val_accuracy: 0.8715\n",
      "Epoch 118/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2217 - accuracy: 0.8952\n",
      "Epoch 118: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2098 - accuracy: 0.9165 - val_loss: 0.3301 - val_accuracy: 0.8731\n",
      "Epoch 119/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1553 - accuracy: 0.9355\n",
      "Epoch 119: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2199 - accuracy: 0.9088 - val_loss: 0.3293 - val_accuracy: 0.8631\n",
      "Epoch 120/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2382 - accuracy: 0.9113\n",
      "Epoch 120: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2143 - accuracy: 0.9140 - val_loss: 0.3212 - val_accuracy: 0.8769\n",
      "Epoch 121/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2278 - accuracy: 0.9113\n",
      "Epoch 121: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2022 - accuracy: 0.9192 - val_loss: 0.3190 - val_accuracy: 0.8708\n",
      "Epoch 122/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1386 - accuracy: 0.9758\n",
      "Epoch 122: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2006 - accuracy: 0.9219 - val_loss: 0.3250 - val_accuracy: 0.8700\n",
      "Epoch 123/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1310 - accuracy: 0.9597\n",
      "Epoch 123: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2045 - accuracy: 0.9190 - val_loss: 0.3309 - val_accuracy: 0.8692\n",
      "Epoch 124/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2687 - accuracy: 0.8871\n",
      "Epoch 124: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2065 - accuracy: 0.9171 - val_loss: 0.3215 - val_accuracy: 0.8731\n",
      "Epoch 125/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1610 - accuracy: 0.9435\n",
      "Epoch 125: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2002 - accuracy: 0.9198 - val_loss: 0.3290 - val_accuracy: 0.8800\n",
      "Epoch 126/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2465 - accuracy: 0.8952\n",
      "Epoch 126: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1964 - accuracy: 0.9221 - val_loss: 0.3330 - val_accuracy: 0.8731\n",
      "Epoch 127/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2413 - accuracy: 0.9194\n",
      "Epoch 127: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.9115 - val_loss: 0.3267 - val_accuracy: 0.8731\n",
      "Epoch 128/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1586 - accuracy: 0.9435\n",
      "Epoch 128: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2017 - accuracy: 0.9190 - val_loss: 0.3284 - val_accuracy: 0.8762\n",
      "Epoch 129/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2029 - accuracy: 0.9113\n",
      "Epoch 129: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2033 - accuracy: 0.9200 - val_loss: 0.3349 - val_accuracy: 0.8831\n",
      "Epoch 130/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1688 - accuracy: 0.9194\n",
      "Epoch 130: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2003 - accuracy: 0.9192 - val_loss: 0.3284 - val_accuracy: 0.8762\n",
      "Epoch 131/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1496 - accuracy: 0.9355\n",
      "Epoch 131: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9188 - val_loss: 0.3599 - val_accuracy: 0.8746\n",
      "Epoch 132/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2166 - accuracy: 0.9113\n",
      "Epoch 132: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1944 - accuracy: 0.9255 - val_loss: 0.3381 - val_accuracy: 0.8677\n",
      "Epoch 133/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2264 - accuracy: 0.8952\n",
      "Epoch 133: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.9180 - val_loss: 0.3476 - val_accuracy: 0.8738\n",
      "Epoch 134/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2316 - accuracy: 0.8871\n",
      "Epoch 134: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1941 - accuracy: 0.9201 - val_loss: 0.3602 - val_accuracy: 0.8577\n",
      "Epoch 135/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2714 - accuracy: 0.8871\n",
      "Epoch 135: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1956 - accuracy: 0.9250 - val_loss: 0.3330 - val_accuracy: 0.8746\n",
      "Epoch 136/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1759 - accuracy: 0.9032\n",
      "Epoch 136: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1888 - accuracy: 0.9257 - val_loss: 0.3328 - val_accuracy: 0.8738\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1367 - accuracy: 0.9677\n",
      "Epoch 137: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1904 - accuracy: 0.9190 - val_loss: 0.3445 - val_accuracy: 0.8762\n",
      "Epoch 138/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.1925 - accuracy: 0.9238\n",
      "Epoch 138: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.9225 - val_loss: 0.3429 - val_accuracy: 0.8738\n",
      "Epoch 139/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1675 - accuracy: 0.9677\n",
      "Epoch 139: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1935 - accuracy: 0.9207 - val_loss: 0.3328 - val_accuracy: 0.8662\n",
      "Epoch 140/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1951 - accuracy: 0.9113\n",
      "Epoch 140: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1988 - accuracy: 0.9190 - val_loss: 0.3441 - val_accuracy: 0.8738\n",
      "Epoch 141/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1917 - accuracy: 0.9274\n",
      "Epoch 141: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2006 - accuracy: 0.9167 - val_loss: 0.3528 - val_accuracy: 0.8585\n",
      "Epoch 142/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1709 - accuracy: 0.9435\n",
      "Epoch 142: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1903 - accuracy: 0.9225 - val_loss: 0.3352 - val_accuracy: 0.8777\n",
      "Epoch 143/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2007 - accuracy: 0.9194\n",
      "Epoch 143: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.9265 - val_loss: 0.3588 - val_accuracy: 0.8662\n",
      "Epoch 144/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1587 - accuracy: 0.9435\n",
      "Epoch 144: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.9225 - val_loss: 0.3549 - val_accuracy: 0.8646\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1727 - accuracy: 0.9355\n",
      "Epoch 145: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1896 - accuracy: 0.9234 - val_loss: 0.3635 - val_accuracy: 0.8638\n",
      "Epoch 146/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1607 - accuracy: 0.9355\n",
      "Epoch 146: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1908 - accuracy: 0.9232 - val_loss: 0.3476 - val_accuracy: 0.8754\n",
      "Epoch 147/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2307 - accuracy: 0.9274\n",
      "Epoch 147: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1881 - accuracy: 0.9211 - val_loss: 0.3591 - val_accuracy: 0.8685\n",
      "Epoch 148/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2435 - accuracy: 0.8952\n",
      "Epoch 148: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2009 - accuracy: 0.9188 - val_loss: 0.3715 - val_accuracy: 0.8715\n",
      "Epoch 149/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1753 - accuracy: 0.9032\n",
      "Epoch 149: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1896 - accuracy: 0.9217 - val_loss: 0.3612 - val_accuracy: 0.8692\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1541 - accuracy: 0.9355\n",
      "Epoch 150: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1874 - accuracy: 0.9232 - val_loss: 0.3302 - val_accuracy: 0.8754\n",
      "Epoch 151/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2343 - accuracy: 0.9032\n",
      "Epoch 151: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2077 - accuracy: 0.9153 - val_loss: 0.3634 - val_accuracy: 0.8692\n",
      "Epoch 152/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1526 - accuracy: 0.9355\n",
      "Epoch 152: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2017 - accuracy: 0.9163 - val_loss: 0.3341 - val_accuracy: 0.8700\n",
      "Epoch 153/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1567 - accuracy: 0.9274\n",
      "Epoch 153: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1897 - accuracy: 0.9238 - val_loss: 0.3468 - val_accuracy: 0.8715\n",
      "Epoch 154/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1432 - accuracy: 0.9597\n",
      "Epoch 154: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1823 - accuracy: 0.9271 - val_loss: 0.3348 - val_accuracy: 0.8715\n",
      "Epoch 155/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1827 - accuracy: 0.9261\n",
      "Epoch 155: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.9261 - val_loss: 0.3287 - val_accuracy: 0.8738\n",
      "Epoch 156/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1854 - accuracy: 0.9113\n",
      "Epoch 156: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9259 - val_loss: 0.3804 - val_accuracy: 0.8654\n",
      "Epoch 157/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1216 - accuracy: 0.9435\n",
      "Epoch 157: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1933 - accuracy: 0.9253 - val_loss: 0.3553 - val_accuracy: 0.8692\n",
      "Epoch 158/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1232 - accuracy: 0.9597\n",
      "Epoch 158: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.9271 - val_loss: 0.3685 - val_accuracy: 0.8677\n",
      "Epoch 159/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1901 - accuracy: 0.9113\n",
      "Epoch 159: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1764 - accuracy: 0.9298 - val_loss: 0.3637 - val_accuracy: 0.8731\n",
      "Epoch 160/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1588 - accuracy: 0.9274\n",
      "Epoch 160: val_accuracy did not improve from 0.88846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.9225 - val_loss: 0.3592 - val_accuracy: 0.8700\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Epoch 1/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.6847 - accuracy: 0.6125 \n",
      "Epoch 1: val_accuracy improved from -inf to 0.75077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.6784 - accuracy: 0.6182 - val_loss: 0.5439 - val_accuracy: 0.7508\n",
      "Epoch 2/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.5094 - accuracy: 0.7984\n",
      "Epoch 2: val_accuracy improved from 0.75077 to 0.80692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7897 - val_loss: 0.4671 - val_accuracy: 0.8069\n",
      "Epoch 3/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.4273 - accuracy: 0.8266\n",
      "Epoch 3: val_accuracy improved from 0.80692 to 0.82846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.8266 - val_loss: 0.3992 - val_accuracy: 0.8285\n",
      "Epoch 4/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3616 - accuracy: 0.8710\n",
      "Epoch 4: val_accuracy improved from 0.82846 to 0.84231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3914 - accuracy: 0.8343 - val_loss: 0.3719 - val_accuracy: 0.8423\n",
      "Epoch 5/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3659 - accuracy: 0.8548\n",
      "Epoch 5: val_accuracy improved from 0.84231 to 0.84846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3682 - accuracy: 0.8470 - val_loss: 0.3568 - val_accuracy: 0.8485\n",
      "Epoch 6/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3131 - accuracy: 0.8790\n",
      "Epoch 6: val_accuracy improved from 0.84846 to 0.85000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3465 - accuracy: 0.8632 - val_loss: 0.3497 - val_accuracy: 0.8500\n",
      "Epoch 7/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3281 - accuracy: 0.8468\n",
      "Epoch 7: val_accuracy did not improve from 0.85000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.8643 - val_loss: 0.3447 - val_accuracy: 0.8500\n",
      "Epoch 8/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2822 - accuracy: 0.9113\n",
      "Epoch 8: val_accuracy did not improve from 0.85000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8690 - val_loss: 0.3505 - val_accuracy: 0.8492\n",
      "Epoch 9/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3260 - accuracy: 0.8871\n",
      "Epoch 9: val_accuracy improved from 0.85000 to 0.85462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8595 - val_loss: 0.3384 - val_accuracy: 0.8546\n",
      "Epoch 10/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2662 - accuracy: 0.9032\n",
      "Epoch 10: val_accuracy improved from 0.85462 to 0.86077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3241 - accuracy: 0.8692 - val_loss: 0.3396 - val_accuracy: 0.8608\n",
      "Epoch 11/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3236 - accuracy: 0.8710\n",
      "Epoch 11: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.8693 - val_loss: 0.3366 - val_accuracy: 0.8538\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2627 - accuracy: 0.8710\n",
      "Epoch 12: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8707 - val_loss: 0.3309 - val_accuracy: 0.8600\n",
      "Epoch 13/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3314 - accuracy: 0.8710\n",
      "Epoch 13: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8726 - val_loss: 0.3319 - val_accuracy: 0.8600\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3278 - accuracy: 0.8952\n",
      "Epoch 14: val_accuracy improved from 0.86077 to 0.86308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8690 - val_loss: 0.3278 - val_accuracy: 0.8631\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2678 - accuracy: 0.8790\n",
      "Epoch 15: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8715 - val_loss: 0.3251 - val_accuracy: 0.8585\n",
      "Epoch 16/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2970 - accuracy: 0.9032\n",
      "Epoch 16: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8745 - val_loss: 0.3368 - val_accuracy: 0.8577\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2979 - accuracy: 0.8871\n",
      "Epoch 17: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 0.8761 - val_loss: 0.3230 - val_accuracy: 0.8562\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2445 - accuracy: 0.8952\n",
      "Epoch 18: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3027 - accuracy: 0.8747 - val_loss: 0.3222 - val_accuracy: 0.8615\n",
      "Epoch 19/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3380 - accuracy: 0.8468\n",
      "Epoch 19: val_accuracy improved from 0.86308 to 0.86692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8745 - val_loss: 0.3223 - val_accuracy: 0.8669\n",
      "Epoch 20/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2995 - accuracy: 0.8755\n",
      "Epoch 20: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2984 - accuracy: 0.8757 - val_loss: 0.3227 - val_accuracy: 0.8608\n",
      "Epoch 21/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2274 - accuracy: 0.9274\n",
      "Epoch 21: val_accuracy improved from 0.86692 to 0.86923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2898 - accuracy: 0.8817 - val_loss: 0.3173 - val_accuracy: 0.8692\n",
      "Epoch 22/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2966 - accuracy: 0.8775\n",
      "Epoch 22: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2979 - accuracy: 0.8759 - val_loss: 0.3280 - val_accuracy: 0.8569\n",
      "Epoch 23/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2948 - accuracy: 0.8741\n",
      "Epoch 23: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.8742 - val_loss: 0.3158 - val_accuracy: 0.8654\n",
      "Epoch 24/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3056 - accuracy: 0.8387\n",
      "Epoch 24: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2852 - accuracy: 0.8795 - val_loss: 0.3415 - val_accuracy: 0.8485\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3190 - accuracy: 0.8710\n",
      "Epoch 25: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2868 - accuracy: 0.8817 - val_loss: 0.3150 - val_accuracy: 0.8615\n",
      "Epoch 26/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2761 - accuracy: 0.8871\n",
      "Epoch 26: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2784 - accuracy: 0.8842 - val_loss: 0.3293 - val_accuracy: 0.8554\n",
      "Epoch 27/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4045 - accuracy: 0.8145\n",
      "Epoch 27: val_accuracy improved from 0.86923 to 0.87538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2851 - accuracy: 0.8790 - val_loss: 0.3082 - val_accuracy: 0.8754\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2192 - accuracy: 0.9355\n",
      "Epoch 28: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2791 - accuracy: 0.8855 - val_loss: 0.3081 - val_accuracy: 0.8708\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2708 - accuracy: 0.8871\n",
      "Epoch 29: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2799 - accuracy: 0.8824 - val_loss: 0.3063 - val_accuracy: 0.8738\n",
      "Epoch 30/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2216 - accuracy: 0.9194\n",
      "Epoch 30: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2712 - accuracy: 0.8867 - val_loss: 0.3065 - val_accuracy: 0.8754\n",
      "Epoch 31/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2359 - accuracy: 0.8871\n",
      "Epoch 31: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2823 - accuracy: 0.8819 - val_loss: 0.3764 - val_accuracy: 0.8369\n",
      "Epoch 32/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3657 - accuracy: 0.8468\n",
      "Epoch 32: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2761 - accuracy: 0.8859 - val_loss: 0.3128 - val_accuracy: 0.8700\n",
      "Epoch 33/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2108 - accuracy: 0.8871\n",
      "Epoch 33: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2742 - accuracy: 0.8855 - val_loss: 0.3065 - val_accuracy: 0.8723\n",
      "Epoch 34/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3023 - accuracy: 0.8710\n",
      "Epoch 34: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2736 - accuracy: 0.8909 - val_loss: 0.3419 - val_accuracy: 0.8577\n",
      "Epoch 35/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3150 - accuracy: 0.8629\n",
      "Epoch 35: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2750 - accuracy: 0.8867 - val_loss: 0.3107 - val_accuracy: 0.8738\n",
      "Epoch 36/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3284 - accuracy: 0.8952\n",
      "Epoch 36: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2636 - accuracy: 0.8915 - val_loss: 0.3014 - val_accuracy: 0.8738\n",
      "Epoch 37/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2566 - accuracy: 0.8710\n",
      "Epoch 37: val_accuracy improved from 0.87538 to 0.87692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2708 - accuracy: 0.8884 - val_loss: 0.3053 - val_accuracy: 0.8769\n",
      "Epoch 38/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2146 - accuracy: 0.8871\n",
      "Epoch 38: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2717 - accuracy: 0.8863 - val_loss: 0.3203 - val_accuracy: 0.8669\n",
      "Epoch 39/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2668 - accuracy: 0.8895\n",
      "Epoch 39: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.8890 - val_loss: 0.3080 - val_accuracy: 0.8700\n",
      "Epoch 40/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2619 - accuracy: 0.8945\n",
      "Epoch 40: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2658 - accuracy: 0.8928 - val_loss: 0.3009 - val_accuracy: 0.8769\n",
      "Epoch 41/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2912 - accuracy: 0.8710\n",
      "Epoch 41: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2636 - accuracy: 0.8919 - val_loss: 0.3177 - val_accuracy: 0.8608\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2506 - accuracy: 0.8952\n",
      "Epoch 42: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2645 - accuracy: 0.8917 - val_loss: 0.3025 - val_accuracy: 0.8708\n",
      "Epoch 43/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2670 - accuracy: 0.8952\n",
      "Epoch 43: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.8903 - val_loss: 0.3144 - val_accuracy: 0.8715\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2421 - accuracy: 0.8871\n",
      "Epoch 44: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2718 - accuracy: 0.8840 - val_loss: 0.3284 - val_accuracy: 0.8600\n",
      "Epoch 45/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2154 - accuracy: 0.9113\n",
      "Epoch 45: val_accuracy improved from 0.87692 to 0.87769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.8953 - val_loss: 0.3071 - val_accuracy: 0.8777\n",
      "Epoch 46/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2944 - accuracy: 0.8710\n",
      "Epoch 46: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2745 - accuracy: 0.8853 - val_loss: 0.3044 - val_accuracy: 0.8723\n",
      "Epoch 47/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2309 - accuracy: 0.9032\n",
      "Epoch 47: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2689 - accuracy: 0.8830 - val_loss: 0.3264 - val_accuracy: 0.8638\n",
      "Epoch 48/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1987 - accuracy: 0.9113\n",
      "Epoch 48: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2562 - accuracy: 0.8924 - val_loss: 0.2945 - val_accuracy: 0.8762\n",
      "Epoch 49/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2725 - accuracy: 0.8710\n",
      "Epoch 49: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2542 - accuracy: 0.8949 - val_loss: 0.2999 - val_accuracy: 0.8746\n",
      "Epoch 50/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2448 - accuracy: 0.9032\n",
      "Epoch 50: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2558 - accuracy: 0.8928 - val_loss: 0.2973 - val_accuracy: 0.8769\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1815 - accuracy: 0.9274\n",
      "Epoch 51: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.9036 - val_loss: 0.3239 - val_accuracy: 0.8654\n",
      "Epoch 52/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2499 - accuracy: 0.8952\n",
      "Epoch 52: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2561 - accuracy: 0.8980 - val_loss: 0.3008 - val_accuracy: 0.8738\n",
      "Epoch 53/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2493 - accuracy: 0.9194\n",
      "Epoch 53: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.8971 - val_loss: 0.3115 - val_accuracy: 0.8738\n",
      "Epoch 54/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2297 - accuracy: 0.9194\n",
      "Epoch 54: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.8997 - val_loss: 0.3062 - val_accuracy: 0.8777\n",
      "Epoch 55/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1922 - accuracy: 0.9194\n",
      "Epoch 55: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.8976 - val_loss: 0.3087 - val_accuracy: 0.8715\n",
      "Epoch 56/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3061 - accuracy: 0.8710\n",
      "Epoch 56: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.8984 - val_loss: 0.3354 - val_accuracy: 0.8585\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2477 - accuracy: 0.8952\n",
      "Epoch 57: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8994 - val_loss: 0.3079 - val_accuracy: 0.8723\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2668 - accuracy: 0.8892\n",
      "Epoch 58: val_accuracy improved from 0.87769 to 0.87923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2668 - accuracy: 0.8892 - val_loss: 0.2983 - val_accuracy: 0.8792\n",
      "Epoch 59/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2411 - accuracy: 0.9036\n",
      "Epoch 59: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2414 - accuracy: 0.9034 - val_loss: 0.3008 - val_accuracy: 0.8731\n",
      "Epoch 60/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2374 - accuracy: 0.9003\n",
      "Epoch 60: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.9001 - val_loss: 0.2997 - val_accuracy: 0.8769\n",
      "Epoch 61/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2429 - accuracy: 0.8991\n",
      "Epoch 61: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2426 - accuracy: 0.8992 - val_loss: 0.3133 - val_accuracy: 0.8685\n",
      "Epoch 62/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2427 - accuracy: 0.9002\n",
      "Epoch 62: val_accuracy improved from 0.87923 to 0.88000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2405 - accuracy: 0.9013 - val_loss: 0.3022 - val_accuracy: 0.8800\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2395 - accuracy: 0.9019\n",
      "Epoch 63: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2395 - accuracy: 0.9019 - val_loss: 0.2961 - val_accuracy: 0.8746\n",
      "Epoch 64/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2350 - accuracy: 0.9079\n",
      "Epoch 64: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2352 - accuracy: 0.9076 - val_loss: 0.2993 - val_accuracy: 0.8746\n",
      "Epoch 65/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2455 - accuracy: 0.9032\n",
      "Epoch 65: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2413 - accuracy: 0.9015 - val_loss: 0.2991 - val_accuracy: 0.8754\n",
      "Epoch 66/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2120 - accuracy: 0.9274\n",
      "Epoch 66: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.9024 - val_loss: 0.2927 - val_accuracy: 0.8785\n",
      "Epoch 67/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2625 - accuracy: 0.9113\n",
      "Epoch 67: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2355 - accuracy: 0.9026 - val_loss: 0.3046 - val_accuracy: 0.8731\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2745 - accuracy: 0.8871\n",
      "Epoch 68: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2374 - accuracy: 0.9048 - val_loss: 0.3036 - val_accuracy: 0.8723\n",
      "Epoch 69/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2752 - accuracy: 0.9032\n",
      "Epoch 69: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2352 - accuracy: 0.9053 - val_loss: 0.3124 - val_accuracy: 0.8669\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1496 - accuracy: 0.9355\n",
      "Epoch 70: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2356 - accuracy: 0.9023 - val_loss: 0.3025 - val_accuracy: 0.8723\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2169 - accuracy: 0.9032\n",
      "Epoch 71: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2386 - accuracy: 0.8990 - val_loss: 0.3036 - val_accuracy: 0.8746\n",
      "Epoch 72/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2409 - accuracy: 0.9004\n",
      "Epoch 72: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2352 - accuracy: 0.9046 - val_loss: 0.2982 - val_accuracy: 0.8762\n",
      "Epoch 73/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2278 - accuracy: 0.8790\n",
      "Epoch 73: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2317 - accuracy: 0.9046 - val_loss: 0.3081 - val_accuracy: 0.8762\n",
      "Epoch 74/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2643 - accuracy: 0.8952\n",
      "Epoch 74: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2381 - accuracy: 0.9028 - val_loss: 0.3037 - val_accuracy: 0.8731\n",
      "Epoch 75/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1905 - accuracy: 0.9274\n",
      "Epoch 75: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2385 - accuracy: 0.8992 - val_loss: 0.3118 - val_accuracy: 0.8762\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1947 - accuracy: 0.9194\n",
      "Epoch 76: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2289 - accuracy: 0.9028 - val_loss: 0.3227 - val_accuracy: 0.8662\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2570 - accuracy: 0.8871\n",
      "Epoch 77: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2376 - accuracy: 0.9024 - val_loss: 0.3668 - val_accuracy: 0.8415\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2134 - accuracy: 0.9194\n",
      "Epoch 78: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2307 - accuracy: 0.9088 - val_loss: 0.3224 - val_accuracy: 0.8762\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1846 - accuracy: 0.9355\n",
      "Epoch 79: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2335 - accuracy: 0.9055 - val_loss: 0.2996 - val_accuracy: 0.8738\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3534 - accuracy: 0.8145\n",
      "Epoch 80: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2254 - accuracy: 0.9065 - val_loss: 0.3047 - val_accuracy: 0.8777\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2546 - accuracy: 0.8952\n",
      "Epoch 81: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2297 - accuracy: 0.9073 - val_loss: 0.2945 - val_accuracy: 0.8792\n",
      "Epoch 82/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1804 - accuracy: 0.9274\n",
      "Epoch 82: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2383 - accuracy: 0.9024 - val_loss: 0.3050 - val_accuracy: 0.8769\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2110 - accuracy: 0.9032\n",
      "Epoch 83: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2240 - accuracy: 0.9088 - val_loss: 0.3244 - val_accuracy: 0.8715\n",
      "Epoch 84/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2607 - accuracy: 0.8790\n",
      "Epoch 84: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2253 - accuracy: 0.9084 - val_loss: 0.3251 - val_accuracy: 0.8700\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2282 - accuracy: 0.9274\n",
      "Epoch 85: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2428 - accuracy: 0.9011 - val_loss: 0.3583 - val_accuracy: 0.8492\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2780 - accuracy: 0.8790\n",
      "Epoch 86: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2324 - accuracy: 0.9040 - val_loss: 0.3092 - val_accuracy: 0.8685\n",
      "Epoch 87/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2106 - accuracy: 0.9113\n",
      "Epoch 87: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.9042 - val_loss: 0.3019 - val_accuracy: 0.8731\n",
      "Epoch 88/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1529 - accuracy: 0.9516\n",
      "Epoch 88: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2251 - accuracy: 0.9034 - val_loss: 0.3090 - val_accuracy: 0.8746\n",
      "Epoch 89/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2356 - accuracy: 0.8952\n",
      "Epoch 89: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2188 - accuracy: 0.9126 - val_loss: 0.3259 - val_accuracy: 0.8677\n",
      "Epoch 90/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2956 - accuracy: 0.8710\n",
      "Epoch 90: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2204 - accuracy: 0.9107 - val_loss: 0.3103 - val_accuracy: 0.8731\n",
      "Epoch 91/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2611 - accuracy: 0.9194\n",
      "Epoch 91: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2219 - accuracy: 0.9090 - val_loss: 0.3236 - val_accuracy: 0.8669\n",
      "Epoch 92/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2358 - accuracy: 0.9113\n",
      "Epoch 92: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2252 - accuracy: 0.9105 - val_loss: 0.3066 - val_accuracy: 0.8731\n",
      "Epoch 93/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1641 - accuracy: 0.9194\n",
      "Epoch 93: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2206 - accuracy: 0.9082 - val_loss: 0.3104 - val_accuracy: 0.8723\n",
      "Epoch 94/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1691 - accuracy: 0.9516\n",
      "Epoch 94: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2158 - accuracy: 0.9123 - val_loss: 0.3154 - val_accuracy: 0.8754\n",
      "Epoch 95/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3063 - accuracy: 0.8790\n",
      "Epoch 95: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2207 - accuracy: 0.9098 - val_loss: 0.3188 - val_accuracy: 0.8692\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1418 - accuracy: 0.9435\n",
      "Epoch 96: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2187 - accuracy: 0.9113 - val_loss: 0.3288 - val_accuracy: 0.8685\n",
      "Epoch 97/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2309 - accuracy: 0.8790\n",
      "Epoch 97: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2269 - accuracy: 0.9071 - val_loss: 0.3113 - val_accuracy: 0.8723\n",
      "Epoch 98/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3228 - accuracy: 0.8548\n",
      "Epoch 98: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2194 - accuracy: 0.9088 - val_loss: 0.3071 - val_accuracy: 0.8731\n",
      "Epoch 99/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1633 - accuracy: 0.9435\n",
      "Epoch 99: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2287 - accuracy: 0.9042 - val_loss: 0.3206 - val_accuracy: 0.8723\n",
      "Epoch 100/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2227 - accuracy: 0.9089\n",
      "Epoch 100: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2187 - accuracy: 0.9109 - val_loss: 0.3213 - val_accuracy: 0.8708\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1598 - accuracy: 0.9516\n",
      "Epoch 101: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2093 - accuracy: 0.9169 - val_loss: 0.3402 - val_accuracy: 0.8685\n",
      "Epoch 102/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2144 - accuracy: 0.9138\n",
      "Epoch 102: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2150 - accuracy: 0.9136 - val_loss: 0.3208 - val_accuracy: 0.8738\n",
      "Epoch 103/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2011 - accuracy: 0.9032\n",
      "Epoch 103: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2148 - accuracy: 0.9128 - val_loss: 0.3433 - val_accuracy: 0.8646\n",
      "Epoch 104/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2713 - accuracy: 0.8871\n",
      "Epoch 104: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.9123 - val_loss: 0.3181 - val_accuracy: 0.8685\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2181 - accuracy: 0.8952\n",
      "Epoch 105: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2179 - accuracy: 0.9098 - val_loss: 0.3612 - val_accuracy: 0.8654\n",
      "Epoch 106/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2164 - accuracy: 0.9113\n",
      "Epoch 106: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2105 - accuracy: 0.9140 - val_loss: 0.3150 - val_accuracy: 0.8769\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1746 - accuracy: 0.9194\n",
      "Epoch 107: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2098 - accuracy: 0.9173 - val_loss: 0.3137 - val_accuracy: 0.8746\n",
      "Epoch 108/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1621 - accuracy: 0.9435\n",
      "Epoch 108: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2082 - accuracy: 0.9157 - val_loss: 0.3405 - val_accuracy: 0.8600\n",
      "Epoch 109/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2343 - accuracy: 0.8790\n",
      "Epoch 109: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.9082 - val_loss: 0.3188 - val_accuracy: 0.8723\n",
      "Epoch 110/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1700 - accuracy: 0.9274\n",
      "Epoch 110: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2080 - accuracy: 0.9138 - val_loss: 0.3135 - val_accuracy: 0.8700\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1659 - accuracy: 0.9355\n",
      "Epoch 111: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2129 - accuracy: 0.9144 - val_loss: 0.3149 - val_accuracy: 0.8723\n",
      "Epoch 112/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2069 - accuracy: 0.9274\n",
      "Epoch 112: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2068 - accuracy: 0.9159 - val_loss: 0.3291 - val_accuracy: 0.8754\n",
      "Epoch 113/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1096 - accuracy: 0.9677\n",
      "Epoch 113: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2089 - accuracy: 0.9124 - val_loss: 0.3276 - val_accuracy: 0.8692\n",
      "Epoch 114/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2320 - accuracy: 0.8790\n",
      "Epoch 114: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2061 - accuracy: 0.9171 - val_loss: 0.3154 - val_accuracy: 0.8677\n",
      "Epoch 115/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1363 - accuracy: 0.9435\n",
      "Epoch 115: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2016 - accuracy: 0.9213 - val_loss: 0.3374 - val_accuracy: 0.8662\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2034 - accuracy: 0.9113\n",
      "Epoch 116: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2049 - accuracy: 0.9155 - val_loss: 0.3326 - val_accuracy: 0.8708\n",
      "Epoch 117/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1879 - accuracy: 0.9194\n",
      "Epoch 117: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2010 - accuracy: 0.9171 - val_loss: 0.3301 - val_accuracy: 0.8692\n",
      "Epoch 118/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2035 - accuracy: 0.9177\n",
      "Epoch 118: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2071 - accuracy: 0.9159 - val_loss: 0.3331 - val_accuracy: 0.8723\n",
      "Epoch 119/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1704 - accuracy: 0.9274\n",
      "Epoch 119: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2058 - accuracy: 0.9130 - val_loss: 0.3332 - val_accuracy: 0.8731\n",
      "Epoch 120/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1994 - accuracy: 0.9194\n",
      "Epoch 120: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2002 - accuracy: 0.9184 - val_loss: 0.3313 - val_accuracy: 0.8685\n",
      "Epoch 121/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2053 - accuracy: 0.9032\n",
      "Epoch 121: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.9109 - val_loss: 0.3280 - val_accuracy: 0.8769\n",
      "Epoch 122/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2011 - accuracy: 0.9203\n",
      "Epoch 122: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2047 - accuracy: 0.9178 - val_loss: 0.3332 - val_accuracy: 0.8700\n",
      "Epoch 123/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1948 - accuracy: 0.9191\n",
      "Epoch 123: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1968 - accuracy: 0.9186 - val_loss: 0.3479 - val_accuracy: 0.8646\n",
      "Epoch 124/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.1931 - accuracy: 0.9209\n",
      "Epoch 124: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1980 - accuracy: 0.9225 - val_loss: 0.3280 - val_accuracy: 0.8700\n",
      "Epoch 125/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1977 - accuracy: 0.9194\n",
      "Epoch 125: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.9198 - val_loss: 0.3344 - val_accuracy: 0.8669\n",
      "Epoch 126/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1917 - accuracy: 0.9266\n",
      "Epoch 126: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.9261 - val_loss: 0.3350 - val_accuracy: 0.8723\n",
      "Epoch 127/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2366 - accuracy: 0.8710\n",
      "Epoch 127: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2020 - accuracy: 0.9157 - val_loss: 0.3358 - val_accuracy: 0.8685\n",
      "Epoch 128/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2076 - accuracy: 0.9032\n",
      "Epoch 128: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2065 - accuracy: 0.9148 - val_loss: 0.3378 - val_accuracy: 0.8600\n",
      "Epoch 129/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2050 - accuracy: 0.9194\n",
      "Epoch 129: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2022 - accuracy: 0.9198 - val_loss: 0.3342 - val_accuracy: 0.8746\n",
      "Epoch 130/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2129 - accuracy: 0.8952\n",
      "Epoch 130: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1974 - accuracy: 0.9194 - val_loss: 0.3496 - val_accuracy: 0.8708\n",
      "Epoch 131/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2208 - accuracy: 0.9355\n",
      "Epoch 131: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1942 - accuracy: 0.9205 - val_loss: 0.3394 - val_accuracy: 0.8662\n",
      "Epoch 132/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2004 - accuracy: 0.9355\n",
      "Epoch 132: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1970 - accuracy: 0.9211 - val_loss: 0.3831 - val_accuracy: 0.8592\n",
      "Epoch 133/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1470 - accuracy: 0.9274\n",
      "Epoch 133: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2041 - accuracy: 0.9151 - val_loss: 0.3321 - val_accuracy: 0.8715\n",
      "Epoch 134/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1833 - accuracy: 0.9355\n",
      "Epoch 134: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1969 - accuracy: 0.9190 - val_loss: 0.4118 - val_accuracy: 0.8585\n",
      "Epoch 135/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3560 - accuracy: 0.8468\n",
      "Epoch 135: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1961 - accuracy: 0.9200 - val_loss: 0.3373 - val_accuracy: 0.8662\n",
      "Epoch 136/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1439 - accuracy: 0.9597\n",
      "Epoch 136: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1998 - accuracy: 0.9165 - val_loss: 0.3549 - val_accuracy: 0.8715\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1225 - accuracy: 0.9516\n",
      "Epoch 137: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1861 - accuracy: 0.9250 - val_loss: 0.3609 - val_accuracy: 0.8662\n",
      "Epoch 138/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2020 - accuracy: 0.9032\n",
      "Epoch 138: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1938 - accuracy: 0.9219 - val_loss: 0.3390 - val_accuracy: 0.8723\n",
      "Epoch 139/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1196 - accuracy: 0.9597\n",
      "Epoch 139: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1872 - accuracy: 0.9259 - val_loss: 0.3406 - val_accuracy: 0.8692\n",
      "Epoch 140/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1737 - accuracy: 0.9194\n",
      "Epoch 140: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1884 - accuracy: 0.9230 - val_loss: 0.3454 - val_accuracy: 0.8677\n",
      "Epoch 141/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1492 - accuracy: 0.9355\n",
      "Epoch 141: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1848 - accuracy: 0.9248 - val_loss: 0.3527 - val_accuracy: 0.8662\n",
      "Epoch 142/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1773 - accuracy: 0.9274\n",
      "Epoch 142: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1848 - accuracy: 0.9244 - val_loss: 0.3519 - val_accuracy: 0.8638\n",
      "Epoch 143/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1332 - accuracy: 0.9597\n",
      "Epoch 143: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.9211 - val_loss: 0.3542 - val_accuracy: 0.8669\n",
      "Epoch 144/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1326 - accuracy: 0.9597\n",
      "Epoch 144: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1877 - accuracy: 0.9230 - val_loss: 0.3433 - val_accuracy: 0.8731\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1164 - accuracy: 0.9435\n",
      "Epoch 145: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1836 - accuracy: 0.9267 - val_loss: 0.3504 - val_accuracy: 0.8685\n",
      "Epoch 146/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2769 - accuracy: 0.9113\n",
      "Epoch 146: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1835 - accuracy: 0.9278 - val_loss: 0.3589 - val_accuracy: 0.8685\n",
      "Epoch 147/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1728 - accuracy: 0.9032\n",
      "Epoch 147: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1857 - accuracy: 0.9269 - val_loss: 0.3563 - val_accuracy: 0.8738\n",
      "Epoch 148/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1453 - accuracy: 0.9516\n",
      "Epoch 148: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.9261 - val_loss: 0.3603 - val_accuracy: 0.8677\n",
      "Epoch 149/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1772 - accuracy: 0.9194\n",
      "Epoch 149: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1818 - accuracy: 0.9284 - val_loss: 0.3597 - val_accuracy: 0.8654\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1607 - accuracy: 0.9274\n",
      "Epoch 150: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.9288 - val_loss: 0.3611 - val_accuracy: 0.8646\n",
      "Epoch 151/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2161 - accuracy: 0.8952\n",
      "Epoch 151: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.9282 - val_loss: 0.3735 - val_accuracy: 0.8723\n",
      "Epoch 152/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2008 - accuracy: 0.9153\n",
      "Epoch 152: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9169 - val_loss: 0.3614 - val_accuracy: 0.8746\n",
      "Epoch 153/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1492 - accuracy: 0.9274\n",
      "Epoch 153: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1742 - accuracy: 0.9300 - val_loss: 0.3575 - val_accuracy: 0.8731\n",
      "Epoch 154/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 0.9346\n",
      "Epoch 154: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1694 - accuracy: 0.9346 - val_loss: 0.3728 - val_accuracy: 0.8662\n",
      "Epoch 155/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1540 - accuracy: 0.9597\n",
      "Epoch 155: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1716 - accuracy: 0.9298 - val_loss: 0.3654 - val_accuracy: 0.8731\n",
      "Epoch 156/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1801 - accuracy: 0.9247\n",
      "Epoch 156: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1806 - accuracy: 0.9242 - val_loss: 0.3688 - val_accuracy: 0.8677\n",
      "Epoch 157/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1692 - accuracy: 0.9194\n",
      "Epoch 157: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1730 - accuracy: 0.9300 - val_loss: 0.3715 - val_accuracy: 0.8646\n",
      "Epoch 158/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1674 - accuracy: 0.9342\n",
      "Epoch 158: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1674 - accuracy: 0.9342 - val_loss: 0.3640 - val_accuracy: 0.8685\n",
      "Epoch 159/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1785 - accuracy: 0.9278\n",
      "Epoch 159: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.9284 - val_loss: 0.3770 - val_accuracy: 0.8708\n",
      "Epoch 160/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1716 - accuracy: 0.9317\n",
      "Epoch 160: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1702 - accuracy: 0.9323 - val_loss: 0.3976 - val_accuracy: 0.8692\n",
      "Epoch 161/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1625 - accuracy: 0.9435\n",
      "Epoch 161: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1690 - accuracy: 0.9328 - val_loss: 0.3842 - val_accuracy: 0.8646\n",
      "Epoch 162/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1361 - accuracy: 0.9516\n",
      "Epoch 162: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1636 - accuracy: 0.9332 - val_loss: 0.3743 - val_accuracy: 0.8685\n",
      "Epoch 163/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.0983 - accuracy: 0.9597\n",
      "Epoch 163: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1576 - accuracy: 0.9384 - val_loss: 0.3791 - val_accuracy: 0.8615\n",
      "Epoch 164/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1275 - accuracy: 0.9274\n",
      "Epoch 164: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1746 - accuracy: 0.9261 - val_loss: 0.3964 - val_accuracy: 0.8600\n",
      "Epoch 165/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1823 - accuracy: 0.9271\n",
      "Epoch 165: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1823 - accuracy: 0.9271 - val_loss: 0.3720 - val_accuracy: 0.8608\n",
      "Epoch 166/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1700 - accuracy: 0.9302\n",
      "Epoch 166: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1700 - accuracy: 0.9302 - val_loss: 0.3923 - val_accuracy: 0.8677\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 32s - loss: 4.9581 - accuracy: 0.3871\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 1.0476 - accuracy: 0.5382 - val_loss: 0.6297 - val_accuracy: 0.6277\n",
      "Epoch 2/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.6231 - accuracy: 0.6290\n",
      "Epoch 2: val_accuracy improved from 0.62769 to 0.81923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.7483 - val_loss: 0.4580 - val_accuracy: 0.8192\n",
      "Epoch 3/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4439 - accuracy: 0.8548\n",
      "Epoch 3: val_accuracy improved from 0.81923 to 0.84308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8297 - val_loss: 0.3922 - val_accuracy: 0.8431\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3780 - accuracy: 0.8484\n",
      "Epoch 4: val_accuracy improved from 0.84308 to 0.84538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3780 - accuracy: 0.8484 - val_loss: 0.3593 - val_accuracy: 0.8454\n",
      "Epoch 5/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3574 - accuracy: 0.8546\n",
      "Epoch 5: val_accuracy improved from 0.84538 to 0.85231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3569 - accuracy: 0.8545 - val_loss: 0.3515 - val_accuracy: 0.8523\n",
      "Epoch 6/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.3487 - accuracy: 0.8553\n",
      "Epoch 6: val_accuracy did not improve from 0.85231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3496 - accuracy: 0.8526 - val_loss: 0.3475 - val_accuracy: 0.8485\n",
      "Epoch 7/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.3329 - accuracy: 0.8673\n",
      "Epoch 7: val_accuracy improved from 0.85231 to 0.85846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3349 - accuracy: 0.8642 - val_loss: 0.3345 - val_accuracy: 0.8585\n",
      "Epoch 8/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3323 - accuracy: 0.8631\n",
      "Epoch 8: val_accuracy did not improve from 0.85846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8618 - val_loss: 0.3452 - val_accuracy: 0.8538\n",
      "Epoch 9/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3339 - accuracy: 0.9194\n",
      "Epoch 9: val_accuracy did not improve from 0.85846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8659 - val_loss: 0.3417 - val_accuracy: 0.8500\n",
      "Epoch 10/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2642 - accuracy: 0.8952\n",
      "Epoch 10: val_accuracy did not improve from 0.85846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8663 - val_loss: 0.3289 - val_accuracy: 0.8585\n",
      "Epoch 11/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3197 - accuracy: 0.8629\n",
      "Epoch 11: val_accuracy improved from 0.85846 to 0.86154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8699 - val_loss: 0.3284 - val_accuracy: 0.8615\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2769 - accuracy: 0.8952\n",
      "Epoch 12: val_accuracy improved from 0.86154 to 0.86385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8713 - val_loss: 0.3317 - val_accuracy: 0.8638\n",
      "Epoch 13/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.3157 - accuracy: 0.8701\n",
      "Epoch 13: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3151 - accuracy: 0.8692 - val_loss: 0.3481 - val_accuracy: 0.8469\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3570 - accuracy: 0.8548\n",
      "Epoch 14: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8580 - val_loss: 0.3445 - val_accuracy: 0.8477\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4278 - accuracy: 0.8548\n",
      "Epoch 15: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8536 - val_loss: 0.3278 - val_accuracy: 0.8638\n",
      "Epoch 16/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1996 - accuracy: 0.9194\n",
      "Epoch 16: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.8551 - val_loss: 0.3302 - val_accuracy: 0.8615\n",
      "Epoch 17/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3104 - accuracy: 0.8698\n",
      "Epoch 17: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8692 - val_loss: 0.3217 - val_accuracy: 0.8623\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2447 - accuracy: 0.9032\n",
      "Epoch 18: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.8732 - val_loss: 0.3301 - val_accuracy: 0.8492\n",
      "Epoch 19/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3976 - accuracy: 0.8065\n",
      "Epoch 19: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3015 - accuracy: 0.8774 - val_loss: 0.3330 - val_accuracy: 0.8615\n",
      "Epoch 20/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3066 - accuracy: 0.8790\n",
      "Epoch 20: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3026 - accuracy: 0.8720 - val_loss: 0.3233 - val_accuracy: 0.8631\n",
      "Epoch 21/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1746 - accuracy: 0.9355\n",
      "Epoch 21: val_accuracy improved from 0.86385 to 0.86538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2984 - accuracy: 0.8747 - val_loss: 0.3247 - val_accuracy: 0.8654\n",
      "Epoch 22/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3000 - accuracy: 0.8737\n",
      "Epoch 22: val_accuracy did not improve from 0.86538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3005 - accuracy: 0.8730 - val_loss: 0.3865 - val_accuracy: 0.8285\n",
      "Epoch 23/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2937 - accuracy: 0.8767\n",
      "Epoch 23: val_accuracy improved from 0.86538 to 0.86692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2965 - accuracy: 0.8761 - val_loss: 0.3163 - val_accuracy: 0.8669\n",
      "Epoch 24/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2972 - accuracy: 0.8745\n",
      "Epoch 24: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2987 - accuracy: 0.8744 - val_loss: 0.3193 - val_accuracy: 0.8615\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2914 - accuracy: 0.8629\n",
      "Epoch 25: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.8786 - val_loss: 0.3184 - val_accuracy: 0.8585\n",
      "Epoch 26/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2591 - accuracy: 0.8790\n",
      "Epoch 26: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2901 - accuracy: 0.8767 - val_loss: 0.4553 - val_accuracy: 0.8038\n",
      "Epoch 27/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4159 - accuracy: 0.7984\n",
      "Epoch 27: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8718 - val_loss: 0.3199 - val_accuracy: 0.8631\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3062 - accuracy: 0.8871\n",
      "Epoch 28: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2878 - accuracy: 0.8849 - val_loss: 0.3171 - val_accuracy: 0.8662\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2966 - accuracy: 0.8468\n",
      "Epoch 29: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2878 - accuracy: 0.8838 - val_loss: 0.3206 - val_accuracy: 0.8577\n",
      "Epoch 30/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2382 - accuracy: 0.9274\n",
      "Epoch 30: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2831 - accuracy: 0.8863 - val_loss: 0.3132 - val_accuracy: 0.8646\n",
      "Epoch 31/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2912 - accuracy: 0.8790\n",
      "Epoch 31: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2898 - accuracy: 0.8803 - val_loss: 0.3109 - val_accuracy: 0.8654\n",
      "Epoch 32/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2833 - accuracy: 0.8468\n",
      "Epoch 32: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3029 - accuracy: 0.8709 - val_loss: 0.3306 - val_accuracy: 0.8531\n",
      "Epoch 33/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2794 - accuracy: 0.9032\n",
      "Epoch 33: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2854 - accuracy: 0.8840 - val_loss: 0.3349 - val_accuracy: 0.8546\n",
      "Epoch 34/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2785 - accuracy: 0.8875\n",
      "Epoch 34: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2769 - accuracy: 0.8892 - val_loss: 0.3232 - val_accuracy: 0.8662\n",
      "Epoch 35/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2803 - accuracy: 0.8886\n",
      "Epoch 35: val_accuracy improved from 0.86692 to 0.87000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2792 - accuracy: 0.8878 - val_loss: 0.3159 - val_accuracy: 0.8700\n",
      "Epoch 36/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3859 - accuracy: 0.8387\n",
      "Epoch 36: val_accuracy improved from 0.87000 to 0.87077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2849 - accuracy: 0.8792 - val_loss: 0.3103 - val_accuracy: 0.8708\n",
      "Epoch 37/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2292 - accuracy: 0.9355\n",
      "Epoch 37: val_accuracy improved from 0.87077 to 0.87308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2768 - accuracy: 0.8840 - val_loss: 0.3100 - val_accuracy: 0.8731\n",
      "Epoch 38/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2722 - accuracy: 0.8912\n",
      "Epoch 38: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2705 - accuracy: 0.8921 - val_loss: 0.3071 - val_accuracy: 0.8685\n",
      "Epoch 39/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2763 - accuracy: 0.8834\n",
      "Epoch 39: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2773 - accuracy: 0.8838 - val_loss: 0.3121 - val_accuracy: 0.8723\n",
      "Epoch 40/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3500 - accuracy: 0.8548\n",
      "Epoch 40: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.8882 - val_loss: 0.3158 - val_accuracy: 0.8638\n",
      "Epoch 41/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1519 - accuracy: 0.9355\n",
      "Epoch 41: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2644 - accuracy: 0.8917 - val_loss: 0.3017 - val_accuracy: 0.8708\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2497 - accuracy: 0.8387\n",
      "Epoch 42: val_accuracy improved from 0.87308 to 0.88077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2628 - accuracy: 0.8951 - val_loss: 0.3092 - val_accuracy: 0.8808\n",
      "Epoch 43/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2632 - accuracy: 0.8790\n",
      "Epoch 43: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2631 - accuracy: 0.8972 - val_loss: 0.3073 - val_accuracy: 0.8677\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2684 - accuracy: 0.9032\n",
      "Epoch 44: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2799 - accuracy: 0.8820 - val_loss: 0.3239 - val_accuracy: 0.8592\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2719 - accuracy: 0.8880\n",
      "Epoch 45: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2719 - accuracy: 0.8880 - val_loss: 0.3008 - val_accuracy: 0.8700\n",
      "Epoch 46/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3513 - accuracy: 0.8710\n",
      "Epoch 46: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2607 - accuracy: 0.8953 - val_loss: 0.3036 - val_accuracy: 0.8662\n",
      "Epoch 47/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2167 - accuracy: 0.8952\n",
      "Epoch 47: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2757 - accuracy: 0.8849 - val_loss: 0.3058 - val_accuracy: 0.8654\n",
      "Epoch 48/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2600 - accuracy: 0.8944\n",
      "Epoch 48: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2602 - accuracy: 0.8940 - val_loss: 0.3023 - val_accuracy: 0.8708\n",
      "Epoch 49/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2576 - accuracy: 0.8919\n",
      "Epoch 49: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2584 - accuracy: 0.8909 - val_loss: 0.3335 - val_accuracy: 0.8638\n",
      "Epoch 50/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1823 - accuracy: 0.9194\n",
      "Epoch 50: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2665 - accuracy: 0.8938 - val_loss: 0.3070 - val_accuracy: 0.8800\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2274 - accuracy: 0.9194\n",
      "Epoch 51: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2524 - accuracy: 0.8967 - val_loss: 0.2960 - val_accuracy: 0.8762\n",
      "Epoch 52/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2701 - accuracy: 0.8871\n",
      "Epoch 52: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.8976 - val_loss: 0.3078 - val_accuracy: 0.8762\n",
      "Epoch 53/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2567 - accuracy: 0.9274\n",
      "Epoch 53: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.9005 - val_loss: 0.2947 - val_accuracy: 0.8723\n",
      "Epoch 54/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2494 - accuracy: 0.9032\n",
      "Epoch 54: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2479 - accuracy: 0.9026 - val_loss: 0.2944 - val_accuracy: 0.8777\n",
      "Epoch 55/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1822 - accuracy: 0.9274\n",
      "Epoch 55: val_accuracy improved from 0.88077 to 0.88231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.8999 - val_loss: 0.3011 - val_accuracy: 0.8823\n",
      "Epoch 56/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2514 - accuracy: 0.9000\n",
      "Epoch 56: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.8999 - val_loss: 0.3002 - val_accuracy: 0.8738\n",
      "Epoch 57/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2488 - accuracy: 0.9002\n",
      "Epoch 57: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.9005 - val_loss: 0.2922 - val_accuracy: 0.8769\n",
      "Epoch 58/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2518 - accuracy: 0.8954\n",
      "Epoch 58: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2529 - accuracy: 0.8944 - val_loss: 0.2940 - val_accuracy: 0.8762\n",
      "Epoch 59/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2475 - accuracy: 0.8949\n",
      "Epoch 59: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2435 - accuracy: 0.8982 - val_loss: 0.3011 - val_accuracy: 0.8723\n",
      "Epoch 60/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2422 - accuracy: 0.9028\n",
      "Epoch 60: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2424 - accuracy: 0.9028 - val_loss: 0.3257 - val_accuracy: 0.8677\n",
      "Epoch 61/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2372 - accuracy: 0.9032\n",
      "Epoch 61: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2740 - accuracy: 0.8845 - val_loss: 0.3119 - val_accuracy: 0.8777\n",
      "Epoch 62/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2670 - accuracy: 0.8871\n",
      "Epoch 62: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2542 - accuracy: 0.8980 - val_loss: 0.2971 - val_accuracy: 0.8746\n",
      "Epoch 63/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2860 - accuracy: 0.8468\n",
      "Epoch 63: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2395 - accuracy: 0.9059 - val_loss: 0.2963 - val_accuracy: 0.8715\n",
      "Epoch 64/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2724 - accuracy: 0.8871\n",
      "Epoch 64: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2402 - accuracy: 0.9026 - val_loss: 0.3141 - val_accuracy: 0.8754\n",
      "Epoch 65/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2724 - accuracy: 0.8790\n",
      "Epoch 65: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2674 - accuracy: 0.8863 - val_loss: 0.2942 - val_accuracy: 0.8692\n",
      "Epoch 66/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2283 - accuracy: 0.9274\n",
      "Epoch 66: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8994 - val_loss: 0.2983 - val_accuracy: 0.8685\n",
      "Epoch 67/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2636 - accuracy: 0.8952\n",
      "Epoch 67: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2383 - accuracy: 0.9048 - val_loss: 0.3043 - val_accuracy: 0.8723\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2503 - accuracy: 0.8871\n",
      "Epoch 68: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2386 - accuracy: 0.9059 - val_loss: 0.2993 - val_accuracy: 0.8769\n",
      "Epoch 69/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2821 - accuracy: 0.9032\n",
      "Epoch 69: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2393 - accuracy: 0.9021 - val_loss: 0.3229 - val_accuracy: 0.8708\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2048 - accuracy: 0.9194\n",
      "Epoch 70: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2436 - accuracy: 0.9024 - val_loss: 0.3032 - val_accuracy: 0.8631\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2571 - accuracy: 0.8790\n",
      "Epoch 71: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.8986 - val_loss: 0.3009 - val_accuracy: 0.8792\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2357 - accuracy: 0.8952\n",
      "Epoch 72: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2356 - accuracy: 0.9059 - val_loss: 0.3009 - val_accuracy: 0.8731\n",
      "Epoch 73/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2378 - accuracy: 0.9032\n",
      "Epoch 73: val_accuracy improved from 0.88231 to 0.88308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2412 - accuracy: 0.9032 - val_loss: 0.3144 - val_accuracy: 0.8831\n",
      "Epoch 74/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2442 - accuracy: 0.9024\n",
      "Epoch 74: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2437 - accuracy: 0.9034 - val_loss: 0.2967 - val_accuracy: 0.8831\n",
      "Epoch 75/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2489 - accuracy: 0.8960\n",
      "Epoch 75: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2437 - accuracy: 0.8980 - val_loss: 0.3047 - val_accuracy: 0.8677\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2518 - accuracy: 0.8952\n",
      "Epoch 76: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2390 - accuracy: 0.9009 - val_loss: 0.3123 - val_accuracy: 0.8708\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2052 - accuracy: 0.9355\n",
      "Epoch 77: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2389 - accuracy: 0.9059 - val_loss: 0.3013 - val_accuracy: 0.8715\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1191 - accuracy: 0.9677\n",
      "Epoch 78: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2363 - accuracy: 0.9023 - val_loss: 0.3043 - val_accuracy: 0.8700\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2604 - accuracy: 0.8710\n",
      "Epoch 79: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2354 - accuracy: 0.9042 - val_loss: 0.3194 - val_accuracy: 0.8669\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2045 - accuracy: 0.9113\n",
      "Epoch 80: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2375 - accuracy: 0.9013 - val_loss: 0.3051 - val_accuracy: 0.8669\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2815 - accuracy: 0.8790\n",
      "Epoch 81: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2300 - accuracy: 0.9090 - val_loss: 0.3024 - val_accuracy: 0.8708\n",
      "Epoch 82/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2348 - accuracy: 0.9194\n",
      "Epoch 82: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.9030 - val_loss: 0.3109 - val_accuracy: 0.8692\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2273 - accuracy: 0.9355\n",
      "Epoch 83: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2242 - accuracy: 0.9096 - val_loss: 0.3015 - val_accuracy: 0.8662\n",
      "Epoch 84/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2234 - accuracy: 0.9125\n",
      "Epoch 84: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2245 - accuracy: 0.9121 - val_loss: 0.3223 - val_accuracy: 0.8638\n",
      "Epoch 85/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2355 - accuracy: 0.9022\n",
      "Epoch 85: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2343 - accuracy: 0.9021 - val_loss: 0.3220 - val_accuracy: 0.8662\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2541 - accuracy: 0.8952\n",
      "Epoch 86: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2391 - accuracy: 0.9021 - val_loss: 0.3052 - val_accuracy: 0.8777\n",
      "Epoch 87/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2397 - accuracy: 0.9274\n",
      "Epoch 87: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2294 - accuracy: 0.9074 - val_loss: 0.3058 - val_accuracy: 0.8654\n",
      "Epoch 88/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2224 - accuracy: 0.9121\n",
      "Epoch 88: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2261 - accuracy: 0.9109 - val_loss: 0.3102 - val_accuracy: 0.8715\n",
      "Epoch 89/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2563 - accuracy: 0.8925\n",
      "Epoch 89: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2558 - accuracy: 0.8928 - val_loss: 0.3498 - val_accuracy: 0.8500\n",
      "Epoch 90/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2339 - accuracy: 0.9003\n",
      "Epoch 90: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2315 - accuracy: 0.9015 - val_loss: 0.3132 - val_accuracy: 0.8677\n",
      "Epoch 91/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2042 - accuracy: 0.9113\n",
      "Epoch 91: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2287 - accuracy: 0.9076 - val_loss: 0.3236 - val_accuracy: 0.8700\n",
      "Epoch 92/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2158 - accuracy: 0.8871\n",
      "Epoch 92: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2242 - accuracy: 0.9088 - val_loss: 0.3087 - val_accuracy: 0.8692\n",
      "Epoch 93/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2118 - accuracy: 0.9113\n",
      "Epoch 93: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2152 - accuracy: 0.9124 - val_loss: 0.3188 - val_accuracy: 0.8715\n",
      "Epoch 94/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2148 - accuracy: 0.9163\n",
      "Epoch 94: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2189 - accuracy: 0.9134 - val_loss: 0.3058 - val_accuracy: 0.8723\n",
      "Epoch 95/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1729 - accuracy: 0.9516\n",
      "Epoch 95: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2310 - accuracy: 0.9040 - val_loss: 0.3007 - val_accuracy: 0.8723\n",
      "Epoch 96/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2234 - accuracy: 0.9060\n",
      "Epoch 96: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2241 - accuracy: 0.9059 - val_loss: 0.3164 - val_accuracy: 0.8654\n",
      "Epoch 97/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2244 - accuracy: 0.9085\n",
      "Epoch 97: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 0.9088 - val_loss: 0.3125 - val_accuracy: 0.8631\n",
      "Epoch 98/1000\n",
      "30/42 [====================>.........] - ETA: 0s - loss: 0.2238 - accuracy: 0.9099\n",
      "Epoch 98: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2196 - accuracy: 0.9111 - val_loss: 0.3175 - val_accuracy: 0.8685\n",
      "Epoch 99/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2092 - accuracy: 0.9167\n",
      "Epoch 99: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.9153 - val_loss: 0.3145 - val_accuracy: 0.8715\n",
      "Epoch 100/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2136 - accuracy: 0.9032\n",
      "Epoch 100: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.9049 - val_loss: 0.3215 - val_accuracy: 0.8669\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2252 - accuracy: 0.9032\n",
      "Epoch 101: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2261 - accuracy: 0.9067 - val_loss: 0.3190 - val_accuracy: 0.8708\n",
      "Epoch 102/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2595 - accuracy: 0.9194\n",
      "Epoch 102: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2133 - accuracy: 0.9157 - val_loss: 0.3206 - val_accuracy: 0.8638\n",
      "Epoch 103/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1834 - accuracy: 0.9274\n",
      "Epoch 103: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9080 - val_loss: 0.3262 - val_accuracy: 0.8715\n",
      "Epoch 104/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1328 - accuracy: 0.9435\n",
      "Epoch 104: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2143 - accuracy: 0.9140 - val_loss: 0.3266 - val_accuracy: 0.8685\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1518 - accuracy: 0.9355\n",
      "Epoch 105: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2207 - accuracy: 0.9090 - val_loss: 0.3326 - val_accuracy: 0.8638\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2252 - accuracy: 0.9071\n",
      "Epoch 106: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2252 - accuracy: 0.9071 - val_loss: 0.3217 - val_accuracy: 0.8669\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2678 - accuracy: 0.8871\n",
      "Epoch 107: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2217 - accuracy: 0.9049 - val_loss: 0.3250 - val_accuracy: 0.8662\n",
      "Epoch 108/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2601 - accuracy: 0.8871\n",
      "Epoch 108: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2167 - accuracy: 0.9119 - val_loss: 0.3501 - val_accuracy: 0.8638\n",
      "Epoch 109/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2628 - accuracy: 0.9113\n",
      "Epoch 109: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2220 - accuracy: 0.9096 - val_loss: 0.3173 - val_accuracy: 0.8746\n",
      "Epoch 110/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2087 - accuracy: 0.9194\n",
      "Epoch 110: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2133 - accuracy: 0.9111 - val_loss: 0.3527 - val_accuracy: 0.8608\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1572 - accuracy: 0.9516\n",
      "Epoch 111: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2081 - accuracy: 0.9148 - val_loss: 0.3193 - val_accuracy: 0.8692\n",
      "Epoch 112/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1401 - accuracy: 0.9355\n",
      "Epoch 112: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2041 - accuracy: 0.9175 - val_loss: 0.3295 - val_accuracy: 0.8715\n",
      "Epoch 113/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1391 - accuracy: 0.9677\n",
      "Epoch 113: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2179 - accuracy: 0.9084 - val_loss: 0.3201 - val_accuracy: 0.8715\n",
      "Epoch 114/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3387 - accuracy: 0.8306\n",
      "Epoch 114: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2136 - accuracy: 0.9111 - val_loss: 0.3220 - val_accuracy: 0.8677\n",
      "Epoch 115/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1785 - accuracy: 0.9194\n",
      "Epoch 115: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2056 - accuracy: 0.9173 - val_loss: 0.3316 - val_accuracy: 0.8723\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2308 - accuracy: 0.8871\n",
      "Epoch 116: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 0.9142 - val_loss: 0.3417 - val_accuracy: 0.8654\n",
      "Epoch 117/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2071 - accuracy: 0.9186\n",
      "Epoch 117: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.9153 - val_loss: 0.3200 - val_accuracy: 0.8708\n",
      "Epoch 118/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2235 - accuracy: 0.9019\n",
      "Epoch 118: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2262 - accuracy: 0.9013 - val_loss: 0.3185 - val_accuracy: 0.8692\n",
      "Epoch 119/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2194 - accuracy: 0.9107\n",
      "Epoch 119: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2192 - accuracy: 0.9111 - val_loss: 0.3256 - val_accuracy: 0.8669\n",
      "Epoch 120/1000\n",
      "26/42 [=================>............] - ETA: 0s - loss: 0.2095 - accuracy: 0.9190\n",
      "Epoch 120: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.9203 - val_loss: 0.3465 - val_accuracy: 0.8700\n",
      "Epoch 121/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2615 - accuracy: 0.9113\n",
      "Epoch 121: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2050 - accuracy: 0.9159 - val_loss: 0.3375 - val_accuracy: 0.8677\n",
      "Epoch 122/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2166 - accuracy: 0.9107\n",
      "Epoch 122: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2147 - accuracy: 0.9124 - val_loss: 0.3356 - val_accuracy: 0.8708\n",
      "Epoch 123/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2007 - accuracy: 0.9167\n",
      "Epoch 123: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2014 - accuracy: 0.9173 - val_loss: 0.3419 - val_accuracy: 0.8692\n",
      "Epoch 124/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2030 - accuracy: 0.9163\n",
      "Epoch 124: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2040 - accuracy: 0.9155 - val_loss: 0.3274 - val_accuracy: 0.8669\n",
      "Epoch 125/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2093 - accuracy: 0.9167\n",
      "Epoch 125: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2102 - accuracy: 0.9153 - val_loss: 0.3495 - val_accuracy: 0.8600\n",
      "Epoch 126/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.1965 - accuracy: 0.9191\n",
      "Epoch 126: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2013 - accuracy: 0.9178 - val_loss: 0.3501 - val_accuracy: 0.8700\n",
      "Epoch 127/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2181 - accuracy: 0.9113\n",
      "Epoch 127: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1972 - accuracy: 0.9196 - val_loss: 0.3290 - val_accuracy: 0.8662\n",
      "Epoch 128/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2004 - accuracy: 0.9032\n",
      "Epoch 128: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1996 - accuracy: 0.9190 - val_loss: 0.3733 - val_accuracy: 0.8638\n",
      "Epoch 129/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2051 - accuracy: 0.9158\n",
      "Epoch 129: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2028 - accuracy: 0.9159 - val_loss: 0.3485 - val_accuracy: 0.8662\n",
      "Epoch 130/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1979 - accuracy: 0.9192\n",
      "Epoch 130: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2000 - accuracy: 0.9182 - val_loss: 0.3354 - val_accuracy: 0.8715\n",
      "Epoch 131/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2011 - accuracy: 0.9200\n",
      "Epoch 131: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2016 - accuracy: 0.9201 - val_loss: 0.3416 - val_accuracy: 0.8692\n",
      "Epoch 132/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2021 - accuracy: 0.9173\n",
      "Epoch 132: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2003 - accuracy: 0.9180 - val_loss: 0.3324 - val_accuracy: 0.8708\n",
      "Epoch 133/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1952 - accuracy: 0.9229\n",
      "Epoch 133: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.9217 - val_loss: 0.3403 - val_accuracy: 0.8654\n",
      "Epoch 134/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1970 - accuracy: 0.9167\n",
      "Epoch 134: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.9175 - val_loss: 0.3414 - val_accuracy: 0.8715\n",
      "Epoch 135/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1951 - accuracy: 0.9202\n",
      "Epoch 135: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1975 - accuracy: 0.9201 - val_loss: 0.3860 - val_accuracy: 0.8600\n",
      "Epoch 136/1000\n",
      "30/42 [====================>.........] - ETA: 0s - loss: 0.1886 - accuracy: 0.9228\n",
      "Epoch 136: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1936 - accuracy: 0.9203 - val_loss: 0.3352 - val_accuracy: 0.8654\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1459 - accuracy: 0.9677\n",
      "Epoch 137: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1893 - accuracy: 0.9263 - val_loss: 0.3431 - val_accuracy: 0.8646\n",
      "Epoch 138/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1484 - accuracy: 0.9274\n",
      "Epoch 138: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.9228 - val_loss: 0.3521 - val_accuracy: 0.8662\n",
      "Epoch 139/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1985 - accuracy: 0.9113\n",
      "Epoch 139: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1990 - accuracy: 0.9190 - val_loss: 0.3434 - val_accuracy: 0.8669\n",
      "Epoch 140/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1982 - accuracy: 0.9274\n",
      "Epoch 140: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1911 - accuracy: 0.9205 - val_loss: 0.3420 - val_accuracy: 0.8638\n",
      "Epoch 141/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1238 - accuracy: 0.9597\n",
      "Epoch 141: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1968 - accuracy: 0.9163 - val_loss: 0.3939 - val_accuracy: 0.8585\n",
      "Epoch 142/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2603 - accuracy: 0.9032\n",
      "Epoch 142: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2044 - accuracy: 0.9140 - val_loss: 0.3808 - val_accuracy: 0.8577\n",
      "Epoch 143/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1906 - accuracy: 0.9113\n",
      "Epoch 143: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1960 - accuracy: 0.9232 - val_loss: 0.3672 - val_accuracy: 0.8485\n",
      "Epoch 144/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1992 - accuracy: 0.9194\n",
      "Epoch 144: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1907 - accuracy: 0.9236 - val_loss: 0.3472 - val_accuracy: 0.8538\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1925 - accuracy: 0.9355\n",
      "Epoch 145: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1916 - accuracy: 0.9236 - val_loss: 0.3619 - val_accuracy: 0.8708\n",
      "Epoch 146/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1310 - accuracy: 0.9516\n",
      "Epoch 146: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1976 - accuracy: 0.9190 - val_loss: 0.3631 - val_accuracy: 0.8623\n",
      "Epoch 147/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2710 - accuracy: 0.8871\n",
      "Epoch 147: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2095 - accuracy: 0.9115 - val_loss: 0.3950 - val_accuracy: 0.8677\n",
      "Epoch 148/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1977 - accuracy: 0.9197\n",
      "Epoch 148: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9194 - val_loss: 0.3500 - val_accuracy: 0.8685\n",
      "Epoch 149/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1776 - accuracy: 0.9355\n",
      "Epoch 149: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.9196 - val_loss: 0.3394 - val_accuracy: 0.8654\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1355 - accuracy: 0.9355\n",
      "Epoch 150: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.9271 - val_loss: 0.3452 - val_accuracy: 0.8638\n",
      "Epoch 151/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2243 - accuracy: 0.9032\n",
      "Epoch 151: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9261 - val_loss: 0.3675 - val_accuracy: 0.8615\n",
      "Epoch 152/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2215 - accuracy: 0.8952\n",
      "Epoch 152: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.9253 - val_loss: 0.3583 - val_accuracy: 0.8662\n",
      "Epoch 153/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2030 - accuracy: 0.9194\n",
      "Epoch 153: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.9248 - val_loss: 0.3526 - val_accuracy: 0.8677\n",
      "Epoch 154/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1545 - accuracy: 0.9194\n",
      "Epoch 154: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1796 - accuracy: 0.9269 - val_loss: 0.3967 - val_accuracy: 0.8654\n",
      "Epoch 155/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.0682 - accuracy: 0.9919\n",
      "Epoch 155: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.9205 - val_loss: 0.3662 - val_accuracy: 0.8654\n",
      "Epoch 156/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1442 - accuracy: 0.9435\n",
      "Epoch 156: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1850 - accuracy: 0.9226 - val_loss: 0.3852 - val_accuracy: 0.8631\n",
      "Epoch 157/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1262 - accuracy: 0.9274\n",
      "Epoch 157: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1817 - accuracy: 0.9223 - val_loss: 0.3932 - val_accuracy: 0.8631\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Epoch 1/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.8523 - accuracy: 0.5387 \n",
      "Epoch 1: val_accuracy improved from -inf to 0.71077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.8406 - accuracy: 0.5465 - val_loss: 0.5991 - val_accuracy: 0.7108\n",
      "Epoch 2/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.5429 - accuracy: 0.7599\n",
      "Epoch 2: val_accuracy improved from 0.71077 to 0.82615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.7606 - val_loss: 0.4851 - val_accuracy: 0.8262\n",
      "Epoch 3/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.4446 - accuracy: 0.8233\n",
      "Epoch 3: val_accuracy improved from 0.82615 to 0.83231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.8268 - val_loss: 0.4086 - val_accuracy: 0.8323\n",
      "Epoch 4/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.3927 - accuracy: 0.8431\n",
      "Epoch 4: val_accuracy improved from 0.83231 to 0.84385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3919 - accuracy: 0.8426 - val_loss: 0.3702 - val_accuracy: 0.8438\n",
      "Epoch 5/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.3667 - accuracy: 0.8430\n",
      "Epoch 5: val_accuracy did not improve from 0.84385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8418 - val_loss: 0.3693 - val_accuracy: 0.8408\n",
      "Epoch 6/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3226 - accuracy: 0.8710\n",
      "Epoch 6: val_accuracy improved from 0.84385 to 0.84538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3668 - accuracy: 0.8413 - val_loss: 0.3587 - val_accuracy: 0.8454\n",
      "Epoch 7/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2893 - accuracy: 0.8710\n",
      "Epoch 7: val_accuracy improved from 0.84538 to 0.85538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3436 - accuracy: 0.8578 - val_loss: 0.3427 - val_accuracy: 0.8554\n",
      "Epoch 8/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2378 - accuracy: 0.9032\n",
      "Epoch 8: val_accuracy did not improve from 0.85538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8593 - val_loss: 0.3682 - val_accuracy: 0.8400\n",
      "Epoch 9/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.3323 - accuracy: 0.8652\n",
      "Epoch 9: val_accuracy improved from 0.85538 to 0.85923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3318 - accuracy: 0.8655 - val_loss: 0.3420 - val_accuracy: 0.8592\n",
      "Epoch 10/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.3249 - accuracy: 0.8666\n",
      "Epoch 10: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8678 - val_loss: 0.3456 - val_accuracy: 0.8485\n",
      "Epoch 11/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3307 - accuracy: 0.8306\n",
      "Epoch 11: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8668 - val_loss: 0.3326 - val_accuracy: 0.8531\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3358 - accuracy: 0.8871\n",
      "Epoch 12: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.8728 - val_loss: 0.3317 - val_accuracy: 0.8538\n",
      "Epoch 13/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3865 - accuracy: 0.8226\n",
      "Epoch 13: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8599 - val_loss: 0.3787 - val_accuracy: 0.8285\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3529 - accuracy: 0.8952\n",
      "Epoch 14: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8578 - val_loss: 0.3805 - val_accuracy: 0.8262\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2930 - accuracy: 0.9032\n",
      "Epoch 15: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8638 - val_loss: 0.3701 - val_accuracy: 0.8292\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3159 - accuracy: 0.8653\n",
      "Epoch 16: val_accuracy improved from 0.85923 to 0.86000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3159 - accuracy: 0.8653 - val_loss: 0.3281 - val_accuracy: 0.8600\n",
      "Epoch 17/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3037 - accuracy: 0.8758\n",
      "Epoch 17: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8751 - val_loss: 0.3266 - val_accuracy: 0.8592\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3207 - accuracy: 0.8710\n",
      "Epoch 18: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.8695 - val_loss: 0.3321 - val_accuracy: 0.8538\n",
      "Epoch 19/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.3051 - accuracy: 0.8728\n",
      "Epoch 19: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3012 - accuracy: 0.8753 - val_loss: 0.3269 - val_accuracy: 0.8554\n",
      "Epoch 20/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2859 - accuracy: 0.9194\n",
      "Epoch 20: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3012 - accuracy: 0.8782 - val_loss: 0.3230 - val_accuracy: 0.8600\n",
      "Epoch 21/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3171 - accuracy: 0.8790\n",
      "Epoch 21: val_accuracy improved from 0.86000 to 0.86308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3074 - accuracy: 0.8726 - val_loss: 0.3215 - val_accuracy: 0.8631\n",
      "Epoch 22/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2143 - accuracy: 0.9113\n",
      "Epoch 22: val_accuracy improved from 0.86308 to 0.86769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2935 - accuracy: 0.8809 - val_loss: 0.3263 - val_accuracy: 0.8677\n",
      "Epoch 23/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2840 - accuracy: 0.9194\n",
      "Epoch 23: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2941 - accuracy: 0.8776 - val_loss: 0.3177 - val_accuracy: 0.8654\n",
      "Epoch 24/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2230 - accuracy: 0.9355\n",
      "Epoch 24: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2945 - accuracy: 0.8769 - val_loss: 0.3167 - val_accuracy: 0.8646\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2920 - accuracy: 0.9032\n",
      "Epoch 25: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2881 - accuracy: 0.8805 - val_loss: 0.3133 - val_accuracy: 0.8669\n",
      "Epoch 26/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2613 - accuracy: 0.8952\n",
      "Epoch 26: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2874 - accuracy: 0.8824 - val_loss: 0.3135 - val_accuracy: 0.8654\n",
      "Epoch 27/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2326 - accuracy: 0.9113\n",
      "Epoch 27: val_accuracy improved from 0.86769 to 0.86846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2828 - accuracy: 0.8828 - val_loss: 0.3107 - val_accuracy: 0.8685\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2632 - accuracy: 0.8952\n",
      "Epoch 28: val_accuracy improved from 0.86846 to 0.87000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2776 - accuracy: 0.8853 - val_loss: 0.3108 - val_accuracy: 0.8700\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3098 - accuracy: 0.8710\n",
      "Epoch 29: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2782 - accuracy: 0.8845 - val_loss: 0.3114 - val_accuracy: 0.8654\n",
      "Epoch 30/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2318 - accuracy: 0.9113\n",
      "Epoch 30: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2893 - accuracy: 0.8817 - val_loss: 0.3306 - val_accuracy: 0.8562\n",
      "Epoch 31/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2910 - accuracy: 0.8871\n",
      "Epoch 31: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2961 - accuracy: 0.8745 - val_loss: 0.3046 - val_accuracy: 0.8692\n",
      "Epoch 32/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3032 - accuracy: 0.8790\n",
      "Epoch 32: val_accuracy improved from 0.87000 to 0.87077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2832 - accuracy: 0.8820 - val_loss: 0.3090 - val_accuracy: 0.8708\n",
      "Epoch 33/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3218 - accuracy: 0.8952\n",
      "Epoch 33: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2753 - accuracy: 0.8855 - val_loss: 0.3149 - val_accuracy: 0.8708\n",
      "Epoch 34/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2420 - accuracy: 0.8952\n",
      "Epoch 34: val_accuracy improved from 0.87077 to 0.87231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2764 - accuracy: 0.8828 - val_loss: 0.3046 - val_accuracy: 0.8723\n",
      "Epoch 35/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2823 - accuracy: 0.8952\n",
      "Epoch 35: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.8872 - val_loss: 0.3140 - val_accuracy: 0.8708\n",
      "Epoch 36/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2741 - accuracy: 0.8952\n",
      "Epoch 36: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2729 - accuracy: 0.8913 - val_loss: 0.3111 - val_accuracy: 0.8669\n",
      "Epoch 37/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3278 - accuracy: 0.8306\n",
      "Epoch 37: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2764 - accuracy: 0.8882 - val_loss: 0.3130 - val_accuracy: 0.8723\n",
      "Epoch 38/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2480 - accuracy: 0.8952\n",
      "Epoch 38: val_accuracy improved from 0.87231 to 0.88154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2647 - accuracy: 0.8949 - val_loss: 0.3000 - val_accuracy: 0.8815\n",
      "Epoch 39/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2636 - accuracy: 0.8935\n",
      "Epoch 39: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.8946 - val_loss: 0.3006 - val_accuracy: 0.8815\n",
      "Epoch 40/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3147 - accuracy: 0.8710\n",
      "Epoch 40: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.8942 - val_loss: 0.3390 - val_accuracy: 0.8592\n",
      "Epoch 41/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3743 - accuracy: 0.8306\n",
      "Epoch 41: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2672 - accuracy: 0.8861 - val_loss: 0.3254 - val_accuracy: 0.8662\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2920 - accuracy: 0.8871\n",
      "Epoch 42: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2617 - accuracy: 0.8949 - val_loss: 0.3004 - val_accuracy: 0.8754\n",
      "Epoch 43/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2933 - accuracy: 0.8629\n",
      "Epoch 43: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2573 - accuracy: 0.8942 - val_loss: 0.2940 - val_accuracy: 0.8754\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2746 - accuracy: 0.9032\n",
      "Epoch 44: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2612 - accuracy: 0.8903 - val_loss: 0.3002 - val_accuracy: 0.8808\n",
      "Epoch 45/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3187 - accuracy: 0.8790\n",
      "Epoch 45: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2587 - accuracy: 0.8917 - val_loss: 0.3108 - val_accuracy: 0.8715\n",
      "Epoch 46/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2712 - accuracy: 0.8858\n",
      "Epoch 46: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.8872 - val_loss: 0.2997 - val_accuracy: 0.8754\n",
      "Epoch 47/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2698 - accuracy: 0.8888\n",
      "Epoch 47: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2704 - accuracy: 0.8890 - val_loss: 0.3008 - val_accuracy: 0.8785\n",
      "Epoch 48/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3362 - accuracy: 0.8387\n",
      "Epoch 48: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.8955 - val_loss: 0.3011 - val_accuracy: 0.8746\n",
      "Epoch 49/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2674 - accuracy: 0.8952\n",
      "Epoch 49: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2621 - accuracy: 0.8924 - val_loss: 0.2947 - val_accuracy: 0.8769\n",
      "Epoch 50/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2038 - accuracy: 0.9435\n",
      "Epoch 50: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2537 - accuracy: 0.8953 - val_loss: 0.3035 - val_accuracy: 0.8754\n",
      "Epoch 51/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2500 - accuracy: 0.9013\n",
      "Epoch 51: val_accuracy improved from 0.88154 to 0.88231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2519 - accuracy: 0.9003 - val_loss: 0.3050 - val_accuracy: 0.8823\n",
      "Epoch 52/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2609 - accuracy: 0.8924\n",
      "Epoch 52: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2603 - accuracy: 0.8930 - val_loss: 0.3016 - val_accuracy: 0.8700\n",
      "Epoch 53/1000\n",
      "22/42 [==============>...............] - ETA: 0s - loss: 0.2474 - accuracy: 0.8970\n",
      "Epoch 53: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.8974 - val_loss: 0.3031 - val_accuracy: 0.8769\n",
      "Epoch 54/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2483 - accuracy: 0.8999\n",
      "Epoch 54: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2476 - accuracy: 0.9005 - val_loss: 0.2940 - val_accuracy: 0.8754\n",
      "Epoch 55/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2919 - accuracy: 0.8790\n",
      "Epoch 55: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2519 - accuracy: 0.8984 - val_loss: 0.3072 - val_accuracy: 0.8723\n",
      "Epoch 56/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2421 - accuracy: 0.8952\n",
      "Epoch 56: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2575 - accuracy: 0.8922 - val_loss: 0.3115 - val_accuracy: 0.8708\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3108 - accuracy: 0.8629\n",
      "Epoch 57: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2531 - accuracy: 0.8963 - val_loss: 0.3000 - val_accuracy: 0.8769\n",
      "Epoch 58/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2618 - accuracy: 0.8913\n",
      "Epoch 58: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2614 - accuracy: 0.8915 - val_loss: 0.2946 - val_accuracy: 0.8823\n",
      "Epoch 59/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2471 - accuracy: 0.8999\n",
      "Epoch 59: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.9003 - val_loss: 0.2897 - val_accuracy: 0.8800\n",
      "Epoch 60/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2370 - accuracy: 0.9077\n",
      "Epoch 60: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2417 - accuracy: 0.9048 - val_loss: 0.3239 - val_accuracy: 0.8662\n",
      "Epoch 61/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2601 - accuracy: 0.8941\n",
      "Epoch 61: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2629 - accuracy: 0.8921 - val_loss: 0.2913 - val_accuracy: 0.8769\n",
      "Epoch 62/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2514 - accuracy: 0.9113\n",
      "Epoch 62: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2816 - accuracy: 0.8817 - val_loss: 0.2910 - val_accuracy: 0.8777\n",
      "Epoch 63/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2710 - accuracy: 0.9032\n",
      "Epoch 63: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.8969 - val_loss: 0.3126 - val_accuracy: 0.8715\n",
      "Epoch 64/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2476 - accuracy: 0.8999\n",
      "Epoch 64: val_accuracy improved from 0.88231 to 0.88385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.8996 - val_loss: 0.2950 - val_accuracy: 0.8838\n",
      "Epoch 65/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2461 - accuracy: 0.9008\n",
      "Epoch 65: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.9021 - val_loss: 0.2953 - val_accuracy: 0.8754\n",
      "Epoch 66/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2390 - accuracy: 0.8985\n",
      "Epoch 66: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2425 - accuracy: 0.8976 - val_loss: 0.3010 - val_accuracy: 0.8777\n",
      "Epoch 67/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2424 - accuracy: 0.9015\n",
      "Epoch 67: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2423 - accuracy: 0.9015 - val_loss: 0.2997 - val_accuracy: 0.8762\n",
      "Epoch 68/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2481 - accuracy: 0.8962\n",
      "Epoch 68: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.8971 - val_loss: 0.2980 - val_accuracy: 0.8777\n",
      "Epoch 69/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2555 - accuracy: 0.8919\n",
      "Epoch 69: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2547 - accuracy: 0.8922 - val_loss: 0.2937 - val_accuracy: 0.8792\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1822 - accuracy: 0.9516\n",
      "Epoch 70: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2438 - accuracy: 0.8986 - val_loss: 0.2942 - val_accuracy: 0.8746\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1979 - accuracy: 0.9113\n",
      "Epoch 71: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8994 - val_loss: 0.3000 - val_accuracy: 0.8762\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1956 - accuracy: 0.9113\n",
      "Epoch 72: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2397 - accuracy: 0.9042 - val_loss: 0.2980 - val_accuracy: 0.8823\n",
      "Epoch 73/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2089 - accuracy: 0.9274\n",
      "Epoch 73: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2333 - accuracy: 0.9046 - val_loss: 0.2902 - val_accuracy: 0.8769\n",
      "Epoch 74/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1627 - accuracy: 0.9516\n",
      "Epoch 74: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2309 - accuracy: 0.9103 - val_loss: 0.2916 - val_accuracy: 0.8792\n",
      "Epoch 75/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2150 - accuracy: 0.8952\n",
      "Epoch 75: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2356 - accuracy: 0.9063 - val_loss: 0.2992 - val_accuracy: 0.8792\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1911 - accuracy: 0.9194\n",
      "Epoch 76: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2348 - accuracy: 0.9076 - val_loss: 0.2931 - val_accuracy: 0.8738\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2478 - accuracy: 0.9032\n",
      "Epoch 77: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2287 - accuracy: 0.9098 - val_loss: 0.2964 - val_accuracy: 0.8792\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2487 - accuracy: 0.9113\n",
      "Epoch 78: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2287 - accuracy: 0.9061 - val_loss: 0.2908 - val_accuracy: 0.8777\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2781 - accuracy: 0.8790\n",
      "Epoch 79: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2377 - accuracy: 0.9032 - val_loss: 0.2959 - val_accuracy: 0.8785\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2036 - accuracy: 0.9194\n",
      "Epoch 80: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2277 - accuracy: 0.9094 - val_loss: 0.3132 - val_accuracy: 0.8677\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1839 - accuracy: 0.9435\n",
      "Epoch 81: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2306 - accuracy: 0.9086 - val_loss: 0.2924 - val_accuracy: 0.8792\n",
      "Epoch 82/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2059 - accuracy: 0.9194\n",
      "Epoch 82: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2646 - accuracy: 0.8851 - val_loss: 0.2914 - val_accuracy: 0.8815\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2041 - accuracy: 0.9194\n",
      "Epoch 83: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.9113 - val_loss: 0.3095 - val_accuracy: 0.8777\n",
      "Epoch 84/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2333 - accuracy: 0.9032\n",
      "Epoch 84: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2281 - accuracy: 0.9076 - val_loss: 0.3252 - val_accuracy: 0.8638\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2834 - accuracy: 0.8468\n",
      "Epoch 85: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2397 - accuracy: 0.8996 - val_loss: 0.3317 - val_accuracy: 0.8562\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2045 - accuracy: 0.8952\n",
      "Epoch 86: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8932 - val_loss: 0.2984 - val_accuracy: 0.8723\n",
      "Epoch 87/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2104 - accuracy: 0.9274\n",
      "Epoch 87: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2253 - accuracy: 0.9099 - val_loss: 0.2999 - val_accuracy: 0.8754\n",
      "Epoch 88/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2244 - accuracy: 0.9101\n",
      "Epoch 88: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.9088 - val_loss: 0.3013 - val_accuracy: 0.8731\n",
      "Epoch 89/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2265 - accuracy: 0.9073\n",
      "Epoch 89: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2262 - accuracy: 0.9067 - val_loss: 0.2947 - val_accuracy: 0.8762\n",
      "Epoch 90/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2290 - accuracy: 0.9088\n",
      "Epoch 90: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2273 - accuracy: 0.9094 - val_loss: 0.3093 - val_accuracy: 0.8731\n",
      "Epoch 91/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2184 - accuracy: 0.9153\n",
      "Epoch 91: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.9142 - val_loss: 0.2968 - val_accuracy: 0.8746\n",
      "Epoch 92/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2167 - accuracy: 0.9117\n",
      "Epoch 92: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2220 - accuracy: 0.9096 - val_loss: 0.3088 - val_accuracy: 0.8654\n",
      "Epoch 93/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2390 - accuracy: 0.8871\n",
      "Epoch 93: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2257 - accuracy: 0.9069 - val_loss: 0.3065 - val_accuracy: 0.8769\n",
      "Epoch 94/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1919 - accuracy: 0.9355\n",
      "Epoch 94: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2221 - accuracy: 0.9092 - val_loss: 0.3253 - val_accuracy: 0.8762\n",
      "Epoch 95/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2028 - accuracy: 0.9113\n",
      "Epoch 95: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.8994 - val_loss: 0.3274 - val_accuracy: 0.8677\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2124 - accuracy: 0.9113\n",
      "Epoch 96: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 0.9103 - val_loss: 0.3060 - val_accuracy: 0.8754\n",
      "Epoch 97/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2667 - accuracy: 0.9194\n",
      "Epoch 97: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2271 - accuracy: 0.9069 - val_loss: 0.3168 - val_accuracy: 0.8715\n",
      "Epoch 98/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2207 - accuracy: 0.9274\n",
      "Epoch 98: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2326 - accuracy: 0.9040 - val_loss: 0.2996 - val_accuracy: 0.8754\n",
      "Epoch 99/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2151 - accuracy: 0.9194\n",
      "Epoch 99: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.9151 - val_loss: 0.3022 - val_accuracy: 0.8692\n",
      "Epoch 100/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2770 - accuracy: 0.8790\n",
      "Epoch 100: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2341 - accuracy: 0.9040 - val_loss: 0.3080 - val_accuracy: 0.8769\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2413 - accuracy: 0.8952\n",
      "Epoch 101: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2186 - accuracy: 0.9107 - val_loss: 0.3042 - val_accuracy: 0.8723\n",
      "Epoch 102/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2219 - accuracy: 0.9055\n",
      "Epoch 102: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2219 - accuracy: 0.9055 - val_loss: 0.2983 - val_accuracy: 0.8723\n",
      "Epoch 103/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1774 - accuracy: 0.9194\n",
      "Epoch 103: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.9055 - val_loss: 0.3002 - val_accuracy: 0.8677\n",
      "Epoch 104/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1921 - accuracy: 0.9274\n",
      "Epoch 104: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2215 - accuracy: 0.9126 - val_loss: 0.3104 - val_accuracy: 0.8677\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2222 - accuracy: 0.8952\n",
      "Epoch 105: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2304 - accuracy: 0.9023 - val_loss: 0.3556 - val_accuracy: 0.8577\n",
      "Epoch 106/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2219 - accuracy: 0.9123\n",
      "Epoch 106: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2205 - accuracy: 0.9126 - val_loss: 0.3076 - val_accuracy: 0.8692\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3183 - accuracy: 0.8548\n",
      "Epoch 107: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2144 - accuracy: 0.9138 - val_loss: 0.3167 - val_accuracy: 0.8754\n",
      "Epoch 108/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1196 - accuracy: 0.9435\n",
      "Epoch 108: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2228 - accuracy: 0.9048 - val_loss: 0.3015 - val_accuracy: 0.8669\n",
      "Epoch 109/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2273 - accuracy: 0.9032\n",
      "Epoch 109: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2112 - accuracy: 0.9121 - val_loss: 0.3156 - val_accuracy: 0.8677\n",
      "Epoch 110/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2161 - accuracy: 0.9113\n",
      "Epoch 110: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2265 - accuracy: 0.9057 - val_loss: 0.3272 - val_accuracy: 0.8738\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2356 - accuracy: 0.9194\n",
      "Epoch 111: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2122 - accuracy: 0.9161 - val_loss: 0.3065 - val_accuracy: 0.8754\n",
      "Epoch 112/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2076 - accuracy: 0.9167\n",
      "Epoch 112: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2067 - accuracy: 0.9163 - val_loss: 0.3159 - val_accuracy: 0.8708\n",
      "Epoch 113/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.2054 - accuracy: 0.9198\n",
      "Epoch 113: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2124 - accuracy: 0.9178 - val_loss: 0.3093 - val_accuracy: 0.8731\n",
      "Epoch 114/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2063 - accuracy: 0.9149\n",
      "Epoch 114: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2061 - accuracy: 0.9144 - val_loss: 0.3630 - val_accuracy: 0.8669\n",
      "Epoch 115/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2163 - accuracy: 0.9123\n",
      "Epoch 115: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2190 - accuracy: 0.9128 - val_loss: 0.3216 - val_accuracy: 0.8738\n",
      "Epoch 116/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2078 - accuracy: 0.9181\n",
      "Epoch 116: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2094 - accuracy: 0.9163 - val_loss: 0.3763 - val_accuracy: 0.8692\n",
      "Epoch 117/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2148 - accuracy: 0.9109\n",
      "Epoch 117: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2175 - accuracy: 0.9098 - val_loss: 0.3295 - val_accuracy: 0.8631\n",
      "Epoch 118/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2064 - accuracy: 0.9143\n",
      "Epoch 118: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2069 - accuracy: 0.9140 - val_loss: 0.3334 - val_accuracy: 0.8731\n",
      "Epoch 119/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2168 - accuracy: 0.9095\n",
      "Epoch 119: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2169 - accuracy: 0.9113 - val_loss: 0.3065 - val_accuracy: 0.8677\n",
      "Epoch 120/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2074 - accuracy: 0.9152\n",
      "Epoch 120: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2062 - accuracy: 0.9146 - val_loss: 0.3080 - val_accuracy: 0.8685\n",
      "Epoch 121/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2019 - accuracy: 0.9192\n",
      "Epoch 121: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2019 - accuracy: 0.9198 - val_loss: 0.3166 - val_accuracy: 0.8746\n",
      "Epoch 122/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2050 - accuracy: 0.9154\n",
      "Epoch 122: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2062 - accuracy: 0.9155 - val_loss: 0.3182 - val_accuracy: 0.8723\n",
      "Epoch 123/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2004 - accuracy: 0.9218\n",
      "Epoch 123: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2003 - accuracy: 0.9211 - val_loss: 0.3237 - val_accuracy: 0.8723\n",
      "Epoch 124/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2064 - accuracy: 0.9355\n",
      "Epoch 124: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2102 - accuracy: 0.9150 - val_loss: 0.3368 - val_accuracy: 0.8762\n",
      "Epoch 125/1000\n",
      "29/42 [===================>..........] - ETA: 0s - loss: 0.2212 - accuracy: 0.9063\n",
      "Epoch 125: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2164 - accuracy: 0.9098 - val_loss: 0.3172 - val_accuracy: 0.8708\n",
      "Epoch 126/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2067 - accuracy: 0.9146\n",
      "Epoch 126: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 0.9142 - val_loss: 0.3330 - val_accuracy: 0.8677\n",
      "Epoch 127/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2033 - accuracy: 0.9183\n",
      "Epoch 127: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2052 - accuracy: 0.9165 - val_loss: 0.3809 - val_accuracy: 0.8615\n",
      "Epoch 128/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2869 - accuracy: 0.8710\n",
      "Epoch 128: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2036 - accuracy: 0.9169 - val_loss: 0.3316 - val_accuracy: 0.8708\n",
      "Epoch 129/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2051 - accuracy: 0.9214\n",
      "Epoch 129: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2007 - accuracy: 0.9225 - val_loss: 0.3484 - val_accuracy: 0.8615\n",
      "Epoch 130/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2018 - accuracy: 0.9190\n",
      "Epoch 130: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2027 - accuracy: 0.9182 - val_loss: 0.3323 - val_accuracy: 0.8715\n",
      "Epoch 131/1000\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.2167 - accuracy: 0.9083\n",
      "Epoch 131: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2151 - accuracy: 0.9084 - val_loss: 0.3320 - val_accuracy: 0.8638\n",
      "Epoch 132/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2111 - accuracy: 0.9095\n",
      "Epoch 132: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2107 - accuracy: 0.9098 - val_loss: 0.3462 - val_accuracy: 0.8692\n",
      "Epoch 133/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1884 - accuracy: 0.9194\n",
      "Epoch 133: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2048 - accuracy: 0.9153 - val_loss: 0.3171 - val_accuracy: 0.8731\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1908 - accuracy: 0.9261\n",
      "Epoch 134: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1908 - accuracy: 0.9261 - val_loss: 0.3357 - val_accuracy: 0.8738\n",
      "Epoch 135/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2332 - accuracy: 0.9032\n",
      "Epoch 135: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1949 - accuracy: 0.9250 - val_loss: 0.3246 - val_accuracy: 0.8731\n",
      "Epoch 136/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1943 - accuracy: 0.9233\n",
      "Epoch 136: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1974 - accuracy: 0.9213 - val_loss: 0.3092 - val_accuracy: 0.8715\n",
      "Epoch 137/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1966 - accuracy: 0.9152\n",
      "Epoch 137: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1975 - accuracy: 0.9148 - val_loss: 0.3319 - val_accuracy: 0.8731\n",
      "Epoch 138/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1883 - accuracy: 0.9264\n",
      "Epoch 138: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.9259 - val_loss: 0.3146 - val_accuracy: 0.8677\n",
      "Epoch 139/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1569 - accuracy: 0.9355\n",
      "Epoch 139: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2042 - accuracy: 0.9140 - val_loss: 0.3231 - val_accuracy: 0.8692\n",
      "Epoch 140/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1646 - accuracy: 0.9597\n",
      "Epoch 140: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2009 - accuracy: 0.9223 - val_loss: 0.3223 - val_accuracy: 0.8638\n",
      "Epoch 141/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1916 - accuracy: 0.9225\n",
      "Epoch 141: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1936 - accuracy: 0.9217 - val_loss: 0.3189 - val_accuracy: 0.8715\n",
      "Epoch 142/1000\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.1967 - accuracy: 0.9231\n",
      "Epoch 142: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1966 - accuracy: 0.9223 - val_loss: 0.3388 - val_accuracy: 0.8654\n",
      "Epoch 143/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1943 - accuracy: 0.9219\n",
      "Epoch 143: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.9244 - val_loss: 0.3480 - val_accuracy: 0.8723\n",
      "Epoch 144/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.1976 - accuracy: 0.9215\n",
      "Epoch 144: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1976 - accuracy: 0.9213 - val_loss: 0.3362 - val_accuracy: 0.8669\n",
      "Epoch 145/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1946 - accuracy: 0.9210\n",
      "Epoch 145: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1920 - accuracy: 0.9219 - val_loss: 0.3409 - val_accuracy: 0.8600\n",
      "Epoch 146/1000\n",
      "26/42 [=================>............] - ETA: 0s - loss: 0.1790 - accuracy: 0.9280\n",
      "Epoch 146: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.9246 - val_loss: 0.3421 - val_accuracy: 0.8623\n",
      "Epoch 147/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1929 - accuracy: 0.9191\n",
      "Epoch 147: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1932 - accuracy: 0.9176 - val_loss: 0.3305 - val_accuracy: 0.8723\n",
      "Epoch 148/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1553 - accuracy: 0.9355\n",
      "Epoch 148: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.9236 - val_loss: 0.3440 - val_accuracy: 0.8700\n",
      "Epoch 149/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1928 - accuracy: 0.9194\n",
      "Epoch 149: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1932 - accuracy: 0.9190 - val_loss: 0.3441 - val_accuracy: 0.8577\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1607 - accuracy: 0.9435\n",
      "Epoch 150: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1989 - accuracy: 0.9184 - val_loss: 0.3482 - val_accuracy: 0.8677\n",
      "Epoch 151/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.1835 - accuracy: 0.9269\n",
      "Epoch 151: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1858 - accuracy: 0.9253 - val_loss: 0.3702 - val_accuracy: 0.8600\n",
      "Epoch 152/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1993 - accuracy: 0.9194\n",
      "Epoch 152: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1833 - accuracy: 0.9250 - val_loss: 0.3496 - val_accuracy: 0.8708\n",
      "Epoch 153/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1092 - accuracy: 0.9597\n",
      "Epoch 153: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 0.9128 - val_loss: 0.3436 - val_accuracy: 0.8677\n",
      "Epoch 154/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1901 - accuracy: 0.9274\n",
      "Epoch 154: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.9278 - val_loss: 0.3288 - val_accuracy: 0.8723\n",
      "Epoch 155/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2653 - accuracy: 0.9032\n",
      "Epoch 155: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.9257 - val_loss: 0.3508 - val_accuracy: 0.8662\n",
      "Epoch 156/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2289 - accuracy: 0.8952\n",
      "Epoch 156: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.9248 - val_loss: 0.3305 - val_accuracy: 0.8692\n",
      "Epoch 157/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1777 - accuracy: 0.9355\n",
      "Epoch 157: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.9228 - val_loss: 0.3533 - val_accuracy: 0.8654\n",
      "Epoch 158/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1466 - accuracy: 0.9516\n",
      "Epoch 158: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.9255 - val_loss: 0.3402 - val_accuracy: 0.8592\n",
      "Epoch 159/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2222 - accuracy: 0.9032\n",
      "Epoch 159: val_accuracy did not improve from 0.88385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.9257 - val_loss: 0.3443 - val_accuracy: 0.8677\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 22s - loss: 1.4459 - accuracy: 0.5161\n",
      "Epoch 1: val_accuracy improved from -inf to 0.76000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.6702 - accuracy: 0.6265 - val_loss: 0.5416 - val_accuracy: 0.7600\n",
      "Epoch 2/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4983 - accuracy: 0.8226\n",
      "Epoch 2: val_accuracy improved from 0.76000 to 0.82923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.7862 - val_loss: 0.4280 - val_accuracy: 0.8292\n",
      "Epoch 3/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.4405 - accuracy: 0.8027\n",
      "Epoch 3: val_accuracy did not improve from 0.82923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.8030 - val_loss: 0.4010 - val_accuracy: 0.8269\n",
      "Epoch 4/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3882 - accuracy: 0.8548\n",
      "Epoch 4: val_accuracy improved from 0.82923 to 0.83846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3779 - accuracy: 0.8461 - val_loss: 0.3710 - val_accuracy: 0.8385\n",
      "Epoch 5/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3740 - accuracy: 0.8356\n",
      "Epoch 5: val_accuracy improved from 0.83846 to 0.85385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8364 - val_loss: 0.3519 - val_accuracy: 0.8538\n",
      "Epoch 6/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.3444 - accuracy: 0.8634\n",
      "Epoch 6: val_accuracy improved from 0.85385 to 0.85538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3443 - accuracy: 0.8630 - val_loss: 0.3463 - val_accuracy: 0.8554\n",
      "Epoch 7/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3378 - accuracy: 0.8629\n",
      "Epoch 7: val_accuracy did not improve from 0.85538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8620 - val_loss: 0.3619 - val_accuracy: 0.8431\n",
      "Epoch 8/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.3363 - accuracy: 0.8608\n",
      "Epoch 8: val_accuracy did not improve from 0.85538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.8632 - val_loss: 0.3493 - val_accuracy: 0.8462\n",
      "Epoch 9/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.3319 - accuracy: 0.8614\n",
      "Epoch 9: val_accuracy improved from 0.85538 to 0.85769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3342 - accuracy: 0.8590 - val_loss: 0.3429 - val_accuracy: 0.8577\n",
      "Epoch 10/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.3620 - accuracy: 0.8372\n",
      "Epoch 10: val_accuracy improved from 0.85769 to 0.85846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3561 - accuracy: 0.8411 - val_loss: 0.3374 - val_accuracy: 0.8585\n",
      "Epoch 11/1000\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.3449 - accuracy: 0.8523\n",
      "Epoch 11: val_accuracy did not improve from 0.85846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8578 - val_loss: 0.3338 - val_accuracy: 0.8585\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2582 - accuracy: 0.9032\n",
      "Epoch 12: val_accuracy improved from 0.85846 to 0.86077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3177 - accuracy: 0.8668 - val_loss: 0.3282 - val_accuracy: 0.8608\n",
      "Epoch 13/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3642 - accuracy: 0.8468\n",
      "Epoch 13: val_accuracy improved from 0.86077 to 0.86231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3195 - accuracy: 0.8632 - val_loss: 0.3297 - val_accuracy: 0.8623\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4354 - accuracy: 0.8145\n",
      "Epoch 14: val_accuracy did not improve from 0.86231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8769 - val_loss: 0.3288 - val_accuracy: 0.8592\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2782 - accuracy: 0.8710\n",
      "Epoch 15: val_accuracy did not improve from 0.86231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8759 - val_loss: 0.3873 - val_accuracy: 0.8338\n",
      "Epoch 16/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3090 - accuracy: 0.8871\n",
      "Epoch 16: val_accuracy improved from 0.86231 to 0.86308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8595 - val_loss: 0.3229 - val_accuracy: 0.8631\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2419 - accuracy: 0.9032\n",
      "Epoch 17: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3021 - accuracy: 0.8720 - val_loss: 0.3390 - val_accuracy: 0.8538\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3302 - accuracy: 0.8548\n",
      "Epoch 18: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3180 - accuracy: 0.8651 - val_loss: 0.3357 - val_accuracy: 0.8531\n",
      "Epoch 19/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3103 - accuracy: 0.8065\n",
      "Epoch 19: val_accuracy improved from 0.86308 to 0.86462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3041 - accuracy: 0.8724 - val_loss: 0.3315 - val_accuracy: 0.8646\n",
      "Epoch 20/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2658 - accuracy: 0.9194\n",
      "Epoch 20: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2993 - accuracy: 0.8736 - val_loss: 0.3178 - val_accuracy: 0.8646\n",
      "Epoch 21/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2436 - accuracy: 0.9274\n",
      "Epoch 21: val_accuracy improved from 0.86462 to 0.86692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2890 - accuracy: 0.8747 - val_loss: 0.3249 - val_accuracy: 0.8669\n",
      "Epoch 22/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2937 - accuracy: 0.8548\n",
      "Epoch 22: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8643 - val_loss: 0.3332 - val_accuracy: 0.8562\n",
      "Epoch 23/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2562 - accuracy: 0.8952\n",
      "Epoch 23: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8643 - val_loss: 0.3673 - val_accuracy: 0.8346\n",
      "Epoch 24/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2845 - accuracy: 0.8629\n",
      "Epoch 24: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2956 - accuracy: 0.8740 - val_loss: 0.3176 - val_accuracy: 0.8669\n",
      "Epoch 25/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2815 - accuracy: 0.8792\n",
      "Epoch 25: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2819 - accuracy: 0.8790 - val_loss: 0.3329 - val_accuracy: 0.8654\n",
      "Epoch 26/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2427 - accuracy: 0.9274\n",
      "Epoch 26: val_accuracy improved from 0.86692 to 0.87000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.8722 - val_loss: 0.3198 - val_accuracy: 0.8700\n",
      "Epoch 27/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3022 - accuracy: 0.8710\n",
      "Epoch 27: val_accuracy improved from 0.87000 to 0.87308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2811 - accuracy: 0.8842 - val_loss: 0.3167 - val_accuracy: 0.8731\n",
      "Epoch 28/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2721 - accuracy: 0.8881\n",
      "Epoch 28: val_accuracy improved from 0.87308 to 0.87538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2726 - accuracy: 0.8878 - val_loss: 0.3061 - val_accuracy: 0.8754\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2296 - accuracy: 0.9113\n",
      "Epoch 29: val_accuracy improved from 0.87538 to 0.87615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2738 - accuracy: 0.8888 - val_loss: 0.3049 - val_accuracy: 0.8762\n",
      "Epoch 30/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2147 - accuracy: 0.8871\n",
      "Epoch 30: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2696 - accuracy: 0.8888 - val_loss: 0.3073 - val_accuracy: 0.8708\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2751 - accuracy: 0.8863\n",
      "Epoch 31: val_accuracy improved from 0.87615 to 0.87692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2751 - accuracy: 0.8863 - val_loss: 0.3038 - val_accuracy: 0.8769\n",
      "Epoch 32/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2530 - accuracy: 0.8548\n",
      "Epoch 32: val_accuracy improved from 0.87692 to 0.88000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2782 - accuracy: 0.8845 - val_loss: 0.3023 - val_accuracy: 0.8800\n",
      "Epoch 33/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2676 - accuracy: 0.8914\n",
      "Epoch 33: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2647 - accuracy: 0.8924 - val_loss: 0.3012 - val_accuracy: 0.8785\n",
      "Epoch 34/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2672 - accuracy: 0.8884\n",
      "Epoch 34: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.8880 - val_loss: 0.3008 - val_accuracy: 0.8723\n",
      "Epoch 35/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3070 - accuracy: 0.8871\n",
      "Epoch 35: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.8909 - val_loss: 0.3066 - val_accuracy: 0.8723\n",
      "Epoch 36/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2281 - accuracy: 0.9194\n",
      "Epoch 36: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2654 - accuracy: 0.8903 - val_loss: 0.3084 - val_accuracy: 0.8769\n",
      "Epoch 37/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3419 - accuracy: 0.8629\n",
      "Epoch 37: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2689 - accuracy: 0.8863 - val_loss: 0.3237 - val_accuracy: 0.8623\n",
      "Epoch 38/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2386 - accuracy: 0.8710\n",
      "Epoch 38: val_accuracy improved from 0.88000 to 0.88692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2674 - accuracy: 0.8884 - val_loss: 0.3072 - val_accuracy: 0.8869\n",
      "Epoch 39/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2651 - accuracy: 0.8548\n",
      "Epoch 39: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2673 - accuracy: 0.8872 - val_loss: 0.3066 - val_accuracy: 0.8723\n",
      "Epoch 40/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1911 - accuracy: 0.9274\n",
      "Epoch 40: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2723 - accuracy: 0.8859 - val_loss: 0.3384 - val_accuracy: 0.8508\n",
      "Epoch 41/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2693 - accuracy: 0.9032\n",
      "Epoch 41: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2621 - accuracy: 0.8919 - val_loss: 0.3094 - val_accuracy: 0.8715\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3263 - accuracy: 0.8710\n",
      "Epoch 42: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2559 - accuracy: 0.8980 - val_loss: 0.3077 - val_accuracy: 0.8700\n",
      "Epoch 43/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2339 - accuracy: 0.9194\n",
      "Epoch 43: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2538 - accuracy: 0.8951 - val_loss: 0.3033 - val_accuracy: 0.8715\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2424 - accuracy: 0.9113\n",
      "Epoch 44: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2529 - accuracy: 0.8944 - val_loss: 0.3270 - val_accuracy: 0.8623\n",
      "Epoch 45/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2533 - accuracy: 0.8952\n",
      "Epoch 45: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2615 - accuracy: 0.8913 - val_loss: 0.3018 - val_accuracy: 0.8808\n",
      "Epoch 46/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2652 - accuracy: 0.9032\n",
      "Epoch 46: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 0.8959 - val_loss: 0.3047 - val_accuracy: 0.8777\n",
      "Epoch 47/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2893 - accuracy: 0.8790\n",
      "Epoch 47: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2565 - accuracy: 0.8942 - val_loss: 0.3248 - val_accuracy: 0.8700\n",
      "Epoch 48/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2182 - accuracy: 0.9032\n",
      "Epoch 48: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2540 - accuracy: 0.8957 - val_loss: 0.2983 - val_accuracy: 0.8785\n",
      "Epoch 49/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2545 - accuracy: 0.8967\n",
      "Epoch 49: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.8976 - val_loss: 0.3061 - val_accuracy: 0.8754\n",
      "Epoch 50/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2512 - accuracy: 0.8940\n",
      "Epoch 50: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.8936 - val_loss: 0.3766 - val_accuracy: 0.8354\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3013 - accuracy: 0.8468\n",
      "Epoch 51: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2521 - accuracy: 0.8951 - val_loss: 0.3127 - val_accuracy: 0.8692\n",
      "Epoch 52/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2499 - accuracy: 0.8965\n",
      "Epoch 52: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.8978 - val_loss: 0.3008 - val_accuracy: 0.8838\n",
      "Epoch 53/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2462 - accuracy: 0.8979\n",
      "Epoch 53: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.8992 - val_loss: 0.3077 - val_accuracy: 0.8769\n",
      "Epoch 54/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.2449 - accuracy: 0.9015\n",
      "Epoch 54: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2459 - accuracy: 0.9011 - val_loss: 0.2998 - val_accuracy: 0.8831\n",
      "Epoch 55/1000\n",
      "29/42 [===================>..........] - ETA: 0s - loss: 0.2365 - accuracy: 0.9052\n",
      "Epoch 55: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.9042 - val_loss: 0.3007 - val_accuracy: 0.8715\n",
      "Epoch 56/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2888 - accuracy: 0.8952\n",
      "Epoch 56: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2584 - accuracy: 0.8934 - val_loss: 0.3021 - val_accuracy: 0.8731\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2134 - accuracy: 0.8952\n",
      "Epoch 57: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2596 - accuracy: 0.8913 - val_loss: 0.3246 - val_accuracy: 0.8615\n",
      "Epoch 58/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2459 - accuracy: 0.8989\n",
      "Epoch 58: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.8984 - val_loss: 0.3036 - val_accuracy: 0.8754\n",
      "Epoch 59/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2390 - accuracy: 0.9030\n",
      "Epoch 59: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2387 - accuracy: 0.9028 - val_loss: 0.3010 - val_accuracy: 0.8800\n",
      "Epoch 60/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2436 - accuracy: 0.8993\n",
      "Epoch 60: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2436 - accuracy: 0.8994 - val_loss: 0.2961 - val_accuracy: 0.8769\n",
      "Epoch 61/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2419 - accuracy: 0.9274\n",
      "Epoch 61: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2376 - accuracy: 0.9057 - val_loss: 0.2995 - val_accuracy: 0.8738\n",
      "Epoch 62/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2386 - accuracy: 0.9020\n",
      "Epoch 62: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2380 - accuracy: 0.9007 - val_loss: 0.3034 - val_accuracy: 0.8769\n",
      "Epoch 63/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2030 - accuracy: 0.9194\n",
      "Epoch 63: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.9009 - val_loss: 0.2980 - val_accuracy: 0.8815\n",
      "Epoch 64/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1916 - accuracy: 0.9194\n",
      "Epoch 64: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.8974 - val_loss: 0.3005 - val_accuracy: 0.8800\n",
      "Epoch 65/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2279 - accuracy: 0.9113\n",
      "Epoch 65: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.8972 - val_loss: 0.2985 - val_accuracy: 0.8808\n",
      "Epoch 66/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2411 - accuracy: 0.9003\n",
      "Epoch 66: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2406 - accuracy: 0.9017 - val_loss: 0.3063 - val_accuracy: 0.8754\n",
      "Epoch 67/1000\n",
      "29/42 [===================>..........] - ETA: 0s - loss: 0.2437 - accuracy: 0.8957\n",
      "Epoch 67: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2408 - accuracy: 0.8990 - val_loss: 0.3007 - val_accuracy: 0.8808\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2633 - accuracy: 0.8710\n",
      "Epoch 68: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2571 - accuracy: 0.8899 - val_loss: 0.3017 - val_accuracy: 0.8785\n",
      "Epoch 69/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2077 - accuracy: 0.9194\n",
      "Epoch 69: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2424 - accuracy: 0.8969 - val_loss: 0.2960 - val_accuracy: 0.8777\n",
      "Epoch 70/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2417 - accuracy: 0.9034\n",
      "Epoch 70: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2418 - accuracy: 0.9038 - val_loss: 0.3056 - val_accuracy: 0.8777\n",
      "Epoch 71/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2358 - accuracy: 0.9048\n",
      "Epoch 71: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2325 - accuracy: 0.9061 - val_loss: 0.3041 - val_accuracy: 0.8792\n",
      "Epoch 72/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2311 - accuracy: 0.9039\n",
      "Epoch 72: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2301 - accuracy: 0.9044 - val_loss: 0.3130 - val_accuracy: 0.8792\n",
      "Epoch 73/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3408 - accuracy: 0.8952\n",
      "Epoch 73: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2378 - accuracy: 0.9013 - val_loss: 0.3143 - val_accuracy: 0.8708\n",
      "Epoch 74/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1623 - accuracy: 0.9274\n",
      "Epoch 74: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2295 - accuracy: 0.9069 - val_loss: 0.3038 - val_accuracy: 0.8785\n",
      "Epoch 75/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1479 - accuracy: 0.9435\n",
      "Epoch 75: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2339 - accuracy: 0.9049 - val_loss: 0.3085 - val_accuracy: 0.8746\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2920 - accuracy: 0.8871\n",
      "Epoch 76: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2390 - accuracy: 0.8988 - val_loss: 0.3132 - val_accuracy: 0.8723\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2311 - accuracy: 0.8629\n",
      "Epoch 77: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2410 - accuracy: 0.8988 - val_loss: 0.3184 - val_accuracy: 0.8692\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2633 - accuracy: 0.8710\n",
      "Epoch 78: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2287 - accuracy: 0.9046 - val_loss: 0.3160 - val_accuracy: 0.8762\n",
      "Epoch 79/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2229 - accuracy: 0.9067\n",
      "Epoch 79: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2272 - accuracy: 0.9053 - val_loss: 0.3117 - val_accuracy: 0.8746\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2094 - accuracy: 0.9274\n",
      "Epoch 80: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2333 - accuracy: 0.9042 - val_loss: 0.3082 - val_accuracy: 0.8754\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2836 - accuracy: 0.8629\n",
      "Epoch 81: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2254 - accuracy: 0.9080 - val_loss: 0.3051 - val_accuracy: 0.8715\n",
      "Epoch 82/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2148 - accuracy: 0.9032\n",
      "Epoch 82: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2316 - accuracy: 0.9065 - val_loss: 0.3144 - val_accuracy: 0.8762\n",
      "Epoch 83/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2206 - accuracy: 0.9108\n",
      "Epoch 83: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2217 - accuracy: 0.9107 - val_loss: 0.3071 - val_accuracy: 0.8754\n",
      "Epoch 84/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2559 - accuracy: 0.8900\n",
      "Epoch 84: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.8928 - val_loss: 0.3086 - val_accuracy: 0.8754\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2613 - accuracy: 0.9113\n",
      "Epoch 85: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2228 - accuracy: 0.9074 - val_loss: 0.3152 - val_accuracy: 0.8746\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1998 - accuracy: 0.9355\n",
      "Epoch 86: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.9067 - val_loss: 0.3115 - val_accuracy: 0.8723\n",
      "Epoch 87/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2215 - accuracy: 0.9111\n",
      "Epoch 87: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2197 - accuracy: 0.9117 - val_loss: 0.3143 - val_accuracy: 0.8692\n",
      "Epoch 88/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1998 - accuracy: 0.9274\n",
      "Epoch 88: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2218 - accuracy: 0.9088 - val_loss: 0.3022 - val_accuracy: 0.8738\n",
      "Epoch 89/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2283 - accuracy: 0.9056\n",
      "Epoch 89: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.9063 - val_loss: 0.3221 - val_accuracy: 0.8677\n",
      "Epoch 90/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2186 - accuracy: 0.9097\n",
      "Epoch 90: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2186 - accuracy: 0.9101 - val_loss: 0.3207 - val_accuracy: 0.8731\n",
      "Epoch 91/1000\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.2193 - accuracy: 0.9131\n",
      "Epoch 91: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2239 - accuracy: 0.9107 - val_loss: 0.3519 - val_accuracy: 0.8500\n",
      "Epoch 92/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2431 - accuracy: 0.8985\n",
      "Epoch 92: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2408 - accuracy: 0.8992 - val_loss: 0.3112 - val_accuracy: 0.8769\n",
      "Epoch 93/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2124 - accuracy: 0.9435\n",
      "Epoch 93: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2163 - accuracy: 0.9128 - val_loss: 0.3059 - val_accuracy: 0.8715\n",
      "Epoch 94/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1844 - accuracy: 0.9435\n",
      "Epoch 94: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2161 - accuracy: 0.9128 - val_loss: 0.3192 - val_accuracy: 0.8662\n",
      "Epoch 95/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1805 - accuracy: 0.9113\n",
      "Epoch 95: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2162 - accuracy: 0.9126 - val_loss: 0.3159 - val_accuracy: 0.8746\n",
      "Epoch 96/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2132 - accuracy: 0.9115\n",
      "Epoch 96: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2154 - accuracy: 0.9105 - val_loss: 0.3165 - val_accuracy: 0.8800\n",
      "Epoch 97/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2318 - accuracy: 0.9056\n",
      "Epoch 97: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2286 - accuracy: 0.9082 - val_loss: 0.3485 - val_accuracy: 0.8723\n",
      "Epoch 98/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2400 - accuracy: 0.8949\n",
      "Epoch 98: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2418 - accuracy: 0.8959 - val_loss: 0.3086 - val_accuracy: 0.8715\n",
      "Epoch 99/1000\n",
      "30/42 [====================>.........] - ETA: 0s - loss: 0.2222 - accuracy: 0.9081\n",
      "Epoch 99: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2253 - accuracy: 0.9067 - val_loss: 0.3534 - val_accuracy: 0.8508\n",
      "Epoch 100/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2329 - accuracy: 0.9113\n",
      "Epoch 100: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2516 - accuracy: 0.8959 - val_loss: 0.3233 - val_accuracy: 0.8692\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1836 - accuracy: 0.9516\n",
      "Epoch 101: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2129 - accuracy: 0.9117 - val_loss: 0.3169 - val_accuracy: 0.8723\n",
      "Epoch 102/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2108 - accuracy: 0.9274\n",
      "Epoch 102: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2163 - accuracy: 0.9099 - val_loss: 0.3192 - val_accuracy: 0.8738\n",
      "Epoch 103/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1582 - accuracy: 0.9435\n",
      "Epoch 103: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2105 - accuracy: 0.9126 - val_loss: 0.3223 - val_accuracy: 0.8669\n",
      "Epoch 104/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2210 - accuracy: 0.9083\n",
      "Epoch 104: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2219 - accuracy: 0.9080 - val_loss: 0.3318 - val_accuracy: 0.8623\n",
      "Epoch 105/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2075 - accuracy: 0.9164\n",
      "Epoch 105: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2094 - accuracy: 0.9151 - val_loss: 0.3225 - val_accuracy: 0.8723\n",
      "Epoch 106/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2240 - accuracy: 0.9032\n",
      "Epoch 106: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2055 - accuracy: 0.9188 - val_loss: 0.3351 - val_accuracy: 0.8723\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1846 - accuracy: 0.9355\n",
      "Epoch 107: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2151 - accuracy: 0.9090 - val_loss: 0.3162 - val_accuracy: 0.8738\n",
      "Epoch 108/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2467 - accuracy: 0.8978\n",
      "Epoch 108: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8990 - val_loss: 0.3749 - val_accuracy: 0.8515\n",
      "Epoch 109/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2844 - accuracy: 0.8871\n",
      "Epoch 109: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2255 - accuracy: 0.9055 - val_loss: 0.3109 - val_accuracy: 0.8685\n",
      "Epoch 110/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2081 - accuracy: 0.9194\n",
      "Epoch 110: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2131 - accuracy: 0.9138 - val_loss: 0.3289 - val_accuracy: 0.8762\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2331 - accuracy: 0.9274\n",
      "Epoch 111: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2254 - accuracy: 0.9055 - val_loss: 0.3350 - val_accuracy: 0.8662\n",
      "Epoch 112/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2051 - accuracy: 0.9163\n",
      "Epoch 112: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2033 - accuracy: 0.9169 - val_loss: 0.3362 - val_accuracy: 0.8708\n",
      "Epoch 113/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2074 - accuracy: 0.9130\n",
      "Epoch 113: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2106 - accuracy: 0.9130 - val_loss: 0.3379 - val_accuracy: 0.8800\n",
      "Epoch 114/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2108 - accuracy: 0.9122\n",
      "Epoch 114: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2106 - accuracy: 0.9126 - val_loss: 0.3172 - val_accuracy: 0.8723\n",
      "Epoch 115/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2024 - accuracy: 0.9177\n",
      "Epoch 115: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2037 - accuracy: 0.9169 - val_loss: 0.3368 - val_accuracy: 0.8731\n",
      "Epoch 116/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2050 - accuracy: 0.9149\n",
      "Epoch 116: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.9150 - val_loss: 0.3670 - val_accuracy: 0.8677\n",
      "Epoch 117/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2137 - accuracy: 0.9103\n",
      "Epoch 117: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2137 - accuracy: 0.9103 - val_loss: 0.3609 - val_accuracy: 0.8685\n",
      "Epoch 118/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2055 - accuracy: 0.9172\n",
      "Epoch 118: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2074 - accuracy: 0.9163 - val_loss: 0.3340 - val_accuracy: 0.8677\n",
      "Epoch 119/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2005 - accuracy: 0.9166\n",
      "Epoch 119: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2017 - accuracy: 0.9165 - val_loss: 0.3233 - val_accuracy: 0.8731\n",
      "Epoch 120/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1986 - accuracy: 0.9181\n",
      "Epoch 120: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1998 - accuracy: 0.9184 - val_loss: 0.3334 - val_accuracy: 0.8715\n",
      "Epoch 121/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1969 - accuracy: 0.9206\n",
      "Epoch 121: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9198 - val_loss: 0.3434 - val_accuracy: 0.8731\n",
      "Epoch 122/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2015 - accuracy: 0.9216\n",
      "Epoch 122: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.9211 - val_loss: 0.3688 - val_accuracy: 0.8708\n",
      "Epoch 123/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1986 - accuracy: 0.9177\n",
      "Epoch 123: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1994 - accuracy: 0.9167 - val_loss: 0.3311 - val_accuracy: 0.8692\n",
      "Epoch 124/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1805 - accuracy: 0.9355\n",
      "Epoch 124: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2015 - accuracy: 0.9186 - val_loss: 0.3337 - val_accuracy: 0.8662\n",
      "Epoch 125/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1574 - accuracy: 0.9516\n",
      "Epoch 125: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1944 - accuracy: 0.9217 - val_loss: 0.3544 - val_accuracy: 0.8662\n",
      "Epoch 126/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1991 - accuracy: 0.9172\n",
      "Epoch 126: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1995 - accuracy: 0.9171 - val_loss: 0.3539 - val_accuracy: 0.8669\n",
      "Epoch 127/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1940 - accuracy: 0.9237\n",
      "Epoch 127: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1928 - accuracy: 0.9234 - val_loss: 0.3430 - val_accuracy: 0.8677\n",
      "Epoch 128/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2026 - accuracy: 0.9162\n",
      "Epoch 128: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1988 - accuracy: 0.9178 - val_loss: 0.3513 - val_accuracy: 0.8700\n",
      "Epoch 129/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1181 - accuracy: 0.9677\n",
      "Epoch 129: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1881 - accuracy: 0.9225 - val_loss: 0.3437 - val_accuracy: 0.8669\n",
      "Epoch 130/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1972 - accuracy: 0.9032\n",
      "Epoch 130: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2024 - accuracy: 0.9169 - val_loss: 0.3622 - val_accuracy: 0.8646\n",
      "Epoch 131/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1922 - accuracy: 0.9212\n",
      "Epoch 131: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1915 - accuracy: 0.9225 - val_loss: 0.3387 - val_accuracy: 0.8662\n",
      "Epoch 132/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1936 - accuracy: 0.9222\n",
      "Epoch 132: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1938 - accuracy: 0.9215 - val_loss: 0.3475 - val_accuracy: 0.8715\n",
      "Epoch 133/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2016 - accuracy: 0.9194\n",
      "Epoch 133: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1958 - accuracy: 0.9178 - val_loss: 0.3411 - val_accuracy: 0.8731\n",
      "Epoch 134/1000\n",
      "30/42 [====================>.........] - ETA: 0s - loss: 0.1827 - accuracy: 0.9245\n",
      "Epoch 134: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1915 - accuracy: 0.9207 - val_loss: 0.3587 - val_accuracy: 0.8654\n",
      "Epoch 135/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1897 - accuracy: 0.9249\n",
      "Epoch 135: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1898 - accuracy: 0.9253 - val_loss: 0.3388 - val_accuracy: 0.8677\n",
      "Epoch 136/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1216 - accuracy: 0.9516\n",
      "Epoch 136: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1888 - accuracy: 0.9255 - val_loss: 0.3805 - val_accuracy: 0.8662\n",
      "Epoch 137/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1935 - accuracy: 0.9204\n",
      "Epoch 137: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1907 - accuracy: 0.9211 - val_loss: 0.3419 - val_accuracy: 0.8669\n",
      "Epoch 138/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1828 - accuracy: 0.9237\n",
      "Epoch 138: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1861 - accuracy: 0.9226 - val_loss: 0.3579 - val_accuracy: 0.8700\n",
      "Epoch 139/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1884 - accuracy: 0.9211\n",
      "Epoch 139: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1881 - accuracy: 0.9217 - val_loss: 0.3886 - val_accuracy: 0.8692\n",
      "Epoch 140/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1840 - accuracy: 0.9285\n",
      "Epoch 140: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1872 - accuracy: 0.9250 - val_loss: 0.3684 - val_accuracy: 0.8662\n",
      "Epoch 141/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1990 - accuracy: 0.9113\n",
      "Epoch 141: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1820 - accuracy: 0.9248 - val_loss: 0.3567 - val_accuracy: 0.8662\n",
      "Epoch 142/1000\n",
      "28/42 [===================>..........] - ETA: 0s - loss: 0.1781 - accuracy: 0.9289\n",
      "Epoch 142: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.9255 - val_loss: 0.3629 - val_accuracy: 0.8608\n",
      "Epoch 143/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.1900 - accuracy: 0.9224\n",
      "Epoch 143: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1935 - accuracy: 0.9205 - val_loss: 0.3628 - val_accuracy: 0.8646\n",
      "Epoch 144/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1879 - accuracy: 0.9223\n",
      "Epoch 144: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1903 - accuracy: 0.9213 - val_loss: 0.3638 - val_accuracy: 0.8600\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1743 - accuracy: 0.9113\n",
      "Epoch 145: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1891 - accuracy: 0.9221 - val_loss: 0.3558 - val_accuracy: 0.8662\n",
      "Epoch 146/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1889 - accuracy: 0.9166\n",
      "Epoch 146: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.9155 - val_loss: 0.3504 - val_accuracy: 0.8692\n",
      "Epoch 147/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1693 - accuracy: 0.9274\n",
      "Epoch 147: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1908 - accuracy: 0.9201 - val_loss: 0.3583 - val_accuracy: 0.8646\n",
      "Epoch 148/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1854 - accuracy: 0.9217\n",
      "Epoch 148: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.9209 - val_loss: 0.3719 - val_accuracy: 0.8700\n",
      "Epoch 149/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1871 - accuracy: 0.9213\n",
      "Epoch 149: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1867 - accuracy: 0.9223 - val_loss: 0.3600 - val_accuracy: 0.8692\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1717 - accuracy: 0.9355\n",
      "Epoch 150: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.9280 - val_loss: 0.3702 - val_accuracy: 0.8738\n",
      "Epoch 151/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1887 - accuracy: 0.9249\n",
      "Epoch 151: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1900 - accuracy: 0.9242 - val_loss: 0.3684 - val_accuracy: 0.8646\n",
      "Epoch 152/1000\n",
      "30/42 [====================>.........] - ETA: 0s - loss: 0.1768 - accuracy: 0.9253\n",
      "Epoch 152: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1782 - accuracy: 0.9250 - val_loss: 0.3614 - val_accuracy: 0.8715\n",
      "Epoch 153/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1829 - accuracy: 0.9113\n",
      "Epoch 153: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.9169 - val_loss: 0.3743 - val_accuracy: 0.8508\n",
      "Epoch 154/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1674 - accuracy: 0.9274\n",
      "Epoch 154: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1802 - accuracy: 0.9244 - val_loss: 0.3739 - val_accuracy: 0.8577\n",
      "Epoch 155/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2579 - accuracy: 0.9032\n",
      "Epoch 155: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1773 - accuracy: 0.9255 - val_loss: 0.3740 - val_accuracy: 0.8685\n",
      "Epoch 156/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1975 - accuracy: 0.9516\n",
      "Epoch 156: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.9223 - val_loss: 0.3646 - val_accuracy: 0.8662\n",
      "Epoch 157/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1752 - accuracy: 0.9286\n",
      "Epoch 157: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1755 - accuracy: 0.9284 - val_loss: 0.3680 - val_accuracy: 0.8623\n",
      "Epoch 158/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1720 - accuracy: 0.9303\n",
      "Epoch 158: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1720 - accuracy: 0.9303 - val_loss: 0.3748 - val_accuracy: 0.8708\n",
      "Epoch 159/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1760 - accuracy: 0.9300\n",
      "Epoch 159: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.9286 - val_loss: 0.3680 - val_accuracy: 0.8638\n",
      "Epoch 160/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1650 - accuracy: 0.9194\n",
      "Epoch 160: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1757 - accuracy: 0.9282 - val_loss: 0.4012 - val_accuracy: 0.8662\n",
      "Epoch 161/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1740 - accuracy: 0.9280\n",
      "Epoch 161: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 0.9277 - val_loss: 0.3759 - val_accuracy: 0.8723\n",
      "Epoch 162/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1680 - accuracy: 0.9274\n",
      "Epoch 162: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1741 - accuracy: 0.9286 - val_loss: 0.3878 - val_accuracy: 0.8677\n",
      "Epoch 163/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1706 - accuracy: 0.9323\n",
      "Epoch 163: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1692 - accuracy: 0.9334 - val_loss: 0.3695 - val_accuracy: 0.8715\n",
      "Epoch 164/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1712 - accuracy: 0.9323\n",
      "Epoch 164: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1704 - accuracy: 0.9319 - val_loss: 0.3937 - val_accuracy: 0.8631\n",
      "Epoch 165/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.1737 - accuracy: 0.9325\n",
      "Epoch 165: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1711 - accuracy: 0.9330 - val_loss: 0.3847 - val_accuracy: 0.8662\n",
      "Epoch 166/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1646 - accuracy: 0.9435\n",
      "Epoch 166: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1699 - accuracy: 0.9300 - val_loss: 0.3856 - val_accuracy: 0.8631\n",
      "Epoch 167/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1719 - accuracy: 0.9278\n",
      "Epoch 167: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1726 - accuracy: 0.9278 - val_loss: 0.3821 - val_accuracy: 0.8438\n",
      "Epoch 168/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.1756 - accuracy: 0.9285\n",
      "Epoch 168: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.9265 - val_loss: 0.3944 - val_accuracy: 0.8654\n",
      "Epoch 169/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1350 - accuracy: 0.9597\n",
      "Epoch 169: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1675 - accuracy: 0.9328 - val_loss: 0.3942 - val_accuracy: 0.8746\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 23s - loss: 2.6743 - accuracy: 0.5242\n",
      "Epoch 1: val_accuracy improved from -inf to 0.74538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.7126 - accuracy: 0.6329 - val_loss: 0.5311 - val_accuracy: 0.7454\n",
      "Epoch 2/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.5007 - accuracy: 0.7742\n",
      "Epoch 2: val_accuracy improved from 0.74538 to 0.82923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.7937 - val_loss: 0.4074 - val_accuracy: 0.8292\n",
      "Epoch 3/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3507 - accuracy: 0.8710\n",
      "Epoch 3: val_accuracy improved from 0.82923 to 0.84077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3974 - accuracy: 0.8278 - val_loss: 0.3769 - val_accuracy: 0.8408\n",
      "Epoch 4/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3526 - accuracy: 0.8387\n",
      "Epoch 4: val_accuracy did not improve from 0.84077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4037 - accuracy: 0.8187 - val_loss: 0.3781 - val_accuracy: 0.8346\n",
      "Epoch 5/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4037 - accuracy: 0.8065\n",
      "Epoch 5: val_accuracy improved from 0.84077 to 0.84692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3580 - accuracy: 0.8480 - val_loss: 0.3533 - val_accuracy: 0.8469\n",
      "Epoch 6/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4264 - accuracy: 0.8468\n",
      "Epoch 6: val_accuracy improved from 0.84692 to 0.85462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3418 - accuracy: 0.8595 - val_loss: 0.3564 - val_accuracy: 0.8546\n",
      "Epoch 7/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3102 - accuracy: 0.8871\n",
      "Epoch 7: val_accuracy did not improve from 0.85462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8620 - val_loss: 0.3463 - val_accuracy: 0.8515\n",
      "Epoch 8/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.3293 - accuracy: 0.8654\n",
      "Epoch 8: val_accuracy did not improve from 0.85462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8659 - val_loss: 0.3426 - val_accuracy: 0.8531\n",
      "Epoch 9/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.3265 - accuracy: 0.8590\n",
      "Epoch 9: val_accuracy improved from 0.85462 to 0.85692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3284 - accuracy: 0.8597 - val_loss: 0.3449 - val_accuracy: 0.8569\n",
      "Epoch 10/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3232 - accuracy: 0.8621\n",
      "Epoch 10: val_accuracy improved from 0.85692 to 0.86000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3241 - accuracy: 0.8609 - val_loss: 0.3349 - val_accuracy: 0.8600\n",
      "Epoch 11/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.3146 - accuracy: 0.8668\n",
      "Epoch 11: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.8659 - val_loss: 0.3513 - val_accuracy: 0.8538\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2919 - accuracy: 0.8790\n",
      "Epoch 12: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3151 - accuracy: 0.8643 - val_loss: 0.3451 - val_accuracy: 0.8562\n",
      "Epoch 13/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3350 - accuracy: 0.8548\n",
      "Epoch 13: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8597 - val_loss: 0.3399 - val_accuracy: 0.8508\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3926 - accuracy: 0.8226\n",
      "Epoch 14: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.8667 - val_loss: 0.3532 - val_accuracy: 0.8538\n",
      "Epoch 15/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3089 - accuracy: 0.8714\n",
      "Epoch 15: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8711 - val_loss: 0.3327 - val_accuracy: 0.8592\n",
      "Epoch 16/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3040 - accuracy: 0.8754\n",
      "Epoch 16: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8749 - val_loss: 0.3877 - val_accuracy: 0.8392\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3317 - accuracy: 0.8629\n",
      "Epoch 17: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3210 - accuracy: 0.8590 - val_loss: 0.4142 - val_accuracy: 0.8108\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3992 - accuracy: 0.8306\n",
      "Epoch 18: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3420 - accuracy: 0.8459 - val_loss: 0.3480 - val_accuracy: 0.8462\n",
      "Epoch 19/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3049 - accuracy: 0.8714\n",
      "Epoch 19: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8703 - val_loss: 0.3459 - val_accuracy: 0.8523\n",
      "Epoch 20/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.3019 - accuracy: 0.8703\n",
      "Epoch 20: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3057 - accuracy: 0.8690 - val_loss: 0.3290 - val_accuracy: 0.8600\n",
      "Epoch 21/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.3020 - accuracy: 0.8753\n",
      "Epoch 21: val_accuracy improved from 0.86000 to 0.86615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3043 - accuracy: 0.8740 - val_loss: 0.3359 - val_accuracy: 0.8662\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2940 - accuracy: 0.8805\n",
      "Epoch 22: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2940 - accuracy: 0.8805 - val_loss: 0.3262 - val_accuracy: 0.8638\n",
      "Epoch 23/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3297 - accuracy: 0.8306\n",
      "Epoch 23: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3021 - accuracy: 0.8717 - val_loss: 0.3329 - val_accuracy: 0.8500\n",
      "Epoch 24/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3142 - accuracy: 0.8790\n",
      "Epoch 24: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2978 - accuracy: 0.8736 - val_loss: 0.3233 - val_accuracy: 0.8662\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4253 - accuracy: 0.8226\n",
      "Epoch 25: val_accuracy improved from 0.86615 to 0.86692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2941 - accuracy: 0.8786 - val_loss: 0.3260 - val_accuracy: 0.8669\n",
      "Epoch 26/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3285 - accuracy: 0.8790\n",
      "Epoch 26: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3012 - accuracy: 0.8699 - val_loss: 0.3295 - val_accuracy: 0.8600\n",
      "Epoch 27/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3058 - accuracy: 0.8741\n",
      "Epoch 27: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8745 - val_loss: 0.3229 - val_accuracy: 0.8669\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2755 - accuracy: 0.9113\n",
      "Epoch 28: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2900 - accuracy: 0.8797 - val_loss: 0.3515 - val_accuracy: 0.8615\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3132 - accuracy: 0.8387\n",
      "Epoch 29: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2927 - accuracy: 0.8780 - val_loss: 0.3219 - val_accuracy: 0.8662\n",
      "Epoch 30/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2842 - accuracy: 0.8815\n",
      "Epoch 30: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2825 - accuracy: 0.8824 - val_loss: 0.3163 - val_accuracy: 0.8669\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2870 - accuracy: 0.8832\n",
      "Epoch 31: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2870 - accuracy: 0.8832 - val_loss: 0.3327 - val_accuracy: 0.8646\n",
      "Epoch 32/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2849 - accuracy: 0.8839\n",
      "Epoch 32: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2856 - accuracy: 0.8828 - val_loss: 0.3199 - val_accuracy: 0.8638\n",
      "Epoch 33/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2870 - accuracy: 0.8786\n",
      "Epoch 33: val_accuracy improved from 0.86692 to 0.87462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2863 - accuracy: 0.8794 - val_loss: 0.3233 - val_accuracy: 0.8746\n",
      "Epoch 34/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2815 - accuracy: 0.8838\n",
      "Epoch 34: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2810 - accuracy: 0.8838 - val_loss: 0.3408 - val_accuracy: 0.8415\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2955 - accuracy: 0.8738\n",
      "Epoch 35: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2955 - accuracy: 0.8738 - val_loss: 0.4230 - val_accuracy: 0.8262\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2965 - accuracy: 0.8732\n",
      "Epoch 36: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2965 - accuracy: 0.8732 - val_loss: 0.3255 - val_accuracy: 0.8677\n",
      "Epoch 37/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3079 - accuracy: 0.8468\n",
      "Epoch 37: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2754 - accuracy: 0.8859 - val_loss: 0.3166 - val_accuracy: 0.8677\n",
      "Epoch 38/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2218 - accuracy: 0.9194\n",
      "Epoch 38: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2744 - accuracy: 0.8857 - val_loss: 0.3133 - val_accuracy: 0.8669\n",
      "Epoch 39/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2699 - accuracy: 0.8906\n",
      "Epoch 39: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2697 - accuracy: 0.8911 - val_loss: 0.3102 - val_accuracy: 0.8708\n",
      "Epoch 40/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2773 - accuracy: 0.8809\n",
      "Epoch 40: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2787 - accuracy: 0.8809 - val_loss: 0.3403 - val_accuracy: 0.8554\n",
      "Epoch 41/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2769 - accuracy: 0.8851\n",
      "Epoch 41: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2755 - accuracy: 0.8849 - val_loss: 0.3306 - val_accuracy: 0.8623\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2061 - accuracy: 0.9194\n",
      "Epoch 42: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2762 - accuracy: 0.8855 - val_loss: 0.3465 - val_accuracy: 0.8631\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2703 - accuracy: 0.8930\n",
      "Epoch 43: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.8930 - val_loss: 0.3616 - val_accuracy: 0.8508\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2524 - accuracy: 0.8952\n",
      "Epoch 44: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2782 - accuracy: 0.8836 - val_loss: 0.3094 - val_accuracy: 0.8708\n",
      "Epoch 45/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2167 - accuracy: 0.8871\n",
      "Epoch 45: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2679 - accuracy: 0.8899 - val_loss: 0.3121 - val_accuracy: 0.8731\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2581 - accuracy: 0.8963\n",
      "Epoch 46: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2581 - accuracy: 0.8963 - val_loss: 0.3042 - val_accuracy: 0.8708\n",
      "Epoch 47/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2777 - accuracy: 0.8861\n",
      "Epoch 47: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2799 - accuracy: 0.8857 - val_loss: 0.3220 - val_accuracy: 0.8677\n",
      "Epoch 48/1000\n",
      "27/42 [==================>...........] - ETA: 0s - loss: 0.2513 - accuracy: 0.9002\n",
      "Epoch 48: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2583 - accuracy: 0.8955 - val_loss: 0.3071 - val_accuracy: 0.8715\n",
      "Epoch 49/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1732 - accuracy: 0.9435\n",
      "Epoch 49: val_accuracy improved from 0.87462 to 0.87692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2587 - accuracy: 0.8971 - val_loss: 0.3037 - val_accuracy: 0.8769\n",
      "Epoch 50/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3030 - accuracy: 0.8710\n",
      "Epoch 50: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2605 - accuracy: 0.8930 - val_loss: 0.3104 - val_accuracy: 0.8754\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2140 - accuracy: 0.9032\n",
      "Epoch 51: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.8963 - val_loss: 0.3083 - val_accuracy: 0.8708\n",
      "Epoch 52/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2817 - accuracy: 0.8871\n",
      "Epoch 52: val_accuracy improved from 0.87692 to 0.87846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.8972 - val_loss: 0.3086 - val_accuracy: 0.8785\n",
      "Epoch 53/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2597 - accuracy: 0.8919\n",
      "Epoch 53: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2607 - accuracy: 0.8917 - val_loss: 0.3060 - val_accuracy: 0.8708\n",
      "Epoch 54/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2719 - accuracy: 0.8790\n",
      "Epoch 54: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2563 - accuracy: 0.8982 - val_loss: 0.3161 - val_accuracy: 0.8692\n",
      "Epoch 55/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3173 - accuracy: 0.8548\n",
      "Epoch 55: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2705 - accuracy: 0.8876 - val_loss: 0.3449 - val_accuracy: 0.8646\n",
      "Epoch 56/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1827 - accuracy: 0.9355\n",
      "Epoch 56: val_accuracy improved from 0.87846 to 0.87923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2640 - accuracy: 0.8897 - val_loss: 0.3054 - val_accuracy: 0.8792\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2037 - accuracy: 0.9113\n",
      "Epoch 57: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2547 - accuracy: 0.8967 - val_loss: 0.3323 - val_accuracy: 0.8646\n",
      "Epoch 58/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3802 - accuracy: 0.8387\n",
      "Epoch 58: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.8980 - val_loss: 0.3031 - val_accuracy: 0.8731\n",
      "Epoch 59/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2633 - accuracy: 0.8710\n",
      "Epoch 59: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.8986 - val_loss: 0.3387 - val_accuracy: 0.8715\n",
      "Epoch 60/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2414 - accuracy: 0.8952\n",
      "Epoch 60: val_accuracy improved from 0.87923 to 0.88000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2560 - accuracy: 0.8944 - val_loss: 0.3094 - val_accuracy: 0.8800\n",
      "Epoch 61/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2476 - accuracy: 0.9002\n",
      "Epoch 61: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.8996 - val_loss: 0.3094 - val_accuracy: 0.8762\n",
      "Epoch 62/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2531 - accuracy: 0.8972\n",
      "Epoch 62: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2560 - accuracy: 0.8955 - val_loss: 0.3257 - val_accuracy: 0.8638\n",
      "Epoch 63/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2377 - accuracy: 0.9039\n",
      "Epoch 63: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2438 - accuracy: 0.9021 - val_loss: 0.3083 - val_accuracy: 0.8800\n",
      "Epoch 64/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2406 - accuracy: 0.9018\n",
      "Epoch 64: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2403 - accuracy: 0.9028 - val_loss: 0.3225 - val_accuracy: 0.8785\n",
      "Epoch 65/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3080 - accuracy: 0.8790\n",
      "Epoch 65: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.9023 - val_loss: 0.3077 - val_accuracy: 0.8769\n",
      "Epoch 66/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2664 - accuracy: 0.9113\n",
      "Epoch 66: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2425 - accuracy: 0.9013 - val_loss: 0.3817 - val_accuracy: 0.8585\n",
      "Epoch 67/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2524 - accuracy: 0.8977\n",
      "Epoch 67: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.8994 - val_loss: 0.3196 - val_accuracy: 0.8762\n",
      "Epoch 68/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2441 - accuracy: 0.9017\n",
      "Epoch 68: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.9017 - val_loss: 0.3130 - val_accuracy: 0.8769\n",
      "Epoch 69/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2545 - accuracy: 0.8952\n",
      "Epoch 69: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.9019 - val_loss: 0.3102 - val_accuracy: 0.8746\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2428 - accuracy: 0.9032\n",
      "Epoch 70: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2370 - accuracy: 0.9038 - val_loss: 0.3156 - val_accuracy: 0.8708\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2182 - accuracy: 0.9032\n",
      "Epoch 71: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2350 - accuracy: 0.9078 - val_loss: 0.3162 - val_accuracy: 0.8777\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2813 - accuracy: 0.8952\n",
      "Epoch 72: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2364 - accuracy: 0.9049 - val_loss: 0.3102 - val_accuracy: 0.8785\n",
      "Epoch 73/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2025 - accuracy: 0.9032\n",
      "Epoch 73: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.8961 - val_loss: 0.3190 - val_accuracy: 0.8762\n",
      "Epoch 74/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2349 - accuracy: 0.9065\n",
      "Epoch 74: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2378 - accuracy: 0.9044 - val_loss: 0.3098 - val_accuracy: 0.8715\n",
      "Epoch 75/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2310 - accuracy: 0.9032\n",
      "Epoch 75: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2584 - accuracy: 0.8967 - val_loss: 0.3594 - val_accuracy: 0.8492\n",
      "Epoch 76/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2520 - accuracy: 0.8933\n",
      "Epoch 76: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.8986 - val_loss: 0.3115 - val_accuracy: 0.8723\n",
      "Epoch 77/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2415 - accuracy: 0.9024\n",
      "Epoch 77: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2388 - accuracy: 0.9036 - val_loss: 0.3525 - val_accuracy: 0.8577\n",
      "Epoch 78/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2436 - accuracy: 0.8993\n",
      "Epoch 78: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8990 - val_loss: 0.3131 - val_accuracy: 0.8746\n",
      "Epoch 79/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2359 - accuracy: 0.9081\n",
      "Epoch 79: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2348 - accuracy: 0.9084 - val_loss: 0.3380 - val_accuracy: 0.8608\n",
      "Epoch 80/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2275 - accuracy: 0.9081\n",
      "Epoch 80: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2308 - accuracy: 0.9055 - val_loss: 0.3084 - val_accuracy: 0.8746\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1552 - accuracy: 0.9677\n",
      "Epoch 81: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2322 - accuracy: 0.9044 - val_loss: 0.3181 - val_accuracy: 0.8708\n",
      "Epoch 82/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2720 - accuracy: 0.9032\n",
      "Epoch 82: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2255 - accuracy: 0.9126 - val_loss: 0.3468 - val_accuracy: 0.8646\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2075 - accuracy: 0.9274\n",
      "Epoch 83: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2264 - accuracy: 0.9109 - val_loss: 0.3153 - val_accuracy: 0.8700\n",
      "Epoch 84/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1700 - accuracy: 0.9274\n",
      "Epoch 84: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2388 - accuracy: 0.9030 - val_loss: 0.3578 - val_accuracy: 0.8631\n",
      "Epoch 85/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2232 - accuracy: 0.9088\n",
      "Epoch 85: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2288 - accuracy: 0.9048 - val_loss: 0.3286 - val_accuracy: 0.8677\n",
      "Epoch 86/1000\n",
      "30/42 [====================>.........] - ETA: 0s - loss: 0.2338 - accuracy: 0.9078\n",
      "Epoch 86: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2344 - accuracy: 0.9073 - val_loss: 0.3010 - val_accuracy: 0.8731\n",
      "Epoch 87/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2231 - accuracy: 0.9070\n",
      "Epoch 87: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2272 - accuracy: 0.9055 - val_loss: 0.3106 - val_accuracy: 0.8731\n",
      "Epoch 88/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2153 - accuracy: 0.9141\n",
      "Epoch 88: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2165 - accuracy: 0.9146 - val_loss: 0.3196 - val_accuracy: 0.8762\n",
      "Epoch 89/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2168 - accuracy: 0.9123\n",
      "Epoch 89: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2162 - accuracy: 0.9126 - val_loss: 0.3176 - val_accuracy: 0.8723\n",
      "Epoch 90/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2212 - accuracy: 0.9117\n",
      "Epoch 90: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.9107 - val_loss: 0.3206 - val_accuracy: 0.8762\n",
      "Epoch 91/1000\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.2271 - accuracy: 0.9065\n",
      "Epoch 91: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2301 - accuracy: 0.9053 - val_loss: 0.3178 - val_accuracy: 0.8715\n",
      "Epoch 92/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1205 - accuracy: 0.9435\n",
      "Epoch 92: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9146 - val_loss: 0.3444 - val_accuracy: 0.8654\n",
      "Epoch 93/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2550 - accuracy: 0.8871\n",
      "Epoch 93: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2208 - accuracy: 0.9088 - val_loss: 0.3322 - val_accuracy: 0.8715\n",
      "Epoch 94/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1919 - accuracy: 0.9355\n",
      "Epoch 94: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2217 - accuracy: 0.9113 - val_loss: 0.3152 - val_accuracy: 0.8715\n",
      "Epoch 95/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2203 - accuracy: 0.9111\n",
      "Epoch 95: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2201 - accuracy: 0.9101 - val_loss: 0.3319 - val_accuracy: 0.8662\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2082 - accuracy: 0.9355\n",
      "Epoch 96: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2187 - accuracy: 0.9126 - val_loss: 0.3336 - val_accuracy: 0.8600\n",
      "Epoch 97/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1902 - accuracy: 0.9355\n",
      "Epoch 97: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2245 - accuracy: 0.9128 - val_loss: 0.3083 - val_accuracy: 0.8708\n",
      "Epoch 98/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1960 - accuracy: 0.9435\n",
      "Epoch 98: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2251 - accuracy: 0.9124 - val_loss: 0.3158 - val_accuracy: 0.8723\n",
      "Epoch 99/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.2151 - accuracy: 0.9113\n",
      "Epoch 99: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.9117 - val_loss: 0.3229 - val_accuracy: 0.8692\n",
      "Epoch 100/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1999 - accuracy: 0.9194\n",
      "Epoch 100: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2143 - accuracy: 0.9121 - val_loss: 0.3273 - val_accuracy: 0.8715\n",
      "Epoch 101/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2309 - accuracy: 0.8992\n",
      "Epoch 101: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2292 - accuracy: 0.9001 - val_loss: 0.3307 - val_accuracy: 0.8654\n",
      "Epoch 102/1000\n",
      "30/42 [====================>.........] - ETA: 0s - loss: 0.2311 - accuracy: 0.9000\n",
      "Epoch 102: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9063 - val_loss: 0.3446 - val_accuracy: 0.8677\n",
      "Epoch 103/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2520 - accuracy: 0.9194\n",
      "Epoch 103: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.9026 - val_loss: 0.3236 - val_accuracy: 0.8685\n",
      "Epoch 104/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2206 - accuracy: 0.9123\n",
      "Epoch 104: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2203 - accuracy: 0.9121 - val_loss: 0.3422 - val_accuracy: 0.8638\n",
      "Epoch 105/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2273 - accuracy: 0.9078\n",
      "Epoch 105: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2254 - accuracy: 0.9086 - val_loss: 0.3112 - val_accuracy: 0.8662\n",
      "Epoch 106/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2248 - accuracy: 0.9111\n",
      "Epoch 106: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2273 - accuracy: 0.9082 - val_loss: 0.3312 - val_accuracy: 0.8715\n",
      "Epoch 107/1000\n",
      "30/42 [====================>.........] - ETA: 0s - loss: 0.2132 - accuracy: 0.9140\n",
      "Epoch 107: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2084 - accuracy: 0.9176 - val_loss: 0.3397 - val_accuracy: 0.8692\n",
      "Epoch 108/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1336 - accuracy: 0.9516\n",
      "Epoch 108: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2110 - accuracy: 0.9142 - val_loss: 0.3162 - val_accuracy: 0.8708\n",
      "Epoch 109/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2195 - accuracy: 0.9105\n",
      "Epoch 109: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2179 - accuracy: 0.9113 - val_loss: 0.3518 - val_accuracy: 0.8623\n",
      "Epoch 110/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2193 - accuracy: 0.9111\n",
      "Epoch 110: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2209 - accuracy: 0.9107 - val_loss: 0.3327 - val_accuracy: 0.8669\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2497 - accuracy: 0.9032\n",
      "Epoch 111: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2144 - accuracy: 0.9126 - val_loss: 0.3492 - val_accuracy: 0.8631\n",
      "Epoch 112/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2078 - accuracy: 0.9170\n",
      "Epoch 112: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2077 - accuracy: 0.9171 - val_loss: 0.3162 - val_accuracy: 0.8746\n",
      "Epoch 113/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2034 - accuracy: 0.9190\n",
      "Epoch 113: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2057 - accuracy: 0.9184 - val_loss: 0.3338 - val_accuracy: 0.8654\n",
      "Epoch 114/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2060 - accuracy: 0.9167\n",
      "Epoch 114: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 0.9175 - val_loss: 0.3239 - val_accuracy: 0.8708\n",
      "Epoch 115/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2192 - accuracy: 0.9121\n",
      "Epoch 115: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.9124 - val_loss: 0.3573 - val_accuracy: 0.8569\n",
      "Epoch 116/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2147 - accuracy: 0.9102\n",
      "Epoch 116: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2131 - accuracy: 0.9111 - val_loss: 0.3322 - val_accuracy: 0.8677\n",
      "Epoch 117/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1996 - accuracy: 0.9202\n",
      "Epoch 117: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2004 - accuracy: 0.9200 - val_loss: 0.3402 - val_accuracy: 0.8715\n",
      "Epoch 118/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2232 - accuracy: 0.9194\n",
      "Epoch 118: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 0.9161 - val_loss: 0.3304 - val_accuracy: 0.8646\n",
      "Epoch 119/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2059 - accuracy: 0.9203\n",
      "Epoch 119: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 0.9203 - val_loss: 0.3272 - val_accuracy: 0.8708\n",
      "Epoch 120/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.0990 - accuracy: 0.9677\n",
      "Epoch 120: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2023 - accuracy: 0.9188 - val_loss: 0.3491 - val_accuracy: 0.8662\n",
      "Epoch 121/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2045 - accuracy: 0.9202\n",
      "Epoch 121: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2053 - accuracy: 0.9192 - val_loss: 0.3245 - val_accuracy: 0.8708\n",
      "Epoch 122/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2056 - accuracy: 0.9168\n",
      "Epoch 122: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2085 - accuracy: 0.9148 - val_loss: 0.3480 - val_accuracy: 0.8662\n",
      "Epoch 123/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2117 - accuracy: 0.9151\n",
      "Epoch 123: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2114 - accuracy: 0.9163 - val_loss: 0.3816 - val_accuracy: 0.8485\n",
      "Epoch 124/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2072 - accuracy: 0.9146\n",
      "Epoch 124: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2074 - accuracy: 0.9151 - val_loss: 0.3174 - val_accuracy: 0.8662\n",
      "Epoch 125/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2349 - accuracy: 0.8952\n",
      "Epoch 125: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1977 - accuracy: 0.9205 - val_loss: 0.3393 - val_accuracy: 0.8654\n",
      "Epoch 126/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2042 - accuracy: 0.9173\n",
      "Epoch 126: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2022 - accuracy: 0.9167 - val_loss: 0.3666 - val_accuracy: 0.8662\n",
      "Epoch 127/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2923 - accuracy: 0.8629\n",
      "Epoch 127: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 0.9121 - val_loss: 0.3387 - val_accuracy: 0.8669\n",
      "Epoch 128/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1370 - accuracy: 0.9435\n",
      "Epoch 128: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1975 - accuracy: 0.9186 - val_loss: 0.3391 - val_accuracy: 0.8700\n",
      "Epoch 129/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1658 - accuracy: 0.9516\n",
      "Epoch 129: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1947 - accuracy: 0.9236 - val_loss: 0.3527 - val_accuracy: 0.8677\n",
      "Epoch 130/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1974 - accuracy: 0.9198\n",
      "Epoch 130: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1972 - accuracy: 0.9205 - val_loss: 0.3260 - val_accuracy: 0.8723\n",
      "Epoch 131/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1978 - accuracy: 0.9181\n",
      "Epoch 131: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.9178 - val_loss: 0.3288 - val_accuracy: 0.8662\n",
      "Epoch 132/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1974 - accuracy: 0.9208\n",
      "Epoch 132: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1957 - accuracy: 0.9215 - val_loss: 0.3340 - val_accuracy: 0.8708\n",
      "Epoch 133/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1892 - accuracy: 0.9242\n",
      "Epoch 133: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.9225 - val_loss: 0.3442 - val_accuracy: 0.8762\n",
      "Epoch 134/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2049 - accuracy: 0.9170\n",
      "Epoch 134: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2024 - accuracy: 0.9182 - val_loss: 0.3429 - val_accuracy: 0.8677\n",
      "Epoch 135/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.1956 - accuracy: 0.9207\n",
      "Epoch 135: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1913 - accuracy: 0.9221 - val_loss: 0.3453 - val_accuracy: 0.8777\n",
      "Epoch 136/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1908 - accuracy: 0.9240\n",
      "Epoch 136: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1908 - accuracy: 0.9240 - val_loss: 0.3553 - val_accuracy: 0.8669\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2361 - accuracy: 0.9032\n",
      "Epoch 137: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1831 - accuracy: 0.9273 - val_loss: 0.3384 - val_accuracy: 0.8731\n",
      "Epoch 138/1000\n",
      "27/42 [==================>...........] - ETA: 0s - loss: 0.1838 - accuracy: 0.9289\n",
      "Epoch 138: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.9278 - val_loss: 0.3371 - val_accuracy: 0.8631\n",
      "Epoch 139/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2291 - accuracy: 0.8871\n",
      "Epoch 139: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.9225 - val_loss: 0.3366 - val_accuracy: 0.8685\n",
      "Epoch 140/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1946 - accuracy: 0.9232\n",
      "Epoch 140: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1946 - accuracy: 0.9230 - val_loss: 0.3380 - val_accuracy: 0.8746\n",
      "Epoch 141/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1846 - accuracy: 0.9256\n",
      "Epoch 141: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1840 - accuracy: 0.9257 - val_loss: 0.3375 - val_accuracy: 0.8669\n",
      "Epoch 142/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1236 - accuracy: 0.9597\n",
      "Epoch 142: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1919 - accuracy: 0.9242 - val_loss: 0.3628 - val_accuracy: 0.8654\n",
      "Epoch 143/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1952 - accuracy: 0.9200\n",
      "Epoch 143: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1898 - accuracy: 0.9223 - val_loss: 0.3526 - val_accuracy: 0.8623\n",
      "Epoch 144/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1854 - accuracy: 0.9295\n",
      "Epoch 144: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.9300 - val_loss: 0.3341 - val_accuracy: 0.8646\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2015 - accuracy: 0.9113\n",
      "Epoch 145: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1900 - accuracy: 0.9257 - val_loss: 0.3474 - val_accuracy: 0.8754\n",
      "Epoch 146/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1856 - accuracy: 0.9254\n",
      "Epoch 146: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1867 - accuracy: 0.9242 - val_loss: 0.3458 - val_accuracy: 0.8654\n",
      "Epoch 147/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1824 - accuracy: 0.9278\n",
      "Epoch 147: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1852 - accuracy: 0.9251 - val_loss: 0.3843 - val_accuracy: 0.8569\n",
      "Epoch 148/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.1837 - accuracy: 0.9242\n",
      "Epoch 148: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1891 - accuracy: 0.9213 - val_loss: 0.3361 - val_accuracy: 0.8654\n",
      "Epoch 149/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1204 - accuracy: 0.9597\n",
      "Epoch 149: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1732 - accuracy: 0.9305 - val_loss: 0.3559 - val_accuracy: 0.8685\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2298 - accuracy: 0.8871\n",
      "Epoch 150: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.9309 - val_loss: 0.3702 - val_accuracy: 0.8638\n",
      "Epoch 151/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1778 - accuracy: 0.9282\n",
      "Epoch 151: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1780 - accuracy: 0.9280 - val_loss: 0.3489 - val_accuracy: 0.8669\n",
      "Epoch 152/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1739 - accuracy: 0.9309\n",
      "Epoch 152: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1706 - accuracy: 0.9319 - val_loss: 0.3747 - val_accuracy: 0.8662\n",
      "Epoch 153/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1649 - accuracy: 0.9380\n",
      "Epoch 153: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1713 - accuracy: 0.9334 - val_loss: 0.3597 - val_accuracy: 0.8677\n",
      "Epoch 154/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1136 - accuracy: 0.9597\n",
      "Epoch 154: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1724 - accuracy: 0.9319 - val_loss: 0.3669 - val_accuracy: 0.8669\n",
      "Epoch 155/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1942 - accuracy: 0.9032\n",
      "Epoch 155: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1710 - accuracy: 0.9336 - val_loss: 0.3796 - val_accuracy: 0.8577\n",
      "Epoch 156/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1718 - accuracy: 0.9302\n",
      "Epoch 156: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1715 - accuracy: 0.9311 - val_loss: 0.3747 - val_accuracy: 0.8592\n",
      "Epoch 157/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1752 - accuracy: 0.9278\n",
      "Epoch 157: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1769 - accuracy: 0.9265 - val_loss: 0.3736 - val_accuracy: 0.8638\n",
      "Epoch 158/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1727 - accuracy: 0.9294\n",
      "Epoch 158: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1727 - accuracy: 0.9294 - val_loss: 0.3618 - val_accuracy: 0.8585\n",
      "Epoch 159/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1789 - accuracy: 0.9194\n",
      "Epoch 159: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.9284 - val_loss: 0.3673 - val_accuracy: 0.8662\n",
      "Epoch 160/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2018 - accuracy: 0.9274\n",
      "Epoch 160: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1839 - accuracy: 0.9284 - val_loss: 0.3574 - val_accuracy: 0.8662\n",
      "Epoch 161/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1573 - accuracy: 0.9274\n",
      "Epoch 161: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1773 - accuracy: 0.9294 - val_loss: 0.3543 - val_accuracy: 0.8615\n",
      "Epoch 162/1000\n",
      "25/42 [================>.............] - ETA: 0s - loss: 0.1721 - accuracy: 0.9284\n",
      "Epoch 162: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1718 - accuracy: 0.9296 - val_loss: 0.3736 - val_accuracy: 0.8646\n",
      "Epoch 163/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1458 - accuracy: 0.9194\n",
      "Epoch 163: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9250 - val_loss: 0.3782 - val_accuracy: 0.8638\n",
      "Epoch 164/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1673 - accuracy: 0.9304\n",
      "Epoch 164: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1666 - accuracy: 0.9313 - val_loss: 0.3773 - val_accuracy: 0.8585\n",
      "Epoch 165/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1883 - accuracy: 0.9435\n",
      "Epoch 165: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1668 - accuracy: 0.9332 - val_loss: 0.3632 - val_accuracy: 0.8723\n",
      "Epoch 166/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1625 - accuracy: 0.9435\n",
      "Epoch 166: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.9296 - val_loss: 0.3576 - val_accuracy: 0.8654\n",
      "Epoch 167/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1481 - accuracy: 0.9435\n",
      "Epoch 167: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.9228 - val_loss: 0.3632 - val_accuracy: 0.8646\n",
      "Epoch 168/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1106 - accuracy: 0.9435\n",
      "Epoch 168: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1738 - accuracy: 0.9288 - val_loss: 0.3657 - val_accuracy: 0.8662\n",
      "Epoch 169/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1675 - accuracy: 0.9331\n",
      "Epoch 169: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1660 - accuracy: 0.9338 - val_loss: 0.3733 - val_accuracy: 0.8662\n",
      "Epoch 170/1000\n",
      "26/42 [=================>............] - ETA: 0s - loss: 0.1725 - accuracy: 0.9299\n",
      "Epoch 170: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1709 - accuracy: 0.9311 - val_loss: 0.3705 - val_accuracy: 0.8685\n",
      "Epoch 171/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1357 - accuracy: 0.9274\n",
      "Epoch 171: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1661 - accuracy: 0.9313 - val_loss: 0.3868 - val_accuracy: 0.8654\n",
      "Epoch 172/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1717 - accuracy: 0.9276\n",
      "Epoch 172: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1705 - accuracy: 0.9282 - val_loss: 0.4007 - val_accuracy: 0.8700\n",
      "Epoch 173/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1826 - accuracy: 0.9194\n",
      "Epoch 173: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1607 - accuracy: 0.9363 - val_loss: 0.3850 - val_accuracy: 0.8623\n",
      "Epoch 174/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1764 - accuracy: 0.9302\n",
      "Epoch 174: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1764 - accuracy: 0.9302 - val_loss: 0.3816 - val_accuracy: 0.8546\n",
      "Epoch 175/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1649 - accuracy: 0.9435\n",
      "Epoch 175: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1643 - accuracy: 0.9317 - val_loss: 0.3982 - val_accuracy: 0.8585\n",
      "Epoch 176/1000\n",
      "29/42 [===================>..........] - ETA: 0s - loss: 0.1749 - accuracy: 0.9288\n",
      "Epoch 176: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9230 - val_loss: 0.3880 - val_accuracy: 0.8577\n",
      "Epoch 177/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1618 - accuracy: 0.9341\n",
      "Epoch 177: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1621 - accuracy: 0.9334 - val_loss: 0.3909 - val_accuracy: 0.8615\n",
      "Epoch 178/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1712 - accuracy: 0.9292\n",
      "Epoch 178: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1705 - accuracy: 0.9300 - val_loss: 0.4003 - val_accuracy: 0.8646\n",
      "Epoch 179/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1904 - accuracy: 0.9194\n",
      "Epoch 179: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1625 - accuracy: 0.9386 - val_loss: 0.3891 - val_accuracy: 0.8669\n",
      "Epoch 180/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1482 - accuracy: 0.9355\n",
      "Epoch 180: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1618 - accuracy: 0.9344 - val_loss: 0.3809 - val_accuracy: 0.8731\n",
      "Epoch 181/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.1724 - accuracy: 0.9319\n",
      "Epoch 181: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1707 - accuracy: 0.9325 - val_loss: 0.3932 - val_accuracy: 0.8608\n",
      "Epoch 182/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1634 - accuracy: 0.9374\n",
      "Epoch 182: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1622 - accuracy: 0.9375 - val_loss: 0.4413 - val_accuracy: 0.8638\n",
      "Epoch 183/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1642 - accuracy: 0.9353\n",
      "Epoch 183: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1633 - accuracy: 0.9346 - val_loss: 0.3818 - val_accuracy: 0.8662\n",
      "Epoch 184/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1660 - accuracy: 0.9331\n",
      "Epoch 184: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1630 - accuracy: 0.9338 - val_loss: 0.3973 - val_accuracy: 0.8638\n",
      "Epoch 185/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1686 - accuracy: 0.9318\n",
      "Epoch 185: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1662 - accuracy: 0.9327 - val_loss: 0.4105 - val_accuracy: 0.8623\n",
      "Epoch 186/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1614 - accuracy: 0.9330\n",
      "Epoch 186: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1614 - accuracy: 0.9332 - val_loss: 0.3711 - val_accuracy: 0.8669\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 22s - loss: 3.9389 - accuracy: 0.3710\n",
      "Epoch 1: val_accuracy improved from -inf to 0.59308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.8867 - accuracy: 0.5426 - val_loss: 0.6746 - val_accuracy: 0.5931\n",
      "Epoch 2/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.6611 - accuracy: 0.6774\n",
      "Epoch 2: val_accuracy improved from 0.59308 to 0.78308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5880 - accuracy: 0.7006 - val_loss: 0.5163 - val_accuracy: 0.7831\n",
      "Epoch 3/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4950 - accuracy: 0.8226\n",
      "Epoch 3: val_accuracy improved from 0.78308 to 0.82462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.8128 - val_loss: 0.4133 - val_accuracy: 0.8246\n",
      "Epoch 4/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.3895 - accuracy: 0.8442\n",
      "Epoch 4: val_accuracy improved from 0.82462 to 0.83846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.8453 - val_loss: 0.3827 - val_accuracy: 0.8385\n",
      "Epoch 5/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.3652 - accuracy: 0.8546\n",
      "Epoch 5: val_accuracy improved from 0.83846 to 0.84692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3667 - accuracy: 0.8480 - val_loss: 0.3559 - val_accuracy: 0.8469\n",
      "Epoch 6/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.3608 - accuracy: 0.8463\n",
      "Epoch 6: val_accuracy improved from 0.84692 to 0.84769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3606 - accuracy: 0.8455 - val_loss: 0.3553 - val_accuracy: 0.8477\n",
      "Epoch 7/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3466 - accuracy: 0.8871\n",
      "Epoch 7: val_accuracy improved from 0.84769 to 0.85462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3496 - accuracy: 0.8561 - val_loss: 0.3462 - val_accuracy: 0.8546\n",
      "Epoch 8/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4201 - accuracy: 0.7903\n",
      "Epoch 8: val_accuracy did not improve from 0.85462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8570 - val_loss: 0.3369 - val_accuracy: 0.8546\n",
      "Epoch 9/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4023 - accuracy: 0.8710\n",
      "Epoch 9: val_accuracy did not improve from 0.85462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.8549 - val_loss: 0.3681 - val_accuracy: 0.8438\n",
      "Epoch 10/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3323 - accuracy: 0.8613\n",
      "Epoch 10: val_accuracy did not improve from 0.85462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8603 - val_loss: 0.3486 - val_accuracy: 0.8438\n",
      "Epoch 11/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2962 - accuracy: 0.8710\n",
      "Epoch 11: val_accuracy improved from 0.85462 to 0.86154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3208 - accuracy: 0.8663 - val_loss: 0.3346 - val_accuracy: 0.8615\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4625 - accuracy: 0.8306\n",
      "Epoch 12: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.8713 - val_loss: 0.3315 - val_accuracy: 0.8592\n",
      "Epoch 13/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2999 - accuracy: 0.8952\n",
      "Epoch 13: val_accuracy improved from 0.86154 to 0.86231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3144 - accuracy: 0.8722 - val_loss: 0.3275 - val_accuracy: 0.8623\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2371 - accuracy: 0.9194\n",
      "Epoch 14: val_accuracy did not improve from 0.86231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8680 - val_loss: 0.3270 - val_accuracy: 0.8623\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3315 - accuracy: 0.8710\n",
      "Epoch 15: val_accuracy improved from 0.86231 to 0.86308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8595 - val_loss: 0.3272 - val_accuracy: 0.8631\n",
      "Epoch 16/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3621 - accuracy: 0.8387\n",
      "Epoch 16: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8732 - val_loss: 0.3433 - val_accuracy: 0.8469\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3500 - accuracy: 0.8226\n",
      "Epoch 17: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.8720 - val_loss: 0.3353 - val_accuracy: 0.8615\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3029 - accuracy: 0.8629\n",
      "Epoch 18: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3222 - accuracy: 0.8657 - val_loss: 0.3552 - val_accuracy: 0.8531\n",
      "Epoch 19/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3169 - accuracy: 0.8647\n",
      "Epoch 19: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3169 - accuracy: 0.8647 - val_loss: 0.3582 - val_accuracy: 0.8362\n",
      "Epoch 20/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.3095 - accuracy: 0.8659\n",
      "Epoch 20: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8670 - val_loss: 0.3255 - val_accuracy: 0.8592\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3077 - accuracy: 0.8751\n",
      "Epoch 21: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8751 - val_loss: 0.3284 - val_accuracy: 0.8600\n",
      "Epoch 22/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.3188 - accuracy: 0.8611\n",
      "Epoch 22: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8647 - val_loss: 0.3667 - val_accuracy: 0.8485\n",
      "Epoch 23/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2754 - accuracy: 0.8790\n",
      "Epoch 23: val_accuracy improved from 0.86308 to 0.86615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8593 - val_loss: 0.3308 - val_accuracy: 0.8662\n",
      "Epoch 24/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3238 - accuracy: 0.8387\n",
      "Epoch 24: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.8734 - val_loss: 0.3325 - val_accuracy: 0.8631\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3432 - accuracy: 0.8629\n",
      "Epoch 25: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.8795 - val_loss: 0.3251 - val_accuracy: 0.8615\n",
      "Epoch 26/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.3313 - accuracy: 0.8567\n",
      "Epoch 26: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8572 - val_loss: 0.3314 - val_accuracy: 0.8554\n",
      "Epoch 27/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3171 - accuracy: 0.8641\n",
      "Epoch 27: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3180 - accuracy: 0.8643 - val_loss: 0.3274 - val_accuracy: 0.8577\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2865 - accuracy: 0.9032\n",
      "Epoch 28: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8665 - val_loss: 0.3245 - val_accuracy: 0.8623\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3757 - accuracy: 0.8387\n",
      "Epoch 29: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.8784 - val_loss: 0.3260 - val_accuracy: 0.8615\n",
      "Epoch 30/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3069 - accuracy: 0.8704\n",
      "Epoch 30: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8709 - val_loss: 0.3402 - val_accuracy: 0.8615\n",
      "Epoch 31/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3076 - accuracy: 0.8629\n",
      "Epoch 31: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2961 - accuracy: 0.8782 - val_loss: 0.3326 - val_accuracy: 0.8646\n",
      "Epoch 32/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.3120 - accuracy: 0.8648\n",
      "Epoch 32: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8668 - val_loss: 0.3296 - val_accuracy: 0.8646\n",
      "Epoch 33/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.3010 - accuracy: 0.8729\n",
      "Epoch 33: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2971 - accuracy: 0.8761 - val_loss: 0.3344 - val_accuracy: 0.8523\n",
      "Epoch 34/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2854 - accuracy: 0.8548\n",
      "Epoch 34: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2976 - accuracy: 0.8759 - val_loss: 0.3336 - val_accuracy: 0.8638\n",
      "Epoch 35/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2562 - accuracy: 0.8952\n",
      "Epoch 35: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.8745 - val_loss: 0.3424 - val_accuracy: 0.8638\n",
      "Epoch 36/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3203 - accuracy: 0.8306\n",
      "Epoch 36: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2975 - accuracy: 0.8740 - val_loss: 0.3354 - val_accuracy: 0.8477\n",
      "Epoch 37/1000\n",
      "24/42 [================>.............] - ETA: 0s - loss: 0.2982 - accuracy: 0.8723\n",
      "Epoch 37: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2986 - accuracy: 0.8755 - val_loss: 0.3382 - val_accuracy: 0.8477\n",
      "Epoch 38/1000\n",
      "30/42 [====================>.........] - ETA: 0s - loss: 0.2995 - accuracy: 0.8750\n",
      "Epoch 38: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2974 - accuracy: 0.8778 - val_loss: 0.3238 - val_accuracy: 0.8623\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2912 - accuracy: 0.8792\n",
      "Epoch 39: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2912 - accuracy: 0.8792 - val_loss: 0.3238 - val_accuracy: 0.8646\n",
      "Epoch 40/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2990 - accuracy: 0.8727\n",
      "Epoch 40: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3008 - accuracy: 0.8728 - val_loss: 0.3249 - val_accuracy: 0.8623\n",
      "Epoch 41/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2543 - accuracy: 0.8710\n",
      "Epoch 41: val_accuracy improved from 0.86615 to 0.86692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8778 - val_loss: 0.3269 - val_accuracy: 0.8669\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2462 - accuracy: 0.9113\n",
      "Epoch 42: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2936 - accuracy: 0.8778 - val_loss: 0.3244 - val_accuracy: 0.8669\n",
      "Epoch 43/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2256 - accuracy: 0.9113\n",
      "Epoch 43: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.8811 - val_loss: 0.3278 - val_accuracy: 0.8585\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3230 - accuracy: 0.8871\n",
      "Epoch 44: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2966 - accuracy: 0.8757 - val_loss: 0.3641 - val_accuracy: 0.8569\n",
      "Epoch 45/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3177 - accuracy: 0.8548\n",
      "Epoch 45: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3026 - accuracy: 0.8705 - val_loss: 0.3369 - val_accuracy: 0.8669\n",
      "Epoch 46/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2864 - accuracy: 0.8836\n",
      "Epoch 46: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2866 - accuracy: 0.8842 - val_loss: 0.3300 - val_accuracy: 0.8608\n",
      "Epoch 47/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2583 - accuracy: 0.8952\n",
      "Epoch 47: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2865 - accuracy: 0.8788 - val_loss: 0.3312 - val_accuracy: 0.8577\n",
      "Epoch 48/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3030 - accuracy: 0.8952\n",
      "Epoch 48: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2892 - accuracy: 0.8770 - val_loss: 0.3392 - val_accuracy: 0.8454\n",
      "Epoch 49/1000\n",
      "25/42 [================>.............] - ETA: 0s - loss: 0.2721 - accuracy: 0.8871\n",
      "Epoch 49: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2873 - accuracy: 0.8797 - val_loss: 0.3180 - val_accuracy: 0.8669\n",
      "Epoch 50/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2500 - accuracy: 0.8871\n",
      "Epoch 50: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2825 - accuracy: 0.8819 - val_loss: 0.3320 - val_accuracy: 0.8523\n",
      "Epoch 51/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2871 - accuracy: 0.8767\n",
      "Epoch 51: val_accuracy improved from 0.86692 to 0.87077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2881 - accuracy: 0.8761 - val_loss: 0.3216 - val_accuracy: 0.8708\n",
      "Epoch 52/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2889 - accuracy: 0.8797\n",
      "Epoch 52: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2878 - accuracy: 0.8794 - val_loss: 0.3379 - val_accuracy: 0.8669\n",
      "Epoch 53/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2832 - accuracy: 0.8812\n",
      "Epoch 53: val_accuracy improved from 0.87077 to 0.87154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2837 - accuracy: 0.8807 - val_loss: 0.3155 - val_accuracy: 0.8715\n",
      "Epoch 54/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2754 - accuracy: 0.8844\n",
      "Epoch 54: val_accuracy did not improve from 0.87154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2772 - accuracy: 0.8826 - val_loss: 0.3478 - val_accuracy: 0.8415\n",
      "Epoch 55/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2851 - accuracy: 0.8816\n",
      "Epoch 55: val_accuracy did not improve from 0.87154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2866 - accuracy: 0.8817 - val_loss: 0.3258 - val_accuracy: 0.8669\n",
      "Epoch 56/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2796 - accuracy: 0.8830\n",
      "Epoch 56: val_accuracy did not improve from 0.87154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2793 - accuracy: 0.8838 - val_loss: 0.3233 - val_accuracy: 0.8577\n",
      "Epoch 57/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2800 - accuracy: 0.8825\n",
      "Epoch 57: val_accuracy improved from 0.87154 to 0.87308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2822 - accuracy: 0.8820 - val_loss: 0.3173 - val_accuracy: 0.8731\n",
      "Epoch 58/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2841 - accuracy: 0.8838\n",
      "Epoch 58: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2835 - accuracy: 0.8826 - val_loss: 0.3154 - val_accuracy: 0.8715\n",
      "Epoch 59/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1692 - accuracy: 0.9274\n",
      "Epoch 59: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2842 - accuracy: 0.8840 - val_loss: 0.3137 - val_accuracy: 0.8685\n",
      "Epoch 60/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2432 - accuracy: 0.8871\n",
      "Epoch 60: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2737 - accuracy: 0.8857 - val_loss: 0.3445 - val_accuracy: 0.8577\n",
      "Epoch 61/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2714 - accuracy: 0.8877\n",
      "Epoch 61: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.8880 - val_loss: 0.3304 - val_accuracy: 0.8677\n",
      "Epoch 62/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2828 - accuracy: 0.8782\n",
      "Epoch 62: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2814 - accuracy: 0.8784 - val_loss: 0.3088 - val_accuracy: 0.8654\n",
      "Epoch 63/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3334 - accuracy: 0.8548\n",
      "Epoch 63: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2706 - accuracy: 0.8871 - val_loss: 0.3298 - val_accuracy: 0.8638\n",
      "Epoch 64/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3328 - accuracy: 0.8548\n",
      "Epoch 64: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2724 - accuracy: 0.8844 - val_loss: 0.3075 - val_accuracy: 0.8692\n",
      "Epoch 65/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2800 - accuracy: 0.8817\n",
      "Epoch 65: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2789 - accuracy: 0.8826 - val_loss: 0.3089 - val_accuracy: 0.8692\n",
      "Epoch 66/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3013 - accuracy: 0.8952\n",
      "Epoch 66: val_accuracy improved from 0.87308 to 0.87538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2611 - accuracy: 0.8934 - val_loss: 0.3040 - val_accuracy: 0.8754\n",
      "Epoch 67/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2091 - accuracy: 0.8952\n",
      "Epoch 67: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2610 - accuracy: 0.8911 - val_loss: 0.3263 - val_accuracy: 0.8577\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2786 - accuracy: 0.8871\n",
      "Epoch 68: val_accuracy improved from 0.87538 to 0.87769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2645 - accuracy: 0.8901 - val_loss: 0.3046 - val_accuracy: 0.8777\n",
      "Epoch 69/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2492 - accuracy: 0.8629\n",
      "Epoch 69: val_accuracy improved from 0.87769 to 0.87846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2623 - accuracy: 0.8913 - val_loss: 0.3027 - val_accuracy: 0.8785\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2364 - accuracy: 0.8871\n",
      "Epoch 70: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2549 - accuracy: 0.8957 - val_loss: 0.3071 - val_accuracy: 0.8785\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1839 - accuracy: 0.9355\n",
      "Epoch 71: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2755 - accuracy: 0.8836 - val_loss: 0.3390 - val_accuracy: 0.8454\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2998 - accuracy: 0.8710\n",
      "Epoch 72: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2669 - accuracy: 0.8897 - val_loss: 0.3261 - val_accuracy: 0.8700\n",
      "Epoch 73/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3518 - accuracy: 0.8548\n",
      "Epoch 73: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2569 - accuracy: 0.8951 - val_loss: 0.3192 - val_accuracy: 0.8577\n",
      "Epoch 74/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2566 - accuracy: 0.8963\n",
      "Epoch 74: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2572 - accuracy: 0.8961 - val_loss: 0.3023 - val_accuracy: 0.8785\n",
      "Epoch 75/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.2708 - accuracy: 0.8837\n",
      "Epoch 75: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.8853 - val_loss: 0.2970 - val_accuracy: 0.8777\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3376 - accuracy: 0.8548\n",
      "Epoch 76: val_accuracy improved from 0.87846 to 0.88154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2532 - accuracy: 0.8957 - val_loss: 0.3052 - val_accuracy: 0.8815\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3284 - accuracy: 0.8548\n",
      "Epoch 77: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2538 - accuracy: 0.8955 - val_loss: 0.3175 - val_accuracy: 0.8700\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2506 - accuracy: 0.9032\n",
      "Epoch 78: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2631 - accuracy: 0.8901 - val_loss: 0.3054 - val_accuracy: 0.8777\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2233 - accuracy: 0.9194\n",
      "Epoch 79: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.8953 - val_loss: 0.3014 - val_accuracy: 0.8723\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2570 - accuracy: 0.8952\n",
      "Epoch 80: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8997 - val_loss: 0.3076 - val_accuracy: 0.8800\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3335 - accuracy: 0.8710\n",
      "Epoch 81: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.8963 - val_loss: 0.3316 - val_accuracy: 0.8662\n",
      "Epoch 82/1000\n",
      "23/42 [===============>..............] - ETA: 0s - loss: 0.2647 - accuracy: 0.8892\n",
      "Epoch 82: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2534 - accuracy: 0.8928 - val_loss: 0.3000 - val_accuracy: 0.8769\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2576 - accuracy: 0.9032\n",
      "Epoch 83: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.9026 - val_loss: 0.2934 - val_accuracy: 0.8738\n",
      "Epoch 84/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1914 - accuracy: 0.9194\n",
      "Epoch 84: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.8963 - val_loss: 0.2995 - val_accuracy: 0.8715\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2242 - accuracy: 0.9032\n",
      "Epoch 85: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2474 - accuracy: 0.8969 - val_loss: 0.3068 - val_accuracy: 0.8708\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2415 - accuracy: 0.8952\n",
      "Epoch 86: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.8974 - val_loss: 0.3169 - val_accuracy: 0.8608\n",
      "Epoch 87/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3067 - accuracy: 0.8629\n",
      "Epoch 87: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2478 - accuracy: 0.8947 - val_loss: 0.3061 - val_accuracy: 0.8723\n",
      "Epoch 88/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2512 - accuracy: 0.8952\n",
      "Epoch 88: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.8957 - val_loss: 0.2932 - val_accuracy: 0.8785\n",
      "Epoch 89/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2692 - accuracy: 0.9032\n",
      "Epoch 89: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2416 - accuracy: 0.9024 - val_loss: 0.2967 - val_accuracy: 0.8800\n",
      "Epoch 90/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2537 - accuracy: 0.8915\n",
      "Epoch 90: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2531 - accuracy: 0.8921 - val_loss: 0.3027 - val_accuracy: 0.8800\n",
      "Epoch 91/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2386 - accuracy: 0.9018\n",
      "Epoch 91: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2387 - accuracy: 0.9015 - val_loss: 0.3152 - val_accuracy: 0.8700\n",
      "Epoch 92/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2352 - accuracy: 0.9043\n",
      "Epoch 92: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2415 - accuracy: 0.9009 - val_loss: 0.3288 - val_accuracy: 0.8631\n",
      "Epoch 93/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2410 - accuracy: 0.8987\n",
      "Epoch 93: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2422 - accuracy: 0.8986 - val_loss: 0.2975 - val_accuracy: 0.8777\n",
      "Epoch 94/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2438 - accuracy: 0.8982\n",
      "Epoch 94: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2431 - accuracy: 0.8994 - val_loss: 0.2991 - val_accuracy: 0.8792\n",
      "Epoch 95/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2029 - accuracy: 0.9113\n",
      "Epoch 95: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2399 - accuracy: 0.8978 - val_loss: 0.3015 - val_accuracy: 0.8738\n",
      "Epoch 96/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.2421 - accuracy: 0.8972\n",
      "Epoch 96: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2431 - accuracy: 0.8974 - val_loss: 0.3071 - val_accuracy: 0.8662\n",
      "Epoch 97/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2357 - accuracy: 0.9014\n",
      "Epoch 97: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2359 - accuracy: 0.9019 - val_loss: 0.2945 - val_accuracy: 0.8700\n",
      "Epoch 98/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2341 - accuracy: 0.9045\n",
      "Epoch 98: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 0.9061 - val_loss: 0.3134 - val_accuracy: 0.8708\n",
      "Epoch 99/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2266 - accuracy: 0.9113\n",
      "Epoch 99: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2310 - accuracy: 0.9051 - val_loss: 0.3006 - val_accuracy: 0.8731\n",
      "Epoch 100/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2411 - accuracy: 0.9047\n",
      "Epoch 100: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2435 - accuracy: 0.9024 - val_loss: 0.3020 - val_accuracy: 0.8692\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1393 - accuracy: 0.9355\n",
      "Epoch 101: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2330 - accuracy: 0.9051 - val_loss: 0.2968 - val_accuracy: 0.8746\n",
      "Epoch 102/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2277 - accuracy: 0.9055\n",
      "Epoch 102: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2290 - accuracy: 0.9061 - val_loss: 0.3061 - val_accuracy: 0.8792\n",
      "Epoch 103/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2426 - accuracy: 0.9014\n",
      "Epoch 103: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2416 - accuracy: 0.9013 - val_loss: 0.3103 - val_accuracy: 0.8738\n",
      "Epoch 104/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2339 - accuracy: 0.9045\n",
      "Epoch 104: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2343 - accuracy: 0.9038 - val_loss: 0.3081 - val_accuracy: 0.8708\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1888 - accuracy: 0.9355\n",
      "Epoch 105: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2287 - accuracy: 0.9051 - val_loss: 0.3273 - val_accuracy: 0.8646\n",
      "Epoch 106/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2437 - accuracy: 0.8980\n",
      "Epoch 106: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8978 - val_loss: 0.3036 - val_accuracy: 0.8785\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2095 - accuracy: 0.9274\n",
      "Epoch 107: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2229 - accuracy: 0.9074 - val_loss: 0.2988 - val_accuracy: 0.8731\n",
      "Epoch 108/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.2210 - accuracy: 0.9113\n",
      "Epoch 108: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2209 - accuracy: 0.9098 - val_loss: 0.3166 - val_accuracy: 0.8738\n",
      "Epoch 109/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1686 - accuracy: 0.9274\n",
      "Epoch 109: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2310 - accuracy: 0.9042 - val_loss: 0.2978 - val_accuracy: 0.8715\n",
      "Epoch 110/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2235 - accuracy: 0.9096\n",
      "Epoch 110: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.9096 - val_loss: 0.3057 - val_accuracy: 0.8777\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1489 - accuracy: 0.9597\n",
      "Epoch 111: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2252 - accuracy: 0.9096 - val_loss: 0.3021 - val_accuracy: 0.8700\n",
      "Epoch 112/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2204 - accuracy: 0.9098\n",
      "Epoch 112: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2243 - accuracy: 0.9080 - val_loss: 0.3010 - val_accuracy: 0.8754\n",
      "Epoch 113/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2261 - accuracy: 0.9076\n",
      "Epoch 113: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2261 - accuracy: 0.9076 - val_loss: 0.3099 - val_accuracy: 0.8723\n",
      "Epoch 114/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2925 - accuracy: 0.8306\n",
      "Epoch 114: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2274 - accuracy: 0.9042 - val_loss: 0.3135 - val_accuracy: 0.8785\n",
      "Epoch 115/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2335 - accuracy: 0.9003\n",
      "Epoch 115: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2317 - accuracy: 0.9023 - val_loss: 0.3132 - val_accuracy: 0.8738\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2488 - accuracy: 0.9274\n",
      "Epoch 116: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2218 - accuracy: 0.9099 - val_loss: 0.3138 - val_accuracy: 0.8738\n",
      "Epoch 117/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2175 - accuracy: 0.9104\n",
      "Epoch 117: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.9071 - val_loss: 0.3051 - val_accuracy: 0.8762\n",
      "Epoch 118/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2377 - accuracy: 0.9113\n",
      "Epoch 118: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.9042 - val_loss: 0.2982 - val_accuracy: 0.8723\n",
      "Epoch 119/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1924 - accuracy: 0.9194\n",
      "Epoch 119: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.9088 - val_loss: 0.3061 - val_accuracy: 0.8769\n",
      "Epoch 120/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.2336 - accuracy: 0.9030\n",
      "Epoch 120: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2340 - accuracy: 0.9013 - val_loss: 0.3362 - val_accuracy: 0.8662\n",
      "Epoch 121/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3188 - accuracy: 0.8387\n",
      "Epoch 121: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2236 - accuracy: 0.9059 - val_loss: 0.3096 - val_accuracy: 0.8777\n",
      "Epoch 122/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2198 - accuracy: 0.9121\n",
      "Epoch 122: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2192 - accuracy: 0.9123 - val_loss: 0.3139 - val_accuracy: 0.8692\n",
      "Epoch 123/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2197 - accuracy: 0.9098\n",
      "Epoch 123: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2172 - accuracy: 0.9105 - val_loss: 0.3182 - val_accuracy: 0.8715\n",
      "Epoch 124/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2099 - accuracy: 0.9145\n",
      "Epoch 124: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2129 - accuracy: 0.9117 - val_loss: 0.3107 - val_accuracy: 0.8654\n",
      "Epoch 125/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2158 - accuracy: 0.9107\n",
      "Epoch 125: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2155 - accuracy: 0.9109 - val_loss: 0.3287 - val_accuracy: 0.8669\n",
      "Epoch 126/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2179 - accuracy: 0.9054\n",
      "Epoch 126: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2159 - accuracy: 0.9063 - val_loss: 0.3295 - val_accuracy: 0.8685\n",
      "Epoch 127/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2190 - accuracy: 0.9076\n",
      "Epoch 127: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2201 - accuracy: 0.9074 - val_loss: 0.3516 - val_accuracy: 0.8577\n",
      "Epoch 128/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.2237 - accuracy: 0.9074\n",
      "Epoch 128: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2268 - accuracy: 0.9038 - val_loss: 0.3099 - val_accuracy: 0.8723\n",
      "Epoch 129/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2312 - accuracy: 0.9274\n",
      "Epoch 129: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.9153 - val_loss: 0.3235 - val_accuracy: 0.8615\n",
      "Epoch 130/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2419 - accuracy: 0.8790\n",
      "Epoch 130: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2119 - accuracy: 0.9117 - val_loss: 0.3309 - val_accuracy: 0.8769\n",
      "Epoch 131/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2246 - accuracy: 0.9030\n",
      "Epoch 131: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.9036 - val_loss: 0.3153 - val_accuracy: 0.8762\n",
      "Epoch 132/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.2236 - accuracy: 0.9049\n",
      "Epoch 132: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.9071 - val_loss: 0.3248 - val_accuracy: 0.8685\n",
      "Epoch 133/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2093 - accuracy: 0.9157\n",
      "Epoch 133: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2110 - accuracy: 0.9148 - val_loss: 0.3183 - val_accuracy: 0.8708\n",
      "Epoch 134/1000\n",
      "29/42 [===================>..........] - ETA: 0s - loss: 0.2038 - accuracy: 0.9160\n",
      "Epoch 134: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2073 - accuracy: 0.9132 - val_loss: 0.3203 - val_accuracy: 0.8723\n",
      "Epoch 135/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2002 - accuracy: 0.9032\n",
      "Epoch 135: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.9084 - val_loss: 0.3209 - val_accuracy: 0.8700\n",
      "Epoch 136/1000\n",
      "29/42 [===================>..........] - ETA: 0s - loss: 0.2081 - accuracy: 0.9121\n",
      "Epoch 136: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2061 - accuracy: 0.9136 - val_loss: 0.3145 - val_accuracy: 0.8677\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2519 - accuracy: 0.8790\n",
      "Epoch 137: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2078 - accuracy: 0.9136 - val_loss: 0.3361 - val_accuracy: 0.8623\n",
      "Epoch 138/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2156 - accuracy: 0.9113\n",
      "Epoch 138: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2119 - accuracy: 0.9144 - val_loss: 0.3198 - val_accuracy: 0.8715\n",
      "Epoch 139/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2145 - accuracy: 0.9095\n",
      "Epoch 139: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2150 - accuracy: 0.9084 - val_loss: 0.3380 - val_accuracy: 0.8715\n",
      "Epoch 140/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2234 - accuracy: 0.8952\n",
      "Epoch 140: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2065 - accuracy: 0.9117 - val_loss: 0.3378 - val_accuracy: 0.8685\n",
      "Epoch 141/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2248 - accuracy: 0.9034\n",
      "Epoch 141: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2248 - accuracy: 0.9036 - val_loss: 0.3200 - val_accuracy: 0.8723\n",
      "Epoch 142/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.2200 - accuracy: 0.9096\n",
      "Epoch 142: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 0.9121 - val_loss: 0.3301 - val_accuracy: 0.8723\n",
      "Epoch 143/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2079 - accuracy: 0.9117\n",
      "Epoch 143: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2099 - accuracy: 0.9109 - val_loss: 0.3298 - val_accuracy: 0.8692\n",
      "Epoch 144/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1908 - accuracy: 0.9194\n",
      "Epoch 144: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2037 - accuracy: 0.9123 - val_loss: 0.3256 - val_accuracy: 0.8738\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2605 - accuracy: 0.9032\n",
      "Epoch 145: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1989 - accuracy: 0.9182 - val_loss: 0.3308 - val_accuracy: 0.8646\n",
      "Epoch 146/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2126 - accuracy: 0.9103\n",
      "Epoch 146: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2117 - accuracy: 0.9105 - val_loss: 0.3258 - val_accuracy: 0.8623\n",
      "Epoch 147/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1987 - accuracy: 0.9169\n",
      "Epoch 147: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1993 - accuracy: 0.9155 - val_loss: 0.3312 - val_accuracy: 0.8646\n",
      "Epoch 148/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2080 - accuracy: 0.9091\n",
      "Epoch 148: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2120 - accuracy: 0.9078 - val_loss: 0.3744 - val_accuracy: 0.8600\n",
      "Epoch 149/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2006 - accuracy: 0.9156\n",
      "Epoch 149: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1997 - accuracy: 0.9161 - val_loss: 0.3337 - val_accuracy: 0.8738\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2105 - accuracy: 0.9113\n",
      "Epoch 150: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2018 - accuracy: 0.9128 - val_loss: 0.3505 - val_accuracy: 0.8708\n",
      "Epoch 151/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2176 - accuracy: 0.8952\n",
      "Epoch 151: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1989 - accuracy: 0.9140 - val_loss: 0.3397 - val_accuracy: 0.8708\n",
      "Epoch 152/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2213 - accuracy: 0.9113\n",
      "Epoch 152: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1989 - accuracy: 0.9159 - val_loss: 0.3457 - val_accuracy: 0.8677\n",
      "Epoch 153/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2790 - accuracy: 0.8871\n",
      "Epoch 153: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1944 - accuracy: 0.9190 - val_loss: 0.3365 - val_accuracy: 0.8554\n",
      "Epoch 154/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1979 - accuracy: 0.9144\n",
      "Epoch 154: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.9148 - val_loss: 0.3356 - val_accuracy: 0.8685\n",
      "Epoch 155/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1971 - accuracy: 0.9147\n",
      "Epoch 155: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.9157 - val_loss: 0.3340 - val_accuracy: 0.8762\n",
      "Epoch 156/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2709 - accuracy: 0.8952\n",
      "Epoch 156: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2094 - accuracy: 0.9109 - val_loss: 0.3424 - val_accuracy: 0.8731\n",
      "Epoch 157/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1163 - accuracy: 0.9516\n",
      "Epoch 157: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2077 - accuracy: 0.9119 - val_loss: 0.3425 - val_accuracy: 0.8623\n",
      "Epoch 158/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2000 - accuracy: 0.9165\n",
      "Epoch 158: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.9165 - val_loss: 0.3764 - val_accuracy: 0.8608\n",
      "Epoch 159/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1429 - accuracy: 0.9435\n",
      "Epoch 159: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1913 - accuracy: 0.9223 - val_loss: 0.3334 - val_accuracy: 0.8677\n",
      "Epoch 160/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1956 - accuracy: 0.9162\n",
      "Epoch 160: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1964 - accuracy: 0.9159 - val_loss: 0.3386 - val_accuracy: 0.8715\n",
      "Epoch 161/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1601 - accuracy: 0.9355\n",
      "Epoch 161: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1944 - accuracy: 0.9186 - val_loss: 0.3698 - val_accuracy: 0.8685\n",
      "Epoch 162/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3675 - accuracy: 0.8710\n",
      "Epoch 162: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1892 - accuracy: 0.9209 - val_loss: 0.3530 - val_accuracy: 0.8715\n",
      "Epoch 163/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1630 - accuracy: 0.9355\n",
      "Epoch 163: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1873 - accuracy: 0.9223 - val_loss: 0.3457 - val_accuracy: 0.8615\n",
      "Epoch 164/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1916 - accuracy: 0.9113\n",
      "Epoch 164: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1915 - accuracy: 0.9209 - val_loss: 0.3402 - val_accuracy: 0.8692\n",
      "Epoch 165/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1769 - accuracy: 0.9113\n",
      "Epoch 165: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1945 - accuracy: 0.9182 - val_loss: 0.3624 - val_accuracy: 0.8592\n",
      "Epoch 166/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1351 - accuracy: 0.9435\n",
      "Epoch 166: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1966 - accuracy: 0.9175 - val_loss: 0.3422 - val_accuracy: 0.8585\n",
      "Epoch 167/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1626 - accuracy: 0.8871\n",
      "Epoch 167: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1878 - accuracy: 0.9217 - val_loss: 0.3390 - val_accuracy: 0.8638\n",
      "Epoch 168/1000\n",
      "29/42 [===================>..........] - ETA: 0s - loss: 0.1867 - accuracy: 0.9232\n",
      "Epoch 168: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.9211 - val_loss: 0.3632 - val_accuracy: 0.8600\n",
      "Epoch 169/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2036 - accuracy: 0.9274\n",
      "Epoch 169: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1889 - accuracy: 0.9225 - val_loss: 0.3529 - val_accuracy: 0.8646\n",
      "Epoch 170/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1419 - accuracy: 0.9435\n",
      "Epoch 170: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1836 - accuracy: 0.9246 - val_loss: 0.3444 - val_accuracy: 0.8662\n",
      "Epoch 171/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2029 - accuracy: 0.9113\n",
      "Epoch 171: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1853 - accuracy: 0.9226 - val_loss: 0.3979 - val_accuracy: 0.8523\n",
      "Epoch 172/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1808 - accuracy: 0.9274\n",
      "Epoch 172: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1858 - accuracy: 0.9230 - val_loss: 0.3439 - val_accuracy: 0.8677\n",
      "Epoch 173/1000\n",
      "29/42 [===================>..........] - ETA: 0s - loss: 0.1847 - accuracy: 0.9266\n",
      "Epoch 173: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1858 - accuracy: 0.9248 - val_loss: 0.4056 - val_accuracy: 0.8577\n",
      "Epoch 174/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2000 - accuracy: 0.9139\n",
      "Epoch 174: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1992 - accuracy: 0.9146 - val_loss: 0.3745 - val_accuracy: 0.8700\n",
      "Epoch 175/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1383 - accuracy: 0.9274\n",
      "Epoch 175: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1809 - accuracy: 0.9253 - val_loss: 0.3620 - val_accuracy: 0.8692\n",
      "Epoch 176/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2636 - accuracy: 0.9032\n",
      "Epoch 176: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1885 - accuracy: 0.9207 - val_loss: 0.3819 - val_accuracy: 0.8685\n",
      "Epoch 177/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2418 - accuracy: 0.8952\n",
      "Epoch 177: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1902 - accuracy: 0.9190 - val_loss: 0.3720 - val_accuracy: 0.8608\n",
      "Epoch 178/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1881 - accuracy: 0.9236\n",
      "Epoch 178: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1881 - accuracy: 0.9236 - val_loss: 0.3643 - val_accuracy: 0.8746\n",
      "Epoch 179/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1399 - accuracy: 0.9355\n",
      "Epoch 179: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.9280 - val_loss: 0.3594 - val_accuracy: 0.8692\n",
      "Epoch 180/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1629 - accuracy: 0.9435\n",
      "Epoch 180: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.9236 - val_loss: 0.3659 - val_accuracy: 0.8654\n",
      "Epoch 181/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1190 - accuracy: 0.9597\n",
      "Epoch 181: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1749 - accuracy: 0.9277 - val_loss: 0.3549 - val_accuracy: 0.8677\n",
      "Epoch 182/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2201 - accuracy: 0.9113\n",
      "Epoch 182: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.9263 - val_loss: 0.3524 - val_accuracy: 0.8623\n",
      "Epoch 183/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1925 - accuracy: 0.9194\n",
      "Epoch 183: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1725 - accuracy: 0.9282 - val_loss: 0.3818 - val_accuracy: 0.8700\n",
      "Epoch 184/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1266 - accuracy: 0.9677\n",
      "Epoch 184: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.9271 - val_loss: 0.4192 - val_accuracy: 0.8638\n",
      "Epoch 185/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1832 - accuracy: 0.9242\n",
      "Epoch 185: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1810 - accuracy: 0.9261 - val_loss: 0.3867 - val_accuracy: 0.8669\n",
      "Epoch 186/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.1838 - accuracy: 0.9243\n",
      "Epoch 186: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.9275 - val_loss: 0.4151 - val_accuracy: 0.8654\n",
      "Epoch 187/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1644 - accuracy: 0.9435\n",
      "Epoch 187: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9157 - val_loss: 0.3745 - val_accuracy: 0.8631\n",
      "Epoch 188/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1779 - accuracy: 0.9289\n",
      "Epoch 188: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1780 - accuracy: 0.9278 - val_loss: 0.3595 - val_accuracy: 0.8731\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 22s - loss: 0.9023 - accuracy: 0.5081\n",
      "Epoch 1: val_accuracy improved from -inf to 0.77538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.6458 - accuracy: 0.6479 - val_loss: 0.5356 - val_accuracy: 0.7754\n",
      "Epoch 2/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.5595 - accuracy: 0.7500\n",
      "Epoch 2: val_accuracy improved from 0.77538 to 0.82154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4843 - accuracy: 0.7930 - val_loss: 0.4470 - val_accuracy: 0.8215\n",
      "Epoch 3/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.4222 - accuracy: 0.8255\n",
      "Epoch 3: val_accuracy improved from 0.82154 to 0.83000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.8257 - val_loss: 0.4068 - val_accuracy: 0.8300\n",
      "Epoch 4/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8483\n",
      "Epoch 4: val_accuracy improved from 0.83000 to 0.84538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8470 - val_loss: 0.3681 - val_accuracy: 0.8454\n",
      "Epoch 5/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3656 - accuracy: 0.8306\n",
      "Epoch 5: val_accuracy did not improve from 0.84538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8516 - val_loss: 0.4853 - val_accuracy: 0.7554\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3739 - accuracy: 0.8386\n",
      "Epoch 6: val_accuracy improved from 0.84538 to 0.84923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3739 - accuracy: 0.8386 - val_loss: 0.3513 - val_accuracy: 0.8492\n",
      "Epoch 7/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3090 - accuracy: 0.8710\n",
      "Epoch 7: val_accuracy did not improve from 0.84923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3468 - accuracy: 0.8566 - val_loss: 0.3597 - val_accuracy: 0.8446\n",
      "Epoch 8/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3468 - accuracy: 0.8544\n",
      "Epoch 8: val_accuracy improved from 0.84923 to 0.86000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3480 - accuracy: 0.8545 - val_loss: 0.3429 - val_accuracy: 0.8600\n",
      "Epoch 9/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2675 - accuracy: 0.8952\n",
      "Epoch 9: val_accuracy did not improve from 0.86000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8655 - val_loss: 0.3423 - val_accuracy: 0.8508\n",
      "Epoch 10/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3263 - accuracy: 0.8710\n",
      "Epoch 10: val_accuracy improved from 0.86000 to 0.86077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8501 - val_loss: 0.3340 - val_accuracy: 0.8608\n",
      "Epoch 11/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4014 - accuracy: 0.8306\n",
      "Epoch 11: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8692 - val_loss: 0.3350 - val_accuracy: 0.8569\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3065 - accuracy: 0.8468\n",
      "Epoch 12: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8674 - val_loss: 0.3429 - val_accuracy: 0.8562\n",
      "Epoch 13/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2934 - accuracy: 0.8629\n",
      "Epoch 13: val_accuracy improved from 0.86077 to 0.86385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8670 - val_loss: 0.3341 - val_accuracy: 0.8638\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2662 - accuracy: 0.8790\n",
      "Epoch 14: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8738 - val_loss: 0.3765 - val_accuracy: 0.8369\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2755 - accuracy: 0.8790\n",
      "Epoch 15: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3247 - accuracy: 0.8628 - val_loss: 0.3836 - val_accuracy: 0.8315\n",
      "Epoch 16/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3135 - accuracy: 0.8720\n",
      "Epoch 16: val_accuracy improved from 0.86385 to 0.86769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3158 - accuracy: 0.8709 - val_loss: 0.3227 - val_accuracy: 0.8677\n",
      "Epoch 17/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3099 - accuracy: 0.8758\n",
      "Epoch 17: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8753 - val_loss: 0.3282 - val_accuracy: 0.8677\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3313 - accuracy: 0.8871\n",
      "Epoch 18: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3060 - accuracy: 0.8726 - val_loss: 0.3282 - val_accuracy: 0.8592\n",
      "Epoch 19/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2302 - accuracy: 0.8952\n",
      "Epoch 19: val_accuracy improved from 0.86769 to 0.86846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3020 - accuracy: 0.8786 - val_loss: 0.3164 - val_accuracy: 0.8685\n",
      "Epoch 20/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2979 - accuracy: 0.8761\n",
      "Epoch 20: val_accuracy improved from 0.86846 to 0.87000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2981 - accuracy: 0.8755 - val_loss: 0.3237 - val_accuracy: 0.8700\n",
      "Epoch 21/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2994 - accuracy: 0.8790\n",
      "Epoch 21: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2974 - accuracy: 0.8790 - val_loss: 0.3458 - val_accuracy: 0.8485\n",
      "Epoch 22/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3399 - accuracy: 0.8629\n",
      "Epoch 22: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3050 - accuracy: 0.8695 - val_loss: 0.3320 - val_accuracy: 0.8646\n",
      "Epoch 23/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2862 - accuracy: 0.8790\n",
      "Epoch 23: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2960 - accuracy: 0.8732 - val_loss: 0.3145 - val_accuracy: 0.8623\n",
      "Epoch 24/1000\n",
      "30/42 [====================>.........] - ETA: 0s - loss: 0.2916 - accuracy: 0.8750\n",
      "Epoch 24: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2941 - accuracy: 0.8765 - val_loss: 0.3161 - val_accuracy: 0.8569\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2889 - accuracy: 0.9032\n",
      "Epoch 25: val_accuracy improved from 0.87000 to 0.87308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2903 - accuracy: 0.8820 - val_loss: 0.3168 - val_accuracy: 0.8731\n",
      "Epoch 26/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2842 - accuracy: 0.8834\n",
      "Epoch 26: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2835 - accuracy: 0.8840 - val_loss: 0.3131 - val_accuracy: 0.8715\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2816 - accuracy: 0.8876\n",
      "Epoch 27: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2816 - accuracy: 0.8876 - val_loss: 0.3061 - val_accuracy: 0.8669\n",
      "Epoch 28/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2906 - accuracy: 0.8767\n",
      "Epoch 28: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2917 - accuracy: 0.8776 - val_loss: 0.3201 - val_accuracy: 0.8669\n",
      "Epoch 29/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2843 - accuracy: 0.8835\n",
      "Epoch 29: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2823 - accuracy: 0.8844 - val_loss: 0.3096 - val_accuracy: 0.8685\n",
      "Epoch 30/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3713 - accuracy: 0.8468\n",
      "Epoch 30: val_accuracy improved from 0.87308 to 0.87923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2768 - accuracy: 0.8849 - val_loss: 0.3003 - val_accuracy: 0.8792\n",
      "Epoch 31/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2702 - accuracy: 0.8710\n",
      "Epoch 31: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2758 - accuracy: 0.8884 - val_loss: 0.3017 - val_accuracy: 0.8762\n",
      "Epoch 32/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3064 - accuracy: 0.8952\n",
      "Epoch 32: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2743 - accuracy: 0.8894 - val_loss: 0.3128 - val_accuracy: 0.8738\n",
      "Epoch 33/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2975 - accuracy: 0.8710\n",
      "Epoch 33: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2692 - accuracy: 0.8872 - val_loss: 0.2972 - val_accuracy: 0.8769\n",
      "Epoch 34/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2362 - accuracy: 0.9113\n",
      "Epoch 34: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2854 - accuracy: 0.8815 - val_loss: 0.3211 - val_accuracy: 0.8754\n",
      "Epoch 35/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3717 - accuracy: 0.8145\n",
      "Epoch 35: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2728 - accuracy: 0.8882 - val_loss: 0.3064 - val_accuracy: 0.8762\n",
      "Epoch 36/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2224 - accuracy: 0.9274\n",
      "Epoch 36: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3019 - accuracy: 0.8711 - val_loss: 0.3245 - val_accuracy: 0.8569\n",
      "Epoch 37/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2919 - accuracy: 0.8792\n",
      "Epoch 37: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2925 - accuracy: 0.8784 - val_loss: 0.3019 - val_accuracy: 0.8785\n",
      "Epoch 38/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1822 - accuracy: 0.9516\n",
      "Epoch 38: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.8867 - val_loss: 0.3123 - val_accuracy: 0.8677\n",
      "Epoch 39/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2806 - accuracy: 0.9032\n",
      "Epoch 39: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2730 - accuracy: 0.8886 - val_loss: 0.2991 - val_accuracy: 0.8731\n",
      "Epoch 40/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.2672 - accuracy: 0.8861\n",
      "Epoch 40: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2650 - accuracy: 0.8886 - val_loss: 0.2967 - val_accuracy: 0.8792\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2682 - accuracy: 0.8896\n",
      "Epoch 41: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2682 - accuracy: 0.8896 - val_loss: 0.2991 - val_accuracy: 0.8708\n",
      "Epoch 42/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2647 - accuracy: 0.8928\n",
      "Epoch 42: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2651 - accuracy: 0.8919 - val_loss: 0.2989 - val_accuracy: 0.8731\n",
      "Epoch 43/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2497 - accuracy: 0.9028\n",
      "Epoch 43: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.8990 - val_loss: 0.2968 - val_accuracy: 0.8723\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2294 - accuracy: 0.9113\n",
      "Epoch 44: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2636 - accuracy: 0.8926 - val_loss: 0.3524 - val_accuracy: 0.8508\n",
      "Epoch 45/1000\n",
      "28/42 [===================>..........] - ETA: 0s - loss: 0.2821 - accuracy: 0.8848\n",
      "Epoch 45: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2736 - accuracy: 0.8886 - val_loss: 0.3062 - val_accuracy: 0.8631\n",
      "Epoch 46/1000\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.2598 - accuracy: 0.8891\n",
      "Epoch 46: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2615 - accuracy: 0.8897 - val_loss: 0.2954 - val_accuracy: 0.8769\n",
      "Epoch 47/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2214 - accuracy: 0.8871\n",
      "Epoch 47: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2540 - accuracy: 0.8957 - val_loss: 0.3010 - val_accuracy: 0.8700\n",
      "Epoch 48/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2667 - accuracy: 0.8871\n",
      "Epoch 48: val_accuracy improved from 0.87923 to 0.88077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2545 - accuracy: 0.8965 - val_loss: 0.2961 - val_accuracy: 0.8808\n",
      "Epoch 49/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2105 - accuracy: 0.9435\n",
      "Epoch 49: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2544 - accuracy: 0.8932 - val_loss: 0.2912 - val_accuracy: 0.8777\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2567 - accuracy: 0.8974\n",
      "Epoch 50: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.8974 - val_loss: 0.3161 - val_accuracy: 0.8715\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2826 - accuracy: 0.8871\n",
      "Epoch 51: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2559 - accuracy: 0.8942 - val_loss: 0.2998 - val_accuracy: 0.8692\n",
      "Epoch 52/1000\n",
      "28/42 [===================>..........] - ETA: 0s - loss: 0.2439 - accuracy: 0.9041\n",
      "Epoch 52: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2561 - accuracy: 0.8959 - val_loss: 0.2933 - val_accuracy: 0.8800\n",
      "Epoch 53/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3316 - accuracy: 0.8548\n",
      "Epoch 53: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2572 - accuracy: 0.8957 - val_loss: 0.3265 - val_accuracy: 0.8585\n",
      "Epoch 54/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2555 - accuracy: 0.8950\n",
      "Epoch 54: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2542 - accuracy: 0.8959 - val_loss: 0.3065 - val_accuracy: 0.8792\n",
      "Epoch 55/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2489 - accuracy: 0.8954\n",
      "Epoch 55: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.8951 - val_loss: 0.2968 - val_accuracy: 0.8731\n",
      "Epoch 56/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2519 - accuracy: 0.8962\n",
      "Epoch 56: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.8969 - val_loss: 0.3078 - val_accuracy: 0.8662\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2344 - accuracy: 0.8790\n",
      "Epoch 57: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.8901 - val_loss: 0.3006 - val_accuracy: 0.8769\n",
      "Epoch 58/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2908 - accuracy: 0.8468\n",
      "Epoch 58: val_accuracy improved from 0.88077 to 0.88615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.8990 - val_loss: 0.2929 - val_accuracy: 0.8862\n",
      "Epoch 59/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1680 - accuracy: 0.9435\n",
      "Epoch 59: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8997 - val_loss: 0.2961 - val_accuracy: 0.8808\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2493 - accuracy: 0.9011\n",
      "Epoch 60: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.9011 - val_loss: 0.3643 - val_accuracy: 0.8554\n",
      "Epoch 61/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2577 - accuracy: 0.8930\n",
      "Epoch 61: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2611 - accuracy: 0.8921 - val_loss: 0.2915 - val_accuracy: 0.8746\n",
      "Epoch 62/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2170 - accuracy: 0.9113\n",
      "Epoch 62: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.8961 - val_loss: 0.3090 - val_accuracy: 0.8785\n",
      "Epoch 63/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3172 - accuracy: 0.8468\n",
      "Epoch 63: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2434 - accuracy: 0.9015 - val_loss: 0.3141 - val_accuracy: 0.8708\n",
      "Epoch 64/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2443 - accuracy: 0.9042\n",
      "Epoch 64: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.9042 - val_loss: 0.3380 - val_accuracy: 0.8623\n",
      "Epoch 65/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2486 - accuracy: 0.8962\n",
      "Epoch 65: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8972 - val_loss: 0.2967 - val_accuracy: 0.8762\n",
      "Epoch 66/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2493 - accuracy: 0.9013\n",
      "Epoch 66: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.9028 - val_loss: 0.3006 - val_accuracy: 0.8708\n",
      "Epoch 67/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2440 - accuracy: 0.9030\n",
      "Epoch 67: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2395 - accuracy: 0.9053 - val_loss: 0.2986 - val_accuracy: 0.8685\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2289 - accuracy: 0.9032\n",
      "Epoch 68: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2433 - accuracy: 0.9042 - val_loss: 0.2993 - val_accuracy: 0.8815\n",
      "Epoch 69/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2407 - accuracy: 0.9016\n",
      "Epoch 69: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2401 - accuracy: 0.9023 - val_loss: 0.3137 - val_accuracy: 0.8669\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3304 - accuracy: 0.8629\n",
      "Epoch 70: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2428 - accuracy: 0.8996 - val_loss: 0.2969 - val_accuracy: 0.8715\n",
      "Epoch 71/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2430 - accuracy: 0.9028\n",
      "Epoch 71: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2430 - accuracy: 0.9019 - val_loss: 0.2956 - val_accuracy: 0.8746\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2370 - accuracy: 0.9032\n",
      "Epoch 72: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.9086 - val_loss: 0.2984 - val_accuracy: 0.8746\n",
      "Epoch 73/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2058 - accuracy: 0.9194\n",
      "Epoch 73: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2380 - accuracy: 0.9009 - val_loss: 0.3204 - val_accuracy: 0.8685\n",
      "Epoch 74/1000\n",
      "30/42 [====================>.........] - ETA: 0s - loss: 0.2337 - accuracy: 0.9067\n",
      "Epoch 74: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2348 - accuracy: 0.9053 - val_loss: 0.3015 - val_accuracy: 0.8731\n",
      "Epoch 75/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2849 - accuracy: 0.9032\n",
      "Epoch 75: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2381 - accuracy: 0.9034 - val_loss: 0.2949 - val_accuracy: 0.8762\n",
      "Epoch 76/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2472 - accuracy: 0.8950\n",
      "Epoch 76: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.8955 - val_loss: 0.3223 - val_accuracy: 0.8746\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2603 - accuracy: 0.9194\n",
      "Epoch 77: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2372 - accuracy: 0.9030 - val_loss: 0.2976 - val_accuracy: 0.8731\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2085 - accuracy: 0.9113\n",
      "Epoch 78: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2330 - accuracy: 0.9049 - val_loss: 0.3101 - val_accuracy: 0.8746\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2619 - accuracy: 0.8710\n",
      "Epoch 79: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2317 - accuracy: 0.9057 - val_loss: 0.2943 - val_accuracy: 0.8700\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2464 - accuracy: 0.8952\n",
      "Epoch 80: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2314 - accuracy: 0.9063 - val_loss: 0.3040 - val_accuracy: 0.8715\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2685 - accuracy: 0.8952\n",
      "Epoch 81: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.8961 - val_loss: 0.2979 - val_accuracy: 0.8715\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2348 - accuracy: 0.9024\n",
      "Epoch 82: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2348 - accuracy: 0.9024 - val_loss: 0.2978 - val_accuracy: 0.8731\n",
      "Epoch 83/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2301 - accuracy: 0.9102\n",
      "Epoch 83: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2334 - accuracy: 0.9073 - val_loss: 0.3069 - val_accuracy: 0.8731\n",
      "Epoch 84/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2130 - accuracy: 0.9274\n",
      "Epoch 84: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2290 - accuracy: 0.9115 - val_loss: 0.3031 - val_accuracy: 0.8746\n",
      "Epoch 85/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2266 - accuracy: 0.9079\n",
      "Epoch 85: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.9076 - val_loss: 0.3148 - val_accuracy: 0.8669\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2887 - accuracy: 0.8790\n",
      "Epoch 86: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2344 - accuracy: 0.9019 - val_loss: 0.3269 - val_accuracy: 0.8662\n",
      "Epoch 87/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2363 - accuracy: 0.8992\n",
      "Epoch 87: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2363 - accuracy: 0.8992 - val_loss: 0.3018 - val_accuracy: 0.8731\n",
      "Epoch 88/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2308 - accuracy: 0.8871\n",
      "Epoch 88: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2277 - accuracy: 0.9082 - val_loss: 0.3016 - val_accuracy: 0.8708\n",
      "Epoch 89/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2299 - accuracy: 0.9050\n",
      "Epoch 89: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.9071 - val_loss: 0.3073 - val_accuracy: 0.8669\n",
      "Epoch 90/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2437 - accuracy: 0.8966\n",
      "Epoch 90: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2426 - accuracy: 0.8965 - val_loss: 0.3067 - val_accuracy: 0.8685\n",
      "Epoch 91/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1853 - accuracy: 0.9435\n",
      "Epoch 91: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2288 - accuracy: 0.9065 - val_loss: 0.3079 - val_accuracy: 0.8700\n",
      "Epoch 92/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2308 - accuracy: 0.9069\n",
      "Epoch 92: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2297 - accuracy: 0.9076 - val_loss: 0.3336 - val_accuracy: 0.8646\n",
      "Epoch 93/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2096 - accuracy: 0.9113\n",
      "Epoch 93: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2411 - accuracy: 0.8972 - val_loss: 0.3140 - val_accuracy: 0.8646\n",
      "Epoch 94/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2578 - accuracy: 0.8871\n",
      "Epoch 94: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2195 - accuracy: 0.9123 - val_loss: 0.3002 - val_accuracy: 0.8738\n",
      "Epoch 95/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2350 - accuracy: 0.9024\n",
      "Epoch 95: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2323 - accuracy: 0.9036 - val_loss: 0.3182 - val_accuracy: 0.8677\n",
      "Epoch 96/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2246 - accuracy: 0.9111\n",
      "Epoch 96: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2244 - accuracy: 0.9109 - val_loss: 0.3103 - val_accuracy: 0.8692\n",
      "Epoch 97/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2478 - accuracy: 0.9113\n",
      "Epoch 97: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2213 - accuracy: 0.9111 - val_loss: 0.3099 - val_accuracy: 0.8685\n",
      "Epoch 98/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1968 - accuracy: 0.9355\n",
      "Epoch 98: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2149 - accuracy: 0.9136 - val_loss: 0.3242 - val_accuracy: 0.8700\n",
      "Epoch 99/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.2164 - accuracy: 0.9097\n",
      "Epoch 99: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2188 - accuracy: 0.9107 - val_loss: 0.3149 - val_accuracy: 0.8700\n",
      "Epoch 100/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2169 - accuracy: 0.9128\n",
      "Epoch 100: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2169 - accuracy: 0.9128 - val_loss: 0.3157 - val_accuracy: 0.8685\n",
      "Epoch 101/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2242 - accuracy: 0.9082\n",
      "Epoch 101: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2242 - accuracy: 0.9082 - val_loss: 0.3239 - val_accuracy: 0.8738\n",
      "Epoch 102/1000\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.2106 - accuracy: 0.9166\n",
      "Epoch 102: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2160 - accuracy: 0.9132 - val_loss: 0.3136 - val_accuracy: 0.8685\n",
      "Epoch 103/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2103 - accuracy: 0.9133\n",
      "Epoch 103: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2092 - accuracy: 0.9136 - val_loss: 0.3179 - val_accuracy: 0.8677\n",
      "Epoch 104/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1792 - accuracy: 0.9113\n",
      "Epoch 104: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2173 - accuracy: 0.9130 - val_loss: 0.3296 - val_accuracy: 0.8677\n",
      "Epoch 105/1000\n",
      "28/42 [===================>..........] - ETA: 0s - loss: 0.2200 - accuracy: 0.9073\n",
      "Epoch 105: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2204 - accuracy: 0.9107 - val_loss: 0.3209 - val_accuracy: 0.8662\n",
      "Epoch 106/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2097 - accuracy: 0.9138\n",
      "Epoch 106: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2088 - accuracy: 0.9148 - val_loss: 0.3246 - val_accuracy: 0.8615\n",
      "Epoch 107/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2108 - accuracy: 0.9154\n",
      "Epoch 107: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2088 - accuracy: 0.9161 - val_loss: 0.3205 - val_accuracy: 0.8692\n",
      "Epoch 108/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2260 - accuracy: 0.9032\n",
      "Epoch 108: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2132 - accuracy: 0.9146 - val_loss: 0.3209 - val_accuracy: 0.8615\n",
      "Epoch 109/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2090 - accuracy: 0.9173\n",
      "Epoch 109: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2112 - accuracy: 0.9150 - val_loss: 0.3128 - val_accuracy: 0.8646\n",
      "Epoch 110/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2455 - accuracy: 0.9113\n",
      "Epoch 110: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.9086 - val_loss: 0.3223 - val_accuracy: 0.8631\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1419 - accuracy: 0.9355\n",
      "Epoch 111: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2292 - accuracy: 0.9026 - val_loss: 0.3270 - val_accuracy: 0.8523\n",
      "Epoch 112/1000\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.2140 - accuracy: 0.9136\n",
      "Epoch 112: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2155 - accuracy: 0.9111 - val_loss: 0.3216 - val_accuracy: 0.8669\n",
      "Epoch 113/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2152 - accuracy: 0.9127\n",
      "Epoch 113: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2141 - accuracy: 0.9132 - val_loss: 0.3239 - val_accuracy: 0.8638\n",
      "Epoch 114/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2040 - accuracy: 0.9215\n",
      "Epoch 114: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2052 - accuracy: 0.9203 - val_loss: 0.3195 - val_accuracy: 0.8685\n",
      "Epoch 115/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2185 - accuracy: 0.9074\n",
      "Epoch 115: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2182 - accuracy: 0.9069 - val_loss: 0.3203 - val_accuracy: 0.8638\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1738 - accuracy: 0.9194\n",
      "Epoch 116: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2063 - accuracy: 0.9123 - val_loss: 0.3288 - val_accuracy: 0.8662\n",
      "Epoch 117/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2063 - accuracy: 0.9127\n",
      "Epoch 117: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2051 - accuracy: 0.9134 - val_loss: 0.3195 - val_accuracy: 0.8662\n",
      "Epoch 118/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2561 - accuracy: 0.9032\n",
      "Epoch 118: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2161 - accuracy: 0.9117 - val_loss: 0.3245 - val_accuracy: 0.8623\n",
      "Epoch 119/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2135 - accuracy: 0.9113\n",
      "Epoch 119: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2042 - accuracy: 0.9150 - val_loss: 0.3330 - val_accuracy: 0.8715\n",
      "Epoch 120/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1801 - accuracy: 0.9274\n",
      "Epoch 120: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2020 - accuracy: 0.9190 - val_loss: 0.3374 - val_accuracy: 0.8623\n",
      "Epoch 121/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2049 - accuracy: 0.9194\n",
      "Epoch 121: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2188 - accuracy: 0.9034 - val_loss: 0.3434 - val_accuracy: 0.8623\n",
      "Epoch 122/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2090 - accuracy: 0.9129\n",
      "Epoch 122: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2071 - accuracy: 0.9142 - val_loss: 0.3503 - val_accuracy: 0.8662\n",
      "Epoch 123/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2010 - accuracy: 0.9190\n",
      "Epoch 123: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2059 - accuracy: 0.9165 - val_loss: 0.3809 - val_accuracy: 0.8546\n",
      "Epoch 124/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2175 - accuracy: 0.9101\n",
      "Epoch 124: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2183 - accuracy: 0.9092 - val_loss: 0.3266 - val_accuracy: 0.8585\n",
      "Epoch 125/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2004 - accuracy: 0.9170\n",
      "Epoch 125: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 0.9173 - val_loss: 0.3566 - val_accuracy: 0.8623\n",
      "Epoch 126/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2020 - accuracy: 0.9161\n",
      "Epoch 126: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2035 - accuracy: 0.9159 - val_loss: 0.3607 - val_accuracy: 0.8577\n",
      "Epoch 127/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1457 - accuracy: 0.9355\n",
      "Epoch 127: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1997 - accuracy: 0.9159 - val_loss: 0.3353 - val_accuracy: 0.8677\n",
      "Epoch 128/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1854 - accuracy: 0.9194\n",
      "Epoch 128: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1962 - accuracy: 0.9213 - val_loss: 0.3500 - val_accuracy: 0.8654\n",
      "Epoch 129/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1956 - accuracy: 0.9208\n",
      "Epoch 129: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9205 - val_loss: 0.3344 - val_accuracy: 0.8600\n",
      "Epoch 130/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2946 - accuracy: 0.8790\n",
      "Epoch 130: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1904 - accuracy: 0.9226 - val_loss: 0.3365 - val_accuracy: 0.8623\n",
      "Epoch 131/1000\n",
      "29/42 [===================>..........] - ETA: 0s - loss: 0.1866 - accuracy: 0.9255\n",
      "Epoch 131: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.9225 - val_loss: 0.3387 - val_accuracy: 0.8562\n",
      "Epoch 132/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1918 - accuracy: 0.9214\n",
      "Epoch 132: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1940 - accuracy: 0.9205 - val_loss: 0.3510 - val_accuracy: 0.8669\n",
      "Epoch 133/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2980 - accuracy: 0.8790\n",
      "Epoch 133: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2003 - accuracy: 0.9190 - val_loss: 0.3622 - val_accuracy: 0.8592\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2198 - accuracy: 0.9053\n",
      "Epoch 134: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2198 - accuracy: 0.9053 - val_loss: 0.3472 - val_accuracy: 0.8623\n",
      "Epoch 135/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2062 - accuracy: 0.9129\n",
      "Epoch 135: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 0.9132 - val_loss: 0.3261 - val_accuracy: 0.8546\n",
      "Epoch 136/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1830 - accuracy: 0.9113\n",
      "Epoch 136: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1867 - accuracy: 0.9234 - val_loss: 0.3409 - val_accuracy: 0.8577\n",
      "Epoch 137/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1912 - accuracy: 0.9207\n",
      "Epoch 137: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1912 - accuracy: 0.9205 - val_loss: 0.3580 - val_accuracy: 0.8608\n",
      "Epoch 138/1000\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.1920 - accuracy: 0.9236\n",
      "Epoch 138: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1936 - accuracy: 0.9198 - val_loss: 0.3549 - val_accuracy: 0.8585\n",
      "Epoch 139/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1815 - accuracy: 0.9516\n",
      "Epoch 139: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1945 - accuracy: 0.9209 - val_loss: 0.3825 - val_accuracy: 0.8646\n",
      "Epoch 140/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1961 - accuracy: 0.9180\n",
      "Epoch 140: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1955 - accuracy: 0.9180 - val_loss: 0.3869 - val_accuracy: 0.8523\n",
      "Epoch 141/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2187 - accuracy: 0.9274\n",
      "Epoch 141: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2017 - accuracy: 0.9201 - val_loss: 0.3847 - val_accuracy: 0.8631\n",
      "Epoch 142/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1908 - accuracy: 0.9245\n",
      "Epoch 142: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1914 - accuracy: 0.9236 - val_loss: 0.3756 - val_accuracy: 0.8631\n",
      "Epoch 143/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1686 - accuracy: 0.9274\n",
      "Epoch 143: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1841 - accuracy: 0.9240 - val_loss: 0.3394 - val_accuracy: 0.8638\n",
      "Epoch 144/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1519 - accuracy: 0.9435\n",
      "Epoch 144: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.9240 - val_loss: 0.3495 - val_accuracy: 0.8631\n",
      "Epoch 145/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1894 - accuracy: 0.9236\n",
      "Epoch 145: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1896 - accuracy: 0.9232 - val_loss: 0.3902 - val_accuracy: 0.8515\n",
      "Epoch 146/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2020 - accuracy: 0.9274\n",
      "Epoch 146: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1909 - accuracy: 0.9194 - val_loss: 0.3775 - val_accuracy: 0.8615\n",
      "Epoch 147/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1817 - accuracy: 0.9292\n",
      "Epoch 147: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1833 - accuracy: 0.9269 - val_loss: 0.3664 - val_accuracy: 0.8554\n",
      "Epoch 148/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2359 - accuracy: 0.8629\n",
      "Epoch 148: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1873 - accuracy: 0.9238 - val_loss: 0.3691 - val_accuracy: 0.8654\n",
      "Epoch 149/1000\n",
      "23/42 [===============>..............] - ETA: 0s - loss: 0.1845 - accuracy: 0.9229\n",
      "Epoch 149: val_accuracy did not improve from 0.88615\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1836 - accuracy: 0.9242 - val_loss: 0.3559 - val_accuracy: 0.8554\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 23s - loss: 5.3576 - accuracy: 0.3871\n",
      "Epoch 1: val_accuracy improved from -inf to 0.71154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 1.0905 - accuracy: 0.5819 - val_loss: 0.5716 - val_accuracy: 0.7115\n",
      "Epoch 2/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.5985 - accuracy: 0.6694\n",
      "Epoch 2: val_accuracy improved from 0.71154 to 0.80077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7722 - val_loss: 0.4683 - val_accuracy: 0.8008\n",
      "Epoch 3/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.4492 - accuracy: 0.8147\n",
      "Epoch 3: val_accuracy improved from 0.80077 to 0.83846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.8162 - val_loss: 0.4129 - val_accuracy: 0.8385\n",
      "Epoch 4/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.4019 - accuracy: 0.8351\n",
      "Epoch 4: val_accuracy improved from 0.83846 to 0.84769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4009 - accuracy: 0.8347 - val_loss: 0.3789 - val_accuracy: 0.8477\n",
      "Epoch 5/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3094 - accuracy: 0.8790\n",
      "Epoch 5: val_accuracy did not improve from 0.84769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8534 - val_loss: 0.3634 - val_accuracy: 0.8438\n",
      "Epoch 6/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3652 - accuracy: 0.8387\n",
      "Epoch 6: val_accuracy did not improve from 0.84769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8422 - val_loss: 0.3596 - val_accuracy: 0.8462\n",
      "Epoch 7/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4171 - accuracy: 0.7661\n",
      "Epoch 7: val_accuracy did not improve from 0.84769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8622 - val_loss: 0.3597 - val_accuracy: 0.8477\n",
      "Epoch 8/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.3431 - accuracy: 0.8578\n",
      "Epoch 8: val_accuracy improved from 0.84769 to 0.85462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3417 - accuracy: 0.8580 - val_loss: 0.3409 - val_accuracy: 0.8546\n",
      "Epoch 9/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.3280 - accuracy: 0.8684\n",
      "Epoch 9: val_accuracy improved from 0.85462 to 0.85923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3270 - accuracy: 0.8676 - val_loss: 0.3394 - val_accuracy: 0.8592\n",
      "Epoch 10/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3264 - accuracy: 0.8676\n",
      "Epoch 10: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8674 - val_loss: 0.3434 - val_accuracy: 0.8577\n",
      "Epoch 11/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2617 - accuracy: 0.9032\n",
      "Epoch 11: val_accuracy improved from 0.85923 to 0.86154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8674 - val_loss: 0.3306 - val_accuracy: 0.8615\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3271 - accuracy: 0.8548\n",
      "Epoch 12: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8565 - val_loss: 0.3314 - val_accuracy: 0.8577\n",
      "Epoch 13/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3429 - accuracy: 0.8468\n",
      "Epoch 13: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3161 - accuracy: 0.8701 - val_loss: 0.3326 - val_accuracy: 0.8562\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2957 - accuracy: 0.8790\n",
      "Epoch 14: val_accuracy improved from 0.86154 to 0.86231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8480 - val_loss: 0.3451 - val_accuracy: 0.8623\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4034 - accuracy: 0.7984\n",
      "Epoch 15: val_accuracy did not improve from 0.86231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8647 - val_loss: 0.3303 - val_accuracy: 0.8623\n",
      "Epoch 16/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3308 - accuracy: 0.8548\n",
      "Epoch 16: val_accuracy did not improve from 0.86231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8682 - val_loss: 0.3311 - val_accuracy: 0.8600\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3616 - accuracy: 0.8306\n",
      "Epoch 17: val_accuracy did not improve from 0.86231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8720 - val_loss: 0.3628 - val_accuracy: 0.8331\n",
      "Epoch 18/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3197 - accuracy: 0.8643\n",
      "Epoch 18: val_accuracy did not improve from 0.86231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8647 - val_loss: 0.3317 - val_accuracy: 0.8546\n",
      "Epoch 19/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3042 - accuracy: 0.8790\n",
      "Epoch 19: val_accuracy improved from 0.86231 to 0.86462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3124 - accuracy: 0.8693 - val_loss: 0.3260 - val_accuracy: 0.8646\n",
      "Epoch 20/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2394 - accuracy: 0.8871\n",
      "Epoch 20: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8695 - val_loss: 0.3443 - val_accuracy: 0.8431\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3090 - accuracy: 0.8720\n",
      "Epoch 21: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8720 - val_loss: 0.3271 - val_accuracy: 0.8600\n",
      "Epoch 22/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2917 - accuracy: 0.8871\n",
      "Epoch 22: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.8759 - val_loss: 0.3252 - val_accuracy: 0.8600\n",
      "Epoch 23/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.3022 - accuracy: 0.8729\n",
      "Epoch 23: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 0.8724 - val_loss: 0.3255 - val_accuracy: 0.8646\n",
      "Epoch 24/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.3042 - accuracy: 0.8770\n",
      "Epoch 24: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 0.8780 - val_loss: 0.3392 - val_accuracy: 0.8446\n",
      "Epoch 25/1000\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.3293 - accuracy: 0.8591\n",
      "Epoch 25: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8593 - val_loss: 0.3486 - val_accuracy: 0.8400\n",
      "Epoch 26/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2936 - accuracy: 0.8795\n",
      "Epoch 26: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2949 - accuracy: 0.8782 - val_loss: 0.3287 - val_accuracy: 0.8523\n",
      "Epoch 27/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3561 - accuracy: 0.8468\n",
      "Epoch 27: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2968 - accuracy: 0.8753 - val_loss: 0.3370 - val_accuracy: 0.8485\n",
      "Epoch 28/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3070 - accuracy: 0.8710\n",
      "Epoch 28: val_accuracy improved from 0.86462 to 0.86692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3097 - accuracy: 0.8690 - val_loss: 0.3239 - val_accuracy: 0.8669\n",
      "Epoch 29/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2942 - accuracy: 0.8803\n",
      "Epoch 29: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2919 - accuracy: 0.8805 - val_loss: 0.3228 - val_accuracy: 0.8654\n",
      "Epoch 30/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2624 - accuracy: 0.8871\n",
      "Epoch 30: val_accuracy did not improve from 0.86692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2973 - accuracy: 0.8751 - val_loss: 0.3254 - val_accuracy: 0.8554\n",
      "Epoch 31/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3388 - accuracy: 0.8548\n",
      "Epoch 31: val_accuracy improved from 0.86692 to 0.87231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3027 - accuracy: 0.8747 - val_loss: 0.3276 - val_accuracy: 0.8723\n",
      "Epoch 32/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2834 - accuracy: 0.8710\n",
      "Epoch 32: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.8717 - val_loss: 0.3296 - val_accuracy: 0.8531\n",
      "Epoch 33/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2821 - accuracy: 0.9113\n",
      "Epoch 33: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.8772 - val_loss: 0.3308 - val_accuracy: 0.8654\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3011 - accuracy: 0.8688\n",
      "Epoch 34: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3011 - accuracy: 0.8688 - val_loss: 0.3304 - val_accuracy: 0.8700\n",
      "Epoch 35/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2450 - accuracy: 0.9194\n",
      "Epoch 35: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.8769 - val_loss: 0.3196 - val_accuracy: 0.8669\n",
      "Epoch 36/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2916 - accuracy: 0.8754\n",
      "Epoch 36: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2923 - accuracy: 0.8753 - val_loss: 0.3211 - val_accuracy: 0.8669\n",
      "Epoch 37/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.2969 - accuracy: 0.8694\n",
      "Epoch 37: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3013 - accuracy: 0.8715 - val_loss: 0.3735 - val_accuracy: 0.8485\n",
      "Epoch 38/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2476 - accuracy: 0.8790\n",
      "Epoch 38: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2945 - accuracy: 0.8772 - val_loss: 0.3186 - val_accuracy: 0.8623\n",
      "Epoch 39/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2385 - accuracy: 0.9435\n",
      "Epoch 39: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2869 - accuracy: 0.8801 - val_loss: 0.3565 - val_accuracy: 0.8431\n",
      "Epoch 40/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3632 - accuracy: 0.8468\n",
      "Epoch 40: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2874 - accuracy: 0.8849 - val_loss: 0.3177 - val_accuracy: 0.8708\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2823 - accuracy: 0.8842\n",
      "Epoch 41: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2823 - accuracy: 0.8842 - val_loss: 0.3199 - val_accuracy: 0.8692\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2561 - accuracy: 0.8952\n",
      "Epoch 42: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2888 - accuracy: 0.8772 - val_loss: 0.3167 - val_accuracy: 0.8685\n",
      "Epoch 43/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2674 - accuracy: 0.8952\n",
      "Epoch 43: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2827 - accuracy: 0.8832 - val_loss: 0.3183 - val_accuracy: 0.8708\n",
      "Epoch 44/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.2852 - accuracy: 0.8817\n",
      "Epoch 44: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2841 - accuracy: 0.8811 - val_loss: 0.3338 - val_accuracy: 0.8562\n",
      "Epoch 45/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2830 - accuracy: 0.8814\n",
      "Epoch 45: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2836 - accuracy: 0.8811 - val_loss: 0.3242 - val_accuracy: 0.8631\n",
      "Epoch 46/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2787 - accuracy: 0.8877\n",
      "Epoch 46: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2779 - accuracy: 0.8876 - val_loss: 0.3150 - val_accuracy: 0.8669\n",
      "Epoch 47/1000\n",
      "29/42 [===================>..........] - ETA: 0s - loss: 0.2694 - accuracy: 0.8915\n",
      "Epoch 47: val_accuracy improved from 0.87231 to 0.87538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2697 - accuracy: 0.8915 - val_loss: 0.3128 - val_accuracy: 0.8754\n",
      "Epoch 48/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2437 - accuracy: 0.9194\n",
      "Epoch 48: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2816 - accuracy: 0.8855 - val_loss: 0.3406 - val_accuracy: 0.8531\n",
      "Epoch 49/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2769 - accuracy: 0.8853\n",
      "Epoch 49: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2786 - accuracy: 0.8844 - val_loss: 0.3513 - val_accuracy: 0.8515\n",
      "Epoch 50/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2775 - accuracy: 0.8827\n",
      "Epoch 50: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2779 - accuracy: 0.8819 - val_loss: 0.3099 - val_accuracy: 0.8746\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2704 - accuracy: 0.8842\n",
      "Epoch 51: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2704 - accuracy: 0.8842 - val_loss: 0.3287 - val_accuracy: 0.8585\n",
      "Epoch 52/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3896 - accuracy: 0.8145\n",
      "Epoch 52: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2742 - accuracy: 0.8845 - val_loss: 0.3355 - val_accuracy: 0.8554\n",
      "Epoch 53/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2694 - accuracy: 0.8903\n",
      "Epoch 53: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2696 - accuracy: 0.8901 - val_loss: 0.3532 - val_accuracy: 0.8554\n",
      "Epoch 54/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3722 - accuracy: 0.8387\n",
      "Epoch 54: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2757 - accuracy: 0.8832 - val_loss: 0.3468 - val_accuracy: 0.8562\n",
      "Epoch 55/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2260 - accuracy: 0.9113\n",
      "Epoch 55: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2634 - accuracy: 0.8909 - val_loss: 0.3287 - val_accuracy: 0.8731\n",
      "Epoch 56/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2671 - accuracy: 0.8914\n",
      "Epoch 56: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2673 - accuracy: 0.8905 - val_loss: 0.3284 - val_accuracy: 0.8615\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2435 - accuracy: 0.9113\n",
      "Epoch 57: val_accuracy did not improve from 0.87538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2741 - accuracy: 0.8869 - val_loss: 0.3169 - val_accuracy: 0.8700\n",
      "Epoch 58/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.2645 - accuracy: 0.8923\n",
      "Epoch 58: val_accuracy improved from 0.87538 to 0.87923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2641 - accuracy: 0.8938 - val_loss: 0.3085 - val_accuracy: 0.8792\n",
      "Epoch 59/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2595 - accuracy: 0.8941\n",
      "Epoch 59: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2593 - accuracy: 0.8936 - val_loss: 0.3226 - val_accuracy: 0.8777\n",
      "Epoch 60/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3262 - accuracy: 0.8548\n",
      "Epoch 60: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2625 - accuracy: 0.8928 - val_loss: 0.3139 - val_accuracy: 0.8654\n",
      "Epoch 61/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2706 - accuracy: 0.8869\n",
      "Epoch 61: val_accuracy improved from 0.87923 to 0.88462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2692 - accuracy: 0.8874 - val_loss: 0.3034 - val_accuracy: 0.8846\n",
      "Epoch 62/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2614 - accuracy: 0.8925\n",
      "Epoch 62: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2694 - accuracy: 0.8894 - val_loss: 0.3316 - val_accuracy: 0.8623\n",
      "Epoch 63/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2219 - accuracy: 0.9113\n",
      "Epoch 63: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2629 - accuracy: 0.8955 - val_loss: 0.3036 - val_accuracy: 0.8708\n",
      "Epoch 64/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2498 - accuracy: 0.8978\n",
      "Epoch 64: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2537 - accuracy: 0.8961 - val_loss: 0.3195 - val_accuracy: 0.8754\n",
      "Epoch 65/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2590 - accuracy: 0.9194\n",
      "Epoch 65: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2612 - accuracy: 0.8947 - val_loss: 0.3446 - val_accuracy: 0.8508\n",
      "Epoch 66/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2568 - accuracy: 0.8918\n",
      "Epoch 66: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2565 - accuracy: 0.8928 - val_loss: 0.3209 - val_accuracy: 0.8754\n",
      "Epoch 67/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2373 - accuracy: 0.9113\n",
      "Epoch 67: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2579 - accuracy: 0.8917 - val_loss: 0.3035 - val_accuracy: 0.8769\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2522 - accuracy: 0.9113\n",
      "Epoch 68: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2547 - accuracy: 0.8978 - val_loss: 0.3214 - val_accuracy: 0.8785\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2603 - accuracy: 0.8932\n",
      "Epoch 69: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2603 - accuracy: 0.8932 - val_loss: 0.3172 - val_accuracy: 0.8615\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2710 - accuracy: 0.8710\n",
      "Epoch 70: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.8938 - val_loss: 0.3068 - val_accuracy: 0.8692\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3206 - accuracy: 0.8548\n",
      "Epoch 71: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.8965 - val_loss: 0.3004 - val_accuracy: 0.8815\n",
      "Epoch 72/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2430 - accuracy: 0.9050\n",
      "Epoch 72: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.9038 - val_loss: 0.3185 - val_accuracy: 0.8762\n",
      "Epoch 73/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2554 - accuracy: 0.8963\n",
      "Epoch 73: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2561 - accuracy: 0.8959 - val_loss: 0.3089 - val_accuracy: 0.8746\n",
      "Epoch 74/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2371 - accuracy: 0.9038\n",
      "Epoch 74: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.9013 - val_loss: 0.3033 - val_accuracy: 0.8792\n",
      "Epoch 75/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1779 - accuracy: 0.9355\n",
      "Epoch 75: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2421 - accuracy: 0.9026 - val_loss: 0.3051 - val_accuracy: 0.8800\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3067 - accuracy: 0.8387\n",
      "Epoch 76: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.9003 - val_loss: 0.3015 - val_accuracy: 0.8769\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2785 - accuracy: 0.8790\n",
      "Epoch 77: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2582 - accuracy: 0.8928 - val_loss: 0.3028 - val_accuracy: 0.8731\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2649 - accuracy: 0.8548\n",
      "Epoch 78: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.8982 - val_loss: 0.2977 - val_accuracy: 0.8738\n",
      "Epoch 79/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.2732 - accuracy: 0.8822\n",
      "Epoch 79: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2657 - accuracy: 0.8872 - val_loss: 0.3130 - val_accuracy: 0.8769\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2433 - accuracy: 0.8952\n",
      "Epoch 80: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2431 - accuracy: 0.9026 - val_loss: 0.3346 - val_accuracy: 0.8669\n",
      "Epoch 81/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2441 - accuracy: 0.9020\n",
      "Epoch 81: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2424 - accuracy: 0.9028 - val_loss: 0.3321 - val_accuracy: 0.8600\n",
      "Epoch 82/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2831 - accuracy: 0.9032\n",
      "Epoch 82: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2484 - accuracy: 0.9005 - val_loss: 0.3121 - val_accuracy: 0.8746\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1937 - accuracy: 0.9274\n",
      "Epoch 83: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2433 - accuracy: 0.8982 - val_loss: 0.3093 - val_accuracy: 0.8715\n",
      "Epoch 84/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2414 - accuracy: 0.9014\n",
      "Epoch 84: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2426 - accuracy: 0.9005 - val_loss: 0.3071 - val_accuracy: 0.8738\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1918 - accuracy: 0.9194\n",
      "Epoch 85: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2424 - accuracy: 0.9024 - val_loss: 0.3169 - val_accuracy: 0.8715\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2529 - accuracy: 0.9032\n",
      "Epoch 86: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2522 - accuracy: 0.8980 - val_loss: 0.3359 - val_accuracy: 0.8662\n",
      "Epoch 87/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2421 - accuracy: 0.8988\n",
      "Epoch 87: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.8969 - val_loss: 0.3263 - val_accuracy: 0.8669\n",
      "Epoch 88/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2378 - accuracy: 0.9048\n",
      "Epoch 88: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2398 - accuracy: 0.9036 - val_loss: 0.3095 - val_accuracy: 0.8754\n",
      "Epoch 89/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2352 - accuracy: 0.9049\n",
      "Epoch 89: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2352 - accuracy: 0.9049 - val_loss: 0.3144 - val_accuracy: 0.8692\n",
      "Epoch 90/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2305 - accuracy: 0.9051\n",
      "Epoch 90: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2348 - accuracy: 0.9021 - val_loss: 0.3005 - val_accuracy: 0.8762\n",
      "Epoch 91/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1634 - accuracy: 0.9516\n",
      "Epoch 91: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2341 - accuracy: 0.9063 - val_loss: 0.3091 - val_accuracy: 0.8708\n",
      "Epoch 92/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2347 - accuracy: 0.9032\n",
      "Epoch 92: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2363 - accuracy: 0.9038 - val_loss: 0.3122 - val_accuracy: 0.8738\n",
      "Epoch 93/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1959 - accuracy: 0.9194\n",
      "Epoch 93: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2398 - accuracy: 0.9021 - val_loss: 0.3275 - val_accuracy: 0.8646\n",
      "Epoch 94/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2456 - accuracy: 0.8993\n",
      "Epoch 94: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.8982 - val_loss: 0.3363 - val_accuracy: 0.8623\n",
      "Epoch 95/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2438 - accuracy: 0.9013\n",
      "Epoch 95: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.9017 - val_loss: 0.3129 - val_accuracy: 0.8700\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2696 - accuracy: 0.8710\n",
      "Epoch 96: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2314 - accuracy: 0.9073 - val_loss: 0.3093 - val_accuracy: 0.8754\n",
      "Epoch 97/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2388 - accuracy: 0.9047\n",
      "Epoch 97: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2359 - accuracy: 0.9057 - val_loss: 0.3343 - val_accuracy: 0.8692\n",
      "Epoch 98/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2346 - accuracy: 0.9058\n",
      "Epoch 98: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2331 - accuracy: 0.9065 - val_loss: 0.3029 - val_accuracy: 0.8754\n",
      "Epoch 99/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2253 - accuracy: 0.9075\n",
      "Epoch 99: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2279 - accuracy: 0.9055 - val_loss: 0.3081 - val_accuracy: 0.8723\n",
      "Epoch 100/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1265 - accuracy: 0.9516\n",
      "Epoch 100: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2638 - accuracy: 0.8915 - val_loss: 0.3407 - val_accuracy: 0.8615\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2121 - accuracy: 0.9274\n",
      "Epoch 101: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2345 - accuracy: 0.9073 - val_loss: 0.3087 - val_accuracy: 0.8762\n",
      "Epoch 102/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2941 - accuracy: 0.9113\n",
      "Epoch 102: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2307 - accuracy: 0.9105 - val_loss: 0.3207 - val_accuracy: 0.8777\n",
      "Epoch 103/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2152 - accuracy: 0.8952\n",
      "Epoch 103: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2300 - accuracy: 0.9044 - val_loss: 0.3198 - val_accuracy: 0.8708\n",
      "Epoch 104/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2796 - accuracy: 0.9113\n",
      "Epoch 104: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2290 - accuracy: 0.9074 - val_loss: 0.3098 - val_accuracy: 0.8762\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2169 - accuracy: 0.8952\n",
      "Epoch 105: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2244 - accuracy: 0.9092 - val_loss: 0.3146 - val_accuracy: 0.8746\n",
      "Epoch 106/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1849 - accuracy: 0.9113\n",
      "Epoch 106: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.9107 - val_loss: 0.3135 - val_accuracy: 0.8746\n",
      "Epoch 107/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2275 - accuracy: 0.9117\n",
      "Epoch 107: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2320 - accuracy: 0.9084 - val_loss: 0.3289 - val_accuracy: 0.8677\n",
      "Epoch 108/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.2299 - accuracy: 0.9064\n",
      "Epoch 108: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2302 - accuracy: 0.9063 - val_loss: 0.3072 - val_accuracy: 0.8685\n",
      "Epoch 109/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2257 - accuracy: 0.9046\n",
      "Epoch 109: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.9055 - val_loss: 0.3081 - val_accuracy: 0.8669\n",
      "Epoch 110/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2203 - accuracy: 0.9113\n",
      "Epoch 110: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2202 - accuracy: 0.9109 - val_loss: 0.3063 - val_accuracy: 0.8692\n",
      "Epoch 111/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2290 - accuracy: 0.9081\n",
      "Epoch 111: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.9096 - val_loss: 0.3390 - val_accuracy: 0.8592\n",
      "Epoch 112/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2484 - accuracy: 0.8871\n",
      "Epoch 112: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.9121 - val_loss: 0.3186 - val_accuracy: 0.8700\n",
      "Epoch 113/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2191 - accuracy: 0.9113\n",
      "Epoch 113: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2281 - accuracy: 0.9117 - val_loss: 0.3200 - val_accuracy: 0.8700\n",
      "Epoch 114/1000\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.2220 - accuracy: 0.9115\n",
      "Epoch 114: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2237 - accuracy: 0.9096 - val_loss: 0.3358 - val_accuracy: 0.8646\n",
      "Epoch 115/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2543 - accuracy: 0.8871\n",
      "Epoch 115: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2367 - accuracy: 0.9044 - val_loss: 0.3089 - val_accuracy: 0.8731\n",
      "Epoch 116/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2244 - accuracy: 0.9107\n",
      "Epoch 116: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2244 - accuracy: 0.9107 - val_loss: 0.3094 - val_accuracy: 0.8777\n",
      "Epoch 117/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2184 - accuracy: 0.9123\n",
      "Epoch 117: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2192 - accuracy: 0.9124 - val_loss: 0.3207 - val_accuracy: 0.8746\n",
      "Epoch 118/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2167 - accuracy: 0.9148\n",
      "Epoch 118: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2159 - accuracy: 0.9151 - val_loss: 0.3156 - val_accuracy: 0.8715\n",
      "Epoch 119/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2408 - accuracy: 0.9194\n",
      "Epoch 119: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2142 - accuracy: 0.9150 - val_loss: 0.3186 - val_accuracy: 0.8731\n",
      "Epoch 120/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2189 - accuracy: 0.9111\n",
      "Epoch 120: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2189 - accuracy: 0.9115 - val_loss: 0.3186 - val_accuracy: 0.8746\n",
      "Epoch 121/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2817 - accuracy: 0.8710\n",
      "Epoch 121: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2134 - accuracy: 0.9132 - val_loss: 0.3119 - val_accuracy: 0.8708\n",
      "Epoch 122/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2151 - accuracy: 0.9130\n",
      "Epoch 122: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2131 - accuracy: 0.9148 - val_loss: 0.3185 - val_accuracy: 0.8685\n",
      "Epoch 123/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2529 - accuracy: 0.9032\n",
      "Epoch 123: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2204 - accuracy: 0.9080 - val_loss: 0.3111 - val_accuracy: 0.8715\n",
      "Epoch 124/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2201 - accuracy: 0.9101\n",
      "Epoch 124: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2201 - accuracy: 0.9101 - val_loss: 0.3252 - val_accuracy: 0.8638\n",
      "Epoch 125/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2215 - accuracy: 0.9107\n",
      "Epoch 125: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2216 - accuracy: 0.9107 - val_loss: 0.3229 - val_accuracy: 0.8677\n",
      "Epoch 126/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1879 - accuracy: 0.9435\n",
      "Epoch 126: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2265 - accuracy: 0.9073 - val_loss: 0.3174 - val_accuracy: 0.8715\n",
      "Epoch 127/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1562 - accuracy: 0.9516\n",
      "Epoch 127: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2176 - accuracy: 0.9136 - val_loss: 0.3096 - val_accuracy: 0.8731\n",
      "Epoch 128/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2533 - accuracy: 0.9194\n",
      "Epoch 128: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2243 - accuracy: 0.9096 - val_loss: 0.3122 - val_accuracy: 0.8708\n",
      "Epoch 129/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2502 - accuracy: 0.8871\n",
      "Epoch 129: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2115 - accuracy: 0.9159 - val_loss: 0.3288 - val_accuracy: 0.8662\n",
      "Epoch 130/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2788 - accuracy: 0.8629\n",
      "Epoch 130: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2207 - accuracy: 0.9105 - val_loss: 0.3177 - val_accuracy: 0.8677\n",
      "Epoch 131/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2097 - accuracy: 0.9158\n",
      "Epoch 131: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.9150 - val_loss: 0.3226 - val_accuracy: 0.8708\n",
      "Epoch 132/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2100 - accuracy: 0.9149\n",
      "Epoch 132: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2106 - accuracy: 0.9148 - val_loss: 0.3204 - val_accuracy: 0.8700\n",
      "Epoch 133/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2050 - accuracy: 0.9173\n",
      "Epoch 133: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2050 - accuracy: 0.9173 - val_loss: 0.3208 - val_accuracy: 0.8731\n",
      "Epoch 134/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2018 - accuracy: 0.9194\n",
      "Epoch 134: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2059 - accuracy: 0.9171 - val_loss: 0.3188 - val_accuracy: 0.8692\n",
      "Epoch 135/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2154 - accuracy: 0.9135\n",
      "Epoch 135: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2148 - accuracy: 0.9134 - val_loss: 0.3137 - val_accuracy: 0.8700\n",
      "Epoch 136/1000\n",
      "29/42 [===================>..........] - ETA: 0s - loss: 0.2050 - accuracy: 0.9196\n",
      "Epoch 136: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2117 - accuracy: 0.9161 - val_loss: 0.3326 - val_accuracy: 0.8654\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1900 - accuracy: 0.9274\n",
      "Epoch 137: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2172 - accuracy: 0.9134 - val_loss: 0.3101 - val_accuracy: 0.8723\n",
      "Epoch 138/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1284 - accuracy: 0.9597\n",
      "Epoch 138: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2063 - accuracy: 0.9138 - val_loss: 0.3246 - val_accuracy: 0.8708\n",
      "Epoch 139/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2054 - accuracy: 0.9166\n",
      "Epoch 139: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2071 - accuracy: 0.9155 - val_loss: 0.3087 - val_accuracy: 0.8708\n",
      "Epoch 140/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2022 - accuracy: 0.9205\n",
      "Epoch 140: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2022 - accuracy: 0.9205 - val_loss: 0.3336 - val_accuracy: 0.8700\n",
      "Epoch 141/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2129 - accuracy: 0.9124\n",
      "Epoch 141: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2129 - accuracy: 0.9124 - val_loss: 0.3329 - val_accuracy: 0.8623\n",
      "Epoch 142/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2036 - accuracy: 0.9199\n",
      "Epoch 142: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2036 - accuracy: 0.9200 - val_loss: 0.3257 - val_accuracy: 0.8708\n",
      "Epoch 143/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2207 - accuracy: 0.8871\n",
      "Epoch 143: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2067 - accuracy: 0.9150 - val_loss: 0.3157 - val_accuracy: 0.8754\n",
      "Epoch 144/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2115 - accuracy: 0.9185\n",
      "Epoch 144: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2121 - accuracy: 0.9178 - val_loss: 0.3134 - val_accuracy: 0.8762\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2007 - accuracy: 0.8952\n",
      "Epoch 145: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2074 - accuracy: 0.9173 - val_loss: 0.3324 - val_accuracy: 0.8723\n",
      "Epoch 146/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1864 - accuracy: 0.9113\n",
      "Epoch 146: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2057 - accuracy: 0.9169 - val_loss: 0.3191 - val_accuracy: 0.8723\n",
      "Epoch 147/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2899 - accuracy: 0.8952\n",
      "Epoch 147: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2130 - accuracy: 0.9119 - val_loss: 0.3089 - val_accuracy: 0.8746\n",
      "Epoch 148/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1821 - accuracy: 0.9435\n",
      "Epoch 148: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2056 - accuracy: 0.9203 - val_loss: 0.3230 - val_accuracy: 0.8708\n",
      "Epoch 149/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2228 - accuracy: 0.9194\n",
      "Epoch 149: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2112 - accuracy: 0.9146 - val_loss: 0.3227 - val_accuracy: 0.8662\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2862 - accuracy: 0.9032\n",
      "Epoch 150: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1972 - accuracy: 0.9217 - val_loss: 0.3171 - val_accuracy: 0.8708\n",
      "Epoch 151/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2034 - accuracy: 0.9194\n",
      "Epoch 151: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2032 - accuracy: 0.9200 - val_loss: 0.3313 - val_accuracy: 0.8692\n",
      "Epoch 152/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.1968 - accuracy: 0.9229\n",
      "Epoch 152: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1992 - accuracy: 0.9205 - val_loss: 0.3272 - val_accuracy: 0.8654\n",
      "Epoch 153/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1985 - accuracy: 0.9221\n",
      "Epoch 153: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9221 - val_loss: 0.3338 - val_accuracy: 0.8715\n",
      "Epoch 154/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2422 - accuracy: 0.9113\n",
      "Epoch 154: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.9228 - val_loss: 0.3308 - val_accuracy: 0.8731\n",
      "Epoch 155/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1699 - accuracy: 0.9274\n",
      "Epoch 155: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2007 - accuracy: 0.9188 - val_loss: 0.3312 - val_accuracy: 0.8677\n",
      "Epoch 156/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1291 - accuracy: 0.9435\n",
      "Epoch 156: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.9238 - val_loss: 0.3222 - val_accuracy: 0.8723\n",
      "Epoch 157/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1200 - accuracy: 0.9758\n",
      "Epoch 157: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2011 - accuracy: 0.9186 - val_loss: 0.3268 - val_accuracy: 0.8662\n",
      "Epoch 158/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2227 - accuracy: 0.9274\n",
      "Epoch 158: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1922 - accuracy: 0.9275 - val_loss: 0.3152 - val_accuracy: 0.8723\n",
      "Epoch 159/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1606 - accuracy: 0.9355\n",
      "Epoch 159: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1962 - accuracy: 0.9215 - val_loss: 0.3327 - val_accuracy: 0.8708\n",
      "Epoch 160/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1947 - accuracy: 0.9213\n",
      "Epoch 160: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1947 - accuracy: 0.9213 - val_loss: 0.3285 - val_accuracy: 0.8715\n",
      "Epoch 161/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2173 - accuracy: 0.9032\n",
      "Epoch 161: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1917 - accuracy: 0.9242 - val_loss: 0.3383 - val_accuracy: 0.8723\n",
      "Epoch 162/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1774 - accuracy: 0.9435\n",
      "Epoch 162: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1871 - accuracy: 0.9244 - val_loss: 0.3224 - val_accuracy: 0.8708\n",
      "Epoch 163/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2169 - accuracy: 0.9113\n",
      "Epoch 163: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2053 - accuracy: 0.9157 - val_loss: 0.3492 - val_accuracy: 0.8715\n",
      "Epoch 164/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2023 - accuracy: 0.9274\n",
      "Epoch 164: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.9236 - val_loss: 0.3385 - val_accuracy: 0.8615\n",
      "Epoch 165/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1889 - accuracy: 0.9247\n",
      "Epoch 165: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1895 - accuracy: 0.9242 - val_loss: 0.3515 - val_accuracy: 0.8708\n",
      "Epoch 166/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1568 - accuracy: 0.9355\n",
      "Epoch 166: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1864 - accuracy: 0.9251 - val_loss: 0.3612 - val_accuracy: 0.8677\n",
      "Epoch 167/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1493 - accuracy: 0.9113\n",
      "Epoch 167: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1892 - accuracy: 0.9234 - val_loss: 0.3540 - val_accuracy: 0.8708\n",
      "Epoch 168/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1902 - accuracy: 0.9230\n",
      "Epoch 168: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1902 - accuracy: 0.9230 - val_loss: 0.3447 - val_accuracy: 0.8669\n",
      "Epoch 169/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1902 - accuracy: 0.9262\n",
      "Epoch 169: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1907 - accuracy: 0.9263 - val_loss: 0.3638 - val_accuracy: 0.8546\n",
      "Epoch 170/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1954 - accuracy: 0.9208\n",
      "Epoch 170: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1956 - accuracy: 0.9198 - val_loss: 0.3250 - val_accuracy: 0.8662\n",
      "Epoch 171/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1919 - accuracy: 0.9234\n",
      "Epoch 171: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.9238 - val_loss: 0.3221 - val_accuracy: 0.8692\n",
      "Epoch 172/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1834 - accuracy: 0.9303\n",
      "Epoch 172: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.9305 - val_loss: 0.3475 - val_accuracy: 0.8685\n",
      "Epoch 173/1000\n",
      "24/42 [================>.............] - ETA: 0s - loss: 0.1750 - accuracy: 0.9284\n",
      "Epoch 173: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1786 - accuracy: 0.9294 - val_loss: 0.3329 - val_accuracy: 0.8715\n",
      "Epoch 174/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1878 - accuracy: 0.9248\n",
      "Epoch 174: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1878 - accuracy: 0.9248 - val_loss: 0.3287 - val_accuracy: 0.8715\n",
      "Epoch 175/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1735 - accuracy: 0.9355\n",
      "Epoch 175: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1801 - accuracy: 0.9275 - val_loss: 0.3635 - val_accuracy: 0.8585\n",
      "Epoch 176/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2768 - accuracy: 0.8952\n",
      "Epoch 176: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9269 - val_loss: 0.3697 - val_accuracy: 0.8708\n",
      "Epoch 177/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1831 - accuracy: 0.9266\n",
      "Epoch 177: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1835 - accuracy: 0.9269 - val_loss: 0.3246 - val_accuracy: 0.8708\n",
      "Epoch 178/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1806 - accuracy: 0.9516\n",
      "Epoch 178: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.9275 - val_loss: 0.3491 - val_accuracy: 0.8723\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 22s - loss: 2.7320 - accuracy: 0.5242\n",
      "Epoch 1: val_accuracy improved from -inf to 0.75692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.7538 - accuracy: 0.5959 - val_loss: 0.5431 - val_accuracy: 0.7569\n",
      "Epoch 2/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.5624 - accuracy: 0.7016\n",
      "Epoch 2: val_accuracy improved from 0.75692 to 0.83154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7928 - val_loss: 0.3965 - val_accuracy: 0.8315\n",
      "Epoch 3/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4230 - accuracy: 0.7903\n",
      "Epoch 3: val_accuracy did not improve from 0.83154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8338 - val_loss: 0.4340 - val_accuracy: 0.7831\n",
      "Epoch 4/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4327 - accuracy: 0.7903\n",
      "Epoch 4: val_accuracy improved from 0.83154 to 0.83308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8480 - val_loss: 0.3726 - val_accuracy: 0.8331\n",
      "Epoch 5/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.3405 - accuracy: 0.8615\n",
      "Epoch 5: val_accuracy improved from 0.83308 to 0.85308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3390 - accuracy: 0.8615 - val_loss: 0.3413 - val_accuracy: 0.8531\n",
      "Epoch 6/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2844 - accuracy: 0.9194\n",
      "Epoch 6: val_accuracy did not improve from 0.85308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.8561 - val_loss: 0.3517 - val_accuracy: 0.8415\n",
      "Epoch 7/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2764 - accuracy: 0.8710\n",
      "Epoch 7: val_accuracy did not improve from 0.85308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8607 - val_loss: 0.3616 - val_accuracy: 0.8446\n",
      "Epoch 8/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3256 - accuracy: 0.8605\n",
      "Epoch 8: val_accuracy did not improve from 0.85308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8613 - val_loss: 0.3555 - val_accuracy: 0.8454\n",
      "Epoch 9/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2903 - accuracy: 0.8871\n",
      "Epoch 9: val_accuracy improved from 0.85308 to 0.86385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3170 - accuracy: 0.8730 - val_loss: 0.3259 - val_accuracy: 0.8638\n",
      "Epoch 10/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2737 - accuracy: 0.8710\n",
      "Epoch 10: val_accuracy improved from 0.86385 to 0.87000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3093 - accuracy: 0.8724 - val_loss: 0.3247 - val_accuracy: 0.8700\n",
      "Epoch 11/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3146 - accuracy: 0.8684\n",
      "Epoch 11: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.8690 - val_loss: 0.3276 - val_accuracy: 0.8638\n",
      "Epoch 12/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3063 - accuracy: 0.8736\n",
      "Epoch 12: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8742 - val_loss: 0.3382 - val_accuracy: 0.8415\n",
      "Epoch 13/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3000 - accuracy: 0.8387\n",
      "Epoch 13: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.8630 - val_loss: 0.3218 - val_accuracy: 0.8615\n",
      "Epoch 14/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2964 - accuracy: 0.8767\n",
      "Epoch 14: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2965 - accuracy: 0.8769 - val_loss: 0.3321 - val_accuracy: 0.8615\n",
      "Epoch 15/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2924 - accuracy: 0.8822\n",
      "Epoch 15: val_accuracy improved from 0.87000 to 0.87231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2922 - accuracy: 0.8824 - val_loss: 0.3153 - val_accuracy: 0.8723\n",
      "Epoch 16/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2825 - accuracy: 0.8548\n",
      "Epoch 16: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2955 - accuracy: 0.8801 - val_loss: 0.3229 - val_accuracy: 0.8708\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2708 - accuracy: 0.8952\n",
      "Epoch 17: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8697 - val_loss: 0.3305 - val_accuracy: 0.8638\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3033 - accuracy: 0.8699\n",
      "Epoch 18: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.8699 - val_loss: 0.3128 - val_accuracy: 0.8692\n",
      "Epoch 19/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2787 - accuracy: 0.8865\n",
      "Epoch 19: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2817 - accuracy: 0.8849 - val_loss: 0.3075 - val_accuracy: 0.8692\n",
      "Epoch 20/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3336 - accuracy: 0.8629\n",
      "Epoch 20: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2933 - accuracy: 0.8757 - val_loss: 0.3065 - val_accuracy: 0.8700\n",
      "Epoch 21/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2805 - accuracy: 0.8819\n",
      "Epoch 21: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2805 - accuracy: 0.8817 - val_loss: 0.3111 - val_accuracy: 0.8662\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2819 - accuracy: 0.8822\n",
      "Epoch 22: val_accuracy improved from 0.87231 to 0.87692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2819 - accuracy: 0.8822 - val_loss: 0.3037 - val_accuracy: 0.8769\n",
      "Epoch 23/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2888 - accuracy: 0.8798\n",
      "Epoch 23: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2883 - accuracy: 0.8797 - val_loss: 0.3366 - val_accuracy: 0.8600\n",
      "Epoch 24/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2595 - accuracy: 0.8629\n",
      "Epoch 24: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2883 - accuracy: 0.8807 - val_loss: 0.3226 - val_accuracy: 0.8731\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2928 - accuracy: 0.8710\n",
      "Epoch 25: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2818 - accuracy: 0.8834 - val_loss: 0.3476 - val_accuracy: 0.8392\n",
      "Epoch 26/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2858 - accuracy: 0.8786\n",
      "Epoch 26: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2856 - accuracy: 0.8792 - val_loss: 0.3138 - val_accuracy: 0.8662\n",
      "Epoch 27/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2697 - accuracy: 0.8908\n",
      "Epoch 27: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2704 - accuracy: 0.8905 - val_loss: 0.3017 - val_accuracy: 0.8723\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2494 - accuracy: 0.9194\n",
      "Epoch 28: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.8888 - val_loss: 0.3047 - val_accuracy: 0.8746\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2478 - accuracy: 0.8710\n",
      "Epoch 29: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2729 - accuracy: 0.8842 - val_loss: 0.2975 - val_accuracy: 0.8738\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2664 - accuracy: 0.8909\n",
      "Epoch 30: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2664 - accuracy: 0.8909 - val_loss: 0.3005 - val_accuracy: 0.8723\n",
      "Epoch 31/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2617 - accuracy: 0.8927\n",
      "Epoch 31: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2593 - accuracy: 0.8938 - val_loss: 0.2986 - val_accuracy: 0.8762\n",
      "Epoch 32/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2823 - accuracy: 0.8834\n",
      "Epoch 32: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2777 - accuracy: 0.8845 - val_loss: 0.3025 - val_accuracy: 0.8731\n",
      "Epoch 33/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2651 - accuracy: 0.8913\n",
      "Epoch 33: val_accuracy improved from 0.87692 to 0.87769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2645 - accuracy: 0.8921 - val_loss: 0.2978 - val_accuracy: 0.8777\n",
      "Epoch 34/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2546 - accuracy: 0.8950\n",
      "Epoch 34: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2589 - accuracy: 0.8924 - val_loss: 0.3150 - val_accuracy: 0.8654\n",
      "Epoch 35/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2863 - accuracy: 0.8871\n",
      "Epoch 35: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2552 - accuracy: 0.8969 - val_loss: 0.3111 - val_accuracy: 0.8715\n",
      "Epoch 36/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3051 - accuracy: 0.8871\n",
      "Epoch 36: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2578 - accuracy: 0.8955 - val_loss: 0.2966 - val_accuracy: 0.8754\n",
      "Epoch 37/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2549 - accuracy: 0.8983\n",
      "Epoch 37: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2555 - accuracy: 0.8978 - val_loss: 0.3007 - val_accuracy: 0.8669\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2578 - accuracy: 0.8926\n",
      "Epoch 38: val_accuracy improved from 0.87769 to 0.88000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2578 - accuracy: 0.8926 - val_loss: 0.2985 - val_accuracy: 0.8800\n",
      "Epoch 39/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2118 - accuracy: 0.9113\n",
      "Epoch 39: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2751 - accuracy: 0.8853 - val_loss: 0.3239 - val_accuracy: 0.8592\n",
      "Epoch 40/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2431 - accuracy: 0.8790\n",
      "Epoch 40: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2635 - accuracy: 0.8922 - val_loss: 0.2965 - val_accuracy: 0.8762\n",
      "Epoch 41/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2548 - accuracy: 0.8956\n",
      "Epoch 41: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.8980 - val_loss: 0.2991 - val_accuracy: 0.8769\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2537 - accuracy: 0.8629\n",
      "Epoch 42: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2705 - accuracy: 0.8872 - val_loss: 0.3194 - val_accuracy: 0.8631\n",
      "Epoch 43/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2598 - accuracy: 0.8926\n",
      "Epoch 43: val_accuracy improved from 0.88000 to 0.88231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2553 - accuracy: 0.8953 - val_loss: 0.2950 - val_accuracy: 0.8823\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1896 - accuracy: 0.9435\n",
      "Epoch 44: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2480 - accuracy: 0.8992 - val_loss: 0.3080 - val_accuracy: 0.8738\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2602 - accuracy: 0.8924\n",
      "Epoch 45: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2602 - accuracy: 0.8924 - val_loss: 0.3058 - val_accuracy: 0.8738\n",
      "Epoch 46/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2578 - accuracy: 0.8871\n",
      "Epoch 46: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.9021 - val_loss: 0.2998 - val_accuracy: 0.8769\n",
      "Epoch 47/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2105 - accuracy: 0.9032\n",
      "Epoch 47: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2479 - accuracy: 0.8986 - val_loss: 0.3006 - val_accuracy: 0.8785\n",
      "Epoch 48/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2580 - accuracy: 0.8925\n",
      "Epoch 48: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2556 - accuracy: 0.8926 - val_loss: 0.3346 - val_accuracy: 0.8554\n",
      "Epoch 49/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1761 - accuracy: 0.9355\n",
      "Epoch 49: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.9023 - val_loss: 0.3034 - val_accuracy: 0.8754\n",
      "Epoch 50/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1734 - accuracy: 0.9355\n",
      "Epoch 50: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2427 - accuracy: 0.9026 - val_loss: 0.3119 - val_accuracy: 0.8746\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2899 - accuracy: 0.8790\n",
      "Epoch 51: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.9009 - val_loss: 0.3000 - val_accuracy: 0.8792\n",
      "Epoch 52/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2646 - accuracy: 0.8871\n",
      "Epoch 52: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2550 - accuracy: 0.8926 - val_loss: 0.3206 - val_accuracy: 0.8608\n",
      "Epoch 53/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3121 - accuracy: 0.8790\n",
      "Epoch 53: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.8992 - val_loss: 0.3431 - val_accuracy: 0.8515\n",
      "Epoch 54/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2113 - accuracy: 0.9194\n",
      "Epoch 54: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2428 - accuracy: 0.9017 - val_loss: 0.3016 - val_accuracy: 0.8777\n",
      "Epoch 55/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1704 - accuracy: 0.9355\n",
      "Epoch 55: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2432 - accuracy: 0.9034 - val_loss: 0.2984 - val_accuracy: 0.8777\n",
      "Epoch 56/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2529 - accuracy: 0.8958\n",
      "Epoch 56: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.8963 - val_loss: 0.2967 - val_accuracy: 0.8746\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1906 - accuracy: 0.9274\n",
      "Epoch 57: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2328 - accuracy: 0.9071 - val_loss: 0.3006 - val_accuracy: 0.8777\n",
      "Epoch 58/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2264 - accuracy: 0.8790\n",
      "Epoch 58: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2418 - accuracy: 0.9017 - val_loss: 0.3153 - val_accuracy: 0.8692\n",
      "Epoch 59/1000\n",
      "29/42 [===================>..........] - ETA: 0s - loss: 0.2520 - accuracy: 0.8993\n",
      "Epoch 59: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.8986 - val_loss: 0.3095 - val_accuracy: 0.8723\n",
      "Epoch 60/1000\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.2435 - accuracy: 0.8989\n",
      "Epoch 60: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2408 - accuracy: 0.9003 - val_loss: 0.3115 - val_accuracy: 0.8762\n",
      "Epoch 61/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2371 - accuracy: 0.8790\n",
      "Epoch 61: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.8922 - val_loss: 0.2944 - val_accuracy: 0.8708\n",
      "Epoch 62/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2019 - accuracy: 0.9274\n",
      "Epoch 62: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2365 - accuracy: 0.9009 - val_loss: 0.2996 - val_accuracy: 0.8762\n",
      "Epoch 63/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2344 - accuracy: 0.9046\n",
      "Epoch 63: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2350 - accuracy: 0.9042 - val_loss: 0.3224 - val_accuracy: 0.8777\n",
      "Epoch 64/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2132 - accuracy: 0.9274\n",
      "Epoch 64: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.8961 - val_loss: 0.3069 - val_accuracy: 0.8754\n",
      "Epoch 65/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2371 - accuracy: 0.9016\n",
      "Epoch 65: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2388 - accuracy: 0.9011 - val_loss: 0.3265 - val_accuracy: 0.8615\n",
      "Epoch 66/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2571 - accuracy: 0.8871\n",
      "Epoch 66: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2317 - accuracy: 0.9067 - val_loss: 0.3089 - val_accuracy: 0.8723\n",
      "Epoch 67/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2736 - accuracy: 0.8710\n",
      "Epoch 67: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2298 - accuracy: 0.9074 - val_loss: 0.3011 - val_accuracy: 0.8769\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2610 - accuracy: 0.9032\n",
      "Epoch 68: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2262 - accuracy: 0.9111 - val_loss: 0.3075 - val_accuracy: 0.8769\n",
      "Epoch 69/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2372 - accuracy: 0.9018\n",
      "Epoch 69: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 0.8999 - val_loss: 0.3014 - val_accuracy: 0.8762\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2325 - accuracy: 0.9032\n",
      "Epoch 70: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2388 - accuracy: 0.9042 - val_loss: 0.3162 - val_accuracy: 0.8815\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1914 - accuracy: 0.9194\n",
      "Epoch 71: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2300 - accuracy: 0.9074 - val_loss: 0.3072 - val_accuracy: 0.8746\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2192 - accuracy: 0.9274\n",
      "Epoch 72: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2227 - accuracy: 0.9115 - val_loss: 0.3129 - val_accuracy: 0.8746\n",
      "Epoch 73/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2894 - accuracy: 0.8952\n",
      "Epoch 73: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2409 - accuracy: 0.8984 - val_loss: 0.3046 - val_accuracy: 0.8677\n",
      "Epoch 74/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1848 - accuracy: 0.9113\n",
      "Epoch 74: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2261 - accuracy: 0.9115 - val_loss: 0.3200 - val_accuracy: 0.8723\n",
      "Epoch 75/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2392 - accuracy: 0.9005\n",
      "Epoch 75: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2392 - accuracy: 0.9005 - val_loss: 0.3309 - val_accuracy: 0.8577\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1983 - accuracy: 0.9274\n",
      "Epoch 76: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2383 - accuracy: 0.9028 - val_loss: 0.3555 - val_accuracy: 0.8515\n",
      "Epoch 77/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2282 - accuracy: 0.9072\n",
      "Epoch 77: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2277 - accuracy: 0.9067 - val_loss: 0.3217 - val_accuracy: 0.8600\n",
      "Epoch 78/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2214 - accuracy: 0.9111\n",
      "Epoch 78: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2234 - accuracy: 0.9103 - val_loss: 0.3019 - val_accuracy: 0.8731\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2134 - accuracy: 0.9032\n",
      "Epoch 79: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2190 - accuracy: 0.9109 - val_loss: 0.3279 - val_accuracy: 0.8723\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2365 - accuracy: 0.9032\n",
      "Epoch 80: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2265 - accuracy: 0.9055 - val_loss: 0.3308 - val_accuracy: 0.8815\n",
      "Epoch 81/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2258 - accuracy: 0.9072\n",
      "Epoch 81: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 0.9073 - val_loss: 0.3203 - val_accuracy: 0.8677\n",
      "Epoch 82/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2151 - accuracy: 0.9274\n",
      "Epoch 82: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2241 - accuracy: 0.9099 - val_loss: 0.3049 - val_accuracy: 0.8708\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2364 - accuracy: 0.9032\n",
      "Epoch 83: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2146 - accuracy: 0.9119 - val_loss: 0.3289 - val_accuracy: 0.8569\n",
      "Epoch 84/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2441 - accuracy: 0.9194\n",
      "Epoch 84: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2169 - accuracy: 0.9128 - val_loss: 0.3125 - val_accuracy: 0.8738\n",
      "Epoch 85/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2190 - accuracy: 0.9092\n",
      "Epoch 85: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2169 - accuracy: 0.9101 - val_loss: 0.3156 - val_accuracy: 0.8715\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2289 - accuracy: 0.8952\n",
      "Epoch 86: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2270 - accuracy: 0.9030 - val_loss: 0.4058 - val_accuracy: 0.8377\n",
      "Epoch 87/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2352 - accuracy: 0.9002\n",
      "Epoch 87: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2342 - accuracy: 0.9011 - val_loss: 0.3324 - val_accuracy: 0.8615\n",
      "Epoch 88/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2659 - accuracy: 0.8871\n",
      "Epoch 88: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2188 - accuracy: 0.9115 - val_loss: 0.3140 - val_accuracy: 0.8692\n",
      "Epoch 89/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2141 - accuracy: 0.9113\n",
      "Epoch 89: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2146 - accuracy: 0.9109 - val_loss: 0.3092 - val_accuracy: 0.8715\n",
      "Epoch 90/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2235 - accuracy: 0.8952\n",
      "Epoch 90: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2219 - accuracy: 0.9088 - val_loss: 0.3300 - val_accuracy: 0.8562\n",
      "Epoch 91/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2269 - accuracy: 0.9071\n",
      "Epoch 91: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2272 - accuracy: 0.9076 - val_loss: 0.3238 - val_accuracy: 0.8731\n",
      "Epoch 92/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2539 - accuracy: 0.9032\n",
      "Epoch 92: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2190 - accuracy: 0.9098 - val_loss: 0.3253 - val_accuracy: 0.8615\n",
      "Epoch 93/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2231 - accuracy: 0.9056\n",
      "Epoch 93: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2233 - accuracy: 0.9053 - val_loss: 0.3340 - val_accuracy: 0.8762\n",
      "Epoch 94/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1722 - accuracy: 0.9113\n",
      "Epoch 94: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.9109 - val_loss: 0.3200 - val_accuracy: 0.8700\n",
      "Epoch 95/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1802 - accuracy: 0.9435\n",
      "Epoch 95: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2128 - accuracy: 0.9134 - val_loss: 0.3302 - val_accuracy: 0.8654\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2294 - accuracy: 0.9032\n",
      "Epoch 96: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.9082 - val_loss: 0.3196 - val_accuracy: 0.8685\n",
      "Epoch 97/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2066 - accuracy: 0.9177\n",
      "Epoch 97: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2080 - accuracy: 0.9173 - val_loss: 0.3242 - val_accuracy: 0.8715\n",
      "Epoch 98/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1654 - accuracy: 0.9435\n",
      "Epoch 98: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2101 - accuracy: 0.9140 - val_loss: 0.3319 - val_accuracy: 0.8700\n",
      "Epoch 99/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2172 - accuracy: 0.9115\n",
      "Epoch 99: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.9111 - val_loss: 0.3380 - val_accuracy: 0.8692\n",
      "Epoch 100/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2156 - accuracy: 0.8790\n",
      "Epoch 100: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2077 - accuracy: 0.9153 - val_loss: 0.3148 - val_accuracy: 0.8654\n",
      "Epoch 101/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2062 - accuracy: 0.9172\n",
      "Epoch 101: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2071 - accuracy: 0.9165 - val_loss: 0.3292 - val_accuracy: 0.8700\n",
      "Epoch 102/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1773 - accuracy: 0.9113\n",
      "Epoch 102: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2072 - accuracy: 0.9130 - val_loss: 0.3386 - val_accuracy: 0.8738\n",
      "Epoch 103/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2729 - accuracy: 0.8710\n",
      "Epoch 103: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2027 - accuracy: 0.9192 - val_loss: 0.3238 - val_accuracy: 0.8662\n",
      "Epoch 104/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2029 - accuracy: 0.9169\n",
      "Epoch 104: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2029 - accuracy: 0.9169 - val_loss: 0.3505 - val_accuracy: 0.8600\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2542 - accuracy: 0.8871\n",
      "Epoch 105: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2197 - accuracy: 0.9092 - val_loss: 0.3347 - val_accuracy: 0.8700\n",
      "Epoch 106/1000\n",
      "28/42 [===================>..........] - ETA: 0s - loss: 0.2129 - accuracy: 0.9075\n",
      "Epoch 106: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2106 - accuracy: 0.9105 - val_loss: 0.3443 - val_accuracy: 0.8615\n",
      "Epoch 107/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2215 - accuracy: 0.9082\n",
      "Epoch 107: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2195 - accuracy: 0.9107 - val_loss: 0.3312 - val_accuracy: 0.8692\n",
      "Epoch 108/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1900 - accuracy: 0.9597\n",
      "Epoch 108: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2003 - accuracy: 0.9176 - val_loss: 0.3307 - val_accuracy: 0.8685\n",
      "Epoch 109/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2039 - accuracy: 0.9151\n",
      "Epoch 109: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2039 - accuracy: 0.9151 - val_loss: 0.3216 - val_accuracy: 0.8738\n",
      "Epoch 110/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2010 - accuracy: 0.9196\n",
      "Epoch 110: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1974 - accuracy: 0.9209 - val_loss: 0.3426 - val_accuracy: 0.8685\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2216 - accuracy: 0.9274\n",
      "Epoch 111: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2074 - accuracy: 0.9188 - val_loss: 0.3571 - val_accuracy: 0.8731\n",
      "Epoch 112/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1372 - accuracy: 0.9516\n",
      "Epoch 112: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2044 - accuracy: 0.9169 - val_loss: 0.3592 - val_accuracy: 0.8577\n",
      "Epoch 113/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2389 - accuracy: 0.8975\n",
      "Epoch 113: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2335 - accuracy: 0.8994 - val_loss: 0.3782 - val_accuracy: 0.8585\n",
      "Epoch 114/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1934 - accuracy: 0.9032\n",
      "Epoch 114: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2036 - accuracy: 0.9161 - val_loss: 0.3461 - val_accuracy: 0.8623\n",
      "Epoch 115/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1471 - accuracy: 0.9516\n",
      "Epoch 115: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2034 - accuracy: 0.9182 - val_loss: 0.3321 - val_accuracy: 0.8662\n",
      "Epoch 116/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.2016 - accuracy: 0.9170\n",
      "Epoch 116: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 0.9171 - val_loss: 0.3593 - val_accuracy: 0.8646\n",
      "Epoch 117/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2431 - accuracy: 0.8871\n",
      "Epoch 117: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1979 - accuracy: 0.9173 - val_loss: 0.3314 - val_accuracy: 0.8692\n",
      "Epoch 118/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2068 - accuracy: 0.9142\n",
      "Epoch 118: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2077 - accuracy: 0.9142 - val_loss: 0.3578 - val_accuracy: 0.8708\n",
      "Epoch 119/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1949 - accuracy: 0.9255\n",
      "Epoch 119: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1954 - accuracy: 0.9242 - val_loss: 0.3495 - val_accuracy: 0.8700\n",
      "Epoch 120/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1247 - accuracy: 0.9597\n",
      "Epoch 120: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1980 - accuracy: 0.9213 - val_loss: 0.3357 - val_accuracy: 0.8715\n",
      "Epoch 121/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2213 - accuracy: 0.9032\n",
      "Epoch 121: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.9211 - val_loss: 0.3563 - val_accuracy: 0.8677\n",
      "Epoch 122/1000\n",
      "30/42 [====================>.........] - ETA: 0s - loss: 0.2006 - accuracy: 0.9212\n",
      "Epoch 122: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1971 - accuracy: 0.9232 - val_loss: 0.3855 - val_accuracy: 0.8492\n",
      "Epoch 123/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2814 - accuracy: 0.8468\n",
      "Epoch 123: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2177 - accuracy: 0.9074 - val_loss: 0.3328 - val_accuracy: 0.8723\n",
      "Epoch 124/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1888 - accuracy: 0.9264\n",
      "Epoch 124: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.9269 - val_loss: 0.3458 - val_accuracy: 0.8700\n",
      "Epoch 125/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1933 - accuracy: 0.9199\n",
      "Epoch 125: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1960 - accuracy: 0.9176 - val_loss: 0.3341 - val_accuracy: 0.8638\n",
      "Epoch 126/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1907 - accuracy: 0.9220\n",
      "Epoch 126: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1944 - accuracy: 0.9209 - val_loss: 0.3356 - val_accuracy: 0.8700\n",
      "Epoch 127/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2235 - accuracy: 0.8871\n",
      "Epoch 127: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2030 - accuracy: 0.9151 - val_loss: 0.3663 - val_accuracy: 0.8677\n",
      "Epoch 128/1000\n",
      "29/42 [===================>..........] - ETA: 0s - loss: 0.2009 - accuracy: 0.9166\n",
      "Epoch 128: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1991 - accuracy: 0.9178 - val_loss: 0.3670 - val_accuracy: 0.8638\n",
      "Epoch 129/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1413 - accuracy: 0.9435\n",
      "Epoch 129: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1887 - accuracy: 0.9223 - val_loss: 0.3522 - val_accuracy: 0.8577\n",
      "Epoch 130/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2299 - accuracy: 0.8871\n",
      "Epoch 130: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1874 - accuracy: 0.9244 - val_loss: 0.3563 - val_accuracy: 0.8677\n",
      "Epoch 131/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1943 - accuracy: 0.9198\n",
      "Epoch 131: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1943 - accuracy: 0.9198 - val_loss: 0.3466 - val_accuracy: 0.8669\n",
      "Epoch 132/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1501 - accuracy: 0.9516\n",
      "Epoch 132: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.9234 - val_loss: 0.3529 - val_accuracy: 0.8646\n",
      "Epoch 133/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1914 - accuracy: 0.9209\n",
      "Epoch 133: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.9219 - val_loss: 0.3580 - val_accuracy: 0.8708\n",
      "Epoch 134/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1647 - accuracy: 0.9435\n",
      "Epoch 134: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1909 - accuracy: 0.9215 - val_loss: 0.3331 - val_accuracy: 0.8577\n",
      "Epoch 135/1000\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.1992 - accuracy: 0.9178\n",
      "Epoch 135: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2010 - accuracy: 0.9186 - val_loss: 0.3457 - val_accuracy: 0.8692\n",
      "Epoch 136/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2365 - accuracy: 0.8871\n",
      "Epoch 136: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.9215 - val_loss: 0.3435 - val_accuracy: 0.8662\n",
      "Epoch 137/1000\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.1880 - accuracy: 0.9234\n",
      "Epoch 137: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1924 - accuracy: 0.9209 - val_loss: 0.3367 - val_accuracy: 0.8646\n",
      "Epoch 138/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1596 - accuracy: 0.9516\n",
      "Epoch 138: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1787 - accuracy: 0.9280 - val_loss: 0.3809 - val_accuracy: 0.8708\n",
      "Epoch 139/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1891 - accuracy: 0.9233\n",
      "Epoch 139: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1901 - accuracy: 0.9226 - val_loss: 0.3481 - val_accuracy: 0.8646\n",
      "Epoch 140/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2012 - accuracy: 0.9113\n",
      "Epoch 140: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1977 - accuracy: 0.9180 - val_loss: 0.3458 - val_accuracy: 0.8762\n",
      "Epoch 141/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1954 - accuracy: 0.9176\n",
      "Epoch 141: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1954 - accuracy: 0.9176 - val_loss: 0.3928 - val_accuracy: 0.8623\n",
      "Epoch 142/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2139 - accuracy: 0.9194\n",
      "Epoch 142: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1840 - accuracy: 0.9246 - val_loss: 0.3417 - val_accuracy: 0.8631\n",
      "Epoch 143/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1836 - accuracy: 0.9241\n",
      "Epoch 143: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1812 - accuracy: 0.9257 - val_loss: 0.3479 - val_accuracy: 0.8654\n",
      "Epoch 144/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1335 - accuracy: 0.9435\n",
      "Epoch 144: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1769 - accuracy: 0.9265 - val_loss: 0.3788 - val_accuracy: 0.8692\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2288 - accuracy: 0.9032\n",
      "Epoch 145: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.9275 - val_loss: 0.3519 - val_accuracy: 0.8662\n",
      "Epoch 146/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1761 - accuracy: 0.9280\n",
      "Epoch 146: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1759 - accuracy: 0.9265 - val_loss: 0.3465 - val_accuracy: 0.8677\n",
      "Epoch 147/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1177 - accuracy: 0.9597\n",
      "Epoch 147: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.9228 - val_loss: 0.3630 - val_accuracy: 0.8600\n",
      "Epoch 148/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2098 - accuracy: 0.9194\n",
      "Epoch 148: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1748 - accuracy: 0.9290 - val_loss: 0.3541 - val_accuracy: 0.8662\n",
      "Epoch 149/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1830 - accuracy: 0.9236\n",
      "Epoch 149: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.9236 - val_loss: 0.3808 - val_accuracy: 0.8700\n",
      "Epoch 150/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1814 - accuracy: 0.9252\n",
      "Epoch 150: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1800 - accuracy: 0.9255 - val_loss: 0.3754 - val_accuracy: 0.8662\n",
      "Epoch 151/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1792 - accuracy: 0.9272\n",
      "Epoch 151: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1787 - accuracy: 0.9280 - val_loss: 0.3705 - val_accuracy: 0.8646\n",
      "Epoch 152/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1462 - accuracy: 0.9516\n",
      "Epoch 152: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.9302 - val_loss: 0.3714 - val_accuracy: 0.8615\n",
      "Epoch 153/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2021 - accuracy: 0.9032\n",
      "Epoch 153: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.9198 - val_loss: 0.3766 - val_accuracy: 0.8646\n",
      "Epoch 154/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1719 - accuracy: 0.9300\n",
      "Epoch 154: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1719 - accuracy: 0.9300 - val_loss: 0.3712 - val_accuracy: 0.8638\n",
      "Epoch 155/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2267 - accuracy: 0.8952\n",
      "Epoch 155: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1784 - accuracy: 0.9302 - val_loss: 0.4498 - val_accuracy: 0.8462\n",
      "Epoch 156/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2470 - accuracy: 0.8952\n",
      "Epoch 156: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1934 - accuracy: 0.9188 - val_loss: 0.3979 - val_accuracy: 0.8654\n",
      "Epoch 157/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1871 - accuracy: 0.9245\n",
      "Epoch 157: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.9250 - val_loss: 0.3731 - val_accuracy: 0.8677\n",
      "Epoch 158/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1502 - accuracy: 0.9435\n",
      "Epoch 158: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1831 - accuracy: 0.9226 - val_loss: 0.3828 - val_accuracy: 0.8700\n",
      "Epoch 159/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1882 - accuracy: 0.9225\n",
      "Epoch 159: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.9225 - val_loss: 0.3628 - val_accuracy: 0.8654\n",
      "Epoch 160/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.0867 - accuracy: 0.9758\n",
      "Epoch 160: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1712 - accuracy: 0.9298 - val_loss: 0.3616 - val_accuracy: 0.8700\n",
      "Epoch 161/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1781 - accuracy: 0.9435\n",
      "Epoch 161: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1727 - accuracy: 0.9309 - val_loss: 0.3825 - val_accuracy: 0.8654\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 23s - loss: 2.0794 - accuracy: 0.6290\n",
      "Epoch 1: val_accuracy improved from -inf to 0.70462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.7090 - accuracy: 0.6365 - val_loss: 0.5589 - val_accuracy: 0.7046\n",
      "Epoch 2/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.5705 - accuracy: 0.6532\n",
      "Epoch 2: val_accuracy improved from 0.70462 to 0.82692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7906 - val_loss: 0.4141 - val_accuracy: 0.8269\n",
      "Epoch 3/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3790 - accuracy: 0.8387\n",
      "Epoch 3: val_accuracy improved from 0.82692 to 0.83538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3997 - accuracy: 0.8307 - val_loss: 0.3753 - val_accuracy: 0.8354\n",
      "Epoch 4/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3472 - accuracy: 0.8548\n",
      "Epoch 4: val_accuracy improved from 0.83538 to 0.84462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8459 - val_loss: 0.3657 - val_accuracy: 0.8446\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3583 - accuracy: 0.8445\n",
      "Epoch 5: val_accuracy did not improve from 0.84462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3583 - accuracy: 0.8445 - val_loss: 0.4316 - val_accuracy: 0.7954\n",
      "Epoch 6/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4127 - accuracy: 0.7500\n",
      "Epoch 6: val_accuracy improved from 0.84462 to 0.85154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8453 - val_loss: 0.3442 - val_accuracy: 0.8515\n",
      "Epoch 7/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3327 - accuracy: 0.8387\n",
      "Epoch 7: val_accuracy improved from 0.85154 to 0.85462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3564 - accuracy: 0.8443 - val_loss: 0.3385 - val_accuracy: 0.8546\n",
      "Epoch 8/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4144 - accuracy: 0.8468\n",
      "Epoch 8: val_accuracy improved from 0.85462 to 0.85538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3408 - accuracy: 0.8572 - val_loss: 0.3354 - val_accuracy: 0.8554\n",
      "Epoch 9/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3701 - accuracy: 0.8306\n",
      "Epoch 9: val_accuracy improved from 0.85538 to 0.85769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8665 - val_loss: 0.3335 - val_accuracy: 0.8577\n",
      "Epoch 10/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2034 - accuracy: 0.9355\n",
      "Epoch 10: val_accuracy improved from 0.85769 to 0.86077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3208 - accuracy: 0.8686 - val_loss: 0.3336 - val_accuracy: 0.8608\n",
      "Epoch 11/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3148 - accuracy: 0.8871\n",
      "Epoch 11: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3208 - accuracy: 0.8688 - val_loss: 0.3698 - val_accuracy: 0.8408\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3562 - accuracy: 0.8468\n",
      "Epoch 12: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.8682 - val_loss: 0.3284 - val_accuracy: 0.8554\n",
      "Epoch 13/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3409 - accuracy: 0.8710\n",
      "Epoch 13: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8672 - val_loss: 0.3582 - val_accuracy: 0.8354\n",
      "Epoch 14/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3179 - accuracy: 0.8726\n",
      "Epoch 14: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.8736 - val_loss: 0.3273 - val_accuracy: 0.8569\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2928 - accuracy: 0.9113\n",
      "Epoch 15: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.8697 - val_loss: 0.3539 - val_accuracy: 0.8400\n",
      "Epoch 16/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4175 - accuracy: 0.8065\n",
      "Epoch 16: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3194 - accuracy: 0.8615 - val_loss: 0.3655 - val_accuracy: 0.8446\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2712 - accuracy: 0.8952\n",
      "Epoch 17: val_accuracy improved from 0.86077 to 0.86615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3028 - accuracy: 0.8786 - val_loss: 0.3261 - val_accuracy: 0.8662\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2833 - accuracy: 0.9032\n",
      "Epoch 18: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3047 - accuracy: 0.8749 - val_loss: 0.3252 - val_accuracy: 0.8608\n",
      "Epoch 19/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2374 - accuracy: 0.9194\n",
      "Epoch 19: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8744 - val_loss: 0.3303 - val_accuracy: 0.8638\n",
      "Epoch 20/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3065 - accuracy: 0.8468\n",
      "Epoch 20: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2984 - accuracy: 0.8780 - val_loss: 0.3219 - val_accuracy: 0.8569\n",
      "Epoch 21/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2383 - accuracy: 0.9113\n",
      "Epoch 21: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8636 - val_loss: 0.3276 - val_accuracy: 0.8546\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2950 - accuracy: 0.8770\n",
      "Epoch 22: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2950 - accuracy: 0.8770 - val_loss: 0.3369 - val_accuracy: 0.8492\n",
      "Epoch 23/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3886 - accuracy: 0.8306\n",
      "Epoch 23: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2978 - accuracy: 0.8751 - val_loss: 0.3580 - val_accuracy: 0.8362\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2961 - accuracy: 0.8794\n",
      "Epoch 24: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2961 - accuracy: 0.8794 - val_loss: 0.3391 - val_accuracy: 0.8592\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3056 - accuracy: 0.8710\n",
      "Epoch 25: val_accuracy did not improve from 0.86615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3005 - accuracy: 0.8745 - val_loss: 0.3578 - val_accuracy: 0.8477\n",
      "Epoch 26/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2933 - accuracy: 0.8780\n",
      "Epoch 26: val_accuracy improved from 0.86615 to 0.86923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2945 - accuracy: 0.8774 - val_loss: 0.3263 - val_accuracy: 0.8692\n",
      "Epoch 27/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3178 - accuracy: 0.8710\n",
      "Epoch 27: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2889 - accuracy: 0.8799 - val_loss: 0.3198 - val_accuracy: 0.8554\n",
      "Epoch 28/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2930 - accuracy: 0.8745\n",
      "Epoch 28: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2953 - accuracy: 0.8730 - val_loss: 0.3187 - val_accuracy: 0.8631\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2298 - accuracy: 0.9032\n",
      "Epoch 29: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3024 - accuracy: 0.8720 - val_loss: 0.3466 - val_accuracy: 0.8400\n",
      "Epoch 30/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3337 - accuracy: 0.8387\n",
      "Epoch 30: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8490 - val_loss: 0.3123 - val_accuracy: 0.8654\n",
      "Epoch 31/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3130 - accuracy: 0.8629\n",
      "Epoch 31: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2807 - accuracy: 0.8892 - val_loss: 0.3122 - val_accuracy: 0.8677\n",
      "Epoch 32/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2206 - accuracy: 0.9032\n",
      "Epoch 32: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2758 - accuracy: 0.8861 - val_loss: 0.3128 - val_accuracy: 0.8685\n",
      "Epoch 33/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2784 - accuracy: 0.8826\n",
      "Epoch 33: val_accuracy improved from 0.86923 to 0.87231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2779 - accuracy: 0.8834 - val_loss: 0.3052 - val_accuracy: 0.8723\n",
      "Epoch 34/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2996 - accuracy: 0.9194\n",
      "Epoch 34: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2760 - accuracy: 0.8896 - val_loss: 0.3402 - val_accuracy: 0.8569\n",
      "Epoch 35/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2410 - accuracy: 0.8790\n",
      "Epoch 35: val_accuracy improved from 0.87231 to 0.87769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2795 - accuracy: 0.8822 - val_loss: 0.3159 - val_accuracy: 0.8777\n",
      "Epoch 36/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2206 - accuracy: 0.8871\n",
      "Epoch 36: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2685 - accuracy: 0.8890 - val_loss: 0.3038 - val_accuracy: 0.8723\n",
      "Epoch 37/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2469 - accuracy: 0.8952\n",
      "Epoch 37: val_accuracy improved from 0.87769 to 0.88000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2783 - accuracy: 0.8845 - val_loss: 0.3129 - val_accuracy: 0.8800\n",
      "Epoch 38/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3448 - accuracy: 0.8629\n",
      "Epoch 38: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2706 - accuracy: 0.8892 - val_loss: 0.3016 - val_accuracy: 0.8777\n",
      "Epoch 39/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2694 - accuracy: 0.8887\n",
      "Epoch 39: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2673 - accuracy: 0.8903 - val_loss: 0.3497 - val_accuracy: 0.8515\n",
      "Epoch 40/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2820 - accuracy: 0.8818\n",
      "Epoch 40: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2810 - accuracy: 0.8820 - val_loss: 0.3235 - val_accuracy: 0.8692\n",
      "Epoch 41/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2615 - accuracy: 0.8930\n",
      "Epoch 41: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2600 - accuracy: 0.8922 - val_loss: 0.2976 - val_accuracy: 0.8685\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2617 - accuracy: 0.9113\n",
      "Epoch 42: val_accuracy did not improve from 0.88000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2578 - accuracy: 0.8946 - val_loss: 0.2990 - val_accuracy: 0.8685\n",
      "Epoch 43/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2571 - accuracy: 0.8965\n",
      "Epoch 43: val_accuracy improved from 0.88000 to 0.88462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2556 - accuracy: 0.8971 - val_loss: 0.3045 - val_accuracy: 0.8846\n",
      "Epoch 44/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2664 - accuracy: 0.8892\n",
      "Epoch 44: val_accuracy did not improve from 0.88462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.8886 - val_loss: 0.2968 - val_accuracy: 0.8754\n",
      "Epoch 45/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2299 - accuracy: 0.9032\n",
      "Epoch 45: val_accuracy improved from 0.88462 to 0.88538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2541 - accuracy: 0.8953 - val_loss: 0.2961 - val_accuracy: 0.8854\n",
      "Epoch 46/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2270 - accuracy: 0.8952\n",
      "Epoch 46: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.8971 - val_loss: 0.2945 - val_accuracy: 0.8831\n",
      "Epoch 47/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2065 - accuracy: 0.9032\n",
      "Epoch 47: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.8967 - val_loss: 0.3094 - val_accuracy: 0.8769\n",
      "Epoch 48/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2815 - accuracy: 0.8952\n",
      "Epoch 48: val_accuracy did not improve from 0.88538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2534 - accuracy: 0.8999 - val_loss: 0.3264 - val_accuracy: 0.8623\n",
      "Epoch 49/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2498 - accuracy: 0.8952\n",
      "Epoch 49: val_accuracy improved from 0.88538 to 0.88692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2668 - accuracy: 0.8938 - val_loss: 0.2975 - val_accuracy: 0.8869\n",
      "Epoch 50/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2540 - accuracy: 0.8967\n",
      "Epoch 50: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2531 - accuracy: 0.8965 - val_loss: 0.3002 - val_accuracy: 0.8685\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2134 - accuracy: 0.9274\n",
      "Epoch 51: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2590 - accuracy: 0.8932 - val_loss: 0.3006 - val_accuracy: 0.8800\n",
      "Epoch 52/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.2678 - accuracy: 0.8879\n",
      "Epoch 52: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.8867 - val_loss: 0.3197 - val_accuracy: 0.8677\n",
      "Epoch 53/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2313 - accuracy: 0.8871\n",
      "Epoch 53: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2579 - accuracy: 0.8926 - val_loss: 0.3174 - val_accuracy: 0.8608\n",
      "Epoch 54/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3052 - accuracy: 0.8790\n",
      "Epoch 54: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2516 - accuracy: 0.8953 - val_loss: 0.2940 - val_accuracy: 0.8815\n",
      "Epoch 55/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2300 - accuracy: 0.9194\n",
      "Epoch 55: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.8901 - val_loss: 0.3365 - val_accuracy: 0.8523\n",
      "Epoch 56/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2768 - accuracy: 0.8710\n",
      "Epoch 56: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.8969 - val_loss: 0.2955 - val_accuracy: 0.8738\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2494 - accuracy: 0.8963\n",
      "Epoch 57: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.8963 - val_loss: 0.2996 - val_accuracy: 0.8846\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2500 - accuracy: 0.8959\n",
      "Epoch 58: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.8959 - val_loss: 0.3016 - val_accuracy: 0.8862\n",
      "Epoch 59/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2445 - accuracy: 0.9006\n",
      "Epoch 59: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2417 - accuracy: 0.9023 - val_loss: 0.2980 - val_accuracy: 0.8746\n",
      "Epoch 60/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2403 - accuracy: 0.9034\n",
      "Epoch 60: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2401 - accuracy: 0.9030 - val_loss: 0.2990 - val_accuracy: 0.8762\n",
      "Epoch 61/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3323 - accuracy: 0.8306\n",
      "Epoch 61: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2412 - accuracy: 0.9007 - val_loss: 0.3249 - val_accuracy: 0.8608\n",
      "Epoch 62/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2468 - accuracy: 0.8947\n",
      "Epoch 62: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2428 - accuracy: 0.8982 - val_loss: 0.3048 - val_accuracy: 0.8815\n",
      "Epoch 63/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2732 - accuracy: 0.8629\n",
      "Epoch 63: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2398 - accuracy: 0.9013 - val_loss: 0.3181 - val_accuracy: 0.8692\n",
      "Epoch 64/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2444 - accuracy: 0.9016\n",
      "Epoch 64: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2401 - accuracy: 0.9019 - val_loss: 0.2946 - val_accuracy: 0.8854\n",
      "Epoch 65/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2381 - accuracy: 0.9026\n",
      "Epoch 65: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2354 - accuracy: 0.9034 - val_loss: 0.2980 - val_accuracy: 0.8862\n",
      "Epoch 66/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2869 - accuracy: 0.8710\n",
      "Epoch 66: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2561 - accuracy: 0.8890 - val_loss: 0.3023 - val_accuracy: 0.8838\n",
      "Epoch 67/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2349 - accuracy: 0.9055\n",
      "Epoch 67: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2391 - accuracy: 0.9032 - val_loss: 0.2931 - val_accuracy: 0.8754\n",
      "Epoch 68/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2411 - accuracy: 0.9022\n",
      "Epoch 68: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2407 - accuracy: 0.9024 - val_loss: 0.2997 - val_accuracy: 0.8831\n",
      "Epoch 69/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1997 - accuracy: 0.9355\n",
      "Epoch 69: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2390 - accuracy: 0.9015 - val_loss: 0.2967 - val_accuracy: 0.8800\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2167 - accuracy: 0.9274\n",
      "Epoch 70: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2384 - accuracy: 0.9038 - val_loss: 0.3010 - val_accuracy: 0.8808\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1633 - accuracy: 0.9274\n",
      "Epoch 71: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.9015 - val_loss: 0.3125 - val_accuracy: 0.8685\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2598 - accuracy: 0.8952\n",
      "Epoch 72: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2415 - accuracy: 0.8990 - val_loss: 0.3048 - val_accuracy: 0.8754\n",
      "Epoch 73/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2332 - accuracy: 0.9046\n",
      "Epoch 73: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2340 - accuracy: 0.9046 - val_loss: 0.3009 - val_accuracy: 0.8708\n",
      "Epoch 74/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2130 - accuracy: 0.9032\n",
      "Epoch 74: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2324 - accuracy: 0.9038 - val_loss: 0.3185 - val_accuracy: 0.8685\n",
      "Epoch 75/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2267 - accuracy: 0.9075\n",
      "Epoch 75: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2285 - accuracy: 0.9065 - val_loss: 0.3059 - val_accuracy: 0.8792\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2107 - accuracy: 0.9032\n",
      "Epoch 76: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2387 - accuracy: 0.9023 - val_loss: 0.3117 - val_accuracy: 0.8792\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1701 - accuracy: 0.9435\n",
      "Epoch 77: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2336 - accuracy: 0.9078 - val_loss: 0.3010 - val_accuracy: 0.8723\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2718 - accuracy: 0.9032\n",
      "Epoch 78: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2291 - accuracy: 0.9073 - val_loss: 0.3021 - val_accuracy: 0.8777\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2287 - accuracy: 0.9194\n",
      "Epoch 79: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2247 - accuracy: 0.9082 - val_loss: 0.3110 - val_accuracy: 0.8777\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2198 - accuracy: 0.8952\n",
      "Epoch 80: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2236 - accuracy: 0.9113 - val_loss: 0.3011 - val_accuracy: 0.8769\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2604 - accuracy: 0.8952\n",
      "Epoch 81: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2237 - accuracy: 0.9082 - val_loss: 0.3186 - val_accuracy: 0.8723\n",
      "Epoch 82/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2292 - accuracy: 0.9062\n",
      "Epoch 82: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2284 - accuracy: 0.9067 - val_loss: 0.3149 - val_accuracy: 0.8669\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2746 - accuracy: 0.8629\n",
      "Epoch 83: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2271 - accuracy: 0.9061 - val_loss: 0.3073 - val_accuracy: 0.8731\n",
      "Epoch 84/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2210 - accuracy: 0.9123\n",
      "Epoch 84: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.9123 - val_loss: 0.3117 - val_accuracy: 0.8677\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2642 - accuracy: 0.9032\n",
      "Epoch 85: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2188 - accuracy: 0.9136 - val_loss: 0.3065 - val_accuracy: 0.8677\n",
      "Epoch 86/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2420 - accuracy: 0.8995\n",
      "Epoch 86: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2427 - accuracy: 0.8984 - val_loss: 0.3072 - val_accuracy: 0.8785\n",
      "Epoch 87/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2082 - accuracy: 0.9194\n",
      "Epoch 87: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.8972 - val_loss: 0.3048 - val_accuracy: 0.8715\n",
      "Epoch 88/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1826 - accuracy: 0.9435\n",
      "Epoch 88: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2183 - accuracy: 0.9101 - val_loss: 0.3080 - val_accuracy: 0.8777\n",
      "Epoch 89/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2030 - accuracy: 0.9355\n",
      "Epoch 89: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2168 - accuracy: 0.9136 - val_loss: 0.3065 - val_accuracy: 0.8754\n",
      "Epoch 90/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2147 - accuracy: 0.9032\n",
      "Epoch 90: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2213 - accuracy: 0.9076 - val_loss: 0.3054 - val_accuracy: 0.8792\n",
      "Epoch 91/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2259 - accuracy: 0.9089\n",
      "Epoch 91: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9107 - val_loss: 0.3088 - val_accuracy: 0.8731\n",
      "Epoch 92/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2698 - accuracy: 0.8790\n",
      "Epoch 92: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2221 - accuracy: 0.9086 - val_loss: 0.3189 - val_accuracy: 0.8669\n",
      "Epoch 93/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2549 - accuracy: 0.8952\n",
      "Epoch 93: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2197 - accuracy: 0.9065 - val_loss: 0.3250 - val_accuracy: 0.8700\n",
      "Epoch 94/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2212 - accuracy: 0.9105\n",
      "Epoch 94: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2233 - accuracy: 0.9096 - val_loss: 0.3120 - val_accuracy: 0.8785\n",
      "Epoch 95/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2564 - accuracy: 0.9032\n",
      "Epoch 95: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2187 - accuracy: 0.9086 - val_loss: 0.3182 - val_accuracy: 0.8792\n",
      "Epoch 96/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2323 - accuracy: 0.9051\n",
      "Epoch 96: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2307 - accuracy: 0.9053 - val_loss: 0.3101 - val_accuracy: 0.8708\n",
      "Epoch 97/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1859 - accuracy: 0.9274\n",
      "Epoch 97: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2202 - accuracy: 0.9103 - val_loss: 0.3215 - val_accuracy: 0.8723\n",
      "Epoch 98/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1948 - accuracy: 0.9194\n",
      "Epoch 98: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2227 - accuracy: 0.9063 - val_loss: 0.3118 - val_accuracy: 0.8738\n",
      "Epoch 99/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2630 - accuracy: 0.8790\n",
      "Epoch 99: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.9126 - val_loss: 0.3303 - val_accuracy: 0.8692\n",
      "Epoch 100/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2118 - accuracy: 0.9113\n",
      "Epoch 100: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2153 - accuracy: 0.9121 - val_loss: 0.3118 - val_accuracy: 0.8731\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1584 - accuracy: 0.9435\n",
      "Epoch 101: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2188 - accuracy: 0.9101 - val_loss: 0.3283 - val_accuracy: 0.8646\n",
      "Epoch 102/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2085 - accuracy: 0.9170\n",
      "Epoch 102: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2080 - accuracy: 0.9169 - val_loss: 0.3234 - val_accuracy: 0.8738\n",
      "Epoch 103/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2562 - accuracy: 0.8952\n",
      "Epoch 103: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2106 - accuracy: 0.9144 - val_loss: 0.3057 - val_accuracy: 0.8754\n",
      "Epoch 104/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2369 - accuracy: 0.9032\n",
      "Epoch 104: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2097 - accuracy: 0.9153 - val_loss: 0.3187 - val_accuracy: 0.8754\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2458 - accuracy: 0.9032\n",
      "Epoch 105: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2185 - accuracy: 0.9098 - val_loss: 0.3186 - val_accuracy: 0.8731\n",
      "Epoch 106/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1907 - accuracy: 0.9194\n",
      "Epoch 106: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2240 - accuracy: 0.9055 - val_loss: 0.3522 - val_accuracy: 0.8562\n",
      "Epoch 107/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2280 - accuracy: 0.9074\n",
      "Epoch 107: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2279 - accuracy: 0.9069 - val_loss: 0.3063 - val_accuracy: 0.8769\n",
      "Epoch 108/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1419 - accuracy: 0.9355\n",
      "Epoch 108: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2143 - accuracy: 0.9090 - val_loss: 0.3157 - val_accuracy: 0.8715\n",
      "Epoch 109/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2127 - accuracy: 0.9274\n",
      "Epoch 109: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2139 - accuracy: 0.9119 - val_loss: 0.3096 - val_accuracy: 0.8746\n",
      "Epoch 110/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1708 - accuracy: 0.9194\n",
      "Epoch 110: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.9061 - val_loss: 0.3846 - val_accuracy: 0.8515\n",
      "Epoch 111/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2154 - accuracy: 0.9107\n",
      "Epoch 111: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2153 - accuracy: 0.9107 - val_loss: 0.3423 - val_accuracy: 0.8677\n",
      "Epoch 112/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2057 - accuracy: 0.9137\n",
      "Epoch 112: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2063 - accuracy: 0.9126 - val_loss: 0.3280 - val_accuracy: 0.8731\n",
      "Epoch 113/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2015 - accuracy: 0.9178\n",
      "Epoch 113: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2015 - accuracy: 0.9178 - val_loss: 0.3164 - val_accuracy: 0.8723\n",
      "Epoch 114/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1750 - accuracy: 0.9194\n",
      "Epoch 114: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1960 - accuracy: 0.9196 - val_loss: 0.3185 - val_accuracy: 0.8715\n",
      "Epoch 115/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1895 - accuracy: 0.9274\n",
      "Epoch 115: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9178 - val_loss: 0.3223 - val_accuracy: 0.8715\n",
      "Epoch 116/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1992 - accuracy: 0.9170\n",
      "Epoch 116: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.9184 - val_loss: 0.3471 - val_accuracy: 0.8623\n",
      "Epoch 117/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1632 - accuracy: 0.9355\n",
      "Epoch 117: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2095 - accuracy: 0.9119 - val_loss: 0.3386 - val_accuracy: 0.8654\n",
      "Epoch 118/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.2034 - accuracy: 0.9142\n",
      "Epoch 118: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2069 - accuracy: 0.9119 - val_loss: 0.3325 - val_accuracy: 0.8638\n",
      "Epoch 119/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1947 - accuracy: 0.9274\n",
      "Epoch 119: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2061 - accuracy: 0.9201 - val_loss: 0.3382 - val_accuracy: 0.8685\n",
      "Epoch 120/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1625 - accuracy: 0.9435\n",
      "Epoch 120: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1996 - accuracy: 0.9165 - val_loss: 0.3321 - val_accuracy: 0.8754\n",
      "Epoch 121/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1156 - accuracy: 0.9677\n",
      "Epoch 121: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1915 - accuracy: 0.9213 - val_loss: 0.3259 - val_accuracy: 0.8785\n",
      "Epoch 122/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1139 - accuracy: 0.9677\n",
      "Epoch 122: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1939 - accuracy: 0.9192 - val_loss: 0.3452 - val_accuracy: 0.8677\n",
      "Epoch 123/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2293 - accuracy: 0.9194\n",
      "Epoch 123: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2059 - accuracy: 0.9126 - val_loss: 0.3236 - val_accuracy: 0.8715\n",
      "Epoch 124/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.1967 - accuracy: 0.9194\n",
      "Epoch 124: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1958 - accuracy: 0.9188 - val_loss: 0.3338 - val_accuracy: 0.8731\n",
      "Epoch 125/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1942 - accuracy: 0.9194\n",
      "Epoch 125: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2004 - accuracy: 0.9188 - val_loss: 0.3286 - val_accuracy: 0.8723\n",
      "Epoch 126/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.1952 - accuracy: 0.9186\n",
      "Epoch 126: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.9198 - val_loss: 0.3240 - val_accuracy: 0.8746\n",
      "Epoch 127/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2002 - accuracy: 0.9137\n",
      "Epoch 127: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1992 - accuracy: 0.9151 - val_loss: 0.3311 - val_accuracy: 0.8731\n",
      "Epoch 128/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3086 - accuracy: 0.8871\n",
      "Epoch 128: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1932 - accuracy: 0.9207 - val_loss: 0.3410 - val_accuracy: 0.8708\n",
      "Epoch 129/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1909 - accuracy: 0.9435\n",
      "Epoch 129: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2030 - accuracy: 0.9175 - val_loss: 0.3442 - val_accuracy: 0.8662\n",
      "Epoch 130/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3337 - accuracy: 0.8468\n",
      "Epoch 130: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2009 - accuracy: 0.9196 - val_loss: 0.3358 - val_accuracy: 0.8677\n",
      "Epoch 131/1000\n",
      "30/42 [====================>.........] - ETA: 0s - loss: 0.1859 - accuracy: 0.9239\n",
      "Epoch 131: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1853 - accuracy: 0.9236 - val_loss: 0.3484 - val_accuracy: 0.8669\n",
      "Epoch 132/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2605 - accuracy: 0.8790\n",
      "Epoch 132: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1893 - accuracy: 0.9267 - val_loss: 0.3324 - val_accuracy: 0.8723\n",
      "Epoch 133/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1860 - accuracy: 0.9275\n",
      "Epoch 133: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.9275 - val_loss: 0.3507 - val_accuracy: 0.8662\n",
      "Epoch 134/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1667 - accuracy: 0.9032\n",
      "Epoch 134: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1950 - accuracy: 0.9196 - val_loss: 0.3455 - val_accuracy: 0.8692\n",
      "Epoch 135/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1367 - accuracy: 0.9355\n",
      "Epoch 135: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.9230 - val_loss: 0.3330 - val_accuracy: 0.8646\n",
      "Epoch 136/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1424 - accuracy: 0.9435\n",
      "Epoch 136: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.9269 - val_loss: 0.3361 - val_accuracy: 0.8662\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1433 - accuracy: 0.9355\n",
      "Epoch 137: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1861 - accuracy: 0.9234 - val_loss: 0.3407 - val_accuracy: 0.8746\n",
      "Epoch 138/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1953 - accuracy: 0.9138\n",
      "Epoch 138: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1928 - accuracy: 0.9151 - val_loss: 0.3375 - val_accuracy: 0.8700\n",
      "Epoch 139/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1733 - accuracy: 0.9435\n",
      "Epoch 139: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1738 - accuracy: 0.9282 - val_loss: 0.3608 - val_accuracy: 0.8754\n",
      "Epoch 140/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1463 - accuracy: 0.9516\n",
      "Epoch 140: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1902 - accuracy: 0.9234 - val_loss: 0.3475 - val_accuracy: 0.8654\n",
      "Epoch 141/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1241 - accuracy: 0.9516\n",
      "Epoch 141: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1957 - accuracy: 0.9200 - val_loss: 0.3531 - val_accuracy: 0.8623\n",
      "Epoch 142/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1885 - accuracy: 0.9203\n",
      "Epoch 142: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1867 - accuracy: 0.9215 - val_loss: 0.3424 - val_accuracy: 0.8654\n",
      "Epoch 143/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1601 - accuracy: 0.9274\n",
      "Epoch 143: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1831 - accuracy: 0.9246 - val_loss: 0.3390 - val_accuracy: 0.8677\n",
      "Epoch 144/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1400 - accuracy: 0.9355\n",
      "Epoch 144: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1823 - accuracy: 0.9250 - val_loss: 0.3570 - val_accuracy: 0.8654\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2238 - accuracy: 0.8952\n",
      "Epoch 145: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.9248 - val_loss: 0.3613 - val_accuracy: 0.8615\n",
      "Epoch 146/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1903 - accuracy: 0.9194\n",
      "Epoch 146: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1801 - accuracy: 0.9257 - val_loss: 0.3472 - val_accuracy: 0.8662\n",
      "Epoch 147/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1622 - accuracy: 0.9194\n",
      "Epoch 147: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1716 - accuracy: 0.9292 - val_loss: 0.3474 - val_accuracy: 0.8677\n",
      "Epoch 148/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1936 - accuracy: 0.9032\n",
      "Epoch 148: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.9255 - val_loss: 0.3448 - val_accuracy: 0.8723\n",
      "Epoch 149/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1727 - accuracy: 0.9194\n",
      "Epoch 149: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.9236 - val_loss: 0.3545 - val_accuracy: 0.8662\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1706 - accuracy: 0.9274\n",
      "Epoch 150: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1786 - accuracy: 0.9265 - val_loss: 0.3770 - val_accuracy: 0.8585\n",
      "Epoch 151/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1701 - accuracy: 0.9329\n",
      "Epoch 151: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1720 - accuracy: 0.9315 - val_loss: 0.3730 - val_accuracy: 0.8715\n",
      "Epoch 152/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1501 - accuracy: 0.9516\n",
      "Epoch 152: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1769 - accuracy: 0.9271 - val_loss: 0.4040 - val_accuracy: 0.8669\n",
      "Epoch 153/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1741 - accuracy: 0.9194\n",
      "Epoch 153: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1848 - accuracy: 0.9261 - val_loss: 0.3630 - val_accuracy: 0.8731\n",
      "Epoch 154/1000\n",
      "28/42 [===================>..........] - ETA: 0s - loss: 0.1743 - accuracy: 0.9323\n",
      "Epoch 154: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1809 - accuracy: 0.9277 - val_loss: 0.3710 - val_accuracy: 0.8577\n",
      "Epoch 155/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1854 - accuracy: 0.9435\n",
      "Epoch 155: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.9248 - val_loss: 0.3593 - val_accuracy: 0.8662\n",
      "Epoch 156/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2382 - accuracy: 0.8952\n",
      "Epoch 156: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1688 - accuracy: 0.9303 - val_loss: 0.3633 - val_accuracy: 0.8700\n",
      "Epoch 157/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1434 - accuracy: 0.9516\n",
      "Epoch 157: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1620 - accuracy: 0.9346 - val_loss: 0.3843 - val_accuracy: 0.8715\n",
      "Epoch 158/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1669 - accuracy: 0.9296\n",
      "Epoch 158: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1666 - accuracy: 0.9292 - val_loss: 0.3969 - val_accuracy: 0.8692\n",
      "Epoch 159/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2863 - accuracy: 0.8790\n",
      "Epoch 159: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1633 - accuracy: 0.9350 - val_loss: 0.3815 - val_accuracy: 0.8708\n",
      "Epoch 160/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2541 - accuracy: 0.9113\n",
      "Epoch 160: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.9288 - val_loss: 0.3942 - val_accuracy: 0.8569\n",
      "Epoch 161/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1981 - accuracy: 0.9194\n",
      "Epoch 161: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1699 - accuracy: 0.9305 - val_loss: 0.3754 - val_accuracy: 0.8700\n",
      "Epoch 162/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1204 - accuracy: 0.9597\n",
      "Epoch 162: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1660 - accuracy: 0.9334 - val_loss: 0.4023 - val_accuracy: 0.8608\n",
      "Epoch 163/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1343 - accuracy: 0.9435\n",
      "Epoch 163: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1774 - accuracy: 0.9282 - val_loss: 0.3699 - val_accuracy: 0.8685\n",
      "Epoch 164/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1582 - accuracy: 0.9274\n",
      "Epoch 164: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1603 - accuracy: 0.9346 - val_loss: 0.4050 - val_accuracy: 0.8615\n",
      "Epoch 165/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1485 - accuracy: 0.9355\n",
      "Epoch 165: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1663 - accuracy: 0.9305 - val_loss: 0.3726 - val_accuracy: 0.8623\n",
      "Epoch 166/1000\n",
      "30/42 [====================>.........] - ETA: 0s - loss: 0.1642 - accuracy: 0.9344\n",
      "Epoch 166: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1649 - accuracy: 0.9344 - val_loss: 0.3851 - val_accuracy: 0.8646\n",
      "Epoch 167/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1137 - accuracy: 0.9677\n",
      "Epoch 167: val_accuracy did not improve from 0.88692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1616 - accuracy: 0.9357 - val_loss: 0.4071 - val_accuracy: 0.8569\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 33s - loss: 1.6722 - accuracy: 0.5565\n",
      "Epoch 1: val_accuracy improved from -inf to 0.69385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.7077 - accuracy: 0.6098 - val_loss: 0.5430 - val_accuracy: 0.6938\n",
      "Epoch 2/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.4961 - accuracy: 0.7696\n",
      "Epoch 2: val_accuracy improved from 0.69385 to 0.82000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4934 - accuracy: 0.7733 - val_loss: 0.4370 - val_accuracy: 0.8200\n",
      "Epoch 3/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4370 - accuracy: 0.7984\n",
      "Epoch 3: val_accuracy improved from 0.82000 to 0.84615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4025 - accuracy: 0.8382 - val_loss: 0.3795 - val_accuracy: 0.8462\n",
      "Epoch 4/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.3708 - accuracy: 0.8410\n",
      "Epoch 4: val_accuracy did not improve from 0.84615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8411 - val_loss: 0.3619 - val_accuracy: 0.8438\n",
      "Epoch 5/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.3495 - accuracy: 0.8563\n",
      "Epoch 5: val_accuracy improved from 0.84615 to 0.85462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3483 - accuracy: 0.8578 - val_loss: 0.3445 - val_accuracy: 0.8546\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3533 - accuracy: 0.8493\n",
      "Epoch 6: val_accuracy did not improve from 0.85462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8493 - val_loss: 0.4420 - val_accuracy: 0.7931\n",
      "Epoch 7/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.3629 - accuracy: 0.8396\n",
      "Epoch 7: val_accuracy did not improve from 0.85462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8418 - val_loss: 0.3456 - val_accuracy: 0.8546\n",
      "Epoch 8/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.3231 - accuracy: 0.8706\n",
      "Epoch 8: val_accuracy improved from 0.85462 to 0.85769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3275 - accuracy: 0.8686 - val_loss: 0.3346 - val_accuracy: 0.8577\n",
      "Epoch 9/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.3222 - accuracy: 0.8651\n",
      "Epoch 9: val_accuracy did not improve from 0.85769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8638 - val_loss: 0.3373 - val_accuracy: 0.8531\n",
      "Epoch 10/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.3184 - accuracy: 0.8629\n",
      "Epoch 10: val_accuracy improved from 0.85769 to 0.85846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3256 - accuracy: 0.8601 - val_loss: 0.3469 - val_accuracy: 0.8585\n",
      "Epoch 11/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.3187 - accuracy: 0.8673\n",
      "Epoch 11: val_accuracy did not improve from 0.85846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8697 - val_loss: 0.3377 - val_accuracy: 0.8577\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2249 - accuracy: 0.9032\n",
      "Epoch 12: val_accuracy did not improve from 0.85846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.8678 - val_loss: 0.3408 - val_accuracy: 0.8585\n",
      "Epoch 13/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.3185 - accuracy: 0.8615\n",
      "Epoch 13: val_accuracy did not improve from 0.85846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8613 - val_loss: 0.3430 - val_accuracy: 0.8577\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3123 - accuracy: 0.8688\n",
      "Epoch 14: val_accuracy improved from 0.85846 to 0.86769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3123 - accuracy: 0.8688 - val_loss: 0.3236 - val_accuracy: 0.8677\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1990 - accuracy: 0.9274\n",
      "Epoch 15: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3018 - accuracy: 0.8724 - val_loss: 0.3237 - val_accuracy: 0.8615\n",
      "Epoch 16/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.3082 - accuracy: 0.8684\n",
      "Epoch 16: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8678 - val_loss: 0.3338 - val_accuracy: 0.8477\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2850 - accuracy: 0.8952\n",
      "Epoch 17: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3013 - accuracy: 0.8720 - val_loss: 0.3246 - val_accuracy: 0.8562\n",
      "Epoch 18/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.3053 - accuracy: 0.8712\n",
      "Epoch 18: val_accuracy did not improve from 0.86769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8713 - val_loss: 0.3198 - val_accuracy: 0.8592\n",
      "Epoch 19/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.3008 - accuracy: 0.8744\n",
      "Epoch 19: val_accuracy improved from 0.86769 to 0.86923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3002 - accuracy: 0.8742 - val_loss: 0.3189 - val_accuracy: 0.8692\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3032 - accuracy: 0.8736\n",
      "Epoch 20: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.8736 - val_loss: 0.3656 - val_accuracy: 0.8462\n",
      "Epoch 21/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3390 - accuracy: 0.8629\n",
      "Epoch 21: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8643 - val_loss: 0.3346 - val_accuracy: 0.8646\n",
      "Epoch 22/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2862 - accuracy: 0.8790\n",
      "Epoch 22: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2879 - accuracy: 0.8780 - val_loss: 0.3161 - val_accuracy: 0.8623\n",
      "Epoch 23/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2911 - accuracy: 0.8795\n",
      "Epoch 23: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2940 - accuracy: 0.8788 - val_loss: 0.3204 - val_accuracy: 0.8638\n",
      "Epoch 24/1000\n",
      "30/42 [====================>.........] - ETA: 0s - loss: 0.3044 - accuracy: 0.8715\n",
      "Epoch 24: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2953 - accuracy: 0.8770 - val_loss: 0.3114 - val_accuracy: 0.8654\n",
      "Epoch 25/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2817 - accuracy: 0.8847\n",
      "Epoch 25: val_accuracy improved from 0.86923 to 0.87231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2811 - accuracy: 0.8849 - val_loss: 0.3090 - val_accuracy: 0.8723\n",
      "Epoch 26/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2064 - accuracy: 0.9435\n",
      "Epoch 26: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2845 - accuracy: 0.8805 - val_loss: 0.3555 - val_accuracy: 0.8477\n",
      "Epoch 27/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2381 - accuracy: 0.9032\n",
      "Epoch 27: val_accuracy improved from 0.87231 to 0.87769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2767 - accuracy: 0.8867 - val_loss: 0.3077 - val_accuracy: 0.8777\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2930 - accuracy: 0.8790\n",
      "Epoch 28: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2767 - accuracy: 0.8867 - val_loss: 0.3102 - val_accuracy: 0.8685\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2735 - accuracy: 0.8952\n",
      "Epoch 29: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2817 - accuracy: 0.8819 - val_loss: 0.2985 - val_accuracy: 0.8723\n",
      "Epoch 30/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2716 - accuracy: 0.8864\n",
      "Epoch 30: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2721 - accuracy: 0.8855 - val_loss: 0.3080 - val_accuracy: 0.8731\n",
      "Epoch 31/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2786 - accuracy: 0.8843\n",
      "Epoch 31: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2787 - accuracy: 0.8842 - val_loss: 0.3391 - val_accuracy: 0.8523\n",
      "Epoch 32/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2382 - accuracy: 0.8952\n",
      "Epoch 32: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2825 - accuracy: 0.8815 - val_loss: 0.3101 - val_accuracy: 0.8692\n",
      "Epoch 33/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2786 - accuracy: 0.8843\n",
      "Epoch 33: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2738 - accuracy: 0.8847 - val_loss: 0.3009 - val_accuracy: 0.8738\n",
      "Epoch 34/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2521 - accuracy: 0.9113\n",
      "Epoch 34: val_accuracy improved from 0.87769 to 0.87846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2663 - accuracy: 0.8876 - val_loss: 0.3042 - val_accuracy: 0.8785\n",
      "Epoch 35/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2794 - accuracy: 0.8853\n",
      "Epoch 35: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2724 - accuracy: 0.8886 - val_loss: 0.3152 - val_accuracy: 0.8638\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2601 - accuracy: 0.8942\n",
      "Epoch 36: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2601 - accuracy: 0.8942 - val_loss: 0.2976 - val_accuracy: 0.8692\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2539 - accuracy: 0.8963\n",
      "Epoch 37: val_accuracy improved from 0.87846 to 0.88154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2539 - accuracy: 0.8963 - val_loss: 0.2928 - val_accuracy: 0.8815\n",
      "Epoch 38/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3151 - accuracy: 0.8548\n",
      "Epoch 38: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2594 - accuracy: 0.8919 - val_loss: 0.3154 - val_accuracy: 0.8638\n",
      "Epoch 39/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2561 - accuracy: 0.8964\n",
      "Epoch 39: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2564 - accuracy: 0.8963 - val_loss: 0.3073 - val_accuracy: 0.8685\n",
      "Epoch 40/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2723 - accuracy: 0.8629\n",
      "Epoch 40: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2591 - accuracy: 0.8921 - val_loss: 0.3000 - val_accuracy: 0.8738\n",
      "Epoch 41/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2591 - accuracy: 0.8963\n",
      "Epoch 41: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2560 - accuracy: 0.8974 - val_loss: 0.3161 - val_accuracy: 0.8631\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2504 - accuracy: 0.8871\n",
      "Epoch 42: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2628 - accuracy: 0.8892 - val_loss: 0.2973 - val_accuracy: 0.8669\n",
      "Epoch 43/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2511 - accuracy: 0.8969\n",
      "Epoch 43: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2534 - accuracy: 0.8959 - val_loss: 0.3001 - val_accuracy: 0.8685\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2827 - accuracy: 0.8710\n",
      "Epoch 44: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.8988 - val_loss: 0.2959 - val_accuracy: 0.8785\n",
      "Epoch 45/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2789 - accuracy: 0.8790\n",
      "Epoch 45: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.8951 - val_loss: 0.3157 - val_accuracy: 0.8677\n",
      "Epoch 46/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2132 - accuracy: 0.9032\n",
      "Epoch 46: val_accuracy improved from 0.88154 to 0.88231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.8959 - val_loss: 0.2994 - val_accuracy: 0.8823\n",
      "Epoch 47/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2493 - accuracy: 0.8871\n",
      "Epoch 47: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2485 - accuracy: 0.8982 - val_loss: 0.2946 - val_accuracy: 0.8762\n",
      "Epoch 48/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3350 - accuracy: 0.8790\n",
      "Epoch 48: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.8999 - val_loss: 0.3083 - val_accuracy: 0.8815\n",
      "Epoch 49/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2858 - accuracy: 0.8952\n",
      "Epoch 49: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.8976 - val_loss: 0.3019 - val_accuracy: 0.8785\n",
      "Epoch 50/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2546 - accuracy: 0.8871\n",
      "Epoch 50: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8994 - val_loss: 0.3456 - val_accuracy: 0.8592\n",
      "Epoch 51/1000\n",
      "26/42 [=================>............] - ETA: 0s - loss: 0.2565 - accuracy: 0.8930\n",
      "Epoch 51: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8996 - val_loss: 0.2996 - val_accuracy: 0.8785\n",
      "Epoch 52/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2436 - accuracy: 0.9018\n",
      "Epoch 52: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.9013 - val_loss: 0.2989 - val_accuracy: 0.8738\n",
      "Epoch 53/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2429 - accuracy: 0.9021\n",
      "Epoch 53: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2420 - accuracy: 0.9032 - val_loss: 0.2939 - val_accuracy: 0.8738\n",
      "Epoch 54/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2421 - accuracy: 0.9007\n",
      "Epoch 54: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2383 - accuracy: 0.9034 - val_loss: 0.2966 - val_accuracy: 0.8731\n",
      "Epoch 55/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2351 - accuracy: 0.9052\n",
      "Epoch 55: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2343 - accuracy: 0.9059 - val_loss: 0.2962 - val_accuracy: 0.8731\n",
      "Epoch 56/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3767 - accuracy: 0.8468\n",
      "Epoch 56: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2403 - accuracy: 0.9028 - val_loss: 0.3085 - val_accuracy: 0.8700\n",
      "Epoch 57/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2529 - accuracy: 0.8945\n",
      "Epoch 57: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.8938 - val_loss: 0.3071 - val_accuracy: 0.8708\n",
      "Epoch 58/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1960 - accuracy: 0.9355\n",
      "Epoch 58: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2529 - accuracy: 0.8934 - val_loss: 0.3046 - val_accuracy: 0.8700\n",
      "Epoch 59/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2376 - accuracy: 0.9066\n",
      "Epoch 59: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2394 - accuracy: 0.9044 - val_loss: 0.3334 - val_accuracy: 0.8638\n",
      "Epoch 60/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2514 - accuracy: 0.8968\n",
      "Epoch 60: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.8961 - val_loss: 0.3044 - val_accuracy: 0.8738\n",
      "Epoch 61/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2360 - accuracy: 0.9038\n",
      "Epoch 61: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2363 - accuracy: 0.9034 - val_loss: 0.3146 - val_accuracy: 0.8662\n",
      "Epoch 62/1000\n",
      "29/42 [===================>..........] - ETA: 0s - loss: 0.2134 - accuracy: 0.9105\n",
      "Epoch 62: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2384 - accuracy: 0.9007 - val_loss: 0.2998 - val_accuracy: 0.8754\n",
      "Epoch 63/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.2323 - accuracy: 0.9061\n",
      "Epoch 63: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2321 - accuracy: 0.9065 - val_loss: 0.3033 - val_accuracy: 0.8777\n",
      "Epoch 64/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2326 - accuracy: 0.9041\n",
      "Epoch 64: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2354 - accuracy: 0.9021 - val_loss: 0.3400 - val_accuracy: 0.8562\n",
      "Epoch 65/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2988 - accuracy: 0.8629\n",
      "Epoch 65: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2352 - accuracy: 0.9040 - val_loss: 0.3090 - val_accuracy: 0.8708\n",
      "Epoch 66/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2243 - accuracy: 0.9080\n",
      "Epoch 66: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2342 - accuracy: 0.9030 - val_loss: 0.2943 - val_accuracy: 0.8746\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2285 - accuracy: 0.9073\n",
      "Epoch 67: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2285 - accuracy: 0.9073 - val_loss: 0.3015 - val_accuracy: 0.8738\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1884 - accuracy: 0.9113\n",
      "Epoch 68: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.9061 - val_loss: 0.3089 - val_accuracy: 0.8692\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2260 - accuracy: 0.9099\n",
      "Epoch 69: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.9099 - val_loss: 0.3099 - val_accuracy: 0.8769\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1762 - accuracy: 0.9597\n",
      "Epoch 70: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2282 - accuracy: 0.9082 - val_loss: 0.3019 - val_accuracy: 0.8731\n",
      "Epoch 71/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2301 - accuracy: 0.9063\n",
      "Epoch 71: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2280 - accuracy: 0.9076 - val_loss: 0.3163 - val_accuracy: 0.8715\n",
      "Epoch 72/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2290 - accuracy: 0.9045\n",
      "Epoch 72: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2317 - accuracy: 0.9023 - val_loss: 0.3626 - val_accuracy: 0.8485\n",
      "Epoch 73/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2447 - accuracy: 0.9018\n",
      "Epoch 73: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.9011 - val_loss: 0.3240 - val_accuracy: 0.8685\n",
      "Epoch 74/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2236 - accuracy: 0.9058\n",
      "Epoch 74: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2261 - accuracy: 0.9053 - val_loss: 0.2980 - val_accuracy: 0.8731\n",
      "Epoch 75/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2187 - accuracy: 0.9136\n",
      "Epoch 75: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2187 - accuracy: 0.9136 - val_loss: 0.3042 - val_accuracy: 0.8731\n",
      "Epoch 76/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2108 - accuracy: 0.9032\n",
      "Epoch 76: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2163 - accuracy: 0.9151 - val_loss: 0.3064 - val_accuracy: 0.8723\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1796 - accuracy: 0.9274\n",
      "Epoch 77: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2187 - accuracy: 0.9124 - val_loss: 0.3086 - val_accuracy: 0.8723\n",
      "Epoch 78/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2167 - accuracy: 0.9157\n",
      "Epoch 78: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2167 - accuracy: 0.9157 - val_loss: 0.3111 - val_accuracy: 0.8762\n",
      "Epoch 79/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2248 - accuracy: 0.9065\n",
      "Epoch 79: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2281 - accuracy: 0.9034 - val_loss: 0.3190 - val_accuracy: 0.8685\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1937 - accuracy: 0.9355\n",
      "Epoch 80: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2291 - accuracy: 0.9044 - val_loss: 0.3110 - val_accuracy: 0.8708\n",
      "Epoch 81/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2142 - accuracy: 0.9163\n",
      "Epoch 81: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2138 - accuracy: 0.9167 - val_loss: 0.3304 - val_accuracy: 0.8608\n",
      "Epoch 82/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2278 - accuracy: 0.9048\n",
      "Epoch 82: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2279 - accuracy: 0.9048 - val_loss: 0.3076 - val_accuracy: 0.8746\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2443 - accuracy: 0.8952\n",
      "Epoch 83: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2082 - accuracy: 0.9182 - val_loss: 0.3065 - val_accuracy: 0.8769\n",
      "Epoch 84/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1838 - accuracy: 0.9435\n",
      "Epoch 84: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2155 - accuracy: 0.9161 - val_loss: 0.3091 - val_accuracy: 0.8677\n",
      "Epoch 85/1000\n",
      "29/42 [===================>..........] - ETA: 0s - loss: 0.2294 - accuracy: 0.9032\n",
      "Epoch 85: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2205 - accuracy: 0.9067 - val_loss: 0.3086 - val_accuracy: 0.8669\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2539 - accuracy: 0.9032\n",
      "Epoch 86: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2082 - accuracy: 0.9126 - val_loss: 0.3255 - val_accuracy: 0.8708\n",
      "Epoch 87/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2116 - accuracy: 0.9129\n",
      "Epoch 87: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2120 - accuracy: 0.9117 - val_loss: 0.3069 - val_accuracy: 0.8808\n",
      "Epoch 88/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2045 - accuracy: 0.9196\n",
      "Epoch 88: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2051 - accuracy: 0.9198 - val_loss: 0.3044 - val_accuracy: 0.8762\n",
      "Epoch 89/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2055 - accuracy: 0.9151\n",
      "Epoch 89: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2139 - accuracy: 0.9119 - val_loss: 0.3072 - val_accuracy: 0.8669\n",
      "Epoch 90/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1580 - accuracy: 0.9435\n",
      "Epoch 90: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2119 - accuracy: 0.9132 - val_loss: 0.3146 - val_accuracy: 0.8723\n",
      "Epoch 91/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2079 - accuracy: 0.9171\n",
      "Epoch 91: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2079 - accuracy: 0.9171 - val_loss: 0.3081 - val_accuracy: 0.8738\n",
      "Epoch 92/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1803 - accuracy: 0.9355\n",
      "Epoch 92: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2218 - accuracy: 0.9074 - val_loss: 0.3164 - val_accuracy: 0.8662\n",
      "Epoch 93/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2031 - accuracy: 0.9169\n",
      "Epoch 93: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2031 - accuracy: 0.9169 - val_loss: 0.3209 - val_accuracy: 0.8754\n",
      "Epoch 94/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2361 - accuracy: 0.9194\n",
      "Epoch 94: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2031 - accuracy: 0.9182 - val_loss: 0.3288 - val_accuracy: 0.8631\n",
      "Epoch 95/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2021 - accuracy: 0.9201\n",
      "Epoch 95: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2015 - accuracy: 0.9200 - val_loss: 0.3193 - val_accuracy: 0.8731\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2800 - accuracy: 0.8871\n",
      "Epoch 96: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2015 - accuracy: 0.9217 - val_loss: 0.3177 - val_accuracy: 0.8731\n",
      "Epoch 97/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1964 - accuracy: 0.9224\n",
      "Epoch 97: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1970 - accuracy: 0.9223 - val_loss: 0.3159 - val_accuracy: 0.8677\n",
      "Epoch 98/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1397 - accuracy: 0.9194\n",
      "Epoch 98: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2022 - accuracy: 0.9184 - val_loss: 0.3088 - val_accuracy: 0.8700\n",
      "Epoch 99/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.2134 - accuracy: 0.9123\n",
      "Epoch 99: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2048 - accuracy: 0.9165 - val_loss: 0.3182 - val_accuracy: 0.8792\n",
      "Epoch 100/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2723 - accuracy: 0.8871\n",
      "Epoch 100: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9240 - val_loss: 0.3135 - val_accuracy: 0.8708\n",
      "Epoch 101/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1926 - accuracy: 0.9254\n",
      "Epoch 101: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1932 - accuracy: 0.9242 - val_loss: 0.3310 - val_accuracy: 0.8700\n",
      "Epoch 102/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1370 - accuracy: 0.9435\n",
      "Epoch 102: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2034 - accuracy: 0.9205 - val_loss: 0.3202 - val_accuracy: 0.8731\n",
      "Epoch 103/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2106 - accuracy: 0.9148\n",
      "Epoch 103: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2106 - accuracy: 0.9148 - val_loss: 0.3729 - val_accuracy: 0.8500\n",
      "Epoch 104/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2007 - accuracy: 0.9198\n",
      "Epoch 104: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2007 - accuracy: 0.9198 - val_loss: 0.3177 - val_accuracy: 0.8777\n",
      "Epoch 105/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2133 - accuracy: 0.9097\n",
      "Epoch 105: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2120 - accuracy: 0.9107 - val_loss: 0.3229 - val_accuracy: 0.8662\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1938 - accuracy: 0.9236\n",
      "Epoch 106: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1938 - accuracy: 0.9236 - val_loss: 0.3207 - val_accuracy: 0.8746\n",
      "Epoch 107/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2051 - accuracy: 0.9192\n",
      "Epoch 107: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2040 - accuracy: 0.9192 - val_loss: 0.3542 - val_accuracy: 0.8577\n",
      "Epoch 108/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1847 - accuracy: 0.9274\n",
      "Epoch 108: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1965 - accuracy: 0.9226 - val_loss: 0.3283 - val_accuracy: 0.8708\n",
      "Epoch 109/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1862 - accuracy: 0.9266\n",
      "Epoch 109: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1865 - accuracy: 0.9265 - val_loss: 0.3462 - val_accuracy: 0.8669\n",
      "Epoch 110/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1903 - accuracy: 0.9113\n",
      "Epoch 110: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2008 - accuracy: 0.9198 - val_loss: 0.3317 - val_accuracy: 0.8777\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1519 - accuracy: 0.9435\n",
      "Epoch 111: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1944 - accuracy: 0.9246 - val_loss: 0.3306 - val_accuracy: 0.8738\n",
      "Epoch 112/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1902 - accuracy: 0.9276\n",
      "Epoch 112: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1898 - accuracy: 0.9265 - val_loss: 0.3469 - val_accuracy: 0.8723\n",
      "Epoch 113/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1906 - accuracy: 0.9249\n",
      "Epoch 113: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1893 - accuracy: 0.9251 - val_loss: 0.3183 - val_accuracy: 0.8731\n",
      "Epoch 114/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1896 - accuracy: 0.9266\n",
      "Epoch 114: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1888 - accuracy: 0.9267 - val_loss: 0.3307 - val_accuracy: 0.8708\n",
      "Epoch 115/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1860 - accuracy: 0.9246\n",
      "Epoch 115: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.9226 - val_loss: 0.3331 - val_accuracy: 0.8723\n",
      "Epoch 116/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1783 - accuracy: 0.9317\n",
      "Epoch 116: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.9319 - val_loss: 0.3349 - val_accuracy: 0.8731\n",
      "Epoch 117/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1924 - accuracy: 0.9229\n",
      "Epoch 117: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1936 - accuracy: 0.9225 - val_loss: 0.3288 - val_accuracy: 0.8762\n",
      "Epoch 118/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1896 - accuracy: 0.9113\n",
      "Epoch 118: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1770 - accuracy: 0.9334 - val_loss: 0.3397 - val_accuracy: 0.8677\n",
      "Epoch 119/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.1820 - accuracy: 0.9281\n",
      "Epoch 119: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1818 - accuracy: 0.9275 - val_loss: 0.3443 - val_accuracy: 0.8708\n",
      "Epoch 120/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1602 - accuracy: 0.9194\n",
      "Epoch 120: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1843 - accuracy: 0.9257 - val_loss: 0.3406 - val_accuracy: 0.8654\n",
      "Epoch 121/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.1901 - accuracy: 0.9219\n",
      "Epoch 121: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1840 - accuracy: 0.9238 - val_loss: 0.3418 - val_accuracy: 0.8700\n",
      "Epoch 122/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2154 - accuracy: 0.8952\n",
      "Epoch 122: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1739 - accuracy: 0.9307 - val_loss: 0.3318 - val_accuracy: 0.8754\n",
      "Epoch 123/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2094 - accuracy: 0.9194\n",
      "Epoch 123: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.9327 - val_loss: 0.3481 - val_accuracy: 0.8738\n",
      "Epoch 124/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2158 - accuracy: 0.9032\n",
      "Epoch 124: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1782 - accuracy: 0.9286 - val_loss: 0.3529 - val_accuracy: 0.8708\n",
      "Epoch 125/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1867 - accuracy: 0.9251\n",
      "Epoch 125: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1852 - accuracy: 0.9259 - val_loss: 0.3761 - val_accuracy: 0.8715\n",
      "Epoch 126/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2021 - accuracy: 0.9274\n",
      "Epoch 126: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1888 - accuracy: 0.9226 - val_loss: 0.3813 - val_accuracy: 0.8662\n",
      "Epoch 127/1000\n",
      "30/42 [====================>.........] - ETA: 0s - loss: 0.1978 - accuracy: 0.9185\n",
      "Epoch 127: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1938 - accuracy: 0.9201 - val_loss: 0.3757 - val_accuracy: 0.8662\n",
      "Epoch 128/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2198 - accuracy: 0.9032\n",
      "Epoch 128: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.9246 - val_loss: 0.3326 - val_accuracy: 0.8769\n",
      "Epoch 129/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1830 - accuracy: 0.9274\n",
      "Epoch 129: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.9294 - val_loss: 0.3452 - val_accuracy: 0.8723\n",
      "Epoch 130/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1757 - accuracy: 0.9317\n",
      "Epoch 130: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1776 - accuracy: 0.9307 - val_loss: 0.3360 - val_accuracy: 0.8731\n",
      "Epoch 131/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1946 - accuracy: 0.9355\n",
      "Epoch 131: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1711 - accuracy: 0.9334 - val_loss: 0.3452 - val_accuracy: 0.8723\n",
      "Epoch 132/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1703 - accuracy: 0.9327\n",
      "Epoch 132: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1684 - accuracy: 0.9344 - val_loss: 0.3321 - val_accuracy: 0.8738\n",
      "Epoch 133/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1774 - accuracy: 0.9296\n",
      "Epoch 133: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1762 - accuracy: 0.9305 - val_loss: 0.3404 - val_accuracy: 0.8792\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1653 - accuracy: 0.9377\n",
      "Epoch 134: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1653 - accuracy: 0.9377 - val_loss: 0.3752 - val_accuracy: 0.8615\n",
      "Epoch 135/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1640 - accuracy: 0.9194\n",
      "Epoch 135: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1713 - accuracy: 0.9307 - val_loss: 0.3321 - val_accuracy: 0.8769\n",
      "Epoch 136/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1728 - accuracy: 0.9317\n",
      "Epoch 136: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1730 - accuracy: 0.9315 - val_loss: 0.3453 - val_accuracy: 0.8762\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1515 - accuracy: 0.9516\n",
      "Epoch 137: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.9286 - val_loss: 0.3392 - val_accuracy: 0.8746\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 23s - loss: 6.2561 - accuracy: 0.4274\n",
      "Epoch 1: val_accuracy improved from -inf to 0.58615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 1.3353 - accuracy: 0.5234 - val_loss: 0.6680 - val_accuracy: 0.5862\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.6154 - accuracy: 0.6769\n",
      "Epoch 2: val_accuracy improved from 0.58615 to 0.78538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6154 - accuracy: 0.6769 - val_loss: 0.5374 - val_accuracy: 0.7854\n",
      "Epoch 3/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.4996 - accuracy: 0.7785\n",
      "Epoch 3: val_accuracy improved from 0.78538 to 0.82769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.7881 - val_loss: 0.4280 - val_accuracy: 0.8277\n",
      "Epoch 4/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.4121 - accuracy: 0.8294\n",
      "Epoch 4: val_accuracy improved from 0.82769 to 0.84462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4110 - accuracy: 0.8305 - val_loss: 0.3833 - val_accuracy: 0.8446\n",
      "Epoch 5/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.3737 - accuracy: 0.8477\n",
      "Epoch 5: val_accuracy did not improve from 0.84462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8445 - val_loss: 0.3748 - val_accuracy: 0.8362\n",
      "Epoch 6/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3599 - accuracy: 0.8558\n",
      "Epoch 6: val_accuracy improved from 0.84462 to 0.85538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3598 - accuracy: 0.8563 - val_loss: 0.3505 - val_accuracy: 0.8554\n",
      "Epoch 7/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.3492 - accuracy: 0.8530\n",
      "Epoch 7: val_accuracy did not improve from 0.85538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3500 - accuracy: 0.8545 - val_loss: 0.3526 - val_accuracy: 0.8538\n",
      "Epoch 8/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.3420 - accuracy: 0.8615\n",
      "Epoch 8: val_accuracy improved from 0.85538 to 0.85769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3414 - accuracy: 0.8615 - val_loss: 0.3382 - val_accuracy: 0.8577\n",
      "Epoch 9/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.3420 - accuracy: 0.8560\n",
      "Epoch 9: val_accuracy did not improve from 0.85769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3415 - accuracy: 0.8565 - val_loss: 0.3421 - val_accuracy: 0.8554\n",
      "Epoch 10/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.3262 - accuracy: 0.8638\n",
      "Epoch 10: val_accuracy did not improve from 0.85769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8632 - val_loss: 0.3372 - val_accuracy: 0.8523\n",
      "Epoch 11/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.3182 - accuracy: 0.8707\n",
      "Epoch 11: val_accuracy did not improve from 0.85769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3208 - accuracy: 0.8682 - val_loss: 0.3664 - val_accuracy: 0.8285\n",
      "Epoch 12/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3218 - accuracy: 0.8690\n",
      "Epoch 12: val_accuracy improved from 0.85769 to 0.86154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3252 - accuracy: 0.8672 - val_loss: 0.3499 - val_accuracy: 0.8615\n",
      "Epoch 13/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.3130 - accuracy: 0.8678\n",
      "Epoch 13: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8701 - val_loss: 0.3878 - val_accuracy: 0.8215\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3161 - accuracy: 0.8674\n",
      "Epoch 14: val_accuracy did not improve from 0.86154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3161 - accuracy: 0.8674 - val_loss: 0.3287 - val_accuracy: 0.8608\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4526 - accuracy: 0.8226\n",
      "Epoch 15: val_accuracy improved from 0.86154 to 0.86308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3089 - accuracy: 0.8713 - val_loss: 0.3234 - val_accuracy: 0.8631\n",
      "Epoch 16/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3126 - accuracy: 0.8662\n",
      "Epoch 16: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3137 - accuracy: 0.8659 - val_loss: 0.3250 - val_accuracy: 0.8577\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3149 - accuracy: 0.8670\n",
      "Epoch 17: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.8670 - val_loss: 0.3541 - val_accuracy: 0.8585\n",
      "Epoch 18/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.3036 - accuracy: 0.8725\n",
      "Epoch 18: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8693 - val_loss: 0.3289 - val_accuracy: 0.8508\n",
      "Epoch 19/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.3087 - accuracy: 0.8726\n",
      "Epoch 19: val_accuracy improved from 0.86308 to 0.86615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3024 - accuracy: 0.8740 - val_loss: 0.3162 - val_accuracy: 0.8662\n",
      "Epoch 20/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2941 - accuracy: 0.8795\n",
      "Epoch 20: val_accuracy improved from 0.86615 to 0.86846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2930 - accuracy: 0.8794 - val_loss: 0.3153 - val_accuracy: 0.8685\n",
      "Epoch 21/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2920 - accuracy: 0.8771\n",
      "Epoch 21: val_accuracy did not improve from 0.86846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2926 - accuracy: 0.8767 - val_loss: 0.3237 - val_accuracy: 0.8638\n",
      "Epoch 22/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.2925 - accuracy: 0.8763\n",
      "Epoch 22: val_accuracy did not improve from 0.86846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2893 - accuracy: 0.8778 - val_loss: 0.3307 - val_accuracy: 0.8669\n",
      "Epoch 23/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2692 - accuracy: 0.8710\n",
      "Epoch 23: val_accuracy did not improve from 0.86846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2857 - accuracy: 0.8842 - val_loss: 0.3077 - val_accuracy: 0.8677\n",
      "Epoch 24/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2999 - accuracy: 0.8745\n",
      "Epoch 24: val_accuracy improved from 0.86846 to 0.87385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2933 - accuracy: 0.8782 - val_loss: 0.3038 - val_accuracy: 0.8738\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2208 - accuracy: 0.9194\n",
      "Epoch 25: val_accuracy did not improve from 0.87385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.8772 - val_loss: 0.3087 - val_accuracy: 0.8715\n",
      "Epoch 26/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2755 - accuracy: 0.8902\n",
      "Epoch 26: val_accuracy improved from 0.87385 to 0.87846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2785 - accuracy: 0.8886 - val_loss: 0.3022 - val_accuracy: 0.8785\n",
      "Epoch 27/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2493 - accuracy: 0.8952\n",
      "Epoch 27: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2879 - accuracy: 0.8799 - val_loss: 0.3096 - val_accuracy: 0.8662\n",
      "Epoch 28/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2894 - accuracy: 0.8788\n",
      "Epoch 28: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2918 - accuracy: 0.8780 - val_loss: 0.3488 - val_accuracy: 0.8423\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2645 - accuracy: 0.8871\n",
      "Epoch 29: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2770 - accuracy: 0.8853 - val_loss: 0.3135 - val_accuracy: 0.8662\n",
      "Epoch 30/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2608 - accuracy: 0.8871\n",
      "Epoch 30: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2852 - accuracy: 0.8809 - val_loss: 0.3021 - val_accuracy: 0.8754\n",
      "Epoch 31/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2605 - accuracy: 0.8952\n",
      "Epoch 31: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2711 - accuracy: 0.8903 - val_loss: 0.2954 - val_accuracy: 0.8777\n",
      "Epoch 32/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2706 - accuracy: 0.8888\n",
      "Epoch 32: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.8894 - val_loss: 0.3620 - val_accuracy: 0.8469\n",
      "Epoch 33/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2845 - accuracy: 0.8819\n",
      "Epoch 33: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2835 - accuracy: 0.8819 - val_loss: 0.3013 - val_accuracy: 0.8769\n",
      "Epoch 34/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2323 - accuracy: 0.9194\n",
      "Epoch 34: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.8890 - val_loss: 0.3217 - val_accuracy: 0.8554\n",
      "Epoch 35/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2864 - accuracy: 0.8790\n",
      "Epoch 35: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2917 - accuracy: 0.8761 - val_loss: 0.3217 - val_accuracy: 0.8669\n",
      "Epoch 36/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.2708 - accuracy: 0.8864\n",
      "Epoch 36: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2674 - accuracy: 0.8876 - val_loss: 0.3075 - val_accuracy: 0.8785\n",
      "Epoch 37/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2693 - accuracy: 0.8886\n",
      "Epoch 37: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2683 - accuracy: 0.8896 - val_loss: 0.3032 - val_accuracy: 0.8777\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2649 - accuracy: 0.8903\n",
      "Epoch 38: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2649 - accuracy: 0.8903 - val_loss: 0.3032 - val_accuracy: 0.8662\n",
      "Epoch 39/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2612 - accuracy: 0.8937\n",
      "Epoch 39: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2611 - accuracy: 0.8921 - val_loss: 0.2964 - val_accuracy: 0.8754\n",
      "Epoch 40/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2621 - accuracy: 0.8931\n",
      "Epoch 40: val_accuracy improved from 0.87846 to 0.87923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2619 - accuracy: 0.8921 - val_loss: 0.3023 - val_accuracy: 0.8792\n",
      "Epoch 41/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2584 - accuracy: 0.8942\n",
      "Epoch 41: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2587 - accuracy: 0.8944 - val_loss: 0.2931 - val_accuracy: 0.8754\n",
      "Epoch 42/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2565 - accuracy: 0.8972\n",
      "Epoch 42: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.8949 - val_loss: 0.3006 - val_accuracy: 0.8754\n",
      "Epoch 43/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2730 - accuracy: 0.8835\n",
      "Epoch 43: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2741 - accuracy: 0.8834 - val_loss: 0.3078 - val_accuracy: 0.8792\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3090 - accuracy: 0.8710\n",
      "Epoch 44: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2738 - accuracy: 0.8851 - val_loss: 0.2967 - val_accuracy: 0.8769\n",
      "Epoch 45/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2589 - accuracy: 0.8920\n",
      "Epoch 45: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.8915 - val_loss: 0.2944 - val_accuracy: 0.8792\n",
      "Epoch 46/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2489 - accuracy: 0.8961\n",
      "Epoch 46: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.8944 - val_loss: 0.2965 - val_accuracy: 0.8731\n",
      "Epoch 47/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2400 - accuracy: 0.9113\n",
      "Epoch 47: val_accuracy improved from 0.87923 to 0.88077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2550 - accuracy: 0.8959 - val_loss: 0.2923 - val_accuracy: 0.8808\n",
      "Epoch 48/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2773 - accuracy: 0.8790\n",
      "Epoch 48: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2608 - accuracy: 0.8892 - val_loss: 0.2965 - val_accuracy: 0.8692\n",
      "Epoch 49/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2499 - accuracy: 0.8981\n",
      "Epoch 49: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.8974 - val_loss: 0.3271 - val_accuracy: 0.8654\n",
      "Epoch 50/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2964 - accuracy: 0.8952\n",
      "Epoch 50: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2539 - accuracy: 0.8971 - val_loss: 0.2913 - val_accuracy: 0.8785\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2091 - accuracy: 0.9032\n",
      "Epoch 51: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2539 - accuracy: 0.8963 - val_loss: 0.3194 - val_accuracy: 0.8646\n",
      "Epoch 52/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4267 - accuracy: 0.8065\n",
      "Epoch 52: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2572 - accuracy: 0.8946 - val_loss: 0.2956 - val_accuracy: 0.8769\n",
      "Epoch 53/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2959 - accuracy: 0.8952\n",
      "Epoch 53: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2561 - accuracy: 0.8922 - val_loss: 0.2970 - val_accuracy: 0.8746\n",
      "Epoch 54/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2701 - accuracy: 0.9194\n",
      "Epoch 54: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.8996 - val_loss: 0.3128 - val_accuracy: 0.8754\n",
      "Epoch 55/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2160 - accuracy: 0.9194\n",
      "Epoch 55: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2621 - accuracy: 0.8901 - val_loss: 0.2961 - val_accuracy: 0.8731\n",
      "Epoch 56/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2460 - accuracy: 0.9013\n",
      "Epoch 56: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.8990 - val_loss: 0.2932 - val_accuracy: 0.8792\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2749 - accuracy: 0.8306\n",
      "Epoch 57: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.8988 - val_loss: 0.3014 - val_accuracy: 0.8792\n",
      "Epoch 58/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2474 - accuracy: 0.8987\n",
      "Epoch 58: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.8984 - val_loss: 0.2951 - val_accuracy: 0.8738\n",
      "Epoch 59/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2497 - accuracy: 0.8989\n",
      "Epoch 59: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.8992 - val_loss: 0.3011 - val_accuracy: 0.8762\n",
      "Epoch 60/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1702 - accuracy: 0.9435\n",
      "Epoch 60: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2431 - accuracy: 0.9024 - val_loss: 0.2937 - val_accuracy: 0.8777\n",
      "Epoch 61/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2448 - accuracy: 0.9024\n",
      "Epoch 61: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2434 - accuracy: 0.9034 - val_loss: 0.3241 - val_accuracy: 0.8669\n",
      "Epoch 62/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2598 - accuracy: 0.8790\n",
      "Epoch 62: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.8955 - val_loss: 0.3043 - val_accuracy: 0.8692\n",
      "Epoch 63/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2428 - accuracy: 0.9017\n",
      "Epoch 63: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2424 - accuracy: 0.9023 - val_loss: 0.3041 - val_accuracy: 0.8638\n",
      "Epoch 64/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2779 - accuracy: 0.9032\n",
      "Epoch 64: val_accuracy improved from 0.88077 to 0.88154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8996 - val_loss: 0.2963 - val_accuracy: 0.8815\n",
      "Epoch 65/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1598 - accuracy: 0.9435\n",
      "Epoch 65: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.8997 - val_loss: 0.2993 - val_accuracy: 0.8746\n",
      "Epoch 66/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2375 - accuracy: 0.9032\n",
      "Epoch 66: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2379 - accuracy: 0.9026 - val_loss: 0.3030 - val_accuracy: 0.8815\n",
      "Epoch 67/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2396 - accuracy: 0.9020\n",
      "Epoch 67: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.9021 - val_loss: 0.2970 - val_accuracy: 0.8754\n",
      "Epoch 68/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2521 - accuracy: 0.8971\n",
      "Epoch 68: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2524 - accuracy: 0.8969 - val_loss: 0.2943 - val_accuracy: 0.8746\n",
      "Epoch 69/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2630 - accuracy: 0.8891\n",
      "Epoch 69: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2607 - accuracy: 0.8911 - val_loss: 0.2929 - val_accuracy: 0.8762\n",
      "Epoch 70/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2446 - accuracy: 0.8968\n",
      "Epoch 70: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2481 - accuracy: 0.8951 - val_loss: 0.3017 - val_accuracy: 0.8746\n",
      "Epoch 71/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2576 - accuracy: 0.8947\n",
      "Epoch 71: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2560 - accuracy: 0.8957 - val_loss: 0.3262 - val_accuracy: 0.8615\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2204 - accuracy: 0.8952\n",
      "Epoch 72: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2418 - accuracy: 0.8982 - val_loss: 0.2950 - val_accuracy: 0.8777\n",
      "Epoch 73/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2372 - accuracy: 0.9043\n",
      "Epoch 73: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2380 - accuracy: 0.9046 - val_loss: 0.2952 - val_accuracy: 0.8785\n",
      "Epoch 74/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1972 - accuracy: 0.9113\n",
      "Epoch 74: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.9042 - val_loss: 0.2967 - val_accuracy: 0.8792\n",
      "Epoch 75/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2438 - accuracy: 0.9022\n",
      "Epoch 75: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2405 - accuracy: 0.9032 - val_loss: 0.2964 - val_accuracy: 0.8715\n",
      "Epoch 76/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2361 - accuracy: 0.9041\n",
      "Epoch 76: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2360 - accuracy: 0.9040 - val_loss: 0.3082 - val_accuracy: 0.8715\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3227 - accuracy: 0.8710\n",
      "Epoch 77: val_accuracy improved from 0.88154 to 0.88231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2520 - accuracy: 0.8951 - val_loss: 0.2907 - val_accuracy: 0.8823\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2715 - accuracy: 0.8710\n",
      "Epoch 78: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2347 - accuracy: 0.9036 - val_loss: 0.3011 - val_accuracy: 0.8723\n",
      "Epoch 79/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2328 - accuracy: 0.9049\n",
      "Epoch 79: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2328 - accuracy: 0.9049 - val_loss: 0.2939 - val_accuracy: 0.8738\n",
      "Epoch 80/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2300 - accuracy: 0.9086\n",
      "Epoch 80: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2338 - accuracy: 0.9073 - val_loss: 0.2921 - val_accuracy: 0.8738\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1548 - accuracy: 0.9516\n",
      "Epoch 81: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2374 - accuracy: 0.9001 - val_loss: 0.3270 - val_accuracy: 0.8638\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2302 - accuracy: 0.9094\n",
      "Epoch 82: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2302 - accuracy: 0.9094 - val_loss: 0.3009 - val_accuracy: 0.8738\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2102 - accuracy: 0.9435\n",
      "Epoch 83: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2363 - accuracy: 0.9034 - val_loss: 0.3160 - val_accuracy: 0.8631\n",
      "Epoch 84/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2730 - accuracy: 0.8790\n",
      "Epoch 84: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2417 - accuracy: 0.8955 - val_loss: 0.2991 - val_accuracy: 0.8769\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2027 - accuracy: 0.9032\n",
      "Epoch 85: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2302 - accuracy: 0.9071 - val_loss: 0.3153 - val_accuracy: 0.8654\n",
      "Epoch 86/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2279 - accuracy: 0.9111\n",
      "Epoch 86: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2274 - accuracy: 0.9113 - val_loss: 0.2988 - val_accuracy: 0.8738\n",
      "Epoch 87/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1891 - accuracy: 0.9355\n",
      "Epoch 87: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 0.9086 - val_loss: 0.3051 - val_accuracy: 0.8762\n",
      "Epoch 88/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2295 - accuracy: 0.9063\n",
      "Epoch 88: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2330 - accuracy: 0.9042 - val_loss: 0.3240 - val_accuracy: 0.8638\n",
      "Epoch 89/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2182 - accuracy: 0.9194\n",
      "Epoch 89: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2243 - accuracy: 0.9088 - val_loss: 0.3030 - val_accuracy: 0.8731\n",
      "Epoch 90/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2254 - accuracy: 0.9063\n",
      "Epoch 90: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2254 - accuracy: 0.9063 - val_loss: 0.3187 - val_accuracy: 0.8669\n",
      "Epoch 91/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2295 - accuracy: 0.9090\n",
      "Epoch 91: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2295 - accuracy: 0.9090 - val_loss: 0.3411 - val_accuracy: 0.8654\n",
      "Epoch 92/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2265 - accuracy: 0.9085\n",
      "Epoch 92: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2256 - accuracy: 0.9088 - val_loss: 0.3037 - val_accuracy: 0.8808\n",
      "Epoch 93/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2069 - accuracy: 0.9113\n",
      "Epoch 93: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2213 - accuracy: 0.9094 - val_loss: 0.3061 - val_accuracy: 0.8754\n",
      "Epoch 94/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.2203 - accuracy: 0.9128\n",
      "Epoch 94: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.9126 - val_loss: 0.3063 - val_accuracy: 0.8769\n",
      "Epoch 95/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2188 - accuracy: 0.9115\n",
      "Epoch 95: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2193 - accuracy: 0.9117 - val_loss: 0.3095 - val_accuracy: 0.8723\n",
      "Epoch 96/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2228 - accuracy: 0.9100\n",
      "Epoch 96: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9101 - val_loss: 0.3019 - val_accuracy: 0.8754\n",
      "Epoch 97/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2139 - accuracy: 0.9136\n",
      "Epoch 97: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2159 - accuracy: 0.9128 - val_loss: 0.3014 - val_accuracy: 0.8762\n",
      "Epoch 98/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2131 - accuracy: 0.9138\n",
      "Epoch 98: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2133 - accuracy: 0.9124 - val_loss: 0.3116 - val_accuracy: 0.8746\n",
      "Epoch 99/1000\n",
      "28/42 [===================>..........] - ETA: 0s - loss: 0.2224 - accuracy: 0.9075\n",
      "Epoch 99: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2191 - accuracy: 0.9099 - val_loss: 0.3005 - val_accuracy: 0.8800\n",
      "Epoch 100/1000\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.2202 - accuracy: 0.9118\n",
      "Epoch 100: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2191 - accuracy: 0.9126 - val_loss: 0.3095 - val_accuracy: 0.8746\n",
      "Epoch 101/1000\n",
      "26/42 [=================>............] - ETA: 0s - loss: 0.2196 - accuracy: 0.9107\n",
      "Epoch 101: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2186 - accuracy: 0.9105 - val_loss: 0.3132 - val_accuracy: 0.8685\n",
      "Epoch 102/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2092 - accuracy: 0.9135\n",
      "Epoch 102: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2124 - accuracy: 0.9130 - val_loss: 0.3124 - val_accuracy: 0.8746\n",
      "Epoch 103/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2199 - accuracy: 0.9102\n",
      "Epoch 103: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2198 - accuracy: 0.9109 - val_loss: 0.3027 - val_accuracy: 0.8777\n",
      "Epoch 104/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1617 - accuracy: 0.9516\n",
      "Epoch 104: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2146 - accuracy: 0.9163 - val_loss: 0.3081 - val_accuracy: 0.8785\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1870 - accuracy: 0.9113\n",
      "Epoch 105: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2094 - accuracy: 0.9165 - val_loss: 0.3101 - val_accuracy: 0.8708\n",
      "Epoch 106/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2418 - accuracy: 0.8790\n",
      "Epoch 106: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2188 - accuracy: 0.9084 - val_loss: 0.3244 - val_accuracy: 0.8685\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1515 - accuracy: 0.9435\n",
      "Epoch 107: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2313 - accuracy: 0.9065 - val_loss: 0.3178 - val_accuracy: 0.8654\n",
      "Epoch 108/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2145 - accuracy: 0.9109\n",
      "Epoch 108: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2138 - accuracy: 0.9113 - val_loss: 0.3060 - val_accuracy: 0.8754\n",
      "Epoch 109/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2112 - accuracy: 0.9149\n",
      "Epoch 109: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2082 - accuracy: 0.9163 - val_loss: 0.3106 - val_accuracy: 0.8808\n",
      "Epoch 110/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2066 - accuracy: 0.9227\n",
      "Epoch 110: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2108 - accuracy: 0.9200 - val_loss: 0.3076 - val_accuracy: 0.8708\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2048 - accuracy: 0.9435\n",
      "Epoch 111: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2134 - accuracy: 0.9165 - val_loss: 0.3039 - val_accuracy: 0.8731\n",
      "Epoch 112/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1940 - accuracy: 0.9355\n",
      "Epoch 112: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2019 - accuracy: 0.9184 - val_loss: 0.3228 - val_accuracy: 0.8723\n",
      "Epoch 113/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2174 - accuracy: 0.9194\n",
      "Epoch 113: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2083 - accuracy: 0.9157 - val_loss: 0.3136 - val_accuracy: 0.8769\n",
      "Epoch 114/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1418 - accuracy: 0.9677\n",
      "Epoch 114: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2135 - accuracy: 0.9132 - val_loss: 0.3039 - val_accuracy: 0.8754\n",
      "Epoch 115/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2060 - accuracy: 0.9174\n",
      "Epoch 115: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2057 - accuracy: 0.9169 - val_loss: 0.3145 - val_accuracy: 0.8700\n",
      "Epoch 116/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2052 - accuracy: 0.9167\n",
      "Epoch 116: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2055 - accuracy: 0.9157 - val_loss: 0.3178 - val_accuracy: 0.8785\n",
      "Epoch 117/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2143 - accuracy: 0.8952\n",
      "Epoch 117: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2045 - accuracy: 0.9196 - val_loss: 0.3287 - val_accuracy: 0.8715\n",
      "Epoch 118/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2079 - accuracy: 0.9203\n",
      "Epoch 118: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2081 - accuracy: 0.9196 - val_loss: 0.3230 - val_accuracy: 0.8708\n",
      "Epoch 119/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2018 - accuracy: 0.9194\n",
      "Epoch 119: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2110 - accuracy: 0.9159 - val_loss: 0.3194 - val_accuracy: 0.8769\n",
      "Epoch 120/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.2016 - accuracy: 0.9173\n",
      "Epoch 120: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2033 - accuracy: 0.9175 - val_loss: 0.3308 - val_accuracy: 0.8685\n",
      "Epoch 121/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1970 - accuracy: 0.9113\n",
      "Epoch 121: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2011 - accuracy: 0.9173 - val_loss: 0.3361 - val_accuracy: 0.8692\n",
      "Epoch 122/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2397 - accuracy: 0.8952\n",
      "Epoch 122: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2088 - accuracy: 0.9140 - val_loss: 0.3231 - val_accuracy: 0.8762\n",
      "Epoch 123/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2263 - accuracy: 0.9113\n",
      "Epoch 123: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1959 - accuracy: 0.9228 - val_loss: 0.3474 - val_accuracy: 0.8700\n",
      "Epoch 124/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2076 - accuracy: 0.9151\n",
      "Epoch 124: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2083 - accuracy: 0.9140 - val_loss: 0.3405 - val_accuracy: 0.8731\n",
      "Epoch 125/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2089 - accuracy: 0.9174\n",
      "Epoch 125: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2085 - accuracy: 0.9163 - val_loss: 0.3263 - val_accuracy: 0.8654\n",
      "Epoch 126/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2002 - accuracy: 0.9207\n",
      "Epoch 126: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2002 - accuracy: 0.9207 - val_loss: 0.3229 - val_accuracy: 0.8792\n",
      "Epoch 127/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2148 - accuracy: 0.9355\n",
      "Epoch 127: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1947 - accuracy: 0.9240 - val_loss: 0.3355 - val_accuracy: 0.8692\n",
      "Epoch 128/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1990 - accuracy: 0.9186\n",
      "Epoch 128: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1992 - accuracy: 0.9184 - val_loss: 0.3260 - val_accuracy: 0.8685\n",
      "Epoch 129/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2021 - accuracy: 0.9153\n",
      "Epoch 129: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1945 - accuracy: 0.9198 - val_loss: 0.3310 - val_accuracy: 0.8769\n",
      "Epoch 130/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1804 - accuracy: 0.9194\n",
      "Epoch 130: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.9192 - val_loss: 0.3473 - val_accuracy: 0.8685\n",
      "Epoch 131/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1990 - accuracy: 0.9220\n",
      "Epoch 131: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1950 - accuracy: 0.9228 - val_loss: 0.3490 - val_accuracy: 0.8646\n",
      "Epoch 132/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1586 - accuracy: 0.9274\n",
      "Epoch 132: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1960 - accuracy: 0.9211 - val_loss: 0.3400 - val_accuracy: 0.8715\n",
      "Epoch 133/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1939 - accuracy: 0.9194\n",
      "Epoch 133: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1898 - accuracy: 0.9265 - val_loss: 0.3322 - val_accuracy: 0.8723\n",
      "Epoch 134/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2093 - accuracy: 0.9274\n",
      "Epoch 134: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.9232 - val_loss: 0.3684 - val_accuracy: 0.8492\n",
      "Epoch 135/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1903 - accuracy: 0.9244\n",
      "Epoch 135: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1903 - accuracy: 0.9244 - val_loss: 0.3368 - val_accuracy: 0.8769\n",
      "Epoch 136/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2046 - accuracy: 0.9185\n",
      "Epoch 136: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2032 - accuracy: 0.9192 - val_loss: 0.3318 - val_accuracy: 0.8715\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2330 - accuracy: 0.8952\n",
      "Epoch 137: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1932 - accuracy: 0.9211 - val_loss: 0.3415 - val_accuracy: 0.8708\n",
      "Epoch 138/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2014 - accuracy: 0.9185\n",
      "Epoch 138: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1959 - accuracy: 0.9211 - val_loss: 0.3295 - val_accuracy: 0.8769\n",
      "Epoch 139/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2088 - accuracy: 0.9113\n",
      "Epoch 139: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2085 - accuracy: 0.9130 - val_loss: 0.3456 - val_accuracy: 0.8646\n",
      "Epoch 140/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2026 - accuracy: 0.9274\n",
      "Epoch 140: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1902 - accuracy: 0.9253 - val_loss: 0.3345 - val_accuracy: 0.8754\n",
      "Epoch 141/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1586 - accuracy: 0.9435\n",
      "Epoch 141: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.9230 - val_loss: 0.3365 - val_accuracy: 0.8769\n",
      "Epoch 142/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1858 - accuracy: 0.9244\n",
      "Epoch 142: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.9238 - val_loss: 0.3573 - val_accuracy: 0.8754\n",
      "Epoch 143/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1965 - accuracy: 0.9207\n",
      "Epoch 143: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1965 - accuracy: 0.9207 - val_loss: 0.3534 - val_accuracy: 0.8692\n",
      "Epoch 144/1000\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.2037 - accuracy: 0.9146\n",
      "Epoch 144: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1997 - accuracy: 0.9161 - val_loss: 0.3423 - val_accuracy: 0.8723\n",
      "Epoch 145/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1699 - accuracy: 0.9194\n",
      "Epoch 145: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1852 - accuracy: 0.9251 - val_loss: 0.3454 - val_accuracy: 0.8715\n",
      "Epoch 146/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1806 - accuracy: 0.9287\n",
      "Epoch 146: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.9290 - val_loss: 0.3405 - val_accuracy: 0.8746\n",
      "Epoch 147/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2182 - accuracy: 0.9113\n",
      "Epoch 147: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1904 - accuracy: 0.9236 - val_loss: 0.3600 - val_accuracy: 0.8677\n",
      "Epoch 148/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2466 - accuracy: 0.9032\n",
      "Epoch 148: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1891 - accuracy: 0.9269 - val_loss: 0.3451 - val_accuracy: 0.8738\n",
      "Epoch 149/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1858 - accuracy: 0.9261\n",
      "Epoch 149: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1862 - accuracy: 0.9267 - val_loss: 0.3617 - val_accuracy: 0.8677\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1552 - accuracy: 0.9355\n",
      "Epoch 150: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1831 - accuracy: 0.9261 - val_loss: 0.3442 - val_accuracy: 0.8677\n",
      "Epoch 151/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1909 - accuracy: 0.9190\n",
      "Epoch 151: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1920 - accuracy: 0.9184 - val_loss: 0.3430 - val_accuracy: 0.8669\n",
      "Epoch 152/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1872 - accuracy: 0.9246\n",
      "Epoch 152: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1872 - accuracy: 0.9246 - val_loss: 0.3384 - val_accuracy: 0.8708\n",
      "Epoch 153/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1888 - accuracy: 0.9212\n",
      "Epoch 153: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.9213 - val_loss: 0.3740 - val_accuracy: 0.8708\n",
      "Epoch 154/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1940 - accuracy: 0.9355\n",
      "Epoch 154: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1940 - accuracy: 0.9198 - val_loss: 0.3552 - val_accuracy: 0.8715\n",
      "Epoch 155/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1677 - accuracy: 0.9274\n",
      "Epoch 155: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1927 - accuracy: 0.9219 - val_loss: 0.3410 - val_accuracy: 0.8669\n",
      "Epoch 156/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1811 - accuracy: 0.9268\n",
      "Epoch 156: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.9261 - val_loss: 0.3544 - val_accuracy: 0.8662\n",
      "Epoch 157/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1229 - accuracy: 0.9597\n",
      "Epoch 157: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1928 - accuracy: 0.9196 - val_loss: 0.3494 - val_accuracy: 0.8638\n",
      "Epoch 158/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1777 - accuracy: 0.9292\n",
      "Epoch 158: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.9292 - val_loss: 0.3488 - val_accuracy: 0.8677\n",
      "Epoch 159/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1839 - accuracy: 0.9273\n",
      "Epoch 159: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1839 - accuracy: 0.9273 - val_loss: 0.3451 - val_accuracy: 0.8685\n",
      "Epoch 160/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.1776 - accuracy: 0.9300\n",
      "Epoch 160: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1813 - accuracy: 0.9271 - val_loss: 0.3742 - val_accuracy: 0.8708\n",
      "Epoch 161/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1854 - accuracy: 0.9265\n",
      "Epoch 161: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9265 - val_loss: 0.3459 - val_accuracy: 0.8692\n",
      "Epoch 162/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1319 - accuracy: 0.9516\n",
      "Epoch 162: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1720 - accuracy: 0.9336 - val_loss: 0.3707 - val_accuracy: 0.8692\n",
      "Epoch 163/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1978 - accuracy: 0.9113\n",
      "Epoch 163: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.9298 - val_loss: 0.3756 - val_accuracy: 0.8692\n",
      "Epoch 164/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1464 - accuracy: 0.9113\n",
      "Epoch 164: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.9288 - val_loss: 0.3484 - val_accuracy: 0.8715\n",
      "Epoch 165/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1737 - accuracy: 0.9298\n",
      "Epoch 165: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1745 - accuracy: 0.9292 - val_loss: 0.3591 - val_accuracy: 0.8654\n",
      "Epoch 166/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1735 - accuracy: 0.9113\n",
      "Epoch 166: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1775 - accuracy: 0.9265 - val_loss: 0.3744 - val_accuracy: 0.8631\n",
      "Epoch 167/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.1851 - accuracy: 0.9279\n",
      "Epoch 167: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1856 - accuracy: 0.9259 - val_loss: 0.3686 - val_accuracy: 0.8685\n",
      "Epoch 168/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1862 - accuracy: 0.9256\n",
      "Epoch 168: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1872 - accuracy: 0.9255 - val_loss: 0.3611 - val_accuracy: 0.8646\n",
      "Epoch 169/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1787 - accuracy: 0.9291\n",
      "Epoch 169: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.9307 - val_loss: 0.3738 - val_accuracy: 0.8692\n",
      "Epoch 170/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1304 - accuracy: 0.9435\n",
      "Epoch 170: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1717 - accuracy: 0.9294 - val_loss: 0.3852 - val_accuracy: 0.8600\n",
      "Epoch 171/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1785 - accuracy: 0.9310\n",
      "Epoch 171: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.9311 - val_loss: 0.3626 - val_accuracy: 0.8708\n",
      "Epoch 172/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1698 - accuracy: 0.9321\n",
      "Epoch 172: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1706 - accuracy: 0.9325 - val_loss: 0.3740 - val_accuracy: 0.8646\n",
      "Epoch 173/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1837 - accuracy: 0.9249\n",
      "Epoch 173: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.9246 - val_loss: 0.3646 - val_accuracy: 0.8646\n",
      "Epoch 174/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1451 - accuracy: 0.9516\n",
      "Epoch 174: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1710 - accuracy: 0.9300 - val_loss: 0.3917 - val_accuracy: 0.8700\n",
      "Epoch 175/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1710 - accuracy: 0.9194\n",
      "Epoch 175: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1889 - accuracy: 0.9236 - val_loss: 0.3959 - val_accuracy: 0.8577\n",
      "Epoch 176/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1806 - accuracy: 0.9355\n",
      "Epoch 176: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1903 - accuracy: 0.9207 - val_loss: 0.3657 - val_accuracy: 0.8692\n",
      "Epoch 177/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2012 - accuracy: 0.9113\n",
      "Epoch 177: val_accuracy did not improve from 0.88231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1747 - accuracy: 0.9290 - val_loss: 0.3713 - val_accuracy: 0.8677\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 23s - loss: 3.2953 - accuracy: 0.5887\n",
      "Epoch 1: val_accuracy improved from -inf to 0.77538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.8081 - accuracy: 0.6234 - val_loss: 0.5333 - val_accuracy: 0.7754\n",
      "Epoch 2/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.5341 - accuracy: 0.7823\n",
      "Epoch 2: val_accuracy improved from 0.77538 to 0.84385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4822 - accuracy: 0.7945 - val_loss: 0.4210 - val_accuracy: 0.8438\n",
      "Epoch 3/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4349 - accuracy: 0.8065\n",
      "Epoch 3: val_accuracy improved from 0.84385 to 0.84538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8407 - val_loss: 0.3868 - val_accuracy: 0.8454\n",
      "Epoch 4/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3778 - accuracy: 0.8387\n",
      "Epoch 4: val_accuracy did not improve from 0.84538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8386 - val_loss: 0.3846 - val_accuracy: 0.8269\n",
      "Epoch 5/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3537 - accuracy: 0.8526\n",
      "Epoch 5: val_accuracy improved from 0.84538 to 0.85923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3549 - accuracy: 0.8528 - val_loss: 0.3473 - val_accuracy: 0.8592\n",
      "Epoch 6/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3679 - accuracy: 0.8387\n",
      "Epoch 6: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8549 - val_loss: 0.3413 - val_accuracy: 0.8577\n",
      "Epoch 7/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.3372 - accuracy: 0.8660\n",
      "Epoch 7: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8653 - val_loss: 0.3395 - val_accuracy: 0.8562\n",
      "Epoch 8/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2524 - accuracy: 0.9194\n",
      "Epoch 8: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8686 - val_loss: 0.3384 - val_accuracy: 0.8562\n",
      "Epoch 9/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.3306 - accuracy: 0.8643\n",
      "Epoch 9: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8626 - val_loss: 0.3369 - val_accuracy: 0.8569\n",
      "Epoch 10/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3334 - accuracy: 0.8583\n",
      "Epoch 10: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8586 - val_loss: 0.3672 - val_accuracy: 0.8492\n",
      "Epoch 11/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.3251 - accuracy: 0.8675\n",
      "Epoch 11: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8657 - val_loss: 0.3421 - val_accuracy: 0.8592\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3061 - accuracy: 0.8871\n",
      "Epoch 12: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8643 - val_loss: 0.3359 - val_accuracy: 0.8592\n",
      "Epoch 13/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.3313 - accuracy: 0.8608\n",
      "Epoch 13: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8611 - val_loss: 0.3326 - val_accuracy: 0.8585\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3669 - accuracy: 0.8306\n",
      "Epoch 14: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3172 - accuracy: 0.8711 - val_loss: 0.3330 - val_accuracy: 0.8585\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3124 - accuracy: 0.8717\n",
      "Epoch 15: val_accuracy improved from 0.85923 to 0.86077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3124 - accuracy: 0.8717 - val_loss: 0.3313 - val_accuracy: 0.8608\n",
      "Epoch 16/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.3247 - accuracy: 0.8579\n",
      "Epoch 16: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8563 - val_loss: 0.3439 - val_accuracy: 0.8492\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2911 - accuracy: 0.8871\n",
      "Epoch 17: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8674 - val_loss: 0.3595 - val_accuracy: 0.8392\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3347 - accuracy: 0.8306\n",
      "Epoch 18: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8734 - val_loss: 0.3506 - val_accuracy: 0.8454\n",
      "Epoch 19/1000\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.3033 - accuracy: 0.8747\n",
      "Epoch 19: val_accuracy did not improve from 0.86077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3038 - accuracy: 0.8740 - val_loss: 0.3395 - val_accuracy: 0.8462\n",
      "Epoch 20/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2788 - accuracy: 0.9032\n",
      "Epoch 20: val_accuracy improved from 0.86077 to 0.86154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3039 - accuracy: 0.8717 - val_loss: 0.3262 - val_accuracy: 0.8615\n",
      "Epoch 21/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3003 - accuracy: 0.8782\n",
      "Epoch 21: val_accuracy improved from 0.86154 to 0.86308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3004 - accuracy: 0.8776 - val_loss: 0.3246 - val_accuracy: 0.8631\n",
      "Epoch 22/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.3117 - accuracy: 0.8683\n",
      "Epoch 22: val_accuracy did not improve from 0.86308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8707 - val_loss: 0.3286 - val_accuracy: 0.8631\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3033 - accuracy: 0.8722\n",
      "Epoch 23: val_accuracy improved from 0.86308 to 0.86923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3033 - accuracy: 0.8722 - val_loss: 0.3410 - val_accuracy: 0.8692\n",
      "Epoch 24/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.3135 - accuracy: 0.8734\n",
      "Epoch 24: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8742 - val_loss: 0.3355 - val_accuracy: 0.8623\n",
      "Epoch 25/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2831 - accuracy: 0.8710\n",
      "Epoch 25: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8692 - val_loss: 0.3783 - val_accuracy: 0.8362\n",
      "Epoch 26/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3978 - accuracy: 0.8065\n",
      "Epoch 26: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2993 - accuracy: 0.8744 - val_loss: 0.3260 - val_accuracy: 0.8662\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2936 - accuracy: 0.8765\n",
      "Epoch 27: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2936 - accuracy: 0.8765 - val_loss: 0.3173 - val_accuracy: 0.8646\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3217 - accuracy: 0.8468\n",
      "Epoch 28: val_accuracy did not improve from 0.86923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2872 - accuracy: 0.8786 - val_loss: 0.3289 - val_accuracy: 0.8669\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3040 - accuracy: 0.8790\n",
      "Epoch 29: val_accuracy improved from 0.86923 to 0.87000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2849 - accuracy: 0.8819 - val_loss: 0.3158 - val_accuracy: 0.8700\n",
      "Epoch 30/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2818 - accuracy: 0.8820\n",
      "Epoch 30: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2851 - accuracy: 0.8811 - val_loss: 0.3442 - val_accuracy: 0.8446\n",
      "Epoch 31/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2826 - accuracy: 0.8819\n",
      "Epoch 31: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2825 - accuracy: 0.8811 - val_loss: 0.3260 - val_accuracy: 0.8577\n",
      "Epoch 32/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2846 - accuracy: 0.8710\n",
      "Epoch 32: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2802 - accuracy: 0.8844 - val_loss: 0.3333 - val_accuracy: 0.8546\n",
      "Epoch 33/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3052 - accuracy: 0.8548\n",
      "Epoch 33: val_accuracy did not improve from 0.87000\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2893 - accuracy: 0.8786 - val_loss: 0.3296 - val_accuracy: 0.8646\n",
      "Epoch 34/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2675 - accuracy: 0.8790\n",
      "Epoch 34: val_accuracy improved from 0.87000 to 0.87077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2881 - accuracy: 0.8826 - val_loss: 0.3089 - val_accuracy: 0.8708\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2920 - accuracy: 0.8782\n",
      "Epoch 35: val_accuracy did not improve from 0.87077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2920 - accuracy: 0.8782 - val_loss: 0.3167 - val_accuracy: 0.8654\n",
      "Epoch 36/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2235 - accuracy: 0.9113\n",
      "Epoch 36: val_accuracy improved from 0.87077 to 0.87462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2831 - accuracy: 0.8824 - val_loss: 0.3253 - val_accuracy: 0.8746\n",
      "Epoch 37/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2695 - accuracy: 0.8887\n",
      "Epoch 37: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2702 - accuracy: 0.8884 - val_loss: 0.3069 - val_accuracy: 0.8715\n",
      "Epoch 38/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2388 - accuracy: 0.8790\n",
      "Epoch 38: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2679 - accuracy: 0.8913 - val_loss: 0.3044 - val_accuracy: 0.8708\n",
      "Epoch 39/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2854 - accuracy: 0.8780\n",
      "Epoch 39: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2854 - accuracy: 0.8774 - val_loss: 0.3162 - val_accuracy: 0.8692\n",
      "Epoch 40/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2895 - accuracy: 0.8871\n",
      "Epoch 40: val_accuracy improved from 0.87462 to 0.87769, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2775 - accuracy: 0.8842 - val_loss: 0.3127 - val_accuracy: 0.8777\n",
      "Epoch 41/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2620 - accuracy: 0.8710\n",
      "Epoch 41: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 0.8928 - val_loss: 0.3119 - val_accuracy: 0.8738\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2499 - accuracy: 0.8548\n",
      "Epoch 42: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 0.8897 - val_loss: 0.3091 - val_accuracy: 0.8708\n",
      "Epoch 43/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2248 - accuracy: 0.9113\n",
      "Epoch 43: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2701 - accuracy: 0.8861 - val_loss: 0.3271 - val_accuracy: 0.8731\n",
      "Epoch 44/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2701 - accuracy: 0.8880\n",
      "Epoch 44: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2687 - accuracy: 0.8882 - val_loss: 0.3000 - val_accuracy: 0.8754\n",
      "Epoch 45/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2564 - accuracy: 0.8952\n",
      "Epoch 45: val_accuracy did not improve from 0.87769\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2594 - accuracy: 0.8919 - val_loss: 0.3118 - val_accuracy: 0.8677\n",
      "Epoch 46/1000\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.2624 - accuracy: 0.8959\n",
      "Epoch 46: val_accuracy improved from 0.87769 to 0.87846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2636 - accuracy: 0.8932 - val_loss: 0.3029 - val_accuracy: 0.8785\n",
      "Epoch 47/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2680 - accuracy: 0.8790\n",
      "Epoch 47: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.8967 - val_loss: 0.3081 - val_accuracy: 0.8708\n",
      "Epoch 48/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2608 - accuracy: 0.8928\n",
      "Epoch 48: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2628 - accuracy: 0.8911 - val_loss: 0.3193 - val_accuracy: 0.8692\n",
      "Epoch 49/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2783 - accuracy: 0.8871\n",
      "Epoch 49: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2558 - accuracy: 0.8959 - val_loss: 0.3020 - val_accuracy: 0.8746\n",
      "Epoch 50/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2544 - accuracy: 0.8979\n",
      "Epoch 50: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2539 - accuracy: 0.8972 - val_loss: 0.3007 - val_accuracy: 0.8746\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2692 - accuracy: 0.8871\n",
      "Epoch 51: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.8951 - val_loss: 0.3058 - val_accuracy: 0.8746\n",
      "Epoch 52/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2500 - accuracy: 0.8984\n",
      "Epoch 52: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.8957 - val_loss: 0.3018 - val_accuracy: 0.8746\n",
      "Epoch 53/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2028 - accuracy: 0.9113\n",
      "Epoch 53: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2540 - accuracy: 0.8969 - val_loss: 0.3131 - val_accuracy: 0.8631\n",
      "Epoch 54/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2622 - accuracy: 0.8629\n",
      "Epoch 54: val_accuracy improved from 0.87846 to 0.88154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2623 - accuracy: 0.8924 - val_loss: 0.3122 - val_accuracy: 0.8815\n",
      "Epoch 55/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2622 - accuracy: 0.8895\n",
      "Epoch 55: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2601 - accuracy: 0.8905 - val_loss: 0.3175 - val_accuracy: 0.8723\n",
      "Epoch 56/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2685 - accuracy: 0.8871\n",
      "Epoch 56: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8997 - val_loss: 0.2989 - val_accuracy: 0.8785\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1614 - accuracy: 0.9113\n",
      "Epoch 57: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.9023 - val_loss: 0.3236 - val_accuracy: 0.8685\n",
      "Epoch 58/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2572 - accuracy: 0.8948\n",
      "Epoch 58: val_accuracy improved from 0.88154 to 0.88308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2555 - accuracy: 0.8961 - val_loss: 0.3014 - val_accuracy: 0.8831\n",
      "Epoch 59/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1913 - accuracy: 0.9194\n",
      "Epoch 59: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.8990 - val_loss: 0.2974 - val_accuracy: 0.8762\n",
      "Epoch 60/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2443 - accuracy: 0.9017\n",
      "Epoch 60: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2430 - accuracy: 0.9023 - val_loss: 0.3008 - val_accuracy: 0.8715\n",
      "Epoch 61/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2446 - accuracy: 0.8988\n",
      "Epoch 61: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.8984 - val_loss: 0.3020 - val_accuracy: 0.8769\n",
      "Epoch 62/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2470 - accuracy: 0.9010\n",
      "Epoch 62: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.9013 - val_loss: 0.3209 - val_accuracy: 0.8692\n",
      "Epoch 63/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2865 - accuracy: 0.8710\n",
      "Epoch 63: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.8978 - val_loss: 0.3200 - val_accuracy: 0.8738\n",
      "Epoch 64/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2542 - accuracy: 0.8961\n",
      "Epoch 64: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2547 - accuracy: 0.8959 - val_loss: 0.2996 - val_accuracy: 0.8762\n",
      "Epoch 65/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2424 - accuracy: 0.9032\n",
      "Epoch 65: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2390 - accuracy: 0.9042 - val_loss: 0.3053 - val_accuracy: 0.8708\n",
      "Epoch 66/1000\n",
      "28/42 [===================>..........] - ETA: 0s - loss: 0.2448 - accuracy: 0.8986\n",
      "Epoch 66: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.8984 - val_loss: 0.3211 - val_accuracy: 0.8715\n",
      "Epoch 67/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2281 - accuracy: 0.8952\n",
      "Epoch 67: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2526 - accuracy: 0.8938 - val_loss: 0.3016 - val_accuracy: 0.8738\n",
      "Epoch 68/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2711 - accuracy: 0.9113\n",
      "Epoch 68: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.9005 - val_loss: 0.3331 - val_accuracy: 0.8715\n",
      "Epoch 69/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1895 - accuracy: 0.9113\n",
      "Epoch 69: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.8986 - val_loss: 0.3289 - val_accuracy: 0.8662\n",
      "Epoch 70/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2633 - accuracy: 0.8917\n",
      "Epoch 70: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2635 - accuracy: 0.8913 - val_loss: 0.3777 - val_accuracy: 0.8500\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2384 - accuracy: 0.8952\n",
      "Epoch 71: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2547 - accuracy: 0.8944 - val_loss: 0.3060 - val_accuracy: 0.8785\n",
      "Epoch 72/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2401 - accuracy: 0.8991\n",
      "Epoch 72: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2411 - accuracy: 0.8994 - val_loss: 0.3207 - val_accuracy: 0.8585\n",
      "Epoch 73/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2526 - accuracy: 0.8960\n",
      "Epoch 73: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2541 - accuracy: 0.8951 - val_loss: 0.3056 - val_accuracy: 0.8762\n",
      "Epoch 74/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2493 - accuracy: 0.8972\n",
      "Epoch 74: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.8976 - val_loss: 0.3106 - val_accuracy: 0.8800\n",
      "Epoch 75/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2496 - accuracy: 0.8960\n",
      "Epoch 75: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.8953 - val_loss: 0.3047 - val_accuracy: 0.8662\n",
      "Epoch 76/1000\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.2334 - accuracy: 0.9062\n",
      "Epoch 76: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2348 - accuracy: 0.9071 - val_loss: 0.3351 - val_accuracy: 0.8631\n",
      "Epoch 77/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2358 - accuracy: 0.9062\n",
      "Epoch 77: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2341 - accuracy: 0.9080 - val_loss: 0.3126 - val_accuracy: 0.8831\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1813 - accuracy: 0.9194\n",
      "Epoch 78: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2329 - accuracy: 0.9084 - val_loss: 0.3054 - val_accuracy: 0.8785\n",
      "Epoch 79/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2316 - accuracy: 0.9080\n",
      "Epoch 79: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2316 - accuracy: 0.9078 - val_loss: 0.3007 - val_accuracy: 0.8708\n",
      "Epoch 80/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1893 - accuracy: 0.9194\n",
      "Epoch 80: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2279 - accuracy: 0.9103 - val_loss: 0.3030 - val_accuracy: 0.8746\n",
      "Epoch 81/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1885 - accuracy: 0.9435\n",
      "Epoch 81: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2345 - accuracy: 0.9040 - val_loss: 0.3308 - val_accuracy: 0.8677\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2322 - accuracy: 0.9059\n",
      "Epoch 82: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2322 - accuracy: 0.9059 - val_loss: 0.3124 - val_accuracy: 0.8731\n",
      "Epoch 83/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2478 - accuracy: 0.9194\n",
      "Epoch 83: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2274 - accuracy: 0.9101 - val_loss: 0.3045 - val_accuracy: 0.8762\n",
      "Epoch 84/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2313 - accuracy: 0.9058\n",
      "Epoch 84: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2307 - accuracy: 0.9057 - val_loss: 0.3087 - val_accuracy: 0.8685\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1981 - accuracy: 0.9194\n",
      "Epoch 85: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2311 - accuracy: 0.9028 - val_loss: 0.3248 - val_accuracy: 0.8723\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1852 - accuracy: 0.9274\n",
      "Epoch 86: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2299 - accuracy: 0.9051 - val_loss: 0.3139 - val_accuracy: 0.8754\n",
      "Epoch 87/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2425 - accuracy: 0.9003\n",
      "Epoch 87: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2397 - accuracy: 0.9013 - val_loss: 0.3358 - val_accuracy: 0.8654\n",
      "Epoch 88/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2282 - accuracy: 0.9090\n",
      "Epoch 88: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2282 - accuracy: 0.9090 - val_loss: 0.3074 - val_accuracy: 0.8715\n",
      "Epoch 89/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2336 - accuracy: 0.9055\n",
      "Epoch 89: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2321 - accuracy: 0.9059 - val_loss: 0.3101 - val_accuracy: 0.8777\n",
      "Epoch 90/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2001 - accuracy: 0.9194\n",
      "Epoch 90: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2266 - accuracy: 0.9111 - val_loss: 0.3063 - val_accuracy: 0.8808\n",
      "Epoch 91/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1990 - accuracy: 0.9113\n",
      "Epoch 91: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2310 - accuracy: 0.9130 - val_loss: 0.3231 - val_accuracy: 0.8700\n",
      "Epoch 92/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3735 - accuracy: 0.8145\n",
      "Epoch 92: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2347 - accuracy: 0.9046 - val_loss: 0.3158 - val_accuracy: 0.8746\n",
      "Epoch 93/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2277 - accuracy: 0.9094\n",
      "Epoch 93: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2281 - accuracy: 0.9099 - val_loss: 0.3157 - val_accuracy: 0.8723\n",
      "Epoch 94/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1952 - accuracy: 0.9194\n",
      "Epoch 94: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.9088 - val_loss: 0.3135 - val_accuracy: 0.8754\n",
      "Epoch 95/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2067 - accuracy: 0.9113\n",
      "Epoch 95: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2171 - accuracy: 0.9138 - val_loss: 0.3185 - val_accuracy: 0.8792\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1521 - accuracy: 0.9355\n",
      "Epoch 96: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2155 - accuracy: 0.9115 - val_loss: 0.3134 - val_accuracy: 0.8731\n",
      "Epoch 97/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2363 - accuracy: 0.9010\n",
      "Epoch 97: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2342 - accuracy: 0.9017 - val_loss: 0.3131 - val_accuracy: 0.8685\n",
      "Epoch 98/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2404 - accuracy: 0.9018\n",
      "Epoch 98: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.9048 - val_loss: 0.3336 - val_accuracy: 0.8731\n",
      "Epoch 99/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2617 - accuracy: 0.8710\n",
      "Epoch 99: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2277 - accuracy: 0.9055 - val_loss: 0.3094 - val_accuracy: 0.8769\n",
      "Epoch 100/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2092 - accuracy: 0.9202\n",
      "Epoch 100: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2135 - accuracy: 0.9175 - val_loss: 0.3264 - val_accuracy: 0.8654\n",
      "Epoch 101/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1867 - accuracy: 0.9113\n",
      "Epoch 101: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 0.9136 - val_loss: 0.3166 - val_accuracy: 0.8746\n",
      "Epoch 102/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2360 - accuracy: 0.9113\n",
      "Epoch 102: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2166 - accuracy: 0.9140 - val_loss: 0.3204 - val_accuracy: 0.8715\n",
      "Epoch 103/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3385 - accuracy: 0.8790\n",
      "Epoch 103: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2152 - accuracy: 0.9144 - val_loss: 0.3837 - val_accuracy: 0.8538\n",
      "Epoch 104/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2144 - accuracy: 0.9168\n",
      "Epoch 104: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2144 - accuracy: 0.9163 - val_loss: 0.3452 - val_accuracy: 0.8600\n",
      "Epoch 105/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2299 - accuracy: 0.8629\n",
      "Epoch 105: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2150 - accuracy: 0.9134 - val_loss: 0.3466 - val_accuracy: 0.8662\n",
      "Epoch 106/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1832 - accuracy: 0.9355\n",
      "Epoch 106: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2158 - accuracy: 0.9130 - val_loss: 0.3264 - val_accuracy: 0.8685\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1791 - accuracy: 0.9194\n",
      "Epoch 107: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2105 - accuracy: 0.9159 - val_loss: 0.3165 - val_accuracy: 0.8654\n",
      "Epoch 108/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1587 - accuracy: 0.9516\n",
      "Epoch 108: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.9080 - val_loss: 0.3461 - val_accuracy: 0.8700\n",
      "Epoch 109/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1547 - accuracy: 0.9435\n",
      "Epoch 109: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2108 - accuracy: 0.9161 - val_loss: 0.3404 - val_accuracy: 0.8754\n",
      "Epoch 110/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2093 - accuracy: 0.9146\n",
      "Epoch 110: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2100 - accuracy: 0.9146 - val_loss: 0.3427 - val_accuracy: 0.8646\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1294 - accuracy: 0.9516\n",
      "Epoch 111: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2302 - accuracy: 0.9055 - val_loss: 0.3206 - val_accuracy: 0.8692\n",
      "Epoch 112/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2408 - accuracy: 0.9003\n",
      "Epoch 112: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2408 - accuracy: 0.9003 - val_loss: 0.4269 - val_accuracy: 0.8362\n",
      "Epoch 113/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2658 - accuracy: 0.8710\n",
      "Epoch 113: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.9078 - val_loss: 0.3264 - val_accuracy: 0.8692\n",
      "Epoch 114/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2107 - accuracy: 0.9132\n",
      "Epoch 114: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2095 - accuracy: 0.9140 - val_loss: 0.3580 - val_accuracy: 0.8523\n",
      "Epoch 115/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1984 - accuracy: 0.9274\n",
      "Epoch 115: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2286 - accuracy: 0.9061 - val_loss: 0.3126 - val_accuracy: 0.8785\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1967 - accuracy: 0.9274\n",
      "Epoch 116: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2037 - accuracy: 0.9192 - val_loss: 0.3155 - val_accuracy: 0.8715\n",
      "Epoch 117/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1505 - accuracy: 0.9194\n",
      "Epoch 117: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2037 - accuracy: 0.9205 - val_loss: 0.3298 - val_accuracy: 0.8754\n",
      "Epoch 118/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2151 - accuracy: 0.9032\n",
      "Epoch 118: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2094 - accuracy: 0.9159 - val_loss: 0.3773 - val_accuracy: 0.8592\n",
      "Epoch 119/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3215 - accuracy: 0.8710\n",
      "Epoch 119: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2074 - accuracy: 0.9142 - val_loss: 0.3465 - val_accuracy: 0.8692\n",
      "Epoch 120/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2074 - accuracy: 0.9156\n",
      "Epoch 120: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2082 - accuracy: 0.9159 - val_loss: 0.3206 - val_accuracy: 0.8638\n",
      "Epoch 121/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2707 - accuracy: 0.8629\n",
      "Epoch 121: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2044 - accuracy: 0.9190 - val_loss: 0.3266 - val_accuracy: 0.8762\n",
      "Epoch 122/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2029 - accuracy: 0.9167\n",
      "Epoch 122: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2012 - accuracy: 0.9175 - val_loss: 0.3498 - val_accuracy: 0.8700\n",
      "Epoch 123/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2416 - accuracy: 0.9032\n",
      "Epoch 123: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2054 - accuracy: 0.9167 - val_loss: 0.3338 - val_accuracy: 0.8662\n",
      "Epoch 124/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2025 - accuracy: 0.9223\n",
      "Epoch 124: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2020 - accuracy: 0.9225 - val_loss: 0.3207 - val_accuracy: 0.8715\n",
      "Epoch 125/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1904 - accuracy: 0.9274\n",
      "Epoch 125: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2090 - accuracy: 0.9190 - val_loss: 0.3362 - val_accuracy: 0.8700\n",
      "Epoch 126/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2007 - accuracy: 0.9211\n",
      "Epoch 126: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1993 - accuracy: 0.9213 - val_loss: 0.3450 - val_accuracy: 0.8731\n",
      "Epoch 127/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2108 - accuracy: 0.9173\n",
      "Epoch 127: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2108 - accuracy: 0.9173 - val_loss: 0.3354 - val_accuracy: 0.8577\n",
      "Epoch 128/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2497 - accuracy: 0.8871\n",
      "Epoch 128: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2041 - accuracy: 0.9200 - val_loss: 0.3315 - val_accuracy: 0.8692\n",
      "Epoch 129/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2574 - accuracy: 0.8871\n",
      "Epoch 129: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1914 - accuracy: 0.9253 - val_loss: 0.3223 - val_accuracy: 0.8662\n",
      "Epoch 130/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1930 - accuracy: 0.9234\n",
      "Epoch 130: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1932 - accuracy: 0.9234 - val_loss: 0.3257 - val_accuracy: 0.8692\n",
      "Epoch 131/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1764 - accuracy: 0.9355\n",
      "Epoch 131: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1955 - accuracy: 0.9269 - val_loss: 0.3444 - val_accuracy: 0.8715\n",
      "Epoch 132/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1329 - accuracy: 0.9516\n",
      "Epoch 132: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1939 - accuracy: 0.9242 - val_loss: 0.3227 - val_accuracy: 0.8654\n",
      "Epoch 133/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2146 - accuracy: 0.9194\n",
      "Epoch 133: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1907 - accuracy: 0.9284 - val_loss: 0.3492 - val_accuracy: 0.8677\n",
      "Epoch 134/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1952 - accuracy: 0.9233\n",
      "Epoch 134: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1954 - accuracy: 0.9230 - val_loss: 0.3349 - val_accuracy: 0.8700\n",
      "Epoch 135/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1834 - accuracy: 0.9274\n",
      "Epoch 135: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2000 - accuracy: 0.9194 - val_loss: 0.3302 - val_accuracy: 0.8646\n",
      "Epoch 136/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1925 - accuracy: 0.9233\n",
      "Epoch 136: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1913 - accuracy: 0.9240 - val_loss: 0.3443 - val_accuracy: 0.8685\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2325 - accuracy: 0.9113\n",
      "Epoch 137: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1941 - accuracy: 0.9250 - val_loss: 0.3360 - val_accuracy: 0.8700\n",
      "Epoch 138/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1438 - accuracy: 0.9516\n",
      "Epoch 138: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1881 - accuracy: 0.9259 - val_loss: 0.3730 - val_accuracy: 0.8577\n",
      "Epoch 139/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2723 - accuracy: 0.8871\n",
      "Epoch 139: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2079 - accuracy: 0.9169 - val_loss: 0.3601 - val_accuracy: 0.8638\n",
      "Epoch 140/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2297 - accuracy: 0.8790\n",
      "Epoch 140: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2338 - accuracy: 0.9032 - val_loss: 0.3601 - val_accuracy: 0.8654\n",
      "Epoch 141/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2109 - accuracy: 0.9032\n",
      "Epoch 141: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.9246 - val_loss: 0.3378 - val_accuracy: 0.8708\n",
      "Epoch 142/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1893 - accuracy: 0.9272\n",
      "Epoch 142: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1841 - accuracy: 0.9290 - val_loss: 0.3325 - val_accuracy: 0.8692\n",
      "Epoch 143/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1881 - accuracy: 0.9252\n",
      "Epoch 143: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.9271 - val_loss: 0.3470 - val_accuracy: 0.8638\n",
      "Epoch 144/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2756 - accuracy: 0.8790\n",
      "Epoch 144: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2098 - accuracy: 0.9144 - val_loss: 0.3447 - val_accuracy: 0.8638\n",
      "Epoch 145/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2087 - accuracy: 0.9141\n",
      "Epoch 145: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2073 - accuracy: 0.9150 - val_loss: 0.3312 - val_accuracy: 0.8692\n",
      "Epoch 146/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1567 - accuracy: 0.9597\n",
      "Epoch 146: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1982 - accuracy: 0.9209 - val_loss: 0.3457 - val_accuracy: 0.8685\n",
      "Epoch 147/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1930 - accuracy: 0.9242\n",
      "Epoch 147: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1953 - accuracy: 0.9225 - val_loss: 0.3336 - val_accuracy: 0.8654\n",
      "Epoch 148/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1248 - accuracy: 0.9758\n",
      "Epoch 148: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1902 - accuracy: 0.9267 - val_loss: 0.3475 - val_accuracy: 0.8638\n",
      "Epoch 149/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1583 - accuracy: 0.9194\n",
      "Epoch 149: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1861 - accuracy: 0.9269 - val_loss: 0.3539 - val_accuracy: 0.8592\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1629 - accuracy: 0.9355\n",
      "Epoch 150: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1895 - accuracy: 0.9259 - val_loss: 0.3629 - val_accuracy: 0.8669\n",
      "Epoch 151/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.1852 - accuracy: 0.9290\n",
      "Epoch 151: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9288 - val_loss: 0.3500 - val_accuracy: 0.8685\n",
      "Epoch 152/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1936 - accuracy: 0.9227\n",
      "Epoch 152: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1915 - accuracy: 0.9240 - val_loss: 0.3396 - val_accuracy: 0.8731\n",
      "Epoch 153/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1652 - accuracy: 0.9435\n",
      "Epoch 153: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9271 - val_loss: 0.3375 - val_accuracy: 0.8646\n",
      "Epoch 154/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1849 - accuracy: 0.9261\n",
      "Epoch 154: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.9277 - val_loss: 0.3513 - val_accuracy: 0.8662\n",
      "Epoch 155/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1803 - accuracy: 0.9323\n",
      "Epoch 155: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.9328 - val_loss: 0.3581 - val_accuracy: 0.8669\n",
      "Epoch 156/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1836 - accuracy: 0.9194\n",
      "Epoch 156: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.9280 - val_loss: 0.3437 - val_accuracy: 0.8731\n",
      "Epoch 157/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1819 - accuracy: 0.9326\n",
      "Epoch 157: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.9325 - val_loss: 0.3505 - val_accuracy: 0.8623\n",
      "Epoch 158/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1803 - accuracy: 0.9311\n",
      "Epoch 158: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.9296 - val_loss: 0.3524 - val_accuracy: 0.8562\n",
      "Epoch 159/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2344 - accuracy: 0.9355\n",
      "Epoch 159: val_accuracy did not improve from 0.88308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1858 - accuracy: 0.9259 - val_loss: 0.3560 - val_accuracy: 0.8700\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Epoch 1/1000\n",
      " 1/42 [..............................] - ETA: 22s - loss: 4.6275 - accuracy: 0.5887\n",
      "Epoch 1: val_accuracy improved from -inf to 0.59154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 1.0668 - accuracy: 0.5445 - val_loss: 0.6828 - val_accuracy: 0.5915\n",
      "Epoch 2/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.5789 - accuracy: 0.6990\n",
      "Epoch 2: val_accuracy improved from 0.59154 to 0.74462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5769 - accuracy: 0.7019 - val_loss: 0.5337 - val_accuracy: 0.7446\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.4544 - accuracy: 0.8116\n",
      "Epoch 3: val_accuracy improved from 0.74462 to 0.82000, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.8116 - val_loss: 0.4189 - val_accuracy: 0.8200\n",
      "Epoch 4/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3974 - accuracy: 0.8419\n",
      "Epoch 4: val_accuracy improved from 0.82000 to 0.84692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3980 - accuracy: 0.8418 - val_loss: 0.3740 - val_accuracy: 0.8469\n",
      "Epoch 5/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3679 - accuracy: 0.8513\n",
      "Epoch 5: val_accuracy improved from 0.84692 to 0.84846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3670 - accuracy: 0.8522 - val_loss: 0.3607 - val_accuracy: 0.8485\n",
      "Epoch 6/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.3484 - accuracy: 0.8627\n",
      "Epoch 6: val_accuracy did not improve from 0.84846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3475 - accuracy: 0.8617 - val_loss: 0.3540 - val_accuracy: 0.8477\n",
      "Epoch 7/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3139 - accuracy: 0.8629\n",
      "Epoch 7: val_accuracy improved from 0.84846 to 0.85538, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3520 - accuracy: 0.8543 - val_loss: 0.3409 - val_accuracy: 0.8554\n",
      "Epoch 8/1000\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.3260 - accuracy: 0.8687\n",
      "Epoch 8: val_accuracy did not improve from 0.85538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8632 - val_loss: 0.3338 - val_accuracy: 0.8546\n",
      "Epoch 9/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3187 - accuracy: 0.8629\n",
      "Epoch 9: val_accuracy did not improve from 0.85538\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8668 - val_loss: 0.3428 - val_accuracy: 0.8454\n",
      "Epoch 10/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3033 - accuracy: 0.8306\n",
      "Epoch 10: val_accuracy improved from 0.85538 to 0.85692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.8626 - val_loss: 0.3451 - val_accuracy: 0.8569\n",
      "Epoch 11/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.3185 - accuracy: 0.8722\n",
      "Epoch 11: val_accuracy improved from 0.85692 to 0.85923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3182 - accuracy: 0.8717 - val_loss: 0.3370 - val_accuracy: 0.8592\n",
      "Epoch 12/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2927 - accuracy: 0.8548\n",
      "Epoch 12: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8680 - val_loss: 0.3248 - val_accuracy: 0.8592\n",
      "Epoch 13/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2498 - accuracy: 0.9113\n",
      "Epoch 13: val_accuracy did not improve from 0.85923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8688 - val_loss: 0.3711 - val_accuracy: 0.8338\n",
      "Epoch 14/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3412 - accuracy: 0.8468\n",
      "Epoch 14: val_accuracy improved from 0.85923 to 0.86077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8576 - val_loss: 0.3230 - val_accuracy: 0.8608\n",
      "Epoch 15/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2643 - accuracy: 0.9113\n",
      "Epoch 15: val_accuracy improved from 0.86077 to 0.86385, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3059 - accuracy: 0.8738 - val_loss: 0.3228 - val_accuracy: 0.8638\n",
      "Epoch 16/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2649 - accuracy: 0.8952\n",
      "Epoch 16: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.8686 - val_loss: 0.3226 - val_accuracy: 0.8623\n",
      "Epoch 17/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2257 - accuracy: 0.9032\n",
      "Epoch 17: val_accuracy did not improve from 0.86385\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8699 - val_loss: 0.3291 - val_accuracy: 0.8554\n",
      "Epoch 18/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2859 - accuracy: 0.8790\n",
      "Epoch 18: val_accuracy improved from 0.86385 to 0.86462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.8745 - val_loss: 0.3190 - val_accuracy: 0.8646\n",
      "Epoch 19/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2989 - accuracy: 0.8765\n",
      "Epoch 19: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3016 - accuracy: 0.8744 - val_loss: 0.3292 - val_accuracy: 0.8577\n",
      "Epoch 20/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3312 - accuracy: 0.8710\n",
      "Epoch 20: val_accuracy did not improve from 0.86462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2961 - accuracy: 0.8769 - val_loss: 0.3251 - val_accuracy: 0.8615\n",
      "Epoch 21/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2942 - accuracy: 0.8774\n",
      "Epoch 21: val_accuracy improved from 0.86462 to 0.86846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2928 - accuracy: 0.8784 - val_loss: 0.3164 - val_accuracy: 0.8685\n",
      "Epoch 22/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.3074 - accuracy: 0.8718\n",
      "Epoch 22: val_accuracy did not improve from 0.86846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8722 - val_loss: 0.3513 - val_accuracy: 0.8408\n",
      "Epoch 23/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2934 - accuracy: 0.8788\n",
      "Epoch 23: val_accuracy did not improve from 0.86846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2927 - accuracy: 0.8782 - val_loss: 0.3214 - val_accuracy: 0.8646\n",
      "Epoch 24/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2882 - accuracy: 0.8548\n",
      "Epoch 24: val_accuracy did not improve from 0.86846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2885 - accuracy: 0.8813 - val_loss: 0.3172 - val_accuracy: 0.8677\n",
      "Epoch 25/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2918 - accuracy: 0.8779\n",
      "Epoch 25: val_accuracy improved from 0.86846 to 0.87231, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2897 - accuracy: 0.8797 - val_loss: 0.3169 - val_accuracy: 0.8723\n",
      "Epoch 26/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3383 - accuracy: 0.8468\n",
      "Epoch 26: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.8838 - val_loss: 0.3340 - val_accuracy: 0.8546\n",
      "Epoch 27/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.4578 - accuracy: 0.7903\n",
      "Epoch 27: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2890 - accuracy: 0.8801 - val_loss: 0.3325 - val_accuracy: 0.8531\n",
      "Epoch 28/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3287 - accuracy: 0.8468\n",
      "Epoch 28: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2824 - accuracy: 0.8845 - val_loss: 0.3063 - val_accuracy: 0.8708\n",
      "Epoch 29/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2777 - accuracy: 0.8871\n",
      "Epoch 29: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2762 - accuracy: 0.8851 - val_loss: 0.3158 - val_accuracy: 0.8715\n",
      "Epoch 30/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2948 - accuracy: 0.8790\n",
      "Epoch 30: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2792 - accuracy: 0.8807 - val_loss: 0.3199 - val_accuracy: 0.8708\n",
      "Epoch 31/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2735 - accuracy: 0.9113\n",
      "Epoch 31: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2760 - accuracy: 0.8863 - val_loss: 0.3108 - val_accuracy: 0.8631\n",
      "Epoch 32/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2777 - accuracy: 0.8830\n",
      "Epoch 32: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2777 - accuracy: 0.8838 - val_loss: 0.3165 - val_accuracy: 0.8638\n",
      "Epoch 33/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3392 - accuracy: 0.8710\n",
      "Epoch 33: val_accuracy did not improve from 0.87231\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2746 - accuracy: 0.8890 - val_loss: 0.3325 - val_accuracy: 0.8592\n",
      "Epoch 34/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2835 - accuracy: 0.8848\n",
      "Epoch 34: val_accuracy improved from 0.87231 to 0.87308, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2837 - accuracy: 0.8842 - val_loss: 0.3039 - val_accuracy: 0.8731\n",
      "Epoch 35/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2412 - accuracy: 0.9113\n",
      "Epoch 35: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2712 - accuracy: 0.8872 - val_loss: 0.3022 - val_accuracy: 0.8715\n",
      "Epoch 36/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2756 - accuracy: 0.8864\n",
      "Epoch 36: val_accuracy did not improve from 0.87308\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2757 - accuracy: 0.8874 - val_loss: 0.3582 - val_accuracy: 0.8469\n",
      "Epoch 37/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3413 - accuracy: 0.8387\n",
      "Epoch 37: val_accuracy improved from 0.87308 to 0.87462, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2672 - accuracy: 0.8876 - val_loss: 0.2989 - val_accuracy: 0.8746\n",
      "Epoch 38/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.2607 - accuracy: 0.8956\n",
      "Epoch 38: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2664 - accuracy: 0.8922 - val_loss: 0.3022 - val_accuracy: 0.8746\n",
      "Epoch 39/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2264 - accuracy: 0.9032\n",
      "Epoch 39: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2653 - accuracy: 0.8915 - val_loss: 0.2996 - val_accuracy: 0.8738\n",
      "Epoch 40/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1585 - accuracy: 0.9516\n",
      "Epoch 40: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2658 - accuracy: 0.8886 - val_loss: 0.2989 - val_accuracy: 0.8731\n",
      "Epoch 41/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2240 - accuracy: 0.8952\n",
      "Epoch 41: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2607 - accuracy: 0.8922 - val_loss: 0.3000 - val_accuracy: 0.8746\n",
      "Epoch 42/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2821 - accuracy: 0.8952\n",
      "Epoch 42: val_accuracy did not improve from 0.87462\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2763 - accuracy: 0.8842 - val_loss: 0.3211 - val_accuracy: 0.8623\n",
      "Epoch 43/1000\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.2683 - accuracy: 0.8861\n",
      "Epoch 43: val_accuracy improved from 0.87462 to 0.87615, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2618 - accuracy: 0.8913 - val_loss: 0.2964 - val_accuracy: 0.8762\n",
      "Epoch 44/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2477 - accuracy: 0.9032\n",
      "Epoch 44: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2736 - accuracy: 0.8851 - val_loss: 0.3162 - val_accuracy: 0.8700\n",
      "Epoch 45/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2646 - accuracy: 0.9274\n",
      "Epoch 45: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2592 - accuracy: 0.8932 - val_loss: 0.2925 - val_accuracy: 0.8754\n",
      "Epoch 46/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3262 - accuracy: 0.8952\n",
      "Epoch 46: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 0.8932 - val_loss: 0.3075 - val_accuracy: 0.8677\n",
      "Epoch 47/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2628 - accuracy: 0.8896\n",
      "Epoch 47: val_accuracy did not improve from 0.87615\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2612 - accuracy: 0.8903 - val_loss: 0.2968 - val_accuracy: 0.8754\n",
      "Epoch 48/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3477 - accuracy: 0.8629\n",
      "Epoch 48: val_accuracy improved from 0.87615 to 0.87692, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 0.8911 - val_loss: 0.3028 - val_accuracy: 0.8769\n",
      "Epoch 49/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2528 - accuracy: 0.8956\n",
      "Epoch 49: val_accuracy did not improve from 0.87692\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2519 - accuracy: 0.8965 - val_loss: 0.3038 - val_accuracy: 0.8754\n",
      "Epoch 50/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2111 - accuracy: 0.9032\n",
      "Epoch 50: val_accuracy improved from 0.87692 to 0.87846, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2600 - accuracy: 0.8942 - val_loss: 0.2911 - val_accuracy: 0.8785\n",
      "Epoch 51/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2031 - accuracy: 0.9113\n",
      "Epoch 51: val_accuracy did not improve from 0.87846\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2602 - accuracy: 0.8880 - val_loss: 0.3588 - val_accuracy: 0.8523\n",
      "Epoch 52/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2688 - accuracy: 0.8862\n",
      "Epoch 52: val_accuracy improved from 0.87846 to 0.87923, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2659 - accuracy: 0.8876 - val_loss: 0.2896 - val_accuracy: 0.8792\n",
      "Epoch 53/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2217 - accuracy: 0.8952\n",
      "Epoch 53: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.8942 - val_loss: 0.2908 - val_accuracy: 0.8762\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2451 - accuracy: 0.8984\n",
      "Epoch 54: val_accuracy did not improve from 0.87923\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8984 - val_loss: 0.2941 - val_accuracy: 0.8777\n",
      "Epoch 55/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1969 - accuracy: 0.9274\n",
      "Epoch 55: val_accuracy improved from 0.87923 to 0.88077, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.9007 - val_loss: 0.2929 - val_accuracy: 0.8808\n",
      "Epoch 56/1000\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.2361 - accuracy: 0.9034\n",
      "Epoch 56: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.9003 - val_loss: 0.3660 - val_accuracy: 0.8400\n",
      "Epoch 57/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3792 - accuracy: 0.8226\n",
      "Epoch 57: val_accuracy did not improve from 0.88077\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2700 - accuracy: 0.8869 - val_loss: 0.2993 - val_accuracy: 0.8800\n",
      "Epoch 58/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3107 - accuracy: 0.8468\n",
      "Epoch 58: val_accuracy improved from 0.88077 to 0.88154, saving model to best_model_weights2.weights.h5\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.9009 - val_loss: 0.2914 - val_accuracy: 0.8815\n",
      "Epoch 59/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2173 - accuracy: 0.9194\n",
      "Epoch 59: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2424 - accuracy: 0.9007 - val_loss: 0.2950 - val_accuracy: 0.8746\n",
      "Epoch 60/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2297 - accuracy: 0.9113\n",
      "Epoch 60: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2430 - accuracy: 0.9011 - val_loss: 0.2967 - val_accuracy: 0.8777\n",
      "Epoch 61/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2820 - accuracy: 0.8629\n",
      "Epoch 61: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.8965 - val_loss: 0.2962 - val_accuracy: 0.8785\n",
      "Epoch 62/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2390 - accuracy: 0.9051\n",
      "Epoch 62: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2394 - accuracy: 0.9030 - val_loss: 0.2968 - val_accuracy: 0.8723\n",
      "Epoch 63/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2504 - accuracy: 0.8971\n",
      "Epoch 63: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.8971 - val_loss: 0.2979 - val_accuracy: 0.8792\n",
      "Epoch 64/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2579 - accuracy: 0.9032\n",
      "Epoch 64: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2405 - accuracy: 0.9026 - val_loss: 0.2942 - val_accuracy: 0.8762\n",
      "Epoch 65/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1733 - accuracy: 0.9274\n",
      "Epoch 65: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2591 - accuracy: 0.8869 - val_loss: 0.3221 - val_accuracy: 0.8669\n",
      "Epoch 66/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2139 - accuracy: 0.8952\n",
      "Epoch 66: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.9001 - val_loss: 0.2924 - val_accuracy: 0.8815\n",
      "Epoch 67/1000\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.2344 - accuracy: 0.9051\n",
      "Epoch 67: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2346 - accuracy: 0.9046 - val_loss: 0.2953 - val_accuracy: 0.8777\n",
      "Epoch 68/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2426 - accuracy: 0.8964\n",
      "Epoch 68: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2417 - accuracy: 0.8961 - val_loss: 0.3066 - val_accuracy: 0.8746\n",
      "Epoch 69/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2890 - accuracy: 0.8629\n",
      "Epoch 69: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2391 - accuracy: 0.9019 - val_loss: 0.2959 - val_accuracy: 0.8769\n",
      "Epoch 70/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3033 - accuracy: 0.8710\n",
      "Epoch 70: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2371 - accuracy: 0.9011 - val_loss: 0.2990 - val_accuracy: 0.8777\n",
      "Epoch 71/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2914 - accuracy: 0.8790\n",
      "Epoch 71: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2365 - accuracy: 0.9021 - val_loss: 0.2938 - val_accuracy: 0.8792\n",
      "Epoch 72/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2913 - accuracy: 0.8790\n",
      "Epoch 72: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2397 - accuracy: 0.9015 - val_loss: 0.3358 - val_accuracy: 0.8631\n",
      "Epoch 73/1000\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.2643 - accuracy: 0.8881\n",
      "Epoch 73: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2561 - accuracy: 0.8917 - val_loss: 0.3027 - val_accuracy: 0.8746\n",
      "Epoch 74/1000\n",
      "27/42 [==================>...........] - ETA: 0s - loss: 0.2304 - accuracy: 0.9044\n",
      "Epoch 74: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2345 - accuracy: 0.9032 - val_loss: 0.3042 - val_accuracy: 0.8700\n",
      "Epoch 75/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2215 - accuracy: 0.9194\n",
      "Epoch 75: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 0.9040 - val_loss: 0.2922 - val_accuracy: 0.8815\n",
      "Epoch 76/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2341 - accuracy: 0.9049\n",
      "Epoch 76: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2341 - accuracy: 0.9049 - val_loss: 0.2950 - val_accuracy: 0.8808\n",
      "Epoch 77/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2394 - accuracy: 0.9032\n",
      "Epoch 77: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2314 - accuracy: 0.9071 - val_loss: 0.3481 - val_accuracy: 0.8546\n",
      "Epoch 78/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2480 - accuracy: 0.9032\n",
      "Epoch 78: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2406 - accuracy: 0.9051 - val_loss: 0.3030 - val_accuracy: 0.8808\n",
      "Epoch 79/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2150 - accuracy: 0.9274\n",
      "Epoch 79: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2315 - accuracy: 0.9059 - val_loss: 0.3302 - val_accuracy: 0.8723\n",
      "Epoch 80/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2363 - accuracy: 0.9028\n",
      "Epoch 80: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2362 - accuracy: 0.9026 - val_loss: 0.3237 - val_accuracy: 0.8646\n",
      "Epoch 81/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2414 - accuracy: 0.9034\n",
      "Epoch 81: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2417 - accuracy: 0.9030 - val_loss: 0.3427 - val_accuracy: 0.8592\n",
      "Epoch 82/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1922 - accuracy: 0.8952\n",
      "Epoch 82: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2385 - accuracy: 0.8999 - val_loss: 0.3151 - val_accuracy: 0.8723\n",
      "Epoch 83/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2294 - accuracy: 0.9072\n",
      "Epoch 83: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2286 - accuracy: 0.9078 - val_loss: 0.2981 - val_accuracy: 0.8762\n",
      "Epoch 84/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1958 - accuracy: 0.9516\n",
      "Epoch 84: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2309 - accuracy: 0.9053 - val_loss: 0.3173 - val_accuracy: 0.8738\n",
      "Epoch 85/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1579 - accuracy: 0.9435\n",
      "Epoch 85: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.8921 - val_loss: 0.3032 - val_accuracy: 0.8708\n",
      "Epoch 86/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2426 - accuracy: 0.9032\n",
      "Epoch 86: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2373 - accuracy: 0.9026 - val_loss: 0.2976 - val_accuracy: 0.8777\n",
      "Epoch 87/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2438 - accuracy: 0.9113\n",
      "Epoch 87: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2392 - accuracy: 0.9017 - val_loss: 0.3275 - val_accuracy: 0.8669\n",
      "Epoch 88/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2355 - accuracy: 0.9113\n",
      "Epoch 88: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2206 - accuracy: 0.9107 - val_loss: 0.3142 - val_accuracy: 0.8785\n",
      "Epoch 89/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2224 - accuracy: 0.9094\n",
      "Epoch 89: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2254 - accuracy: 0.9067 - val_loss: 0.3040 - val_accuracy: 0.8754\n",
      "Epoch 90/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2216 - accuracy: 0.9067\n",
      "Epoch 90: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.9071 - val_loss: 0.3032 - val_accuracy: 0.8723\n",
      "Epoch 91/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2256 - accuracy: 0.9083\n",
      "Epoch 91: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2277 - accuracy: 0.9080 - val_loss: 0.3087 - val_accuracy: 0.8777\n",
      "Epoch 92/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2169 - accuracy: 0.9152\n",
      "Epoch 92: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2189 - accuracy: 0.9144 - val_loss: 0.3536 - val_accuracy: 0.8585\n",
      "Epoch 93/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2471 - accuracy: 0.8974\n",
      "Epoch 93: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8988 - val_loss: 0.3453 - val_accuracy: 0.8631\n",
      "Epoch 94/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2403 - accuracy: 0.8982\n",
      "Epoch 94: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2391 - accuracy: 0.8996 - val_loss: 0.3213 - val_accuracy: 0.8746\n",
      "Epoch 95/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2247 - accuracy: 0.9030\n",
      "Epoch 95: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2247 - accuracy: 0.9030 - val_loss: 0.3308 - val_accuracy: 0.8585\n",
      "Epoch 96/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2286 - accuracy: 0.8871\n",
      "Epoch 96: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2215 - accuracy: 0.9082 - val_loss: 0.3021 - val_accuracy: 0.8715\n",
      "Epoch 97/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2197 - accuracy: 0.9101\n",
      "Epoch 97: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2197 - accuracy: 0.9101 - val_loss: 0.3076 - val_accuracy: 0.8708\n",
      "Epoch 98/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2147 - accuracy: 0.9109\n",
      "Epoch 98: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2165 - accuracy: 0.9115 - val_loss: 0.3191 - val_accuracy: 0.8769\n",
      "Epoch 99/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2194 - accuracy: 0.9119\n",
      "Epoch 99: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2194 - accuracy: 0.9119 - val_loss: 0.3067 - val_accuracy: 0.8754\n",
      "Epoch 100/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2179 - accuracy: 0.9107\n",
      "Epoch 100: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2179 - accuracy: 0.9107 - val_loss: 0.3122 - val_accuracy: 0.8723\n",
      "Epoch 101/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2187 - accuracy: 0.9084\n",
      "Epoch 101: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2187 - accuracy: 0.9084 - val_loss: 0.3155 - val_accuracy: 0.8723\n",
      "Epoch 102/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2119 - accuracy: 0.9113\n",
      "Epoch 102: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2208 - accuracy: 0.9063 - val_loss: 0.3067 - val_accuracy: 0.8777\n",
      "Epoch 103/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2216 - accuracy: 0.8952\n",
      "Epoch 103: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2216 - accuracy: 0.9069 - val_loss: 0.3138 - val_accuracy: 0.8685\n",
      "Epoch 104/1000\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.2129 - accuracy: 0.9147\n",
      "Epoch 104: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2121 - accuracy: 0.9146 - val_loss: 0.3135 - val_accuracy: 0.8700\n",
      "Epoch 105/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2074 - accuracy: 0.9158\n",
      "Epoch 105: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2061 - accuracy: 0.9165 - val_loss: 0.3188 - val_accuracy: 0.8669\n",
      "Epoch 106/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2115 - accuracy: 0.9136\n",
      "Epoch 106: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2100 - accuracy: 0.9136 - val_loss: 0.3205 - val_accuracy: 0.8685\n",
      "Epoch 107/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3047 - accuracy: 0.8710\n",
      "Epoch 107: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2141 - accuracy: 0.9132 - val_loss: 0.3096 - val_accuracy: 0.8723\n",
      "Epoch 108/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2163 - accuracy: 0.9119\n",
      "Epoch 108: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2169 - accuracy: 0.9113 - val_loss: 0.3437 - val_accuracy: 0.8692\n",
      "Epoch 109/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2308 - accuracy: 0.9017\n",
      "Epoch 109: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2262 - accuracy: 0.9057 - val_loss: 0.3196 - val_accuracy: 0.8731\n",
      "Epoch 110/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1808 - accuracy: 0.9516\n",
      "Epoch 110: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.9163 - val_loss: 0.3061 - val_accuracy: 0.8692\n",
      "Epoch 111/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2132 - accuracy: 0.8952\n",
      "Epoch 111: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2119 - accuracy: 0.9115 - val_loss: 0.3452 - val_accuracy: 0.8615\n",
      "Epoch 112/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2140 - accuracy: 0.9100\n",
      "Epoch 112: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2143 - accuracy: 0.9105 - val_loss: 0.3323 - val_accuracy: 0.8654\n",
      "Epoch 113/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1945 - accuracy: 0.9194\n",
      "Epoch 113: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2192 - accuracy: 0.9084 - val_loss: 0.3217 - val_accuracy: 0.8708\n",
      "Epoch 114/1000\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.2084 - accuracy: 0.9100\n",
      "Epoch 114: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2064 - accuracy: 0.9123 - val_loss: 0.3174 - val_accuracy: 0.8777\n",
      "Epoch 115/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1989 - accuracy: 0.9201\n",
      "Epoch 115: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1989 - accuracy: 0.9201 - val_loss: 0.3271 - val_accuracy: 0.8715\n",
      "Epoch 116/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1956 - accuracy: 0.9032\n",
      "Epoch 116: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2019 - accuracy: 0.9175 - val_loss: 0.3285 - val_accuracy: 0.8754\n",
      "Epoch 117/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2763 - accuracy: 0.8548\n",
      "Epoch 117: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2036 - accuracy: 0.9173 - val_loss: 0.3230 - val_accuracy: 0.8723\n",
      "Epoch 118/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1884 - accuracy: 0.9274\n",
      "Epoch 118: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2039 - accuracy: 0.9169 - val_loss: 0.3177 - val_accuracy: 0.8692\n",
      "Epoch 119/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2024 - accuracy: 0.9274\n",
      "Epoch 119: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2006 - accuracy: 0.9184 - val_loss: 0.3163 - val_accuracy: 0.8738\n",
      "Epoch 120/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2057 - accuracy: 0.9183\n",
      "Epoch 120: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.9192 - val_loss: 0.3256 - val_accuracy: 0.8738\n",
      "Epoch 121/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.2094 - accuracy: 0.9137\n",
      "Epoch 121: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2101 - accuracy: 0.9130 - val_loss: 0.3394 - val_accuracy: 0.8654\n",
      "Epoch 122/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2090 - accuracy: 0.9165\n",
      "Epoch 122: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2098 - accuracy: 0.9167 - val_loss: 0.3367 - val_accuracy: 0.8646\n",
      "Epoch 123/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.3424 - accuracy: 0.8548\n",
      "Epoch 123: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2020 - accuracy: 0.9159 - val_loss: 0.3395 - val_accuracy: 0.8700\n",
      "Epoch 124/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1794 - accuracy: 0.9435\n",
      "Epoch 124: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2042 - accuracy: 0.9192 - val_loss: 0.3333 - val_accuracy: 0.8692\n",
      "Epoch 125/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1947 - accuracy: 0.9223\n",
      "Epoch 125: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1947 - accuracy: 0.9223 - val_loss: 0.3383 - val_accuracy: 0.8708\n",
      "Epoch 126/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1446 - accuracy: 0.9435\n",
      "Epoch 126: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2010 - accuracy: 0.9176 - val_loss: 0.3164 - val_accuracy: 0.8723\n",
      "Epoch 127/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.2083 - accuracy: 0.9153\n",
      "Epoch 127: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2078 - accuracy: 0.9146 - val_loss: 0.3246 - val_accuracy: 0.8723\n",
      "Epoch 128/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1769 - accuracy: 0.9435\n",
      "Epoch 128: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2057 - accuracy: 0.9132 - val_loss: 0.3520 - val_accuracy: 0.8677\n",
      "Epoch 129/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2256 - accuracy: 0.8952\n",
      "Epoch 129: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1992 - accuracy: 0.9207 - val_loss: 0.3227 - val_accuracy: 0.8677\n",
      "Epoch 130/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1871 - accuracy: 0.9264\n",
      "Epoch 130: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1887 - accuracy: 0.9257 - val_loss: 0.3460 - val_accuracy: 0.8777\n",
      "Epoch 131/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1996 - accuracy: 0.9435\n",
      "Epoch 131: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1955 - accuracy: 0.9211 - val_loss: 0.3160 - val_accuracy: 0.8669\n",
      "Epoch 132/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1951 - accuracy: 0.9180\n",
      "Epoch 132: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1951 - accuracy: 0.9180 - val_loss: 0.3353 - val_accuracy: 0.8692\n",
      "Epoch 133/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1898 - accuracy: 0.9274\n",
      "Epoch 133: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.9186 - val_loss: 0.3254 - val_accuracy: 0.8738\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1946 - accuracy: 0.9234\n",
      "Epoch 134: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1946 - accuracy: 0.9234 - val_loss: 0.3633 - val_accuracy: 0.8577\n",
      "Epoch 135/1000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.1887 - accuracy: 0.9222\n",
      "Epoch 135: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.9226 - val_loss: 0.3401 - val_accuracy: 0.8685\n",
      "Epoch 136/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1323 - accuracy: 0.9516\n",
      "Epoch 136: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1902 - accuracy: 0.9221 - val_loss: 0.3458 - val_accuracy: 0.8723\n",
      "Epoch 137/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1594 - accuracy: 0.9113\n",
      "Epoch 137: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.9242 - val_loss: 0.3718 - val_accuracy: 0.8654\n",
      "Epoch 138/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1999 - accuracy: 0.9161\n",
      "Epoch 138: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1991 - accuracy: 0.9161 - val_loss: 0.3370 - val_accuracy: 0.8692\n",
      "Epoch 139/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1851 - accuracy: 0.9113\n",
      "Epoch 139: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1896 - accuracy: 0.9215 - val_loss: 0.3447 - val_accuracy: 0.8685\n",
      "Epoch 140/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1840 - accuracy: 0.9233\n",
      "Epoch 140: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1828 - accuracy: 0.9240 - val_loss: 0.3348 - val_accuracy: 0.8723\n",
      "Epoch 141/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1541 - accuracy: 0.9355\n",
      "Epoch 141: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1812 - accuracy: 0.9311 - val_loss: 0.3391 - val_accuracy: 0.8715\n",
      "Epoch 142/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1676 - accuracy: 0.9597\n",
      "Epoch 142: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.9217 - val_loss: 0.3442 - val_accuracy: 0.8700\n",
      "Epoch 143/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.2323 - accuracy: 0.9194\n",
      "Epoch 143: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2036 - accuracy: 0.9155 - val_loss: 0.3774 - val_accuracy: 0.8592\n",
      "Epoch 144/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1431 - accuracy: 0.9516\n",
      "Epoch 144: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1934 - accuracy: 0.9211 - val_loss: 0.3732 - val_accuracy: 0.8638\n",
      "Epoch 145/1000\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1880 - accuracy: 0.9244\n",
      "Epoch 145: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.9251 - val_loss: 0.3623 - val_accuracy: 0.8623\n",
      "Epoch 146/1000\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1840 - accuracy: 0.9258\n",
      "Epoch 146: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1831 - accuracy: 0.9263 - val_loss: 0.3447 - val_accuracy: 0.8615\n",
      "Epoch 147/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1885 - accuracy: 0.9113\n",
      "Epoch 147: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1859 - accuracy: 0.9219 - val_loss: 0.3311 - val_accuracy: 0.8646\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1847 - accuracy: 0.9228\n",
      "Epoch 148: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.9228 - val_loss: 0.3657 - val_accuracy: 0.8662\n",
      "Epoch 149/1000\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1801 - accuracy: 0.9265\n",
      "Epoch 149: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1826 - accuracy: 0.9250 - val_loss: 0.3708 - val_accuracy: 0.8654\n",
      "Epoch 150/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1574 - accuracy: 0.9435\n",
      "Epoch 150: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.9277 - val_loss: 0.3455 - val_accuracy: 0.8700\n",
      "Epoch 151/1000\n",
      " 1/42 [..............................] - ETA: 0s - loss: 0.1791 - accuracy: 0.9194\n",
      "Epoch 151: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1813 - accuracy: 0.9248 - val_loss: 0.3489 - val_accuracy: 0.8677\n",
      "Epoch 152/1000\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1821 - accuracy: 0.9265\n",
      "Epoch 152: val_accuracy did not improve from 0.88154\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.9265 - val_loss: 0.3774 - val_accuracy: 0.8631\n",
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    }
   ],
   "source": [
    "for fight in fights:\n",
    "    #define column headers for new df\n",
    "    column_headers = ['redCorner', 'blueCorner', 'winner', 'redCorner_wins', 'blueCorner_wins', 'redCorner_losses', \n",
    "                    'blueCorner_losses', 'redCorner_draws', 'blueCorner_draws', 'redCorner_age', 'blueCorner_age',\n",
    "                    'redCorner_nation', 'blueCorner_nation', 'redCorner_knockdowns', 'blueCorner_knockdowns',\n",
    "                    'redCorner_sig_str_percentage', 'blueCorner_sig_str_percentage', 'redCorner_takedowns',\n",
    "                    'blueCorner_takedowns', 'redCorner_takedown_percentage', 'blueCorner_takedown_percentage',\n",
    "                    'redCorner_subs_attempted', 'blueCorner_subs_attempted', 'redCorner_height', 'blueCorner_height',\n",
    "                    'redCorner_reach', 'blueCorner_reach', 'redCorner_stance', 'blueCorner_stance', 'redCorner_sig_str_landed_per_minute',\n",
    "                    'blueCorner_sig_str_landed_per_minute', 'redCorner_fightTime', 'blueCorner_fightTime', \n",
    "                    'redCorner_sig_str_absorbed_per_minute', 'blueCorner_sig_str_absorbed_per_minute', 'redCorner_sig_str_defense',\n",
    "                    'blueCorner_sig_str_defense', 'redCorner_takedown_defense', 'blueCorner_takedown_defense']\n",
    "\n",
    "    #Create a new DataFrame with the specified column headers\n",
    "    dfCustom = pd.DataFrame(columns=column_headers)\n",
    "\n",
    "\n",
    "    fighters = fight.split(' vs ')\n",
    "    fighter1 = str(fighters[0])\n",
    "    fighter2 = str(fighters[1])\n",
    "\n",
    "    #create custom input data\n",
    "    redCorner = np.nan\n",
    "    blueCorner = np.nan\n",
    "    winner = np.nan\n",
    "    redCorner_wins = np.nan\n",
    "    blueCorner_wins = np.nan\n",
    "    redCorner_losses = np.nan\n",
    "    blueCorner_losses = np.nan\n",
    "    redCorner_draws = np.nan\n",
    "    blueCorner_draws = np.nan\n",
    "    redCorner_age = np.nan\n",
    "    blueCorner_age = np.nan\n",
    "    redCorner_nation = np.nan\n",
    "    blueCorner_nation = np.nan\n",
    "    redCorner_knockdowns = np.nan\n",
    "    blueCorner_knockdowns = np.nan\n",
    "    redCorner_sig_str_percentage = np.nan\n",
    "    blueCorner_sig_str_percentage = np.nan\n",
    "    redCorner_takedowns = np.nan\n",
    "    blueCorner_takedowns = np.nan\n",
    "    redCorner_takedown_percentage = np.nan\n",
    "    blueCorner_takedown_percentage = np.nan\n",
    "    redCorner_subs_attempted = np.nan\n",
    "    blueCorner_subs_attempted = np.nan\n",
    "    redCorner_height = np.nan\n",
    "    blueCorner_height = np.nan\n",
    "    redCorner_reach = np.nan\n",
    "    blueCorner_reach = np.nan\n",
    "    redCorner_stance = np.nan\n",
    "    blueCorner_stance = np.nan\n",
    "    redCorner_sig_str_landed_per_minute = np.nan\n",
    "    blueCorner_sig_str_landed_per_minute = np.nan \n",
    "    redCorner_fightTime = np.nan\n",
    "    blueCorner_fightTime = np.nan\n",
    "    redCorner_sig_str_absorbed_per_minute = np.nan\n",
    "    blueCorner_sig_str_absorbed_per_minute = np.nan\n",
    "    redCorner_sig_str_defense = np.nan\n",
    "    blueCorner_sig_str_defense = np.nan\n",
    "    redCorner_takedown_defense = np.nan \n",
    "    blueCorner_takedown_defense = np.nan\n",
    "    if fighter1 in dfCareer['name'].values:\n",
    "        try:\n",
    "            indexCareer = dfCareer.index[dfCareer['name'] == fighter1].tolist()[0]\n",
    "            redCorner = dfCareer.at[indexCareer, 'name']\n",
    "            redCorner_wins = dfCareer.at[indexCareer, 'wins']\n",
    "            redCorner_losses = dfCareer.at[indexCareer, 'losses']\n",
    "            redCorner_draws = dfCareer.at[indexCareer, 'draws']\n",
    "            redCorner_age = dfCareer.at[indexCareer, 'age']\n",
    "            redCorner_nation = dfCareer.at[indexCareer, 'nation']\n",
    "            redCorner_knockdowns = dfCareer.at[indexCareer, 'knockdown_avg']\n",
    "            redCorner_sig_str_percentage = dfCareer.at[indexCareer, 'sig_str_accuracy']\n",
    "            redCorner_takedowns = dfCareer.at[indexCareer, 'takedown_average']\n",
    "            redCorner_takedown_percentage = dfCareer.at[indexCareer, 'takedown_accuracy']\n",
    "            redCorner_subs_attempted = dfCareer.at[indexCareer, 'subs_attempted_average']\n",
    "            redCorner_height = dfCareer.at[indexCareer, 'height']\n",
    "            redCorner_reach = dfCareer.at[indexCareer, 'reach']\n",
    "            redCorner_stance = dfCareer.at[indexCareer, 'stance']\n",
    "            redCorner_sig_str_landed_per_minute = dfCareer.at[indexCareer, 'sig_str_landed_per_min']\n",
    "            redCorner_fightTime = dfCareer.at[indexCareer, 'average_fight_time']\n",
    "            redCorner_sig_str_absorbed_per_minute = dfCareer.at[indexCareer, 'sig_str_absorbed_per_min']\n",
    "            redCorner_sig_str_defense = dfCareer.at[indexCareer, 'sig_str_defense']\n",
    "            redCorner_takedown_defense = dfCareer.at[indexCareer, 'takedown_defense']\n",
    "        except:\n",
    "            pass\n",
    "    if fighter2 in dfCareer['name'].values:\n",
    "        try:\n",
    "            indexCareer = dfCareer.index[dfCareer['name'] == fighter2].tolist()[0]\n",
    "            blueCorner = dfCareer.at[indexCareer, 'name']\n",
    "            blueCorner_wins = dfCareer.at[indexCareer, 'wins']\n",
    "            blueCorner_losses = dfCareer.at[indexCareer, 'losses']\n",
    "            blueCorner_draws = dfCareer.at[indexCareer, 'draws']\n",
    "            blueCorner_age = dfCareer.at[indexCareer, 'age']\n",
    "            blueCorner_nation = dfCareer.at[indexCareer, 'nation']\n",
    "            blueCorner_knockdowns = dfCareer.at[indexCareer, 'knockdown_avg']\n",
    "            blueCorner_sig_str_percentage = dfCareer.at[indexCareer, 'sig_str_accuracy']\n",
    "            blueCorner_takedowns = dfCareer.at[indexCareer, 'takedown_average']\n",
    "            blueCorner_takedown_percentage = dfCareer.at[indexCareer, 'takedown_accuracy']\n",
    "            blueCorner_subs_attempted = dfCareer.at[indexCareer, 'subs_attempted_average']\n",
    "            blueCorner_height = dfCareer.at[indexCareer, 'height']\n",
    "            blueCorner_reach = dfCareer.at[indexCareer, 'reach']\n",
    "            blueCorner_stance = dfCareer.at[indexCareer, 'stance']\n",
    "            blueCorner_sig_str_landed_per_minute = dfCareer.at[indexCareer, 'sig_str_landed_per_min']\n",
    "            blueCorner_fightTime = dfCareer.at[indexCareer, 'average_fight_time']\n",
    "            blueCorner_sig_str_absorbed_per_minute = dfCareer.at[indexCareer, 'sig_str_absorbed_per_min']\n",
    "            blueCorner_sig_str_defense = dfCareer.at[indexCareer, 'sig_str_defense']\n",
    "            blueCorner_takedown_defense = dfCareer.at[indexCareer, 'takedown_defense']\n",
    "        except:\n",
    "            pass\n",
    "    column_vals = {\n",
    "        'redCorner': redCorner, \n",
    "        'blueCorner': blueCorner, \n",
    "        'winner': winner,\n",
    "        'redCorner_wins': redCorner_wins, \n",
    "        'blueCorner_wins': blueCorner_wins, \n",
    "        'redCorner_losses': redCorner_losses, \n",
    "        'blueCorner_losses': blueCorner_losses, \n",
    "        'redCorner_draws': redCorner_draws, \n",
    "        'blueCorner_draws': blueCorner_draws, \n",
    "        'redCorner_age': redCorner_age, \n",
    "        'blueCorner_age': blueCorner_age,\n",
    "        'redCorner_nation': redCorner_nation, \n",
    "        'blueCorner_nation': blueCorner_nation, \n",
    "        'redCorner_knockdowns': redCorner_knockdowns, \n",
    "        'blueCorner_knockdowns': blueCorner_knockdowns,\n",
    "        'redCorner_sig_str_percentage': redCorner_sig_str_percentage, \n",
    "        'blueCorner_sig_str_percentage': blueCorner_sig_str_percentage, \n",
    "        'redCorner_takedowns': redCorner_takedowns,\n",
    "        'blueCorner_takedowns': blueCorner_takedowns, \n",
    "        'redCorner_takedown_percentage': redCorner_takedown_percentage, \n",
    "        'blueCorner_takedown_percentage': blueCorner_takedown_percentage,\n",
    "        'redCorner_subs_attempted': redCorner_subs_attempted, \n",
    "        'blueCorner_subs_attempted': blueCorner_subs_attempted, \n",
    "        'redCorner_height': redCorner_height, \n",
    "        'blueCorner_height': blueCorner_height,\n",
    "        'redCorner_reach': redCorner_reach, \n",
    "        'blueCorner_reach': blueCorner_reach, \n",
    "        'redCorner_stance': redCorner_stance, \n",
    "        'blueCorner_stance': blueCorner_stance, \n",
    "        'redCorner_sig_str_landed_per_minute': redCorner_sig_str_landed_per_minute,\n",
    "        'blueCorner_sig_str_landed_per_minute': blueCorner_sig_str_landed_per_minute, \n",
    "        'redCorner_fightTime': redCorner_fightTime, \n",
    "        'blueCorner_fightTime': blueCorner_fightTime, \n",
    "        'redCorner_sig_str_absorbed_per_minute': redCorner_sig_str_absorbed_per_minute, \n",
    "        'blueCorner_sig_str_absorbed_per_minute': blueCorner_sig_str_absorbed_per_minute, \n",
    "        'redCorner_sig_str_defense': redCorner_sig_str_defense,\n",
    "        'blueCorner_sig_str_defense': blueCorner_sig_str_defense, \n",
    "        'redCorner_takedown_defense': redCorner_takedown_defense, \n",
    "        'blueCorner_takedown_defense': blueCorner_takedown_defense\n",
    "    }\n",
    "    dfCustom.loc[len(dfCustom)] = column_vals\n",
    "\n",
    "\n",
    "    predictions = []\n",
    "    for i in range(3):\n",
    "        dfInput = dfCustom.copy()\n",
    "\n",
    "\n",
    "        df = pd.read_csv(f'traindata{dateToday}.csv')\n",
    "\n",
    "\n",
    "        df = df.dropna(inplace=False)\n",
    "\n",
    "\n",
    "        #dropping referee\n",
    "        df.drop('referee', axis=1, inplace=True)\n",
    "\n",
    "        #drop billings\n",
    "        df.drop('billing', axis=1, inplace=True)\n",
    "\n",
    "        #drop venue\n",
    "        df.drop('venue', axis=1, inplace=True)\n",
    "\n",
    "        #drop title_fight\n",
    "        df.drop('title_fight', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "        df.rename(columns={'fightTime': 'redCorner_fightTime'}, inplace=True)\n",
    "        df.insert(32, 'blueCorner_fightTime', df['redCorner_fightTime'])\n",
    "\n",
    "        dfColumns = df.columns\n",
    "\n",
    "\n",
    "        dfInputColumns = dfInput.columns\n",
    "\n",
    "\n",
    "        #one hot encode redCorner_nation\n",
    "        column = df[['redCorner_nation']].copy()\n",
    "        df_encoded = pd.get_dummies(column, columns=['redCorner_nation'], prefix='redCorner_nation').astype(int)\n",
    "        df = pd.concat([df, df_encoded], axis=1)\n",
    "\n",
    "        #one hot encode blueCorner_nation\n",
    "        column = df[['blueCorner_nation']].copy()\n",
    "        df_encoded = pd.get_dummies(column, columns=['blueCorner_nation'], prefix='blueCorner_nation').astype(int)\n",
    "        df = pd.concat([df, df_encoded], axis=1)\n",
    "\n",
    "\n",
    "        #one hot encode redCorner_stance\n",
    "        column = df[['redCorner_stance']].copy()\n",
    "        df_encoded = pd.get_dummies(column, columns=['redCorner_stance'], prefix='redCorner_stance').astype(int)\n",
    "        df = pd.concat([df, df_encoded], axis=1)\n",
    "\n",
    "        #one hot encode blueCorner_stance\n",
    "        column = df[['blueCorner_stance']].copy()\n",
    "        df_encoded = pd.get_dummies(column, columns=['blueCorner_stance'], prefix='blueCorner_stance').astype(int)\n",
    "        df = pd.concat([df, df_encoded], axis=1)\n",
    "\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            if row['winner'] == 1:\n",
    "                df.drop(index)\n",
    "\n",
    "        df['blueCorner'] = 1\n",
    "        df['winner'] = df['winner'].replace(2, 1)\n",
    "\n",
    "\n",
    "\n",
    "        #one hot encode redCorner_nation\n",
    "        column = df[['redCorner_nation']].copy()\n",
    "        df_encoded = pd.get_dummies(column, columns=['redCorner_nation'], prefix='redCorner_nation').astype(int)\n",
    "        dfInput.drop('redCorner_nation', axis=1, inplace=True)\n",
    "        dfInput = pd.concat([dfInput, df_encoded], axis=1)\n",
    "\n",
    "        #one hot encode blueCorner_nation\n",
    "        column = df[['blueCorner_nation']].copy()\n",
    "        df_encoded = pd.get_dummies(column, columns=['blueCorner_nation'], prefix='blueCorner_nation').astype(int)\n",
    "        dfInput.drop('blueCorner_nation', axis=1, inplace=True)\n",
    "        dfInput = pd.concat([dfInput, df_encoded], axis=1)\n",
    "\n",
    "        df.drop('redCorner_nation', axis=1, inplace=True)\n",
    "        df.drop('blueCorner_nation', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "        #one hot encode redCorner_stance\n",
    "        column = df[['redCorner_stance']].copy()\n",
    "        df_encoded = pd.get_dummies(column, columns=['redCorner_stance'], prefix='redCorner_stance').astype(int)\n",
    "        dfInput.drop('redCorner_stance', axis=1, inplace=True)\n",
    "        dfInput = pd.concat([dfInput, df_encoded], axis=1)\n",
    "\n",
    "        #one hot encode blueCorner_stance\n",
    "        column = df[['blueCorner_stance']].copy()\n",
    "        df_encoded = pd.get_dummies(column, columns=['blueCorner_stance'], prefix='blueCorner_stance').astype(int)\n",
    "        dfInput.drop('blueCorner_stance', axis=1, inplace=True)\n",
    "        dfInput = pd.concat([dfInput, df_encoded], axis=1)\n",
    "\n",
    "        df.drop('redCorner_stance', axis=1, inplace=True)\n",
    "        df.drop('blueCorner_stance', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "        #limit the data\n",
    "        dfInput = dfInput.head(1)\n",
    "\n",
    "\n",
    "        #when one hot encoding, nations that have no representation in the train set have Nan values. This sets them to zero as they would have been zero if they were represented\n",
    "        df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "        #dropna\n",
    "        dfInput.dropna(subset=dfInput.columns.difference(['winner']), inplace=True)\n",
    "\n",
    "\n",
    "        dfInput.at[0, 'redCorner'] = 0.0\n",
    "        dfInput.at[0, 'blueCorner'] = 1.0\n",
    "\n",
    "        #x,y split\n",
    "        target_column = 'winner'\n",
    "        y = df[target_column]\n",
    "        X = df.drop(target_column, axis=1)\n",
    "\n",
    "        #create train test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        #Define the deep learning model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(64, activation = 'relu'))\n",
    "        model.add(Dense(32, activation = 'relu'))\n",
    "        model.add(Dense(16, activation = 'relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        #earlyStopping\n",
    "        earlystopping = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "\n",
    "        # Define the ModelCheckpoint callback\n",
    "        checkpoint = ModelCheckpoint(filepath='best_model_weights2.weights.h5', save_weights_only=True, monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "\n",
    "        #compile\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        #train\n",
    "        model.fit(X_train, y_train, epochs=1000, batch_size=124, validation_data=(X_test, y_test), callbacks=[checkpoint, earlystopping])\n",
    "\n",
    "        # x, y split for dfMock\n",
    "        target_column = 'winner'\n",
    "        y_mock = dfInput[target_column]\n",
    "        X_mock = dfInput.drop(target_column, axis=1)\n",
    "        X_mock = X_mock.fillna(0)\n",
    "\n",
    "        #accuracy\n",
    "        y_hat = model.predict(X_mock)\n",
    "\n",
    "        #store prediction\n",
    "        prediction = float(y_hat[0])\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    predictionsAverage = sum(predictions)/len(predictions)\n",
    "\n",
    "    #new item to add\n",
    "    item  = {'Fight': fight, 'Prediction': predictionsAverage}\n",
    "\n",
    "    #append the new item to the DataFrame\n",
    "    dfTracking.loc[len(dfTracking)] = item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fight</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Winner</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brandon Royval vs Tatsuro Taira</td>\n",
       "      <td>0.756120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brad Tavares vs JunYong Park</td>\n",
       "      <td>0.763234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chidi Njokuani vs Jared Gooden</td>\n",
       "      <td>0.199098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grant Dawson vs Rafa Garcia</td>\n",
       "      <td>0.343276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daniel Rodriguez vs Alex Morono</td>\n",
       "      <td>0.366457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Fight  Prediction  Predicted  Winner  Result\n",
       "0  Brandon Royval vs Tatsuro Taira    0.756120        NaN     NaN     NaN\n",
       "1     Brad Tavares vs JunYong Park    0.763234        NaN     NaN     NaN\n",
       "2   Chidi Njokuani vs Jared Gooden    0.199098        NaN     NaN     NaN\n",
       "3      Grant Dawson vs Rafa Garcia    0.343276        NaN     NaN     NaN\n",
       "4  Daniel Rodriguez vs Alex Morono    0.366457        NaN     NaN     NaN"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dfTracking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fight</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Winner</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brandon Royval vs Tatsuro Taira</td>\n",
       "      <td>0.756120</td>\n",
       "      <td>Tatsuro Taira</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brad Tavares vs JunYong Park</td>\n",
       "      <td>0.763234</td>\n",
       "      <td>JunYong Park</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chidi Njokuani vs Jared Gooden</td>\n",
       "      <td>0.199098</td>\n",
       "      <td>Chidi Njokuani</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grant Dawson vs Rafa Garcia</td>\n",
       "      <td>0.343276</td>\n",
       "      <td>Grant Dawson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daniel Rodriguez vs Alex Morono</td>\n",
       "      <td>0.366457</td>\n",
       "      <td>Daniel Rodriguez</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Fight  Prediction         Predicted  Winner  \\\n",
       "0  Brandon Royval vs Tatsuro Taira    0.756120     Tatsuro Taira     NaN   \n",
       "1     Brad Tavares vs JunYong Park    0.763234      JunYong Park     NaN   \n",
       "2   Chidi Njokuani vs Jared Gooden    0.199098    Chidi Njokuani     NaN   \n",
       "3      Grant Dawson vs Rafa Garcia    0.343276      Grant Dawson     NaN   \n",
       "4  Daniel Rodriguez vs Alex Morono    0.366457  Daniel Rodriguez     NaN   \n",
       "\n",
       "   Result  \n",
       "0     NaN  \n",
       "1     NaN  \n",
       "2     NaN  \n",
       "3     NaN  \n",
       "4     NaN  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in dfTracking.iterrows():\n",
    "    fight = row['Fight']\n",
    "    corners = fight.split(' vs ')\n",
    "    redCorner = corners[0]\n",
    "    blueCorner = corners[1]\n",
    "    prediction = row['Prediction']\n",
    "    if(prediction > 0.5):\n",
    "        dfTracking.at[index, 'Predicted'] = str(blueCorner)\n",
    "    if(prediction < 0.5):\n",
    "        dfTracking.at[index, 'Predicted'] = str(redCorner)\n",
    "dfTracking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fight</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Winner</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brandon Royval vs Tatsuro Taira</td>\n",
       "      <td>0.756120</td>\n",
       "      <td>Tatsuro Taira</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brad Tavares vs JunYong Park</td>\n",
       "      <td>0.763234</td>\n",
       "      <td>JunYong Park</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chidi Njokuani vs Jared Gooden</td>\n",
       "      <td>0.199098</td>\n",
       "      <td>Chidi Njokuani</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grant Dawson vs Rafa Garcia</td>\n",
       "      <td>0.343276</td>\n",
       "      <td>Grant Dawson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daniel Rodriguez vs Alex Morono</td>\n",
       "      <td>0.366457</td>\n",
       "      <td>Daniel Rodriguez</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Fight  Prediction         Predicted Winner Result\n",
       "0  Brandon Royval vs Tatsuro Taira    0.756120     Tatsuro Taira    NaN    NaN\n",
       "1     Brad Tavares vs JunYong Park    0.763234      JunYong Park    NaN    NaN\n",
       "2   Chidi Njokuani vs Jared Gooden    0.199098    Chidi Njokuani    NaN    NaN\n",
       "3      Grant Dawson vs Rafa Garcia    0.343276      Grant Dawson    NaN    NaN\n",
       "4  Daniel Rodriguez vs Alex Morono    0.366457  Daniel Rodriguez    NaN    NaN"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrackingCompleted = pd.concat([dfTracking, dfPrevPreds], ignore_index=True)\n",
    "dfTrackingCompleted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrackingCompleted.to_csv(f'predictions{dateToday}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
