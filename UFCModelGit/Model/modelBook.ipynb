{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>referee</th>\n",
       "      <th>venue</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>billing</th>\n",
       "      <th>redCorner_wins</th>\n",
       "      <th>blueCorner_wins</th>\n",
       "      <th>redCorner_losses</th>\n",
       "      <th>...</th>\n",
       "      <th>blueCorner_stance</th>\n",
       "      <th>redCorner_sig_str_landed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_landed_per_minute</th>\n",
       "      <th>fightTime</th>\n",
       "      <th>redCorner_sig_str_absorbed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_absorbed_per_minute</th>\n",
       "      <th>redCorner_sig_str_defense</th>\n",
       "      <th>blueCorner_sig_str_defense</th>\n",
       "      <th>redCorner_takedown_defense</th>\n",
       "      <th>blueCorner_takedown_defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>4.480000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>4.480000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.533333</td>\n",
       "      <td>1.533333</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.533333</td>\n",
       "      <td>1.533333</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.959391</td>\n",
       "      <td>3.045685</td>\n",
       "      <td>3.283333</td>\n",
       "      <td>3.045685</td>\n",
       "      <td>3.959391</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.733333</td>\n",
       "      <td>2.533333</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.533333</td>\n",
       "      <td>1.733333</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.611940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5.454545</td>\n",
       "      <td>5.454545</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>5.454545</td>\n",
       "      <td>5.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   redCorner  blueCorner  winner  referee  venue  title_fight  billing  \\\n",
       "0          0           2       2       48    193            0        0   \n",
       "1          0           2       0       82    193            0        1   \n",
       "2          0           2       0       66    193            0        2   \n",
       "3          0           2       2       82    193            0        2   \n",
       "4          0           2       1       48    193            0        2   \n",
       "\n",
       "   redCorner_wins  blueCorner_wins  redCorner_losses  ...  blueCorner_stance  \\\n",
       "0              12               12                 2  ...                  0   \n",
       "1              17               27                 5  ...                  1   \n",
       "2              17               19                 5  ...                  0   \n",
       "3              12               16                 5  ...                  1   \n",
       "4              14               26                 0  ...                  0   \n",
       "\n",
       "   redCorner_sig_str_landed_per_minute  blueCorner_sig_str_landed_per_minute  \\\n",
       "0                             1.360000                              4.480000   \n",
       "1                             1.533333                              1.533333   \n",
       "2                             3.959391                              3.045685   \n",
       "3                             1.733333                              2.533333   \n",
       "4                             5.454545                              5.454545   \n",
       "\n",
       "   fightTime  redCorner_sig_str_absorbed_per_minute  \\\n",
       "0  25.000000                               4.480000   \n",
       "1  15.000000                               1.533333   \n",
       "2   3.283333                               3.045685   \n",
       "3  15.000000                               2.533333   \n",
       "4   0.183333                               5.454545   \n",
       "\n",
       "   blueCorner_sig_str_absorbed_per_minute  redCorner_sig_str_defense  \\\n",
       "0                                1.360000                   0.407407   \n",
       "1                                1.533333                   0.610169   \n",
       "2                                3.959391                   0.545455   \n",
       "3                                1.733333                   0.703125   \n",
       "4                                5.454545                   0.000000   \n",
       "\n",
       "   blueCorner_sig_str_defense  redCorner_takedown_defense  \\\n",
       "0                    0.776316                         1.0   \n",
       "1                    0.452381                         0.5   \n",
       "2                    0.717391                         1.0   \n",
       "3                    0.611940                         1.0   \n",
       "4                    0.500000                         1.0   \n",
       "\n",
       "   blueCorner_takedown_defense  \n",
       "0                     1.000000  \n",
       "1                     0.500000  \n",
       "2                     1.000000  \n",
       "3                     0.888889  \n",
       "4                     1.000000  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('traindata2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>redCorner_wins</th>\n",
       "      <th>blueCorner_wins</th>\n",
       "      <th>redCorner_losses</th>\n",
       "      <th>blueCorner_losses</th>\n",
       "      <th>redCorner_draws</th>\n",
       "      <th>blueCorner_draws</th>\n",
       "      <th>redCorner_age</th>\n",
       "      <th>...</th>\n",
       "      <th>redCorner_sig_str_landed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_landed_per_minute</th>\n",
       "      <th>redCorner_fightTime</th>\n",
       "      <th>blueCorner_fightTime</th>\n",
       "      <th>redCorner_sig_str_absorbed_per_minute</th>\n",
       "      <th>blueCorner_sig_str_absorbed_per_minute</th>\n",
       "      <th>redCorner_sig_str_defense</th>\n",
       "      <th>blueCorner_sig_str_defense</th>\n",
       "      <th>redCorner_takedown_defense</th>\n",
       "      <th>blueCorner_takedown_defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.02</td>\n",
       "      <td>4.55</td>\n",
       "      <td>9.833333</td>\n",
       "      <td>13.733333</td>\n",
       "      <td>3.01</td>\n",
       "      <td>3.76</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.38</td>\n",
       "      <td>3.37</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>11.416667</td>\n",
       "      <td>3.33</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.34</td>\n",
       "      <td>5.20</td>\n",
       "      <td>15.583333</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>5.19</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.68</td>\n",
       "      <td>6.59</td>\n",
       "      <td>10.766667</td>\n",
       "      <td>12.950000</td>\n",
       "      <td>4.90</td>\n",
       "      <td>6.43</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.07</td>\n",
       "      <td>4.34</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>13.266667</td>\n",
       "      <td>5.40</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   redCorner  blueCorner  winner  redCorner_wins  blueCorner_wins  \\\n",
       "0          0           1       1            12.0             12.0   \n",
       "1          0           1       0            17.0             19.0   \n",
       "2          0           1       1            12.0             16.0   \n",
       "3          0           1       0            13.0             15.0   \n",
       "4          0           1       1            17.0             13.0   \n",
       "\n",
       "   redCorner_losses  blueCorner_losses  redCorner_draws  blueCorner_draws  \\\n",
       "0               2.0                4.0              0.0               0.0   \n",
       "1               5.0                4.0              0.0               0.0   \n",
       "2               5.0                5.0              0.0               1.0   \n",
       "3               6.0                8.0              0.0               0.0   \n",
       "4               0.0                6.0              0.0               0.0   \n",
       "\n",
       "   redCorner_age  ...  redCorner_sig_str_landed_per_minute  \\\n",
       "0           35.0  ...                                 3.02   \n",
       "1           33.0  ...                                 4.38   \n",
       "2           37.0  ...                                 4.34   \n",
       "3           33.0  ...                                 5.68   \n",
       "4           29.0  ...                                 3.07   \n",
       "\n",
       "   blueCorner_sig_str_landed_per_minute  redCorner_fightTime  \\\n",
       "0                                  4.55             9.833333   \n",
       "1                                  3.37            10.600000   \n",
       "2                                  5.20            15.583333   \n",
       "3                                  6.59            10.766667   \n",
       "4                                  4.34            15.000000   \n",
       "\n",
       "   blueCorner_fightTime  redCorner_sig_str_absorbed_per_minute  \\\n",
       "0             13.733333                                   3.01   \n",
       "1             11.416667                                   3.33   \n",
       "2             11.100000                                   5.19   \n",
       "3             12.950000                                   4.90   \n",
       "4             13.266667                                   5.40   \n",
       "\n",
       "   blueCorner_sig_str_absorbed_per_minute  redCorner_sig_str_defense  \\\n",
       "0                                    3.76                       0.55   \n",
       "1                                    2.91                       0.54   \n",
       "2                                    2.23                       0.55   \n",
       "3                                    6.43                       0.63   \n",
       "4                                    3.27                       0.61   \n",
       "\n",
       "   blueCorner_sig_str_defense  redCorner_takedown_defense  \\\n",
       "0                        0.58                        0.33   \n",
       "1                        0.62                        0.74   \n",
       "2                        0.65                        0.77   \n",
       "3                        0.51                        0.43   \n",
       "4                        0.54                        0.00   \n",
       "\n",
       "   blueCorner_takedown_defense  \n",
       "0                         0.72  \n",
       "1                         0.73  \n",
       "2                         0.92  \n",
       "3                         0.69  \n",
       "4                         0.62  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMock = pd.read_csv('mockTestData.csv')\n",
    "dfMock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6155\n",
      "6155\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df = df.dropna(inplace=False)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5092\n",
      "5092\n"
     ]
    }
   ],
   "source": [
    "print(len(dfMock))\n",
    "dfMock = dfMock.dropna(inplace=False)\n",
    "print(len(dfMock))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>winner</th>\n",
       "      <th>redCorner_wins</th>\n",
       "      <th>blueCorner_wins</th>\n",
       "      <th>redCorner_losses</th>\n",
       "      <th>blueCorner_losses</th>\n",
       "      <th>redCorner_draws</th>\n",
       "      <th>blueCorner_draws</th>\n",
       "      <th>redCorner_age</th>\n",
       "      <th>...</th>\n",
       "      <th>blueCorner_nation_103.0</th>\n",
       "      <th>blueCorner_nation_107.0</th>\n",
       "      <th>blueCorner_nation_110.0</th>\n",
       "      <th>blueCorner_nation_112.0</th>\n",
       "      <th>blueCorner_nation_113.0</th>\n",
       "      <th>blueCorner_nation_114.0</th>\n",
       "      <th>blueCorner_nation_115.0</th>\n",
       "      <th>blueCorner_nation_117.0</th>\n",
       "      <th>blueCorner_nation_118.0</th>\n",
       "      <th>blueCorner_nation_119.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 277 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   redCorner  blueCorner  winner  redCorner_wins  blueCorner_wins  \\\n",
       "0          0           2       2              12               12   \n",
       "1          0           2       0              17               27   \n",
       "2          0           2       0              17               19   \n",
       "3          0           2       2              12               16   \n",
       "4          0           2       1              14               26   \n",
       "\n",
       "   redCorner_losses  blueCorner_losses  redCorner_draws  blueCorner_draws  \\\n",
       "0                 2                  4                0                 0   \n",
       "1                 5                 12                1                 0   \n",
       "2                 5                  4                0                 0   \n",
       "3                 5                  5                0                 1   \n",
       "4                 0                  8                0                 0   \n",
       "\n",
       "   redCorner_age  ...  blueCorner_nation_103.0  blueCorner_nation_107.0  \\\n",
       "0           35.0  ...                      0.0                      0.0   \n",
       "1           34.0  ...                      0.0                      0.0   \n",
       "2           33.0  ...                      0.0                      0.0   \n",
       "3           37.0  ...                      0.0                      0.0   \n",
       "4           33.0  ...                      0.0                      0.0   \n",
       "\n",
       "   blueCorner_nation_110.0  blueCorner_nation_112.0  blueCorner_nation_113.0  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                      0.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   blueCorner_nation_114.0  blueCorner_nation_115.0  blueCorner_nation_117.0  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                      0.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   blueCorner_nation_118.0  blueCorner_nation_119.0  \n",
       "0                      0.0                      0.0  \n",
       "1                      0.0                      0.0  \n",
       "2                      0.0                      0.0  \n",
       "3                      0.0                      0.0  \n",
       "4                      0.0                      0.0  \n",
       "\n",
       "[5 rows x 277 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping referee\n",
    "df.drop('referee', axis=1, inplace=True)\n",
    "\n",
    "#drop billings\n",
    "df.drop('billing', axis=1, inplace=True)\n",
    "\n",
    "#one hot encode redCorner_nation\n",
    "df_encoded = pd.get_dummies(dfMock, columns=['redCorner_nation'], prefix='redCorner_nation').astype(int)\n",
    "df.drop('redCorner_nation', axis=1, inplace=True)\n",
    "df = pd.concat([df, df_encoded], axis=1)\n",
    "\n",
    "#one hot encode blueCorner_nation\n",
    "df_encoded = pd.get_dummies(dfMock, columns=['blueCorner_nation'], prefix='blueCorner_nation').astype(int)\n",
    "df.drop('blueCorner_nation', axis=1, inplace=True)\n",
    "df = pd.concat([df, df_encoded], axis=1)\n",
    "\n",
    "#drop venue\n",
    "df.drop('venue', axis=1, inplace=True)\n",
    "\n",
    "#drop title_fight\n",
    "df.drop('title_fight', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reindex on an axis with duplicate labels",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblueCorner\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwinner\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwinner\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwinner\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/Desktop/UFCModel/UFCModel/UFCModelGit/.venv/lib/python3.11/site-packages/pandas/core/frame.py:4077\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4075\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) DataFrame?\u001b[39;00m\n\u001b[1;32m   4076\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, DataFrame):\n\u001b[0;32m-> 4077\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4079\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[1;32m   4080\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n",
      "File \u001b[0;32m~/Desktop/UFCModel/UFCModel/UFCModelGit/.venv/lib/python3.11/site-packages/pandas/core/generic.py:10978\u001b[0m, in \u001b[0;36mNDFrame.where\u001b[0;34m(self, cond, other, inplace, axis, level)\u001b[0m\n\u001b[1;32m  10971\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m  10972\u001b[0m                 _chained_assignment_warning_method_msg,\n\u001b[1;32m  10973\u001b[0m                 \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m  10974\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m  10975\u001b[0m             )\n\u001b[1;32m  10977\u001b[0m other \u001b[38;5;241m=\u001b[39m common\u001b[38;5;241m.\u001b[39mapply_if_callable(other, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m> 10978\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_where\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/UFCModel/UFCModel/UFCModelGit/.venv/lib/python3.11/site-packages/pandas/core/generic.py:10679\u001b[0m, in \u001b[0;36mNDFrame._where\u001b[0;34m(self, cond, other, inplace, axis, level, warn)\u001b[0m\n\u001b[1;32m  10676\u001b[0m     cond \u001b[38;5;241m=\u001b[39m cond\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m  10678\u001b[0m cond \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mcond \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m cond\n\u001b[0;32m> 10679\u001b[0m cond \u001b[38;5;241m=\u001b[39m \u001b[43mcond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m  10681\u001b[0m \u001b[38;5;66;03m# try to align with other\u001b[39;00m\n\u001b[1;32m  10682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, NDFrame):\n\u001b[1;32m  10683\u001b[0m     \u001b[38;5;66;03m# align with me\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/UFCModel/UFCModel/UFCModelGit/.venv/lib/python3.11/site-packages/pandas/core/frame.py:5365\u001b[0m, in \u001b[0;36mDataFrame.reindex\u001b[0;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   5346\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m   5347\u001b[0m     NDFrame\u001b[38;5;241m.\u001b[39mreindex,\n\u001b[1;32m   5348\u001b[0m     klass\u001b[38;5;241m=\u001b[39m_shared_doc_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mklass\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5363\u001b[0m     tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5364\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m-> 5365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5369\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5376\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/UFCModel/UFCModel/UFCModelGit/.venv/lib/python3.11/site-packages/pandas/core/generic.py:5604\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[0;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   5601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_multi(axes, copy, fill_value)\n\u001b[1;32m   5603\u001b[0m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[0;32m-> 5604\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_axes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5605\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m   5606\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/UFCModel/UFCModel/UFCModelGit/.venv/lib/python3.11/site-packages/pandas/core/generic.py:5627\u001b[0m, in \u001b[0;36mNDFrame._reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   5624\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   5626\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(a)\n\u001b[0;32m-> 5627\u001b[0m new_index, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5628\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\n\u001b[1;32m   5629\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5631\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(a)\n\u001b[1;32m   5632\u001b[0m obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   5633\u001b[0m     {axis: [new_index, indexer]},\n\u001b[1;32m   5634\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m   5635\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m   5636\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   5637\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/UFCModel/UFCModel/UFCModelGit/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:4426\u001b[0m, in \u001b[0;36mIndex.reindex\u001b[0;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[1;32m   4423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot handle a non-unique multi-index!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4424\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[1;32m   4425\u001b[0m     \u001b[38;5;66;03m# GH#42568\u001b[39;00m\n\u001b[0;32m-> 4426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4427\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4428\u001b[0m     indexer, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(target)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex on an axis with duplicate labels"
     ]
    }
   ],
   "source": [
    "df['blueCorner'] = 1\n",
    "df = df[df['winner'] != 1]\n",
    "df['winner'] = df['winner'].replace(2, 1)\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redCorner</th>\n",
       "      <th>blueCorner</th>\n",
       "      <th>title_fight</th>\n",
       "      <th>redCorner_wins</th>\n",
       "      <th>blueCorner_wins</th>\n",
       "      <th>redCorner_losses</th>\n",
       "      <th>blueCorner_losses</th>\n",
       "      <th>redCorner_draws</th>\n",
       "      <th>blueCorner_draws</th>\n",
       "      <th>redCorner_age</th>\n",
       "      <th>...</th>\n",
       "      <th>venue_196</th>\n",
       "      <th>venue_197</th>\n",
       "      <th>venue_198</th>\n",
       "      <th>venue_201</th>\n",
       "      <th>venue_202</th>\n",
       "      <th>venue_205</th>\n",
       "      <th>venue_206</th>\n",
       "      <th>venue_207</th>\n",
       "      <th>venue_208</th>\n",
       "      <th>venue_209</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5799</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2343</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 415 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      redCorner  blueCorner  title_fight  redCorner_wins  blueCorner_wins  \\\n",
       "5980          0           1            0               8                6   \n",
       "5799          0           1            0              22                6   \n",
       "1521          0           1            0              15                8   \n",
       "2343          0           1            0              23               15   \n",
       "1669          0           1            0              13               12   \n",
       "\n",
       "      redCorner_losses  blueCorner_losses  redCorner_draws  blueCorner_draws  \\\n",
       "5980                 2                  0                0                 0   \n",
       "5799                 8                  1                0                 0   \n",
       "1521                 2                  1                0                 1   \n",
       "2343                 8                  5                0                 0   \n",
       "1669                 5                  5                0                 0   \n",
       "\n",
       "      redCorner_age  ...  venue_196  venue_197  venue_198  venue_201  \\\n",
       "5980             31  ...          0          0          0          0   \n",
       "5799             29  ...          0          0          0          0   \n",
       "1521             24  ...          0          0          0          0   \n",
       "2343             42  ...          0          0          0          0   \n",
       "1669             38  ...          0          0          0          0   \n",
       "\n",
       "      venue_202  venue_205  venue_206  venue_207  venue_208  venue_209  \n",
       "5980          0          0          0          0          0          0  \n",
       "5799          0          0          0          0          0          0  \n",
       "1521          0          0          0          0          0          0  \n",
       "2343          0          0          0          0          0          0  \n",
       "1669          0          0          0          0          0          0  \n",
       "\n",
       "[5 rows x 415 columns]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x,y split\n",
    "target_column = 'winner'\n",
    "y = df[target_column]\n",
    "X = df.drop(target_column, axis=1)\n",
    "\n",
    "#create train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.5633 - accuracy: 0.7225\n",
      "Epoch 1: val_accuracy improved from -inf to 0.76285, saving model to best_model_weights.h5\n",
      "39/39 [==============================] - 2s 12ms/step - loss: 0.5587 - accuracy: 0.7248 - val_loss: 0.4520 - val_accuracy: 0.7629\n",
      "Epoch 2/1000\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.3848 - accuracy: 0.8434\n",
      "Epoch 2: val_accuracy improved from 0.76285 to 0.84992, saving model to best_model_weights.h5\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.3848 - accuracy: 0.8434 - val_loss: 0.3412 - val_accuracy: 0.8499\n",
      "Epoch 3/1000\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.3269 - accuracy: 0.8627\n",
      "Epoch 3: val_accuracy did not improve from 0.84992\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3296 - accuracy: 0.8621 - val_loss: 0.3333 - val_accuracy: 0.8483\n",
      "Epoch 4/1000\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.3099 - accuracy: 0.8737\n",
      "Epoch 4: val_accuracy improved from 0.84992 to 0.85572, saving model to best_model_weights.h5\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3072 - accuracy: 0.8735 - val_loss: 0.3133 - val_accuracy: 0.8557\n",
      "Epoch 5/1000\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.2919 - accuracy: 0.8788\n",
      "Epoch 5: val_accuracy improved from 0.85572 to 0.86899, saving model to best_model_weights.h5\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2907 - accuracy: 0.8797 - val_loss: 0.3137 - val_accuracy: 0.8690\n",
      "Epoch 6/1000\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.2799 - accuracy: 0.8857\n",
      "Epoch 6: val_accuracy did not improve from 0.86899\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2822 - accuracy: 0.8839 - val_loss: 0.3296 - val_accuracy: 0.8557\n",
      "Epoch 7/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.2722 - accuracy: 0.8847\n",
      "Epoch 7: val_accuracy did not improve from 0.86899\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2720 - accuracy: 0.8835 - val_loss: 0.3012 - val_accuracy: 0.8624\n",
      "Epoch 8/1000\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.2585 - accuracy: 0.8937\n",
      "Epoch 8: val_accuracy improved from 0.86899 to 0.87065, saving model to best_model_weights.h5\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2596 - accuracy: 0.8932 - val_loss: 0.2944 - val_accuracy: 0.8706\n",
      "Epoch 9/1000\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.2581 - accuracy: 0.8942\n",
      "Epoch 9: val_accuracy improved from 0.87065 to 0.87728, saving model to best_model_weights.h5\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2580 - accuracy: 0.8942 - val_loss: 0.2940 - val_accuracy: 0.8773\n",
      "Epoch 10/1000\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.2511 - accuracy: 0.8982\n",
      "Epoch 10: val_accuracy did not improve from 0.87728\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.2481 - accuracy: 0.8992 - val_loss: 0.3024 - val_accuracy: 0.8665\n",
      "Epoch 11/1000\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.2492 - accuracy: 0.8974\n",
      "Epoch 11: val_accuracy did not improve from 0.87728\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.2411 - accuracy: 0.9002 - val_loss: 0.2944 - val_accuracy: 0.8748\n",
      "Epoch 12/1000\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.2332 - accuracy: 0.9061\n",
      "Epoch 12: val_accuracy did not improve from 0.87728\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.2332 - accuracy: 0.9061 - val_loss: 0.2996 - val_accuracy: 0.8740\n",
      "Epoch 13/1000\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.2291 - accuracy: 0.9075\n",
      "Epoch 13: val_accuracy did not improve from 0.87728\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.2303 - accuracy: 0.9061 - val_loss: 0.2945 - val_accuracy: 0.8773\n",
      "Epoch 14/1000\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.2189 - accuracy: 0.9109\n",
      "Epoch 14: val_accuracy did not improve from 0.87728\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2194 - accuracy: 0.9100 - val_loss: 0.3205 - val_accuracy: 0.8673\n",
      "Epoch 15/1000\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.2024 - accuracy: 0.9183\n",
      "Epoch 15: val_accuracy improved from 0.87728 to 0.88226, saving model to best_model_weights.h5\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2104 - accuracy: 0.9162 - val_loss: 0.2936 - val_accuracy: 0.8823\n",
      "Epoch 16/1000\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.2131 - accuracy: 0.9116\n",
      "Epoch 16: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.2074 - accuracy: 0.9158 - val_loss: 0.2914 - val_accuracy: 0.8781\n",
      "Epoch 17/1000\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.2054 - accuracy: 0.9177\n",
      "Epoch 17: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2065 - accuracy: 0.9177 - val_loss: 0.2901 - val_accuracy: 0.8814\n",
      "Epoch 18/1000\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.1935 - accuracy: 0.9226\n",
      "Epoch 18: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.1935 - accuracy: 0.9226 - val_loss: 0.3153 - val_accuracy: 0.8648\n",
      "Epoch 19/1000\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.1903 - accuracy: 0.9229\n",
      "Epoch 19: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.1953 - accuracy: 0.9193 - val_loss: 0.3068 - val_accuracy: 0.8690\n",
      "Epoch 20/1000\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.1883 - accuracy: 0.9240\n",
      "Epoch 20: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.1903 - accuracy: 0.9233 - val_loss: 0.2977 - val_accuracy: 0.8723\n",
      "Epoch 21/1000\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.1870 - accuracy: 0.9269\n",
      "Epoch 21: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.1949 - accuracy: 0.9222 - val_loss: 0.3148 - val_accuracy: 0.8648\n",
      "Epoch 22/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.1823 - accuracy: 0.9240\n",
      "Epoch 22: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.1824 - accuracy: 0.9239 - val_loss: 0.3023 - val_accuracy: 0.8706\n",
      "Epoch 23/1000\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.1706 - accuracy: 0.9311\n",
      "Epoch 23: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.1711 - accuracy: 0.9309 - val_loss: 0.3421 - val_accuracy: 0.8640\n",
      "Epoch 24/1000\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.1675 - accuracy: 0.9294\n",
      "Epoch 24: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.1686 - accuracy: 0.9301 - val_loss: 0.3080 - val_accuracy: 0.8748\n",
      "Epoch 25/1000\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.1750 - accuracy: 0.9295\n",
      "Epoch 25: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.1771 - accuracy: 0.9282 - val_loss: 0.3128 - val_accuracy: 0.8682\n",
      "Epoch 26/1000\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.1723 - accuracy: 0.9292\n",
      "Epoch 26: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.1705 - accuracy: 0.9293 - val_loss: 0.3206 - val_accuracy: 0.8715\n",
      "Epoch 27/1000\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.1607 - accuracy: 0.9357\n",
      "Epoch 27: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.1588 - accuracy: 0.9370 - val_loss: 0.3185 - val_accuracy: 0.8798\n",
      "Epoch 28/1000\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.1527 - accuracy: 0.9433\n",
      "Epoch 28: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.1521 - accuracy: 0.9426 - val_loss: 0.3182 - val_accuracy: 0.8765\n",
      "Epoch 29/1000\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.1505 - accuracy: 0.9405\n",
      "Epoch 29: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.1526 - accuracy: 0.9394 - val_loss: 0.3408 - val_accuracy: 0.8690\n",
      "Epoch 30/1000\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.1623 - accuracy: 0.9324\n",
      "Epoch 30: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.1630 - accuracy: 0.9332 - val_loss: 0.3344 - val_accuracy: 0.8698\n",
      "Epoch 31/1000\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.1683 - accuracy: 0.9252\n",
      "Epoch 31: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.1645 - accuracy: 0.9270 - val_loss: 0.3554 - val_accuracy: 0.8632\n",
      "Epoch 32/1000\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.1634 - accuracy: 0.9299\n",
      "Epoch 32: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.1610 - accuracy: 0.9309 - val_loss: 0.3356 - val_accuracy: 0.8723\n",
      "Epoch 33/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.1357 - accuracy: 0.9475\n",
      "Epoch 33: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.1365 - accuracy: 0.9467 - val_loss: 0.3293 - val_accuracy: 0.8781\n",
      "Epoch 34/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.1412 - accuracy: 0.9440\n",
      "Epoch 34: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.1408 - accuracy: 0.9446 - val_loss: 0.3525 - val_accuracy: 0.8673\n",
      "Epoch 35/1000\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.1372 - accuracy: 0.9435\n",
      "Epoch 35: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.1392 - accuracy: 0.9436 - val_loss: 0.3482 - val_accuracy: 0.8624\n",
      "Epoch 36/1000\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.1343 - accuracy: 0.9503\n",
      "Epoch 36: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.1381 - accuracy: 0.9475 - val_loss: 0.3488 - val_accuracy: 0.8648\n",
      "Epoch 37/1000\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.1233 - accuracy: 0.9526\n",
      "Epoch 37: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.1268 - accuracy: 0.9500 - val_loss: 0.3703 - val_accuracy: 0.8648\n",
      "Epoch 38/1000\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.1240 - accuracy: 0.9509\n",
      "Epoch 38: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.1241 - accuracy: 0.9506 - val_loss: 0.3542 - val_accuracy: 0.8657\n",
      "Epoch 39/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.1290 - accuracy: 0.9528\n",
      "Epoch 39: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.1295 - accuracy: 0.9531 - val_loss: 0.3628 - val_accuracy: 0.8673\n",
      "Epoch 40/1000\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.1157 - accuracy: 0.9536\n",
      "Epoch 40: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.1167 - accuracy: 0.9525 - val_loss: 0.3688 - val_accuracy: 0.8607\n",
      "Epoch 41/1000\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.1338 - accuracy: 0.9444\n",
      "Epoch 41: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.1302 - accuracy: 0.9461 - val_loss: 0.3746 - val_accuracy: 0.8698\n",
      "Epoch 42/1000\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.1065 - accuracy: 0.9551\n",
      "Epoch 42: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.1074 - accuracy: 0.9554 - val_loss: 0.3798 - val_accuracy: 0.8665\n",
      "Epoch 43/1000\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.1030 - accuracy: 0.9614\n",
      "Epoch 43: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.1112 - accuracy: 0.9571 - val_loss: 0.4062 - val_accuracy: 0.8657\n",
      "Epoch 44/1000\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.1088 - accuracy: 0.9556\n",
      "Epoch 44: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.1081 - accuracy: 0.9560 - val_loss: 0.3774 - val_accuracy: 0.8682\n",
      "Epoch 45/1000\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.1067 - accuracy: 0.9556\n",
      "Epoch 45: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.1077 - accuracy: 0.9556 - val_loss: 0.4358 - val_accuracy: 0.8590\n",
      "Epoch 46/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.1043 - accuracy: 0.9594\n",
      "Epoch 46: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.1045 - accuracy: 0.9585 - val_loss: 0.4084 - val_accuracy: 0.8640\n",
      "Epoch 47/1000\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.0981 - accuracy: 0.9613\n",
      "Epoch 47: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0978 - accuracy: 0.9612 - val_loss: 0.3950 - val_accuracy: 0.8665\n",
      "Epoch 48/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0959 - accuracy: 0.9633\n",
      "Epoch 48: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0934 - accuracy: 0.9645 - val_loss: 0.4155 - val_accuracy: 0.8673\n",
      "Epoch 49/1000\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.0920 - accuracy: 0.9671\n",
      "Epoch 49: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0918 - accuracy: 0.9662 - val_loss: 0.4076 - val_accuracy: 0.8706\n",
      "Epoch 50/1000\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.0957 - accuracy: 0.9633\n",
      "Epoch 50: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0965 - accuracy: 0.9627 - val_loss: 0.4088 - val_accuracy: 0.8648\n",
      "Epoch 51/1000\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 0.0811 - accuracy: 0.9716\n",
      "Epoch 51: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0810 - accuracy: 0.9720 - val_loss: 0.4355 - val_accuracy: 0.8632\n",
      "Epoch 52/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0807 - accuracy: 0.9712\n",
      "Epoch 52: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0829 - accuracy: 0.9699 - val_loss: 0.4367 - val_accuracy: 0.8557\n",
      "Epoch 53/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0768 - accuracy: 0.9712\n",
      "Epoch 53: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0797 - accuracy: 0.9706 - val_loss: 0.4433 - val_accuracy: 0.8566\n",
      "Epoch 54/1000\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.0804 - accuracy: 0.9687\n",
      "Epoch 54: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0826 - accuracy: 0.9683 - val_loss: 0.4312 - val_accuracy: 0.8648\n",
      "Epoch 55/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0842 - accuracy: 0.9673\n",
      "Epoch 55: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0832 - accuracy: 0.9670 - val_loss: 0.4735 - val_accuracy: 0.8566\n",
      "Epoch 56/1000\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.0733 - accuracy: 0.9715\n",
      "Epoch 56: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0738 - accuracy: 0.9718 - val_loss: 0.4617 - val_accuracy: 0.8541\n",
      "Epoch 57/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0709 - accuracy: 0.9731\n",
      "Epoch 57: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.9735 - val_loss: 0.4923 - val_accuracy: 0.8599\n",
      "Epoch 58/1000\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.0696 - accuracy: 0.9765\n",
      "Epoch 58: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0680 - accuracy: 0.9774 - val_loss: 0.4836 - val_accuracy: 0.8590\n",
      "Epoch 59/1000\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.0584 - accuracy: 0.9791\n",
      "Epoch 59: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0655 - accuracy: 0.9762 - val_loss: 0.5111 - val_accuracy: 0.8665\n",
      "Epoch 60/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0663 - accuracy: 0.9765\n",
      "Epoch 60: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.9747 - val_loss: 0.5170 - val_accuracy: 0.8549\n",
      "Epoch 61/1000\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.0663 - accuracy: 0.9750\n",
      "Epoch 61: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.9753 - val_loss: 0.4967 - val_accuracy: 0.8599\n",
      "Epoch 62/1000\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.0647 - accuracy: 0.9753\n",
      "Epoch 62: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0643 - accuracy: 0.9762 - val_loss: 0.5300 - val_accuracy: 0.8541\n",
      "Epoch 63/1000\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.0611 - accuracy: 0.9794\n",
      "Epoch 63: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0637 - accuracy: 0.9778 - val_loss: 0.5166 - val_accuracy: 0.8557\n",
      "Epoch 64/1000\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.0612 - accuracy: 0.9787\n",
      "Epoch 64: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.0638 - accuracy: 0.9776 - val_loss: 0.5317 - val_accuracy: 0.8532\n",
      "Epoch 65/1000\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.0690 - accuracy: 0.9743\n",
      "Epoch 65: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0665 - accuracy: 0.9747 - val_loss: 0.5310 - val_accuracy: 0.8491\n",
      "Epoch 66/1000\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.0606 - accuracy: 0.9771\n",
      "Epoch 66: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0622 - accuracy: 0.9782 - val_loss: 0.5367 - val_accuracy: 0.8566\n",
      "Epoch 67/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0534 - accuracy: 0.9819\n",
      "Epoch 67: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0534 - accuracy: 0.9818 - val_loss: 0.5291 - val_accuracy: 0.8590\n",
      "Epoch 68/1000\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.0538 - accuracy: 0.9802\n",
      "Epoch 68: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0544 - accuracy: 0.9795 - val_loss: 0.5800 - val_accuracy: 0.8474\n",
      "Epoch 69/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0580 - accuracy: 0.9778\n",
      "Epoch 69: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0574 - accuracy: 0.9782 - val_loss: 0.5514 - val_accuracy: 0.8549\n",
      "Epoch 70/1000\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.0538 - accuracy: 0.9806\n",
      "Epoch 70: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0532 - accuracy: 0.9801 - val_loss: 0.5638 - val_accuracy: 0.8541\n",
      "Epoch 71/1000\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.0494 - accuracy: 0.9825\n",
      "Epoch 71: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0506 - accuracy: 0.9824 - val_loss: 0.5854 - val_accuracy: 0.8499\n",
      "Epoch 72/1000\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 0.9803\n",
      "Epoch 72: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0567 - accuracy: 0.9803 - val_loss: 0.6099 - val_accuracy: 0.8541\n",
      "Epoch 73/1000\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.0486 - accuracy: 0.9824\n",
      "Epoch 73: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9813 - val_loss: 0.5774 - val_accuracy: 0.8458\n",
      "Epoch 74/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0419 - accuracy: 0.9878\n",
      "Epoch 74: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0430 - accuracy: 0.9873 - val_loss: 0.6036 - val_accuracy: 0.8458\n",
      "Epoch 75/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0405 - accuracy: 0.9868\n",
      "Epoch 75: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0436 - accuracy: 0.9859 - val_loss: 0.6470 - val_accuracy: 0.8574\n",
      "Epoch 76/1000\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.0350 - accuracy: 0.9879\n",
      "Epoch 76: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0378 - accuracy: 0.9867 - val_loss: 0.6272 - val_accuracy: 0.8491\n",
      "Epoch 77/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0491 - accuracy: 0.9831\n",
      "Epoch 77: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0598 - accuracy: 0.9782 - val_loss: 0.7413 - val_accuracy: 0.8400\n",
      "Epoch 78/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0678 - accuracy: 0.9724\n",
      "Epoch 78: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0652 - accuracy: 0.9741 - val_loss: 0.6188 - val_accuracy: 0.8532\n",
      "Epoch 79/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0453 - accuracy: 0.9841\n",
      "Epoch 79: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0444 - accuracy: 0.9844 - val_loss: 0.6124 - val_accuracy: 0.8516\n",
      "Epoch 80/1000\n",
      "26/39 [===================>..........] - ETA: 0s - loss: 0.0364 - accuracy: 0.9898\n",
      "Epoch 80: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0364 - accuracy: 0.9896 - val_loss: 0.6365 - val_accuracy: 0.8590\n",
      "Epoch 81/1000\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.0338 - accuracy: 0.9893\n",
      "Epoch 81: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0353 - accuracy: 0.9892 - val_loss: 0.6545 - val_accuracy: 0.8491\n",
      "Epoch 82/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0476 - accuracy: 0.9834\n",
      "Epoch 82: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0467 - accuracy: 0.9838 - val_loss: 0.6856 - val_accuracy: 0.8491\n",
      "Epoch 83/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0353 - accuracy: 0.9890\n",
      "Epoch 83: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0410 - accuracy: 0.9867 - val_loss: 0.7391 - val_accuracy: 0.8383\n",
      "Epoch 84/1000\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.0755 - accuracy: 0.9720\n",
      "Epoch 84: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0696 - accuracy: 0.9743 - val_loss: 0.6409 - val_accuracy: 0.8582\n",
      "Epoch 85/1000\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.0458 - accuracy: 0.9828\n",
      "Epoch 85: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.0439 - accuracy: 0.9840 - val_loss: 0.6441 - val_accuracy: 0.8433\n",
      "Epoch 86/1000\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.0332 - accuracy: 0.9898\n",
      "Epoch 86: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0342 - accuracy: 0.9894 - val_loss: 0.6619 - val_accuracy: 0.8582\n",
      "Epoch 87/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0417 - accuracy: 0.9844\n",
      "Epoch 87: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0452 - accuracy: 0.9824 - val_loss: 0.6525 - val_accuracy: 0.8458\n",
      "Epoch 88/1000\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.0484 - accuracy: 0.9814\n",
      "Epoch 88: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0462 - accuracy: 0.9820 - val_loss: 0.6760 - val_accuracy: 0.8400\n",
      "Epoch 89/1000\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.0366 - accuracy: 0.9869\n",
      "Epoch 89: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0354 - accuracy: 0.9880 - val_loss: 0.7090 - val_accuracy: 0.8449\n",
      "Epoch 90/1000\n",
      "31/39 [======================>.......] - ETA: 0s - loss: 0.0442 - accuracy: 0.9841\n",
      "Epoch 90: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0440 - accuracy: 0.9842 - val_loss: 0.6811 - val_accuracy: 0.8391\n",
      "Epoch 91/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0308 - accuracy: 0.9902\n",
      "Epoch 91: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0297 - accuracy: 0.9909 - val_loss: 0.6893 - val_accuracy: 0.8507\n",
      "Epoch 92/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0270 - accuracy: 0.9924\n",
      "Epoch 92: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0288 - accuracy: 0.9919 - val_loss: 0.7014 - val_accuracy: 0.8458\n",
      "Epoch 93/1000\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.0246 - accuracy: 0.9934\n",
      "Epoch 93: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0235 - accuracy: 0.9936 - val_loss: 0.7178 - val_accuracy: 0.8466\n",
      "Epoch 94/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0255 - accuracy: 0.9936\n",
      "Epoch 94: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0263 - accuracy: 0.9934 - val_loss: 0.7380 - val_accuracy: 0.8458\n",
      "Epoch 95/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0234 - accuracy: 0.9946\n",
      "Epoch 95: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0263 - accuracy: 0.9929 - val_loss: 0.7416 - val_accuracy: 0.8524\n",
      "Epoch 96/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0242 - accuracy: 0.9932\n",
      "Epoch 96: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0238 - accuracy: 0.9934 - val_loss: 0.7280 - val_accuracy: 0.8532\n",
      "Epoch 97/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0248 - accuracy: 0.9932\n",
      "Epoch 97: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 0.9936 - val_loss: 0.7514 - val_accuracy: 0.8474\n",
      "Epoch 98/1000\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.0197 - accuracy: 0.9948\n",
      "Epoch 98: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0209 - accuracy: 0.9944 - val_loss: 0.7919 - val_accuracy: 0.8466\n",
      "Epoch 99/1000\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.0242 - accuracy: 0.9935\n",
      "Epoch 99: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0232 - accuracy: 0.9938 - val_loss: 0.7705 - val_accuracy: 0.8433\n",
      "Epoch 100/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0208 - accuracy: 0.9941\n",
      "Epoch 100: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0206 - accuracy: 0.9938 - val_loss: 0.7704 - val_accuracy: 0.8425\n",
      "Epoch 101/1000\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.0219 - accuracy: 0.9934\n",
      "Epoch 101: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0214 - accuracy: 0.9942 - val_loss: 0.7910 - val_accuracy: 0.8466\n",
      "Epoch 102/1000\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.0215 - accuracy: 0.9938\n",
      "Epoch 102: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0209 - accuracy: 0.9942 - val_loss: 0.8345 - val_accuracy: 0.8391\n",
      "Epoch 103/1000\n",
      "35/39 [=========================>....] - ETA: 0s - loss: 0.0313 - accuracy: 0.9882\n",
      "Epoch 103: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0307 - accuracy: 0.9886 - val_loss: 0.7944 - val_accuracy: 0.8516\n",
      "Epoch 104/1000\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.0478 - accuracy: 0.9800\n",
      "Epoch 104: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.0391 - accuracy: 0.9844 - val_loss: 0.7921 - val_accuracy: 0.8449\n",
      "Epoch 105/1000\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.0237 - accuracy: 0.9925\n",
      "Epoch 105: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0228 - accuracy: 0.9932 - val_loss: 0.7979 - val_accuracy: 0.8516\n",
      "Epoch 106/1000\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 0.0235 - accuracy: 0.9935\n",
      "Epoch 106: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0231 - accuracy: 0.9938 - val_loss: 0.8078 - val_accuracy: 0.8491\n",
      "Epoch 107/1000\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9962\n",
      "Epoch 107: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0149 - accuracy: 0.9963 - val_loss: 0.8071 - val_accuracy: 0.8474\n",
      "Epoch 108/1000\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.0145 - accuracy: 0.9970\n",
      "Epoch 108: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.0148 - accuracy: 0.9967 - val_loss: 0.8159 - val_accuracy: 0.8483\n",
      "Epoch 109/1000\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.0154 - accuracy: 0.9958\n",
      "Epoch 109: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.8340 - val_accuracy: 0.8449\n",
      "Epoch 110/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0189 - accuracy: 0.9936\n",
      "Epoch 110: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0182 - accuracy: 0.9940 - val_loss: 0.8741 - val_accuracy: 0.8383\n",
      "Epoch 111/1000\n",
      "32/39 [=======================>......] - ETA: 0s - loss: 0.0143 - accuracy: 0.9950\n",
      "Epoch 111: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.8418 - val_accuracy: 0.8458\n",
      "Epoch 112/1000\n",
      "29/39 [=====================>........] - ETA: 0s - loss: 0.0179 - accuracy: 0.9958\n",
      "Epoch 112: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0192 - accuracy: 0.9950 - val_loss: 0.8589 - val_accuracy: 0.8458\n",
      "Epoch 113/1000\n",
      "30/39 [======================>.......] - ETA: 0s - loss: 0.0130 - accuracy: 0.9973\n",
      "Epoch 113: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0126 - accuracy: 0.9973 - val_loss: 0.9080 - val_accuracy: 0.8400\n",
      "Epoch 114/1000\n",
      "28/39 [====================>.........] - ETA: 0s - loss: 0.0137 - accuracy: 0.9954\n",
      "Epoch 114: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0148 - accuracy: 0.9950 - val_loss: 0.8711 - val_accuracy: 0.8391\n",
      "Epoch 115/1000\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 0.0165 - accuracy: 0.9944\n",
      "Epoch 115: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0167 - accuracy: 0.9944 - val_loss: 0.8651 - val_accuracy: 0.8532\n",
      "Epoch 116/1000\n",
      "36/39 [==========================>...] - ETA: 0s - loss: 0.0203 - accuracy: 0.9926\n",
      "Epoch 116: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.0223 - accuracy: 0.9915 - val_loss: 0.8694 - val_accuracy: 0.8499\n",
      "Epoch 117/1000\n",
      "34/39 [=========================>....] - ETA: 0s - loss: 0.0168 - accuracy: 0.9948\n",
      "Epoch 117: val_accuracy did not improve from 0.88226\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 0.8643 - val_accuracy: 0.8466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x16956f950>"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define the deep learning model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#earlyStopping\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "\n",
    "# Define the ModelCheckpoint callback\n",
    "checkpoint = ModelCheckpoint(filepath='best_model_weights2.h5', save_weights_only=True, monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "\n",
    "\n",
    "#compile\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#train\n",
    "model.fit(X_train, y_train, epochs=1000, batch_size=124, validation_data=(X_test, y_test), callbacks=[checkpoint, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8814262023217247"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "y_hat = [0 if val<0.5 else 1 for val in y_hat]\n",
    "accuracy_score(y_test,y_hat)\n",
    "\n",
    "#0.8864013266998342"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked Variables:\n",
      "blueCorner_nation_50: 0.21174356341362\n",
      "blueCorner_nation_6: 0.16472549736499786\n",
      "venue_120: 0.14383138716220856\n",
      "venue_57: 0.13589636981487274\n",
      "venue_162: 0.12582555413246155\n",
      "redCorner_nation_58: 0.12574870884418488\n",
      "blueCorner_nation_13: 0.12402216345071793\n",
      "redCorner_nation_95: 0.12378573417663574\n",
      "blueCorner_nation_26: 0.12047754228115082\n",
      "blueCorner_nation_2: 0.1198096051812172\n",
      "blueCorner_nation_93: 0.11854516714811325\n",
      "blueCorner_nation_55: 0.11648006737232208\n",
      "venue_142: 0.11283749341964722\n",
      "venue_30: 0.11148937046527863\n",
      "venue_11: 0.11033229529857635\n",
      "blueCorner_nation_44: 0.10973824560642242\n",
      "venue_133: 0.10907673090696335\n",
      "blueCorner_subs_attempted: 0.10896721482276917\n",
      "redCorner_nation_22: 0.1074802577495575\n",
      "redCorner: 0.10747494548559189\n",
      "venue_127: 0.10713514685630798\n",
      "venue_143: 0.10581628978252411\n",
      "blueCorner_nation_46: 0.1058102548122406\n",
      "redCorner_draws: 0.10473790764808655\n",
      "venue_139: 0.10439343750476837\n",
      "redCorner_nation_88: 0.10430562496185303\n",
      "redCorner_nation_51: 0.1042865514755249\n",
      "redCorner_nation_47: 0.10420186072587967\n",
      "venue_81: 0.10409395396709442\n",
      "venue_190: 0.10363789647817612\n",
      "blueCorner_nation_64: 0.10360904783010483\n",
      "redCorner_nation_0: 0.10340449213981628\n",
      "venue_92: 0.10337556898593903\n",
      "venue_209: 0.10332036018371582\n",
      "venue_131: 0.10301816463470459\n",
      "blueCorner_nation_51: 0.10277282446622849\n",
      "venue_132: 0.10257318615913391\n",
      "venue_119: 0.10249889642000198\n",
      "venue_113: 0.10246295481920242\n",
      "redCorner_nation_25: 0.10235045105218887\n",
      "blueCorner_nation_92: 0.10227794945240021\n",
      "venue_36: 0.10175898671150208\n",
      "blueCorner_knockdowns: 0.10169734060764313\n",
      "venue_95: 0.10144311189651489\n",
      "redCorner_nation_60: 0.10106800496578217\n",
      "redCorner_nation_97: 0.10051631182432175\n",
      "redCorner_nation_78: 0.10051213204860687\n",
      "venue_93: 0.10027646273374557\n",
      "blueCorner_nation_109: 0.09963876008987427\n",
      "blueCorner_nation_104: 0.09948381036520004\n",
      "venue_104: 0.0990283265709877\n",
      "venue_50: 0.09889275580644608\n",
      "venue_59: 0.09880116581916809\n",
      "blueCorner_nation_23: 0.09844543039798737\n",
      "redCorner_losses: 0.09842542558908463\n",
      "blueCorner_nation_21: 0.09818266332149506\n",
      "blueCorner_sig_str_defense: 0.09808237850666046\n",
      "redCorner_nation_27: 0.09792616963386536\n",
      "venue_80: 0.09716664999723434\n",
      "redCorner_nation_96: 0.09684086591005325\n",
      "redCorner_nation_32: 0.09661844372749329\n",
      "venue_106: 0.09644884616136551\n",
      "venue_136: 0.09615369886159897\n",
      "venue_130: 0.09584370255470276\n",
      "venue_154: 0.09526840597391129\n",
      "blueCorner_nation_32: 0.09442416578531265\n",
      "redCorner_sig_str_defense: 0.09437994658946991\n",
      "venue_83: 0.09352237731218338\n",
      "redCorner_nation_38: 0.09339535981416702\n",
      "blueCorner_nation_11: 0.09262455999851227\n",
      "venue_177: 0.09255322813987732\n",
      "redCorner_nation_40: 0.09155790507793427\n",
      "venue_34: 0.09119419008493423\n",
      "blueCorner_nation_77: 0.09097172319889069\n",
      "venue_39: 0.09084250777959824\n",
      "venue_14: 0.09062504023313522\n",
      "blueCorner_nation_28: 0.09044404327869415\n",
      "blueCorner_nation_91: 0.08997544646263123\n",
      "venue_3: 0.0896599069237709\n",
      "blueCorner_nation_57: 0.08952781558036804\n",
      "blueCorner_nation_58: 0.08899003267288208\n",
      "blueCorner_nation_65: 0.08872977644205093\n",
      "redCorner_nation_11: 0.08847324550151825\n",
      "blueCorner_sig_str_landed_per_minute: 0.08823783695697784\n",
      "venue_52: 0.08809268474578857\n",
      "redCorner_nation_98: 0.08777948468923569\n",
      "blueCorner_nation_14: 0.08760686963796616\n",
      "billing_0: 0.08743980526924133\n",
      "venue_89: 0.0871279239654541\n",
      "blueCorner_nation_42: 0.08689190447330475\n",
      "blueCorner_nation_38: 0.0866163894534111\n",
      "blueCorner_sig_str_absorbed_per_minute: 0.08659656345844269\n",
      "blueCorner_nation_80: 0.08658581972122192\n",
      "blueCorner_takedowns: 0.0861046239733696\n",
      "venue_77: 0.08551165461540222\n",
      "blueCorner_nation_70: 0.08545989543199539\n",
      "blueCorner_nation_94: 0.08537830412387848\n",
      "redCorner_nation_57: 0.08515897393226624\n",
      "blueCorner_nation_79: 0.08445267379283905\n",
      "venue_153: 0.08367422223091125\n",
      "venue_51: 0.08303683996200562\n",
      "blueCorner_nation_45: 0.08179590106010437\n",
      "venue_40: 0.08108547329902649\n",
      "redCorner_nation_26: 0.08091611415147781\n",
      "venue_70: 0.08024896681308746\n",
      "venue_68: 0.0796465054154396\n",
      "blueCorner_nation_52: 0.07957514375448227\n",
      "venue_111: 0.07953327894210815\n",
      "venue_145: 0.0786069855093956\n",
      "venue_85: 0.07840929925441742\n",
      "redCorner_nation_7: 0.07796168327331543\n",
      "venue_60: 0.0774356946349144\n",
      "blueCorner_nation_18: 0.07742925733327866\n",
      "blueCorner_nation_34: 0.07734659314155579\n",
      "redCorner_takedown_defense: 0.07722766697406769\n",
      "redCorner_nation_89: 0.07686556130647659\n",
      "blueCorner_nation_108: 0.07658181339502335\n",
      "venue_45: 0.07615981251001358\n",
      "venue_75: 0.07587973773479462\n",
      "venue_84: 0.07582142949104309\n",
      "redCorner_nation_70: 0.07556666433811188\n",
      "venue_53: 0.07545123249292374\n",
      "redCorner_sig_str_absorbed_per_minute: 0.0752241313457489\n",
      "redCorner_nation_1: 0.07472197711467743\n",
      "blueCorner_nation_16: 0.07469994574785233\n",
      "redCorner_nation_66: 0.07460431754589081\n",
      "venue_1: 0.07430999726057053\n",
      "venue_47: 0.07421204447746277\n",
      "redCorner_nation_14: 0.07355661690235138\n",
      "redCorner_nation_65: 0.07337296009063721\n",
      "venue_55: 0.07327940315008163\n",
      "venue_5: 0.07322970777750015\n",
      "blueCorner_nation_47: 0.07320579141378403\n",
      "venue_160: 0.07289934903383255\n",
      "redCorner_nation_3: 0.07250537723302841\n",
      "venue_54: 0.07249341905117035\n",
      "redCorner_nation_94: 0.07243947684764862\n",
      "blueCorner_nation_31: 0.0715809240937233\n",
      "venue_37: 0.0712878629565239\n",
      "redCorner_nation_49: 0.07126622647047043\n",
      "blueCorner_nation_43: 0.07088155299425125\n",
      "venue_26: 0.07059494405984879\n",
      "redCorner_nation_62: 0.07018948346376419\n",
      "venue_125: 0.06983597576618195\n",
      "blueCorner_nation_62: 0.06963462382555008\n",
      "venue_118: 0.06953086704015732\n",
      "blueCorner_nation_0: 0.06948009133338928\n",
      "blueCorner_nation_78: 0.06900878995656967\n",
      "blueCorner_nation_110: 0.06899046152830124\n",
      "venue_21: 0.0686551034450531\n",
      "redCorner_sig_str_landed_per_minute: 0.06814825534820557\n",
      "redCorner_nation_77: 0.06787413358688354\n",
      "venue_100: 0.06741444766521454\n",
      "redCorner_nation_68: 0.06736856698989868\n",
      "venue_152: 0.067206472158432\n",
      "venue_38: 0.06714056432247162\n",
      "blueCorner_nation_76: 0.06704788655042648\n",
      "redCorner_nation_48: 0.06665261834859848\n",
      "redCorner_nation_87: 0.06633707135915756\n",
      "venue_144: 0.06610386818647385\n",
      "venue_8: 0.06608995050191879\n",
      "blueCorner_nation_63: 0.06607423722743988\n",
      "blueCorner_nation_24: 0.06568704545497894\n",
      "blueCorner_nation_75: 0.06535552442073822\n",
      "venue_28: 0.06532736867666245\n",
      "redCorner_nation_12: 0.0652451366186142\n",
      "redCorner_nation_18: 0.06509867310523987\n",
      "redCorner_nation_61: 0.06484701484441757\n",
      "blueCorner_nation_103: 0.06445033103227615\n",
      "redCorner_nation_93: 0.06395971029996872\n",
      "blueCorner_nation_68: 0.06378678977489471\n",
      "venue_19: 0.061655715107917786\n",
      "venue_48: 0.061634015291929245\n",
      "venue_149: 0.061325427144765854\n",
      "blueCorner_nation_22: 0.06123737245798111\n",
      "redCorner_nation_80: 0.06097402051091194\n",
      "redCorner_nation_72: 0.060549668967723846\n",
      "venue_180: 0.060536015778779984\n",
      "venue_17: 0.060439180582761765\n",
      "venue_148: 0.0602298229932785\n",
      "redCorner_nation_23: 0.05989271029829979\n",
      "redCorner_nation_2: 0.05980849266052246\n",
      "venue_16: 0.05978778749704361\n",
      "redCorner_nation_6: 0.05978357791900635\n",
      "blueCorner_nation_19: 0.0591200590133667\n",
      "redCorner_nation_69: 0.058507394045591354\n",
      "venue_71: 0.0584445483982563\n",
      "redCorner_nation_46: 0.058074891567230225\n",
      "venue_112: 0.057445164769887924\n",
      "redCorner_nation_37: 0.05682479217648506\n",
      "venue_49: 0.056540172547101974\n",
      "redCorner_nation_39: 0.05564263463020325\n",
      "blueCorner_nation_9: 0.05552012845873833\n",
      "blueCorner_nation_33: 0.05539444833993912\n",
      "redCorner_nation_34: 0.05524633824825287\n",
      "venue_134: 0.055083587765693665\n",
      "venue_86: 0.05478883162140846\n",
      "blueCorner_nation_105: 0.05443856865167618\n",
      "venue_4: 0.05398419499397278\n",
      "blueCorner_nation_4: 0.05374643951654434\n",
      "redCorner_nation_74: 0.05365961045026779\n",
      "billing_1: 0.053302228450775146\n",
      "venue_35: 0.05314001813530922\n",
      "billing_2: 0.05296283960342407\n",
      "venue_197: 0.05260343849658966\n",
      "title_fight: 0.052052661776542664\n",
      "venue_185: 0.05130602419376373\n",
      "venue_129: 0.05116208642721176\n",
      "blueCorner_nation_35: 0.050989918410778046\n",
      "venue_9: 0.05066090077161789\n",
      "blueCorner: 0.050658561289310455\n",
      "venue_208: 0.05052613094449043\n",
      "redCorner_nation_59: 0.05049284175038338\n",
      "venue_18: 0.050242479890584946\n",
      "redCorner_nation_35: 0.050106994807720184\n",
      "redCorner_nation_83: 0.049479901790618896\n",
      "venue_73: 0.04942111670970917\n",
      "redCorner_nation_91: 0.04927200824022293\n",
      "venue_2: 0.04896072298288345\n",
      "venue_24: 0.048698790371418\n",
      "venue_6: 0.04863790422677994\n",
      "venue_141: 0.04830104485154152\n",
      "redCorner_nation_24: 0.04803831875324249\n",
      "venue_110: 0.04790547490119934\n",
      "venue_159: 0.047763142734766006\n",
      "blueCorner_nation_20: 0.047737881541252136\n",
      "redCorner_age: 0.047705866396427155\n",
      "venue_90: 0.04765244945883751\n",
      "redCorner_nation_31: 0.04755128175020218\n",
      "redCorner_nation_99: 0.0470692440867424\n",
      "blueCorner_nation_73: 0.04671682044863701\n",
      "venue_205: 0.0458819717168808\n",
      "blueCorner_nation_60: 0.045566216111183167\n",
      "venue_88: 0.04546301066875458\n",
      "redCorner_nation_8: 0.0452456921339035\n",
      "venue_82: 0.044822726398706436\n",
      "venue_41: 0.04467026889324188\n",
      "blueCorner_nation_27: 0.04460225626826286\n",
      "blueCorner_nation_5: 0.04457971453666687\n",
      "venue_58: 0.04438212513923645\n",
      "venue_207: 0.0442955382168293\n",
      "redCorner_nation_9: 0.043467216193675995\n",
      "blueCorner_nation_72: 0.043446507304906845\n",
      "blueCorner_nation_74: 0.04311589151620865\n",
      "venue_107: 0.04278005659580231\n",
      "venue_102: 0.04267003759741783\n",
      "redCorner_nation_100: 0.04260546341538429\n",
      "redCorner_nation_17: 0.04239541292190552\n",
      "blueCorner_nation_83: 0.04238484054803848\n",
      "venue_29: 0.04212305322289467\n",
      "blueCorner_nation_56: 0.04203053191304207\n",
      "venue_101: 0.0418037474155426\n",
      "venue_74: 0.04148207977414131\n",
      "venue_128: 0.0408463329076767\n",
      "redCorner_subs_attempted: 0.040802329778671265\n",
      "venue_161: 0.04048436880111694\n",
      "redCorner_nation_82: 0.040284521877765656\n",
      "redCorner_nation_86: 0.03929014503955841\n",
      "redCorner_nation_20: 0.039151325821876526\n",
      "venue_91: 0.03896680474281311\n",
      "venue_27: 0.03875749558210373\n",
      "blueCorner_nation_61: 0.038507841527462006\n",
      "venue_99: 0.03789933770895004\n",
      "blueCorner_nation_30: 0.037656884640455246\n",
      "venue_194: 0.03737586736679077\n",
      "redCorner_nation_52: 0.0369371622800827\n",
      "venue_32: 0.03691538795828819\n",
      "venue_66: 0.036798518151044846\n",
      "blueCorner_nation_41: 0.03678172826766968\n",
      "venue_61: 0.036030977964401245\n",
      "blueCorner_nation_102: 0.03577720373868942\n",
      "venue_126: 0.03563559800386429\n",
      "blueCorner_takedown_percentage: 0.035625115036964417\n",
      "venue_116: 0.035486675798892975\n",
      "venue_123: 0.035198476165533066\n",
      "venue_56: 0.034612640738487244\n",
      "venue_43: 0.03427083045244217\n",
      "venue_196: 0.03426780924201012\n",
      "venue_12: 0.03374665975570679\n",
      "blueCorner_nation_37: 0.033731356263160706\n",
      "blueCorner_nation_1: 0.03341327980160713\n",
      "venue_87: 0.03338528051972389\n",
      "venue_10: 0.03289187699556351\n",
      "redCorner_nation_50: 0.03282109647989273\n",
      "blueCorner_nation_89: 0.032730065286159515\n",
      "blueCorner_nation_71: 0.032502349466085434\n",
      "venue_64: 0.032229844480752945\n",
      "venue_31: 0.032103948295116425\n",
      "venue_121: 0.03207572177052498\n",
      "redCorner_wins: 0.03205929696559906\n",
      "venue_33: 0.03190436214208603\n",
      "blueCorner_nation_59: 0.031762320548295975\n",
      "venue_78: 0.030386917293071747\n",
      "redCorner_sig_str_percentage: 0.030386626720428467\n",
      "venue_0: 0.03021809458732605\n",
      "venue_79: 0.030055196955800056\n",
      "redCorner_nation_5: 0.029756933450698853\n",
      "blueCorner_nation_39: 0.029735412448644638\n",
      "blueCorner_nation_82: 0.029611114412546158\n",
      "redCorner_nation_4: 0.02915244549512863\n",
      "redCorner_nation_28: 0.02898772805929184\n",
      "blueCorner_nation_66: 0.02840811386704445\n",
      "venue_189: 0.028116676956415176\n",
      "venue_13: 0.028096849098801613\n",
      "venue_46: 0.027702700346708298\n",
      "redCorner_takedown_percentage: 0.027667522430419922\n",
      "redCorner_nation_75: 0.027509693056344986\n",
      "venue_124: 0.027488622814416885\n",
      "redCorner_nation_13: 0.027463018894195557\n",
      "redCorner_nation_64: 0.02725524827837944\n",
      "billing_3: 0.027053043246269226\n",
      "redCorner_nation_19: 0.02688261866569519\n",
      "blueCorner_nation_85: 0.0265139602124691\n",
      "redCorner_nation_56: 0.026454098522663116\n",
      "venue_202: 0.026082441210746765\n",
      "redCorner_nation_63: 0.025240998715162277\n",
      "venue_122: 0.025059014558792114\n",
      "venue_172: 0.024921534582972527\n",
      "redCorner_nation_76: 0.024584230035543442\n",
      "redCorner_nation_43: 0.02449519746005535\n",
      "venue_108: 0.02438490092754364\n",
      "venue_201: 0.0242875125259161\n",
      "venue_97: 0.024227740243077278\n",
      "blueCorner_wins: 0.02335517108440399\n",
      "venue_181: 0.023152124136686325\n",
      "redCorner_nation_85: 0.023151621222496033\n",
      "blueCorner_nation_48: 0.023009194061160088\n",
      "venue_206: 0.023003259673714638\n",
      "blueCorner_nation_7: 0.022921882569789886\n",
      "redCorner_nation_41: 0.02245384454727173\n",
      "blueCorner_takedown_defense: 0.02195090800523758\n",
      "redCorner_nation_53: 0.021344458684325218\n",
      "blueCorner_nation_81: 0.021204674616456032\n",
      "redCorner_nation_79: 0.019826281815767288\n",
      "blueCorner_nation_36: 0.019174348562955856\n",
      "venue_117: 0.019093096256256104\n",
      "venue_135: 0.019009623676538467\n",
      "venue_23: 0.019001543521881104\n",
      "venue_63: 0.01876959763467312\n",
      "venue_103: 0.01850942336022854\n",
      "venue_94: 0.01829385943710804\n",
      "venue_114: 0.01823749952018261\n",
      "redCorner_nation_55: 0.017908992245793343\n",
      "venue_186: 0.017550691962242126\n",
      "venue_44: 0.017305150628089905\n",
      "venue_198: 0.01702772080898285\n",
      "venue_158: 0.01686721295118332\n",
      "redCorner_nation_33: 0.016772329807281494\n",
      "venue_7: 0.0166416484862566\n",
      "blueCorner_nation_84: 0.016178131103515625\n",
      "venue_76: 0.016046464443206787\n",
      "blueCorner_nation_54: 0.015978900715708733\n",
      "venue_109: 0.015830205753445625\n",
      "blueCorner_losses: 0.01567821204662323\n",
      "blueCorner_nation_12: 0.015480206348001957\n",
      "venue_15: 0.015114601701498032\n",
      "blueCorner_nation_53: 0.014904428273439407\n",
      "redCorner_takedowns: 0.014833718538284302\n",
      "redCorner_nation_92: 0.01481247041374445\n",
      "redCorner_nation_71: 0.014748737215995789\n",
      "blueCorner_nation_29: 0.014346355572342873\n",
      "redCorner_nation_10: 0.01427026093006134\n",
      "venue_179: 0.014090120792388916\n",
      "venue_65: 0.012625232338905334\n",
      "blueCorner_nation_88: 0.012135371565818787\n",
      "redCorner_nation_44: 0.011920091696083546\n",
      "blueCorner_nation_3: 0.01110451016575098\n",
      "venue_25: 0.010912173427641392\n",
      "venue_62: 0.010850011371076107\n",
      "venue_105: 0.010282833129167557\n",
      "redCorner_nation_90: 0.010115149430930614\n",
      "redCorner_nation_15: 0.010090455412864685\n",
      "blueCorner_nation_90: 0.010026742704212666\n",
      "blueCorner_nation_8: 0.009841633029282093\n",
      "redCorner_nation_21: 0.00977732241153717\n",
      "venue_96: 0.00974165741354227\n",
      "venue_174: 0.009019446559250355\n",
      "venue_22: 0.008879682049155235\n",
      "redCorner_nation_45: 0.00867882277816534\n",
      "blueCorner_nation_107: 0.008608013391494751\n",
      "redCorner_nation_73: 0.008162074722349644\n",
      "venue_67: 0.007961227558553219\n",
      "redCorner_nation_42: 0.007820247672498226\n",
      "redCorner_nation_67: 0.007778431288897991\n",
      "blueCorner_nation_87: 0.007564514875411987\n",
      "blueCorner_nation_15: 0.00751979136839509\n",
      "blueCorner_nation_101: 0.007483386900275946\n",
      "blueCorner_nation_86: 0.007344787009060383\n",
      "blueCorner_nation_25: 0.006631027441471815\n",
      "blueCorner_nation_17: 0.0064753517508506775\n",
      "blueCorner_sig_str_percentage: 0.00622490793466568\n",
      "venue_98: 0.006204658187925816\n",
      "blueCorner_nation_10: 0.006112679373472929\n",
      "venue_72: 0.005412606988102198\n",
      "blueCorner_nation_106: 0.005118461325764656\n",
      "venue_115: 0.004696319345384836\n",
      "redCorner_nation_29: 0.004643067717552185\n",
      "redCorner_nation_30: 0.004514604806900024\n",
      "blueCorner_age: 0.0035957545042037964\n",
      "venue_178: 0.0033712477888911963\n",
      "blueCorner_nation_67: 0.0031624818220734596\n",
      "redCorner_nation_84: 0.0029233095701783895\n",
      "redCorner_nation_54: 0.0024622869677841663\n",
      "blueCorner_nation_69: 0.0024265304673463106\n",
      "fightTime: 0.0020868629217147827\n",
      "venue_140: 0.0019604263361543417\n",
      "blueCorner_draws: 0.0017600879073143005\n",
      "redCorner_knockdowns: 0.0014051422476768494\n",
      "blueCorner_nation_40: 0.0012610716512426734\n",
      "venue_20: 0.0012244954705238342\n",
      "venue_69: 0.0012112932745367289\n",
      "blueCorner_nation_49: 0.0011035124771296978\n",
      "redCorner_nation_81: 0.0006481744931079447\n",
      "venue_182: 0.0004038734477944672\n",
      "redCorner_nation_36: 7.944993558339775e-05\n"
     ]
    }
   ],
   "source": [
    "#variable weights\n",
    "first_layer_weights = model.layers[0].get_weights()[0]\n",
    "input_variables = X_train.columns\n",
    "variable_weights = dict(zip(input_variables, np.abs(first_layer_weights.flatten())))\n",
    "ranked_variables = sorted(variable_weights.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Ranked Variables:\")\n",
    "for variable, weight in ranked_variables:\n",
    "    print(f\"{variable}: {weight}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
