{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import math\n",
    "import csv\n",
    "from csv import writer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#site request\n",
    "url = \"https://www.ufc.com/athletes/all\"\n",
    "\n",
    "querystring = {\"page\":\"0\"}\n",
    "\n",
    "payload = \"\"\n",
    "headers = {\n",
    "    \"cookie\": \"STYXKEY_region=USA.US.en.Default\",\n",
    "    \"User-Agent\": \"insomnia/8.5.0\"\n",
    "}\n",
    "\n",
    "response = requests.request(\"GET\", url, data=payload, headers=headers, params=querystring)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Athletes found: 2936\n"
     ]
    }
   ],
   "source": [
    "#create soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "div = soup.find('div', class_=re.compile('althelete-total'))\n",
    "\n",
    "#get num athletes\n",
    "athleteTotal = div.text.strip().split(' ')[0]\n",
    "print(f\"Athletes found: {athleteTotal}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266\n"
     ]
    }
   ],
   "source": [
    "#calc number of pages to loop through - 11 fighters shown per\n",
    "numPages = math.floor(int(athleteTotal)/11)\n",
    "print(numPages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fighter links found: 2926\n"
     ]
    }
   ],
   "source": [
    "linkParts = []\n",
    "for i in range(numPages):\n",
    "    #site request\n",
    "    url = \"https://www.ufc.com/athletes/all\"\n",
    "    querystring = {\"page\":f\"{i}\"}\n",
    "\n",
    "    payload = \"\"\n",
    "    headers = {\n",
    "        \"cookie\": \"STYXKEY_region=USA.US.en.Default\",\n",
    "        \"User-Agent\": \"insomnia/8.5.0\"\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, data=payload, headers=headers, params=querystring)\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    urlParts = soup.find_all('a', class_=re.compile(\"e-button--black\"))\n",
    "\n",
    "\n",
    "\n",
    "    for part in urlParts:\n",
    "        href = part['href']\n",
    "        if href:\n",
    "            linkParts.append(href)\n",
    "\n",
    "print(f\"Fighter links found: {len(linkParts)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Shamil Abdurakhimov...\n",
      "https://www.ufc.com/athlete/shamil-abdurakhimov\n",
      "[['Shamil Abdurakhimov', '20', '8', '0', '75.00', '76.00', '41', 'Dagestan Republic, Russia', '44%', '251 of 567', '23%', '5 of 30', '2.41', '1.01', '55%', '0.29', '3.02', '0.14', '45%', '09:27']]\n"
     ]
    }
   ],
   "source": [
    "fighterStats = []\n",
    "\n",
    "#scrape statistics\n",
    "url = f\"https://www.ufc.com{linkParts[4]}\"\n",
    "site = requests.get(url, headers=headers)\n",
    "\n",
    "#initalize attributes\n",
    "name = None\n",
    "wins = None\n",
    "losses = None\n",
    "draws = None\n",
    "sig_str_accuracy = None\n",
    "sig_str_totals = None\n",
    "takedown_accuracy = None\n",
    "takedown_totals = None\n",
    "sig_str_per_minute = None\n",
    "takedown_avg_per_fifteen = None\n",
    "sig_str_defense = None\n",
    "knockdown_avg = None\n",
    "sig_str_absorbed_per_min = None\n",
    "submission_avg_per_fifteen = None\n",
    "takedown_defense = None\n",
    "avg_fight_time = None\n",
    "nation = None\n",
    "age = None\n",
    "height = None\n",
    "reach = None\n",
    "\n",
    "#soup\n",
    "soup = BeautifulSoup(site.content, 'html.parser')\n",
    "\n",
    "#scrape + clean name\n",
    "try:\n",
    "    name = soup.find('h1', class_=re.compile('hero-profile__name')).text.strip()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#scrape + clean wins, losses, draws\n",
    "try:\n",
    "    record = soup.find('p', class_=re.compile('hero-profile__division-body')).text.strip().split(' ')\n",
    "    record = record[0].split('-')\n",
    "    wins = record[0]\n",
    "    losses = record[1]\n",
    "    draws = record[2]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#scrape + clean sig_str_accuracy + sig_str_totals + takedown_accuracy + takedown_totals\n",
    "try:\n",
    "    div = soup.find_all('div', class_=re.compile(\"overlap-athlete-content overlap-athlete-content--horizontal\"))\n",
    "    stripped = div[0].text.strip().split('\\n')\n",
    "    clean_stripped = [item for item in stripped if item != '']\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    if(clean_stripped[2].lower() == 'striking accuracy'):\n",
    "        sig_str_accuracy = clean_stripped[1]\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    if(clean_stripped[3].lower() == \"sig. strikes landed\" and clean_stripped[5].lower() == \"sig. strikes attempted\"):\n",
    "        sig_str_totals = f\"{clean_stripped[4]} of {clean_stripped[6]}\"\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    stripped = div[1].text.strip().split('\\n')\n",
    "    clean_stripped = [item for item in stripped if item != '']\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    if clean_stripped[2].lower() == 'takedown accuracy':\n",
    "        takedown_accuracy = clean_stripped[1]\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    if clean_stripped[3].lower() == 'takedowns landed' and clean_stripped[5].lower() == \"takedowns attempted\":\n",
    "        takedown_totals = f\"{clean_stripped[4]} of {clean_stripped[6]}\"\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "#scrape + clean sig_str_per_minute + takedown_avg_per_fifteen + sig_str_defense + knockdown_avg\n",
    "\n",
    "divs = soup.find_all('div', class_=re.compile('c-stat-compare__group c-stat-compare__group-1'))\n",
    "\n",
    "for div in divs:\n",
    "    try:\n",
    "        if(div.find('div', class_=re.compile('c-stat-compare__label')).text.strip().lower() == \"sig. str. landed\"):\n",
    "            sig_str_per_minute = div.find('div', class_=re.compile(\"c-stat-compare__number\")).text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        if(div.find('div', class_=re.compile('c-stat-compare__label')).text.strip().lower() == \"takedown avg\"):\n",
    "            takedown_avg_per_fifteen = div.find('div', class_=re.compile(\"c-stat-compare__number\")).text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        if(div.find('div', class_=re.compile('c-stat-compare__label')).text.strip().lower() == \"sig. str. defense\"):\n",
    "            sig_str_defense = f\"{div.find('div', class_=re.compile(\"c-stat-compare__number\")).text.strip().split('\\n')[0]}%\"\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        if(div.find('div', class_=re.compile('c-stat-compare__label')).text.strip().lower() == \"knockdown avg\"):\n",
    "            knockdown_avg = div.find('div', class_=re.compile(\"c-stat-compare__number\")).text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "# scrape + clean sig_str_absorbed_per_min + submission_avg_per_fifteen + takedown_defense + avg_fight_time\n",
    "divs = soup.find_all('div', re.compile('c-stat-compare__group c-stat-compare__group-2'))\n",
    "for div in divs:\n",
    "    try:\n",
    "        if(div.find('div', class_=re.compile('c-stat-compare__label')).text.strip().lower() == \"sig. str. absorbed\"):\n",
    "            sig_str_absorbed_per_min = div.find('div', class_=re.compile(\"c-stat-compare__number\")).text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        if(div.find('div', class_=re.compile('c-stat-compare__label')).text.strip().lower() == \"submission avg\"):\n",
    "            submission_avg_per_fifteen = div.find('div', class_=re.compile(\"c-stat-compare__number\")).text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        if(div.find('div', class_=re.compile('c-stat-compare__label')).text.strip().lower() == \"takedown defense\"):\n",
    "            takedown_defense = f\"{div.find('div', class_=re.compile(\"c-stat-compare__number\")).text.strip().split('\\n')[0]}%\"\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        if(div.find('div', class_=re.compile('c-stat-compare__label')).text.strip().lower() == \"average fight time\"):\n",
    "            avg_fight_time = div.find('div', class_=re.compile(\"c-stat-compare__number\")).text.strip()\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "\n",
    "\n",
    "#scrape + clean nation + age + height + reach\n",
    "divs = soup.find_all('div', class_=re.compile('c-bio__field'))\n",
    "\n",
    "for div in divs:\n",
    "    try:\n",
    "        if(div.find('div', class_=re.compile('c-bio__label')).text.strip().lower() == 'place of birth'):\n",
    "            nation = div.find('div', class_=re.compile('c-bio__text')).text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        if(div.find('div', class_=re.compile('c-bio__label')).text.strip().lower() == 'age'):\n",
    "            age = div.find('div', class_=re.compile('field field--name-age field--type-integer field--label-hidden field__item')).text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        if(div.find('div', class_=re.compile('c-bio__label')).text.strip().lower() == 'height'):\n",
    "            height = div.find('div', class_=re.compile('c-bio__text')).text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        if(div.find('div', class_=re.compile('c-bio__label')).text.strip().lower() == 'reach'):\n",
    "            reach = div.find('div', class_=re.compile('c-bio__text')).text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "print(f'Scraping {name}...')\n",
    "print(url)\n",
    "fighterStats.append([name, wins, losses, draws, height, reach, age, nation, sig_str_accuracy, sig_str_totals, takedown_accuracy, takedown_totals, sig_str_per_minute, takedown_avg_per_fifteen, sig_str_defense, knockdown_avg, sig_str_absorbed_per_min, submission_avg_per_fifteen, takedown_defense, avg_fight_time])\n",
    "print(fighterStats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(fighterStatistics)\n\u001b[1;32m      8\u001b[0m writer\u001b[38;5;241m.\u001b[39mwriterow(head)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriterows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfighterStats\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "#create csv file\n",
    "\n",
    "\n",
    "head = ['name', 'wins', 'losses', 'draws', 'height', 'reach', 'age', 'nation', 'sig_str_accuracy', 'sig_str_totals', 'takedown_accuracy', 'takedown_totals', 'sig_str_per_minute', 'takedown_avg_per_fifteen', 'sig_str_defense', 'knockdown_avg', 'sig_str_absorbed_per_min', 'submission_avg_per_fifteen', 'takedown_defense', 'avg_fight_time']\n",
    "\n",
    "with open('alt_fighter_stats.csv', 'w', encoding='UTF8', newline='') as fighterStatistics:\n",
    "    writer = csv.writer(fighterStatistics)\n",
    "    writer.writerow(head)\n",
    "    writer.writerows(fighterStats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
