{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "from csv import writer\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proxies: 42\n"
     ]
    }
   ],
   "source": [
    "proxylist =[]\n",
    "with open('working_proxies.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        proxylist.append(row[0])\n",
    "print(f'Proxies: {len(proxylist)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensure site is accessible\n",
    "def getProxyUserAgent():\n",
    "    for i in proxylist:\n",
    "        #test to see if website is accessible\n",
    "        userAgents = ['Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/116.0','Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/115.0','Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36','Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36','Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36','Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0','Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/116.0','Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36 Edg/115.0.1901.188','insomnia/8.4.5','Mozilla/5.0 (Linux; Android 13; Pixel 6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (Linux; Android 13; Pixel 6a) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (Linux; Android 13; Pixel 6 Pro) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (Linux; Android 13; Pixel 7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (Linux; Android 13; Pixel 7 Pro) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (Linux; Android 12; moto g pure) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (Linux; Android 12; moto g stylus 5G) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36v','Mozilla/5.0 (Linux; Android 13; SM-G998U) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36','Mozilla/5.0 (iPhone; CPU iPhone OS 12_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) FxiOS/13.2b11866 Mobile/16A366 Safari/605.1.15','Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/11.0 Mobile/15A372 Safari/604.1']\n",
    "        userAgent = userAgents[random.randint(0,len(userAgents)-1)]\n",
    "        try:\n",
    "            payload = ''\n",
    "            headers = {\n",
    "                \"cookie\": \"_tapology_mma_session=zo%252F9cU1na2qfRAvGf4E%252FBdxyMqNEgZbmqUYGnDxTYw%252BkgkuquO4qPimSMq%252FNc4fAxpLoIGwkl%252Fvw%252FhO04rqrL1PuS7516fTWktFyWhkz6YUy7MvWUVyjNQ7R26QYA8TeQruG5w%252B6RAj71bMME5MxoLjpSOs%252FyinaA6qsprmBZ2LnagrpzZ7bxaPvk7o%252FohTgZgxpo0FGWGaDdHERD%252B3Bt3C3ucykGOC7WB65EM8xB6C8gMNzGsvEu8FbvGnbMaoqzGzx%252FjRprzFrLN4mE5vdrJ1fsjoDV9cn5NEE2zI%253D--IkSvjCRiM5qMGaKi--o55iUwoIEhI6T8jM4UW6tA%253D%253D\",\n",
    "                \"User-Agent\": f'{userAgent}'\n",
    "            }\n",
    "\n",
    "            url = \"https://www.tapology.com\"\n",
    "        \n",
    "            #site request\n",
    "            response = requests.request(\"GET\", url, data=payload, headers=headers, proxies={'http': f\"http://{i}\"})\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            boutInfo = soup.find('div', class_=re.compile('right'))\n",
    "            labels = boutInfo.find_all('li')\n",
    "            proxyheader = [i,userAgent]\n",
    "            return proxyheader\n",
    "        except:\n",
    "            pass\n",
    "        #check to see if uesr agent was the issue\n",
    "        try:\n",
    "            userAgents.remove(userAgent)\n",
    "            userAgent = userAgents[random.randint(0,len(userAgents)-1)]\n",
    "            payload = ''\n",
    "            headers = {'User-Agent':f'{userAgent}',\n",
    "            \"cookie\": \"_tapology_mma_session=TCLB17ieOPnBLmCBTuxpX8s3uBODZMN3jL3jBbFhwPoywfbzG7gyvp%252BAzbOk4gOZ%252FOCykOUwcpEoJBwoj2rJyiMxdHWSaiLFkBYjfuUDpZ2VY6ECFn6rpTPmUBY1Zr2anIqiklY6fz9yQlBkPAhcx%252BWSzVgsc%252B%252F8UCqkb6WnM6xr8GUikb8U2UkMVYZ3Nj1dIA0vbXpDhKykqgW%252BCnlyglp8rtdlQ37m0SaYWjLDthG7Tik3idUvGlSXFAU55zAnxz6UNncMNhTbo5ltINfso54j60i7hOq0utNOz9w%253D--ChZexYwNpevIJ%252BV8--HhKStLELFfNWYOTZIAKM6Q%253D%253D\"}\n",
    "            url = \"https://www.tapology.com/fightcenter/bouts/2974-ufc-64-clay-the-carpenter-guida-vs-justin-pretty-boy-james\"\n",
    "        \n",
    "            #site request\n",
    "            response = requests.request(\"GET\", url, data=payload, headers=headers, proxies={'http': f\"http://{i}\"})\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            boutInfo = soup.find('div', class_=re.compile('right'))\n",
    "            labels = boutInfo.find_all('li')\n",
    "            proxyheader = [i,userAgent]\n",
    "            return proxyheader\n",
    "        #if user agent is not new issue, wait for next IP\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            print(\"Waiting for new IP...\")\n",
    "            ipurl = \"https://ipecho.net/plain\"\n",
    "            ipHeader = {\"User-Agent\": \"insomnia/8.4.5\"}\n",
    "            ipr = requests.request(\"GET\", url=ipurl, headers=ipHeader)\n",
    "            soup = BeautifulSoup(ipr.content, 'html.parser')\n",
    "            currentIp = soup.text.strip()\n",
    "            newIP = soup.text.strip()\n",
    "            while(currentIp == newIP):\n",
    "                ipurl = \"https://ipecho.net/plain\"\n",
    "                ipHeader = {\"User-Agent\": \"insomnia/8.4.5\"}\n",
    "                ipr = requests.request(\"GET\", url=ipurl, headers=ipHeader)\n",
    "                soup = BeautifulSoup(ipr.content, 'html.parser')\n",
    "                newIP = soup.text.strip()\n",
    "                time.sleep(15)\n",
    "            userAgents.remove(userAgent)\n",
    "            userAgent = userAgents[random.randint(0,len(userAgents)-1)]\n",
    "            payload = ''\n",
    "            headers = {'User-Agent':f'{userAgent}',\n",
    "            \"cookie\": \"_tapology_mma_session=TCLB17ieOPnBLmCBTuxpX8s3uBODZMN3jL3jBbFhwPoywfbzG7gyvp%252BAzbOk4gOZ%252FOCykOUwcpEoJBwoj2rJyiMxdHWSaiLFkBYjfuUDpZ2VY6ECFn6rpTPmUBY1Zr2anIqiklY6fz9yQlBkPAhcx%252BWSzVgsc%252B%252F8UCqkb6WnM6xr8GUikb8U2UkMVYZ3Nj1dIA0vbXpDhKykqgW%252BCnlyglp8rtdlQ37m0SaYWjLDthG7Tik3idUvGlSXFAU55zAnxz6UNncMNhTbo5ltINfso54j60i7hOq0utNOz9w%253D--ChZexYwNpevIJ%252BV8--HhKStLELFfNWYOTZIAKM6Q%253D%253D\"}\n",
    "            url = \"https://www.tapology.com/fightcenter/bouts/2974-ufc-64-clay-the-carpenter-guida-vs-justin-pretty-boy-james\"\n",
    "        \n",
    "            #site request\n",
    "            response = requests.request(\"GET\", url, data=payload, headers=headers, proxies={'http': f\"http://{i}\"})\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            boutInfo = soup.find('div', class_=re.compile('right'))\n",
    "            labels = boutInfo.find_all('li')\n",
    "            proxyheader = [i,userAgent]\n",
    "            return proxyheader\n",
    "        except:\n",
    "            print(\"Maintenence required...\")\n",
    "            input(\"Press enter to continue\")\n",
    "            userAgents.remove(userAgent)\n",
    "            userAgent = userAgents[random.randint(0,len(userAgents)-1)]\n",
    "            payload = ''\n",
    "            headers = {'User-Agent':f'{userAgent}',\n",
    "            \"cookie\": \"_tapology_mma_session=TCLB17ieOPnBLmCBTuxpX8s3uBODZMN3jL3jBbFhwPoywfbzG7gyvp%252BAzbOk4gOZ%252FOCykOUwcpEoJBwoj2rJyiMxdHWSaiLFkBYjfuUDpZ2VY6ECFn6rpTPmUBY1Zr2anIqiklY6fz9yQlBkPAhcx%252BWSzVgsc%252B%252F8UCqkb6WnM6xr8GUikb8U2UkMVYZ3Nj1dIA0vbXpDhKykqgW%252BCnlyglp8rtdlQ37m0SaYWjLDthG7Tik3idUvGlSXFAU55zAnxz6UNncMNhTbo5ltINfso54j60i7hOq0utNOz9w%253D--ChZexYwNpevIJ%252BV8--HhKStLELFfNWYOTZIAKM6Q%253D%253D\"}\n",
    "            url = \"https://www.tapology.com/fightcenter/bouts/2974-ufc-64-clay-the-carpenter-guida-vs-justin-pretty-boy-james\"\n",
    "        \n",
    "            #site request\n",
    "            response = requests.request(\"GET\", url, data=payload, headers=headers, proxies={'http': f\"http://{i}\"})\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            boutInfo = soup.find('div', class_=re.compile('right'))\n",
    "            labels = boutInfo.find_all('li')\n",
    "            proxyheader = [i,userAgent]\n",
    "            return proxyheader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#site request\n",
    "proxyheader = getProxyUserAgent()\n",
    "proxy = proxyheader[0]\n",
    "userAgent = proxyheader[1]\n",
    "querystring = {\"group\":\"ufc\",\"page\":1,\"region\":\"\",\"schedule\":\"results\",\"sport\":\"all\"}\n",
    "url = 'https://www.tapology.com/fightcenter'\n",
    "\n",
    "payload = \"\"\n",
    "headers = {\n",
    "    \"cookie\": \"_tapology_mma_session=%252BnGrxOO8u60FBkwjnPf5U9cMUlW%252B%252F76dZtFNqnrNzBiOvQybvXmEnNM%252Fu1%252BEvOx0w4zOYLO6aIlNCfl8UnsrtSYiMl2eRJHAyiBcnd2iP0A0MCwFxGErsRcK9jbT%252BixWWetj2aX%252FvsQSBYea%252Fe73CRDIdSn95lPxaMgzhrkIGIY2KzurUSeLm0hoWxHQyq01nb7UJfYbF53mL1vhZO1yAYpprixBeuhXy70HLYlQemANkpVvl7tT0Z5DTe68LgVyn8qXKLn1hOvclfkBIfaVwBd1HyV5eIRqOMicbIQ%253D--%252BzoeexZ3ARMoGYGy--kqTFUNtOGR74GqxibycT1g%253D%253D\",\n",
    "    \"User-Agent\": f\"{userAgent}\"\n",
    "}\n",
    "\n",
    "response = requests.request(\"GET\", url, data=payload, headers=headers, params=querystring, proxies={'http': f\"http://{proxy}, 'https:'https/{proxy}\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/fightcenter/events/101868-ufc\n"
     ]
    }
   ],
   "source": [
    "#get part for url of event\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "sections = soup.find_all('section', class_=re.compile('fcListing'))\n",
    "span = sections[0].find('span', class_=re.compile('name'))\n",
    "a = span.find('a')\n",
    "part = a['href']\n",
    "print(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#site request\n",
    "proxyheader = getProxyUserAgent()\n",
    "proxy = proxyheader[0]\n",
    "userAgent = proxyheader[1]\n",
    "headers = {\n",
    "    \"cookie\": \"_tapology_mma_session=SalX0GSlJmX83Xr61Esyd2IpHEnEaKZ8EYxG%252FzqzxFw61SFd5cUeTP0bI6faVXCwYrNZI%252FCI%252F8k3ulCobIDgFsfjQS0mH2Cmyrjw8uRPRid1zHpuRUdB38T9zitk9HAt06s%252BJfGPJHcaekBUI5HjpDKqJqiMNg7codsNhLvZcnHeW1FlGhcz%252BGEtmlLZDuRBcl2UPylh%252B4x97JplnC7%252FxEOXfQg51XgXLvIBL4dbuO90Cwblj7LJe3XnNpqLWcefA4r6d9gVHHKBiRN10S1K9ntnmMjzz%252FLTgDxPUBI%253D--cIDn0iKYjggibUZ3--CAvjxd4oiPcvmYyMijxPGA%253D%253D\",\n",
    "    \"User-Agent\": f'{userAgent}'\n",
    "}\n",
    "\n",
    "url = f'https://www.tapology.com{part}'\n",
    "site = requests.get(url, headers=headers, proxies={'http': f\"http://{proxy}, 'https:'https/{proxy}\"})\n",
    "print(site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/fightcenter/bouts/797823-ufc-296-leon-rocky-edwards-vs-colby-chaos-covington', '/fightcenter/bouts/797824-ufc-296-alexandre-the-cannibal-pantoja-vs-brandon-raw-dawg-royval-ii', '/fightcenter/bouts/798192-ufc-296-shavkat-nomad-rakhmonov-vs-stephen-wonderboy-thompson', '/fightcenter/bouts/798388-ufc-296-tony-el-cucuy-ferguson-vs-paddy-the-baddy-pimblett', '/fightcenter/bouts/825412-ufc-296-josh-cc0-emmett-vs-bryce-thug-nasty-mitchell', '/fightcenter/bouts/805139-ufc-296-alonzo-atomic-menifield-vs-dustin-the-hanyak-jacoby', '/fightcenter/bouts/799933-ufc-296-irene-aldana-vs-karol-rosa', '/fightcenter/bouts/807290-ufc-296-cody-no-love-garbrandt-vs-brian-boom-kelleher', '/fightcenter/bouts/800321-ufc-296-king-casey-o-neill-vs-queen-of-violence-ariane-lipski', '/fightcenter/bouts/798624-ufc-296-tagir-ulanbekov-vs-cody-durden', '/fightcenter/bouts/813864-ufc-296-andre-touchy-fili-vs-lucas-almeida', '/fightcenter/bouts/807639-ufc-296-shamil-gaziev-vs-martin-badys-buday']\n"
     ]
    }
   ],
   "source": [
    "#get url parts from all fights on the card\n",
    "soup = BeautifulSoup(site.content, 'html.parser')\n",
    "spans = soup.find_all('span', class_='billing')\n",
    "parts = []\n",
    "for span in spans:\n",
    "    href = span.find('a')\n",
    "    part = href['href']\n",
    "    parts.append(part)\n",
    "print(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.tapology.com/fightcenter/bouts/797823-ufc-296-leon-rocky-edwards-vs-colby-chaos-covington\n",
      "Scraping Leon Edwards vs Colby Covington...0%\n",
      "https://www.tapology.com/fightcenter/bouts/797824-ufc-296-alexandre-the-cannibal-pantoja-vs-brandon-raw-dawg-royval-ii\n",
      "Scraping Alexandre Pantoja vs Brandon Royval...8%\n",
      "https://www.tapology.com/fightcenter/bouts/798192-ufc-296-shavkat-nomad-rakhmonov-vs-stephen-wonderboy-thompson\n",
      "Scraping Shavkat Rakhmonov vs Stephen Thompson...17%\n",
      "https://www.tapology.com/fightcenter/bouts/798388-ufc-296-tony-el-cucuy-ferguson-vs-paddy-the-baddy-pimblett\n",
      "Scraping Paddy Pimblett vs Tony Ferguson...25%\n",
      "https://www.tapology.com/fightcenter/bouts/825412-ufc-296-josh-cc0-emmett-vs-bryce-thug-nasty-mitchell\n",
      "Scraping Josh Emmett vs Bryce Mitchell...33%\n",
      "https://www.tapology.com/fightcenter/bouts/805139-ufc-296-alonzo-atomic-menifield-vs-dustin-the-hanyak-jacoby\n",
      "Scraping Alonzo Menifield vs Dustin Jacoby...42%\n",
      "https://www.tapology.com/fightcenter/bouts/799933-ufc-296-irene-aldana-vs-karol-rosa\n",
      "Scraping Irene Aldana vs Karol Rosa...50%\n",
      "https://www.tapology.com/fightcenter/bouts/807290-ufc-296-cody-no-love-garbrandt-vs-brian-boom-kelleher\n",
      "Scraping Cody Garbrandt vs Brian Kelleher...58%\n",
      "https://www.tapology.com/fightcenter/bouts/800321-ufc-296-king-casey-o-neill-vs-queen-of-violence-ariane-lipski\n",
      "Scraping Ariane Lipski vs Casey O'Neill...67%\n",
      "https://www.tapology.com/fightcenter/bouts/798624-ufc-296-tagir-ulanbekov-vs-cody-durden\n",
      "Scraping Tagir Ulanbekov vs Cody Durden...75%\n",
      "https://www.tapology.com/fightcenter/bouts/813864-ufc-296-andre-touchy-fili-vs-lucas-almeida\n",
      "Scraping Andre Fili vs Lucas Almeida...83%\n",
      "https://www.tapology.com/fightcenter/bouts/807639-ufc-296-shamil-gaziev-vs-martin-badys-buday\n",
      "Scraping Shamil Gaziev vs Martin Buday...92%\n"
     ]
    }
   ],
   "source": [
    "fightStats = []\n",
    "\n",
    "for i in parts:\n",
    "    proxyheader = getProxyUserAgent()\n",
    "    proxy = proxyheader[0]\n",
    "    userAgent = proxyheader[1]\n",
    "    payload = \"\"\n",
    "    headers = {\n",
    "        \"cookie\": \"_tapology_mma_session=6FGp%252FJUSTWYMfoxo8TfW%252BIXzLpUq7U9PMAJo5rHJA0IW5nmUvBfyvSfM1xK04kt35b9X7qEKQCxCoWu2ufxYHMbwDH88yla0%252FpzMP71n6pbfW%252FroMtWAh2n5sk9oxYFnmpfxohRaQMysmv%252B9f5fj0Omemblq8KM9NEDFiR5UPFyFXXYiM0Ee%252FWLYZ5JqObzpWnulDsrgvVtdtWFthH9vY6xz9HAvSb4KOm1HA6TvXXxYOO2Vuk6MeJwKYdwj3yqz8dV%252FHRgPknI5PsGEx3z3mxBNOJaFkRBT6iB%252B5Zo%253D--pNnhVuV4ORLaBVOE--yUSbtIv6C91epo3hOY0i5w%253D%253D\",\n",
    "        \"User-Agent\": f'{userAgent}'\n",
    "    }\n",
    "\n",
    "\n",
    "    url = f\"https://www.tapology.com{i}\"\n",
    "        \n",
    "    #site request\n",
    "    response = requests.request(\"GET\", url, data=payload, headers=headers, proxies={'http': f\"http://{proxy}, 'https:'https/{proxy}\"})\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    \n",
    "    try:\n",
    "        #scrape event\n",
    "        boutInfo = soup.find('div', class_=re.compile('right'))\n",
    "        lilabels = boutInfo.find_all('li')\n",
    "    except:\n",
    "        proxyheader = getProxyUserAgent()\n",
    "        proxy = proxyheader[0]\n",
    "        userAgent = proxyheader[1]\n",
    "        payload = \"\"\n",
    "        headers = {\n",
    "            \"cookie\": \"_tapology_mma_session=6FGp%252FJUSTWYMfoxo8TfW%252BIXzLpUq7U9PMAJo5rHJA0IW5nmUvBfyvSfM1xK04kt35b9X7qEKQCxCoWu2ufxYHMbwDH88yla0%252FpzMP71n6pbfW%252FroMtWAh2n5sk9oxYFnmpfxohRaQMysmv%252B9f5fj0Omemblq8KM9NEDFiR5UPFyFXXYiM0Ee%252FWLYZ5JqObzpWnulDsrgvVtdtWFthH9vY6xz9HAvSb4KOm1HA6TvXXxYOO2Vuk6MeJwKYdwj3yqz8dV%252FHRgPknI5PsGEx3z3mxBNOJaFkRBT6iB%252B5Zo%253D--pNnhVuV4ORLaBVOE--yUSbtIv6C91epo3hOY0i5w%253D%253D\",\n",
    "            \"User-Agent\": f'{userAgent}'\n",
    "        }\n",
    "        response = requests.request(\"GET\", url, data=payload, headers=headers, proxies={'http': f\"http://{proxy}, 'https:'https/{proxy}\"})\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        #scrape event\n",
    "        boutInfo = soup.find('div', class_=re.compile('right'))\n",
    "        lilabels = boutInfo.find_all('li')\n",
    "        \n",
    "    print(url)\n",
    "    #initialize attributes\n",
    "    event = None\n",
    "    date = None\n",
    "    venue = None\n",
    "    title_fight = 'no'\n",
    "    billing = None\n",
    "    winner = None\n",
    "    loser = None\n",
    "    winner_wins = None\n",
    "    loser_wins = None\n",
    "    winner_losses = None\n",
    "    loser_losses = None\n",
    "    winner_draws = None\n",
    "    loser_draws = None\n",
    "    winner_age = None\n",
    "    loser_age = None\n",
    "    belt_status = None\n",
    "    winner_nationality = None\n",
    "    loser_nationality = None\n",
    "    winner_fan = None\n",
    "    loser_fan = None\n",
    "    fight_name = None\n",
    "\n",
    "    \n",
    "    for num in range(1, len(lilabels)+1):\n",
    "        #scrape + clean event name\n",
    "        try:\n",
    "            if(lilabels[num].find('strong').text.strip() == 'Event:'):\n",
    "                event = lilabels[num].find('a').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        #scrape + clean date\n",
    "        try:\n",
    "            if(lilabels[num].find('strong').text.strip() == 'Date:'):\n",
    "                nCleanDate = lilabels[num].find('span').text.strip()\n",
    "                dateList = nCleanDate.split(' ')\n",
    "                date = dateList[1]\n",
    "        except:\n",
    "            pass\n",
    "        #scrape + clean venue\n",
    "        try:\n",
    "            if(lilabels[num].find('strong').text.strip() == 'Venue:'):\n",
    "                venue = lilabels[num].find('span').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        #scrape whether it is a title fight\n",
    "        try:\n",
    "            if(lilabels[num].find('strong').text.strip() == 'Title on Line:'):\n",
    "                title_fight = 'yes'\n",
    "        except:\n",
    "            pass\n",
    "        #scrape + clean belt status\n",
    "        try:\n",
    "            if(lilabels[num].find('strong').text.strip() == 'Belt Status Before Fight:'):\n",
    "                belt_status = lilabels[num].find('span').text.strip()\n",
    "                #needs to be cleaned\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    \n",
    "    #scrape + clean billing\n",
    "    try:\n",
    "        billingInfo = soup.find('h4', class_=re.compile('boutPreResult'))\n",
    "        billing_info = billingInfo.text.strip()\n",
    "        billList = billing_info.split('|')\n",
    "        billing = billList[0][:-1]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #scrape +clean winner+fightname\n",
    "    try:\n",
    "        fight_name = f'{soup.find('span', class_=re.compile('fName left')).find('a').text.strip()} vs {soup.find('span', class_=re.compile('fName right')).find('a').text.strip()}'\n",
    "        if(soup.find('span', class_=re.compile('fName left')).find('a').text.strip().lower().__contains__(soup.find('p', class_=re.compile('results')).find('span').text.strip().lower())):\n",
    "            winnerInfo = soup.find('span', class_=re.compile('fName left'))\n",
    "            winner = winnerInfo.find('a').text.strip()\n",
    "            loserInfo = soup.find('span', class_=re.compile('fName right'))\n",
    "            loser = loserInfo.find('a').text.strip()\n",
    "        else:\n",
    "            pass\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #scrape + parse table\n",
    "    table = soup.find('table', class_=re.compile('fighterStats spaced'))\n",
    "    trLabels = table.find_all('tr')\n",
    "    for tr in trLabels:\n",
    "        try:\n",
    "            if(tr.find('td', class_=re.compile('category')).text.strip() == 'Pro Record At Fight'):\n",
    "                tdLabels = tr.find_all('td')\n",
    "                #scrape +clean records\n",
    "                winner_record = tdLabels[0].text.strip()\n",
    "                loser_record = tdLabels[len(tdLabels)-1].text.strip()\n",
    "                #clean to fit atrributes\n",
    "                list_winner_record = winner_record.split('-')\n",
    "                winner_wins = list_winner_record[0]\n",
    "                winner_losses = list_winner_record[1]\n",
    "                winner_draws = list_winner_record[2]\n",
    "                list_loser_record = loser_record.split('-')\n",
    "                loser_wins = list_loser_record[0]\n",
    "                loser_losses = list_loser_record[1]\n",
    "                loser_draws = list_loser_record[2]\n",
    "        except:\n",
    "            pass\n",
    "        #scrape + clean nationality\n",
    "        try:\n",
    "            if(tr.find('td', class_=re.compile('category')).text.strip() == 'Nationality'):\n",
    "                nationalities = tr.find_all('img', class_=re.compile('countryFlag mini'))\n",
    "                winner_nationality = nationalities[0].text.strip()\n",
    "                loser_nationality = nationalities[1].text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        #scrape + clean age\n",
    "        try:\n",
    "            if(tr.find('td', class_='category').text.strip()== 'Age at Fight'):\n",
    "                tdLabels = tr.find_all('td')\n",
    "                #scrape + clean ages\n",
    "                winnerAge = tdLabels[0].text.strip()\n",
    "                winnerAgeList = winnerAge.split(',')\n",
    "                winner_age = winnerAgeList[0][:-6]\n",
    "                loserAge = tdLabels[len(tdLabels)-1].text.strip()\n",
    "                loserAgeList = loserAge.split(',')\n",
    "                loser_age = loserAgeList[0][:-6]\n",
    "        except:\n",
    "            pass\n",
    "    #find + clean tapology fan predictions\n",
    "    try:\n",
    "        divs = soup.find_all('div', class_='number')\n",
    "        loser_fan = divs[0].text.strip()\n",
    "        winner_fan = divs[1].text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    print(f'Scraping {fight_name}...')\n",
    "    fightStats.append([fight_name,winner, loser, event,date,venue,title_fight,billing,winner_wins ,loser_wins ,winner_losses ,loser_losses ,winner_draws,loser_draws,winner_age ,loser_age ,belt_status ,winner_nationality ,loser_nationality ,winner_fan ,loser_fan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = ['fight','winner', 'loser', 'event','date','venue','title_fight','billing','winner_wins' ,'loser_wins' ,'winner_losses' ,'loser_losses' ,'winner_draws','loser_draws','winner_age' ,'loser_age' ,'belt_status' ,'winner_nationality' ,'loser_nationality' ,'winner_fan ','loser_fan']\n",
    "\n",
    "\n",
    "with open('updateTapology.csv', 'w', encoding='UTF8', newline='') as updateTapology:\n",
    "    writer = csv.writer(updateTapology)\n",
    "    writer.writerow(head)\n",
    "    writer.writerows(fightStats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
